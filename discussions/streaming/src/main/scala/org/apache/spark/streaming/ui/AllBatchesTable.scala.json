[
  {
    "id" : "df31ad50-0e84-45fa-bedf-6195c95659b8",
    "prId" : 26756,
    "prUrl" : "https://github.com/apache/spark/pull/26756#pullrequestreview-327324777",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b3d22a15-8fa3-4a88-9169-7214295da9f3",
        "parentId" : null,
        "authorId" : "75554730-8183-463c-bf1d-7cd5b4e9f22b",
        "body" : "I think this assert is unnecessary since none of them will vary ever?",
        "createdAt" : "2019-12-04T14:45:11Z",
        "updatedAt" : "2019-12-15T04:22:23Z",
        "lastEditedBy" : "75554730-8183-463c-bf1d-7cd5b4e9f22b",
        "tags" : [
        ]
      },
      {
        "id" : "01ce1a06-291a-4024-b4a5-7c0a02640161",
        "parentId" : "b3d22a15-8fa3-4a88-9169-7214295da9f3",
        "authorId" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "body" : "assert is there to make sure of that only.",
        "createdAt" : "2019-12-05T06:08:38Z",
        "updatedAt" : "2019-12-15T04:22:23Z",
        "lastEditedBy" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "tags" : [
        ]
      }
    ],
    "commit" : "7ec80b920014ac326fd5b23e6699eca040111a2f",
    "line" : 86,
    "diffHunk" : "@@ -1,1 +75,79 @@      Some(\"Total time taken to handle a batch\"), None)\n\n    assert(completedBatchTableHeaders.length == tooltips.length)\n\n    val headerRow: Seq[Node] = {"
  },
  {
    "id" : "5f57072a-bfa4-4470-81f7-c3705efbc99b",
    "prId" : 26756,
    "prUrl" : "https://github.com/apache/spark/pull/26756#pullrequestreview-327324453",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c773a693-1d73-463d-813d-140b03290c38",
        "parentId" : null,
        "authorId" : "75554730-8183-463c-bf1d-7cd5b4e9f22b",
        "body" : "can we use `getFirstFailureReason(()` here?",
        "createdAt" : "2019-12-04T15:04:56Z",
        "updatedAt" : "2019-12-15T04:22:23Z",
        "lastEditedBy" : "75554730-8183-463c-bf1d-7cd5b4e9f22b",
        "tags" : [
        ]
      },
      {
        "id" : "580fe6e8-17a4-4d55-9ce9-75eee744e775",
        "parentId" : "c773a693-1d73-463d-813d-140b03290c38",
        "authorId" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "body" : "No. We cannot use `getFirstFailureReason()` here",
        "createdAt" : "2019-12-05T06:07:20Z",
        "updatedAt" : "2019-12-15T04:22:23Z",
        "lastEditedBy" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "tags" : [
        ]
      }
    ],
    "commit" : "7ec80b920014ac326fd5b23e6699eca040111a2f",
    "line" : 278,
    "diffHunk" : "@@ -1,1 +183,187 @@\n  protected def getFirstFailureTableCell(batch: BatchUIData): Seq[Node] = {\n    val firstFailureReason = batch.outputOperations.flatMap(_._2.failureReason).headOption\n    firstFailureReason.map { failureReason =>\n      val failureReasonForUI = UIUtils.createOutputOperationFailureForUI(failureReason)"
  },
  {
    "id" : "ce43f7a1-9743-4cdf-a2bc-c4a9cd2660c7",
    "prId" : 26756,
    "prUrl" : "https://github.com/apache/spark/pull/26756#pullrequestreview-327991395",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4eda8825-e36c-4358-bf53-1e9184fe8e6d",
        "parentId" : null,
        "authorId" : "d0d56018-475d-4da3-93a6-5e843402b7f2",
        "body" : "Is the tooltip newly added in this PR or was that already there?",
        "createdAt" : "2019-12-05T15:38:01Z",
        "updatedAt" : "2019-12-15T04:22:23Z",
        "lastEditedBy" : "d0d56018-475d-4da3-93a6-5e843402b7f2",
        "tags" : [
        ]
      },
      {
        "id" : "18d07e0a-4dd0-49b0-8c1f-1c9c9876ad24",
        "parentId" : "4eda8825-e36c-4358-bf53-1e9184fe8e6d",
        "authorId" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "body" : "These tooltips were already there.",
        "createdAt" : "2019-12-06T04:22:27Z",
        "updatedAt" : "2019-12-15T04:22:23Z",
        "lastEditedBy" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "tags" : [
        ]
      }
    ],
    "commit" : "7ec80b920014ac326fd5b23e6699eca040111a2f",
    "line" : 82,
    "diffHunk" : "@@ -1,1 +71,75 @@      \"Processing Delay\", \"Total Delay\", \"Output Ops: Succeeded/Total\")\n\n    val tooltips = Seq(None, None, Some(\"Time taken by Streaming scheduler to\" +\n      \" submit jobs of a batch\"), Some(\"Time taken to process all jobs of a batch\"),\n      Some(\"Total time taken to handle a batch\"), None)"
  },
  {
    "id" : "fd646082-92b3-46d3-bb0e-cbd39c0b34c8",
    "prId" : 26756,
    "prUrl" : "https://github.com/apache/spark/pull/26756#pullrequestreview-328206048",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8d703038-baf1-4437-8039-174ee8fc2809",
        "parentId" : null,
        "authorId" : "d0d56018-475d-4da3-93a6-5e843402b7f2",
        "body" : "I think the same code is there in the method `createOutputOperationProgressBar`? Can't we use that?",
        "createdAt" : "2019-12-06T13:50:54Z",
        "updatedAt" : "2019-12-15T04:22:23Z",
        "lastEditedBy" : "d0d56018-475d-4da3-93a6-5e843402b7f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "7ec80b920014ac326fd5b23e6699eca040111a2f",
    "line" : 204,
    "diffHunk" : "@@ -1,1 +165,169 @@      <td class=\"progress-cell\">\n        {SparkUIUtils.makeProgressBar(started = batch.numActiveOutputOp,\n        completed = batch.numCompletedOutputOp, failed = batch.numFailedOutputOp, skipped = 0,\n        reasonToNumKilled = Map.empty, total = batch.outputOperations.size)}\n      </td>"
  },
  {
    "id" : "16777d1e-9bd5-4613-b93f-5b4b6033bcb5",
    "prId" : 26756,
    "prUrl" : "https://github.com/apache/spark/pull/26756#pullrequestreview-328206048",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ef145f0f-83cd-4e51-a5eb-24592665492f",
        "parentId" : null,
        "authorId" : "d0d56018-475d-4da3-93a6-5e843402b7f2",
        "body" : "Is it newly added? `getFirstFailureReason` method already exist right? can't we reuse it?",
        "createdAt" : "2019-12-06T13:53:34Z",
        "updatedAt" : "2019-12-15T04:22:23Z",
        "lastEditedBy" : "d0d56018-475d-4da3-93a6-5e843402b7f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "7ec80b920014ac326fd5b23e6699eca040111a2f",
    "line" : 265,
    "diffHunk" : "@@ -1,1 +179,183 @@\n  protected def getFirstFailureReason(batches: Seq[BatchUIData]): Option[String] = {\n    batches.flatMap(_.outputOperations.flatMap(_._2.failureReason)).headOption\n  }\n"
  },
  {
    "id" : "5babad21-3c57-4620-b559-8f0f606150c2",
    "prId" : 26756,
    "prUrl" : "https://github.com/apache/spark/pull/26756#pullrequestreview-328206048",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "077ae6b4-0c09-4bd8-bcdf-6d222b068796",
        "parentId" : null,
        "authorId" : "d0d56018-475d-4da3-93a6-5e843402b7f2",
        "body" : "Same here. Avoid duplication of the methods",
        "createdAt" : "2019-12-06T13:54:10Z",
        "updatedAt" : "2019-12-15T04:22:23Z",
        "lastEditedBy" : "d0d56018-475d-4da3-93a6-5e843402b7f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "7ec80b920014ac326fd5b23e6699eca040111a2f",
    "line" : 278,
    "diffHunk" : "@@ -1,1 +183,187 @@\n  protected def getFirstFailureTableCell(batch: BatchUIData): Seq[Node] = {\n    val firstFailureReason = batch.outputOperations.flatMap(_._2.failureReason).headOption\n    firstFailureReason.map { failureReason =>\n      val failureReasonForUI = UIUtils.createOutputOperationFailureForUI(failureReason)"
  },
  {
    "id" : "9351dfc8-8895-464d-9486-6d89e44cd3f8",
    "prId" : 26756,
    "prUrl" : "https://github.com/apache/spark/pull/26756#pullrequestreview-332282978",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bbbc29cf-2541-4b57-ae0f-1b74bbcca251",
        "parentId" : null,
        "authorId" : "d0d56018-475d-4da3-93a6-5e843402b7f2",
        "body" : "Don't we need to add `#tableHeaderId` here?\r\nhttps://github.com/apache/spark/blob/67b644c3d74b0587dd5d498b903383ac4de932fe/sql/core/src/main/scala/org/apache/spark/sql/execution/ui/AllExecutionsPage.scala#L259",
        "createdAt" : "2019-12-15T19:36:44Z",
        "updatedAt" : "2019-12-15T19:56:59Z",
        "lastEditedBy" : "d0d56018-475d-4da3-93a6-5e843402b7f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "7ec80b920014ac326fd5b23e6699eca040111a2f",
    "line" : 42,
    "diffHunk" : "@@ -1,1 +55,59 @@      s\"&$streamingBatchTag.sort=$encodedSortColumn\" +\n      s\"&$streamingBatchTag.desc=$desc\" +\n      s\"&$pageSizeFormField=$pageSize\"\n  }\n"
  },
  {
    "id" : "782aaef7-7d83-4a98-80dc-882cac3a1972",
    "prId" : 26756,
    "prUrl" : "https://github.com/apache/spark/pull/26756#pullrequestreview-332360876",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f940bda0-f28f-4fb3-837b-de0b43a92288",
        "parentId" : null,
        "authorId" : "d0d56018-475d-4da3-93a6-5e843402b7f2",
        "body" : "Here also it seems we need to add `#tableHeaderId` ?\r\nhttps://github.com/apache/spark/blob/67b644c3d74b0587dd5d498b903383ac4de932fe/sql/core/src/main/scala/org/apache/spark/sql/execution/ui/AllExecutionsPage.scala#L268",
        "createdAt" : "2019-12-15T19:37:55Z",
        "updatedAt" : "2019-12-15T19:56:59Z",
        "lastEditedBy" : "d0d56018-475d-4da3-93a6-5e843402b7f2",
        "tags" : [
        ]
      },
      {
        "id" : "a9cba0ce-04de-4a85-8a90-02ae1d158f68",
        "parentId" : "f940bda0-f28f-4fb3-837b-de0b43a92288",
        "authorId" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "body" : "I will add the `tableHeaderId`  in the link.",
        "createdAt" : "2019-12-16T06:33:08Z",
        "updatedAt" : "2019-12-16T06:33:09Z",
        "lastEditedBy" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "tags" : [
        ]
      }
    ],
    "commit" : "7ec80b920014ac326fd5b23e6699eca040111a2f",
    "line" : 61,
    "diffHunk" : "@@ -1,1 +64,68 @@  override def goButtonFormPath: String = {\n    val encodedSortColumn = URLEncoder.encode(sortColumn, UTF_8.name())\n    s\"$parameterPath&$streamingBatchTag.sort=$encodedSortColumn&$streamingBatchTag.desc=$desc\"\n  }\n"
  },
  {
    "id" : "dc3b889d-f87f-4439-a523-eacad6cfe315",
    "prId" : 26756,
    "prUrl" : "https://github.com/apache/spark/pull/26756#pullrequestreview-332413096",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "42d90627-56f4-4159-9e70-01bd1f74220b",
        "parentId" : null,
        "authorId" : "d0d56018-475d-4da3-93a6-5e843402b7f2",
        "body" : "Is the headers only for `completedBatchTables`?",
        "createdAt" : "2019-12-15T19:38:42Z",
        "updatedAt" : "2019-12-15T19:56:59Z",
        "lastEditedBy" : "d0d56018-475d-4da3-93a6-5e843402b7f2",
        "tags" : [
        ]
      },
      {
        "id" : "c9b98ff2-f524-4d70-b7f9-5b5c024889bb",
        "parentId" : "42d90627-56f4-4159-9e70-01bd1f74220b",
        "authorId" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "body" : "Both the tables are identical i.e. the schema is same for both. So headers will remain same for both. But yeah, `completedBatchTableHeaders` is misleading. So, i will update the variable name.",
        "createdAt" : "2019-12-16T06:30:34Z",
        "updatedAt" : "2019-12-16T06:30:35Z",
        "lastEditedBy" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "tags" : [
        ]
      },
      {
        "id" : "ff12968d-d38f-4048-a917-402a78594eef",
        "parentId" : "42d90627-56f4-4159-9e70-01bd1f74220b",
        "authorId" : "d0d56018-475d-4da3-93a6-5e843402b7f2",
        "body" : "From the attached screenshot, I can see `Total Delay` isn't there in the `ActiveBatches` table and `Status` field isn't there in the `CompletedBatches` table? ",
        "createdAt" : "2019-12-16T08:55:35Z",
        "updatedAt" : "2019-12-16T08:55:35Z",
        "lastEditedBy" : "d0d56018-475d-4da3-93a6-5e843402b7f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "7ec80b920014ac326fd5b23e6699eca040111a2f",
    "line" : 79,
    "diffHunk" : "@@ -1,1 +68,72 @@\n  override def headers: Seq[Node] = {\n    val completedBatchTableHeaders = Seq(\"Batch Time\", \"Records\", \"Scheduling Delay\",\n      \"Processing Delay\", \"Total Delay\", \"Output Ops: Succeeded/Total\")\n"
  }
]