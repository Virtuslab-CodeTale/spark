[
  {
    "id" : "d755d9e2-8732-45de-aaf1-e36321a20e75",
    "prId" : 31323,
    "prUrl" : "https://github.com/apache/spark/pull/31323#pullrequestreview-576042977",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "eb0bfda4-2ca7-4b1f-9ef6-0758aad8b6a9",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "@LuciferYang, can you fix this line to `Utils.tryWithResource(Source.fromFile(kdc.getKrb5conf, \"UTF-8\")) { krb5Conf  =>`? that will reduce the diff  a lot.",
        "createdAt" : "2021-01-26T04:49:54Z",
        "updatedAt" : "2021-01-26T05:44:52Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "38fa1173-70e1-4270-8d4c-82af9c410a12",
        "parentId" : "eb0bfda4-2ca7-4b1f-9ef6-0758aad8b6a9",
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "replace with  `Utils.tryWithResource(Source.fromFile(kdc.getKrb5conf, \"UTF-8\"))(_.getLines().toList)`, only 1 line changed",
        "createdAt" : "2021-01-26T05:46:56Z",
        "updatedAt" : "2021-01-26T05:46:56Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      }
    ],
    "commit" : "245d8446e831043a140b8c16a31a9710328a67a7",
    "line" : 3,
    "diffHunk" : "@@ -1,1 +167,171 @@   * In this method we rewrite krb5.conf to make kdc and client use the same enctypes\n   */\n  private def rewriteKrb5Conf(): Unit = {\n    val krb5Conf = Utils\n      .tryWithResource(Source.fromFile(kdc.getKrb5conf, \"UTF-8\"))(_.getLines().toList)"
  },
  {
    "id" : "8a7ccd0b-9d4a-4a62-9b1c-72c19a6d0d25",
    "prId" : 30939,
    "prUrl" : "https://github.com/apache/spark/pull/30939#pullrequestreview-558962501",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a727f98f-123b-4ba0-8bb0-36c58c0beeea",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "https://github.com/apache/kafka/pull/8931",
        "createdAt" : "2020-12-27T22:31:55Z",
        "updatedAt" : "2020-12-28T05:31:54Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "91a6ccd0ac017b7ab8122103aa183969f6e0c91d",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +575,579 @@    // ensure that logs from all replicas are deleted if delete topic is marked successful\n    assert(servers.forall(server => topicAndPartitions.forall(tp =>\n      server.getLogManager.getLog(tp).isEmpty)),\n      s\"topic $topic still exists in log manager\")\n    // ensure that topic is removed from all cleaner offsets"
  },
  {
    "id" : "92c81916-ce1f-4b3b-8169-d44f98d39df5",
    "prId" : 29386,
    "prUrl" : "https://github.com/apache/spark/pull/29386#pullrequestreview-463527416",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "63c6545e-7ba4-46fb-948f-92a767ed3c28",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "This change is required to compile.",
        "createdAt" : "2020-08-07T18:42:49Z",
        "updatedAt" : "2020-08-07T18:42:49Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "3001355177ff581e25b8cded79d4ef79a0e48200",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +396,400 @@\n  def getAllTopicsAndPartitionSize(): Seq[(String, Int)] = {\n    zkClient.getPartitionsForTopics(zkClient.getAllTopicsInCluster()).mapValues(_.size).toSeq\n  }\n"
  },
  {
    "id" : "4faea20a-d908-4432-9422-5eca76236375",
    "prId" : 26960,
    "prUrl" : "https://github.com/apache/spark/pull/26960#pullrequestreview-335080548",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "90e79bb7-fea7-41cf-bd85-bdbe3c028988",
        "parentId" : null,
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "The return type is changed - it no longer returns Option, but includes None in its return type.",
        "createdAt" : "2019-12-20T06:01:42Z",
        "updatedAt" : "2019-12-20T15:24:58Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      }
    ],
    "commit" : "4cca9d27f08f595c1e1dd8df6bdbf8024ec6e59d",
    "line" : 118,
    "diffHunk" : "@@ -1,1 +583,587 @@    // ensure that the topic-partition has been deleted from all brokers' replica managers\n    assert(servers.forall(server => topicAndPartitions.forall(tp =>\n      server.replicaManager.getPartition(tp) == HostedPartition.None)),\n      s\"topic $topic still exists in the replica manager\")\n    // ensure that logs from all replicas are deleted if delete topic is marked successful"
  },
  {
    "id" : "11e7d625-2eae-41c2-8d54-56c56dc38b11",
    "prId" : 26960,
    "prUrl" : "https://github.com/apache/spark/pull/26960#pullrequestreview-335615867",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ff69e005-6525-4d37-b0a5-510fb9740414",
        "parentId" : null,
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "partitionState.basePartitionState no longer exists. partitionState.basePartitionState.XXX seem to be moved to partitionState.XXX, at least for these we use",
        "createdAt" : "2019-12-20T06:03:24Z",
        "updatedAt" : "2019-12-20T15:24:58Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      },
      {
        "id" : "bef983ba-1e14-442b-8ab9-940771b4467e",
        "parentId" : "ff69e005-6525-4d37-b0a5-510fb9740414",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Got it.",
        "createdAt" : "2019-12-21T18:07:03Z",
        "updatedAt" : "2019-12-21T18:07:04Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "4cca9d27f08f595c1e1dd8df6bdbf8024ec6e59d",
    "line" : 145,
    "diffHunk" : "@@ -1,1 +626,630 @@      case Some(partitionState) =>\n        zkClient.getLeaderForPartition(new TopicPartition(topic, partition)).isDefined &&\n          Request.isValidBrokerId(partitionState.leader) &&\n          !partitionState.replicas.isEmpty\n"
  }
]