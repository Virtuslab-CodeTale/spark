[
  {
    "id" : "d7df8064-b94b-4cb8-bfd0-bbef08c8bdfd",
    "prId" : 32609,
    "prUrl" : "https://github.com/apache/spark/pull/32609#pullrequestreview-667296982",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e67f8d55-cb79-4a62-8f4d-197cc0c1293e",
        "parentId" : null,
        "authorId" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "body" : "`specifying both global timestamp and specific timestamp for partition` added to test case 1. vs 2. fallback which is good. In order to cover all \"preferences\" maybe we can add a case where all config options added.\r\n",
        "createdAt" : "2021-05-24T06:39:02Z",
        "updatedAt" : "2021-05-24T06:58:14Z",
        "lastEditedBy" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "tags" : [
        ]
      },
      {
        "id" : "b76c4163-05c1-47f7-b494-068af1972f97",
        "parentId" : "e67f8d55-cb79-4a62-8f4d-197cc0c1293e",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "Yeah I changed the test a bit to cover two cases: all options / timestamp per partition vs offset. Thanks for the suggestion.",
        "createdAt" : "2021-05-25T00:31:59Z",
        "updatedAt" : "2021-05-25T00:31:59Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      }
    ],
    "commit" : "b72f590de83217aa30753df1a28f2b1ac9459983",
    "line" : 137,
    "diffHunk" : "@@ -1,1 +580,584 @@      offsetOptionKey: String,\n      defaultOffsets: KafkaOffsetRangeLimit): KafkaOffsetRangeLimit = {\n    // The order below represents \"preferences\"\n\n    if (params.contains(globalOffsetTimestampOptionKey)) {"
  },
  {
    "id" : "480b8cdf-f6b4-4ee2-a2bf-6efdce5131ec",
    "prId" : 24967,
    "prUrl" : "https://github.com/apache/spark/pull/24967#pullrequestreview-253956411",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "48661be7-409e-4a6d-bb51-9817e939fccd",
        "parentId" : null,
        "authorId" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "body" : "This is not a required change but thought it would be good to simplify.",
        "createdAt" : "2019-06-25T12:05:36Z",
        "updatedAt" : "2019-08-08T11:49:28Z",
        "lastEditedBy" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "tags" : [
        ]
      }
    ],
    "commit" : "e0e8a8851f975311be990c5a4889d4c9870c3bea",
    "line" : 132,
    "diffHunk" : "@@ -1,1 +456,460 @@      val uniqueGroupId = streamingUniqueGroupId(caseInsensitiveOptions, checkpointLocation)\n\n      val specifiedKafkaParams = convertToSpecifiedParams(caseInsensitiveOptions)\n\n      val startingStreamOffsets = KafkaSourceProvider.getKafkaOffsetRangeLimit("
  },
  {
    "id" : "7a264c25-251b-4f1b-8c56-a4c62376d8db",
    "prId" : 24738,
    "prUrl" : "https://github.com/apache/spark/pull/24738#pullrequestreview-252308114",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cbb193b2-2e90-4405-b9d2-81a0177433a4",
        "parentId" : null,
        "authorId" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "body" : "I think group ID configuration should be available on batch side as well but not yet added even if couple of lines. Don't want to mix up several intentions in this PR. I'm going to file another jira + PR  when this one merged.",
        "createdAt" : "2019-06-20T13:59:34Z",
        "updatedAt" : "2019-07-01T12:57:50Z",
        "lastEditedBy" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "tags" : [
        ]
      }
    ],
    "commit" : "e8f9774522e738a39d44d750017eb7d5296dbdd1",
    "line" : 120,
    "diffHunk" : "@@ -1,1 +592,596 @@   */\n  private[kafka010] def batchUniqueGroupId(): String = {\n    s\"spark-kafka-relation-${UUID.randomUUID}\"\n  }\n"
  },
  {
    "id" : "05a4ed7a-a40a-4268-a047-8099a7657c5a",
    "prId" : 24738,
    "prUrl" : "https://github.com/apache/spark/pull/24738#pullrequestreview-255646887",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fc181c8b-3991-4c15-b970-0d191981229d",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "should we at least put topic name in the kafka table name?",
        "createdAt" : "2019-06-28T06:32:45Z",
        "updatedAt" : "2019-07-01T12:57:50Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "97f8b6ee-2019-4cf2-becb-eff57322e0c9",
        "parentId" : "fc181c8b-3991-4c15-b970-0d191981229d",
        "authorId" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "body" : "Strategy is not always available and this is the case with topic as well.\r\nThere is a possibility to provide topic as column (in case of write). Such case the table has multiple topics and only available while rows processed.\r\n\r\nStrategy + topic can be added conditionally which most of the time represents the situation.\r\nOn the other hand I don't think it worth to parse the rows and update `KafkaTable` name accordingly. Since this provides partial information and the implementation was quite complex compared to the value not sure it has the be added (and that's the reason why not added).\r\n\r\nWDYT, should this be added?\r\n",
        "createdAt" : "2019-06-28T08:33:40Z",
        "updatedAt" : "2019-07-01T12:57:50Z",
        "lastEditedBy" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "tags" : [
        ]
      }
    ],
    "commit" : "e8f9774522e738a39d44d750017eb7d5296dbdd1",
    "line" : 44,
    "diffHunk" : "@@ -1,1 +357,361 @@  class KafkaTable extends Table with SupportsRead with SupportsWrite {\n\n    override def name(): String = \"KafkaTable\"\n\n    override def schema(): StructType = KafkaOffsetReader.kafkaSchema"
  }
]