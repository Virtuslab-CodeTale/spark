[
  {
    "id" : "288f492d-d409-4cc1-9ab8-28ae2031746b",
    "prId" : 31490,
    "prUrl" : "https://github.com/apache/spark/pull/31490#pullrequestreview-689713808",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cc340011-7a05-4012-9b6d-e5449106e3a4",
        "parentId" : null,
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "super nit: `Iff` -> `If`",
        "createdAt" : "2021-06-21T22:51:34Z",
        "updatedAt" : "2021-06-21T23:33:43Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      },
      {
        "id" : "af751ccb-aba5-4d04-a27d-f4d4b737c25c",
        "parentId" : "cc340011-7a05-4012-9b6d-e5449106e3a4",
        "authorId" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "body" : "Iff is intentional here. [It means \"if and only if\"](https://en.wikipedia.org/wiki/If_and_only_if) and is [pretty widely used in the Spark codebase](https://github.com/apache/spark/search?q=repo%3Aapache%2Fspark+iff).",
        "createdAt" : "2021-06-22T16:07:18Z",
        "updatedAt" : "2021-06-22T16:07:18Z",
        "lastEditedBy" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "tags" : [
        ]
      }
    ],
    "commit" : "c7eea8a3eb7495f1908c0b851981b22bc5e024c2",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +69,73 @@\n  /**\n   * Iff true, perform Catalyst-to-Avro schema matching based on field position instead of field\n   * name. This allows for a structurally equivalent Catalyst schema to be used with an Avro schema\n   * whose field names do not match. Defaults to false."
  },
  {
    "id" : "f94b5ce2-76a8-4711-9039-4c92eb4e874b",
    "prId" : 27174,
    "prUrl" : "https://github.com/apache/spark/pull/27174#pullrequestreview-341565885",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3125e074-2a7e-4cf3-bbe1-20d4e2989a03",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Why do we define a separate method?",
        "createdAt" : "2020-01-12T10:13:36Z",
        "updatedAt" : "2020-01-12T10:13:36Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "7fdf386d-8d16-4f46-b203-9249e0f43173",
        "parentId" : "3125e074-2a7e-4cf3-bbe1-20d4e2989a03",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "hmm, to reuse the same code in 2 places.",
        "createdAt" : "2020-01-12T10:17:36Z",
        "updatedAt" : "2020-01-12T10:17:36Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "639c85b5-f4a5-4eda-9565-2354b1ea08cb",
        "parentId" : "3125e074-2a7e-4cf3-bbe1-20d4e2989a03",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "I don't feel strongly but I think it's fine to don't do it ...",
        "createdAt" : "2020-01-12T10:19:28Z",
        "updatedAt" : "2020-01-12T10:19:28Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "e25f1954d62972476e3bb4bdb58fa6fd8921d51c",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +70,74 @@   */\n  val ignoreExtension: Boolean = {\n    def warn(s: String): Unit = logWarning(\n      s\"$s is deprecated, and it will be not use by Avro datasource in the future releases. \" +\n      \"Use the general data source option pathGlobFilter for filtering file names.\")"
  },
  {
    "id" : "19b74c8d-1c76-4e49-a8ce-1d8a4321e872",
    "prId" : 27174,
    "prUrl" : "https://github.com/apache/spark/pull/27174#pullrequestreview-341810197",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a353e6d0-d477-40d9-ad08-b2ed0c9e5bff",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "@MaxGekk, from a cursory look, this warning can be shown for every file which I think is noisy:\r\n\r\nhttps://github.com/apache/spark/blob/053dd858d38e6107bc71e0aa3a4954291b74f8c8/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/v2/FilePartitionReaderFactory.scala#L24-L30\r\n\r\nhttps://github.com/apache/spark/blob/053dd858d38e6107bc71e0aa3a4954291b74f8c8/external/avro/src/main/scala/org/apache/spark/sql/v2/avro/AvroPartitionReaderFactory.scala#L61\r\n\r\nDo you mind if I ask double check this?",
        "createdAt" : "2020-01-12T10:17:01Z",
        "updatedAt" : "2020-01-12T10:17:16Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "fc248047-8e2a-4b05-8bb5-75acc2df4509",
        "parentId" : "a353e6d0-d477-40d9-ad08-b2ed0c9e5bff",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "@HyukjinKwon I will check that but general thoughts are:\r\n1. The log warning is printed only if an user sets non-default config values\r\n2. I don't think `AvroOptions` should be created (initialized from scratch) per-each file if it is created in current implementation. I would say it is not necessary to initialize AvroOptions again and again. After all, AvroOptions should be the same for all files/partitions.\r\n3. And the noise in logs will force people to avoid using of the deprecated options ;-)",
        "createdAt" : "2020-01-12T10:29:23Z",
        "updatedAt" : "2020-01-12T10:50:28Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "2ff80388-4a3a-4883-9ab7-564787124742",
        "parentId" : "a353e6d0-d477-40d9-ad08-b2ed0c9e5bff",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "@HyukjinKwon you are right, it prints warnings per each partition. I have confirmed that by the test:\r\n```scala\r\n  test(\"count deprecation log events\") {\r\n    val partitionNum = 3\r\n    val logAppender = new AppenderSkeleton {\r\n      val loggingEvents = new ArrayBuffer[LoggingEvent]()\r\n\r\n      override def append(loggingEvent: LoggingEvent): Unit = loggingEvents.append(loggingEvent)\r\n      override def close(): Unit = {}\r\n      override def requiresLayout(): Boolean = false\r\n    }\r\n    withTempPath { dir =>\r\n      Seq((\"a\", 1, 2), (\"b\", 1, 2), (\"c\", 2, 1), (\"d\", 2, 1))\r\n        .toDF(\"value\", \"p1\", \"p2\")\r\n        .repartition(partitionNum)\r\n        .write\r\n        .format(\"avro\")\r\n        .option(\"header\", true)\r\n        .save(dir.getCanonicalPath)\r\n      withLogAppender(logAppender) {\r\n        val df = spark\r\n          .read\r\n          .format(\"avro\")\r\n          .schema(\"value STRING, p1 INTEGER, p2 INTEGER\")\r\n          .option(AvroOptions.ignoreExtensionKey, false)\r\n          .option(\"header\", true)\r\n          .load(dir.getCanonicalPath)\r\n        df.count()\r\n      }\r\n      val deprecatedEvents = logAppender.loggingEvents\r\n        .map(_.getRenderedMessage)\r\n        .filter(_.contains(AvroOptions.ignoreExtensionKey))\r\n      assert(deprecatedEvents.size === partitionNum)\r\n    }\r\n  }\r\n```",
        "createdAt" : "2020-01-12T16:55:31Z",
        "updatedAt" : "2020-01-12T16:55:32Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "697b6c2d-5279-449b-8f45-20a0565b98f7",
        "parentId" : "a353e6d0-d477-40d9-ad08-b2ed0c9e5bff",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "When I moved instantiation of AvroOptions out of buildReader():\r\n<img width=\"857\" alt=\"Screen Shot 2020-01-12 at 20 14 06\" src=\"https://user-images.githubusercontent.com/1580697/72222647-359c3a00-3578-11ea-92d3-0802dbb21b3c.png\">\r\nThe warning is printed always 2 times. It means `AvroPartitionReaderFactory` is constructed twice.\r\nAnd both times from https://github.com/apache/spark/blob/053dd858d38e6107bc71e0aa3a4954291b74f8c8/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/v2/DataSourceV2ScanExecBase.scala#L60-L66 which is called:\r\nFirst time from\r\n<img width=\"860\" alt=\"Screen Shot 2020-01-12 at 20 32 02\" src=\"https://user-images.githubusercontent.com/1580697/72222900-a8a6b000-357a-11ea-8792-2e94532199f0.png\">\r\nThe second time from:\r\n<img width=\"656\" alt=\"Screen Shot 2020-01-12 at 20 33 36\" src=\"https://user-images.githubusercontent.com/1580697/72222915-d5f35e00-357a-11ea-9f91-da36c59d62ff.png\">\r\n",
        "createdAt" : "2020-01-12T17:34:24Z",
        "updatedAt" : "2020-01-12T17:34:24Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "c8ae5709-6df3-4e82-b2a6-6f784f30a6b7",
        "parentId" : "a353e6d0-d477-40d9-ad08-b2ed0c9e5bff",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "It is interesting that rewriting `supportsColumnar` as:\r\n```scala\r\n  override val supportsColumnar: Boolean = {\r\n    val factory = readerFactory\r\n    require(partitions.forall(factory.supportColumnarReads) ||\r\n      !partitions.exists(factory.supportColumnarReads),\r\n      \"Cannot mix row-based and columnar input partitions.\")\r\n\r\n    partitions.exists(factory.supportColumnarReads)\r\n  }\r\n```\r\ndoes not help too because `DataSourceV2ScanExecBase` is initialized twice from:\r\nFirst time:\r\n<img width=\"851\" alt=\"Screen Shot 2020-01-12 at 20 52 49\" src=\"https://user-images.githubusercontent.com/1580697/72223223-84000780-357d-11ea-829e-768d37d3fd1f.png\">\r\nSecond time in `TreeNode.makeCopy`:\r\n<img width=\"797\" alt=\"Screen Shot 2020-01-12 at 21 06 40\" src=\"https://user-images.githubusercontent.com/1580697/72223406-73e92780-357f-11ea-9c18-86ec0c84ae2c.png\">\r\nMaking `supportsColumnar` as `lazy val` doesn't help as well because `supportsColumnar` is invoked twice for different objects.\r\n",
        "createdAt" : "2020-01-12T18:08:00Z",
        "updatedAt" : "2020-01-12T18:08:01Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "fd6a1cfe-496a-4631-8f37-c2c7f2d166d9",
        "parentId" : "a353e6d0-d477-40d9-ad08-b2ed0c9e5bff",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "I think it is not nice that we construct some classes twice when it is not necessary. WDYT? /cc @cloud-fan @dongjoon-hyun ",
        "createdAt" : "2020-01-13T11:12:27Z",
        "updatedAt" : "2020-01-13T11:12:27Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "207e0f77-f2f7-4fb7-bb56-3b5f5c34036f",
        "parentId" : "a353e6d0-d477-40d9-ad08-b2ed0c9e5bff",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Yea we shouldn't instantiate twice, but not a big problem. I'm more worried about we instantiate it for every partition.",
        "createdAt" : "2020-01-13T12:11:38Z",
        "updatedAt" : "2020-01-13T12:11:38Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "5b7be05b-45cb-44bb-aaa0-fa767072053f",
        "parentId" : "a353e6d0-d477-40d9-ad08-b2ed0c9e5bff",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "@MaxGekk, even if we fix this, it will still show the warning twice for schema inference and reading path at the very least. It's okay as long as we show the warning and document. Let's just go simple in this PR. This warning will be removed very soon, too.",
        "createdAt" : "2020-01-13T12:29:21Z",
        "updatedAt" : "2020-01-13T12:29:21Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "e25f1954d62972476e3bb4bdb58fa6fd8921d51c",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +83,87 @@      .map { ignoreExtensionOption =>\n        if (ignoreExtensionOption != !ignoreFilesWithoutExtensionByDefault) {\n          warn(s\"The Avro option '${AvroOptions.ignoreExtensionKey}'\")\n        }\n        ignoreExtensionOption"
  },
  {
    "id" : "9266a217-2bc5-4522-bc3b-5b64aed852ce",
    "prId" : 24518,
    "prUrl" : "https://github.com/apache/spark/pull/24518#pullrequestreview-339682535",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "49c9f6c1-6c67-438e-8fe5-76af4dd4204c",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "I am wondering whom is this deprecation warning to? Spark users don't use `ignoreExtension` directly. I do think we should print a warning when we read & detect that `AvroFileFormat.IgnoreFilesWithoutExtensionProperty` and/or `AvroOptions.ignoreExtensionKey` are set otherwise users will never see the deprecation.",
        "createdAt" : "2020-01-07T19:18:26Z",
        "updatedAt" : "2020-01-07T19:18:37Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "25e5020d-f251-4d9e-8d18-1ebdce3c41c9",
        "parentId" : "49c9f6c1-6c67-438e-8fe5-76af4dd4204c",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "I think it already shows an warning at https://github.com/apache/spark/pull/24518/files/d8f8420d9d3c97f96c1e09855e008ece3f275ad3#diff-8b28467c7f7a28d7fcf208a613a373c8R61",
        "createdAt" : "2020-01-08T00:23:45Z",
        "updatedAt" : "2020-01-08T00:23:46Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "bb47cc17-7d97-4473-bdb3-6c9179e49642",
        "parentId" : "49c9f6c1-6c67-438e-8fe5-76af4dd4204c",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "only in one case at schema inferring. I would remove this annotation and print warning in initialization of `AvroOptions`. The deprecation warning is printed only while Spark compilation which is useless for users. ",
        "createdAt" : "2020-01-08T07:02:44Z",
        "updatedAt" : "2020-01-08T07:02:44Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "012bf209-25cb-46a3-b74d-870c4804f499",
        "parentId" : "49c9f6c1-6c67-438e-8fe5-76af4dd4204c",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "I think we should remove `deprecated`. \r\n\r\nIt would be great if we can put that logic into `AvroOptions` e.g.:\r\n\r\n```scala\r\n    parameters\r\n      .get(AvroOptions.ignoreExtensionKey)\r\n      .map { v =>\r\n        logWarning(...)\r\n        v.toBoolean\r\n      }.getOrElse(!ignoreFilesWithoutExtension)\r\n```\r\n\r\nHowever, can you make it doesn't show the logs too many times? If we put there, seems like it will show the same logs multiple times.",
        "createdAt" : "2020-01-08T07:22:45Z",
        "updatedAt" : "2020-01-08T07:22:45Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "4e053bef-0465-454e-bbc0-7a8a6f9a2b40",
        "parentId" : "49c9f6c1-6c67-438e-8fe5-76af4dd4204c",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "If you can find a better way, please go and open a PR (and some nits I picked below)",
        "createdAt" : "2020-01-08T07:24:47Z",
        "updatedAt" : "2020-01-08T07:24:47Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "d8f8420d9d3c97f96c1e09855e008ece3f275ad3",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +60,64 @@   * is taken into account. If the former one is not set too, file extensions are ignored.\n   */\n  @deprecated(\"Use the general data source option pathGlobFilter for filtering file names\", \"3.0\")\n  val ignoreExtension: Boolean = {\n    val ignoreFilesWithoutExtensionByDefault = false"
  },
  {
    "id" : "f2473236-a93e-4d24-8d32-d8a23d0d86bb",
    "prId" : 24518,
    "prUrl" : "https://github.com/apache/spark/pull/24518#pullrequestreview-339682181",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d32f0d56-39d6-44f9-a249-63fdcac684e6",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "`ignoreExtensionKey` -> `IGNORE_EXTENTION_KEY` to be consistent with other `XXXOptions`",
        "createdAt" : "2020-01-08T07:23:38Z",
        "updatedAt" : "2020-01-08T07:23:39Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "d8f8420d9d3c97f96c1e09855e008ece3f275ad3",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +68,72 @@\n    parameters\n      .get(AvroOptions.ignoreExtensionKey)\n      .map(_.toBoolean)\n      .getOrElse(!ignoreFilesWithoutExtension)"
  }
]