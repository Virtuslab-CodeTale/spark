[
  {
    "id" : "bf5b2bba-70b2-4105-bf07-31314170da2b",
    "prId" : 32969,
    "prUrl" : "https://github.com/apache/spark/pull/32969#pullrequestreview-689730874",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "08e769c3-994a-40c5-b8f7-3f672fd2dd6e",
        "parentId" : null,
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "shall we update the benchmark result?",
        "createdAt" : "2021-06-22T16:18:49Z",
        "updatedAt" : "2021-06-22T16:18:49Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "d9e40d747ffc26c16c7e40044388476db7767a7a",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +51,55 @@          .persist(StorageLevel.DISK_ONLY)\n        // cache the data to ensure we are not benchmarking range or repartition\n        df.noop()\n        df.createOrReplaceTempView(\"t1\")\n        val benchmark = new Benchmark(s\"Write wide rows into $files files\", values, output = output)"
  },
  {
    "id" : "d880b13b-2a02-43f7-adf0-80b5241b0171",
    "prId" : 29354,
    "prUrl" : "https://github.com/apache/spark/pull/29354#pullrequestreview-462838630",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a8e0197c-c1f3-4ca3-a924-6c82ece4e09d",
        "parentId" : null,
        "authorId" : "6e35521d-0def-4310-bc41-de4685fba931",
        "body" : "This is accidental.",
        "createdAt" : "2020-08-06T20:06:10Z",
        "updatedAt" : "2020-08-06T20:06:10Z",
        "lastEditedBy" : "6e35521d-0def-4310-bc41-de4685fba931",
        "tags" : [
        ]
      }
    ],
    "commit" : "054d60229e7a6eb31da1be3f23ac1f2b59a95261",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +22,26 @@ * {{{\n *   1. without sbt: bin/spark-submit --class <this class>\n *        --jars <spark core test jar>,<spark catalyst test jar>,\n  *              <spark sql test jar>,<spark avro jar>\n *        <spark avro test jar>"
  }
]