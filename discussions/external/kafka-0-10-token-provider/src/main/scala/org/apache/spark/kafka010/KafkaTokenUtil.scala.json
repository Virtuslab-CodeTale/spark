[
  {
    "id" : "7566f207-1983-44f4-8740-af278fbb08fe",
    "prId" : 24627,
    "prUrl" : "https://github.com/apache/spark/pull/24627#pullrequestreview-238454676",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "22389a05-cadc-4046-90e4-4d5a9c4ab595",
        "parentId" : null,
        "authorId" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "body" : "This is unrelated fix. There were additional spaces at the end of the generated string. This change removes it. Worth to mention the code works both way but thought it's just ugly.",
        "createdAt" : "2019-05-16T15:03:36Z",
        "updatedAt" : "2019-06-03T08:23:28Z",
        "lastEditedBy" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "tags" : [
        ]
      }
    ],
    "commit" : "67aa337ad48e393a2e19f60fc29bca559dd2380f",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +195,199 @@      | useTicketCache=true\n      | serviceName=\"${clusterConf.kerberosServiceName}\";\n      \"\"\".stripMargin.replace(\"\\n\", \"\").trim\n    logDebug(s\"Krb ticket cache JAAS params: $params\")\n    params"
  },
  {
    "id" : "7157af02-0eb9-4889-80d1-d36f86ed2321",
    "prId" : 24627,
    "prUrl" : "https://github.com/apache/spark/pull/24627#pullrequestreview-238455313",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "92a7d456-b62a-4abf-8834-900961048b79",
        "parentId" : null,
        "authorId" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "body" : "This is unrelated fix. There were additional spaces at the end of the generated string. This change removes it. Worth to mention the code works both way but thought it's just ugly.",
        "createdAt" : "2019-05-16T15:04:28Z",
        "updatedAt" : "2019-06-03T08:23:28Z",
        "lastEditedBy" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "tags" : [
        ]
      }
    ],
    "commit" : "67aa337ad48e393a2e19f60fc29bca559dd2380f",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +271,275 @@      | username=\"$username\"\n      | password=\"$password\";\n      \"\"\".stripMargin.replace(\"\\n\", \"\").trim\n    logDebug(s\"Scram JAAS params: ${KafkaRedactionUtil.redactJaasParam(params)}\")\n"
  },
  {
    "id" : "fcec09bf-4ba4-469b-960a-79e07885a868",
    "prId" : 24305,
    "prUrl" : "https://github.com/apache/spark/pull/24305#pullrequestreview-233144796",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5a1de448-1ce5-406a-81e1-155e379afb91",
        "parentId" : null,
        "authorId" : "0b3111e2-9584-4813-8cb5-8f40e119f71c",
        "body" : "empty line between methods",
        "createdAt" : "2019-04-30T17:26:11Z",
        "updatedAt" : "2019-05-06T10:37:16Z",
        "lastEditedBy" : "0b3111e2-9584-4813-8cb5-8f40e119f71c",
        "tags" : [
        ]
      },
      {
        "id" : "5db1df86-a698-4228-8e90-014696740720",
        "parentId" : "5a1de448-1ce5-406a-81e1-155e379afb91",
        "authorId" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "body" : "Fixed.",
        "createdAt" : "2019-05-02T17:40:34Z",
        "updatedAt" : "2019-05-06T10:37:16Z",
        "lastEditedBy" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "tags" : [
        ]
      }
    ],
    "commit" : "e5bcc181d5b748490efdbf83625a47fb36892b82",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +50,54 @@    new Text(s\"$TOKEN_SERVICE_PREFIX.$identifier\")\n\n  private def getClusterIdentifier(service: Text): String =\n    service.toString().replace(s\"$TOKEN_SERVICE_PREFIX.\", \"\")\n"
  },
  {
    "id" : "fcbd80dd-f5c9-4de3-a417-4e85abb2ba02",
    "prId" : 24305,
    "prUrl" : "https://github.com/apache/spark/pull/24305#pullrequestreview-234693315",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "512ff422-6310-4860-b7f5-f3a0fd9e7ffa",
        "parentId" : null,
        "authorId" : "0b3111e2-9584-4813-8cb5-8f40e119f71c",
        "body" : "Also, an idea: wouldn't it be good to match the servers against the \"auth\" list too? That way the regex doesn't need to match the servers listed in the \"auth\" config, and in fact can be optional in case the \"auth\" list has all the servers you want.",
        "createdAt" : "2019-05-03T21:38:49Z",
        "updatedAt" : "2019-05-06T10:37:16Z",
        "lastEditedBy" : "0b3111e2-9584-4813-8cb5-8f40e119f71c",
        "tags" : [
        ]
      },
      {
        "id" : "1c2b0426-47fa-401e-afaf-d22440e34cfe",
        "parentId" : "512ff422-6310-4860-b7f5-f3a0fd9e7ffa",
        "authorId" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "body" : "> That way the regex doesn't need to match the servers listed in the \"auth\" config\r\n\r\nNot sure if I understand what you mean. `findMatchingToken` does the following:\r\n* Get all available tokens\r\n* Drops all non-Kafka tokens\r\n* Gets a valid Kafka cluster config for each token (tokens are obtained based on this config)\r\n* Does pattern matching agains the source/sink `bootstrap.servers`\r\n\r\nThis code part is independent from \"auth\" list.\r\n\r\nYou mean 2 step matching? Like first try to match against \"auth\" list and if not found try to match with regex?\r\n",
        "createdAt" : "2019-05-06T14:54:19Z",
        "updatedAt" : "2019-05-06T14:54:19Z",
        "lastEditedBy" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "tags" : [
        ]
      },
      {
        "id" : "ec0001d4-3d0b-402f-bfc0-f7eabdccc287",
        "parentId" : "512ff422-6310-4860-b7f5-f3a0fd9e7ffa",
        "authorId" : "0b3111e2-9584-4813-8cb5-8f40e119f71c",
        "body" : "> Like first try to match against \"auth\" list and if not found try to match with regex?\r\n\r\nYes. That way for simple / small clusters you don't even need to define the regex, if all the servers are listed in the auth list.",
        "createdAt" : "2019-05-06T16:16:31Z",
        "updatedAt" : "2019-05-06T16:16:31Z",
        "lastEditedBy" : "0b3111e2-9584-4813-8cb5-8f40e119f71c",
        "tags" : [
        ]
      },
      {
        "id" : "620501de-4eff-4040-a61d-e287243fc687",
        "parentId" : "512ff422-6310-4860-b7f5-f3a0fd9e7ffa",
        "authorId" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "body" : "The most simple single cluster scenario works without any regex config by the user.\r\n\r\nIn the multi-cluster case even if providing a proper regex is an extra step I would keep the implementation as it is. As a user I would personally burn more time on understanding such fallback scenarios than writing a regex. If hostname pattern changes somehow then it has to be re-understand again (in general not big fan of fallbacks until it's absolutely not required).\r\n\r\nIf you think we can adapt the code because both solutions are good.\r\n",
        "createdAt" : "2019-05-07T08:18:34Z",
        "updatedAt" : "2019-05-07T08:18:35Z",
        "lastEditedBy" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "tags" : [
        ]
      },
      {
        "id" : "f0bd01a8-f5a9-41a1-9428-e584c75c080a",
        "parentId" : "512ff422-6310-4860-b7f5-f3a0fd9e7ffa",
        "authorId" : "0b3111e2-9584-4813-8cb5-8f40e119f71c",
        "body" : "Sounded like a pretty easy thing to implement, but anyway, not worth spending too much time on.",
        "createdAt" : "2019-05-07T18:39:35Z",
        "updatedAt" : "2019-05-07T18:39:35Z",
        "lastEditedBy" : "0b3111e2-9584-4813-8cb5-8f40e119f71c",
        "tags" : [
        ]
      }
    ],
    "commit" : "e5bcc181d5b748490efdbf83625a47fb36892b82",
    "line" : 188,
    "diffHunk" : "@@ -1,1 +248,252 @@      .filter { clusterConfig =>\n        val pattern = Pattern.compile(clusterConfig.targetServersRegex)\n        Utils.stringToSeq(bootStrapServers).exists(pattern.matcher(_).matches())\n      }\n    require(clusterConfigs.size <= 1, \"More than one delegation token matches the following \" +"
  }
]