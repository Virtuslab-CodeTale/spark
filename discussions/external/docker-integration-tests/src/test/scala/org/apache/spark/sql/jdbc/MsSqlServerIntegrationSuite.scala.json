[
  {
    "id" : "a0f89875-3258-4c1b-b7db-36eaa844156d",
    "prId" : 29932,
    "prUrl" : "https://github.com/apache/spark/pull/29932#pullrequestreview-500898725",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8a7d85c9-6fdc-4e43-afec-f0194f873fbb",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "This is not changed.",
        "createdAt" : "2020-10-02T07:02:48Z",
        "updatedAt" : "2020-10-02T11:33:49Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "0ef813b4171b9942e341ec788ddb41151bdb3110",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +36,40 @@  override val db = new DatabaseOnDocker {\n    override val imageName = sys.env.getOrElse(\"MSSQLSERVER_DOCKER_IMAGE_NAME\",\n      \"mcr.microsoft.com/mssql/server:2019-GA-ubuntu-16.04\")\n    override val env = Map(\n      \"SA_PASSWORD\" -> \"Sapass123\","
  },
  {
    "id" : "741afe1f-3ce1-4f76-a319-a312bbf8796e",
    "prId" : 28635,
    "prUrl" : "https://github.com/apache/spark/pull/28635#pullrequestreview-417648132",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "75123264-122b-4a5d-abbb-58deb32d4394",
        "parentId" : null,
        "authorId" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "body" : "This is not absolutely necessary, if we think we can extract it into a new PR. Thought it would be overkill.",
        "createdAt" : "2020-05-25T11:30:28Z",
        "updatedAt" : "2020-06-04T11:03:51Z",
        "lastEditedBy" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "tags" : [
        ]
      }
    ],
    "commit" : "0a718490ac5e8394674a5b8f64d9f8be382805fe",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +28,32 @@class MsSqlServerIntegrationSuite extends DockerJDBCIntegrationSuite {\n  override val db = new DatabaseOnDocker {\n    override val imageName = \"mcr.microsoft.com/mssql/server:2019-GA-ubuntu-16.04\"\n    override val env = Map(\n      \"SA_PASSWORD\" -> \"Sapass123\","
  },
  {
    "id" : "fd7bb9c1-79a3-482c-ab81-fd3e23bd0f6b",
    "prId" : 26549,
    "prUrl" : "https://github.com/apache/spark/pull/26549#pullrequestreview-318749084",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6b40638a-e942-4fdf-9368-d8ec3c1c0e3f",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Wait, how was this possible before? Do we cover unsigned cases too?",
        "createdAt" : "2019-11-18T05:02:55Z",
        "updatedAt" : "2019-11-18T05:02:55Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "c175fe5a-fa41-4fb4-8968-5fd1a1c9e253",
        "parentId" : "6b40638a-e942-4fdf-9368-d8ec3c1c0e3f",
        "authorId" : "af133a35-c4d5-4a44-81d2-5683a0e3bb07",
        "body" : "Yes, all test cases including signed and unsigned are covered now for ByteType and ShortType. Refer to test(\"SPARK-29644: Write tables with ShortType\") and  test(\"SPARK-29644: Write tables with ByteType\") in JDBCWriteSuite.scala and MsSQLServerIntegrationSuite.scala.\r\n\r\nEarlier it all worked as everything was treated as an integer. Every test cases treated ByteType and ShortType as integers. These test are corrected now.",
        "createdAt" : "2019-11-18T05:50:21Z",
        "updatedAt" : "2019-11-18T05:50:22Z",
        "lastEditedBy" : "af133a35-c4d5-4a44-81d2-5683a0e3bb07",
        "tags" : [
        ]
      },
      {
        "id" : "a2305ef4-95b6-4be4-8a80-a20f7c3ac446",
        "parentId" : "6b40638a-e942-4fdf-9368-d8ec3c1c0e3f",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "I meant \r\n\r\n1. This TINYINT seems able to contain unsigned values (https://dev.mysql.com/doc/refman/8.0/en/integer-types.html) up to 255. How do we handle?\r\n2. Previously the value given here was `255` for `TINYINT` which is performed via MySQL if I am not mistaken. How was this possible without UNSIGNED keyword?",
        "createdAt" : "2019-11-18T06:14:00Z",
        "updatedAt" : "2019-11-18T06:14:01Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "42819a95-fde0-4d95-b687-e336b8ec79e5",
        "parentId" : "6b40638a-e942-4fdf-9368-d8ec3c1c0e3f",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "@HyukjinKwon .\r\nIt seems that we need to revert https://github.com/apache/spark/pull/23400 with the same reason. How do you think about that?",
        "createdAt" : "2019-11-19T02:20:50Z",
        "updatedAt" : "2019-11-19T02:20:51Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "feca67a0922d97749380d5ef8944cefe55aa6c2b",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +60,64 @@        |INSERT INTO numbers VALUES (\n        |0,\n        |127, 32767, 2147483647, 9223372036854775807,\n        |123456789012345.123456789012345, 123456789012345.123456789012345,\n        |123456789012345.123456789012345,"
  },
  {
    "id" : "4ab01ae8-7914-4a46-86ac-50318267ea89",
    "prId" : 26301,
    "prUrl" : "https://github.com/apache/spark/pull/26301#pullrequestreview-309585870",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "22f14184-8687-4ea8-9169-fd5ace399492",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Can you write tests in `JDBCWriteSuite`?",
        "createdAt" : "2019-10-30T04:51:28Z",
        "updatedAt" : "2019-11-13T22:08:53Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "66046aba-4dd2-4272-b9f0-b6113e2fb5df",
        "parentId" : "22f14184-8687-4ea8-9169-fd5ace399492",
        "authorId" : "af133a35-c4d5-4a44-81d2-5683a0e3bb07",
        "body" : "I have not written unit test cases in JDBCWriteSuite before, but will try as i get time. \r\nTo do a generic ix this would require changes to mapping in SMALLINT mapping in getCatalystType which is currently set to INTEGER.\r\n\r\nprivate def getCatalystType(\r\n      sqlType: Int,\r\n      precision: Int,\r\n      scale: Int,\r\n      signed: Boolean): DataType = {\r\n    val answer = sqlType match {\r\n\r\n   **case java.sql.Types.SMALLINT      => ShortType**\r\n}\r\n\r\nand test cases modified accordingly. \r\n\r\nDo you think we should do the generic fix? \r\n",
        "createdAt" : "2019-10-30T23:52:21Z",
        "updatedAt" : "2019-11-13T22:08:53Z",
        "lastEditedBy" : "af133a35-c4d5-4a44-81d2-5683a0e3bb07",
        "tags" : [
        ]
      }
    ],
    "commit" : "06008946964cc7acb8df3ff781513e4577dd2116",
    "line" : 51,
    "diffHunk" : "@@ -1,1 +223,227 @@    val colType = rows(0).toSeq.map(x => x.getClass.toString)\n    assert(colType(0) == \"class java.lang.Short\")\n  }\n\n  test(\"SPARK-29644: Write tables with ByteType\") {"
  },
  {
    "id" : "701a2e59-d712-4dcf-9b73-f533d19d87ae",
    "prId" : 26301,
    "prUrl" : "https://github.com/apache/spark/pull/26301#pullrequestreview-315959318",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ec63ff97-df16-4f06-915d-e09cbaef6fba",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Have you checked if this integration test passed in your local env?",
        "createdAt" : "2019-11-12T23:25:54Z",
        "updatedAt" : "2019-11-13T22:08:53Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "5a351f44-82f0-4464-b135-06f09c1b5474",
        "parentId" : "ec63ff97-df16-4f06-915d-e09cbaef6fba",
        "authorId" : "af133a35-c4d5-4a44-81d2-5683a0e3bb07",
        "body" : "Yes, i have tested in my local and all integration test passed.",
        "createdAt" : "2019-11-13T01:51:17Z",
        "updatedAt" : "2019-11-13T22:08:53Z",
        "lastEditedBy" : "af133a35-c4d5-4a44-81d2-5683a0e3bb07",
        "tags" : [
        ]
      },
      {
        "id" : "2f4209fb-429f-4871-8370-3cb33e1a64b9",
        "parentId" : "ec63ff97-df16-4f06-915d-e09cbaef6fba",
        "authorId" : "af133a35-c4d5-4a44-81d2-5683a0e3bb07",
        "body" : "and tested for all type of DBs which were impacted. PostGres, MsSQLServer, MySQL",
        "createdAt" : "2019-11-13T01:57:40Z",
        "updatedAt" : "2019-11-13T22:08:53Z",
        "lastEditedBy" : "af133a35-c4d5-4a44-81d2-5683a0e3bb07",
        "tags" : [
        ]
      }
    ],
    "commit" : "06008946964cc7acb8df3ff781513e4577dd2116",
    "line" : 72,
    "diffHunk" : "@@ -1,1 +244,248 @@    val colType = rows(0).toSeq.map(x => x.getClass.toString)\n    assert(colType(0) == \"class java.lang.Byte\")\n  }\n}"
  },
  {
    "id" : "2f0a6800-a070-4fca-a0fc-ef8a93ffd35e",
    "prId" : 26301,
    "prUrl" : "https://github.com/apache/spark/pull/26301#pullrequestreview-316626595",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "323a7ea9-805e-46de-955e-9e1a93b4f3d6",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "I think its ok for `JDBCWriteSuite` to only have the two write tests below for byte and short. So, can you remove the write tests from the integration tests?",
        "createdAt" : "2019-11-12T23:34:07Z",
        "updatedAt" : "2019-11-13T22:08:53Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "60892846-7cea-48b4-9be0-c3c26ad2d449",
        "parentId" : "323a7ea9-805e-46de-955e-9e1a93b4f3d6",
        "authorId" : "af133a35-c4d5-4a44-81d2-5683a0e3bb07",
        "body" : "I think both test have their important purpose. JDBCWriteSuite unit test will catch any spark regression in CI/CD and integration test are great to ensure that functionality works end to end. Consider that ByteType should translate to TINYINT in SQLServer, but in PostGres  both ByteType maps to SMALLINT. This real distinction is factually verified in Integration test. So i think having integration test is very important and thus we should not remove these.\r\n",
        "createdAt" : "2019-11-13T01:56:57Z",
        "updatedAt" : "2019-11-13T22:08:53Z",
        "lastEditedBy" : "af133a35-c4d5-4a44-81d2-5683a0e3bb07",
        "tags" : [
        ]
      },
      {
        "id" : "11916f72-8a1f-4b42-96df-e6d2cf51d5bd",
        "parentId" : "323a7ea9-805e-46de-955e-9e1a93b4f3d6",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "But, very verbose. So, can we share this test by making a base abstract test class?",
        "createdAt" : "2019-11-13T03:15:15Z",
        "updatedAt" : "2019-11-13T22:08:53Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "f535ba54-9f8a-45b8-b3b6-bd3ab04007fb",
        "parentId" : "323a7ea9-805e-46de-955e-9e1a93b4f3d6",
        "authorId" : "af133a35-c4d5-4a44-81d2-5683a0e3bb07",
        "body" : "Agree. Will take a shot at it today,  else will remove these test cases and attempt add these cleanly with fix later.",
        "createdAt" : "2019-11-13T19:57:42Z",
        "updatedAt" : "2019-11-13T22:08:53Z",
        "lastEditedBy" : "af133a35-c4d5-4a44-81d2-5683a0e3bb07",
        "tags" : [
        ]
      },
      {
        "id" : "30cefede-ef2c-4600-8651-1b94acfb0e5b",
        "parentId" : "323a7ea9-805e-46de-955e-9e1a93b4f3d6",
        "authorId" : "af133a35-c4d5-4a44-81d2-5683a0e3bb07",
        "body" : "Several test cases in the integration suite are quite similar, the framework does not have a notion of a common base class for same test case. This fix will require some refactoring of the framework. Something i can attempt later, not in scope of this PR. \r\n\r\nI would remove the repeated test in all DB types and retain it for SQL server only.",
        "createdAt" : "2019-11-13T21:11:12Z",
        "updatedAt" : "2019-11-13T22:08:53Z",
        "lastEditedBy" : "af133a35-c4d5-4a44-81d2-5683a0e3bb07",
        "tags" : [
        ]
      },
      {
        "id" : "7cf53e66-9265-46aa-b7fa-cd236bac67b3",
        "parentId" : "323a7ea9-805e-46de-955e-9e1a93b4f3d6",
        "authorId" : "af133a35-c4d5-4a44-81d2-5683a0e3bb07",
        "body" : "Fixed. These repeated test cases are removed. Only retained in MsSQLIntegrationTest. Will refactor test suite later to have common test cases in it.",
        "createdAt" : "2019-11-13T22:10:36Z",
        "updatedAt" : "2019-11-13T22:10:37Z",
        "lastEditedBy" : "af133a35-c4d5-4a44-81d2-5683a0e3bb07",
        "tags" : [
        ]
      },
      {
        "id" : "5cedc54b-39ae-44fc-888c-8415daca65bb",
        "parentId" : "323a7ea9-805e-46de-955e-9e1a93b4f3d6",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ur, sorry for my late response. Yea, that follow-up looks ok to me.",
        "createdAt" : "2019-11-13T23:25:39Z",
        "updatedAt" : "2019-11-13T23:25:39Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "06008946964cc7acb8df3ff781513e4577dd2116",
    "line" : 53,
    "diffHunk" : "@@ -1,1 +225,229 @@  }\n\n  test(\"SPARK-29644: Write tables with ByteType\") {\n    import testImplicits._\n    val df = Seq(-127.toByte, 0.toByte, 1.toByte, 38.toByte, 128.toByte).toDF(\"a\")"
  },
  {
    "id" : "2ce8d4e9-532f-459d-b92f-cad8d1744619",
    "prId" : 26301,
    "prUrl" : "https://github.com/apache/spark/pull/26301#pullrequestreview-341480194",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d85bc052-b58b-467b-bb58-3152541f665a",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Ditto - https://github.com/apache/spark/pull/26549#discussion_r347202275. Can anyone explain why it was possible, and how do we handle unsigned cases?",
        "createdAt" : "2019-11-18T05:12:03Z",
        "updatedAt" : "2019-11-18T05:12:03Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "3feeb102-876c-40a4-baa6-2ef804d83693",
        "parentId" : "d85bc052-b58b-467b-bb58-3152541f665a",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Continuing from https://github.com/apache/spark/pull/26549#discussion_r347213679 : TINYINT looks like it's a single byte alright, so using ByteType is reasonable. However it looks like it's treated as signed by some but not all DBMSes. Is it unsigned in SQL Server?\r\n\r\nJust checking: these types like TINYINT and SMALLINT are not standard types, although widely supported, right? should these types be used by default for all JDBC sources?\r\n\r\nYeah I have some more doubts now that the TINYINT issue was pointed out. @shivsood ",
        "createdAt" : "2019-11-18T15:08:55Z",
        "updatedAt" : "2019-11-18T15:08:56Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "81b36cf7-f2e7-40b8-9d6a-d631e0899627",
        "parentId" : "d85bc052-b58b-467b-bb58-3152541f665a",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Got it. @gatorsmile , @HyukjinKwon , @srowen . I overlooked that mismatch between TINYINT vs Byte in this PR.",
        "createdAt" : "2019-11-18T16:59:28Z",
        "updatedAt" : "2019-11-18T16:59:28Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "fd5ecc70-d69f-4625-9278-45b6c6717f65",
        "parentId" : "d85bc052-b58b-467b-bb58-3152541f665a",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "`SMALLINT` is widely supported because it's SQL-92. For TINYINT, I agree that we need to revert partially for that type.",
        "createdAt" : "2019-11-18T17:04:11Z",
        "updatedAt" : "2019-11-18T17:04:11Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "7e4af624-34e7-4cf5-b92d-b4fb5ee9a976",
        "parentId" : "d85bc052-b58b-467b-bb58-3152541f665a",
        "authorId" : "af133a35-c4d5-4a44-81d2-5683a0e3bb07",
        "body" : "Thanks all for pointing out these issues. I had overlooked handling of unsigned cases and the fact that each database may define on its own. I think the problem exists for both SMALLINT and TINYINT. \r\n- TINYINT is very clear that it can be range any where from -127 to +127 and unsigned as 0 to 255. Both [SQLServer](https://docs.microsoft.com/en-us/sql/t-sql/data-types/int-bigint-smallint-and-tinyint-transact-sql?view=sql-server-ver15) and [MySQL](https://dev.mysql.com/doc/refman/8.0/en/integer-types.html)\r\n- SMALLINT can take an unsigned value 0 to 65535 per [MySQL](https://dev.mysql.com/doc/refman/8.0/en/integer-types.html) \r\n\r\nMy understanding is that there are no unsigned type in Spark. c.f. https://spark.apache.org/docs/latest/sql-reference.html. Is that assertion right?\r\n\r\nDo we have a test for an integer where integer value is 4294967295? Per [MySQL](https://dev.mysql.com/doc/refman/8.0/en/integer-types.html)  documentation that's possible that an unsigned integer will have that value.",
        "createdAt" : "2019-11-19T00:02:55Z",
        "updatedAt" : "2019-11-19T00:05:19Z",
        "lastEditedBy" : "af133a35-c4d5-4a44-81d2-5683a0e3bb07",
        "tags" : [
        ]
      },
      {
        "id" : "f13ff66a-6704-4a7d-b110-02743d5f5692",
        "parentId" : "d85bc052-b58b-467b-bb58-3152541f665a",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Thanks guys for addressing my comment thoroughly and taking care of this afterwards.",
        "createdAt" : "2019-11-19T00:07:25Z",
        "updatedAt" : "2019-11-19T00:07:25Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "a73db0c2-6c3f-406b-b3d5-e3e186fd1c09",
        "parentId" : "d85bc052-b58b-467b-bb58-3152541f665a",
        "authorId" : "af133a35-c4d5-4a44-81d2-5683a0e3bb07",
        "body" : "So at this stage the only solution i have for this problem is \r\n1. Map SMALLINT as IntegerType\r\n2. Map TINYINT as ShortType\r\n\r\nand ofcourse add test cases to cover all signed and unsigned ranges. I can make these changes is very one is ok with this plan?\r\n\r\n@HyukjinKwon @gatorsmile @dongjoon-hyun @srowen @maropu Thanks for your comments. Please let me know if you are ok with the plan above.\r\n\r\n",
        "createdAt" : "2019-11-19T00:15:45Z",
        "updatedAt" : "2019-11-19T00:15:46Z",
        "lastEditedBy" : "af133a35-c4d5-4a44-81d2-5683a0e3bb07",
        "tags" : [
        ]
      },
      {
        "id" : "43872f1e-9f81-4359-9098-eb448a0948b9",
        "parentId" : "d85bc052-b58b-467b-bb58-3152541f665a",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "looks fine to me.",
        "createdAt" : "2019-11-19T00:19:11Z",
        "updatedAt" : "2019-11-19T00:19:11Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "1e4b53b3-313c-494b-b543-463761be3f05",
        "parentId" : "d85bc052-b58b-467b-bb58-3152541f665a",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Since some dbmss don't support unsigned cases, I just want to know the exact behaviour first that we should support from Spark to the all the existing dbmss and vice versa.",
        "createdAt" : "2019-11-19T03:22:08Z",
        "updatedAt" : "2019-11-19T03:22:09Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "d8b94660-9e0a-4ad7-a68b-b52a5130bf1b",
        "parentId" : "d85bc052-b58b-467b-bb58-3152541f665a",
        "authorId" : "af133a35-c4d5-4a44-81d2-5683a0e3bb07",
        "body" : "The behavior would be as follows.\r\n### Overwrite scenario\r\n1. (ShortType -> Int) If a spark df has a ShortType, on overwrite a DBMSS table with type Int will get created. Because Spark ShortyType is -32768 to +32767 only these values can be written. \r\n2. (ByteType -> SmallInt) In a spark df has a ByteType, on overwrite  DBMSS table with type Short will get created. Because Spark ShortyType is -128 to +127 only these values can be written. \r\n\r\n### Read scenario\r\n1. If an existing table in DBMSS has type TinyInt, a read in Spark would results in a ShortType. Because ShortType range in Spark in -32786 to +32768, DBMSS signed value -127 to +127 and unsigned range of 0 to 255 will be handled.\r\n\r\n2. If an existing table in DBMSS has type SmallInt, a read would result in Spark dataframe having a column type as Integer. Because Integer range in Spark in -2147483648 to +2147483648, DBMSS signed value --32768 to +32768 as well as unsigned range of 0 to 65535 will be handled.\r\n\r\n",
        "createdAt" : "2019-11-19T04:22:20Z",
        "updatedAt" : "2019-11-19T04:22:20Z",
        "lastEditedBy" : "af133a35-c4d5-4a44-81d2-5683a0e3bb07",
        "tags" : [
        ]
      },
      {
        "id" : "c4b67a5e-3a5d-401e-9b43-85df2f8d2efd",
        "parentId" : "d85bc052-b58b-467b-bb58-3152541f665a",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "So we have to use a widening conversion both ways. That's the safest thing to do, I guess, and less of a change from the current behavior, where bytes go all the way to ints.",
        "createdAt" : "2019-11-19T15:36:06Z",
        "updatedAt" : "2019-11-19T15:36:07Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "60bd2179-a7f2-4393-8eec-925a46fb0110",
        "parentId" : "d85bc052-b58b-467b-bb58-3152541f665a",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ur, I see. right.",
        "createdAt" : "2019-11-20T08:38:55Z",
        "updatedAt" : "2019-11-20T08:38:55Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "0085076d-5658-4e1c-8828-212918895fdf",
        "parentId" : "d85bc052-b58b-467b-bb58-3152541f665a",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Anyway, thanks for the explanation, @shivsood ",
        "createdAt" : "2019-11-20T08:39:50Z",
        "updatedAt" : "2019-11-20T08:39:50Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "a47411b2-4828-4a9b-86b7-7057781f602a",
        "parentId" : "d85bc052-b58b-467b-bb58-3152541f665a",
        "authorId" : "af133a35-c4d5-4a44-81d2-5683a0e3bb07",
        "body" : "Raised PR https://github.com/apache/spark/pull/27172 with the proposed fix. ShortType is unchanged, only ByteType  fix is modified to map to ShortType on the read path so enable support for  0 to 255 range. \r\n\r\n@maropu @srowen @HyukjinKwon  as FYI. Thanks\r\n",
        "createdAt" : "2020-01-10T23:59:05Z",
        "updatedAt" : "2020-01-10T23:59:22Z",
        "lastEditedBy" : "af133a35-c4d5-4a44-81d2-5683a0e3bb07",
        "tags" : [
        ]
      }
    ],
    "commit" : "06008946964cc7acb8df3ff781513e4577dd2116",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +60,64 @@        |INSERT INTO numbers VALUES (\n        |0,\n        |127, 32767, 2147483647, 9223372036854775807,\n        |123456789012345.123456789012345, 123456789012345.123456789012345,\n        |123456789012345.123456789012345,"
  }
]