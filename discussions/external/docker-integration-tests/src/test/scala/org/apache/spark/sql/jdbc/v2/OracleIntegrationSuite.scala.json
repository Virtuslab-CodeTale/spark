[
  {
    "id" : "c0e95318-5140-47af-b17a-fead5972d8d6",
    "prId" : 29912,
    "prUrl" : "https://github.com/apache/spark/pull/29912#pullrequestreview-499884389",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cc43fb8f-ad3e-4203-9164-3227b816d086",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "plz remove all the unused imports.",
        "createdAt" : "2020-09-30T23:42:40Z",
        "updatedAt" : "2020-10-06T17:58:35Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "5be3a7d432cfc5083d4014811a8676bd156c66d9",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +29,33 @@import org.apache.spark.sql.test.SharedSparkSession\nimport org.apache.spark.sql.types._\nimport org.apache.spark.tags.DockerTest\n\n/**"
  },
  {
    "id" : "4f87ba9a-0df7-44f1-aaa7-947fea89619d",
    "prId" : 29912,
    "prUrl" : "https://github.com/apache/spark/pull/29912#pullrequestreview-502029674",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a2565349-3f7f-499d-830e-318166dda6f6",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Could we run the existing tests of `o.a.s.s.jdbc.OracleIntegrationSuite` for the V2 JDBC path? I think it is okay to fix it in a separate PR though.",
        "createdAt" : "2020-09-30T23:47:11Z",
        "updatedAt" : "2020-10-06T17:58:35Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "a81fbb93-4a31-48c9-80b4-4450059168a7",
        "parentId" : "a2565349-3f7f-499d-830e-318166dda6f6",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "I opened the JIRA ticket for that https://issues.apache.org/jira/browse/SPARK-33066, let's do that separately. Probably, we will need to split the ticket per each supported dialect. ",
        "createdAt" : "2020-10-05T07:15:44Z",
        "updatedAt" : "2020-10-06T17:58:35Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "3692d97f-cfae-4a2a-a7e7-7dcfd386897f",
        "parentId" : "a2565349-3f7f-499d-830e-318166dda6f6",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Yea, looks okay. Thanks for opening it, Max!",
        "createdAt" : "2020-10-05T13:00:17Z",
        "updatedAt" : "2020-10-06T17:58:35Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "5be3a7d432cfc5083d4014811a8676bd156c66d9",
    "line" : 57,
    "diffHunk" : "@@ -1,1 +55,59 @@ */\n@DockerTest\nclass OracleIntegrationSuite extends DockerJDBCIntegrationSuite with SharedSparkSession {\n  override val db = new DatabaseOnDocker {\n    override val imageName = sys.env(\"ORACLE_DOCKER_IMAGE_NAME\")"
  },
  {
    "id" : "e3e7dbf1-8781-4daa-b4c7-699974e13296",
    "prId" : 29912,
    "prUrl" : "https://github.com/apache/spark/pull/29912#pullrequestreview-501893024",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3f46d1b1-2172-4801-82c8-8d66d6920d45",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Does this `ALTER` command always succeed? What if we add a new column having the same name with the existing column? Anyway, I think it is better to add some tests for error cases.",
        "createdAt" : "2020-10-01T00:01:44Z",
        "updatedAt" : "2020-10-06T17:58:35Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "42c2d43a-bd4e-4099-83e4-3e3c89d6ff3a",
        "parentId" : "3f46d1b1-2172-4801-82c8-8d66d6920d45",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "We test here dialect specific changes:\r\n`ALTER TABLE ... ALTER COLUMN` vs `ALTER TABLE ... ADD`\r\nI believe the test for error handling should be added to `JDBCTableCatalogSuite` since error handling should be generic.",
        "createdAt" : "2020-10-05T07:22:14Z",
        "updatedAt" : "2020-10-06T17:58:35Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "4c3194c5-b0f3-483c-a195-0ca05fa994f8",
        "parentId" : "3f46d1b1-2172-4801-82c8-8d66d6920d45",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "I added negative tests to the common tests https://github.com/apache/spark/pull/29945",
        "createdAt" : "2020-10-05T09:50:48Z",
        "updatedAt" : "2020-10-06T17:58:35Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "5be3a7d432cfc5083d4014811a8676bd156c66d9",
    "line" : 79,
    "diffHunk" : "@@ -1,1 +77,81 @@    withTable(\"oracle.alt_table\") {\n      sql(\"CREATE TABLE oracle.alt_table (ID STRING) USING _\")\n      sql(\"ALTER TABLE oracle.alt_table ADD COLUMNS (C1 STRING, C2 STRING)\")\n      var t = spark.table(\"oracle.alt_table\")\n      var expectedSchema = new StructType()"
  },
  {
    "id" : "e724bef0-361c-4203-968f-319443b9a286",
    "prId" : 29912,
    "prUrl" : "https://github.com/apache/spark/pull/29912#pullrequestreview-501914519",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f6c1e452-f244-4ff0-b8cb-4cd624d9802b",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "ditto: We can alter a column from a string type to a int one?",
        "createdAt" : "2020-10-01T00:03:48Z",
        "updatedAt" : "2020-10-06T17:58:35Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "3e34a4c0-cd60-42c6-a672-98d1c887032d",
        "parentId" : "f6c1e452-f244-4ff0-b8cb-4cd624d9802b",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "No:\r\n```\r\nrg.apache.spark.sql.AnalysisException: Cannot update alt_table field ID: string cannot be cast to int; line 1 pos 0;\r\n[info] AlterTable org.apache.spark.sql.execution.datasources.v2.jdbc.JDBCTableCatalog@3ebc40fe, alt_table, RelationV2[ID#25] alt_table, [org.apache.spark.sql.connector.catalog.TableChange$UpdateColumnType@ce035e83]\r\n[info]   at org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\r\n[info]   at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$31(CheckAnalysis.scala:528)\r\n[info]   at scala.collection.immutable.List.foreach(List.scala:392)\r\n[info]   at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:489)\r\n```\r\nI will add a check for that.",
        "createdAt" : "2020-10-05T10:20:05Z",
        "updatedAt" : "2020-10-06T17:58:35Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "5be3a7d432cfc5083d4014811a8676bd156c66d9",
    "line" : 106,
    "diffHunk" : "@@ -1,1 +104,108 @@    withTable(\"oracle.alt_table\") {\n      sql(\"CREATE TABLE oracle.alt_table (ID INTEGER) USING _\")\n      sql(\"ALTER TABLE oracle.alt_table ALTER COLUMN id TYPE STRING\")\n      val t = spark.table(\"oracle.alt_table\")\n      val expectedSchema = new StructType().add(\"ID\", StringType)"
  },
  {
    "id" : "3df0641a-f3e5-426d-9cda-ae8c21e55a4a",
    "prId" : 29912,
    "prUrl" : "https://github.com/apache/spark/pull/29912#pullrequestreview-501906141",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "40b6017b-80f8-4830-8917-9d0d292d2cce",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "ditto: What if we drop a non-existent column?",
        "createdAt" : "2020-10-01T00:04:38Z",
        "updatedAt" : "2020-10-06T17:58:35Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "76010999-f1fc-413d-b03f-c38656e0055f",
        "parentId" : "40b6017b-80f8-4830-8917-9d0d292d2cce",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "I will add negative tests.",
        "createdAt" : "2020-10-05T10:07:43Z",
        "updatedAt" : "2020-10-06T17:58:35Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "5be3a7d432cfc5083d4014811a8676bd156c66d9",
    "line" : 136,
    "diffHunk" : "@@ -1,1 +134,138 @@    withTable(\"oracle.alt_table\") {\n      sql(\"CREATE TABLE oracle.alt_table (ID STRING NOT NULL) USING _\")\n      sql(\"ALTER TABLE oracle.alt_table ALTER COLUMN ID DROP NOT NULL\")\n      val t = spark.table(\"oracle.alt_table\")\n      val expectedSchema = new StructType().add(\"ID\", StringType, nullable = true)"
  }
]