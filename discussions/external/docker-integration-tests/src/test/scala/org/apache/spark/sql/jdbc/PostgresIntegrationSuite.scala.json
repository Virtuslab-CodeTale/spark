[
  {
    "id" : "a1a240b0-6cad-46a0-90df-8fe01cf070dc",
    "prId" : 31419,
    "prUrl" : "https://github.com/apache/spark/pull/31419#pullrequestreview-581542073",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3e5ac3e0-9996-49a6-b94a-0aecd0125bb5",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "How about adding tests for non-array cases, e.g., `col xml` and `col tsvector`?",
        "createdAt" : "2021-02-02T06:52:09Z",
        "updatedAt" : "2021-02-08T03:09:52Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "15c6b88d-938f-4323-90ca-b9d91504ac35",
        "parentId" : "3e5ac3e0-9996-49a6-b94a-0aecd0125bb5",
        "authorId" : "3a227965-84e0-47cf-9974-11293764f028",
        "body" : "I found there are lots of types not tested so far. So I'll open another PR for non-array cases and focus on array cases in this PR.",
        "createdAt" : "2021-02-02T15:52:54Z",
        "updatedAt" : "2021-02-08T03:09:52Z",
        "lastEditedBy" : "3a227965-84e0-47cf-9974-11293764f028",
        "tags" : [
        ]
      },
      {
        "id" : "d5b6cee4-8f89-44c7-89cf-ab01c479b476",
        "parentId" : "3e5ac3e0-9996-49a6-b94a-0aecd0125bb5",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Does that mean there are types that aren't supported, but for which we support arrays? did I misunderstand that?",
        "createdAt" : "2021-02-02T16:26:14Z",
        "updatedAt" : "2021-02-08T03:09:52Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "c8b358ad-dd16-49e5-920f-f036b7556e95",
        "parentId" : "3e5ac3e0-9996-49a6-b94a-0aecd0125bb5",
        "authorId" : "3a227965-84e0-47cf-9974-11293764f028",
        "body" : "I mean that some supported non-array types like `numeric`, `varchar`, `date` and etc are not tested.\r\nSo, we need to add tests for those types in addition to the types supported by this PR.",
        "createdAt" : "2021-02-02T16:39:14Z",
        "updatedAt" : "2021-02-08T03:09:52Z",
        "lastEditedBy" : "3a227965-84e0-47cf-9974-11293764f028",
        "tags" : [
        ]
      }
    ],
    "commit" : "010413ee49728b5ed537636aef520f024e12ec09",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +90,94 @@\n    conn.prepareStatement(\"CREATE TABLE st_with_array (c0 uuid, c1 inet, c2 cidr,\" +\n      \"c3 json, c4 jsonb, c5 uuid[], c6 inet[], c7 cidr[], c8 json[], c9 jsonb[], c10 xml[], \" +\n      \"c11 tsvector[], c12 tsquery[], c13 macaddr[], c14 txid_snapshot[], c15 point[], \" +\n      \"c16 line[], c17 lseg[], c18 box[], c19 path[], c20 polygon[], c21 circle[], c22 pg_lsn[], \" +"
  },
  {
    "id" : "ad172fef-832b-41f6-8dbf-b26a473ea4d1",
    "prId" : 29932,
    "prUrl" : "https://github.com/apache/spark/pull/29932#pullrequestreview-500898026",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a134ae36-53d4-4f3d-ae54-d208263f1aa7",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "I verified this.\r\n```\r\nPostgresIntegrationSuite:\r\n- Type mapping for various types\r\n- Basic write test\r\n- Creating a table with shorts and floats\r\n- SPARK-20557: column type TIMESTAMP with TIME ZONE and TIME with TIME ZONE should be recognized\r\n- SPARK-22291: Conversion error when transforming array types of uuid, inet and cidr to StingType in PostgreSQL\r\n- query JDBC option\r\n- write byte as smallint\r\n- character type tests\r\n- SPARK-32576: character array type tests\r\n```",
        "createdAt" : "2020-10-02T07:01:17Z",
        "updatedAt" : "2020-10-02T11:33:49Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "0ef813b4171b9942e341ec788ddb41151bdb3110",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +37,41 @@class PostgresIntegrationSuite extends DockerJDBCIntegrationSuite {\n  override val db = new DatabaseOnDocker {\n    override val imageName = sys.env.getOrElse(\"POSTGRES_DOCKER_IMAGE_NAME\", \"postgres:13.0-alpine\")\n    override val env = Map(\n      \"POSTGRES_PASSWORD\" -> \"rootpass\""
  }
]