[
  {
    "id" : "c619dce9-7572-4981-853d-f81fe8abff52",
    "prId" : 33630,
    "prUrl" : "https://github.com/apache/spark/pull/33630#pullrequestreview-721909143",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4c223112-8a80-4b63-b731-628c87c5e961",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "`MutableAggregationBuffer` itself seems to be used in our API. Is `jsonValue` incompatibility okay?\r\n\r\n```scala\r\n  /**\r\n   * Initializes the given aggregation buffer, i.e. the zero value of the aggregation buffer.\r\n   *\r\n   * The contract should be that applying the merge function on two initial buffers should just\r\n   * return the initial buffer itself, i.e.\r\n   * `merge(initialBuffer, initialBuffer)` should equal `initialBuffer`.\r\n   *\r\n   * @since 1.5.0\r\n   */\r\n  def initialize(buffer: MutableAggregationBuffer): Unit\r\n```\r\n\r\ncc @HyukjinKwon , @cloud-fan ",
        "createdAt" : "2021-08-04T06:15:31Z",
        "updatedAt" : "2021-08-04T06:16:09Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "13bb8eeb-29d7-42cd-aaaa-a8beda1e8a4d",
        "parentId" : "4c223112-8a80-4b63-b731-628c87c5e961",
        "authorId" : "3a227965-84e0-47cf-9974-11293764f028",
        "body" : "`MutableAggregationBuffer.jsonValue` is marked as `private[sql]` so I thought it's OK. But if I'm missing something, please let me know.\r\nMaybe, users need to re-compile their applications due to the binary compatibility of `MutableAggregationBuffer` will break?",
        "createdAt" : "2021-08-04T06:34:54Z",
        "updatedAt" : "2021-08-04T06:34:55Z",
        "lastEditedBy" : "3a227965-84e0-47cf-9974-11293764f028",
        "tags" : [
        ]
      }
    ],
    "commit" : "02782040e91b9ba38d72f43d016727b94efd405d",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +40,44 @@    ProblemFilters.exclude[IncompatibleMethTypeProblem](\"org.apache.spark.ml.param.FloatParam.jValueDecode\"),\n    ProblemFilters.exclude[IncompatibleMethTypeProblem](\"org.apache.spark.mllib.tree.model.TreeEnsembleModel#SaveLoadV1_0.readMetadata\"),\n    ProblemFilters.exclude[IncompatibleResultTypeProblem](\"org.apache.spark.sql.expressions.MutableAggregationBuffer.jsonValue\")\n  )\n"
  },
  {
    "id" : "19b28cc9-6320-402e-b0f4-efcae4950add",
    "prId" : 33199,
    "prUrl" : "https://github.com/apache/spark/pull/33199#pullrequestreview-698552027",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3866bce8-0cff-41f0-8dc6-15b43bc240ad",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "cc @AngersZhuuuu and @srowen for SPARK-34848\r\n- https://github.com/apache/spark/pull/31948",
        "createdAt" : "2021-07-03T01:00:03Z",
        "updatedAt" : "2021-07-03T01:02:42Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "78c6a4572bfccb8a29b2cc239d5f3d2c08ff3dc3",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +56,60 @@\n    // [SPARK-34848][CORE] Add duration to TaskMetricDistributions\n    ProblemFilters.exclude[DirectMissingMethodProblem](\"org.apache.spark.status.api.v1.TaskMetricDistributions.this\"),\n\n    // [SPARK-34488][CORE] Support task Metrics Distributions and executor Metrics Distributions"
  },
  {
    "id" : "3ff7fc91-02ea-4b9d-a5ba-47541cd03708",
    "prId" : 33199,
    "prUrl" : "https://github.com/apache/spark/pull/33199#pullrequestreview-698552138",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "314e4980-0d0c-426c-a2b3-337e59757779",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "cc @AngersZhuuuu and @srowen for SPARK-34488\r\n- https://github.com/apache/spark/pull/31611",
        "createdAt" : "2021-07-03T01:01:22Z",
        "updatedAt" : "2021-07-03T01:03:08Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "78c6a4572bfccb8a29b2cc239d5f3d2c08ff3dc3",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +60,64 @@    // [SPARK-34488][CORE] Support task Metrics Distributions and executor Metrics Distributions\n    // in the REST API call for a specified stage\n    ProblemFilters.exclude[MissingMethodProblem](\"org.apache.spark.status.api.v1.StageData.this\"),\n\n    // [SPARK-35896] Include more granular metrics for stateful operators in StreamingQueryProgress"
  },
  {
    "id" : "e50732dd-7aa1-49e0-b327-1c2b0da53e3a",
    "prId" : 33199,
    "prUrl" : "https://github.com/apache/spark/pull/33199#pullrequestreview-698552202",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "549812cf-d3f7-46ba-85a6-8f25ce07e831",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "cc @vkorukanti and @HeartSaVioR for SPARK-35896\r\n- https://github.com/apache/spark/pull/33091",
        "createdAt" : "2021-07-03T01:02:14Z",
        "updatedAt" : "2021-07-03T01:03:26Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "78c6a4572bfccb8a29b2cc239d5f3d2c08ff3dc3",
    "line" : 35,
    "diffHunk" : "@@ -1,1 +63,67 @@\n    // [SPARK-35896] Include more granular metrics for stateful operators in StreamingQueryProgress\n    ProblemFilters.exclude[DirectMissingMethodProblem](\"org.apache.spark.sql.streaming.StateOperatorProgress.this\"),\n\n    (problem: Problem) => problem match {"
  },
  {
    "id" : "b708c6ba-de4e-4721-b5a2-082ef7943c81",
    "prId" : 33196,
    "prUrl" : "https://github.com/apache/spark/pull/33196#pullrequestreview-698476325",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "efcf79a0-de79-4660-a26f-5aecc3fb03a6",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "We need not address there here, but I'm wondering if we should carry forward all the previous excludes? In master (currently 3.3.0) we're only concerned with excluding changes since 3.2.x. If, somehow, a previous exclusion matched a new, legitimate breaking change of the same type, we'd be masking it, no? or maybe i'm not thinking about it correctly.",
        "createdAt" : "2021-07-02T20:15:56Z",
        "updatedAt" : "2021-07-02T20:15:57Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      }
    ],
    "commit" : "780fd6345d9d6f444534ed47aa4273fa9b810499",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +36,40 @@\n  // Exclude rules for 3.3.x\n  lazy val v33excludes = v32excludes ++ Seq(\n  )\n"
  }
]