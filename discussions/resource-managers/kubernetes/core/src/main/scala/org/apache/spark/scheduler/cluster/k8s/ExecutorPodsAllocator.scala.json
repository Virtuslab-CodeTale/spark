[
  {
    "id" : "00657760-ceb3-418f-aa1e-f9eec29cb965",
    "prId" : 33492,
    "prUrl" : "https://github.com/apache/spark/pull/33492#pullrequestreview-713520912",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a3e320b3-ab8a-4da5-a0e5-cc1bc7584e05",
        "parentId" : null,
        "authorId" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "body" : "This is a rename but the old name was misleading as it counts the pending PODs which  unknown by the scheduler.",
        "createdAt" : "2021-07-23T08:54:41Z",
        "updatedAt" : "2021-07-23T08:54:41Z",
        "lastEditedBy" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "tags" : [
        ]
      }
    ],
    "commit" : "2e78f6c08a8a066cc52123c35a5de852b92457c4",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +244,248 @@      // This variable is used later to print some debug logs. It's updated when cleaning up\n      // excess pod requests, since currentPendingExecutorsForRpId is immutable.\n      var pendingCountForRpId = currentPendingExecutorsForRpId.size\n\n      val newlyCreatedExecutorsForRpId ="
  },
  {
    "id" : "b84a75ed-be35-4562-9447-25f6c297f259",
    "prId" : 33492,
    "prUrl" : "https://github.com/apache/spark/pull/33492#pullrequestreview-713522986",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5c12e82f-7019-4d47-a208-024bca9abd2f",
        "parentId" : null,
        "authorId" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "body" : "This again a rename to avoid \"known\" prefix as it not for scheduler known PODs but PODs for this resource profile.",
        "createdAt" : "2021-07-23T08:57:21Z",
        "updatedAt" : "2021-07-23T08:57:21Z",
        "lastEditedBy" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "tags" : [
        ]
      }
    ],
    "commit" : "2e78f6c08a8a066cc52123c35a5de852b92457c4",
    "line" : 59,
    "diffHunk" : "@@ -1,1 +276,280 @@        currentPendingExecutorsForRpId.size + schedulerKnownPendingExecsForRpId.size +\n        newlyCreatedExecutorsForRpId.size + schedulerKnownNewlyCreatedExecsForRpId.size\n      val podCountForRpId = currentRunningCount + notRunningPodCountForRpId\n\n      if (podCountForRpId > targetNum) {"
  },
  {
    "id" : "0713907d-f2aa-4e1e-ad8c-d09fe65028b0",
    "prId" : 33492,
    "prUrl" : "https://github.com/apache/spark/pull/33492#pullrequestreview-713524325",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "714d03d1-d37e-46f5-b124-1b7a267d6771",
        "parentId" : null,
        "authorId" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "body" : "Last rename for the same reason as earlier: this are PODs unknow by the scheduler so safe to be removed here (no task can be scheduled on them).",
        "createdAt" : "2021-07-23T08:59:11Z",
        "updatedAt" : "2021-07-23T08:59:11Z",
        "lastEditedBy" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "tags" : [
        ]
      }
    ],
    "commit" : "2e78f6c08a8a066cc52123c35a5de852b92457c4",
    "line" : 70,
    "diffHunk" : "@@ -1,1 +284,288 @@            currentTime - createTime > executorIdleTimeout\n          }.keys.take(excess).toList\n        val pendingToDelete = currentPendingExecutorsForRpId\n          .filter(x => isExecutorIdleTimedOut(x._2, currentTime))\n          .take(excess - newlyCreatedToDelete.size)"
  },
  {
    "id" : "70bb4d1f-32fb-4e78-9dad-1dec2849952c",
    "prId" : 33492,
    "prUrl" : "https://github.com/apache/spark/pull/33492#pullrequestreview-713542468",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "60a94339-d888-49cb-bce5-1aefc664d640",
        "parentId" : null,
        "authorId" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "body" : "The condition previously used \"outstanding\" which contains pending (unknown by the scheduler) PODs as well but the old condition to call `requestNewExecutors` was:\r\n\r\n```\r\n  if (newlyCreatedExecutorsForRpId.isEmpty\r\n        && knownPodCount < targetNum) {\r\n        requestNewExecutors(targetNum, knownPodCount, applicationId, rpId, k8sKnownPVCNames)\r\n      }\r\n```\r\n\r\nSo here really the emptiness of `newlyCreatedExecutorsForRpId` should be checked.",
        "createdAt" : "2021-07-23T09:22:58Z",
        "updatedAt" : "2021-07-23T09:22:58Z",
        "lastEditedBy" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "tags" : [
        ]
      }
    ],
    "commit" : "2e78f6c08a8a066cc52123c35a5de852b92457c4",
    "line" : 111,
    "diffHunk" : "@@ -1,1 +320,324 @@            \"equal to the number of requested executors. Not scaling up further.\")\n        } else {\n          if (newlyCreatedExecutorsForRpId.nonEmpty) {\n            logDebug(s\"Still waiting for ${newlyCreatedExecutorsForRpId.size} executors for \" +\n              s\"ResourceProfile Id $rpId before requesting more.\")"
  },
  {
    "id" : "d9bb5ba9-b365-4880-b92f-3d65e1c7549d",
    "prId" : 33492,
    "prUrl" : "https://github.com/apache/spark/pull/33492#pullrequestreview-713544424",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "062e1df7-b763-4240-9b35-89d81d9b22c9",
        "parentId" : null,
        "authorId" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "body" : "Instead of `foreach` here is `flatMap` as we need to do the process in two steps for counting all the not running PODs for all the resource profiles before we decide how to split the remaining pending PODs slot between the resource profiles.",
        "createdAt" : "2021-07-23T09:25:29Z",
        "updatedAt" : "2021-07-23T09:25:29Z",
        "lastEditedBy" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "tags" : [
        ]
      }
    ],
    "commit" : "2e78f6c08a8a066cc52123c35a5de852b92457c4",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +228,232 @@      .toSeq\n      .sortBy(_._1)\n      .flatMap { case (rpId, targetNum) =>\n      val podsForRpId = rpIdToExecsAndPodState.getOrElse(rpId, mutable.HashMap.empty)\n"
  },
  {
    "id" : "bfd53eec-8ee0-4ed7-9660-e5ecfe300392",
    "prId" : 33492,
    "prUrl" : "https://github.com/apache/spark/pull/33492#pullrequestreview-717317477",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0a9e8d12-e469-457d-9837-5f41a40c4a0c",
        "parentId" : null,
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "I get this is the old behaviour, but I would think that we might allocate up to max pending so requiring newlyCreated to be empty seems strange to me.",
        "createdAt" : "2021-07-23T23:15:20Z",
        "updatedAt" : "2021-07-23T23:15:46Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      },
      {
        "id" : "4e6e28e4-a86a-4091-aee4-5372715524aa",
        "parentId" : "0a9e8d12-e469-457d-9837-5f41a40c4a0c",
        "authorId" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "body" : "This is kept intentionally, see https://github.com/apache/spark/pull/33492#discussion_r675961263.\r\n\r\nThe new limit is enforced at https://github.com/apache/spark/blob/adc512d4e1837713713fefc6f64af3b0c6c8cdc8/resource-managers/kubernetes/core/src/main/scala/org/apache/spark/scheduler/cluster/k8s/ExecutorPodsAllocator.scala#L336-L339\r\n",
        "createdAt" : "2021-07-24T07:26:29Z",
        "updatedAt" : "2021-07-24T07:26:30Z",
        "lastEditedBy" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "tags" : [
        ]
      },
      {
        "id" : "9e1ab5d7-2887-4300-8002-26580ec12ee0",
        "parentId" : "0a9e8d12-e469-457d-9837-5f41a40c4a0c",
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "Cool :)",
        "createdAt" : "2021-07-28T18:03:42Z",
        "updatedAt" : "2021-07-28T18:03:42Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      }
    ],
    "commit" : "2e78f6c08a8a066cc52123c35a5de852b92457c4",
    "line" : 123,
    "diffHunk" : "@@ -1,1 +332,336 @@        None\n      }\n    }\n\n    val remainingSlotFromPendingPods = maxPendingPods - totalNotRunningPodCount"
  },
  {
    "id" : "aa74a084-814c-4130-89b2-055ed701c613",
    "prId" : 33492,
    "prUrl" : "https://github.com/apache/spark/pull/33492#pullrequestreview-717931383",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3f9b8bd6-2fa7-4171-b624-1ab59c243ce7",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "I removed the previous my comment because I'm also not sure what is the best way to inform the users this situation. Do you think we have a good way to inform to the users when we hit this limitation, @attilapiros ?",
        "createdAt" : "2021-07-28T23:55:05Z",
        "updatedAt" : "2021-07-28T23:55:05Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "0db78ae8-ecfe-4e68-8e19-a0629cc4bdbe",
        "parentId" : "3f9b8bd6-2fa7-4171-b624-1ab59c243ce7",
        "authorId" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "body" : "We could change this to logInfo:\r\nhttps://github.com/apache/spark/blob/adc512d4e1837713713fefc6f64af3b0c6c8cdc8/resource-managers/kubernetes/core/src/main/scala/org/apache/spark/scheduler/cluster/k8s/ExecutorPodsAllocator.scala#L323-L324\r\n\r\nBut for a higher batch allocation size this message could be annoying as every POD status change will generate such a log line while it reaches 0.",
        "createdAt" : "2021-07-29T10:28:44Z",
        "updatedAt" : "2021-07-29T10:28:45Z",
        "lastEditedBy" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "tags" : [
        ]
      }
    ],
    "commit" : "2e78f6c08a8a066cc52123c35a5de852b92457c4",
    "line" : 121,
    "diffHunk" : "@@ -1,1 +330,334 @@      } else {\n        // for this resource profile we do not request more PODs\n        None\n      }\n    }"
  },
  {
    "id" : "b376e080-db13-45ed-8d90-dc678a32dab1",
    "prId" : 32752,
    "prUrl" : "https://github.com/apache/spark/pull/32752#pullrequestreview-675881629",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0f912a9b-699c-45d1-975e-1591cdf92d38",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "If we are going to just `logWarning`, the following code pattern will be better like the other places.\r\n```scala\r\nUtils.tryLogNonFatalError {\r\n  kubernetesClient.pods()\r\n    .withName(kubernetesDriverPodName.get)\r\n    .waitUntilReady(driverPodReadinessTimeout, TimeUnit.MINUTES)\r\n}\r\n```",
        "createdAt" : "2021-06-03T16:52:25Z",
        "updatedAt" : "2021-06-03T16:52:25Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "83972e88-cde8-4972-afbb-f34b76c37b56",
        "parentId" : "0f912a9b-699c-45d1-975e-1591cdf92d38",
        "authorId" : "da8d4675-e56b-4240-b43c-bac7c4a2f788",
        "body" : "If we just do `logWarning` and continue to create executor pods after this timeout, it's very likely executor pods will still hit the `UnknownHostException` issue.\r\nConsidering this, throwing a SparkException may be more intuitive and fail-fast. Please let me know your thoughts on this. Thanks.\r\nLike here:\r\nhttps://github.com/apache/spark/blob/0342dcb6289bae67f6ab742b8fd03b2d653e52ea/resource-managers/kubernetes/core/src/main/scala/org/apache/spark/scheduler/cluster/k8s/ExecutorPodsAllocator.scala#L73-L79\r\n",
        "createdAt" : "2021-06-03T17:39:01Z",
        "updatedAt" : "2021-06-03T17:39:02Z",
        "lastEditedBy" : "da8d4675-e56b-4240-b43c-bac7c4a2f788",
        "tags" : [
        ]
      },
      {
        "id" : "42a79b3f-43ab-4fd7-870e-790bba227d53",
        "parentId" : "0f912a9b-699c-45d1-975e-1591cdf92d38",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "-1 for `SparkException` idea. That is a huge regression.\r\n\r\n`UnknownHostException` is not a job blocker because Spark is going to create the required executors in any way eventually. If you throws SparkException, you change will be a breaker of the existing Spark pipelines indeed.",
        "createdAt" : "2021-06-04T00:10:15Z",
        "updatedAt" : "2021-06-04T00:10:15Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "31b37a83-194c-44a2-9dff-16f2ddca3fc1",
        "parentId" : "0f912a9b-699c-45d1-975e-1591cdf92d38",
        "authorId" : "da8d4675-e56b-4240-b43c-bac7c4a2f788",
        "body" : "As the [JIRA issue](https://issues.apache.org/jira/browse/SPARK-32975) describes, driver will not create new executors when this error happens.\r\n> Once this error happens, driver doesn't restart executor.\r\n\r\nHowever, other executors may be running fine. It's just that the number of healthy executors will be less than expected.    So I agree not to use `SparkException` here.",
        "createdAt" : "2021-06-04T02:36:04Z",
        "updatedAt" : "2021-06-04T02:36:04Z",
        "lastEditedBy" : "da8d4675-e56b-4240-b43c-bac7c4a2f788",
        "tags" : [
        ]
      },
      {
        "id" : "e552fa54-cf97-4d04-882c-8536806a9d2f",
        "parentId" : "0f912a9b-699c-45d1-975e-1591cdf92d38",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "I don't think the error report is correct because Apache Spark doesn't use `restart` executor at all. The driver will keep creating new executors because the executors with `UnknownHostException` will be dead on the failure. I'm currently describing the Apache Spark behavior, not 3rd party operator behavior.",
        "createdAt" : "2021-06-04T03:04:26Z",
        "updatedAt" : "2021-06-04T03:04:27Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "4dbae0a7280471df9903c9a4b2a998f915968bc9",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +110,114 @@        .withName(kubernetesDriverPodName.get)\n        .waitUntilReady(driverPodReadinessTimeout, TimeUnit.SECONDS)\n    }\n    snapshotsStore.addSubscriber(podAllocationDelay) {\n      onNewSnapshots(applicationId, schedulerBackend, _)"
  }
]