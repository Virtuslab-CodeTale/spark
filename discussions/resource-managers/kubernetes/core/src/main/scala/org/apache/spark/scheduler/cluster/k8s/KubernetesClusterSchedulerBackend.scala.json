[
  {
    "id" : "333e6326-3656-47a3-b5fb-2074abbf3c38",
    "prId" : 33211,
    "prUrl" : "https://github.com/apache/spark/pull/33211#pullrequestreview-703469554",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1aea976c-9064-460e-9e5f-a075d9b0b759",
        "parentId" : null,
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "Would it make sense to instead change the superclass appId impl?",
        "createdAt" : "2021-07-09T17:07:58Z",
        "updatedAt" : "2021-07-09T17:08:03Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      },
      {
        "id" : "03de390a-ed02-4922-9988-72e9fe6f30a3",
        "parentId" : "1aea976c-9064-460e-9e5f-a075d9b0b759",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "The superclass appId i.e. `SchedulerBackend` is only used as fallback id beside `KubernetesClusterSchedulerBackend` then it doesn't make much sense. I prefer the current one.",
        "createdAt" : "2021-07-10T04:15:44Z",
        "updatedAt" : "2021-07-10T04:15:44Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "6d0c3dcf12483d9cf0ba6cec9a8e9e1a379e6a38",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +90,94 @@   */\n  override def applicationId(): String = {\n    conf.getOption(\"spark.app.id\").map(_.toString).getOrElse(appId)\n  }\n"
  },
  {
    "id" : "e8f1f044-8ccc-47a8-9b4c-663bf327a2ef",
    "prId" : 32288,
    "prUrl" : "https://github.com/apache/spark/pull/32288#pullrequestreview-642783382",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "98c8f134-500b-4318-8837-368da1b52fe8",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "So we don't delete PVC before?",
        "createdAt" : "2021-04-22T21:36:38Z",
        "updatedAt" : "2021-04-22T21:36:38Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "47e309a5-7afa-43c2-b39c-fedced68f8dd",
        "parentId" : "98c8f134-500b-4318-8837-368da1b52fe8",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Previously, the lifecycle is tied with the executor pod.\r\nNow, the lifecycle is tied with the driver pod. So, it will be deleted when the driver pod die.\r\nThis code is to support early deletion at the app termination.\r\nThis is the same one for `spark.kubernetes.driver.service.deleteOnTermination`~\r\n",
        "createdAt" : "2021-04-23T00:02:19Z",
        "updatedAt" : "2021-04-23T00:02:19Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "b350f2500e222244b41351fe6d68437f896bb1e1",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +140,144 @@        .withLabel(SPARK_APP_ID_LABEL, applicationId())\n        .delete()\n    }\n\n    if (shouldDeleteExecutors) {"
  }
]