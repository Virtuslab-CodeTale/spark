[
  {
    "id" : "5af19a23-1373-4306-bdc1-aa13c87699b1",
    "prId" : 33563,
    "prUrl" : "https://github.com/apache/spark/pull/33563#pullrequestreview-717559027",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c315f0af-6ae1-4116-9cef-648247b7540f",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "The default is `false` in order to preserve the previous behavior which requests the consistent data.",
        "createdAt" : "2021-07-29T00:06:05Z",
        "updatedAt" : "2021-07-29T00:06:05Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "b9898f9a2e5644bbde128c944d1be3c521943b93",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +402,406 @@      .version(\"3.3.0\")\n      .booleanConf\n      .createWithDefault(false)\n\n  val KUBERNETES_EXECUTOR_EVENT_PROCESSING_INTERVAL ="
  },
  {
    "id" : "beab821b-b971-47c7-8db0-0474423834ad",
    "prId" : 33563,
    "prUrl" : "https://github.com/apache/spark/pull/33563#pullrequestreview-717711587",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a408b5aa-21f3-4fc2-9f62-400a1eeb92c7",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Now we replace only when we receive a monotonically increased resourceVersion. Is `This should be used carefully` still necessary?",
        "createdAt" : "2021-07-29T06:20:44Z",
        "updatedAt" : "2021-07-29T06:20:44Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "a1aaa804-64ea-4d0a-accb-6334208f33a6",
        "parentId" : "a408b5aa-21f3-4fc2-9f62-400a1eeb92c7",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Yes, it's still risky because it gets stale data~",
        "createdAt" : "2021-07-29T06:21:41Z",
        "updatedAt" : "2021-07-29T06:21:41Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "4cf8541e-bb7f-4e70-8a89-2899d0c62987",
        "parentId" : "a408b5aa-21f3-4fc2-9f62-400a1eeb92c7",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Spark driver still may time-out executor pods because they are not visible to the driver.",
        "createdAt" : "2021-07-29T06:22:55Z",
        "updatedAt" : "2021-07-29T06:22:55Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "b9898f9a2e5644bbde128c944d1be3c521943b93",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +399,403 @@    ConfigBuilder(\"spark.kubernetes.executor.enablePollingWithResourceVersion\")\n      .doc(\"If true, `resourceVersion` is set with `0` during invoking pod listing APIs \" +\n        \"in order to allow API Server-side caching. This should be used carefully.\")\n      .version(\"3.3.0\")\n      .booleanConf"
  },
  {
    "id" : "91a01dfb-6057-4ac5-8ad0-579fde748c02",
    "prId" : 32564,
    "prUrl" : "https://github.com/apache/spark/pull/32564#pullrequestreview-660593361",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "75bff202-97e6-49aa-a0b9-61f6109f05f1",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Do we need \"driver\" in the config name? We reuse executor PVCs, right?",
        "createdAt" : "2021-05-17T06:28:16Z",
        "updatedAt" : "2021-05-17T06:28:17Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "9579fd47-71fe-4784-87f5-16939b9c9058",
        "parentId" : "75bff202-97e6-49aa-a0b9-61f6109f05f1",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Technically, *driver* is the actor who is re-injecting driver-owned PVCs.",
        "createdAt" : "2021-05-17T06:31:25Z",
        "updatedAt" : "2021-05-17T06:31:26Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "b87803e241d6ea380884db477be6b35fdc86f137",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +73,77 @@  val KUBERNETES_DRIVER_REUSE_PVC =\n    ConfigBuilder(\"spark.kubernetes.driver.reusePersistentVolumeClaim\")\n      .doc(\"If true, driver pod tries to reuse driver-owned on-demand persistent volume claims \" +\n        \"of the deleted executor pods if exists. This can be useful to reduce executor pod \" +\n        \"creation delay by skipping persistent volume creations. Note that a pod in \" +"
  },
  {
    "id" : "4fff38fa-bb05-42a8-b93d-68393712edb4",
    "prId" : 31790,
    "prUrl" : "https://github.com/apache/spark/pull/31790#pullrequestreview-702381604",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c3b1be3f-89ac-42f7-95fb-c7d68e31c8e5",
        "parentId" : null,
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "This default seems high, can you explain why 150?",
        "createdAt" : "2021-06-25T17:59:21Z",
        "updatedAt" : "2021-06-25T18:00:10Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      },
      {
        "id" : "59b30c08-f2db-4390-994b-06e9c47f9b95",
        "parentId" : "c3b1be3f-89ac-42f7-95fb-c7d68e31c8e5",
        "authorId" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "body" : "Thanks for the review!\r\n\r\nMy main intention was to come up with a limit which protect us from overloading the k8s scheduler but still allows progressive upscaling. I think when a PODs spends long time in pending state we should make the allocation as early as possible but being careful to avoid the overloading of the k8s scheduler as that would be counterproductive for the allocations. And as we still use the batch size during upscaling there is a limited number of active new POD requests from a single Spark application (this also helps to avoid the overloading).\r\n\r\nAnd the second reason was I hoped this a good default for those envs where the batchsize is already increased (I have seen examples where the batch size was set to 50). \r\n\r\nBut I just run a few tests and although I have seen 150 pending PODs was not causing any problem during resource allocation my test was running in a EKS cluster where only one Spark app was submitted (my test app) and even the cluster size was small. \r\n\r\nSo nevertheless we can go for a different solution:\r\n**Another strategy to choose this limit would be to use a default which is conformed to the default batch size (which is really small = 5). So what about setting the default to 15 here?** In this case we can mention this new config in the migration guide. \r\n\r\n@holdenk WDYT?\r\n",
        "createdAt" : "2021-06-26T18:13:15Z",
        "updatedAt" : "2021-06-26T18:13:15Z",
        "lastEditedBy" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "tags" : [
        ]
      },
      {
        "id" : "1d844967-1153-4406-91e3-dd6569362a7e",
        "parentId" : "c3b1be3f-89ac-42f7-95fb-c7d68e31c8e5",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "I'd like to propose to disable this feature at Apache Spark 3.2.0 to remove the side-effect completely. For example, we can use `Int.MaxValue` as default to disable this feature.\r\nWDYT, @attilapiros and @holdenk ?",
        "createdAt" : "2021-06-27T05:07:39Z",
        "updatedAt" : "2021-06-27T05:14:13Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "48334daf-1925-4712-a4c6-91c0462d2dba",
        "parentId" : "c3b1be3f-89ac-42f7-95fb-c7d68e31c8e5",
        "authorId" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "body" : "@dongjoon-hyun \r\n> And, it would be great if we keep the existing test cases with the default configuration (disabled), and add new test coverage for this new conf.\r\n\r\nSo this PR has 3 small features which relates to each others:\r\n- modify how the batch size limit is taken into account: earlier the next batch is not started when even one POD was stuck as newly created POD: **these causes some of the test changes**\r\n- change what is outstanding PODs are: earlier Pending PODs and newly created PODs was counted as outstanding PODs which [was stopping the allocation if it was coming from the scheduler](https://github.com/apache/spark/blob/master/resource-managers/kubernetes/core/src/main/scala/org/apache/spark/scheduler/cluster/k8s/ExecutorPodsAllocator.scala#L125). \r\n**This causes the rest of the unit test difference.**\r\n- introduce limit for pending pods\r\n\r\nLet me separate them into different PRs (at least for two) this will make the review easier.  \r\n\r\n",
        "createdAt" : "2021-06-27T08:24:43Z",
        "updatedAt" : "2021-06-27T08:24:44Z",
        "lastEditedBy" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "tags" : [
        ]
      },
      {
        "id" : "1f9e758f-c03f-4c75-8f80-9379ceb86dbb",
        "parentId" : "c3b1be3f-89ac-42f7-95fb-c7d68e31c8e5",
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "Sounds good, ping me on your split PRs and I'll be happy to take a look.",
        "createdAt" : "2021-07-08T18:31:18Z",
        "updatedAt" : "2021-07-08T18:31:23Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      }
    ],
    "commit" : "61cdaab5057da929d0eea59caa87cd272c235c17",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +299,303 @@      .intConf\n      .checkValue(value => value > 0, \"Maximum number of pending pods should be a positive integer\")\n      .createWithDefault(150)\n\n  val KUBERNETES_ALLOCATION_BATCH_DELAY ="
  },
  {
    "id" : "0ef9656a-bdb0-463e-85b8-9eb16bab8681",
    "prId" : 31790,
    "prUrl" : "https://github.com/apache/spark/pull/31790#pullrequestreview-693377779",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7ace2543-c858-4c4a-98a4-b7fa04828dc5",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "`alloction` -> `allocation`?",
        "createdAt" : "2021-06-27T05:04:14Z",
        "updatedAt" : "2021-06-27T05:04:15Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "61cdaab5057da929d0eea59caa87cd272c235c17",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +295,299 @@  val KUBERNETES_MAX_PENDING_PODS =\n    ConfigBuilder(\"spark.kubernetes.allocation.max.pendingPods\")\n      .doc(\"Maximum number of pending pods allowed during executor alloction for this application.\")\n      .version(\"3.2.0\")\n      .intConf"
  },
  {
    "id" : "e30ca67e-0ff6-48cd-9932-150e02d836c9",
    "prId" : 31790,
    "prUrl" : "https://github.com/apache/spark/pull/31790#pullrequestreview-693377845",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "291baecf-2efb-4e31-988f-65e805f7aa0f",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "This introduces a new namespace, `max`, with only one child, `pendingPods`. Do you have a plan to add more? Otherwise, we need to reduce the depth like `maxPendingPods`.",
        "createdAt" : "2021-06-27T05:05:45Z",
        "updatedAt" : "2021-06-27T05:05:45Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "61cdaab5057da929d0eea59caa87cd272c235c17",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +294,298 @@\n  val KUBERNETES_MAX_PENDING_PODS =\n    ConfigBuilder(\"spark.kubernetes.allocation.max.pendingPods\")\n      .doc(\"Maximum number of pending pods allowed during executor alloction for this application.\")\n      .version(\"3.2.0\")"
  },
  {
    "id" : "0a895110-52d9-44d2-97a1-b98300a12e0e",
    "prId" : 31513,
    "prUrl" : "https://github.com/apache/spark/pull/31513#pullrequestreview-589306968",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "401adb1a-c975-49f1-a183-834551a0e2dc",
        "parentId" : null,
        "authorId" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "body" : "This came up [in a comment of SPARK-34389](https://issues.apache.org/jira/browse/SPARK-34389?focusedCommentId=17282614&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17282614).",
        "createdAt" : "2021-02-12T09:47:54Z",
        "updatedAt" : "2021-02-25T09:06:49Z",
        "lastEditedBy" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "tags" : [
        ]
      }
    ],
    "commit" : "bb578d296e77af20b4c3a006ac0349a84630fdad",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +275,279 @@      .doc(\"Time to wait before a newly created executor POD request, which does not reached \" +\n        \"the POD pending state yet, considered timedout and will be deleted.\")\n      .version(\"3.1.0\")\n      .timeConf(TimeUnit.MILLISECONDS)\n      .checkValue(value => value > 0, \"Allocation executor timeout must be a positive time value.\")"
  },
  {
    "id" : "a1eee193-8c37-464d-bf0c-f6e47f67514e",
    "prId" : 31195,
    "prUrl" : "https://github.com/apache/spark/pull/31195#pullrequestreview-569532793",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dd524be6-cd2a-4bd9-9720-3549899df9bd",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "It seems that we need to change this to 3.0.2 in this case.",
        "createdAt" : "2021-01-15T17:09:18Z",
        "updatedAt" : "2021-01-15T17:09:18Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "661a4532-ddd5-49a5-a355-00382cfb24e2",
        "parentId" : "dd524be6-cd2a-4bd9-9720-3549899df9bd",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Let's do this later in the follow-up because we need to update to `master/branch-3.1/branch-3.0` together.",
        "createdAt" : "2021-01-15T17:12:08Z",
        "updatedAt" : "2021-01-15T17:12:08Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "4b5b8412-fcd4-42bf-b8cf-a9714f58d9d8",
        "parentId" : "dd524be6-cd2a-4bd9-9720-3549899df9bd",
        "authorId" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "body" : "Ok. \r\n\r\nWe have some other configs suffering from the safe problem, here for example:\r\nhttps://github.com/apache/spark/blob/3afa99ae6393e9a3be88c24aa764e793839eec02/resource-managers/kubernetes/core/src/main/scala/org/apache/spark/deploy/k8s/Config.scala#L412-L416\r\n",
        "createdAt" : "2021-01-15T18:51:31Z",
        "updatedAt" : "2021-01-15T18:51:32Z",
        "lastEditedBy" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "tags" : [
        ]
      }
    ],
    "commit" : "3afa99ae6393e9a3be88c24aa764e793839eec02",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +424,428 @@        \"registration time and the time of the polling. After this time the POD is considered \" +\n        \"missing from the cluster and the executor will be removed.\")\n      .version(\"3.1.1\")\n      .timeConf(TimeUnit.MILLISECONDS)\n      .checkValue(delay => delay > 0, \"delay must be a positive time value\")"
  },
  {
    "id" : "cafd8db4-94e7-425e-9ff5-87b8fd773b4f",
    "prId" : 31195,
    "prUrl" : "https://github.com/apache/spark/pull/31195#pullrequestreview-569533712",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1b7369a7-d1e0-4b58-a538-16e6c43849df",
        "parentId" : null,
        "authorId" : "8c82da5a-f351-4a37-a8a9-13809311b07b",
        "body" : "nit: remove time as it simply has to be a positive value (millis assumed, no?)",
        "createdAt" : "2021-01-15T18:18:49Z",
        "updatedAt" : "2021-01-15T18:20:05Z",
        "lastEditedBy" : "8c82da5a-f351-4a37-a8a9-13809311b07b",
        "tags" : [
        ]
      },
      {
        "id" : "d783e97e-cde7-444c-b114-32630dae5da8",
        "parentId" : "1b7369a7-d1e0-4b58-a538-16e6c43849df",
        "authorId" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "body" : "I do not think so.  Negative value is parsed and accepted as valid value, call stack:\r\n\r\nhttps://github.com/apache/spark/blob/3afa99ae6393e9a3be88c24aa764e793839eec02/core/src/main/scala/org/apache/spark/internal/config/ConfigBuilder.scala#L252-L255\r\n\r\nhttps://github.com/apache/spark/blob/3afa99ae6393e9a3be88c24aa764e793839eec02/core/src/main/scala/org/apache/spark/internal/config/ConfigBuilder.scala#L56\r\n\r\n**See the optional \"-\":**\r\n\r\nhttps://github.com/apache/spark/blob/3afa99ae6393e9a3be88c24aa764e793839eec02/common/network-common/src/main/java/org/apache/spark/network/util/JavaUtils.java#L232\r\n\r\nhttps://github.com/apache/spark/blob/3afa99ae6393e9a3be88c24aa764e793839eec02/common/network-common/src/main/java/org/apache/spark/network/util/JavaUtils.java#L237\r\n",
        "createdAt" : "2021-01-15T18:47:46Z",
        "updatedAt" : "2021-01-15T18:47:47Z",
        "lastEditedBy" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "tags" : [
        ]
      },
      {
        "id" : "d2bc9ac3-d868-4cde-b832-fe9a37030d68",
        "parentId" : "1b7369a7-d1e0-4b58-a538-16e6c43849df",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Again, we should not make such a difference which exists in only branch-3.0, @jaceklaskowski .",
        "createdAt" : "2021-01-15T18:52:55Z",
        "updatedAt" : "2021-01-15T18:52:55Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "3afa99ae6393e9a3be88c24aa764e793839eec02",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +426,430 @@      .version(\"3.1.1\")\n      .timeConf(TimeUnit.MILLISECONDS)\n      .checkValue(delay => delay > 0, \"delay must be a positive time value\")\n      .createWithDefaultString(\"30s\")\n"
  },
  {
    "id" : "160d7383-08ed-452d-9c55-9878f39dfeb7",
    "prId" : 30684,
    "prUrl" : "https://github.com/apache/spark/pull/30684#pullrequestreview-597859504",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1372a6cc-f09d-4756-bebd-4bed310f4b1a",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "For the security, shall we make this `true` by default? For the users who don't have `ca`, they can use `spark.kubernetes.trust.certificates=false` explicitly, @hddong ?",
        "createdAt" : "2020-12-31T00:52:53Z",
        "updatedAt" : "2020-12-31T00:52:53Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "0e6328d8-4210-4d86-86e4-ca6c6ca16023",
        "parentId" : "1372a6cc-f09d-4756-bebd-4bed310f4b1a",
        "authorId" : "24e25c90-3ce5-4e08-8d5c-5f5f5fbd2714",
        "body" : "> For the security, shall we make this `true` by default? For the users who don't have `ca`, they can use `spark.kubernetes.trust.certificates=false` explicitly, @hddong ?\r\n\r\n`false` means need `ca`, so default value is what you expect.",
        "createdAt" : "2021-01-19T09:58:04Z",
        "updatedAt" : "2021-01-19T09:58:05Z",
        "lastEditedBy" : "24e25c90-3ce5-4e08-8d5c-5f5f5fbd2714",
        "tags" : [
        ]
      },
      {
        "id" : "7c8f20a9-7018-49af-a9b0-0e9f527fb804",
        "parentId" : "1372a6cc-f09d-4756-bebd-4bed310f4b1a",
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "I think maybe the confusion indicates we could find a better name for the config.",
        "createdAt" : "2021-02-24T19:44:22Z",
        "updatedAt" : "2021-02-24T19:44:22Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      }
    ],
    "commit" : "14e1cac6d228ab396454bfa7603b7374c3b2f2a2",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +398,402 @@      .version(\"3.2.0\")\n      .booleanConf\n      .createWithDefault(false)\n\n  val KUBERNETES_NODE_SELECTOR_PREFIX = \"spark.kubernetes.node.selector.\""
  },
  {
    "id" : "31c66639-4a65-45e4-9ee7-c748d45746a3",
    "prId" : 30675,
    "prUrl" : "https://github.com/apache/spark/pull/30675#pullrequestreview-548688863",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2dff7d38-821a-419d-8c32-cb124b2cdd47",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Could you add a version `.version(\"3.1.0\")` here? I guess Apache 3.1.0 is the first release to have this bug fix.",
        "createdAt" : "2020-12-09T23:07:33Z",
        "updatedAt" : "2021-01-09T19:40:55Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "a98bf364b8ccdfdc5abef4b4355e61c74c9f3802",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +483,487 @@        \"list of PODs then this delta time is taken as the accepted time difference between the \" +\n        \"registration time and the time of the polling. After this time the POD is considered \" +\n        \"missing from the cluster and the executor will be removed.\")\n      .version(\"3.1.1\")\n      .timeConf(TimeUnit.MILLISECONDS)"
  },
  {
    "id" : "8183ace6-a60d-4825-86de-3feca387eec1",
    "prId" : 30675,
    "prUrl" : "https://github.com/apache/spark/pull/30675#pullrequestreview-550437874",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dd9eb87d-7fa4-4f6c-8030-9ccde293f58f",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Is there a reason why we choose `30s`?",
        "createdAt" : "2020-12-09T23:15:19Z",
        "updatedAt" : "2021-01-09T19:40:55Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "657877ef-f835-4487-8529-5883789c54ff",
        "parentId" : "dd9eb87d-7fa4-4f6c-8030-9ccde293f58f",
        "authorId" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "body" : "As one poll is also 30s this seemed to me a reasonable value (so we just skip one poll time with the reaction). \r\nSo this way this is a very safe setting to avoid stopping of executors by mistake.",
        "createdAt" : "2020-12-10T15:36:27Z",
        "updatedAt" : "2021-01-09T19:40:55Z",
        "lastEditedBy" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "tags" : [
        ]
      },
      {
        "id" : "ace0f50f-6951-408d-828f-da59684de015",
        "parentId" : "dd9eb87d-7fa4-4f6c-8030-9ccde293f58f",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Then, why don't we reuse `KUBERNETES_EXECUTOR_API_POLLING_INTERVAL` instead of defining a new constant, @attilapiros ? Technically, it sounds like we need to adjust this config together if we change `KUBERNETES_EXECUTOR_API_POLLING_INTERVAL`.\r\n> As one poll is also 30s this seemed to me a reasonable value (so we just skip one poll time with the reaction).\r\nSo this way this is a very safe setting to avoid stopping of executors by mistake.",
        "createdAt" : "2020-12-10T16:45:50Z",
        "updatedAt" : "2021-01-09T19:40:55Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "427429ba-77f5-4a5e-9aef-ea31b932c885",
        "parentId" : "dd9eb87d-7fa4-4f6c-8030-9ccde293f58f",
        "authorId" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "body" : "I think it make sense to configure them separately here I just gave an explanation what was in my mind regarding its default.",
        "createdAt" : "2020-12-10T17:29:46Z",
        "updatedAt" : "2021-01-09T19:40:55Z",
        "lastEditedBy" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "tags" : [
        ]
      },
      {
        "id" : "904e66a7-aa6f-4822-8e55-992acbd9359f",
        "parentId" : "dd9eb87d-7fa4-4f6c-8030-9ccde293f58f",
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "I think you're right, having this be configurable makes sense. In my own work I've noticed different behavior between even different versions of minikube.",
        "createdAt" : "2020-12-11T18:33:05Z",
        "updatedAt" : "2021-01-09T19:40:55Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      }
    ],
    "commit" : "a98bf364b8ccdfdc5abef4b4355e61c74c9f3802",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +487,491 @@      .timeConf(TimeUnit.MILLISECONDS)\n      .checkValue(delay => delay > 0, \"delay must be a positive time value\")\n      .createWithDefaultString(\"30s\")\n\n  val KUBERNETES_DRIVER_LABEL_PREFIX = \"spark.kubernetes.driver.label.\""
  },
  {
    "id" : "8765a7a8-9783-425a-8b26-d62ebc09f6db",
    "prId" : 30472,
    "prUrl" : "https://github.com/apache/spark/pull/30472#pullrequestreview-544971971",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "13adcc42-5421-4de9-8d75-4d3327d289bb",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "This will probably be for 3.2.0, note",
        "createdAt" : "2020-12-04T13:48:05Z",
        "updatedAt" : "2021-01-06T05:10:00Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      }
    ],
    "commit" : "a42f82d40337a3b171196e6a97b9f76c8977a08b",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +104,108 @@      .doc(\"Max size limit for a config map. This is configurable as per\" +\n        \" https://etcd.io/docs/v3.4.0/dev-guide/limit/ on k8s server end.\")\n      .version(\"3.1.0\")\n      .longConf\n      .createWithDefault(1572864) // 1.5 MiB"
  }
]