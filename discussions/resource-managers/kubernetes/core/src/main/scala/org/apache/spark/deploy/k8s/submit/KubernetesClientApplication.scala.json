[
  {
    "id" : "1ffdf6e6-cae4-4f25-bb09-c7a3cb89cfc7",
    "prId" : 30283,
    "prUrl" : "https://github.com/apache/spark/pull/30283#pullrequestreview-530765011",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "80ae5d8a-37c9-4809-82c9-702ad5afe1d9",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Let's remove this empty line like the other branch.",
        "createdAt" : "2020-11-15T04:03:16Z",
        "updatedAt" : "2020-11-20T01:49:22Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "1c64c6cbdfd392be490f031c4599d786d831b9c2",
    "line" : 64,
    "diffHunk" : "@@ -1,1 +158,162 @@        // Reset resource to old before we start the watch, this is important for race conditions\n        watcher.reset()\n\n        watch = podWithName.watch(watcher)\n"
  },
  {
    "id" : "0f6fd306-feac-4e09-bf09-d42e281e026b",
    "prId" : 30283,
    "prUrl" : "https://github.com/apache/spark/pull/30283#pullrequestreview-534998124",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "19795b99-60b3-4ad0-9526-0d50cfc17ac1",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Shall we add the following comments like the other branches?\r\n```\r\n// Send the latest pod state we know to the watcher to make sure we didn't miss anything\r\n```",
        "createdAt" : "2020-11-15T04:03:49Z",
        "updatedAt" : "2020-11-20T01:49:22Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "c47a5d3a-20d9-4cb0-963a-79cf1cca4f8a",
        "parentId" : "19795b99-60b3-4ad0-9526-0d50cfc17ac1",
        "authorId" : "616a44bb-2bcb-45fb-8f40-13f498f69117",
        "body" : "Done",
        "createdAt" : "2020-11-20T00:58:37Z",
        "updatedAt" : "2020-11-20T01:49:22Z",
        "lastEditedBy" : "616a44bb-2bcb-45fb-8f40-13f498f69117",
        "tags" : [
        ]
      }
    ],
    "commit" : "1c64c6cbdfd392be490f031c4599d786d831b9c2",
    "line" : 66,
    "diffHunk" : "@@ -1,1 +160,164 @@\n        watch = podWithName.watch(watcher)\n\n        // Send the latest pod state we know to the watcher to make sure we didn't miss anything\n        watcher.eventReceived(Action.MODIFIED, podWithName.get())"
  },
  {
    "id" : "67b84007-afc5-445e-a456-9dad99028eb9",
    "prId" : 30283,
    "prUrl" : "https://github.com/apache/spark/pull/30283#pullrequestreview-534998164",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e7bfe128-6a54-425a-b4a5-fa13c02be3b8",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Please add the following comment like the other branches.\r\n```\r\n// Break the while loop if the pod is completed or we don't want to wait\r\n```",
        "createdAt" : "2020-11-15T04:04:13Z",
        "updatedAt" : "2020-11-20T01:49:22Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "e974532e-81df-4667-9521-9f2060ef60b9",
        "parentId" : "e7bfe128-6a54-425a-b4a5-fa13c02be3b8",
        "authorId" : "616a44bb-2bcb-45fb-8f40-13f498f69117",
        "body" : "Done",
        "createdAt" : "2020-11-20T00:58:45Z",
        "updatedAt" : "2020-11-20T01:49:22Z",
        "lastEditedBy" : "616a44bb-2bcb-45fb-8f40-13f498f69117",
        "tags" : [
        ]
      }
    ],
    "commit" : "1c64c6cbdfd392be490f031c4599d786d831b9c2",
    "line" : 69,
    "diffHunk" : "@@ -1,1 +163,167 @@        // Send the latest pod state we know to the watcher to make sure we didn't miss anything\n        watcher.eventReceived(Action.MODIFIED, podWithName.get())\n\n        // Break the while loop if the pod is completed or we don't want to wait\n        if(watcher.watchOrStop(sId)) {"
  },
  {
    "id" : "100623e2-a0a4-4f9d-8625-fcd484e0003e",
    "prId" : 30283,
    "prUrl" : "https://github.com/apache/spark/pull/30283#pullrequestreview-537785665",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "454bf146-eccf-4dd1-8a94-c48847fb5ee3",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "~Please revert this change. This is inconsistent with Apache Spark 3.1 and 3.0.~",
        "createdAt" : "2020-11-24T18:16:56Z",
        "updatedAt" : "2020-11-24T18:20:10Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "1c64c6cbdfd392be490f031c4599d786d831b9c2",
    "line" : 85,
    "diffHunk" : "@@ -1,1 +245,249 @@    val watcher = new LoggingPodStatusWatcherImpl(kubernetesAppId,\n      loggingInterval,\n      waitForAppCompletion)\n\n    Utils.tryWithResource(SparkKubernetesClientFactory.createKubernetesClient("
  },
  {
    "id" : "a798645a-19e3-41d6-bc0c-0a679f3174a3",
    "prId" : 27520,
    "prUrl" : "https://github.com/apache/spark/pull/27520#pullrequestreview-360117814",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5e8bbfd2-7262-4f1e-8bfb-ab55b3e695bf",
        "parentId" : null,
        "authorId" : "0f164c82-9c74-4ede-90f3-81ed401c0724",
        "body" : "This only adds the `OwnerReference` to the resource metadata to the local copies of the resources in memory, without updating the resources to the API server.",
        "createdAt" : "2020-02-10T19:29:57Z",
        "updatedAt" : "2020-02-10T19:29:57Z",
        "lastEditedBy" : "0f164c82-9c74-4ede-90f3-81ed401c0724",
        "tags" : [
        ]
      },
      {
        "id" : "fd79bf01-74cf-4327-9ac0-6c81417ccf7b",
        "parentId" : "5e8bbfd2-7262-4f1e-8bfb-ab55b3e695bf",
        "authorId" : "79d368bd-8aec-43ce-bcd3-764c21bb93d5",
        "body" : "Hi Yinan Li, thanks a lot for taking the look here. You are right here. But, I was wondering, can I do something to fix it. For example, if I do not create the driver pod before creating resources, the owner reference is not properly set up and if I do the other way, optional mount does not work(this issue).  ",
        "createdAt" : "2020-02-11T10:02:05Z",
        "updatedAt" : "2020-02-11T10:02:05Z",
        "lastEditedBy" : "79d368bd-8aec-43ce-bcd3-764c21bb93d5",
        "tags" : [
        ]
      },
      {
        "id" : "8907fb23-96f6-4192-84c6-841eb1e61acf",
        "parentId" : "5e8bbfd2-7262-4f1e-8bfb-ab55b3e695bf",
        "authorId" : "0f164c82-9c74-4ede-90f3-81ed401c0724",
        "body" : "Basically you will need to update the resources against the API server after the driver pod gets created. However, there's a potential risk here: if the creation of the driver pod failed for whatever reasons, the ownerRefs won't be added so garbage collection won't kick in and consequently the resources won't be properly cleaned up.",
        "createdAt" : "2020-02-11T20:37:09Z",
        "updatedAt" : "2020-02-11T22:44:17Z",
        "lastEditedBy" : "0f164c82-9c74-4ede-90f3-81ed401c0724",
        "tags" : [
        ]
      },
      {
        "id" : "11af1663-feb2-4b23-b928-92e538c86047",
        "parentId" : "5e8bbfd2-7262-4f1e-8bfb-ab55b3e695bf",
        "authorId" : "79d368bd-8aec-43ce-bcd3-764c21bb93d5",
        "body" : "One way to avoid that risk is to have a [job](https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/) and let the job own all the resources including the pod. What do you think?",
        "createdAt" : "2020-02-12T08:07:43Z",
        "updatedAt" : "2020-02-12T08:07:44Z",
        "lastEditedBy" : "79d368bd-8aec-43ce-bcd3-764c21bb93d5",
        "tags" : [
        ]
      },
      {
        "id" : "e57b0ab6-01f3-406a-bee9-196ad329eb79",
        "parentId" : "5e8bbfd2-7262-4f1e-8bfb-ab55b3e695bf",
        "authorId" : "0f164c82-9c74-4ede-90f3-81ed401c0724",
        "body" : "The idea of using a Job to run the driver has been rejected long time ago.",
        "createdAt" : "2020-02-12T16:27:27Z",
        "updatedAt" : "2020-02-12T16:27:27Z",
        "lastEditedBy" : "0f164c82-9c74-4ede-90f3-81ed401c0724",
        "tags" : [
        ]
      },
      {
        "id" : "289a1511-5d95-4f89-965e-522e44fd2352",
        "parentId" : "5e8bbfd2-7262-4f1e-8bfb-ab55b3e695bf",
        "authorId" : "79d368bd-8aec-43ce-bcd3-764c21bb93d5",
        "body" : "@liyinan926 Thanks for helping me think through this, so far whatever solution I could think, I have no way to solve this problem without introducing another problem or risks. I will keep thinking, and if you get any hints, please help me with it. In the meantime, I am closing this PR.",
        "createdAt" : "2020-02-18T07:33:09Z",
        "updatedAt" : "2020-02-18T07:33:10Z",
        "lastEditedBy" : "79d368bd-8aec-43ce-bcd3-764c21bb93d5",
        "tags" : [
        ]
      }
    ],
    "commit" : "514caddf6e022842c1a052c214d4bc78ed606e3d",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +134,138 @@        kubernetesClient.resourceList(otherKubernetesResources: _*).createOrReplace()\n        createdDriverPod = Some(kubernetesClient.pods().create(resolvedDriverPod))\n        addDriverOwnerReference(createdDriverPod.get, otherKubernetesResources)\n      } catch {\n        case NonFatal(e) =>"
  }
]