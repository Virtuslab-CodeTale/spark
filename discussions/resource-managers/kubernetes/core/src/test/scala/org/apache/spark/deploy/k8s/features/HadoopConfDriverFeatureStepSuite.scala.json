[
  {
    "id" : "64ee5fbe-a9fb-4673-8dcb-dedcc982377f",
    "prId" : 25609,
    "prUrl" : "https://github.com/apache/spark/pull/25609#pullrequestreview-300684575",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d9794123-f2bd-4493-9207-e2dbf728fc34",
        "parentId" : null,
        "authorId" : "63281e91-e961-4e6e-b0bb-6855587910d1",
        "body" : "minor: remove space",
        "createdAt" : "2019-10-11T13:28:43Z",
        "updatedAt" : "2019-10-12T01:59:38Z",
        "lastEditedBy" : "63281e91-e961-4e6e-b0bb-6855587910d1",
        "tags" : [
        ]
      }
    ],
    "commit" : "7f2c9579965df56285362363ec4d6e2844a11d04",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +69,73 @@    val sparkConf = new SparkConfWithEnv(Map(ENV_HADOOP_CONF_DIR -> confDir.getAbsolutePath()))\n      .set(Config.KUBERNETES_HADOOP_CONF_CONFIG_MAP, \"testConfigMap\")\n    val conf = KubernetesTestConf.createDriverConf(sparkConf = sparkConf)\n\n    val step = new HadoopConfDriverFeatureStep(conf)"
  }
]