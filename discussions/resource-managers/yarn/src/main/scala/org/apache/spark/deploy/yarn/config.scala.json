[
  {
    "id" : "144d81cf-0da6-4b77-a7e3-92bb2e1c163f",
    "prId" : 30282,
    "prUrl" : "https://github.com/apache/spark/pull/30282#pullrequestreview-525876156",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c2e13ae1-12eb-4cb4-a4fa-0237c1a6bdab",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "You can provide zip files in pyFiles or via `spark.submit.pyFiles` configuration.",
        "createdAt" : "2020-11-08T11:39:47Z",
        "updatedAt" : "2020-11-08T11:39:47Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "5a1a31cf-298b-432c-b109-aced3fe7e991",
        "parentId" : "c2e13ae1-12eb-4cb4-a4fa-0237c1a6bdab",
        "authorId" : "cf8c9534-0cf3-4aad-8ead-54c363cfa86e",
        "body" : "I tried to use --py-files, but it has path and resources like below:\r\n```\r\nPYTHONPATH -> {{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-0.10.7-src.zip<CPS>{{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-0.10.9-src.zip\r\n\r\nresources:\r\n    __spark_conf__ -> resource { scheme: \"hdfs\" host: \"MTPrime-CO4-fed\" port: -1 file: \"/user/zhonzh/.sparkStaging/application_1604622164128_7216/__spark_conf__.zip\" } size: 536359 timestamp: 1604858318432 type: ARCHIVE visibility: PRIVATE\r\n    pyspark.zip -> resource { scheme: \"hdfs\" host: \"MTPrime-CO4-fed\" port: -1 file: \"/user/zhonzh/.sparkStaging/application_1604622164128_7216/pyspark.zip\" } size: 595809 timestamp: 1604858311600 type: FILE visibility: PUBLIC\r\n    py4j-0.10.9-src.zip -> resource { scheme: \"hdfs\" host: \"MTPrime-CO4-fed\" port: -1 file: \"/user/zhonzh/.sparkStaging/application_1604622164128_7216/py4j-0.10.9-src.zip\" } size: 41587 timestamp: 1604858316398 type: FILE visibility: PUBLIC\r\n    __spark_libs__ -> resource { scheme: \"hdfs\" host: \"MTPrime-CO4-fed\" port: -1 file: \"/user/zhonzh/.sparkStaging/application_1604622164128_7216/spark-3.0.1-mt-jars.zip\" } size: 197891674 timestamp: 1604858291631 type: ARCHIVE visibility: PUBLIC\r\n    py4j-0.10.7-src.zip -> resource { scheme: \"hdfs\" host: \"MTPrime-CO4-fed\" port: -1 file: \"/user/zhonzh/.sparkStaging/application_1604622164128_7216/py4j-0.10.7-src.zip\" } size: 42437 timestamp: 1604858314170 type: FILE visibility: PUBLIC\r\n```\r\n\r\nI used `--py-files \"hdfs://MTPrime-CO4-0/user/zhonzh/pyspark.zip,hdfs://MTPrime-CO4-0/user/zhonzh/py4j-0.10.9-src.zip\"`. This is from spark3 while local python lib is spark 2.4.\r\n\r\nWe have 2 issues here:\r\n\r\n1. Local pyspark.zip is added first, it take precedence. This cause passed by pyFiles not working.\r\n2. If I use same name as pyspark.zip, the upload will be skipped as both have same name.\r\n\r\nWhat's your suggestions to handle this?\r\n",
        "createdAt" : "2020-11-08T18:20:06Z",
        "updatedAt" : "2020-11-08T18:20:07Z",
        "lastEditedBy" : "cf8c9534-0cf3-4aad-8ead-54c363cfa86e",
        "tags" : [
        ]
      },
      {
        "id" : "2462abe3-6656-469d-906a-efd838925018",
        "parentId" : "c2e13ae1-12eb-4cb4-a4fa-0237c1a6bdab",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "I don't think Spark is supposed to work with other py4j and pyspark.zip. They are built-in for each release.",
        "createdAt" : "2020-11-09T01:38:17Z",
        "updatedAt" : "2020-11-09T01:38:18Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "545dab707de0138d216f812ef4eaa9925de4c573",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +132,136 @@\n  private[spark] val SPARK_PYSPARK_ARCHIVE = ConfigBuilder(\"spark.yarn.pyspark.archives\")\n    .doc(\"Location of pyspark.zip and py4j.zip.\")\n    .version(\"3.0.1\")\n    .stringConf"
  },
  {
    "id" : "7618db5c-e789-494f-a08b-fb0b67ae3518",
    "prId" : 29906,
    "prUrl" : "https://github.com/apache/spark/pull/29906#pullrequestreview-504081594",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "47a89111-12ab-422e-a0e9-01278a82fd89",
        "parentId" : null,
        "authorId" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "body" : "I wonder if `spark.yarn.exclude.excludeOnFailure.enabled` or something might be better to bring it more in line with `spark.yarn.exclude.nodes`? I don't really see why \"launch\" appears in this config name...",
        "createdAt" : "2020-10-02T23:09:30Z",
        "updatedAt" : "2020-10-28T13:50:33Z",
        "lastEditedBy" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "tags" : [
        ]
      },
      {
        "id" : "dbdeddce-fdc4-472e-995d-9ef9bf000d5f",
        "parentId" : "47a89111-12ab-422e-a0e9-01278a82fd89",
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "because its excluding due to executor launch failures. I'd prefer to leave this. ",
        "createdAt" : "2020-10-07T14:15:41Z",
        "updatedAt" : "2020-10-28T13:50:33Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      },
      {
        "id" : "c4642e1c-7929-4644-94ed-008af9f073a2",
        "parentId" : "47a89111-12ab-422e-a0e9-01278a82fd89",
        "authorId" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "body" : "Sure, makes sense.",
        "createdAt" : "2020-10-07T16:53:40Z",
        "updatedAt" : "2020-10-28T13:50:33Z",
        "lastEditedBy" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "tags" : [
        ]
      }
    ],
    "commit" : "b38dd66500cdd4a12f78cca1eeacf116f0ea5b4e",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +382,386 @@  /* YARN allocator-level excludeOnFailure related config entries. */\n  private[spark] val YARN_EXECUTOR_LAUNCH_EXCLUDE_ON_FAILURE_ENABLED =\n    ConfigBuilder(\"spark.yarn.executor.launch.excludeOnFailure.enabled\")\n      .version(\"3.1.0\")\n      .withAlternative(\"spark.yarn.blacklist.executor.launch.blacklisting.enabled\")"
  },
  {
    "id" : "b9abeead-263f-40d7-9afe-3b9b65bc6322",
    "prId" : 29906,
    "prUrl" : "https://github.com/apache/spark/pull/29906#pullrequestreview-518379773",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "475b81fa-9605-4d58-a73a-eee85ccd3874",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Shall we add it to deprecated config too?",
        "createdAt" : "2020-10-28T07:43:59Z",
        "updatedAt" : "2020-10-28T13:50:33Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "b38dd66500cdd4a12f78cca1eeacf116f0ea5b4e",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +384,388 @@    ConfigBuilder(\"spark.yarn.executor.launch.excludeOnFailure.enabled\")\n      .version(\"3.1.0\")\n      .withAlternative(\"spark.yarn.blacklist.executor.launch.blacklisting.enabled\")\n      .booleanConf\n      .createWithDefault(false)"
  }
]