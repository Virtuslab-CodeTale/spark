[
  {
    "id" : "12abee47-fc62-4cf1-b6e5-fd6bd6067148",
    "prId" : 29813,
    "prUrl" : "https://github.com/apache/spark/pull/29813#pullrequestreview-492206230",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c0638d68-532e-42d6-a5e5-183f02740c8f",
        "parentId" : null,
        "authorId" : "8504b0ee-156b-4d62-881c-7cb3c1c670f8",
        "body" : "`...` is not actually supported?",
        "createdAt" : "2020-09-20T16:06:36Z",
        "updatedAt" : "2020-09-20T18:10:13Z",
        "lastEditedBy" : "8504b0ee-156b-4d62-881c-7cb3c1c670f8",
        "tags" : [
        ]
      },
      {
        "id" : "f70168aa-681a-4b44-95ff-1d67c84265db",
        "parentId" : "c0638d68-532e-42d6-a5e5-183f02740c8f",
        "authorId" : "8504b0ee-156b-4d62-881c-7cb3c1c670f8",
        "body" : "nvm, seen below it's added to the generic",
        "createdAt" : "2020-09-20T16:08:01Z",
        "updatedAt" : "2020-09-20T18:10:13Z",
        "lastEditedBy" : "8504b0ee-156b-4d62-881c-7cb3c1c670f8",
        "tags" : [
        ]
      },
      {
        "id" : "4cb29d25-31a7-4633-98cb-d481f5ca722d",
        "parentId" : "c0638d68-532e-42d6-a5e5-183f02740c8f",
        "authorId" : "981b170c-729a-429c-b115-0350ea50b32b",
        "body" : "That's correct, but I am not sure if there is a better way of handling that.\r\n\r\nRight now we have generic as follows:\r\n\r\n```R\r\nsetGeneric(\"unionByName\", function(x, y, ...) { standardGeneric(\"unionByName\") })\r\n```\r\n\r\nâ€’ as far as I am aware this is the convention for handling optional arguments we use in SparkR.\r\n\r\nTechnically speaking we could have\r\n\r\n```R\r\nsetGeneric(\"unionByName\", function(x, y, allowMissingColumns) { standardGeneric(\"unionByName\") })\r\n```\r\n\r\nbut then we'd have to support\r\n\r\n```R\r\nsignature(x = \"SparkDataFrame\", y = \"SparkDataFrame\", allowMissingColumns = \"missing\")\r\n```\r\n\r\nand \r\n\r\n```R\r\nsignature(x = \"SparkDataFrame\", y = \"SparkDataFrame\", allowMissingColumns = \"logical\")\r\n```\r\n\r\nif I am not mistaken, and in the past I've been told that's too much.\r\n\r\nDo I miss something?",
        "createdAt" : "2020-09-20T16:24:57Z",
        "updatedAt" : "2020-09-20T18:10:13Z",
        "lastEditedBy" : "981b170c-729a-429c-b115-0350ea50b32b",
        "tags" : [
        ]
      },
      {
        "id" : "7a67d0ff-3407-44b5-b574-61e4dacf57f8",
        "parentId" : "c0638d68-532e-42d6-a5e5-183f02740c8f",
        "authorId" : "8504b0ee-156b-4d62-881c-7cb3c1c670f8",
        "body" : "The way you've done it looks natural to me",
        "createdAt" : "2020-09-20T16:34:17Z",
        "updatedAt" : "2020-09-20T18:10:13Z",
        "lastEditedBy" : "8504b0ee-156b-4d62-881c-7cb3c1c670f8",
        "tags" : [
        ]
      }
    ],
    "commit" : "059772426eab15e85f78dd3076b957800ebd0217",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +2875,2879 @@#' @param y A SparkDataFrame\n#' @param allowMissingColumns logical\n#' @param ... further arguments to be passed to or from other methods.\n#' @return A SparkDataFrame containing the result of the union.\n#' @family SparkDataFrame functions"
  },
  {
    "id" : "966b79d1-9236-4aa6-9d42-ec92b6a04c3d",
    "prId" : 29252,
    "prUrl" : "https://github.com/apache/spark/pull/29252#pullrequestreview-455438135",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a6ecc2cc-4fac-45bf-b8a0-926e18cf626d",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "This looks good.",
        "createdAt" : "2020-07-27T01:36:06Z",
        "updatedAt" : "2020-07-27T01:50:01Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "e93e0b05-ca92-4a60-8e00-8565ed83b9e8",
        "parentId" : "a6ecc2cc-4fac-45bf-b8a0-926e18cf626d",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Quick question. When was this API added? R side currently supports Arrow 0.15.1+.",
        "createdAt" : "2020-07-27T01:56:19Z",
        "updatedAt" : "2020-07-27T01:56:19Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "bf0d9a00-6988-4714-afa4-d25a39c2ca21",
        "parentId" : "a6ecc2cc-4fac-45bf-b8a0-926e18cf626d",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Jenkins has old Arrow, @HyukjinKwon , and this passed Jenkins~",
        "createdAt" : "2020-07-27T01:59:50Z",
        "updatedAt" : "2020-07-27T01:59:50Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "8628abb9-4bfe-446a-a438-6b15cb864297",
        "parentId" : "a6ecc2cc-4fac-45bf-b8a0-926e18cf626d",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Please note that the failure didn't occurred in Jenkins environment. Only GitHub Action and AppVeyor failed so far.",
        "createdAt" : "2020-07-27T02:00:24Z",
        "updatedAt" : "2020-07-27T02:00:24Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "e70dba8b-7862-433a-9ace-6f52e24f1040",
        "parentId" : "a6ecc2cc-4fac-45bf-b8a0-926e18cf626d",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Oh.. Jenkins doesn't have arrow? Let me check then.",
        "createdAt" : "2020-07-27T02:01:48Z",
        "updatedAt" : "2020-07-27T02:01:48Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "04a4df3c-0f8c-4894-ac1f-2b165a521f6f",
        "parentId" : "a6ecc2cc-4fac-45bf-b8a0-926e18cf626d",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "BTW, I believe Apache Spark 3.1 can have Arrow 1.0.0 of course, but we have also a pinning PR if we want.\r\n- https://github.com/apache/spark/pull/29251",
        "createdAt" : "2020-07-27T02:02:31Z",
        "updatedAt" : "2020-07-27T02:02:31Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "0e7d911b-8b75-4184-b018-bce5525cc7ad",
        "parentId" : "a6ecc2cc-4fac-45bf-b8a0-926e18cf626d",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Ah, Jenkins doesn't have one yet. It's true that people will likely use the latest version of Arrow R as R rather aggressively encourages people to use the latest version. I will just make a quick followup with an if-else.",
        "createdAt" : "2020-07-27T02:05:11Z",
        "updatedAt" : "2020-07-27T02:05:11Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "c735a16a-f397-477d-92c6-d6c8de609b94",
        "parentId" : "a6ecc2cc-4fac-45bf-b8a0-926e18cf626d",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "It exists in arrow_0.17.1.tar. I checked NAMESPACE~",
        "createdAt" : "2020-07-27T02:16:31Z",
        "updatedAt" : "2020-07-27T02:16:32Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "d346451b-d424-4c65-a0be-a62569263093",
        "parentId" : "a6ecc2cc-4fac-45bf-b8a0-926e18cf626d",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Ah, right, this was added since 0.17.0.",
        "createdAt" : "2020-07-27T02:16:33Z",
        "updatedAt" : "2020-07-27T02:16:33Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "412b394b-2d1d-4899-b4f2-aa0afe59cc83",
        "parentId" : "a6ecc2cc-4fac-45bf-b8a0-926e18cf626d",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Oh.. It's not 0.15. Got it.",
        "createdAt" : "2020-07-27T02:16:57Z",
        "updatedAt" : "2020-07-27T02:16:57Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "930d77af-c854-4033-9572-dd2f54d63885",
        "parentId" : "a6ecc2cc-4fac-45bf-b8a0-926e18cf626d",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "For this part, if we are not bump up our minimum, we need to have `if .. else`. Please make a follow up. Thanks, guys.",
        "createdAt" : "2020-07-27T02:17:55Z",
        "updatedAt" : "2020-07-27T02:17:55Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "64c9383b-e3c9-4033-a68a-90effa4a0979",
        "parentId" : "a6ecc2cc-4fac-45bf-b8a0-926e18cf626d",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Maybe increasing minimum Arrow version to 0.17.1?",
        "createdAt" : "2020-07-27T02:18:58Z",
        "updatedAt" : "2020-07-27T02:18:58Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "e7ea4a53-82cd-4b63-9cc8-a1336571ced0",
        "parentId" : "a6ecc2cc-4fac-45bf-b8a0-926e18cf626d",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Let me just bump up the minimal version of Arrow in SparkR at https://github.com/apache/spark/pull/29253. Should be fine since such minimal version bump-up is already documented.",
        "createdAt" : "2020-07-27T02:30:59Z",
        "updatedAt" : "2020-07-27T02:30:59Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "af2acdf226d2f92a4ef0f70993496061d09a917a",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1234,1238 @@                output <- tryCatch({\n                  doServerAuth(conn, authSecret)\n                  arrowTable <- arrow::read_ipc_stream(readRaw(conn))\n                  # Arrow drops `as_tibble` since 0.14.0, see ARROW-5190.\n                  if (exists(\"as_tibble\", envir = asNamespace(\"arrow\"))) {"
  },
  {
    "id" : "c5b0e091-cf8d-4c4b-9c3a-163b6b492d26",
    "prId" : 28387,
    "prUrl" : "https://github.com/apache/spark/pull/28387#pullrequestreview-401612610",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6b070842-804d-4105-9bd9-cbc283f0610c",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Thanks, I wonder why I missed this ..",
        "createdAt" : "2020-04-28T08:30:37Z",
        "updatedAt" : "2020-04-28T18:06:56Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "fb195db718023acab7c8f66a16363846e78485ce",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +1227,1231 @@              data.frame()\n            } else if (useArrow) {\n              if (requireNamespace(\"arrow\", quietly = TRUE)) {\n                portAuth <- callJMethod(x@sdf, \"collectAsArrowToR\")\n                port <- portAuth[[1]]"
  },
  {
    "id" : "b55bc0e9-d56d-484b-b749-3ff30292ded1",
    "prId" : 28386,
    "prUrl" : "https://github.com/apache/spark/pull/28386#pullrequestreview-532050497",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "37eb218a-6caf-4c93-876f-2b5739a8b3ae",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Sorry for an ignorant question. Why do we need `collapse = \" \"`?",
        "createdAt" : "2020-11-16T09:43:49Z",
        "updatedAt" : "2020-11-17T06:46:25Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "1b7a719a-e3fb-4e39-b05f-223df3bb3ad7",
        "parentId" : "37eb218a-6caf-4c93-876f-2b5739a8b3ae",
        "authorId" : "8504b0ee-156b-4d62-881c-7cb3c1c670f8",
        "body" : "Sorry I think I responded to this in the main conversation thread rather than here. Resolving.",
        "createdAt" : "2020-11-17T06:22:10Z",
        "updatedAt" : "2020-11-17T06:46:25Z",
        "lastEditedBy" : "8504b0ee-156b-4d62-881c-7cb3c1c670f8",
        "tags" : [
        ]
      }
    ],
    "commit" : "3aa97f369c3b3cb468a73d6bebc8b8c235094469",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +3447,3451 @@          signature(what = \"SparkDataFrame\"),\n          function(what, pos = 2L,\n                   name = paste(deparse(substitute(what), backtick = FALSE), collapse = \" \"),\n                   warn.conflicts = TRUE) {\n            args <- as.list(environment()) # capture all parameters - this must be the first line"
  },
  {
    "id" : "9cf0ecc8-e428-4aaa-ad31-2a428df9cba9",
    "prId" : 28386,
    "prUrl" : "https://github.com/apache/spark/pull/28386#pullrequestreview-532052802",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bd0e7362-bad3-4bc7-b97e-9487787e7a4c",
        "parentId" : null,
        "authorId" : "981b170c-729a-429c-b115-0350ea50b32b",
        "body" : "Could we also have some test for this one? ",
        "createdAt" : "2020-11-17T00:13:21Z",
        "updatedAt" : "2020-11-17T06:46:25Z",
        "lastEditedBy" : "981b170c-729a-429c-b115-0350ea50b32b",
        "tags" : [
        ]
      },
      {
        "id" : "ff3ae463-1eed-4997-b028-0e6cc9eead84",
        "parentId" : "bd0e7362-bad3-4bc7-b97e-9487787e7a4c",
        "authorId" : "8504b0ee-156b-4d62-881c-7cb3c1c670f8",
        "body" : "good idea; added",
        "createdAt" : "2020-11-17T06:27:45Z",
        "updatedAt" : "2020-11-17T06:46:25Z",
        "lastEditedBy" : "8504b0ee-156b-4d62-881c-7cb3c1c670f8",
        "tags" : [
        ]
      }
    ],
    "commit" : "3aa97f369c3b3cb468a73d6bebc8b8c235094469",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +3444,3448 @@#' @seealso \\link{detach}\n#' @note attach since 1.6.0\nsetMethod(\"attach\",\n          signature(what = \"SparkDataFrame\"),\n          function(what, pos = 2L,"
  },
  {
    "id" : "8bf31da7-b003-453a-a940-8fee7bf12faa",
    "prId" : 28365,
    "prUrl" : "https://github.com/apache/spark/pull/28365#pullrequestreview-400723248",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bc42956b-865e-44dd-822d-7e5f5ea72a20",
        "parentId" : null,
        "authorId" : "8504b0ee-156b-4d62-881c-7cb3c1c670f8",
        "body" : "here, `paste` was creating an extra space, now fixed",
        "createdAt" : "2020-04-27T08:15:12Z",
        "updatedAt" : "2020-05-01T07:49:43Z",
        "lastEditedBy" : "8504b0ee-156b-4d62-881c-7cb3c1c670f8",
        "tags" : [
        ]
      }
    ],
    "commit" : "02d17283dacabb04102d276d05942d6f2d442ece",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +432,436 @@                  specialtype <- specialtypeshandle(x)\n                  if (is.null(specialtype)) {\n                    stop(\"Unsupported data type: \", x)\n                  }\n                  type <- PRIMITIVE_TYPES[[specialtype]]"
  },
  {
    "id" : "b51ef55c-2e7b-4800-8f1a-9ae818a271be",
    "prId" : 28350,
    "prUrl" : "https://github.com/apache/spark/pull/28350#pullrequestreview-400603519",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f609d94c-774c-48bf-8af9-67cf1b2ba1d6",
        "parentId" : null,
        "authorId" : "8504b0ee-156b-4d62-881c-7cb3c1c670f8",
        "body" : "Even though this code in `\\dontrun{}` won't be evaluated by CRAN machines, still end users might want to copy-paste the code directly & expect it to be valid R code (this is the point of the `run.dontrun` argument for `example()`).\r\n\r\nSo I added the comment hash here in addition to the change describing `func` detailed above.",
        "createdAt" : "2020-04-26T17:57:35Z",
        "updatedAt" : "2020-04-27T06:09:10Z",
        "lastEditedBy" : "8504b0ee-156b-4d62-881c-7cb3c1c670f8",
        "tags" : [
        ]
      },
      {
        "id" : "3e7d60d1-c120-4837-8db0-728889a8c8ee",
        "parentId" : "f609d94c-774c-48bf-8af9-67cf1b2ba1d6",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Yup, I think we should comment them out.",
        "createdAt" : "2020-04-27T03:21:24Z",
        "updatedAt" : "2020-04-27T06:09:10Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "3c6c6c51bf8f5c3af9fbeaf1a4e182190bb600e6",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +1684,1688 @@#'\n#' \\dontrun{\n#' # Computes the arithmetic mean of the second column by grouping\n#' # on the first and third columns. Output the grouping values and the average.\n#'"
  },
  {
    "id" : "6f78532a-9bed-4f39-bbae-397decb454e7",
    "prId" : 28350,
    "prUrl" : "https://github.com/apache/spark/pull/28350#pullrequestreview-400609883",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6624e08a-9a17-4b17-9b27-2f694ee63c3d",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Oh, sorry, can we fix `gapplyCollect` too while we're here?",
        "createdAt" : "2020-04-27T03:42:56Z",
        "updatedAt" : "2020-04-27T06:09:10Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "a24888e7-e3f5-40fe-8fe9-55b5d990d6d2",
        "parentId" : "6624e08a-9a17-4b17-9b27-2f694ee63c3d",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Should be the same. You can reword the documentation there to point `gapply` out or just copy and paste for now",
        "createdAt" : "2020-04-27T03:43:20Z",
        "updatedAt" : "2020-04-27T06:09:10Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "db272e1e-7f55-4fdf-9f1e-bb8d328bb958",
        "parentId" : "6624e08a-9a17-4b17-9b27-2f694ee63c3d",
        "authorId" : "8504b0ee-156b-4d62-881c-7cb3c1c670f8",
        "body" : "I saw this but I wasn't sure what to do ðŸ˜… ",
        "createdAt" : "2020-04-27T03:44:00Z",
        "updatedAt" : "2020-04-27T06:09:10Z",
        "lastEditedBy" : "8504b0ee-156b-4d62-881c-7cb3c1c670f8",
        "tags" : [
        ]
      },
      {
        "id" : "0d1f785f-7922-434e-9ea6-9d6dab299d46",
        "parentId" : "6624e08a-9a17-4b17-9b27-2f694ee63c3d",
        "authorId" : "8504b0ee-156b-4d62-881c-7cb3c1c670f8",
        "body" : "Any reason not to merge the Rd for `gapplyCollect` to be in the same help as `gapply`?",
        "createdAt" : "2020-04-27T03:44:16Z",
        "updatedAt" : "2020-04-27T06:09:10Z",
        "lastEditedBy" : "8504b0ee-156b-4d62-881c-7cb3c1c670f8",
        "tags" : [
        ]
      },
      {
        "id" : "932e94f5-06b5-4448-a78e-1de71b4ab11c",
        "parentId" : "6624e08a-9a17-4b17-9b27-2f694ee63c3d",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Can be .. any good clean and consistent way is fine as long as we can clarify the differences - `gapplyCollect` is a short cut of `gapply` and `collect`; `gapplyCollect` can omit the return schema, and directly collects to the driver side. Except this, all are same.",
        "createdAt" : "2020-04-27T03:46:08Z",
        "updatedAt" : "2020-04-27T06:09:10Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "833f326c-bb18-4a8c-9662-f18f9864969d",
        "parentId" : "6624e08a-9a17-4b17-9b27-2f694ee63c3d",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "We can just conservatively keep the current duplicates with copying and pasting the current doc changes too for now. I don't mind.",
        "createdAt" : "2020-04-27T03:46:59Z",
        "updatedAt" : "2020-04-27T06:09:10Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "b2309e5e-14f7-48a6-affc-b902f041ac3e",
        "parentId" : "6624e08a-9a17-4b17-9b27-2f694ee63c3d",
        "authorId" : "8504b0ee-156b-4d62-881c-7cb3c1c670f8",
        "body" : "OK. I think merging the Rd is the right way to go, and can increase awareness too -- actually I had never heard of `gapplyCollect` before filing this PR.\r\n\r\nBut I'll have to brush up on my `roxygen2` to get there from here, will follow up in a while.",
        "createdAt" : "2020-04-27T03:47:52Z",
        "updatedAt" : "2020-04-27T06:09:10Z",
        "lastEditedBy" : "8504b0ee-156b-4d62-881c-7cb3c1c670f8",
        "tags" : [
        ]
      },
      {
        "id" : "3b6b10d6-1e1d-4bbd-8c4a-61bf4e5c36b0",
        "parentId" : "6624e08a-9a17-4b17-9b27-2f694ee63c3d",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Thanks!",
        "createdAt" : "2020-04-27T03:49:31Z",
        "updatedAt" : "2020-04-27T06:09:10Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "3c6c6c51bf8f5c3af9fbeaf1a4e182190bb600e6",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +1678,1682 @@#'\n#' The output of \\code{func} must be a \\code{data.frame} matching \\code{schema} --\n#' in particular this means the names of the output \\code{data.frame} are irrelevant\n#'\n#' @seealso \\link{gapplyCollect}"
  }
]