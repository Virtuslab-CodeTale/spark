[
  {
    "id" : "d38dbd22-dcd9-4862-a2c8-37a2380b3f2f",
    "prId" : 29855,
    "prUrl" : "https://github.com/apache/spark/pull/29855#pullrequestreview-495178838",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5689dc10-a14d-49aa-97bb-9eb20be3a750",
        "parentId" : null,
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "nit: Fix style/indentation in this class.",
        "createdAt" : "2020-09-24T06:26:37Z",
        "updatedAt" : "2020-10-13T15:54:30Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      }
    ],
    "commit" : "2c95f18d2bdf9ac373b0d5319b686a1d66c1e72b",
    "line" : 83,
    "diffHunk" : "@@ -1,1 +81,85 @@      return !errorStackTrace.contains(BLOCK_APPEND_COLLISION_DETECTED_MSG_PREFIX) &&\n        !errorStackTrace.contains(TOO_LATE_MESSAGE_SUFFIX);\n    }\n  }\n}"
  },
  {
    "id" : "57c0418f-3dfd-4d6e-af55-522206b04bda",
    "prId" : 29855,
    "prUrl" : "https://github.com/apache/spark/pull/29855#pullrequestreview-503270926",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "46b19d9b-259e-4798-bea1-dd2c99e45164",
        "parentId" : null,
        "authorId" : "bc001dd4-5224-4ca1-afdd-49d69783d7f2",
        "body" : "why not retry on ConnectException, while we usually treat the connection timeout as a transient error?",
        "createdAt" : "2020-10-06T18:09:11Z",
        "updatedAt" : "2020-10-13T15:54:30Z",
        "lastEditedBy" : "bc001dd4-5224-4ca1-afdd-49d69783d7f2",
        "tags" : [
        ]
      },
      {
        "id" : "e0ed3b4d-4157-4b3a-94a9-e4a1f7cd29d9",
        "parentId" : "46b19d9b-259e-4798-bea1-dd2c99e45164",
        "authorId" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "body" : "In our operation experience, the client usually see this exception when the shuffle service becomes unavailable and it won't come back quickly within seconds.\r\nSince push-based shuffle is best effort only, we decided to do this so we can quickly pass the shuffle service that's no longer available, instead of prolonging the push time by keeping retrying on these unavailable shuffle services which could take quite some time based on # of retries and wait time between retries.",
        "createdAt" : "2020-10-06T19:00:17Z",
        "updatedAt" : "2020-10-13T15:54:30Z",
        "lastEditedBy" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "tags" : [
        ]
      }
    ],
    "commit" : "2c95f18d2bdf9ac373b0d5319b686a1d66c1e72b",
    "line" : 71,
    "diffHunk" : "@@ -1,1 +69,73 @@    public boolean shouldRetryError(Throwable t) {\n      // If it is a connection time out or a connection closed exception, no need to retry.\n      if (t.getCause() != null && t.getCause() instanceof ConnectException) {\n        return false;\n      }"
  },
  {
    "id" : "ede216f4-aad1-4eab-b899-be5f6b81fcb1",
    "prId" : 29855,
    "prUrl" : "https://github.com/apache/spark/pull/29855#pullrequestreview-506180796",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4040d84b-e07b-487c-8175-e214f9dca967",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "nit: redundant empty line.",
        "createdAt" : "2020-10-11T14:14:19Z",
        "updatedAt" : "2020-10-13T15:54:30Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "2c95f18d2bdf9ac373b0d5319b686a1d66c1e72b",
    "line" : 67,
    "diffHunk" : "@@ -1,1 +65,69 @@    public static final String BLOCK_APPEND_COLLISION_DETECTED_MSG_PREFIX =\n      \"Couldn't find an opportunity to write block\";\n\n    @Override\n    public boolean shouldRetryError(Throwable t) {"
  },
  {
    "id" : "202183ba-aab0-4520-8f5c-f936f65cf87b",
    "prId" : 29855,
    "prUrl" : "https://github.com/apache/spark/pull/29855#pullrequestreview-506372606",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6c46fe0d-865e-4e28-94f0-8098370a49c7",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "I can see how we detect the collision on the same server for multiple attempts. But how do we prevent it when it happens on different servers?",
        "createdAt" : "2020-10-11T14:16:55Z",
        "updatedAt" : "2020-10-13T15:54:30Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "5e5fe576-87e4-4acf-853b-80671f5d65af",
        "parentId" : "6c46fe0d-865e-4e28-94f0-8098370a49c7",
        "authorId" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "body" : "I don't quite get it. Here collision refers to multiple blocks belonging to the same shuffle partition getting pushed at the same time to the same shuffle service. Since the shuffle service needs to completely append one block before handling the other, we get a collision. Right now, all blocks belonging to one shuffle partition get pushed to the same shuffle service, so there won't be collisions between different servers.\r\nEven if we potentially allow multiple shuffle services to handle one shuffle partition in the future, collision is still something that can happen on one server, not between servers.\r\n\r\nDid you mean block duplication instead, i.e., the same block getting pushed multiple times? For now, with one shuffle service always handling one shuffle partition, it can be properly handled. If we allow multiple shuffle services to handle one partition down the way, Spark driver should divide blocks based on disjoint map Id subranges so that each shuffle service will only handle a disjoint subset of blocks for a given shuffle partition.",
        "createdAt" : "2020-10-11T15:46:04Z",
        "updatedAt" : "2020-10-13T15:54:30Z",
        "lastEditedBy" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "tags" : [
        ]
      },
      {
        "id" : "96aeae9f-1f7f-4e14-9ec2-9e15c22186b3",
        "parentId" : "6c46fe0d-865e-4e28-94f0-8098370a49c7",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "> Right now, all blocks belonging to one shuffle partition get pushed to the same shuffle service, so there won't be collisions between different servers.\r\n\r\nI see. Got it.",
        "createdAt" : "2020-10-12T04:53:14Z",
        "updatedAt" : "2020-10-13T15:54:30Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "0393f8c5-f7ca-44a1-9bdd-d1f7e5937daa",
        "parentId" : "6c46fe0d-865e-4e28-94f0-8098370a49c7",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "BTW, how do you know the partition info of a certain shuffle block? Do you use the `mapId` of a shuffle block? If so, I think you should be aware of the new shuffle fetch protocol in 3.0, that we use `taskAttemptId`(which is unique among multiple task attempts) instead of `partitionId` as `mapId` by default. This might break the current assumption of preventing the collision.",
        "createdAt" : "2020-10-12T06:01:57Z",
        "updatedAt" : "2020-10-13T15:54:30Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "35ba12df-f0f7-455e-84a5-26caf63153e0",
        "parentId" : "6c46fe0d-865e-4e28-94f0-8098370a49c7",
        "authorId" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "body" : "Yes, we are aware of the distinction between mapId and mapPartitionId introduced in 3.0.\r\nWe have internally discussed the implication of this change, and it should be minimum.\r\nSPARK-32923 was created so that we can make push-based shuffle supporting indeterminate stage retries as well.",
        "createdAt" : "2020-10-12T07:50:50Z",
        "updatedAt" : "2020-10-13T15:54:30Z",
        "lastEditedBy" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "tags" : [
        ]
      }
    ],
    "commit" : "2c95f18d2bdf9ac373b0d5319b686a1d66c1e72b",
    "line" : 60,
    "diffHunk" : "@@ -1,1 +58,62 @@    /**\n     * String constant used for generating exception messages indicating the server couldn't\n     * append a block after all available attempts due to collision with other blocks belonging\n     * to the same shuffle partition, and also for later checking such exceptions on the client\n     * side. When we get a block push failure because of the block couldn't be written due to"
  },
  {
    "id" : "8ef17c55-1dc4-41fe-99a1-34c1dca084e5",
    "prId" : 29855,
    "prUrl" : "https://github.com/apache/spark/pull/29855#pullrequestreview-506415200",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "acd7f83c-65cb-4524-a41a-e77833eecf61",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "> You mean the one on line 84? It should be `&&`, since we need to check both places.\r\n\r\nIf we need to check both places, shouldn't we ensure the error message contains 2 COULD_NOT_FIND_OPPORTUNITY_MSG_PREFIX / TOO_LATE_MESSAGE_SUFFIX separately?",
        "createdAt" : "2020-10-12T05:04:13Z",
        "updatedAt" : "2020-10-13T15:54:30Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "6f33548f-2c28-4a7d-9368-67fd30b1c4a6",
        "parentId" : "acd7f83c-65cb-4524-a41a-e77833eecf61",
        "authorId" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "body" : "I meant we need to check both of the 2 strings do not exist in either of the 2 places.",
        "createdAt" : "2020-10-12T08:45:56Z",
        "updatedAt" : "2020-10-13T15:54:30Z",
        "lastEditedBy" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "tags" : [
        ]
      }
    ],
    "commit" : "2c95f18d2bdf9ac373b0d5319b686a1d66c1e72b",
    "line" : 82,
    "diffHunk" : "@@ -1,1 +80,84 @@      String errorStackTrace = Throwables.getStackTraceAsString(t);\n      return !errorStackTrace.contains(BLOCK_APPEND_COLLISION_DETECTED_MSG_PREFIX) &&\n        !errorStackTrace.contains(TOO_LATE_MESSAGE_SUFFIX);\n    }\n  }"
  }
]