[
  {
    "id" : "a992bf0d-5b3d-4d4e-9f18-3aeb1a2f650b",
    "prId" : 33116,
    "prUrl" : "https://github.com/apache/spark/pull/33116#pullrequestreview-712990853",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ea006496-3322-4218-a3f7-834b88ddc41e",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "nit: 2 idents? (same for below)",
        "createdAt" : "2021-07-22T03:54:27Z",
        "updatedAt" : "2021-07-22T03:54:28Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "7f695a8d-8f5a-4064-b263-488b4f3a344b",
        "parentId" : "ea006496-3322-4218-a3f7-834b88ddc41e",
        "authorId" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "body" : "fixed, thanks for catching that",
        "createdAt" : "2021-07-22T16:20:21Z",
        "updatedAt" : "2021-07-22T16:20:21Z",
        "lastEditedBy" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "tags" : [
        ]
      }
    ],
    "commit" : "d62dd57a1fec572209e0fa69d53a3eea8b5ffe6f",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +303,307 @@    // Time latency for open block request in ms\n    private final Timer openBlockRequestLatencyMillis =\n        new TimerWithCustomTimeUnit(TimeUnit.MILLISECONDS);\n    // Time latency for executor registration latency in ms\n    private final Timer registerExecutorRequestLatencyMillis ="
  },
  {
    "id" : "8e37f871-5816-440c-8bdb-8ffdb019cd6f",
    "prId" : 33116,
    "prUrl" : "https://github.com/apache/spark/pull/33116#pullrequestreview-712347766",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "788eddf4-1d8f-4869-9cf0-74feb0eeec6f",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "@Victsm @otterc  FYI",
        "createdAt" : "2021-07-22T03:58:08Z",
        "updatedAt" : "2021-07-22T03:58:35Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "d62dd57a1fec572209e0fa69d53a3eea8b5ffe6f",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +309,313 @@    // Time latency for processing fetch merged blocks meta request latency in ms\n    private final Timer fetchMergedBlocksMetaLatencyMillis =\n        new TimerWithCustomTimeUnit(TimeUnit.MILLISECONDS);\n    // Time latency for processing finalize shuffle merge request latency in ms\n    private final Timer finalizeShuffleMergeLatencyMillis ="
  },
  {
    "id" : "fa08f057-b5ee-4e4c-a41a-c16c79cd42ed",
    "prId" : 33034,
    "prUrl" : "https://github.com/apache/spark/pull/33034#pullrequestreview-717419322",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "68732c69-e1cc-4d63-bbac-70230913f248",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Please add a comment to describe the format of the ShuffleChunk before we do the parse below.",
        "createdAt" : "2021-07-27T02:24:05Z",
        "updatedAt" : "2021-07-27T04:43:15Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "9090953f-680c-4ea3-b0b3-a6777cc532fb",
        "parentId" : "68732c69-e1cc-4d63-bbac-70230913f248",
        "authorId" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "body" : "Addressed it with a method javadoc",
        "createdAt" : "2021-07-28T20:07:04Z",
        "updatedAt" : "2021-07-28T20:07:04Z",
        "lastEditedBy" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "tags" : [
        ]
      }
    ],
    "commit" : "4a43d1d0ccab25a5b790feaa9c74591abaeaca40",
    "line" : 102,
    "diffHunk" : "@@ -1,1 +450,454 @@        int shuffleId,\n        int shuffleMergeId) {\n      final int[] reduceIdAndChunkIds = new int[2 * blockIds.length];\n      for(int i = 0; i < blockIds.length; i++) {\n        String[] blockIdParts = blockIds[i].split(\"_\");"
  },
  {
    "id" : "9a9d924b-8d36-4b20-a5ed-1eaa2b9eaeab",
    "prId" : 32811,
    "prUrl" : "https://github.com/apache/spark/pull/32811#pullrequestreview-683580494",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "85d51a80-1c94-4787-828f-6d7372b54634",
        "parentId" : null,
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "@Ngone51 This is another case of duplication between common modules and spark core (we had seen other cases where code is getting duplicated) ... we should find a way to unify them.",
        "createdAt" : "2021-06-15T16:43:21Z",
        "updatedAt" : "2021-06-16T04:04:57Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      }
    ],
    "commit" : "e7a612dab57a47de0d671b8c28a2f271a18fb7bb",
    "line" : 42,
    "diffHunk" : "@@ -1,1 +63,67 @@    implements RpcHandler.MergedBlockMetaReqHandler {\n  private static final Logger logger = LoggerFactory.getLogger(ExternalBlockHandler.class);\n  private static final String SHUFFLE_MERGER_IDENTIFIER = \"shuffle-push-merger\";\n  private static final String SHUFFLE_BLOCK_ID = \"shuffle\";\n  private static final String SHUFFLE_CHUNK_ID = \"shuffleChunk\";"
  },
  {
    "id" : "2b1c68f1-8224-44e3-9120-8d341870bbf4",
    "prId" : 32388,
    "prUrl" : "https://github.com/apache/spark/pull/32388#pullrequestreview-693639763",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "20289250-1953-4480-8c93-81d3a5cfb9da",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Is this valid when we do `getContinuousBlocksData`? To be clear to the metric audience, could you revise the definition you are aiming?",
        "createdAt" : "2021-05-31T01:58:55Z",
        "updatedAt" : "2021-05-31T02:01:31Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "8b9fabfc-b9be-4ded-9939-cd6ed731cd91",
        "parentId" : "20289250-1953-4480-8c93-81d3a5cfb9da",
        "authorId" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "body" : "This is a great point, thanks Dongjoon!\r\n\r\nCurrently a single batch fetch will be considered as one block fetch by this metric, regardless of how many blocks are fetched in the block. For our purposes, this is what we're interested in, since a big part of what we want to understand with this is the number of random reads we're submitting.\r\n\r\nHowever I see value in breaking it out as the actual number of blocks as well. Perhaps we can have two metrics, `blockTransferRate` and `blockFetchRequestRate`. In the case of non-batch fetches they will be the same, and with batch fetches the `blockTransferRate` will be higher than the `blockFetchRequestRate`. WDYT?",
        "createdAt" : "2021-06-01T16:11:00Z",
        "updatedAt" : "2021-06-01T16:11:01Z",
        "lastEditedBy" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "tags" : [
        ]
      },
      {
        "id" : "011b788e-1dea-412a-a499-5302e03eda71",
        "parentId" : "20289250-1953-4480-8c93-81d3a5cfb9da",
        "authorId" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "body" : "On second thought, I don't like `blockFetchRequestRate` since I think `FetchRequest` sounds like it would be at the level of a `OpenBlocks`/`FetchShuffleBlocks` message vs. the individual response level.\r\n\r\nMaybe `blockTransferMessageRate`? Or `blockBufferTransferRate`?",
        "createdAt" : "2021-06-01T16:43:47Z",
        "updatedAt" : "2021-06-01T16:43:48Z",
        "lastEditedBy" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "tags" : [
        ]
      },
      {
        "id" : "b094cd54-f40c-46e3-b7c5-25d8f53b294a",
        "parentId" : "20289250-1953-4480-8c93-81d3a5cfb9da",
        "authorId" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "body" : "Pushed up a new commit with `blockTransferMessageRate` to demonstrate the idea, let me know what you think.",
        "createdAt" : "2021-06-01T16:54:31Z",
        "updatedAt" : "2021-06-01T16:54:32Z",
        "lastEditedBy" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "tags" : [
        ]
      },
      {
        "id" : "b9941a36-8363-4458-b739-52a575e55ecc",
        "parentId" : "20289250-1953-4480-8c93-81d3a5cfb9da",
        "authorId" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "body" : "@dongjoon-hyun how does the new code look to you?",
        "createdAt" : "2021-06-11T15:37:48Z",
        "updatedAt" : "2021-06-11T15:37:48Z",
        "lastEditedBy" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "tags" : [
        ]
      },
      {
        "id" : "ff44e6ca-cf9f-4b88-a3f6-f206530b782c",
        "parentId" : "20289250-1953-4480-8c93-81d3a5cfb9da",
        "authorId" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "body" : "@mridulm I would also be curious about your thoughts on the new metrics.",
        "createdAt" : "2021-06-17T20:47:12Z",
        "updatedAt" : "2021-06-17T20:47:13Z",
        "lastEditedBy" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "tags" : [
        ]
      },
      {
        "id" : "fdcd77d9-2715-479c-84ff-f64b3705bfb9",
        "parentId" : "20289250-1953-4480-8c93-81d3a5cfb9da",
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "In spark read side, we treat a single read of `ShuffleBlockBatchId` as a single block read (from metric point of view).\r\nA [recent discussion](https://github.com/apache/spark/pull/32140#discussion_r652733447) of this in push based shuffle here for context (see `ShuffleBlockBatchId` in `ShuffleBlockFetcherIterator`).\r\n\r\nGiven that, I am fine with treating a batch read as a single read - given it would be contiguous (effectively, similar to reading a 'large' block).\r\n\r\nThoughts @dongjoon-hyun, @xkrogen ?",
        "createdAt" : "2021-06-21T23:50:05Z",
        "updatedAt" : "2021-06-21T23:50:18Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      },
      {
        "id" : "ab9b7651-bf3a-4d9d-b6ef-680152c8dd94",
        "parentId" : "20289250-1953-4480-8c93-81d3a5cfb9da",
        "authorId" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "body" : "Thanks for that context @mridulm! To clarify, are you suggesting we ditch the new proposal and only maintain the old version, which would treat a batch fetch as a single block transfer?\r\n\r\nFrom the comments on #32140, it seems like @otterc was indicating that there's a future plan to add metrics on the push-based shuffle side that also break out the merged chunks in terms of number of underlying blocks. Should we do the same here (which is basically my new proposal)?",
        "createdAt" : "2021-06-22T16:05:24Z",
        "updatedAt" : "2021-06-22T16:05:25Z",
        "lastEditedBy" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "tags" : [
        ]
      },
      {
        "id" : "20ee03e0-5301-4139-a605-3c289fa10dbd",
        "parentId" : "20289250-1953-4480-8c93-81d3a5cfb9da",
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "That would be a new metric, if introduced, in read side.\r\nCurrently, what is tracked treats it as a single request - that request could be a block fetch or a single fetch for a large block or merged block read.",
        "createdAt" : "2021-06-23T01:29:33Z",
        "updatedAt" : "2021-06-23T01:29:33Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      },
      {
        "id" : "e515e793-662b-4eec-9bcb-ade997c2b29f",
        "parentId" : "20289250-1953-4480-8c93-81d3a5cfb9da",
        "authorId" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "body" : "Okay. I am pretty neutral here, happy to go either way. @dongjoon-hyun or @otterc , any thoughts?",
        "createdAt" : "2021-06-23T16:49:30Z",
        "updatedAt" : "2021-06-23T16:49:31Z",
        "lastEditedBy" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "tags" : [
        ]
      },
      {
        "id" : "dd7e5b3d-385c-4a6e-9c39-94b72849d155",
        "parentId" : "20289250-1953-4480-8c93-81d3a5cfb9da",
        "authorId" : "9953a478-bdd8-4f15-be59-f6f654ff85ae",
        "body" : "I don't have anything much to add here . Would be okay either ways.",
        "createdAt" : "2021-06-23T22:17:33Z",
        "updatedAt" : "2021-06-23T22:17:33Z",
        "lastEditedBy" : "9953a478-bdd8-4f15-be59-f6f654ff85ae",
        "tags" : [
        ]
      },
      {
        "id" : "f5464b70-a9c4-4353-851f-94b670425133",
        "parentId" : "20289250-1953-4480-8c93-81d3a5cfb9da",
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "Would definitely want to hear @dongjoon-hyun's thoughts here, given he has context !\r\nAlso, +CC @Ngone51 who is helping review the client side for push based shuffle and has looked at similar codepaths recently.",
        "createdAt" : "2021-06-24T05:06:22Z",
        "updatedAt" : "2021-06-24T05:06:22Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      },
      {
        "id" : "0e4d8e15-bb35-484b-a707-1c9f41f98972",
        "parentId" : "20289250-1953-4480-8c93-81d3a5cfb9da",
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "I am assuming there are no further suggestions to resolve here ... we can do a follow up in case there is a change in behavior required for 3.2\r\n+CC @dongjoon-hyun ",
        "createdAt" : "2021-06-28T07:34:26Z",
        "updatedAt" : "2021-06-28T07:34:26Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      }
    ],
    "commit" : "16f53dc0e88927d0a80f6d87f0311cce90d4ef9a",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +307,311 @@    // Time latency for processing finalize shuffle merge request latency in ms\n    private final Timer finalizeShuffleMergeLatencyMillis = new Timer();\n    // Block transfer rate in blocks per second\n    private final Meter blockTransferRate = new Meter();\n    // Block fetch message rate per second. When using non-batch fetches"
  },
  {
    "id" : "202f0180-88f3-4237-b03b-36ece0aca8fc",
    "prId" : 29855,
    "prUrl" : "https://github.com/apache/spark/pull/29855#pullrequestreview-506095674",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7835cbf2-12ce-441c-a8fb-6a66053e454c",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Why we need `user` here? Is it a system user or something else?",
        "createdAt" : "2020-09-24T13:13:43Z",
        "updatedAt" : "2020-10-13T15:54:30Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "1d41d2dd-9d65-468e-8fc7-efdb870801da",
        "parentId" : "7835cbf2-12ce-441c-a8fb-6a66053e454c",
        "authorId" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "body" : "The `user` is the ID for the user running the Spark app. The `appId` and `user` together indicates the unique local dir paths where merged shuffle files for executors on a given node are stored.\r\n\r\nIs your concern that this API might be too YARN specific?",
        "createdAt" : "2020-09-25T17:14:09Z",
        "updatedAt" : "2020-10-13T15:54:30Z",
        "lastEditedBy" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "tags" : [
        ]
      },
      {
        "id" : "3a477c22-f2a2-4736-95f6-bd40555cc0bb",
        "parentId" : "7835cbf2-12ce-441c-a8fb-6a66053e454c",
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "that is definitely a good question. For other external shuffle services is this enough or should it be behind another interface that different ones could specify different arguments.",
        "createdAt" : "2020-09-28T14:47:06Z",
        "updatedAt" : "2020-10-13T15:54:30Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      },
      {
        "id" : "7c50262b-b452-44d2-9656-8288cd0da16c",
        "parentId" : "7835cbf2-12ce-441c-a8fb-6a66053e454c",
        "authorId" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "body" : "It's a bit unclear at this moment, especially on that part of what's needed in different schedulers.\r\nOur current approach for determining the merged shuffle file directory path is the following:\r\n\r\n1. The implementation of MergedShuffleFileManager (RPC handler for block push requests) will be initialized with a relative directory path pattern, which is relative to the list of executor local dirs (a common concept across all schedulers).\r\n2. The actual path for storing the merged shuffle files for a given application on a given host is then decided based on the local dirs and the materialization of the relative path pattern with the appId and user ID.\r\n\r\nThe assumption is that once we know the local dirs for a given app, the remaining portion of the directory path to the merged shuffle files will be mostly the same across different applications except the app Id and the user Id portion in the path.",
        "createdAt" : "2020-09-29T21:42:03Z",
        "updatedAt" : "2020-10-13T15:54:30Z",
        "lastEditedBy" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "tags" : [
        ]
      },
      {
        "id" : "b9b10659-0297-4bd4-a86d-a2f426f569e7",
        "parentId" : "7835cbf2-12ce-441c-a8fb-6a66053e454c",
        "authorId" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "body" : "I'd prefer to resolve this comment for now, and revisit when it's more clear what the requirement for  a potentially more generic API would be.",
        "createdAt" : "2020-10-10T12:57:09Z",
        "updatedAt" : "2020-10-13T15:54:30Z",
        "lastEditedBy" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "tags" : [
        ]
      }
    ],
    "commit" : "2c95f18d2bdf9ac373b0d5319b686a1d66c1e72b",
    "line" : 140,
    "diffHunk" : "@@ -1,1 +445,449 @@\n    @Override\n    public void registerApplication(String appId, String user) {\n      // No-op. Do nothing.\n    }"
  },
  {
    "id" : "ec55c2df-5bf4-4b41-b1f8-0af7772abd7b",
    "prId" : 29855,
    "prUrl" : "https://github.com/apache/spark/pull/29855#pullrequestreview-506764912",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c8bf291a-8fcd-4bab-a2a6-b7ec723b79fb",
        "parentId" : null,
        "authorId" : "bc001dd4-5224-4ca1-afdd-49d69783d7f2",
        "body" : "we should also make it a NoOp?",
        "createdAt" : "2020-10-12T04:29:41Z",
        "updatedAt" : "2020-10-13T15:54:30Z",
        "lastEditedBy" : "bc001dd4-5224-4ca1-afdd-49d69783d7f2",
        "tags" : [
        ]
      },
      {
        "id" : "aea365ba-d62a-4b7e-bdb4-c12942cf43e2",
        "parentId" : "c8bf291a-8fcd-4bab-a2a6-b7ec723b79fb",
        "authorId" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "body" : "This API is right now only invoked by YarnShuffleService during YARN application shutdown sequence.\r\nMaking this a no-op is more generic in case we could potentially invoke this API from other places down the way.",
        "createdAt" : "2020-10-12T16:31:35Z",
        "updatedAt" : "2020-10-13T15:54:30Z",
        "lastEditedBy" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "tags" : [
        ]
      }
    ],
    "commit" : "2c95f18d2bdf9ac373b0d5319b686a1d66c1e72b",
    "line" : 151,
    "diffHunk" : "@@ -1,1 +456,460 @@    @Override\n    public void applicationRemoved(String appId, boolean cleanupLocalDirs) {\n      throw new UnsupportedOperationException(\"Cannot handle shuffle block merge\");\n    }\n"
  },
  {
    "id" : "c6170550-a5e5-4ae5-9b80-215a5f9b5607",
    "prId" : 29855,
    "prUrl" : "https://github.com/apache/spark/pull/29855#pullrequestreview-506381632",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "25592bf6-8996-48a8-8ca8-b225b5f9898e",
        "parentId" : null,
        "authorId" : "bc001dd4-5224-4ca1-afdd-49d69783d7f2",
        "body" : "rename to `receivePushBlockStream` ?",
        "createdAt" : "2020-10-12T04:33:09Z",
        "updatedAt" : "2020-10-13T15:54:30Z",
        "lastEditedBy" : "bc001dd4-5224-4ca1-afdd-49d69783d7f2",
        "tags" : [
        ]
      },
      {
        "id" : "a06138d8-05ee-4eee-aaf9-baaeb70edd0d",
        "parentId" : "25592bf6-8996-48a8-8ca8-b225b5f9898e",
        "authorId" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "body" : "This is from the API introduced in SPARK-6237.\r\nThat API was used for transferring large RDD partition blocks (>2GB), and we reused it for transferring shuffle partition blocks.\r\nPrefer to keep this API's name generic in case there are other use cases that could reuse this as well.",
        "createdAt" : "2020-10-12T08:02:37Z",
        "updatedAt" : "2020-10-13T15:54:30Z",
        "lastEditedBy" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "tags" : [
        ]
      }
    ],
    "commit" : "2c95f18d2bdf9ac373b0d5319b686a1d66c1e72b",
    "line" : 56,
    "diffHunk" : "@@ -1,1 +112,116 @@\n  @Override\n  public StreamCallbackWithID receiveStream(\n      TransportClient client,\n      ByteBuffer messageHeader,"
  },
  {
    "id" : "3eec0bee-94e4-4ac3-b855-3ab89e2db19f",
    "prId" : 29855,
    "prUrl" : "https://github.com/apache/spark/pull/29855#pullrequestreview-506267260",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "29f78378-2543-4476-a7cd-18a31650b010",
        "parentId" : null,
        "authorId" : "bc001dd4-5224-4ca1-afdd-49d69783d7f2",
        "body" : "Should we also append the original IOException in the new RuntimeException?",
        "createdAt" : "2020-10-12T04:36:44Z",
        "updatedAt" : "2020-10-13T15:54:30Z",
        "lastEditedBy" : "bc001dd4-5224-4ca1-afdd-49d69783d7f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "2c95f18d2bdf9ac373b0d5319b686a1d66c1e72b",
    "line" : 94,
    "diffHunk" : "@@ -1,1 +203,207 @@        callback.onSuccess(statuses.toByteBuffer());\n      } catch(IOException e) {\n        throw new RuntimeException(String.format(\"Error while finalizing shuffle merge \"\n          + \"for application %s shuffle %d\", msg.appId, msg.shuffleId), e);\n      } finally {"
  }
]