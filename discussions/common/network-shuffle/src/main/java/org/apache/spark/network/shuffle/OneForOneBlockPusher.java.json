[
  {
    "id" : "abac6c62-532e-44da-9f5a-383c2f2f8797",
    "prId" : 33613,
    "prUrl" : "https://github.com/apache/spark/pull/33613#pullrequestreview-723612730",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "86b14f45-d2fc-41e1-beb3-2384772d70a8",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Shall we log the specific error for each case? Also, including whether we'd retry the block or not.",
        "createdAt" : "2021-08-05T08:41:08Z",
        "updatedAt" : "2021-08-05T08:41:08Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "5dc10294-56e6-4ba1-86dd-8ddfe40ab975",
        "parentId" : "86b14f45-d2fc-41e1-beb3-2384772d70a8",
        "authorId" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "body" : "We have the existing handling in `ErrorHandler#shouldLogError` to decide whether to log the error or not.\r\nCertain issues such as too late block push or block push collision can be more frequent, and logging at info level for every occurrence of these issues on either server side or client side could pollute the logs.",
        "createdAt" : "2021-08-05T17:19:43Z",
        "updatedAt" : "2021-08-05T17:19:43Z",
        "lastEditedBy" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "tags" : [
        ]
      }
    ],
    "commit" : "52b709356b367a8616acffec9f7f3a0eec834fce",
    "line" : 100,
    "diffHunk" : "@@ -1,1 +128,132 @@    // would immediately invoke parent listener's onBlockTransferFailure. However, the remaining\n    // blocks in the same batch would remain current and active and they won't be impacted by\n    // this exception.\n    if (PUSH_ERROR_HANDLER.shouldRetryError(e)) {\n      String[] targetBlockId = Arrays.copyOfRange(blockIds, index, index + 1);"
  },
  {
    "id" : "717175e0-6a1e-4322-baa5-1f47d8a44634",
    "prId" : 33034,
    "prUrl" : "https://github.com/apache/spark/pull/33034#pullrequestreview-715534786",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "16a9313c-900d-4845-a7e9-a2674ee31c15",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "We should exclude batched block id too.",
        "createdAt" : "2021-07-27T03:04:32Z",
        "updatedAt" : "2021-07-27T04:43:15Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "d8c55768-eefe-4866-9eec-7fb349da2e19",
        "parentId" : "16a9313c-900d-4845-a7e9-a2674ee31c15",
        "authorId" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "body" : "I didn't quite get it. This is in the `push` side right? Can you please explain a bit?",
        "createdAt" : "2021-07-27T06:29:34Z",
        "updatedAt" : "2021-07-27T06:29:34Z",
        "lastEditedBy" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "tags" : [
        ]
      },
      {
        "id" : "9e6bd6b9-ea38-4949-80cb-bba04922aa4c",
        "parentId" : "16a9313c-900d-4845-a7e9-a2674ee31c15",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "@venkata91  Ok, my bad. I misread it.",
        "createdAt" : "2021-07-27T06:32:23Z",
        "updatedAt" : "2021-07-27T06:32:23Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "4a43d1d0ccab25a5b790feaa9c74591abaeaca40",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +136,140 @@        + blockIds[i];\n      String[] blockIdParts = blockIds[i].split(\"_\");\n      if (blockIdParts.length != 5 || !blockIdParts[0].equals(SHUFFLE_PUSH_BLOCK_PREFIX)) {\n        throw new IllegalArgumentException(\n          \"Unexpected shuffle push block id format: \" + blockIds[i]);"
  },
  {
    "id" : "631ebcbf-24eb-427f-a9f5-b8cdccd08bfb",
    "prId" : 29855,
    "prUrl" : "https://github.com/apache/spark/pull/29855#pullrequestreview-509371655",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "027d70db-6ed2-4acb-a731-61509eacd370",
        "parentId" : null,
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "Instead of reusing `BlockFetchingListener`, add a new interface for push ?\r\n",
        "createdAt" : "2020-09-24T06:44:49Z",
        "updatedAt" : "2020-10-13T15:54:30Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      },
      {
        "id" : "23ca05b3-9636-4a46-8931-54ba714a99d3",
        "parentId" : "027d70db-6ed2-4acb-a731-61509eacd370",
        "authorId" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "body" : "It's going to be the exact same API. As commented in this PR, we are thinking of renaming BlockFetchingListener and RetryingBlockFetcher, both of which are reused for block fetch/push, to BlockTransferListener and RetryingBlockTransferor for more appropriate naming.\r\nThis change is not included in this PR to reduce the number of files we touch. ",
        "createdAt" : "2020-09-24T17:47:53Z",
        "updatedAt" : "2020-10-13T15:54:30Z",
        "lastEditedBy" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "tags" : [
        ]
      },
      {
        "id" : "2d757960-309b-471f-b548-39bcf676ff24",
        "parentId" : "027d70db-6ed2-4acb-a731-61509eacd370",
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "so just to clarify you are going to rename it later? (you said you were thinking about it). It is a public interface though as well so wouldn't want to do it in minor release",
        "createdAt" : "2020-09-28T14:49:16Z",
        "updatedAt" : "2020-10-13T15:54:30Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      },
      {
        "id" : "682bdc23-a9f6-4d24-82eb-696f0943381d",
        "parentId" : "027d70db-6ed2-4acb-a731-61509eacd370",
        "authorId" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "body" : "For the public interface change not going into a minor release, do you think this API change would be fine to go into 3.1.0?",
        "createdAt" : "2020-09-29T20:44:36Z",
        "updatedAt" : "2020-10-13T15:54:30Z",
        "lastEditedBy" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "tags" : [
        ]
      },
      {
        "id" : "612b05bc-dcc1-409e-a460-0242ee27ce6f",
        "parentId" : "027d70db-6ed2-4acb-a731-61509eacd370",
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "feature releases are supposed to be api compatible so it would be better to add one vs renaming if we do that.",
        "createdAt" : "2020-10-15T13:21:43Z",
        "updatedAt" : "2020-10-15T13:21:44Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      }
    ],
    "commit" : "2c95f18d2bdf9ac373b0d5319b686a1d66c1e72b",
    "line" : 53,
    "diffHunk" : "@@ -1,1 +51,55 @@      String appId,\n      String[] blockIds,\n      BlockFetchingListener listener,\n      Map<String, ManagedBuffer> buffers) {\n    this.client = client;"
  },
  {
    "id" : "8630c0d9-a47b-469c-ac7a-57da0c7f5d32",
    "prId" : 29855,
    "prUrl" : "https://github.com/apache/spark/pull/29855#pullrequestreview-507588938",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "069e85be-bbb5-4c38-87c1-2cdb4b444fd3",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Every block has a separate `BlockPushCallback`. So what's the motivation to fail the following blocks in batch? (Note I'm not aware of the detail of listerner in  `failRemainingBlocks`.)",
        "createdAt" : "2020-10-11T14:46:59Z",
        "updatedAt" : "2020-10-13T15:54:30Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "aa504311-d073-42bf-ab91-32373427f890",
        "parentId" : "069e85be-bbb5-4c38-87c1-2cdb4b444fd3",
        "authorId" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "body" : "The listener in `failRemainingBlocks` is the `RetryingBlockFetchListener`.\r\nHere, if the exception is something that will happen for every block push, i.e., blocking being too late or we have a client side connection issue, all remaining blocks will fail.\r\nBy eagerly failing all remaining blocks, it could potentially speed up processing on the client side.\r\n\r\nThis is similar to how `OneForOneBlockFetcher` handles things.\r\nThe difference is that `OneForOneBlockFetcher` always eagerly fail all remaining blocks, while `OneForOneBlockPusher` does not.",
        "createdAt" : "2020-10-11T16:16:19Z",
        "updatedAt" : "2020-10-13T15:54:30Z",
        "lastEditedBy" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "tags" : [
        ]
      },
      {
        "id" : "8a6b9c73-f43d-44ec-8405-7e1705d1823e",
        "parentId" : "069e85be-bbb5-4c38-87c1-2cdb4b444fd3",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "> Here, if the exception is something that will happen for every block push, i.e., blocking being too late or we have a client side connection issue, all remaining blocks will fail.\r\n\r\nWould it have any side effect by calling `failRemainingBlocks` for multiple times for the same block in this case?\r\n\r\nI mean, we may call `failRemainingBlocks` for multiple times like `failRemainingBlocks(Array(0, 1, ..., 4), e)`, `failRemainingBlocks(Array(1, ..., 4), e)`, ..., `failRemainingBlocks(Array(4), e)`.",
        "createdAt" : "2020-10-12T05:00:35Z",
        "updatedAt" : "2020-10-13T15:54:30Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "08432d40-f776-4052-a5a6-4d073916db8e",
        "parentId" : "069e85be-bbb5-4c38-87c1-2cdb4b444fd3",
        "authorId" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "body" : "Each time we call `failRemainingBlocks`, if the block transfer is retriable, then `RetryingBlockFetchListener` will initiate the retry.\r\nAs part of that, it will retry all remaining block transfers and also change `currentListener`, so it would ignore any callback invocation for blocks from the previous attempt.\r\nFor example, once we invoke `failRemainingBlocks(Array(1, 2, 3, 4), e)`, block 1, 2, 3, 4 will be retired if e is retriable.\r\nIf later on, `failRemainingBlocks(Array(2, 3, 4), e)` is invoked, it means the transfer of block 2 during the retry encountered an issue, and thus we need to retry transferring block 2, 3, 4 a 2nd time.\r\nEach invocation is for a unique attempt of transferring the blocks.",
        "createdAt" : "2020-10-12T07:57:37Z",
        "updatedAt" : "2020-10-13T15:54:30Z",
        "lastEditedBy" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "tags" : [
        ]
      },
      {
        "id" : "cc1c3c82-e096-435e-b480-befe940cda15",
        "parentId" : "069e85be-bbb5-4c38-87c1-2cdb4b444fd3",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "I see. Thanks for the explanation.\r\n\r\nBut what's the case for the non-retriable listener or when `e` is not retriable? Seems like it may print duplicate logs for the same block. This's acceptable if the real `onBlockFetchFailure` operation is idempotent, e.g. `outstandingBlocksIds.remove(blockId)` for the `RetryingBlockFetchListener`'s case. But it's still good if we can improve it as a followup.",
        "createdAt" : "2020-10-13T12:24:20Z",
        "updatedAt" : "2020-10-13T15:54:30Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "86ff7366-4e2b-470f-8f66-23c99a849dad",
        "parentId" : "069e85be-bbb5-4c38-87c1-2cdb4b444fd3",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "I see. Thanks for the explanation.\r\n\r\nBut what's the case for the non-retriable listener or when `e` is not retriable? Seems like it may print duplicate logs for the same block for `RetryingBlockFetchListener`'s case. This's acceptable if the real `onBlockFetchFailure` operation is idempotent, e.g. `outstandingBlocksIds.remove(blockId)`. But it's still good if we can improve it as a followup.",
        "createdAt" : "2020-10-13T12:24:22Z",
        "updatedAt" : "2020-10-13T15:54:30Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "a5072b82-508d-4d73-bc7a-9167a534919b",
        "parentId" : "069e85be-bbb5-4c38-87c1-2cdb4b444fd3",
        "authorId" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "body" : "If it's not retriable, the exception will then be surfaced to the parent listener, which will actually handle the failure.\r\nThe log will only be printed for the exceptions that are not retriable, and thus it should only print the log once per block by `RetryingBlockFetchListener`.\r\nIt will however print the log for the entire batch of blocks in the invocation of `failRemainingBlocks` with a non-retriable exception though.\r\nThis is the current behavior of Spark for block fetch failure as well.\r\n\r\nIn terms of parent listener, `RetryingBlockFetchListener` already has the mechanism in place to ensure it only surface the exception to the parent listener once per block, through its tracking of the current active listener.",
        "createdAt" : "2020-10-13T15:53:21Z",
        "updatedAt" : "2020-10-13T15:54:30Z",
        "lastEditedBy" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "tags" : [
        ]
      }
    ],
    "commit" : "2c95f18d2bdf9ac373b0d5319b686a1d66c1e72b",
    "line" : 94,
    "diffHunk" : "@@ -1,1 +92,96 @@        failRemainingBlocks(targetBlockId, e);\n      } else {\n        String[] targetBlockId = Arrays.copyOfRange(blockIds, index, blockIds.length);\n        failRemainingBlocks(targetBlockId, e);\n      }"
  }
]