[
  {
    "id" : "a0479213-b2bd-46a5-8f95-eb9a6c1ab9ff",
    "prId" : 32811,
    "prUrl" : "https://github.com/apache/spark/pull/32811#pullrequestreview-683580494",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a04f3d26-262e-4fd0-bef8-8d598b29106b",
        "parentId" : null,
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "Add a note that even though `reduceIds.length` == `chunkIds.length`, we are explicitly setting the length in interest of forward compatibility ?",
        "createdAt" : "2021-06-16T04:02:30Z",
        "updatedAt" : "2021-06-16T04:04:57Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      }
    ],
    "commit" : "e7a612dab57a47de0d671b8c28a2f271a18fb7bb",
    "line" : 101,
    "diffHunk" : "@@ -1,1 +99,103 @@    // Even though reduceIds.length == chunkIds.length, we are explicitly setting the length in the\n    // interest of forward compatibility.\n    buf.writeInt(chunkIds.length);\n    for (int[] ids: chunkIds) {\n      Encoders.IntArrays.encode(buf, ids);"
  }
]