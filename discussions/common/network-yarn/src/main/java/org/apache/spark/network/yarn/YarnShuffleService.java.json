[
  {
    "id" : "b57a5a7b-f48a-4ec6-8349-fc01fdb62184",
    "prId" : 31936,
    "prUrl" : "https://github.com/apache/spark/pull/31936#pullrequestreview-620001464",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a28209e5-b58b-4826-8bd7-26ce5fbf98be",
        "parentId" : null,
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "again add comment about with YARN 2.9+",
        "createdAt" : "2021-03-24T13:29:59Z",
        "updatedAt" : "2021-03-29T17:15:56Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      },
      {
        "id" : "e818ef45-e3ad-4a5b-b4f5-ca09351265b7",
        "parentId" : "a28209e5-b58b-4826-8bd7-26ce5fbf98be",
        "authorId" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "body" : "This will work on YARN 2.7 and older as well. Made this more explicit here.",
        "createdAt" : "2021-03-24T17:12:07Z",
        "updatedAt" : "2021-03-29T17:15:56Z",
        "lastEditedBy" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "tags" : [
        ]
      }
    ],
    "commit" : "ef880526e05b6143c31d98829d22d25cea659401",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +84,88 @@ * Hadoop {@link Configuration} passed by the YARN NodeManager. It is also possible to configure\n * the shuffle service by placing a resource named\n * {@value SHUFFLE_SERVICE_CONF_OVERLAY_RESOURCE_NAME} into the classpath, which should be an\n * XML file in the standard Hadoop Configuration resource format. Note that when the shuffle\n * service is loaded in the default manner, without configuring"
  },
  {
    "id" : "9a2c566f-68e3-4d37-8916-fa8b63d12709",
    "prId" : 31936,
    "prUrl" : "https://github.com/apache/spark/pull/31936#pullrequestreview-619994810",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a3f3475f-beab-42db-934e-36da002eb172",
        "parentId" : null,
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "for yarn 2.9+",
        "createdAt" : "2021-03-24T13:31:05Z",
        "updatedAt" : "2021-03-29T17:15:56Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      },
      {
        "id" : "7c3655bb-7828-482c-b1a3-1f7b8c203e2a",
        "parentId" : "a3f3475f-beab-42db-934e-36da002eb172",
        "authorId" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "body" : "No, all versions of YARN, as discussed above.",
        "createdAt" : "2021-03-24T17:06:16Z",
        "updatedAt" : "2021-03-29T17:15:56Z",
        "lastEditedBy" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "tags" : [
        ]
      }
    ],
    "commit" : "ef880526e05b6143c31d98829d22d25cea659401",
    "line" : 63,
    "diffHunk" : "@@ -1,1 +171,175 @@  public YarnShuffleService() {\n    // The name of the auxiliary service configured within the NodeManager\n    // (`yarn.nodemanager.aux-services`) is treated as the source-of-truth, so this one can be\n    // arbitrary. The NodeManager will log a warning if the configured name doesn't match this name,\n    // to inform operators of a potential misconfiguration, but this name is otherwise not used."
  },
  {
    "id" : "d7a2049e-571e-4e0c-8a1b-1e0521bbeb86",
    "prId" : 28416,
    "prUrl" : "https://github.com/apache/spark/pull/28416#pullrequestreview-403904218",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "24e86856-7eaf-4b79-a6dc-5afe3b41f046",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "This one-line seems to be the intended contribution. Did you face some error with `numRegisteredConnections` while adding this? I'm wondering if there is a reason to remove `numRegisteredConnections`.",
        "createdAt" : "2020-04-30T21:54:07Z",
        "updatedAt" : "2020-05-08T00:37:05Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "f9241beb4c0d369276d7da6883825c5fb6540afa",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +199,203 @@      blockHandler.getAllMetrics().getMetrics().put(\"numRegisteredConnections\",\n          shuffleServer.getRegisteredConnections());\n      blockHandler.getAllMetrics().getMetrics().putAll(shuffleServer.getAllMetrics().getMetrics());\n      YarnShuffleServiceMetrics serviceMetrics =\n          new YarnShuffleServiceMetrics(blockHandler.getAllMetrics());"
  },
  {
    "id" : "b307c51c-2a3a-44f7-a87e-9c46e4fa3ea4",
    "prId" : 28416,
    "prUrl" : "https://github.com/apache/spark/pull/28416#pullrequestreview-403960176",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "eba381ae-e243-42bd-95e9-5f81557615a1",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "If we put all metrics at line 201, do we need to have this line?",
        "createdAt" : "2020-04-30T21:59:54Z",
        "updatedAt" : "2020-05-08T00:37:05Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "48c55194-3dac-446b-8c40-9a1732763bd2",
        "parentId" : "eba381ae-e243-42bd-95e9-5f81557615a1",
        "authorId" : "334a081c-cba1-403e-ac80-30e6124077d1",
        "body" : "Line 201 only adds all metrics from `NettyMemoryMetrics`. This line adds `numRegisteredConnections` from `TransportContext` which is actually counting the number of registrations as explained above.",
        "createdAt" : "2020-05-01T00:17:52Z",
        "updatedAt" : "2020-05-08T00:37:05Z",
        "lastEditedBy" : "334a081c-cba1-403e-ac80-30e6124077d1",
        "tags" : [
        ]
      }
    ],
    "commit" : "f9241beb4c0d369276d7da6883825c5fb6540afa",
    "line" : 2,
    "diffHunk" : "@@ -1,1 +197,201 @@\n      // register metrics on the block handler into the Node Manager's metrics system.\n      blockHandler.getAllMetrics().getMetrics().put(\"numRegisteredConnections\",\n          shuffleServer.getRegisteredConnections());\n      blockHandler.getAllMetrics().getMetrics().putAll(shuffleServer.getAllMetrics().getMetrics());"
  },
  {
    "id" : "53831aa5-9ef3-445a-a579-56a6152e92b1",
    "prId" : 26000,
    "prUrl" : "https://github.com/apache/spark/pull/26000#pullrequestreview-297773086",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c1c8cc18-a00b-4d4b-aa89-17ccb917dfea",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Is this still hardcoded? Should we use configured SHUFFLE_SERVICE_NAME?",
        "createdAt" : "2019-10-02T19:53:31Z",
        "updatedAt" : "2019-10-11T14:26:44Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "7f5c71d2-3855-47b2-9053-391c9dcf2530",
        "parentId" : "c1c8cc18-a00b-4d4b-aa89-17ccb917dfea",
        "authorId" : "8a6edd00-b7b1-4996-9273-c919a5c44db3",
        "body" : "It _is_ still hardcoded. I haven't found a way to access Spark configuration from that constructor and `org.apache.hadoop.yarn.server.api.AuxiliaryService` requires the name. Do you have a suggestion of how that could be done?",
        "createdAt" : "2019-10-02T20:12:30Z",
        "updatedAt" : "2019-10-11T14:26:44Z",
        "lastEditedBy" : "8a6edd00-b7b1-4996-9273-c919a5c44db3",
        "tags" : [
        ]
      },
      {
        "id" : "6fbeedea-2180-4ad6-873a-0e95c0bc3d86",
        "parentId" : "c1c8cc18-a00b-4d4b-aa89-17ccb917dfea",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "As I commented below https://github.com/apache/spark/pull/26000#discussion_r330742783, if this is just for yarn, put it in YarnShuffleService, like  \"spark.yarn.shuffle.stopOnFailure\"?\r\n",
        "createdAt" : "2019-10-02T20:17:41Z",
        "updatedAt" : "2019-10-11T14:26:44Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "f403226f-3be1-4dd8-8efe-a75430edfec1",
        "parentId" : "c1c8cc18-a00b-4d4b-aa89-17ccb917dfea",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "It is hardcoded here. Once the shuffle service name is configured, won't they mismatch? Will it cause problem?",
        "createdAt" : "2019-10-04T15:34:47Z",
        "updatedAt" : "2019-10-11T14:26:44Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "85a0a501-e821-4ef3-b25c-8db52b920ec9",
        "parentId" : "c1c8cc18-a00b-4d4b-aa89-17ccb917dfea",
        "authorId" : "8a6edd00-b7b1-4996-9273-c919a5c44db3",
        "body" : "It *is* hardcoded *here*. HDP hardcodes another value though (`spark2_shuffle`). While vanilla Spark would keep working as is and would use the name `spark_shuffle`, the new configuration option would allow users to point Spark to non-vanilla shuffle service.\r\nThe changes to that class are done only to test that changing the name of the service and in the configuration play nicely together.",
        "createdAt" : "2019-10-04T17:58:07Z",
        "updatedAt" : "2019-10-11T14:26:44Z",
        "lastEditedBy" : "8a6edd00-b7b1-4996-9273-c919a5c44db3",
        "tags" : [
        ]
      },
      {
        "id" : "cdec9de3-b233-4cd9-ae26-c9a6b1c3b64c",
        "parentId" : "c1c8cc18-a00b-4d4b-aa89-17ccb917dfea",
        "authorId" : "8a6edd00-b7b1-4996-9273-c919a5c44db3",
        "body" : "It seems impossible to register the service with the name passed in the configuration because the configuration is passed *after* the class is instantiated.",
        "createdAt" : "2019-10-04T17:59:12Z",
        "updatedAt" : "2019-10-11T14:26:44Z",
        "lastEditedBy" : "8a6edd00-b7b1-4996-9273-c919a5c44db3",
        "tags" : [
        ]
      },
      {
        "id" : "7bca3130-91a5-41b6-bc09-9bf86acb1b6b",
        "parentId" : "c1c8cc18-a00b-4d4b-aa89-17ccb917dfea",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "I see. So this config can only be used to let Spark choose which service to connect. It cannot change the name of Shuffle Service.",
        "createdAt" : "2019-10-04T20:40:23Z",
        "updatedAt" : "2019-10-11T14:26:44Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "6d228b57-9f08-4e4a-9286-06abe52f8a50",
        "parentId" : "c1c8cc18-a00b-4d4b-aa89-17ccb917dfea",
        "authorId" : "8a6edd00-b7b1-4996-9273-c919a5c44db3",
        "body" : "Yes. I guess I could implement a workaround, which would get the config setting from the default `Configuration`, but that, at least theoretically, wouldn't guarantee that the exact configuration would be passed during service initialization.",
        "createdAt" : "2019-10-05T03:29:27Z",
        "updatedAt" : "2019-10-11T14:26:44Z",
        "lastEditedBy" : "8a6edd00-b7b1-4996-9273-c919a5c44db3",
        "tags" : [
        ]
      }
    ],
    "commit" : "60795d4edd89aeddd4a864246fae845789be6345",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +137,141 @@\n  public YarnShuffleService() {\n    this(\"spark_shuffle\");\n  }\n"
  },
  {
    "id" : "49dc8e6d-edaf-41d6-803a-a37f98da6f75",
    "prId" : 26000,
    "prUrl" : "https://github.com/apache/spark/pull/26000#pullrequestreview-328355918",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "03e8c1ce-571a-48e9-9b69-57d87084fd99",
        "parentId" : null,
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "So the name by itself isn't going to be enough.  If you really want it configurable we are going to have to have the port configurable. For instance the config name for the port spark.shuffle.service.port needs to be able to be something like spark.shuffle.service.{serviceName}.port.  Otherwise all the spark shuffle servers will try to get the same port and fail.  The only other option will be to use 0 for ephemeral but ",
        "createdAt" : "2019-10-10T19:15:57Z",
        "updatedAt" : "2019-10-11T14:26:44Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      },
      {
        "id" : "6f2ae8e0-34c3-4232-a676-aefda9157f4f",
        "parentId" : "03e8c1ce-571a-48e9-9b69-57d87084fd99",
        "authorId" : "8a6edd00-b7b1-4996-9273-c919a5c44db3",
        "body" : "The name specified here is actually useful only in tests. YARN's service instantiation logic wouldn't even pass the name of the service used in the config to instantiated service. I guess that's the main reason the names and ports are hardcoded or bound to non-namespaced configuration keys.\r\nThe way HDP overcomes that is by providing different classpaths with different implementations for different versions of the service (`spark_shuffle` for Spark 1.6.x and `spark2_shuffle` for Spark 2+). The only way I see it's possible to pass different parameters to the same implementation of the service is by providing different configs on the classpath.\r\n\r\nI will add a comment here stating that the name is actually only used for the tests, but otherwise would always be hardcoded to `spark_shuffle`.",
        "createdAt" : "2019-10-11T14:07:10Z",
        "updatedAt" : "2019-10-11T14:26:44Z",
        "lastEditedBy" : "8a6edd00-b7b1-4996-9273-c919a5c44db3",
        "tags" : [
        ]
      },
      {
        "id" : "db672faf-56e9-4d45-af93-da1fbc8842bc",
        "parentId" : "03e8c1ce-571a-48e9-9b69-57d87084fd99",
        "authorId" : "e913f9af-103d-40d4-976e-9aa8e12e7211",
        "body" : "I think there are a few things getting muddled together here -- one is how you'd support running two shuffle services, and the other is how a client could choose which shuffle service it talks to.\r\n\r\nThe client can already set the port for the shuffle server with `spark.shuffle.service.port`, it just can't set the name used in the `ExecutorRunnable`.\r\n\r\nThe other thing to add about how the names of the shuffle servers matter in yarn is that the name goes into `yarn-site.xml` as described in the \"Configuring the External Shuffle Service\" in [`running-on-yarn.md`](https://github.com/apache/spark/blame/c1a5f94973213b1cad15388f3ef8a488424c34a7/docs/running-on-yarn.md#L660).",
        "createdAt" : "2019-12-06T17:42:41Z",
        "updatedAt" : "2019-12-06T17:53:10Z",
        "lastEditedBy" : "e913f9af-103d-40d4-976e-9aa8e12e7211",
        "tags" : [
        ]
      }
    ],
    "commit" : "60795d4edd89aeddd4a864246fae845789be6345",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +146,150 @@   * When instantiated by YARN, constructor without arguments would be called.\n   */\n  protected YarnShuffleService(String serviceName) {\n    super(serviceName);\n    logger.info(\"Initializing YARN shuffle service \\\"{}\\\" for Spark\", serviceName);"
  }
]