[
  {
    "id" : "307c8a66-3024-4624-a72a-37ed8932d312",
    "prId" : 31559,
    "prUrl" : "https://github.com/apache/spark/pull/31559#pullrequestreview-590003370",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "127fd85a-3ad1-4da6-8f32-a123de3226db",
        "parentId" : null,
        "authorId" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "body" : "Using the fallback as release script can be used to build any Spark refs (see GIT_REF) where could be no Gemfile at all.  ",
        "createdAt" : "2021-02-13T23:35:22Z",
        "updatedAt" : "2021-02-18T03:15:04Z",
        "lastEditedBy" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "tags" : [
        ]
      }
    ],
    "commit" : "508039ed4d87e15272a0a34474126db39c137385",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +334,338 @@  cd docs\n  # TODO: Make configurable to add this: PRODUCTION=1\n  if [ ! -f \"Gemfile\" ]; then\n    cp \"$SELF/Gemfile\" .\n    cp \"$SELF/Gemfile.lock\" ."
  },
  {
    "id" : "b3cc55bd-3e81-43d9-8d6d-e3ee603440d2",
    "prId" : 29703,
    "prUrl" : "https://github.com/apache/spark/pull/29703#pullrequestreview-485580266",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "342960e3-452e-415b-8c5a-4dbb49230a10",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "If we happen to drop Hive 1.2 (or add other combinations of profiles in the distributions), we'll have to change this and [here](https://github.com/apache/spark/pull/29703/files#diff-87e663b6bc59c82beaf09ead1840ac4aR26-R41). I believe this could be done separately later.",
        "createdAt" : "2020-09-10T05:02:00Z",
        "updatedAt" : "2020-09-22T04:29:30Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "20491e0cdd5b1fae207cf20d8091d4c456728b39",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +280,284 @@  #   if you're changing them.\n  declare -A BINARY_PKGS_ARGS\n  BINARY_PKGS_ARGS[\"hadoop3.2\"]=\"-Phadoop-3.2 $HIVE_PROFILES\"\n  if ! is_dry_run; then\n    BINARY_PKGS_ARGS[\"without-hadoop\"]=\"-Phadoop-provided\""
  },
  {
    "id" : "c97e2281-a443-4efe-b110-84b1eff59926",
    "prId" : 25655,
    "prUrl" : "https://github.com/apache/spark/pull/25655#pullrequestreview-285227616",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "00d0680f-beaa-4727-a72a-41b62b89a1bf",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "hmm, when we build binary dist later, don't we run `build/spark-build-info` to prepare correct `spark-version-info.properties`?",
        "createdAt" : "2019-09-03T23:39:17Z",
        "updatedAt" : "2019-09-03T23:39:17Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "76157228-dbce-4ac1-b232-bf7d98f9ddfc",
        "parentId" : "00d0680f-beaa-4727-a72a-41b62b89a1bf",
        "authorId" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "body" : "If we do not need ro run `build/spark-build-info` later, how to prepare the correct `spark-version-info.properties` to show the correct information in `bin/spark-submit --version`?",
        "createdAt" : "2019-09-04T14:18:44Z",
        "updatedAt" : "2019-09-04T14:18:44Z",
        "lastEditedBy" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "tags" : [
        ]
      },
      {
        "id" : "06c42a40-7688-427d-8291-d94666f47695",
        "parentId" : "00d0680f-beaa-4727-a72a-41b62b89a1bf",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "I think it's supposed to be ran for both SBT and Maven builds:\r\n\r\n```\r\ncore/pom.xml:                  <arg value=\"${project.basedir}/../build/spark-build-info\"/>\r\nproject/SparkBuild.scala:      val buildScript = baseDirectory.value + \"/../build/spark-build-info\"\r\n```\r\n\r\nI think @viirya meant we might better consider fixing somewhere around `build/spark-build-info` script.",
        "createdAt" : "2019-09-08T02:42:57Z",
        "updatedAt" : "2019-09-08T02:42:58Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "a8fef2c5-6bf3-4888-8d50-25bea5f60d1f",
        "parentId" : "00d0680f-beaa-4727-a72a-41b62b89a1bf",
        "authorId" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "body" : "I see. `build/spark-build-info` is called from one of two builds and on docker or host.\r\n\r\nThe straightforward way seems to always keep `.git`. Another possible way may keep this information somewhere and refer to this later.",
        "createdAt" : "2019-09-08T17:53:02Z",
        "updatedAt" : "2019-09-08T17:53:03Z",
        "lastEditedBy" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "tags" : [
        ]
      }
    ],
    "commit" : "0365c0543133a16013123ea8c3d916822426f2ba",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +179,183 @@  fi\n\n  tar cvzf spark-$SPARK_VERSION.tgz --exclude spark-$SPARK_VERSION/.git spark-$SPARK_VERSION\n  echo $GPG_PASSPHRASE | $GPG --passphrase-fd 0 --armour --output spark-$SPARK_VERSION.tgz.asc \\\n    --detach-sig spark-$SPARK_VERSION.tgz"
  }
]