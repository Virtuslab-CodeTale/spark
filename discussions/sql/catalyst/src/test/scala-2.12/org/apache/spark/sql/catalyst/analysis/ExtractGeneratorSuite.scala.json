[
  {
    "id" : "44ce6d4f-e8cb-47ec-b504-d2ed618d54c9",
    "prId" : 31213,
    "prUrl" : "https://github.com/apache/spark/pull/31213#pullrequestreview-580063636",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "eba41405-3af7-4604-ae9e-4a430f6e0886",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Is it possible for end users to get stuck on this issue? If possible, could you add end-2-end tests, too?",
        "createdAt" : "2021-02-01T06:45:51Z",
        "updatedAt" : "2021-02-01T06:45:51Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "e775c8eb-8b32-41a5-974f-2c91dc1dd570",
        "parentId" : "eba41405-3af7-4604-ae9e-4a430f6e0886",
        "authorId" : "a8e23d47-3ae4-4385-848c-38a216d1bd08",
        "body" : "I hit this issue while using spark in java. The step before was an join, where I used `JavaConverters.collectionAsScalaIterable(Arrays.asList(columns)).toSeq()` as the join condition. The JavaConverters helper returns an lazy collection.\r\nI can take a look at on how to e2e test this.",
        "createdAt" : "2021-02-01T07:15:06Z",
        "updatedAt" : "2021-02-01T07:15:07Z",
        "lastEditedBy" : "a8e23d47-3ae4-4385-848c-38a216d1bd08",
        "tags" : [
        ]
      },
      {
        "id" : "3cb24064-5e30-4aab-af83-bbfd31dab609",
        "parentId" : "eba41405-3af7-4604-ae9e-4a430f6e0886",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Thanks!",
        "createdAt" : "2021-02-01T07:15:55Z",
        "updatedAt" : "2021-02-01T07:15:55Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "82ca8f528eae0ce960f26fc6fd5a10601afa3723",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +34,38 @@\n    // view is a lazy seq\n    val rel = LocalRelation(output = columns.view)\n    val plan = Project(rel.output ++ (explode :: Nil), rel)\n"
  }
]