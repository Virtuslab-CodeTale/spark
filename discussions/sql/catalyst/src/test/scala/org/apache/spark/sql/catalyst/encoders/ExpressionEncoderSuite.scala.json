[
  {
    "id" : "6d0728ce-0bb6-4ec9-989a-923b8d0ef59e",
    "prId" : 31888,
    "prUrl" : "https://github.com/apache/spark/pull/31888#pullrequestreview-619431543",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "39dad986-c186-4ada-b198-a67913b55064",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Is this the compilation error?\r\n\r\n```\r\n[info]   Cause: org.codehaus.commons.compiler.CompileException: File 'generated.java', Line 32, Column 124: failed to compile: org.codehaus.commons.compiler.CompileException: File 'generated.java', Line 32, Column 124: \"org.apache.\r\nspark.sql.catalyst.encoders.ExpressionEncoderSuite$MalformedClassObject$\" has no member type \"ExpressionEncoderSuite$MalformedClassObject$MalformedNameExample\"\r\n```",
        "createdAt" : "2021-03-22T18:28:22Z",
        "updatedAt" : "2021-03-22T18:28:22Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "3cb6796a-b375-4b23-ab48-33fdc7a5fe11",
        "parentId" : "39dad986-c186-4ada-b198-a67913b55064",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "But by moving `MalformedClassObject` out of `ExpressionEncoderSuite`, the generated code can be compiled.\r\n\r\nI'm not sure what this test wants to test actually. Am I confused or do I misunderstand it?",
        "createdAt" : "2021-03-22T18:34:56Z",
        "updatedAt" : "2021-03-22T18:34:57Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "7e12890f-dd6c-431a-99f0-0907c894cf84",
        "parentId" : "39dad986-c186-4ada-b198-a67913b55064",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "> Is this the compilation error?\r\n\r\nYea, that's the expected error. Actually, the master has same error when `useFallback = false`:\r\nhttps://github.com/apache/spark/blob/d32bb4e5ee4718741252c46c50a40810b722f12d/sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/encoders/ExpressionEncoderSuite.scala#L219\r\n\r\n```\r\n// master\r\n[info]   Cause: org.codehaus.commons.compiler.CompileException: File 'generated.java', Line 32, Column 124: failed to compile: org.codehaus.commons.compiler.CompileException: File 'generated.java', Line 32, Column 124: \"org.apache.spark.sql.catalyst.encoders.ExpressionEncoderSuite$MalformedClassObject$\" has no member type \"ExpressionEncoderSuite$MalformedClassObject$MalformedNameExample\"\r\n[info]   at org.apache.spark.sql.errors.QueryExecutionErrors$.compilerError(QueryExecutionErrors.scala:328)\r\n```\r\n\r\n> But by moving MalformedClassObject out of ExpressionEncoderSuite, the generated code can be compiled.\r\n\r\nIIUC the condition where the error happens is that `MalformedClassObject` is placed in `ExpressionEncoderSuite` as Kris said in the previous PR: https://github.com/apache/spark/pull/31709#issuecomment-791275810\r\n```\r\nActually, what's more interesting is the different rules of Java's nested classes and Scala's. Since there is no such\r\n notion of a \"companion object\" or built-in \"singleton object\" notion on the Java language level, at least not in \r\nJava 8, the Java language syntax for creating a new instance of a inner class object doesn't work well for Scala's\r\n class Foo { object Bar { class Baz {...} } } kind of nesting, i.e. even when we do use the correct \"simple name\" \r\n(e.g. MalformedNameExample), there would still be no valid Java syntax to create it (i.e. outerObj.new \r\nInnerClass(...) doesn't work when outerObj is a Scala object)\r\n```\r\ncc: @rednaxelafx ",
        "createdAt" : "2021-03-23T07:26:12Z",
        "updatedAt" : "2021-03-23T07:26:13Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "5ad9315f-2602-44b0-83be-a31173f1488d",
        "parentId" : "39dad986-c186-4ada-b198-a67913b55064",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Got it. Thanks for the reference.",
        "createdAt" : "2021-03-24T08:20:13Z",
        "updatedAt" : "2021-03-24T08:20:14Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "5152fffc7344f98d1c9c83d35f219e2855bc4cff",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +218,222 @@        boundEncoder.fromRow(row)\n      }.getCause.getMessage\n      assert(errMsg.contains(\"failed to compile: \"))\n    }\n  }"
  },
  {
    "id" : "48802d83-3d7f-44ef-a5bb-83d5d0c26965",
    "prId" : 31837,
    "prUrl" : "https://github.com/apache/spark/pull/31837#pullrequestreview-611980293",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8e2696fd-73e7-4e7f-9172-da5ccb682ad3",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Since we use `deepEquals` for `Array[Array[_]]` and `Array[_]`, the previous `case` statement is removed.",
        "createdAt" : "2021-03-15T09:28:07Z",
        "updatedAt" : "2021-03-15T09:28:07Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "32ba29227f6361706e8e2572c2c26a9a8b3b2647",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +596,600 @@        case (b1: Array[Int], b2: Array[Int]) => Arrays.equals(b1, b2)\n        case (b1: Array[_], b2: Array[_]) =>\n          Arrays.deepEquals(b1.asInstanceOf[Array[AnyRef]], b2.asInstanceOf[Array[AnyRef]])\n        case (left: Comparable[_], right: Comparable[_]) =>\n          left.asInstanceOf[Comparable[Any]].compareTo(right) == 0"
  },
  {
    "id" : "59bfaa51-0708-48af-b64c-f97253e3984d",
    "prId" : 31766,
    "prUrl" : "https://github.com/apache/spark/pull/31766#pullrequestreview-609433220",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "382f40f7-5c79-4fa5-b4ed-aaef59e0da60",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "do we know why this simply test has to use fallback test?",
        "createdAt" : "2021-03-11T05:56:00Z",
        "updatedAt" : "2021-03-11T05:56:01Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "7fbc3861-5d18-4cb1-b6fa-26feb53a76a7",
        "parentId" : "382f40f7-5c79-4fa5-b4ed-aaef59e0da60",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "I also was surprised that we have several cases instead of the new two tests.\r\nIt seems to be broken at some commits during the time because we didn't notice it due to this `CodegenInterpretedPlanTest` test framework bug.\r\nActually, I decided to focus on the test suite first and makes the recovery the beyond of the scope of this PR.\r\n\r\nWe may had better file a new JIRA aiming the recovery of those test cases one by one if possible.\r\n\r\nBTW, for this specific instance, the following was the error.\r\n```\r\n[info] - encode/decode for array of int: [I@74655d03 (interpreted path) *** FAILED *** (14 milliseconds)\r\n[info]   Exception thrown while decoding\r\n[info]   Converted: [0,1000000020,3,0,ffffff850000001f,4]\r\n[info]   Schema: value#680\r\n[info]   root\r\n[info]   -- value: array (nullable = true)\r\n[info]       |-- element: integer (containsNull = false)\r\n[info]   \r\n[info]   \r\n[info]   Encoder:\r\n[info]   class[value[0]: array<int>] (ExpressionEncoderSuite.scala:578)\r\n[info]   org.scalatest.exceptions.TestFailedException:\r\n[info]   at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:472)\r\n[info]   at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:471)\r\n[info]   at org.scalatest.funsuite.AnyFunSuite.newAssertionFailedException(AnyFunSuite.scala:1563)\r\n[info]   at org.scalatest.Assertions.fail(Assertions.scala:949)\r\n[info]   at org.scalatest.Assertions.fail$(Assertions.scala:945)\r\n[info]   at org.scalatest.funsuite.AnyFunSuite.fail(AnyFunSuite.scala:1563)\r\n[info]   at org.apache.spark.sql.catalyst.encoders.ExpressionEncoderSuite.$anonfun$encodeDecodeTest$1(ExpressionEncoderSuite.scala:578)\r\n[info]   at org.apache.spark.sql.catalyst.encoders.ExpressionEncoderSuite.verifyNotLeakingReflectionObjects(ExpressionEncoderSuite.scala:656)\r\n[info]   at org.apache.spark.sql.catalyst.encoders.ExpressionEncoderSuite.$anonfun$testAndVerifyNotLeakingReflectionObjects$2(ExpressionEncoderSuite.scala:669)\r\n[info]   at org.apache.spark.sql.catalyst.plans.CodegenInterpretedPlanTest.$anonfun$test$4(PlanTest.scala:50)\r\n[info]   at org.apache.spark.sql.catalyst.plans.SQLHelper.withSQLConf(SQLHelper.scala:54)\r\n[info]   at org.apache.spark.sql.catalyst.plans.SQLHelper.withSQLConf$(SQLHelper.scala:38)\r\n[info]   at org.apache.spark.sql.catalyst.encoders.ExpressionEncoderSuite.withSQLConf(ExpressionEncoderSuite.scala:118)\r\n[info]   at org.apache.spark.sql.catalyst.plans.CodegenInterpretedPlanTest.$anonfun$test$3(PlanTest.scala:50)\r\n[info]   at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n[info]   at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85)\r\n[info]   at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83)\r\n[info]   at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)\r\n[info]   at org.scalatest.Transformer.apply(Transformer.scala:22)\r\n[info]   at org.scalatest.Transformer.apply(Transformer.scala:20)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike$$anon$1.apply(AnyFunSuiteLike.scala:190)\r\n[info]   at org.apache.spark.SparkFunSuite.withFixture(SparkFunSuite.scala:178)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.invokeWithFixture$1(AnyFunSuiteLike.scala:188)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTest$1(AnyFunSuiteLike.scala:200)\r\n[info]   at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.runTest(AnyFunSuiteLike.scala:200)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.runTest$(AnyFunSuiteLike.scala:182)\r\n[info]   at org.apache.spark.SparkFunSuite.org$scalatest$BeforeAndAfterEach$$super$runTest(SparkFunSuite.scala:61)\r\n[info]   at org.scalatest.BeforeAndAfterEach.runTest(BeforeAndAfterEach.scala:234)\r\n[info]   at org.scalatest.BeforeAndAfterEach.runTest$(BeforeAndAfterEach.scala:227)\r\n[info]   at org.apache.spark.SparkFunSuite.runTest(SparkFunSuite.scala:61)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$runTests$1(AnyFunSuiteLike.scala:233)\r\n[info]   at org.scalatest.SuperEngine.$anonfun$runTestsInBranch$1(Engine.scala:413)\r\n[info]   at scala.collection.immutable.List.foreach(List.scala:392)\r\n[info]   at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)\r\n[info]   at org.scalatest.SuperEngine.runTestsInBranch(Engine.scala:396)\r\n[info]   at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:475)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.runTests(AnyFunSuiteLike.scala:233)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.runTests$(AnyFunSuiteLike.scala:232)\r\n[info]   at org.scalatest.funsuite.AnyFunSuite.runTests(AnyFunSuite.scala:1563)\r\n[info]   at org.scalatest.Suite.run(Suite.scala:1112)\r\n[info]   at org.scalatest.Suite.run$(Suite.scala:1094)\r\n[info]   at org.scalatest.funsuite.AnyFunSuite.org$scalatest$funsuite$AnyFunSuiteLike$$super$run(AnyFunSuite.scala:1563)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.$anonfun$run$1(AnyFunSuiteLike.scala:237)\r\n[info]   at org.scalatest.SuperEngine.runImpl(Engine.scala:535)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.run(AnyFunSuiteLike.scala:237)\r\n[info]   at org.scalatest.funsuite.AnyFunSuiteLike.run$(AnyFunSuiteLike.scala:236)\r\n[info]   at org.apache.spark.SparkFunSuite.org$scalatest$BeforeAndAfterAll$$super$run(SparkFunSuite.scala:61)\r\n[info]   at org.scalatest.BeforeAndAfterAll.liftedTree1$1(BeforeAndAfterAll.scala:213)\r\n[info]   at org.scalatest.BeforeAndAfterAll.run(BeforeAndAfterAll.scala:210)\r\n[info]   at org.scalatest.BeforeAndAfterAll.run$(BeforeAndAfterAll.scala:208)\r\n[info]   at org.apache.spark.SparkFunSuite.run(SparkFunSuite.scala:61)\r\n[info]   at org.scalatest.tools.Framework.org$scalatest$tools$Framework$$runSuite(Framework.scala:318)\r\n[info]   at org.scalatest.tools.Framework$ScalaTestTask.execute(Framework.scala:513)\r\n[info]   at sbt.ForkMain$Run.lambda$runTest$1(ForkMain.java:413)\r\n[info]   at java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n[info]   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n[info]   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n[info]   at java.lang.Thread.run(Thread.java:748)\r\n[info]   Cause: java.lang.RuntimeException: Error while decoding: java.lang.NoSuchMethodException: org.apache.spark.sql.catalyst.util.GenericArrayData.toIntArray()\r\n[info] mapobjects(lambdavariable(MapObject, IntegerType, false, -1), assertnotnull(lambdavariable(MapObject, IntegerType, false, -1)), input[0, array<int>, true], None).toIntArray\r\n[info]   at org.apache.spark.sql.catalyst.encoders.ExpressionEncoder$Deserializer.apply(ExpressionEncoder.scala:186)\r\n[info]   at org.apache.spark.sql.catalyst.encoders.ExpressionEncoderSuite.$anonfun$encodeDecodeTest$1(ExpressionEncoderSuite.scala:576)\r\n[info]   at org.apache.spark.sql.catalyst.encoders.ExpressionEncoderSuite.verifyNotLeakingReflectionObjects(ExpressionEncoderSuite.scala:656)\r\n[info]   at org.apache.spark.sql.catalyst.encoders.ExpressionEncoderSuite.$anonfun$testAndVerifyNotLeakingReflectionObjects$2(ExpressionEncoderSuite.scala:669)\r\n```",
        "createdAt" : "2021-03-11T06:20:39Z",
        "updatedAt" : "2021-03-11T06:22:16Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "6becc553-a781-4b60-b383-4516c5a9f410",
        "parentId" : "382f40f7-5c79-4fa5-b4ed-aaef59e0da60",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "This test suite fix aims to land to `master/3.1/3.0/2.4`.",
        "createdAt" : "2021-03-11T06:24:25Z",
        "updatedAt" : "2021-03-11T06:24:25Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "fa2fa0bb-f06c-4121-a954-ffc3b052595b",
        "parentId" : "382f40f7-5c79-4fa5-b4ed-aaef59e0da60",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "sounds good, let's fix these bugs one by one later.",
        "createdAt" : "2021-03-11T06:39:25Z",
        "updatedAt" : "2021-03-11T06:39:25Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "54636fce7de8368d23f7133d862ea737845954b1",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +162,166 @@    \"seq of seq of string\")\n\n  encodeDecodeTest(Array(31, -123, 4), \"array of int\", useFallback = true)\n  encodeDecodeTest(Array(\"abc\", \"xyz\"), \"array of string\")\n  encodeDecodeTest(Array(\"a\", null, \"x\"), \"array of string with null\")"
  },
  {
    "id" : "d75777e3-8500-4dbc-9084-d230c91d8b9e",
    "prId" : 31764,
    "prUrl" : "https://github.com/apache/spark/pull/31764#pullrequestreview-605979213",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3c867b6f-e8ad-4ff2-b8ce-bdaa337dd52f",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "How about leaving some comments here about why we need the fallback based on the Kris investigation? https://github.com/apache/spark/pull/31709#issuecomment-791275810",
        "createdAt" : "2021-03-08T05:46:15Z",
        "updatedAt" : "2021-03-08T05:46:15Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "ed5c3c0aa37f2e660ec7fafe8ee014716f6ddacc",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +216,220 @@      MalformedClassObject.MalformedNameExample(42),\n      \"nested Scala class should work\",\n      useFallback = true)\n  }\n"
  },
  {
    "id" : "40f6d1a7-ec2b-4d95-acfc-8f7bf39b1178",
    "prId" : 31733,
    "prUrl" : "https://github.com/apache/spark/pull/31733#pullrequestreview-604512114",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6b6ee927-4bd7-4f4b-8e4a-5ba2134f5388",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "@rednaxelafx  Ah, I've checked the minimum number of the inner classes so as to reproduce this issue, then I found that the current number is minimum; if one of the inner classes is removed, the error goes away. So, I kept the test classes as they are.",
        "createdAt" : "2021-03-04T12:32:08Z",
        "updatedAt" : "2021-03-04T14:11:47Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "a79c1d90-2326-427b-a12f-7692e1f34d1c",
        "parentId" : "6b6ee927-4bd7-4f4b-8e4a-5ba2134f5388",
        "authorId" : "3a12ce0f-9e73-4cfb-a4b4-b19368cddc2f",
        "body" : "Thank you very much! Interesting... when I was trying to repro, I kept adding nesting levels that I vaguely remember that I might have added more than necessary, but it looks like that's it already",
        "createdAt" : "2021-03-04T20:04:14Z",
        "updatedAt" : "2021-03-04T20:04:14Z",
        "lastEditedBy" : "3a12ce0f-9e73-4cfb-a4b4-b19368cddc2f",
        "tags" : [
        ]
      }
    ],
    "commit" : "b342610cc53b888a62c0520c635a8f523271c2d4",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +237,241 @@                                    object OuterLevelWithVeryVeryVeryLongClassName18 {\n                                      object OuterLevelWithVeryVeryVeryLongClassName19 {\n                                        object OuterLevelWithVeryVeryVeryLongClassName20 {\n                                          case class MalformedNameExample(x: Int)\n                                        }}}}}}}}}}}}}}}}}}}}"
  },
  {
    "id" : "fbb9bb15-5020-403c-95a3-90d503c85367",
    "prId" : 24367,
    "prUrl" : "https://github.com/apache/spark/pull/24367#pullrequestreview-228733521",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1485cc8c-1e2f-4d5d-b6f3-04039004cdc3",
        "parentId" : null,
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "I tried and the test case failed:\r\n```\r\nCan't compare maps!\r\norg.apache.avro.AvroRuntimeException: Can't compare maps!\r\n\tat org.apache.avro.generic.GenericData.compare(GenericData.java:984)\r\n\tat org.apache.avro.specific.SpecificData.compare(SpecificData.java:333)\r\n\tat org.apache.avro.generic.GenericData.compare(GenericData.java:961)\r\n\tat org.apache.avro.specific.SpecificData.compare(SpecificData.java:333)\r\n\tat org.apache.avro.generic.GenericData.compare(GenericData.java:946)\r\n\tat org.apache.avro.specific.SpecificRecordBase.compareTo(SpecificRecordBase.java:81)\r\n\tat org.apache.avro.specific.SpecificRecordBase.compareTo(SpecificRecordBase.java:30)\r\n\tat org.apache.spark.sql.catalyst.encoders.ExpressionEncoderSuite.$anonfun$encodeDecodeTest$1(ExpressionEncoderSuite.scala:442)\r\n\r\n```",
        "createdAt" : "2019-04-19T12:55:18Z",
        "updatedAt" : "2019-05-18T08:23:50Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "6f7a0f11-6227-4b06-898a-65e6393d391f",
        "parentId" : "1485cc8c-1e2f-4d5d-b6f3-04039004cdc3",
        "authorId" : "238d8924-263e-475c-84d6-504d8ececcd8",
        "body" : "The issue here is how the `input` and the `convertedBack` objects are compared\r\n\r\nif we replace the check, in line ExpressionEncoderSuite.scala:442,\r\n\r\n`left.asInstanceOf[Comparable[Any]].compareTo(right) == 0`\r\nBy\r\n`left.asInstanceOf[Comparable[Any]].equals(right) == 0`\r\n\r\nthe test for Avro encoder passes, but unfortunately other tests fail\r\n\r\nEquality of objects is tricky.\r\n\r\nThe GenericData `compare` function \r\n```\r\n  /** Comparison implementation.  When equals is true, only checks for equality,\r\n   * not for order. */\r\n  @SuppressWarnings(value=\"unchecked\")\r\n  protected int compare(Object o1, Object o2, Schema s, boolean equals) {\r\n```\r\nfails to compare Maps when the parameter `equals` is `false`\r\n\r\n\r\nI propose the following\r\n\r\nreplace ExpressionEncoderSuite:434:444 lines\r\n\r\n```\r\n      val isCorrect = (input, convertedBack) match {\r\n        case (b1: Array[Byte], b2: Array[Byte]) => Arrays.equals(b1, b2)\r\n        case (b1: Array[Int], b2: Array[Int]) => Arrays.equals(b1, b2)\r\n        case (b1: Array[Array[_]], b2: Array[Array[_]]) =>\r\n          Arrays.deepEquals(b1.asInstanceOf[Array[AnyRef]], b2.asInstanceOf[Array[AnyRef]])\r\n        case (b1: Array[_], b2: Array[_]) =>\r\n          Arrays.equals(b1.asInstanceOf[Array[AnyRef]], b2.asInstanceOf[Array[AnyRef]])\r\n        case (left: Comparable[_], right: Comparable[_]) =>\r\n          left.asInstanceOf[Comparable[Any]].compareTo(right) == 0\r\n        case _ => input == convertedBack\r\n      }\r\n```\r\n\r\nby \r\n\r\n```\r\n      val convertedBackRow = encoder.toRow(convertedBack)\r\n      val isCorrect = row == convertedBackRow\r\n```\r\n\r\nWith the proposed modification all the tests in ExpressionEncoderSuite passes\r\n\r\n~~I think this makes sense, the check should not depend on how the foreign objects implement~~ `equality`  (see next comment)",
        "createdAt" : "2019-04-19T14:22:06Z",
        "updatedAt" : "2019-05-18T08:23:50Z",
        "lastEditedBy" : "238d8924-263e-475c-84d6-504d8ececcd8",
        "tags" : [
        ]
      },
      {
        "id" : "74bc61df-5fb5-44d0-90c1-1125dfde66c4",
        "parentId" : "1485cc8c-1e2f-4d5d-b6f3-04039004cdc3",
        "authorId" : "238d8924-263e-475c-84d6-504d8ececcd8",
        "body" : "we must compare `input` and `convertedBack` ;  the equality `row==convertedBackRow` does not guarantee that the encoder is correct; indeed a buggy encoder may create a row with missing fields such that `row==convertedBackRow`  is true while `input==convertedBack` is false.\r\n\r\nFor the avro encoder test the test `input == convertedBack` is true when the encoder is correct, thus we propose the following modification:\r\n\r\n```\r\n      val isCorrect = input == convertedBack || ((input, convertedBack) match {\r\n        case (b1: Array[Byte], b2: Array[Byte]) => Arrays.equals(b1, b2)\r\n        case (b1: Array[Int], b2: Array[Int]) => Arrays.equals(b1, b2)\r\n        case (b1: Array[Array[_]], b2: Array[Array[_]]) =>\r\n          Arrays.deepEquals(b1.asInstanceOf[Array[AnyRef]], b2.asInstanceOf[Array[AnyRef]])\r\n        case (b1: Array[_], b2: Array[_]) =>\r\n          Arrays.equals(b1.asInstanceOf[Array[AnyRef]], b2.asInstanceOf[Array[AnyRef]])\r\n        case (left: Comparable[_], right: Comparable[_]) =>\r\n          left.asInstanceOf[Comparable[Any]].compareTo(right) == 0\r\n        case _ => false\r\n      })\r\n```\r\n\r\nWith this modification all the tests pass\r\n",
        "createdAt" : "2019-04-19T15:40:42Z",
        "updatedAt" : "2019-05-18T08:23:50Z",
        "lastEditedBy" : "238d8924-263e-475c-84d6-504d8ececcd8",
        "tags" : [
        ]
      }
    ],
    "commit" : "2574e3d90f4d9de2de7b4b4a55eade668f495729",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +310,314 @@  encodeDecodeTest(Option.empty[String], \"empty option of string\")\n\n  encodeDecodeTest(\n    AvroExample1.newBuilder()\n      .setMyarray(List(\"Foo\", \"Bar\").asJava)"
  },
  {
    "id" : "b98b5297-1c26-4fdc-9267-932e0978ccad",
    "prId" : 24299,
    "prUrl" : "https://github.com/apache/spark/pull/24299#pullrequestreview-225407989",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "67007ec6-ebe9-4635-a92e-a5a28135b720",
        "parentId" : null,
        "authorId" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "body" : "Thanks @bdrillard for the summary of previous work.\r\n\r\nSeems #22878 covered this scenario? Please correct me if I missing something. https://github.com/apache/spark/pull/22878/files#diff-24ca7610c9c163779104e6c797713431R327",
        "createdAt" : "2019-04-11T08:57:01Z",
        "updatedAt" : "2019-05-18T08:27:08Z",
        "lastEditedBy" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "tags" : [
        ]
      }
    ],
    "commit" : "b8653a87fb6e7d306114c840ffccdfe894bc8157",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +310,314 @@  encodeDecodeTest(Option.empty[String], \"empty option of string\")\n\n  encodeDecodeTest(\n    AvroExample1.newBuilder()\n      .setMyarray(List(\"Foo\", \"Bar\").asJava)"
  }
]