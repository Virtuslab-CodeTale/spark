[
  {
    "id" : "e32b1057-dbca-4071-955c-fb197f9bf4dd",
    "prId" : 30745,
    "prUrl" : "https://github.com/apache/spark/pull/30745#pullrequestreview-599430011",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "34a2bddb-ba80-4a5e-aaaf-3ef4f25b8bcf",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "nit: `7.0 * 11 * 17 * 19`",
        "createdAt" : "2021-02-26T09:10:29Z",
        "updatedAt" : "2021-03-01T17:18:18Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "a62c8310-823d-4c28-8b48-a07d8b7cb801",
        "parentId" : "34a2bddb-ba80-4a5e-aaaf-3ef4f25b8bcf",
        "authorId" : "dc7a33cf-bba6-4512-a5a1-248c3cac6eae",
        "body" : "I prefer the original because it's a *slightly* stronger test of round-off errors. The original computes the product using integer arithmetic *before* conversion to `Double`, and confirms that this is consistent with `product` which uses conversion of each element individually to a `Double`.",
        "createdAt" : "2021-02-26T09:44:20Z",
        "updatedAt" : "2021-03-01T17:18:18Z",
        "lastEditedBy" : "dc7a33cf-bba6-4512-a5a1-248c3cac6eae",
        "tags" : [
        ]
      },
      {
        "id" : "b31371e6-97d2-45a6-9570-5670e5a876a4",
        "parentId" : "34a2bddb-ba80-4a5e-aaaf-3ef4f25b8bcf",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "(I agree with that)",
        "createdAt" : "2021-02-26T10:10:44Z",
        "updatedAt" : "2021-03-01T17:18:18Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      }
    ],
    "commit" : "1cdabcbdab2d54c67f09139f3b6cea1b2c09e04e",
    "line" : 102,
    "diffHunk" : "@@ -1,1 +100,104 @@    // Pair\n    val p2 = evaluator.update(InternalRow(17.0), InternalRow(19.0))\n    assert(evaluator.merge(p1, p2) === InternalRow((7 * 11 * 17 * 19).toDouble))\n    assert(evaluator.merge(p1, p2) === evaluator.merge(p2, p1))\n"
  },
  {
    "id" : "ec64d460-022a-46c4-87bf-601c280731fb",
    "prId" : 30745,
    "prUrl" : "https://github.com/apache/spark/pull/30745#pullrequestreview-599381747",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "031ef9da-1c83-470b-a1db-5f51f9bd6d74",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can we also test special values like NaN, Infinity, etc.?",
        "createdAt" : "2021-02-26T09:11:36Z",
        "updatedAt" : "2021-03-01T17:18:18Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "1cdabcbdab2d54c67f09139f3b6cea1b2c09e04e",
    "line" : 155,
    "diffHunk" : "@@ -1,1 +153,157 @@    val m12 = evaluator.merge(p1, p2)\n    assert(evaluator.eval(m12) === InternalRow(2.0 * 3 * 5 * 7 * 11))\n  }\n}"
  }
]