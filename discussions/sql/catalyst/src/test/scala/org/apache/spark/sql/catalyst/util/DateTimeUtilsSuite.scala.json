[
  {
    "id" : "c85ab9d0-5f1e-46df-8194-7ec5bc60cb34",
    "prId" : 33490,
    "prUrl" : "https://github.com/apache/spark/pull/33490#pullrequestreview-715752028",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1dcd588f-14f9-475c-964c-4080b8286243",
        "parentId" : null,
        "authorId" : "29c89154-22f7-40ee-b295-115a55734d6c",
        "body" : "Maybe we can do some special handling to allow this.",
        "createdAt" : "2021-07-23T04:36:56Z",
        "updatedAt" : "2021-07-23T04:36:56Z",
        "lastEditedBy" : "29c89154-22f7-40ee-b295-115a55734d6c",
        "tags" : [
        ]
      },
      {
        "id" : "740e7835-3c33-46a1-b6ca-26d24b5ad502",
        "parentId" : "1dcd588f-14f9-475c-964c-4080b8286243",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Is this valid? doesn't quite look like it",
        "createdAt" : "2021-07-23T11:36:38Z",
        "updatedAt" : "2021-07-23T11:36:58Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "f09a1f43-dea3-42f5-b0d8-2c358f717dc9",
        "parentId" : "1dcd588f-14f9-475c-964c-4080b8286243",
        "authorId" : "29c89154-22f7-40ee-b295-115a55734d6c",
        "body" : "@srowen, thanks for reviewing. Personally I think it's invalid and this usage is blocked in my PR. But since previously it's allowed in the test case, so maybe someone will argue we should still allow it",
        "createdAt" : "2021-07-26T05:09:07Z",
        "updatedAt" : "2021-07-26T10:24:25Z",
        "lastEditedBy" : "29c89154-22f7-40ee-b295-115a55734d6c",
        "tags" : [
        ]
      },
      {
        "id" : "6916bd61-77f9-4223-99a7-6760ffc8b9c8",
        "parentId" : "1dcd588f-14f9-475c-964c-4080b8286243",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Was it previously allowed? this test is new",
        "createdAt" : "2021-07-26T12:58:26Z",
        "updatedAt" : "2021-07-26T12:58:26Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "c4c3b52e-dc55-456f-9b3c-9b40fe55402a",
        "parentId" : "1dcd588f-14f9-475c-964c-4080b8286243",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "It was previously allowed: https://github.com/apache/spark/pull/33490/files#diff-95555ac355a4972b9a61cad3e6599b0ac3c242877c1a393ecc5a77842e90091eL185",
        "createdAt" : "2021-07-27T10:33:50Z",
        "updatedAt" : "2021-07-27T10:33:50Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "48e73572a18b3d4a2083014388f2750f8eab6589",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +292,296 @@      checkStringToTimestamp(\"+\", None)\n      checkStringToTimestamp(\"T\", None)\n      checkStringToTimestamp(\"2015-03-18T\", None)\n      checkStringToTimestamp(\"12::\", None)\n      checkStringToTimestamp(\"2015-03-18T12:03:17-8:\", None)"
  },
  {
    "id" : "8e027b70-e8ba-4b8d-b0bc-aa110e8657a9",
    "prId" : 32959,
    "prUrl" : "https://github.com/apache/spark/pull/32959#pullrequestreview-688053401",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "33ca8e99-621e-4ef9-99b1-89047ba10d0b",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "we also need end-to-end test",
        "createdAt" : "2021-06-21T06:00:27Z",
        "updatedAt" : "2021-06-21T06:00:28Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "538463a405c2eac1ddfccba8d82ca846f81e5a22",
    "line" : 102,
    "diffHunk" : "@@ -1,1 +341,345 @@    checkStringToTimestamp(\"2021-01-01T12:30:4294967297+4294967297:30\", None)\n  }\n\n  test(\"SPARK-15379: special invalid date string\") {\n    // Test stringToDate"
  },
  {
    "id" : "0c73eacb-3ac4-4aae-b30e-5decef830b15",
    "prId" : 32814,
    "prUrl" : "https://github.com/apache/spark/pull/32814#pullrequestreview-678221125",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3b636b98-65ba-4531-b021-c636e6db5de2",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "let's test negative value as well.",
        "createdAt" : "2021-06-08T08:11:34Z",
        "updatedAt" : "2021-06-08T08:11:34Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "a2326e0abc8cca80032213476d53ee5b0b9228ea",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +639,643 @@    assert(microsToLocalDateTime(100) ==  LocalDateTime.parse(\"1970-01-01T00:00:00.0001\"))\n    assert(microsToLocalDateTime(100000000) ==  LocalDateTime.parse(\"1970-01-01T00:01:40\"))\n    assert(microsToLocalDateTime(100000000000L) ==  LocalDateTime.parse(\"1970-01-02T03:46:40\"))\n    assert(microsToLocalDateTime(253402300799999999L) ==\n      LocalDateTime.parse(\"9999-12-31T23:59:59.999999\"))"
  },
  {
    "id" : "78bcf708-3f4f-4710-8d58-a69b8c506763",
    "prId" : 30303,
    "prUrl" : "https://github.com/apache/spark/pull/30303#pullrequestreview-527363704",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b8458fa3-4dfb-4e4a-b9ad-31e2f9aea3bd",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "The checks for millis and micros don't fail when I reverted your fix. I guess because zone offset has seconds precision.",
        "createdAt" : "2020-11-10T07:21:29Z",
        "updatedAt" : "2020-11-10T16:54:36Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "0be74e50-7577-4b2b-b76e-b89b32b606ac",
        "parentId" : "b8458fa3-4dfb-4e4a-b9ad-31e2f9aea3bd",
        "authorId" : "898aa86e-30e8-495b-8406-2922eef22253",
        "body" : "Yeah your guess is right.",
        "createdAt" : "2020-11-10T16:09:26Z",
        "updatedAt" : "2020-11-10T16:54:36Z",
        "lastEditedBy" : "898aa86e-30e8-495b-8406-2922eef22253",
        "tags" : [
        ]
      }
    ],
    "commit" : "493654073293c8bf6b5e24b4688e5fc9f1967f03",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +538,542 @@        testTrunc(DateTimeUtils.TRUNC_TO_SECOND, \"1769-10-17T17:10:02\", inputTS.get, zid)\n        testTrunc(DateTimeUtils.TRUNC_TO_MILLISECOND, \"1769-10-17T17:10:02.123\", inputTS.get, zid)\n        testTrunc(DateTimeUtils.TRUNC_TO_MICROSECOND, \"1769-10-17T17:10:02.123456\",\n          inputTS.get, zid)\n      }"
  },
  {
    "id" : "04058470-8a8d-4126-a01d-54284e3a50ef",
    "prId" : 28189,
    "prUrl" : "https://github.com/apache/spark/pull/28189#pullrequestreview-392034725",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "304b4449-031d-4d3c-b8ff-8f350b809b85",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "<img width=\"797\" alt=\"Screenshot 2020-04-11 at 19 01 34\" src=\"https://user-images.githubusercontent.com/1580697/79048599-f046e180-7c26-11ea-9940-eddee9785fb4.png\">\r\n",
        "createdAt" : "2020-04-11T16:02:45Z",
        "updatedAt" : "2020-04-13T08:52:46Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "0024728f-e902-4b0c-adb2-4099c83d1cfb",
        "parentId" : "304b4449-031d-4d3c-b8ff-8f350b809b85",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "what's the behavior of Spark 2.4?",
        "createdAt" : "2020-04-13T06:16:29Z",
        "updatedAt" : "2020-04-13T08:52:46Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "e195dc39-f998-4510-b1e8-c89d61149767",
        "parentId" : "304b4449-031d-4d3c-b8ff-8f350b809b85",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "See the same test in 2.4 https://github.com/apache/spark/blob/branch-2.4/sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/util/DateTimeUtilsSuite.scala#L580-L581 but it sets PST time zone.",
        "createdAt" : "2020-04-13T06:28:18Z",
        "updatedAt" : "2020-04-13T08:52:46Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "561e1587-98a7-4cae-ad61-2e6a975774bf",
        "parentId" : "304b4449-031d-4d3c-b8ff-8f350b809b85",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "as we have looked into the JDK code before, PST is treated as LA. So the behavior is the same as 2.4, and it's great!\r\n\r\ncan we highlight it in the `Does this PR introduce any user-facing change?` section? Say it's changed back to the 2.4 behavior.",
        "createdAt" : "2020-04-13T06:31:18Z",
        "updatedAt" : "2020-04-13T08:52:46Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "0657685d-52f5-4515-b536-724f81e283c7",
        "parentId" : "304b4449-031d-4d3c-b8ff-8f350b809b85",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "done",
        "createdAt" : "2020-04-13T08:57:44Z",
        "updatedAt" : "2020-04-13T08:57:45Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "a28f2a1bd7d053051cc252f37de4e412abef9ce6",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +497,501 @@      test(\"2016-03-13 03:00:00\", tz, \"2016-03-13 10:00:00.0\")\n      test(\"2016-11-06 00:59:59\", tz, \"2016-11-06 07:59:59.0\")\n      test(\"2016-11-06 01:00:00\", tz, \"2016-11-06 09:00:00.0\")\n      test(\"2016-11-06 01:59:59\", tz, \"2016-11-06 09:59:59.0\")\n      test(\"2016-11-06 02:00:00\", tz, \"2016-11-06 10:00:00.0\")"
  },
  {
    "id" : "cbd0e3aa-2794-4a5a-a7b0-38820fe0901f",
    "prId" : 27980,
    "prUrl" : "https://github.com/apache/spark/pull/27980#pullrequestreview-379042226",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "80a8e9c3-df7a-4c81-a24b-d2e7c27d7c34",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Here, I restored the code of Spark 2.4: https://github.com/apache/spark/blob/branch-2.4/sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/util/DateTimeUtilsSuite.scala#L88",
        "createdAt" : "2020-03-22T20:04:59Z",
        "updatedAt" : "2020-03-24T07:33:21Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "46b6613e4025f91487ce58e09cf0a1bccb17897e",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +91,95 @@    def checkFromToJavaDate(d1: Date): Unit = {\n      val d2 = toJavaDate(fromJavaDate(d1))\n      assert(d2.toString === d1.toString)\n    }\n"
  },
  {
    "id" : "929540ab-7dd4-42e9-92f3-91581a389fd9",
    "prId" : 27873,
    "prUrl" : "https://github.com/apache/spark/pull/27873#pullrequestreview-372529125",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cca9e379-a9dd-4f3d-83ca-261d8221fd98",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I don't know why we pick -20000 and 20000 as the boundaries, just to be safe to always test the boundary values.",
        "createdAt" : "2020-03-11T07:42:24Z",
        "updatedAt" : "2020-03-11T07:42:24Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "c7819b9be03b9ac87ae649c7e922ca4994893560",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +624,628 @@    for (tz <- ALL_TIMEZONES) {\n      val skipped = skipped_days.getOrElse(tz.getID, Set.empty)\n      val testingData = Seq(-20000, 20000) ++\n        (1 to 1000).map(_ => (math.random() * 40000 - 20000).toInt)\n      testingData.foreach { d =>"
  },
  {
    "id" : "2646f218-9db2-49ca-9e76-f9ed397dd972",
    "prId" : 27873,
    "prUrl" : "https://github.com/apache/spark/pull/27873#pullrequestreview-372941009",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "23cfef10-aab6-4ac4-8a50-91db00f7717d",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "There are 2 approaches for generating random values for Catalyst's types:\r\n1. https://github.com/apache/spark/blob/1febd373ea806326d269a60048ee52543a76c918/sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/expressions/LiteralGenerator.scala#L114-L124\r\n2. RandomDataGenerator.forType(): https://github.com/apache/spark/blob/9562b26914f9a0c513e34b9b90cdec60067ef055/sql/catalyst/src/test/scala/org/apache/spark/sql/RandomDataGenerator.scala#L178-L193\r\n\r\nCan you use one of them?",
        "createdAt" : "2020-03-11T15:27:14Z",
        "updatedAt" : "2020-03-11T15:27:20Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "eb661299-f84f-47c7-b012-c4a0bb1436ed",
        "parentId" : "23cfef10-aab6-4ac4-8a50-91db00f7717d",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Sorry seeing this comment too late.\r\n\r\nHere we just need to get a random int. It's nothing about the catalyst data type. I think it's better to keep simple.",
        "createdAt" : "2020-03-11T15:48:50Z",
        "updatedAt" : "2020-03-11T15:48:51Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "09bb1c34-c30e-4de5-8b2e-6313c88556ec",
        "parentId" : "23cfef10-aab6-4ac4-8a50-91db00f7717d",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "It is not related to the PR but I think we could unify random data generators for Catalyst's types. ",
        "createdAt" : "2020-03-11T16:47:46Z",
        "updatedAt" : "2020-03-11T16:47:47Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "c7819b9be03b9ac87ae649c7e922ca4994893560",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +625,629 @@      val skipped = skipped_days.getOrElse(tz.getID, Set.empty)\n      val testingData = Seq(-20000, 20000) ++\n        (1 to 1000).map(_ => (math.random() * 40000 - 20000).toInt)\n      testingData.foreach { d =>\n        if (!skipped.contains(d)) {"
  },
  {
    "id" : "c1a941e5-1f33-45d0-8376-209d17978648",
    "prId" : 27753,
    "prUrl" : "https://github.com/apache/spark/pull/27753#pullrequestreview-368799267",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a83b01d4-500f-4703-b0b4-29352e97a26f",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can we test some corner cases like `GMT+7:30`?",
        "createdAt" : "2020-03-04T10:26:06Z",
        "updatedAt" : "2020-03-04T14:13:06Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "147d3add-ca01-4102-9b2e-2daf932d883b",
        "parentId" : "a83b01d4-500f-4703-b0b4-29352e97a26f",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "This format is not supported by ZoneId. I put all supported formats to the PR's description:\r\n```scala\r\nscala> getZoneId(\"GMT+7:30\")\r\njava.time.DateTimeException: Invalid ID for offset-based ZoneId: GMT+7:30\r\n  at java.time.ZoneId.ofWithPrefix(ZoneId.java:437)\r\n  at java.time.ZoneId.of(ZoneId.java:407)\r\n  at java.time.ZoneId.of(ZoneId.java:359)\r\n  at java.time.ZoneId.of(ZoneId.java:315)\r\n  at org.apache.spark.sql.catalyst.util.DateTimeUtils$.getZoneId(DateTimeUtils.scala:57)\r\n  ... 53 elided\r\nCaused by: java.time.DateTimeException: Invalid ID for ZoneOffset, non numeric characters found: +7:30\r\n  at java.time.ZoneOffset.parseNumber(ZoneOffset.java:269)\r\n  at java.time.ZoneOffset.of(ZoneOffset.java:221)\r\n  at java.time.ZoneId.ofWithPrefix(ZoneId.java:431)\r\n  ... 57 more\r\n\r\nscala> getZoneId(\"GMT+7\")\r\nres5: java.time.ZoneId = GMT+07:00\r\n\r\nscala> getZoneId(\"GMT+07:30\")\r\nres6: java.time.ZoneId = GMT+07:30\r\n```",
        "createdAt" : "2020-03-04T13:59:25Z",
        "updatedAt" : "2020-03-04T14:13:06Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "59448c4c-27d2-4001-ab6f-cf293247e390",
        "parentId" : "a83b01d4-500f-4703-b0b4-29352e97a26f",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "I have to leave the existing code only because of the case, see https://github.com/apache/spark/pull/27753#discussion_r386240731",
        "createdAt" : "2020-03-04T14:00:33Z",
        "updatedAt" : "2020-03-04T14:13:06Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "00a07ab500b63cb13edcd8bf71ad709d008e2d5b",
    "line" : 50,
    "diffHunk" : "@@ -1,1 +235,239 @@      expected = Option(date(2015, 3, 18, 12, 3, 17, 123000, zid = zoneId))\n      checkStringToTimestamp(\"2015-03-18T12:03:17.123+07:30\", expected)\n      checkStringToTimestamp(\"2015-03-18T12:03:17.123GMT+07:30\", expected)\n\n      expected = Option(date(2015, 3, 18, 12, 3, 17, 123121, zid = zoneId))"
  },
  {
    "id" : "0d8a6847-d2db-416e-a694-0e7e65a3cd21",
    "prId" : 27596,
    "prUrl" : "https://github.com/apache/spark/pull/27596#pullrequestreview-359385076",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1d20421c-88bf-4f6a-9657-74ffdfdc1a6c",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "This is new test.",
        "createdAt" : "2020-02-16T07:28:56Z",
        "updatedAt" : "2020-02-16T11:31:18Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "5b577a4a-1f64-441b-a645-ea99781c7a7c",
        "parentId" : "1d20421c-88bf-4f6a-9657-74ffdfdc1a6c",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Before the changes:\r\n```sql\r\nspark-sql> select hour(timestamp '0010-01-01 00:00:00');\r\n23\r\n```",
        "createdAt" : "2020-02-16T07:31:22Z",
        "updatedAt" : "2020-02-16T11:31:18Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "59491286e6a034b7f2dd1d8a9f79f84c62b51d23",
    "line" : 162,
    "diffHunk" : "@@ -1,1 +301,305 @@    assert(getHours(input, zoneGMT) === 10)\n    input = date(10, 1, 1, 0, 0, 0, 0, zonePST)\n    assert(getHours(input, zonePST) === 0)\n  }\n"
  },
  {
    "id" : "a23197cb-1e4f-48e2-84a4-8e588b52ec43",
    "prId" : 27596,
    "prUrl" : "https://github.com/apache/spark/pull/27596#pullrequestreview-359390534",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4e5e8af0-3c5d-4a74-bbe6-b36d0aba5a51",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "New test",
        "createdAt" : "2020-02-16T09:23:48Z",
        "updatedAt" : "2020-02-16T11:31:18Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "59491286e6a034b7f2dd1d8a9f79f84c62b51d23",
    "line" : 182,
    "diffHunk" : "@@ -1,1 +313,317 @@    assert(getMinutes(input, zoneGMT) === 7)\n    assert(getMinutes(input, getZoneId(\"Australia/North\")) === 37)\n    input = date(10, 1, 1, 0, 0, 0, 0, zonePST)\n    assert(getMinutes(input, zonePST) === 0)\n  }"
  },
  {
    "id" : "19449693-020f-42ef-a18a-45ca040aa357",
    "prId" : 27596,
    "prUrl" : "https://github.com/apache/spark/pull/27596#pullrequestreview-359390537",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c4d8e20e-f2ff-480c-92d7-e31c03bd99d2",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "new test",
        "createdAt" : "2020-02-16T09:23:56Z",
        "updatedAt" : "2020-02-16T11:31:18Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "59491286e6a034b7f2dd1d8a9f79f84c62b51d23",
    "line" : 199,
    "diffHunk" : "@@ -1,1 +324,328 @@    assert(getSeconds(input, zonePST) === 9)\n    assert(getSeconds(input, zoneGMT) === 9)\n    input = date(10, 1, 1, 0, 0, 0, 0, zonePST)\n    assert(getSeconds(input, zonePST) === 0)\n  }"
  },
  {
    "id" : "de556f5f-ff80-472c-878a-53bbf54570bc",
    "prId" : 27494,
    "prUrl" : "https://github.com/apache/spark/pull/27494#pullrequestreview-355568112",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "846dc9df-7bb9-4d20-a759-3a6dcca3ce2a",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "I had to use the formatter to avoid calendar problems - `Date.toString` formats slightly differently than `DateTimeFormatter`, I guess because of different year lengths in calendars.",
        "createdAt" : "2020-02-08T20:45:45Z",
        "updatedAt" : "2020-02-12T12:44:38Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "e5d463f67d68efcff046851479b4789d1e4f50a0",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +93,97 @@    def checkFromToJavaDate(d1: Date): Unit = {\n      val d2 = toJavaDate(fromJavaDate(d1))\n      assert(format(d2) === format(d1))\n    }\n"
  },
  {
    "id" : "5eeea189-c195-4e84-bdf1-7b4392b27d8f",
    "prId" : 26236,
    "prUrl" : "https://github.com/apache/spark/pull/26236#pullrequestreview-306883087",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "67211fc3-3bcb-4add-bc0d-638b24859f4e",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Could you put the JDK / OS version for this into the PR description, please?",
        "createdAt" : "2019-10-23T23:28:26Z",
        "updatedAt" : "2019-10-23T23:28:26Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "8f8d514a-244a-438d-bdef-c871cd5cbe99",
        "parentId" : "67211fc3-3bcb-4add-bc0d-638b24859f4e",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "I updated the JDK version. I'll ask the reporter to comment here with more details. That said, I think this is an obvious fix so I'm not too worried about those details. It doesn't happen on 1.8.0_222 at least.",
        "createdAt" : "2019-10-23T23:39:23Z",
        "updatedAt" : "2019-10-23T23:39:24Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "860ec22e-d88d-4028-a5b8-98d23ba2d851",
        "parentId" : "67211fc3-3bcb-4add-bc0d-638b24859f4e",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "CC @darshan-pandya",
        "createdAt" : "2019-10-23T23:40:00Z",
        "updatedAt" : "2019-10-23T23:40:00Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "465199bd-1287-4cd0-b113-d63e98acccce",
        "parentId" : "67211fc3-3bcb-4add-bc0d-638b24859f4e",
        "authorId" : "0c069ebf-b8e1-40a2-99fa-72e9ec5426b1",
        "body" : "When we encountered, this test failed on jdk 1.8.0_232",
        "createdAt" : "2019-10-24T19:29:13Z",
        "updatedAt" : "2019-10-24T19:29:14Z",
        "lastEditedBy" : "0c069ebf-b8e1-40a2-99fa-72e9ec5426b1",
        "tags" : [
        ]
      },
      {
        "id" : "2f774ff3-e37c-40ba-b6c2-90ecc4d3ddec",
        "parentId" : "67211fc3-3bcb-4add-bc0d-638b24859f4e",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "And, which OS did you used?",
        "createdAt" : "2019-10-24T19:39:19Z",
        "updatedAt" : "2019-10-24T19:39:31Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "8bd819ea-9eeb-407d-9418-858355b6c823",
        "parentId" : "67211fc3-3bcb-4add-bc0d-638b24859f4e",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "I assume it's Linux @darshan-pandya but would it matter? Java uses its own TZ info rather than anything from the OS.",
        "createdAt" : "2019-10-24T21:34:06Z",
        "updatedAt" : "2019-10-24T21:34:06Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "336bd18e-78f4-49df-90f5-218318fa0d04",
        "parentId" : "67211fc3-3bcb-4add-bc0d-638b24859f4e",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Just out of curiosity, ðŸ˜„ .",
        "createdAt" : "2019-10-24T21:45:20Z",
        "updatedAt" : "2019-10-24T21:45:20Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "cbeccdc5204d0fcc0e532f399ec39a16c932d7d2",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +556,560 @@    // There are some days are skipped entirely in some timezone, skip them here.\n    val skipped_days = Map[String, Set[Int]](\n      \"Kwajalein\" -> Set(8632, 8633, 8634),\n      \"Pacific/Apia\" -> Set(15338),\n      \"Pacific/Enderbury\" -> Set(9130, 9131),"
  },
  {
    "id" : "ffe48d9e-3a6b-4101-9af1-c94a92129da9",
    "prId" : 26143,
    "prUrl" : "https://github.com/apache/spark/pull/26143#pullrequestreview-302798047",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "14e2c505-bd8e-4c6b-b646-fdcc93c7de79",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "You described 2 cases in the PR discription `':'` and `' '`. This test checks the first one only. Could you add at least one more check for `' '`.",
        "createdAt" : "2019-10-16T18:47:08Z",
        "updatedAt" : "2019-10-18T17:50:35Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "5ef53b7ca639c0bff5db28b9d96ba810974b3207",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +458,462 @@\n  test(\"trailing characters while converting string to timestamp\") {\n    val s = UTF8String.fromString(\"2019-10-31T10:59:23Z:::\")\n    val time = DateTimeUtils.stringToTimestamp(s, defaultZoneId)\n    assert(time == None)"
  },
  {
    "id" : "2270d315-7f20-40e4-a07d-8c829670af17",
    "prId" : 26134,
    "prUrl" : "https://github.com/apache/spark/pull/26134#pullrequestreview-302338968",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f21a8e4a-2cf6-40aa-a190-6e49cfe03828",
        "parentId" : null,
        "authorId" : "58a5dec8-caad-405f-b8fe-9510071c1cb9",
        "body" : "test case to demonstrate the daylight saving case",
        "createdAt" : "2019-10-16T06:08:56Z",
        "updatedAt" : "2019-11-01T05:44:12Z",
        "lastEditedBy" : "58a5dec8-caad-405f-b8fe-9510071c1cb9",
        "tags" : [
        ]
      }
    ],
    "commit" : "2f901894eb24d7deec31947708b9afdaae2a4866",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +383,387 @@  }\n\n  test(\"timestamp add days\") {\n    // 2019-3-9 is the end of Pacific Standard Time\n    val ts1 = date(2019, 3, 9, 12, 0, 0, 123000, TimeZonePST)"
  }
]