[
  {
    "id" : "1d513112-09ca-4cc3-a767-b601b030aa30",
    "prId" : 33183,
    "prUrl" : "https://github.com/apache/spark/pull/33183#pullrequestreview-699596485",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "75a0f305-3451-4bba-9521-c40f0e55a6b8",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This is the key to trigger this bug. Ideally, in SQL query, nested columns should result to `GetStructField` with non-None `name`. But there are places that can create `GetStructField` with None `name`, such as `UnresolvedStar.expand`, Dataset encoder stuff, etc.\r\n\r\nIt's better to have an end-to-end test, but I'm fine with this UT.",
        "createdAt" : "2021-07-06T06:35:37Z",
        "updatedAt" : "2021-07-06T06:35:38Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "6a79d5b6-f95a-4e94-a0ff-c4a4ef0ac310",
        "parentId" : "75a0f305-3451-4bba-9521-c40f0e55a6b8",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Yea, I see. For None case, the current `nestedFieldToAlias` cannot catch it up.",
        "createdAt" : "2021-07-06T06:58:15Z",
        "updatedAt" : "2021-07-06T06:58:16Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "d073d7ad1fe957cd92080499b35654a24c286b3a",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +751,755 @@      .repartition(100)\n      .select(\n        GetStructField('struct_data, 1, None).as(\"value\"),\n        $\"struct_data.search_params.col1\".as(\"col1\"),\n        $\"struct_data.search_params.col2\".as(\"col2\")).analyze"
  },
  {
    "id" : "56ff9da4-3ca9-494c-8ac6-9002b36e17ba",
    "prId" : 31966,
    "prUrl" : "https://github.com/apache/spark/pull/31966#pullrequestreview-627657812",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "76eb18dd-edd0-4074-8fb2-14953896e541",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "If we want to revise this test case, shall we revise the test name together?",
        "createdAt" : "2021-03-27T18:37:32Z",
        "updatedAt" : "2021-04-25T00:49:15Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "01fc2c41-c844-423a-9cf5-9fea9cb3d15c",
        "parentId" : "76eb18dd-edd0-4074-8fb2-14953896e541",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "okay. revised.",
        "createdAt" : "2021-04-05T06:31:11Z",
        "updatedAt" : "2021-04-25T00:49:15Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "a7194092ebc3a9ca97daba29fda0fcc0ec099cf4",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +337,341 @@    val query = companies\n      .generate(Explode('employers.getField(\"company\")), outputNames = Seq(\"company\"))\n      .select('company.getField(\"name\"), 'company.getField(\"address\"))\n      .analyze\n    val optimized = Optimize.execute(query)"
  },
  {
    "id" : "4dc1bb63-2f34-4595-992e-fff5cc3f42d6",
    "prId" : 28898,
    "prUrl" : "https://github.com/apache/spark/pull/28898#pullrequestreview-437975941",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d0ec04b6-0285-4a39-b8fa-1281ff4d9e9d",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "If there is only one query, we don't need to name it as `query1`, `optimized1`...",
        "createdAt" : "2020-06-26T02:27:13Z",
        "updatedAt" : "2020-07-24T06:11:32Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "a0b8d070f027460dd1e5fdbd7dc35d0440450b0a",
    "line" : 41,
    "diffHunk" : "@@ -1,1 +519,523 @@    val optimized1 = Optimize.execute(query1)\n    val aliases1 = collectGeneratedAliases(optimized1)\n    val expected1 = contact\n      .select($\"name.first\", $\"address\", $\"id\", $\"name.first\".as(aliases1(1)))\n      .window(Seq(winExpr.as(\"window\")), Seq($\"address\"), Seq($\"id\".asc))"
  },
  {
    "id" : "3393b075-03f2-46cc-8ec7-8f4ea20f0860",
    "prId" : 28898,
    "prUrl" : "https://github.com/apache/spark/pull/28898#pullrequestreview-440383698",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "05aa9677-2843-4923-a18c-a8a0e13468ba",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Could you add some tests for the other combinations, e.g., Filter + Limit, Filter + Sort, ...?",
        "createdAt" : "2020-06-30T08:06:34Z",
        "updatedAt" : "2020-07-24T06:11:32Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "46e6c7fb-b5a3-4728-8c17-a847a4da4b90",
        "parentId" : "05aa9677-2843-4923-a18c-a8a0e13468ba",
        "authorId" : "e2104308-ae70-4ecf-9798-03460fcd8763",
        "body" : "Done",
        "createdAt" : "2020-06-30T21:03:14Z",
        "updatedAt" : "2020-07-24T06:11:32Z",
        "lastEditedBy" : "e2104308-ae70-4ecf-9798-03460fcd8763",
        "tags" : [
        ]
      }
    ],
    "commit" : "a0b8d070f027460dd1e5fdbd7dc35d0440450b0a",
    "line" : 37,
    "diffHunk" : "@@ -1,1 +515,519 @@    val winExpr = windowExpr(RowNumber(), spec)\n    val query1 = contact.select($\"name.first\", winExpr.as('window))\n      .where($\"window\" === 1 && $\"name.first\" === \"a\")\n      .analyze\n    val optimized1 = Optimize.execute(query1)"
  },
  {
    "id" : "289da146-ec16-43ae-80fd-46c8a024da63",
    "prId" : 28898,
    "prUrl" : "https://github.com/apache/spark/pull/28898#pullrequestreview-453013139",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "40648c3f-d1ad-4f8f-ac65-7cda4861d4d2",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Shall we move this test case into `test(\"Nested field pruning for Window\")`.",
        "createdAt" : "2020-07-22T05:35:15Z",
        "updatedAt" : "2020-07-24T06:11:32Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "54c1b1e3-41a0-4c4f-9445-33bce608806e",
        "parentId" : "40648c3f-d1ad-4f8f-ac65-7cda4861d4d2",
        "authorId" : "e2104308-ae70-4ecf-9798-03460fcd8763",
        "body" : "This is to test Filter->Window combination, so I think it fits more with the test description. The `test(\"Nested field pruning for Window\")` is to test for `Windows` operators alone. ",
        "createdAt" : "2020-07-22T05:39:43Z",
        "updatedAt" : "2020-07-24T06:11:32Z",
        "lastEditedBy" : "e2104308-ae70-4ecf-9798-03460fcd8763",
        "tags" : [
        ]
      },
      {
        "id" : "f2a96af3-026c-4ded-917c-3189c6300b0d",
        "parentId" : "40648c3f-d1ad-4f8f-ac65-7cda4861d4d2",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "This is the same. This PR doesn't support `Filter` in general. This PR only supports `Filter` when the child is `Window`. So, it's more natural the `Window` test case have this.",
        "createdAt" : "2020-07-22T05:53:01Z",
        "updatedAt" : "2020-07-24T06:11:32Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "a0b8d070f027460dd1e5fdbd7dc35d0440450b0a",
    "line" : 48,
    "diffHunk" : "@@ -1,1 +526,530 @@      .select($\"first\", $\"window\")\n      .analyze\n    comparePlans(optimized1, expected1)\n\n    val query2 = contact.sortBy($\"name.first\".asc)"
  },
  {
    "id" : "b532f87b-8bf6-442a-9dc4-601416da44aa",
    "prId" : 28898,
    "prUrl" : "https://github.com/apache/spark/pull/28898#pullrequestreview-453008421",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ce0743f3-e3bf-4429-b391-e2ab503123d9",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Shall we move this test case into `test(\"Nested field pruning for Sort\")`?",
        "createdAt" : "2020-07-22T05:35:39Z",
        "updatedAt" : "2020-07-24T06:11:32Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "8d78b85d-26f3-4196-8566-8578881bcfa7",
        "parentId" : "ce0743f3-e3bf-4429-b391-e2ab503123d9",
        "authorId" : "e2104308-ae70-4ecf-9798-03460fcd8763",
        "body" : "This is to test Filter->Sort combination, so I think it fits more with the test description. The `test(\"Nested field pruning for Sort\")` is to test for `Sort` operators alone. ",
        "createdAt" : "2020-07-22T05:40:08Z",
        "updatedAt" : "2020-07-24T06:11:32Z",
        "lastEditedBy" : "e2104308-ae70-4ecf-9798-03460fcd8763",
        "tags" : [
        ]
      }
    ],
    "commit" : "a0b8d070f027460dd1e5fdbd7dc35d0440450b0a",
    "line" : 63,
    "diffHunk" : "@@ -1,1 +541,545 @@      .select($\"${aliases2(0)}\".as(\"first\"))\n      .analyze\n    comparePlans(optimized2, expected2)\n\n    val query3 = contact.distribute($\"name.first\")(100)"
  },
  {
    "id" : "7abb80a2-347f-46f7-b5db-d89e961e5ddf",
    "prId" : 28898,
    "prUrl" : "https://github.com/apache/spark/pull/28898#pullrequestreview-453012589",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1e6df5cc-f604-47d6-9f3d-12c6723d068e",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Shall we merge this line 578 to 597 into `test(\"Pushing a single nested field projection\")`?",
        "createdAt" : "2020-07-22T05:39:35Z",
        "updatedAt" : "2020-07-24T06:11:32Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "5578359c-4372-4258-b556-a1ca755bd2a4",
        "parentId" : "1e6df5cc-f604-47d6-9f3d-12c6723d068e",
        "authorId" : "e2104308-ae70-4ecf-9798-03460fcd8763",
        "body" : "This is a test the combination of `Filter-> Sample/GlobalLimit/LocalLimit/Repartition`, so that's why it's under this test name -- to test for the combination of `Filter` and other children that can be pushed through. ",
        "createdAt" : "2020-07-22T05:42:52Z",
        "updatedAt" : "2020-07-24T06:11:32Z",
        "lastEditedBy" : "e2104308-ae70-4ecf-9798-03460fcd8763",
        "tags" : [
        ]
      },
      {
        "id" : "7fd87fd0-af7c-46a6-9bb1-e14cb6e81ca0",
        "parentId" : "1e6df5cc-f604-47d6-9f3d-12c6723d068e",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "I know that but this PR doesn't support `Filter` completely. I believe we had better collect these simple test case addition there.",
        "createdAt" : "2020-07-22T05:51:29Z",
        "updatedAt" : "2020-07-24T06:11:32Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "a0b8d070f027460dd1e5fdbd7dc35d0440450b0a",
    "line" : 117,
    "diffHunk" : "@@ -1,1 +595,599 @@      (plan: LogicalPlan) => Sample(0.0, 0.6, false, 11L, plan)).foreach {  base =>\n        runTest(base)\n      }\n  }\n"
  },
  {
    "id" : "d61eccf8-1a74-4e7f-a255-a8f27e3ba7f7",
    "prId" : 28560,
    "prUrl" : "https://github.com/apache/spark/pull/28560#pullrequestreview-416585458",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "af1f5436-b962-41b6-b4ff-16768a9633ba",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Thanks for this update and looks fine.",
        "createdAt" : "2020-05-22T01:00:01Z",
        "updatedAt" : "2020-05-22T01:00:01Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "b2e56d55fe1dda39a47ba654e2b60a81fea7e492",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +370,374 @@      (plan: LogicalPlan) => plan.limit(100),\n      (plan: LogicalPlan) => plan.repartition(100),\n      (plan: LogicalPlan) => Sample(0.0, 0.6, false, 11L, plan)).foreach {  base =>\n      runTest(base)\n    }"
  },
  {
    "id" : "27db9da4-b0ae-4613-a92c-47fec36e4abb",
    "prId" : 27675,
    "prUrl" : "https://github.com/apache/spark/pull/27675#pullrequestreview-363656699",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5279f2dc-f9a4-46fb-8aa9-2548a68d9ea8",
        "parentId" : null,
        "authorId" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "body" : "Since we need the whole structure, why we expected the local relation to be column pruned?",
        "createdAt" : "2020-02-22T19:12:26Z",
        "updatedAt" : "2020-02-24T13:37:32Z",
        "lastEditedBy" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "tags" : [
        ]
      },
      {
        "id" : "e7a3954b-723a-44f5-b598-d478b0dcb411",
        "parentId" : "5279f2dc-f9a4-46fb-8aa9-2548a68d9ea8",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Yea, it seems that's just a mistake. cc: @dongjoon-hyun  ",
        "createdAt" : "2020-02-23T06:39:24Z",
        "updatedAt" : "2020-02-24T13:37:32Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "6f235bd0-9ef0-4407-acf3-117f2c4c13aa",
        "parentId" : "5279f2dc-f9a4-46fb-8aa9-2548a68d9ea8",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "btw, can you add tests in this suite, too?",
        "createdAt" : "2020-02-23T06:40:45Z",
        "updatedAt" : "2020-02-24T13:37:32Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "419a572b-9ff1-40ed-b881-14ee215aea33",
        "parentId" : "5279f2dc-f9a4-46fb-8aa9-2548a68d9ea8",
        "authorId" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "body" : "I could add something similar to the SQL test to here as well:\r\n```\r\n  test(\"SPARK-30870: Don't alias a nested column if it means the whole attribute\") {\r\n    val valueStructType = StructType.fromDDL(\"field struct<a:int, b:int>\")\r\n    val r = LocalRelation('value.struct(valueStructType))\r\n\r\n    val field = GetStructField('value, 0, Some(\"field\"))\r\n\r\n    val query = r\r\n      .limit(5)\r\n      .select(field)\r\n      .analyze\r\n\r\n    val optimized = Optimize.execute(query)\r\n\r\n    comparePlans(optimized, query)\r\n  }\r\n```\r\nbut it wouldn't be much different to this particular test (`Some nested column means the whole structure`). ",
        "createdAt" : "2020-02-24T13:18:10Z",
        "updatedAt" : "2020-02-24T13:37:32Z",
        "lastEditedBy" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "tags" : [
        ]
      },
      {
        "id" : "0e27c0d6-3a5c-44e5-b3f5-32599871a676",
        "parentId" : "5279f2dc-f9a4-46fb-8aa9-2548a68d9ea8",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Hi, @peter-toth and @maropu .\r\nThe original code is correct, this is not about column pruning. This is about `limit` push down.",
        "createdAt" : "2020-02-24T18:56:47Z",
        "updatedAt" : "2020-02-24T18:57:19Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "ace3417a-4596-4fb5-b44a-6687545e2360",
        "parentId" : "5279f2dc-f9a4-46fb-8aa9-2548a68d9ea8",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "But the test name is `Some nested column means the whole structure`?",
        "createdAt" : "2020-02-24T19:06:28Z",
        "updatedAt" : "2020-02-24T19:06:28Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "6bc39688-494f-4521-9e08-e9d9076deee5",
        "parentId" : "5279f2dc-f9a4-46fb-8aa9-2548a68d9ea8",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Ya. It might be misleading now, but It was `true` in the original context.\r\n- https://github.com/apache/spark/pull/23964",
        "createdAt" : "2020-02-24T19:12:55Z",
        "updatedAt" : "2020-02-24T19:12:55Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "9d430d39-7a08-45f1-9a3e-9259ea38c13c",
        "parentId" : "5279f2dc-f9a4-46fb-8aa9-2548a68d9ea8",
        "authorId" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "body" : "@dongjoon-hyun hmm, does this test have anything to do with limit push down? There is no `LimitPushDown` in the optimizer of this suite: https://github.com/apache/spark/blob/5a51b9472f5dfbf99ef6f8d6c7151618157c446e/sql/catalyst/src/test/scala/org/apache/spark/sql/catalyst/optimizer/NestedColumnAliasingSuite.scala#L34-L39 and actually `limit` is closer to the relation in the original `query` than in `expected`, but I might be wrong.",
        "createdAt" : "2020-02-24T19:16:14Z",
        "updatedAt" : "2020-02-24T19:31:48Z",
        "lastEditedBy" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "tags" : [
        ]
      },
      {
        "id" : "d553fa22-c7c2-46a9-bf16-c317f329ffe2",
        "parentId" : "5279f2dc-f9a4-46fb-8aa9-2548a68d9ea8",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Sorry, I meant a pushdown over `limit`.",
        "createdAt" : "2020-02-24T19:39:57Z",
        "updatedAt" : "2020-02-24T19:39:57Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "52531dde-28a6-4c50-af41-509c25121b2c",
        "parentId" : "5279f2dc-f9a4-46fb-8aa9-2548a68d9ea8",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "`[SPARK-26975][SQL] Support nested-column pruning over limit/sample/repartition` is about that.",
        "createdAt" : "2020-02-24T19:40:11Z",
        "updatedAt" : "2020-02-24T19:40:11Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "855946b2-7402-428f-9b94-c248b8920661",
        "parentId" : "5279f2dc-f9a4-46fb-8aa9-2548a68d9ea8",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Hmm. I got it. So, this is the result of bug fix, isn't it?",
        "createdAt" : "2020-02-24T19:42:02Z",
        "updatedAt" : "2020-02-24T19:42:02Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "1cf36ea2-ee99-4b06-bae2-dfa1bd35fa60",
        "parentId" : "5279f2dc-f9a4-46fb-8aa9-2548a68d9ea8",
        "authorId" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "body" : "Yes, it is. In this test case there is no point in pushing down the `project` over the `limit`.",
        "createdAt" : "2020-02-24T19:51:24Z",
        "updatedAt" : "2020-02-24T19:51:25Z",
        "lastEditedBy" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "tags" : [
        ]
      }
    ],
    "commit" : "e4c900979baffd4f04f3d953b3f0b7ec3c387b2f",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +216,220 @@    val optimized = Optimize.execute(query)\n\n    comparePlans(optimized, query)\n  }\n"
  },
  {
    "id" : "03bd9b48-438c-43e7-ac34-b02726aeaeba",
    "prId" : 24637,
    "prUrl" : "https://github.com/apache/spark/pull/24637#pullrequestreview-252099004",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0efbf561-722f-404f-9a72-d48b8727e7e9",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Yep. This looks like the minimal challenge for now.",
        "createdAt" : "2019-06-20T05:45:02Z",
        "updatedAt" : "2019-07-19T00:53:01Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "0821444a85d30a8ecad1c731ced04bfcd31bb273",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +269,273 @@}\n\nobject NestedColumnAliasingSuite {\n  def collectGeneratedAliases(query: LogicalPlan): ArrayBuffer[String] = {\n    val aliases = ArrayBuffer[String]()"
  },
  {
    "id" : "5da8250a-d4d4-4c67-8277-05e7619b8114",
    "prId" : 24599,
    "prUrl" : "https://github.com/apache/spark/pull/24599#pullrequestreview-240376872",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bb602dde-32fd-4cb2-b547-dc29223368d1",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "There still are many usage of `GetStructField` in this test suite. Maybe make a minor PR to rewrite them.",
        "createdAt" : "2019-05-22T01:53:51Z",
        "updatedAt" : "2019-06-12T00:54:38Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "3aab8bf953fab5e26ebe83f252efb63a9a10d469",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +28,32 @@import org.apache.spark.sql.types.{StringType, StructField, StructType}\n\nclass NestedColumnAliasingSuite extends SchemaPruningTest {\n\n  object Optimize extends RuleExecutor[LogicalPlan] {"
  }
]