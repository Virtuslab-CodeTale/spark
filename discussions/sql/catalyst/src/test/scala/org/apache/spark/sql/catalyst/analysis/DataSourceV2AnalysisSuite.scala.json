[
  {
    "id" : "a5088623-0e76-484f-8028-cf2b0e1bfdb2",
    "prId" : 26293,
    "prUrl" : "https://github.com/apache/spark/pull/26293#pullrequestreview-310946435",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3da8e403-a8e3-4efa-a4b2-09984993fb5f",
        "parentId" : null,
        "authorId" : "75554730-8183-463c-bf1d-7cd5b4e9f22b",
        "body" : "@maropu Review this fix.",
        "createdAt" : "2019-11-04T09:25:16Z",
        "updatedAt" : "2019-11-04T09:25:35Z",
        "lastEditedBy" : "75554730-8183-463c-bf1d-7cd5b4e9f22b",
        "tags" : [
        ]
      }
    ],
    "commit" : "1a4cff0343999409bf01b745f740287a733efa50",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +539,543 @@        \"Cannot write incompatible data to table\", \"'table-name'\",\n        \"Struct 'col' 0-th field name does not match\", \"expected 'a', found 'x'\",\n        \"Struct 'col' 1-th field name does not match\", \"expected 'b', found 'y'\"))\n    }\n  }"
  },
  {
    "id" : "8ef63472-1c14-4bcd-a4a4-5ff964ccc01d",
    "prId" : 25453,
    "prUrl" : "https://github.com/apache/spark/pull/25453#pullrequestreview-277564447",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "87e8cdca-4070-4c44-bed5-6c081bd11008",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "how about creating a temporary dir for loc?",
        "createdAt" : "2019-08-21T00:39:16Z",
        "updatedAt" : "2019-08-22T08:27:31Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "3fc47332-4b87-4c8f-9eb6-40cfa990519e",
        "parentId" : "87e8cdca-4070-4c44-bed5-6c081bd11008",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "This is actually copied from `AnalysisTest`. I think it should be fine.",
        "createdAt" : "2019-08-21T05:30:19Z",
        "updatedAt" : "2019-08-22T08:27:31Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "eb9442cdeadd2ab2232c82a3dfb65055489e4e06",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +123,127 @@    val catalog = new SessionCatalog(new InMemoryCatalog, FunctionRegistry.builtin, conf)\n    catalog.createDatabase(\n      CatalogDatabase(\"default\", \"\", new URI(\"loc\"), Map.empty),\n      ignoreIfExists = false)\n    new Analyzer(catalog, conf) {"
  },
  {
    "id" : "22d01552-ed94-40ea-baa9-bddea7d45d8a",
    "prId" : 24806,
    "prUrl" : "https://github.com/apache/spark/pull/24806#pullrequestreview-248962022",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b34c0b4d-dd37-4b8b-83fd-7bb75c8ec4ed",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "why this change?",
        "createdAt" : "2019-06-12T06:53:19Z",
        "updatedAt" : "2019-06-12T07:04:18Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "5d114586-307b-467c-9a78-0028cf366628",
        "parentId" : "b34c0b4d-dd37-4b8b-83fd-7bb75c8ec4ed",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "In this test case, the error message `\"Cannot safely cast\", \"'x'\", \"DoubleType to FloatType\"` is gone after code changes.\r\nSo I think we should make the test case simpler. The nullability error in the `x` column is enough.",
        "createdAt" : "2019-06-12T07:18:20Z",
        "updatedAt" : "2019-06-12T07:18:20Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "555b4cbf-4a39-43bf-b00c-4373ee8d2ec7",
        "parentId" : "b34c0b4d-dd37-4b8b-83fd-7bb75c8ec4ed",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "No, all errors should be reported: that's exactly what this test case is validating.\r\n\r\nAttempting to write a double to a float column is an error that should be shown, even if there is a nullability error for the column as well.",
        "createdAt" : "2019-06-12T19:08:45Z",
        "updatedAt" : "2019-06-12T19:09:13Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      }
    ],
    "commit" : "3e2949131a8a7579149a7dd4153650461f5b5da2",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +291,295 @@\n    val query = TestRelation(StructType(Seq(\n      StructField(\"x\", FloatType),\n      StructField(\"b\", FloatType))).toAttributes)\n"
  },
  {
    "id" : "fc6b4276-86f0-45f9-91c7-0629d2332b76",
    "prId" : 24806,
    "prUrl" : "https://github.com/apache/spark/pull/24806#pullrequestreview-248573666",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "37585f85-ac8a-47ca-a2dd-2d0f4aa60f40",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ditto",
        "createdAt" : "2019-06-12T06:53:26Z",
        "updatedAt" : "2019-06-12T07:04:18Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "3e2949131a8a7579149a7dd4153650461f5b5da2",
    "line" : 40,
    "diffHunk" : "@@ -1,1 +440,444 @@\n    val query = TestRelation(StructType(Seq(\n      StructField(\"x\", FloatType),\n      StructField(\"b\", FloatType))).toAttributes)\n"
  }
]