[
  {
    "id" : "be4b9901-92c2-4459-86f1-c4d5c0a5455f",
    "prId" : 32213,
    "prUrl" : "https://github.com/apache/spark/pull/32213#pullrequestreview-638296037",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "27a1c1ef-1364-439d-b3b4-d0e91e139df0",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "I didn't add checks for ANSI intervals because there are separate tests for that in the test suite.",
        "createdAt" : "2021-04-18T06:00:10Z",
        "updatedAt" : "2021-04-18T06:00:10Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "7f27f3fc614d65224f81f87b6e8a74c736f2048b",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +193,197 @@    checkArrayLiteral(Array(\"a\", \"b\", \"c\"))\n    checkArrayLiteral(Array(1.0, 4.0))\n    checkArrayLiteral(Array(new CalendarInterval(1, 0, 0), new CalendarInterval(0, 1, 0)))\n    val arr = collection.mutable.WrappedArray.make(Array(1.0, 4.0))\n    checkEvaluation(Literal(arr), toCatalyst(arr))"
  },
  {
    "id" : "16979e80-8e22-4e7b-b860-0f72d76e950b",
    "prId" : 30868,
    "prUrl" : "https://github.com/apache/spark/pull/30868#pullrequestreview-556769176",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9979607a-1155-4404-af4e-d171cf2e8eea",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Is this a user-facing bug? If so, its better to add end-2-end tests, too.",
        "createdAt" : "2020-12-22T00:05:29Z",
        "updatedAt" : "2020-12-22T00:05:29Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "8cd4ea11-c7c6-47d6-ae5e-b0cfb837b313",
        "parentId" : "9979607a-1155-4404-af4e-d171cf2e8eea",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "I think it's not a user-facing bug. User usually use the `Literal.apply` code path and the `Literal.create` is used by Spark self.",
        "createdAt" : "2020-12-22T01:52:42Z",
        "updatedAt" : "2020-12-22T01:52:42Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "9531151d34d20ae39c155811e36189f51a33ca6b",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +336,340 @@      Literal.create(Array(1.toByte, 2.toByte, 3.toByte), BinaryType))\n    assert(Literal(Array(\"1\", \"2\", \"3\")) ==\n      Literal.create(Array(\"1\", \"2\", \"3\"), ArrayType(StringType)))\n  }\n}"
  }
]