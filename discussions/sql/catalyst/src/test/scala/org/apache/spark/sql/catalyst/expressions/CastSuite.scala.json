[
  {
    "id" : "db450853-fc0c-499c-9756-12f778906c47",
    "prId" : 32898,
    "prUrl" : "https://github.com/apache/spark/pull/32898#pullrequestreview-682606880",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ae0baeea-0ffb-43b3-aeb2-17f9240b1f2b",
        "parentId" : null,
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "@pingsutw could you test multiple time zone as the default, similar to https://github.com/apache/spark/pull/32878?\r\nAlso, we should test input strings with time zone like `2021-06-14 15:01:24+08:00` as well, which expects `2021-06-14 15:01:24`.",
        "createdAt" : "2021-06-14T07:02:13Z",
        "updatedAt" : "2021-06-14T07:02:24Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "d07a8e87-22fc-474e-99fc-4aa5f88e89ba",
        "parentId" : "ae0baeea-0ffb-43b3-aeb2-17f9240b1f2b",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "As I mentioned in https://issues.apache.org/jira/browse/SPARK-35720, I don't think we can simply use `stringToTimestamp` here. You will find that when you have more test cases here.",
        "createdAt" : "2021-06-14T07:04:27Z",
        "updatedAt" : "2021-06-14T07:04:27Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "28396dca-e7f4-47f5-8e4d-ed91719a8142",
        "parentId" : "ae0baeea-0ffb-43b3-aeb2-17f9240b1f2b",
        "authorId" : "ceeeb20a-de49-4bcb-b9cf-1347004fd842",
        "body" : "@gengliangwang thanks for the review. Will update ASAP.",
        "createdAt" : "2021-06-14T07:51:20Z",
        "updatedAt" : "2021-06-14T07:51:20Z",
        "lastEditedBy" : "ceeeb20a-de49-4bcb-b9cf-1347004fd842",
        "tags" : [
        ]
      }
    ],
    "commit" : "b17975f024fb0dd66ab60912aa4b63f5008ccea2",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +1298,1302 @@\n  test(\"SPARK-35720: Support casting of String to timestamp without time zone type\") {\n    specialTs.foreach { s =>\n      val expectedTs = LocalDateTime.parse(s)\n      checkEvaluation(cast(Literal(s), TimestampWithoutTZType), expectedTs)"
  },
  {
    "id" : "43759c38-9d82-4967-bd42-d11af1c323ae",
    "prId" : 32869,
    "prUrl" : "https://github.com/apache/spark/pull/32869#pullrequestreview-681070354",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dc4b7657-8290-40bf-86bb-6141d36fba0b",
        "parentId" : null,
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "This is a trivial change for the test case. There is no need to replace the space.",
        "createdAt" : "2021-06-10T17:30:31Z",
        "updatedAt" : "2021-06-10T17:30:31Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "dde4cd800a3d2e9aac55d05b5d99cc00fba0a2e6",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +1257,1261 @@  test(\"SPARK-35711: cast timestamp without time zone to timestamp with local time zone\") {\n    specialTs.foreach { s =>\n      val dt = LocalDateTime.parse(s)\n      checkEvaluation(cast(dt, TimestampType), DateTimeUtils.localDateTimeToMicros(dt))\n    }"
  },
  {
    "id" : "0493788b-e402-4376-a54d-8486d6f29847",
    "prId" : 32846,
    "prUrl" : "https://github.com/apache/spark/pull/32846#pullrequestreview-679874361",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "edba62df-56ae-40d3-9d89-2bae6bf8845c",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can we put `T` in the strings directly?",
        "createdAt" : "2021-06-09T16:11:56Z",
        "updatedAt" : "2021-06-09T16:11:56Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "d9ea3260-5fed-437b-bb58-34de8ca0489d",
        "parentId" : "edba62df-56ae-40d3-9d89-2bae6bf8845c",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "well, the result won't contain the \"T\", so we have to replace one of them eventually.\r\nThe test inputs are from https://github.com/apache/spark/blob/master/sql/catalyst/src/test/scala/org/apache/spark/sql/RandomDataGenerator.scala#L156",
        "createdAt" : "2021-06-09T16:14:21Z",
        "updatedAt" : "2021-06-09T16:14:21Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "814e1076-139b-4072-b6af-fde5d7837cc2",
        "parentId" : "edba62df-56ae-40d3-9d89-2bae6bf8845c",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ah I see, got it",
        "createdAt" : "2021-06-09T16:15:16Z",
        "updatedAt" : "2021-06-09T16:15:16Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "ec0b133846ea0cdabb14a30de1e77709053e9347",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +1716,1720 @@      \"9999-12-31 23:59:59\"  // the last supported timestamp according to SQL standard\n    ).foreach { s =>\n      checkEvaluation(cast(LocalDateTime.parse(s.replace(\" \", \"T\")), StringType), s)\n    }\n  }"
  },
  {
    "id" : "9c9d862d-df7b-417b-85e9-bc8fd65be170",
    "prId" : 32266,
    "prUrl" : "https://github.com/apache/spark/pull/32266#pullrequestreview-648440471",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3daa7c08-c1e4-491d-b1b8-a677be9e5e1e",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Could you add round trip tests: string -> year-month interval -> string, and year-month interval -> string -> year-month interval",
        "createdAt" : "2021-04-21T08:36:21Z",
        "updatedAt" : "2021-04-30T02:48:22Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "060c5871-aeb6-44f7-81b7-6e1e2e4f4a3a",
        "parentId" : "3daa7c08-c1e4-491d-b1b8-a677be9e5e1e",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Could you test corner cases when arithmetic overflow happens. Also test upper and lower cases.",
        "createdAt" : "2021-04-21T08:42:44Z",
        "updatedAt" : "2021-04-30T02:48:22Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "4e2234f6-ed7a-4925-8fe9-2d1084a5a529",
        "parentId" : "3daa7c08-c1e4-491d-b1b8-a677be9e5e1e",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> Could you test corner cases when arithmetic overflow happens. Also test upper and lower cases.\r\n\r\nCurrent test is not correct according to https://github.com/apache/spark/pull/32281, will update after https://github.com/apache/spark/pull/32281 merged",
        "createdAt" : "2021-04-22T07:53:05Z",
        "updatedAt" : "2021-04-30T02:48:22Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "f63d6dcb-3d2d-4248-940e-e6c7f4d921ae",
        "parentId" : "3daa7c08-c1e4-491d-b1b8-a677be9e5e1e",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Please, check the input in lower case.  For example:\r\n```scala\r\n    checkEvaluation(cast(Literal.create(\"  interval '1-0' YEAR TO MONTH  \"),\r\n      YearMonthIntervalType), 12)\r\n```",
        "createdAt" : "2021-04-29T16:53:33Z",
        "updatedAt" : "2021-04-30T02:48:23Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "5ca83abe001897216575fad9f00906de553626c6",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1776,1780 @@  }\n\n  test(\"SPARK-35111: Cast string to year-month interval\") {\n    checkEvaluation(cast(Literal.create(\"INTERVAL '1-0' YEAR TO MONTH\"),\n      YearMonthIntervalType), 12)"
  },
  {
    "id" : "8c710948-2dc0-4ea7-99a0-ee2389764ab1",
    "prId" : 31775,
    "prUrl" : "https://github.com/apache/spark/pull/31775#pullrequestreview-606031136",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "069e3196-d2c6-47cc-97af-b22490c022c8",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "nit: It looks like we don't need to wrap `SQLConf.withExistingConf` now.",
        "createdAt" : "2021-03-08T07:49:10Z",
        "updatedAt" : "2021-03-08T07:49:11Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "6bfb870b9c1bb446c20ac5ae306efdf10a1ddb7a",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +964,968 @@    val activeConf = conf\n    ALL_TIMEZONES.foreach { zid =>\n      def checkCastWithParseError(str: String): Unit = {\n        checkExceptionInExpression[DateTimeException](\n          cast(Literal(str), TimestampType, Option(zid.getId)),"
  },
  {
    "id" : "c4391692-6212-42de-bbd0-ae1f4949f50f",
    "prId" : 31764,
    "prUrl" : "https://github.com/apache/spark/pull/31764#pullrequestreview-606043698",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0cc113d6-0966-4186-aec0-e020d0cc5cab",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "do we have to clone the conf here?",
        "createdAt" : "2021-03-08T04:50:10Z",
        "updatedAt" : "2021-03-08T04:50:10Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "156f9268-7779-48b9-b491-24d03c0ccea4",
        "parentId" : "0cc113d6-0966-4186-aec0-e020d0cc5cab",
        "authorId" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "body" : "agree, I thought that this was a tentative workaround.",
        "createdAt" : "2021-03-08T07:26:45Z",
        "updatedAt" : "2021-03-08T07:26:46Z",
        "lastEditedBy" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "tags" : [
        ]
      },
      {
        "id" : "44f33914-d26f-4b58-826d-a771738c3fb0",
        "parentId" : "0cc113d6-0966-4186-aec0-e020d0cc5cab",
        "authorId" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "body" : "@dongjoon-hyun Can #31775 allow us to revert this?",
        "createdAt" : "2021-03-08T07:35:30Z",
        "updatedAt" : "2021-03-08T07:35:30Z",
        "lastEditedBy" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "tags" : [
        ]
      },
      {
        "id" : "4c954592-2380-4345-96d3-96408db716a9",
        "parentId" : "0cc113d6-0966-4186-aec0-e020d0cc5cab",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "I think so.",
        "createdAt" : "2021-03-08T08:10:07Z",
        "updatedAt" : "2021-03-08T08:10:08Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "ed5c3c0aa37f2e660ec7fafe8ee014716f6ddacc",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +962,966 @@\n  test(\"ANSI mode: cast string to timestamp with parse error\") {\n    val activeConf = conf.clone()\n    new ParVector(ALL_TIMEZONES.toVector).foreach { zid =>\n      def checkCastWithParseError(str: String): Unit = {"
  },
  {
    "id" : "2a609665-ebee-4676-a531-d6f426413cb6",
    "prId" : 30540,
    "prUrl" : "https://github.com/apache/spark/pull/30540#pullrequestreview-540607365",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "01051acc-bc88-4781-87ef-546673f95ca5",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "It doesn't need to make a followup only to fix some nits. We can just do it when we happen to touch the codes around here.",
        "createdAt" : "2020-11-30T03:04:07Z",
        "updatedAt" : "2020-11-30T03:04:07Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "7fd78973-2bb0-4745-bc4a-ee7ff1dff850",
        "parentId" : "01051acc-bc88-4781-87ef-546673f95ca5",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "I am going to approve this PR for this time since it's already open but let's avoid next time.",
        "createdAt" : "2020-11-30T03:04:32Z",
        "updatedAt" : "2020-11-30T03:04:33Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "271d6c4b-84cc-4aba-849a-752e5d73785d",
        "parentId" : "01051acc-bc88-4781-87ef-546673f95ca5",
        "authorId" : "cce1c782-0596-44b6-8b99-6b77d2cca53c",
        "body" : "OK. I got it, will try my best to avoid such issue in future.",
        "createdAt" : "2020-11-30T05:28:58Z",
        "updatedAt" : "2020-11-30T05:28:59Z",
        "lastEditedBy" : "cce1c782-0596-44b6-8b99-6b77d2cca53c",
        "tags" : [
        ]
      }
    ],
    "commit" : "30257d89a3216698caf10c248cecd3c1d11586f8",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +972,976 @@        checkCastWithParseError(\"2015-031-8\")\n        checkCastWithParseError(\"2015-03-18T12:03:17-0:70\")\n        checkCastWithParseError(\"abdef\")\n      }\n    }"
  },
  {
    "id" : "12318761-eb55-4b3f-9924-d5e301a8bea7",
    "prId" : 30442,
    "prUrl" : "https://github.com/apache/spark/pull/30442#pullrequestreview-539976065",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4153dfc9-c575-49a4-a835-06eefc1b50e1",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "is it just `checkCastWithParseError(\"abdef\")`?",
        "createdAt" : "2020-11-27T13:22:17Z",
        "updatedAt" : "2020-11-27T13:22:18Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "e4fe5ee34b47bb5f57aad76fa41caa2c27eee53d",
    "line" : 67,
    "diffHunk" : "@@ -1,1 +957,961 @@\n        val input = \"abdef\"\n        checkExceptionInExpression[DateTimeException](\n          cast(input, TimestampType, Option(zid.getId)),\n          s\"Cannot cast $input to TimestampType.\")"
  },
  {
    "id" : "8ebc043b-767d-47bd-bbbe-161a804230f6",
    "prId" : 30260,
    "prUrl" : "https://github.com/apache/spark/pull/30260#pullrequestreview-528124305",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3878ae19-40f5-45f4-ade3-f27a44e74295",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "(nit and this is not related to this PR though...) `SPARK-22825` -> `SPARK-22825:`",
        "createdAt" : "2020-11-10T02:18:32Z",
        "updatedAt" : "2020-11-18T13:36:51Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "cf340bd3-2b1b-4ef2-81f8-d89bdd942b6c",
        "parentId" : "3878ae19-40f5-45f4-ade3-f27a44e74295",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "I would prefer keeping them unchanged in this PR ",
        "createdAt" : "2020-11-11T12:23:06Z",
        "updatedAt" : "2020-11-18T13:36:51Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "6003bef62c59d623ca59e51532b4fa5006c56fa2",
    "line" : 752,
    "diffHunk" : "@@ -1,1 +1354,1358 @@  }\n\n  test(\"SPARK-22825 Cast array to string\") {\n    val ret1 = cast(Literal.create(Array(1, 2, 3, 4, 5)), StringType)\n    checkEvaluation(ret1, \"[1, 2, 3, 4, 5]\")"
  },
  {
    "id" : "888fe5b0-2374-417c-aed1-5ecbfae8d57b",
    "prId" : 30260,
    "prUrl" : "https://github.com/apache/spark/pull/30260#pullrequestreview-526800432",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8bb531e5-418c-4d4b-bf5c-7308385c1942",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "ditto",
        "createdAt" : "2020-11-10T02:18:44Z",
        "updatedAt" : "2020-11-18T13:36:51Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "6003bef62c59d623ca59e51532b4fa5006c56fa2",
    "line" : 794,
    "diffHunk" : "@@ -1,1 +1396,1400 @@  }\n\n  test(\"SPARK-22973 Cast map to string\") {\n    Seq(\n      false -> (\"{\", \"}\"),"
  },
  {
    "id" : "9a443c2c-8b99-4de5-9edd-ef848b1e2d87",
    "prId" : 30260,
    "prUrl" : "https://github.com/apache/spark/pull/30260#pullrequestreview-526800432",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e865e466-6b04-402d-85d0-49c80dada07c",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "ditto",
        "createdAt" : "2020-11-10T02:18:51Z",
        "updatedAt" : "2020-11-18T13:36:51Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "6003bef62c59d623ca59e51532b4fa5006c56fa2",
    "line" : 828,
    "diffHunk" : "@@ -1,1 +1430,1434 @@  }\n\n  test(\"SPARK-22981 Cast struct to string\") {\n    Seq(\n      false -> (\"{\", \"}\"),"
  },
  {
    "id" : "8c10c737-fde9-42e7-9e39-36221014d656",
    "prId" : 30260,
    "prUrl" : "https://github.com/apache/spark/pull/30260#pullrequestreview-533477857",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cf30b2b8-d18d-4207-9331-d8a8ab651922",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "It's fragile to change global conf. How about we override `test` method and wrap the test funnc with `withSQLConf`?",
        "createdAt" : "2020-11-18T08:52:47Z",
        "updatedAt" : "2020-11-18T13:36:51Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "8a40ad87-b3c2-4abf-9c99-56962c76bcc3",
        "parentId" : "cf30b2b8-d18d-4207-9331-d8a8ab651922",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "For `SQL.get`,  when there is no active SparkSession, it actually creates a new SQLConf instance per thread:\r\n```\r\n/**\r\n * Default config. Only used when there is no active SparkSession for the thread.\r\n * See [[get]] for more information.\r\n */\r\nprivate lazy val fallbackConf = new ThreadLocal[SQLConf] {\r\n  override def initialValue: SQLConf = new SQLConf\r\n}\r\n```\r\nThus we don't need to worry about modifying the SQLConf will break the other concurrent tests here.",
        "createdAt" : "2020-11-18T14:06:01Z",
        "updatedAt" : "2020-11-19T06:36:46Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "6003bef62c59d623ca59e51532b4fa5006c56fa2",
    "line" : 933,
    "diffHunk" : "@@ -1,1 +1512,1516 @@  override def beforeAll(): Unit = {\n    super.beforeAll()\n    SQLConf.get.setConf(SQLConf.ANSI_ENABLED, true)\n  }\n"
  },
  {
    "id" : "31cc167b-596a-4ca1-a669-1939fa7cb586",
    "prId" : 29731,
    "prUrl" : "https://github.com/apache/spark/pull/29731#pullrequestreview-488694250",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "af293e36-7bac-4fb6-9dbe-f68d32dec34c",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Is this behaivour different between ANSI enabled/disabled? I think this test should only include specific behaivours in the ANSI mode.",
        "createdAt" : "2020-09-14T07:18:28Z",
        "updatedAt" : "2020-09-16T05:34:25Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "d23a1771-b878-4233-b3e3-77fb0e15fcf6",
        "parentId" : "af293e36-7bac-4fb6-9dbe-f68d32dec34c",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "Yes. It should throw exception In ANSI mode.",
        "createdAt" : "2020-09-15T13:40:30Z",
        "updatedAt" : "2020-09-16T05:34:25Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      }
    ],
    "commit" : "abf2f7e45b60f15742bf04c47ad1ff6d0ab130dc",
    "line" : 37,
    "diffHunk" : "@@ -1,1 +1432,1436 @@  test(\"Fast fail for cast string type to decimal type in ansi mode\") {\n    checkEvaluation(cast(\"12345678901234567890123456789012345678\", DecimalType(38, 0)),\n      Decimal(\"12345678901234567890123456789012345678\"))\n    checkExceptionInExpression[ArithmeticException](\n      cast(\"123456789012345678901234567890123456789\", DecimalType(38, 0)),"
  },
  {
    "id" : "ed55937a-3340-4662-a127-ba597197e5d4",
    "prId" : 28593,
    "prUrl" : "https://github.com/apache/spark/pull/28593#pullrequestreview-417777351",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0bb30901-f7d5-409f-ab7c-b365d701971c",
        "parentId" : null,
        "authorId" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "body" : "How about the following style to make it small?\r\n\r\n```\r\n  Seq(true, false).foreach { enabled =>\r\n    withSQLConf(SQLConf.LEGACY_AllOW_CAST_NUMERIC_TO_TIMESTAMP.key -> enabled.toString) {\r\n      assert(cast(2.toByte, TimestampType).resolved == enabled)\r\n      ...\r\n    }\r\n  }\r\n```",
        "createdAt" : "2020-05-27T05:21:26Z",
        "updatedAt" : "2020-06-15T17:23:35Z",
        "lastEditedBy" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "tags" : [
        ]
      },
      {
        "id" : "4d1db66c-9428-4c4b-8f7e-81059c81f6ff",
        "parentId" : "0bb30901-f7d5-409f-ab7c-b365d701971c",
        "authorId" : "a67e5600-3f69-4b96-9c53-73795f48a0f6",
        "body" : "Nice !  @kiszk",
        "createdAt" : "2020-05-27T07:09:12Z",
        "updatedAt" : "2020-06-15T17:23:35Z",
        "lastEditedBy" : "a67e5600-3f69-4b96-9c53-73795f48a0f6",
        "tags" : [
        ]
      }
    ],
    "commit" : "12b42396f058569354040d466962904794fa5c5e",
    "line" : 139,
    "diffHunk" : "@@ -1,1 +1337,1341 @@      }\n    }\n  }\n}\n"
  }
]