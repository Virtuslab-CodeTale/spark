[
  {
    "id" : "db450853-fc0c-499c-9756-12f778906c47",
    "prId" : 32898,
    "prUrl" : "https://github.com/apache/spark/pull/32898#pullrequestreview-682606880",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ae0baeea-0ffb-43b3-aeb2-17f9240b1f2b",
        "parentId" : null,
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "@pingsutw could you test multiple time zone as the default, similar to https://github.com/apache/spark/pull/32878?\r\nAlso, we should test input strings with time zone like `2021-06-14 15:01:24+08:00` as well, which expects `2021-06-14 15:01:24`.",
        "createdAt" : "2021-06-14T07:02:13Z",
        "updatedAt" : "2021-06-14T07:02:24Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "d07a8e87-22fc-474e-99fc-4aa5f88e89ba",
        "parentId" : "ae0baeea-0ffb-43b3-aeb2-17f9240b1f2b",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "As I mentioned in https://issues.apache.org/jira/browse/SPARK-35720, I don't think we can simply use `stringToTimestamp` here. You will find that when you have more test cases here.",
        "createdAt" : "2021-06-14T07:04:27Z",
        "updatedAt" : "2021-06-14T07:04:27Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "28396dca-e7f4-47f5-8e4d-ed91719a8142",
        "parentId" : "ae0baeea-0ffb-43b3-aeb2-17f9240b1f2b",
        "authorId" : "ceeeb20a-de49-4bcb-b9cf-1347004fd842",
        "body" : "@gengliangwang thanks for the review. Will update ASAP.",
        "createdAt" : "2021-06-14T07:51:20Z",
        "updatedAt" : "2021-06-14T07:51:20Z",
        "lastEditedBy" : "ceeeb20a-de49-4bcb-b9cf-1347004fd842",
        "tags" : [
        ]
      }
    ],
    "commit" : "b17975f024fb0dd66ab60912aa4b63f5008ccea2",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +1298,1302 @@\n  test(\"SPARK-35720: Support casting of String to timestamp without time zone type\") {\n    specialTs.foreach { s =>\n      val expectedTs = LocalDateTime.parse(s)\n      checkEvaluation(cast(Literal(s), TimestampWithoutTZType), expectedTs)"
  },
  {
    "id" : "43759c38-9d82-4967-bd42-d11af1c323ae",
    "prId" : 32869,
    "prUrl" : "https://github.com/apache/spark/pull/32869#pullrequestreview-681070354",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dc4b7657-8290-40bf-86bb-6141d36fba0b",
        "parentId" : null,
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "This is a trivial change for the test case. There is no need to replace the space.",
        "createdAt" : "2021-06-10T17:30:31Z",
        "updatedAt" : "2021-06-10T17:30:31Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "dde4cd800a3d2e9aac55d05b5d99cc00fba0a2e6",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +1257,1261 @@  test(\"SPARK-35711: cast timestamp without time zone to timestamp with local time zone\") {\n    specialTs.foreach { s =>\n      val dt = LocalDateTime.parse(s)\n      checkEvaluation(cast(dt, TimestampType), DateTimeUtils.localDateTimeToMicros(dt))\n    }"
  },
  {
    "id" : "0493788b-e402-4376-a54d-8486d6f29847",
    "prId" : 32846,
    "prUrl" : "https://github.com/apache/spark/pull/32846#pullrequestreview-679874361",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "edba62df-56ae-40d3-9d89-2bae6bf8845c",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can we put `T` in the strings directly?",
        "createdAt" : "2021-06-09T16:11:56Z",
        "updatedAt" : "2021-06-09T16:11:56Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "d9ea3260-5fed-437b-bb58-34de8ca0489d",
        "parentId" : "edba62df-56ae-40d3-9d89-2bae6bf8845c",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "well, the result won't contain the \"T\", so we have to replace one of them eventually.\r\nThe test inputs are from https://github.com/apache/spark/blob/master/sql/catalyst/src/test/scala/org/apache/spark/sql/RandomDataGenerator.scala#L156",
        "createdAt" : "2021-06-09T16:14:21Z",
        "updatedAt" : "2021-06-09T16:14:21Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "814e1076-139b-4072-b6af-fde5d7837cc2",
        "parentId" : "edba62df-56ae-40d3-9d89-2bae6bf8845c",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ah I see, got it",
        "createdAt" : "2021-06-09T16:15:16Z",
        "updatedAt" : "2021-06-09T16:15:16Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "ec0b133846ea0cdabb14a30de1e77709053e9347",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +1716,1720 @@      \"9999-12-31 23:59:59\"  // the last supported timestamp according to SQL standard\n    ).foreach { s =>\n      checkEvaluation(cast(LocalDateTime.parse(s.replace(\" \", \"T\")), StringType), s)\n    }\n  }"
  },
  {
    "id" : "9c9d862d-df7b-417b-85e9-bc8fd65be170",
    "prId" : 32266,
    "prUrl" : "https://github.com/apache/spark/pull/32266#pullrequestreview-648440471",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3daa7c08-c1e4-491d-b1b8-a677be9e5e1e",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Could you add round trip tests: string -> year-month interval -> string, and year-month interval -> string -> year-month interval",
        "createdAt" : "2021-04-21T08:36:21Z",
        "updatedAt" : "2021-04-30T02:48:22Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "060c5871-aeb6-44f7-81b7-6e1e2e4f4a3a",
        "parentId" : "3daa7c08-c1e4-491d-b1b8-a677be9e5e1e",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Could you test corner cases when arithmetic overflow happens. Also test upper and lower cases.",
        "createdAt" : "2021-04-21T08:42:44Z",
        "updatedAt" : "2021-04-30T02:48:22Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "4e2234f6-ed7a-4925-8fe9-2d1084a5a529",
        "parentId" : "3daa7c08-c1e4-491d-b1b8-a677be9e5e1e",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> Could you test corner cases when arithmetic overflow happens. Also test upper and lower cases.\r\n\r\nCurrent test is not correct according to https://github.com/apache/spark/pull/32281, will update after https://github.com/apache/spark/pull/32281 merged",
        "createdAt" : "2021-04-22T07:53:05Z",
        "updatedAt" : "2021-04-30T02:48:22Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "f63d6dcb-3d2d-4248-940e-e6c7f4d921ae",
        "parentId" : "3daa7c08-c1e4-491d-b1b8-a677be9e5e1e",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Please, check the input in lower case.  For example:\r\n```scala\r\n    checkEvaluation(cast(Literal.create(\"  interval '1-0' YEAR TO MONTH  \"),\r\n      YearMonthIntervalType), 12)\r\n```",
        "createdAt" : "2021-04-29T16:53:33Z",
        "updatedAt" : "2021-04-30T02:48:23Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "5ca83abe001897216575fad9f00906de553626c6",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1776,1780 @@  }\n\n  test(\"SPARK-35111: Cast string to year-month interval\") {\n    checkEvaluation(cast(Literal.create(\"INTERVAL '1-0' YEAR TO MONTH\"),\n      YearMonthIntervalType), 12)"
  },
  {
    "id" : "8c710948-2dc0-4ea7-99a0-ee2389764ab1",
    "prId" : 31775,
    "prUrl" : "https://github.com/apache/spark/pull/31775#pullrequestreview-606031136",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "069e3196-d2c6-47cc-97af-b22490c022c8",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "nit: It looks like we don't need to wrap `SQLConf.withExistingConf` now.",
        "createdAt" : "2021-03-08T07:49:10Z",
        "updatedAt" : "2021-03-08T07:49:11Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "6bfb870b9c1bb446c20ac5ae306efdf10a1ddb7a",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +964,968 @@    val activeConf = conf\n    ALL_TIMEZONES.foreach { zid =>\n      def checkCastWithParseError(str: String): Unit = {\n        checkExceptionInExpression[DateTimeException](\n          cast(Literal(str), TimestampType, Option(zid.getId)),"
  },
  {
    "id" : "c4391692-6212-42de-bbd0-ae1f4949f50f",
    "prId" : 31764,
    "prUrl" : "https://github.com/apache/spark/pull/31764#pullrequestreview-606043698",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0cc113d6-0966-4186-aec0-e020d0cc5cab",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "do we have to clone the conf here?",
        "createdAt" : "2021-03-08T04:50:10Z",
        "updatedAt" : "2021-03-08T04:50:10Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "156f9268-7779-48b9-b491-24d03c0ccea4",
        "parentId" : "0cc113d6-0966-4186-aec0-e020d0cc5cab",
        "authorId" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "body" : "agree, I thought that this was a tentative workaround.",
        "createdAt" : "2021-03-08T07:26:45Z",
        "updatedAt" : "2021-03-08T07:26:46Z",
        "lastEditedBy" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "tags" : [
        ]
      },
      {
        "id" : "44f33914-d26f-4b58-826d-a771738c3fb0",
        "parentId" : "0cc113d6-0966-4186-aec0-e020d0cc5cab",
        "authorId" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "body" : "@dongjoon-hyun Can #31775 allow us to revert this?",
        "createdAt" : "2021-03-08T07:35:30Z",
        "updatedAt" : "2021-03-08T07:35:30Z",
        "lastEditedBy" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "tags" : [
        ]
      },
      {
        "id" : "4c954592-2380-4345-96d3-96408db716a9",
        "parentId" : "0cc113d6-0966-4186-aec0-e020d0cc5cab",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "I think so.",
        "createdAt" : "2021-03-08T08:10:07Z",
        "updatedAt" : "2021-03-08T08:10:08Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "ed5c3c0aa37f2e660ec7fafe8ee014716f6ddacc",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +962,966 @@\n  test(\"ANSI mode: cast string to timestamp with parse error\") {\n    val activeConf = conf.clone()\n    new ParVector(ALL_TIMEZONES.toVector).foreach { zid =>\n      def checkCastWithParseError(str: String): Unit = {"
  },
  {
    "id" : "2a609665-ebee-4676-a531-d6f426413cb6",
    "prId" : 30540,
    "prUrl" : "https://github.com/apache/spark/pull/30540#pullrequestreview-540607365",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "01051acc-bc88-4781-87ef-546673f95ca5",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "It doesn't need to make a followup only to fix some nits. We can just do it when we happen to touch the codes around here.",
        "createdAt" : "2020-11-30T03:04:07Z",
        "updatedAt" : "2020-11-30T03:04:07Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "7fd78973-2bb0-4745-bc4a-ee7ff1dff850",
        "parentId" : "01051acc-bc88-4781-87ef-546673f95ca5",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "I am going to approve this PR for this time since it's already open but let's avoid next time.",
        "createdAt" : "2020-11-30T03:04:32Z",
        "updatedAt" : "2020-11-30T03:04:33Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "271d6c4b-84cc-4aba-849a-752e5d73785d",
        "parentId" : "01051acc-bc88-4781-87ef-546673f95ca5",
        "authorId" : "cce1c782-0596-44b6-8b99-6b77d2cca53c",
        "body" : "OK. I got it, will try my best to avoid such issue in future.",
        "createdAt" : "2020-11-30T05:28:58Z",
        "updatedAt" : "2020-11-30T05:28:59Z",
        "lastEditedBy" : "cce1c782-0596-44b6-8b99-6b77d2cca53c",
        "tags" : [
        ]
      }
    ],
    "commit" : "30257d89a3216698caf10c248cecd3c1d11586f8",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +972,976 @@        checkCastWithParseError(\"2015-031-8\")\n        checkCastWithParseError(\"2015-03-18T12:03:17-0:70\")\n        checkCastWithParseError(\"abdef\")\n      }\n    }"
  },
  {
    "id" : "12318761-eb55-4b3f-9924-d5e301a8bea7",
    "prId" : 30442,
    "prUrl" : "https://github.com/apache/spark/pull/30442#pullrequestreview-539976065",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4153dfc9-c575-49a4-a835-06eefc1b50e1",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "is it just `checkCastWithParseError(\"abdef\")`?",
        "createdAt" : "2020-11-27T13:22:17Z",
        "updatedAt" : "2020-11-27T13:22:18Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "e4fe5ee34b47bb5f57aad76fa41caa2c27eee53d",
    "line" : 67,
    "diffHunk" : "@@ -1,1 +957,961 @@\n        val input = \"abdef\"\n        checkExceptionInExpression[DateTimeException](\n          cast(input, TimestampType, Option(zid.getId)),\n          s\"Cannot cast $input to TimestampType.\")"
  },
  {
    "id" : "8ebc043b-767d-47bd-bbbe-161a804230f6",
    "prId" : 30260,
    "prUrl" : "https://github.com/apache/spark/pull/30260#pullrequestreview-528124305",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3878ae19-40f5-45f4-ade3-f27a44e74295",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "(nit and this is not related to this PR though...) `SPARK-22825` -> `SPARK-22825:`",
        "createdAt" : "2020-11-10T02:18:32Z",
        "updatedAt" : "2020-11-18T13:36:51Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "cf340bd3-2b1b-4ef2-81f8-d89bdd942b6c",
        "parentId" : "3878ae19-40f5-45f4-ade3-f27a44e74295",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "I would prefer keeping them unchanged in this PR ",
        "createdAt" : "2020-11-11T12:23:06Z",
        "updatedAt" : "2020-11-18T13:36:51Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "6003bef62c59d623ca59e51532b4fa5006c56fa2",
    "line" : 752,
    "diffHunk" : "@@ -1,1 +1354,1358 @@  }\n\n  test(\"SPARK-22825 Cast array to string\") {\n    val ret1 = cast(Literal.create(Array(1, 2, 3, 4, 5)), StringType)\n    checkEvaluation(ret1, \"[1, 2, 3, 4, 5]\")"
  },
  {
    "id" : "888fe5b0-2374-417c-aed1-5ecbfae8d57b",
    "prId" : 30260,
    "prUrl" : "https://github.com/apache/spark/pull/30260#pullrequestreview-526800432",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8bb531e5-418c-4d4b-bf5c-7308385c1942",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "ditto",
        "createdAt" : "2020-11-10T02:18:44Z",
        "updatedAt" : "2020-11-18T13:36:51Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "6003bef62c59d623ca59e51532b4fa5006c56fa2",
    "line" : 794,
    "diffHunk" : "@@ -1,1 +1396,1400 @@  }\n\n  test(\"SPARK-22973 Cast map to string\") {\n    Seq(\n      false -> (\"{\", \"}\"),"
  },
  {
    "id" : "9a443c2c-8b99-4de5-9edd-ef848b1e2d87",
    "prId" : 30260,
    "prUrl" : "https://github.com/apache/spark/pull/30260#pullrequestreview-526800432",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e865e466-6b04-402d-85d0-49c80dada07c",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "ditto",
        "createdAt" : "2020-11-10T02:18:51Z",
        "updatedAt" : "2020-11-18T13:36:51Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "6003bef62c59d623ca59e51532b4fa5006c56fa2",
    "line" : 828,
    "diffHunk" : "@@ -1,1 +1430,1434 @@  }\n\n  test(\"SPARK-22981 Cast struct to string\") {\n    Seq(\n      false -> (\"{\", \"}\"),"
  },
  {
    "id" : "8c10c737-fde9-42e7-9e39-36221014d656",
    "prId" : 30260,
    "prUrl" : "https://github.com/apache/spark/pull/30260#pullrequestreview-533477857",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cf30b2b8-d18d-4207-9331-d8a8ab651922",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "It's fragile to change global conf. How about we override `test` method and wrap the test funnc with `withSQLConf`?",
        "createdAt" : "2020-11-18T08:52:47Z",
        "updatedAt" : "2020-11-18T13:36:51Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "8a40ad87-b3c2-4abf-9c99-56962c76bcc3",
        "parentId" : "cf30b2b8-d18d-4207-9331-d8a8ab651922",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "For `SQL.get`,  when there is no active SparkSession, it actually creates a new SQLConf instance per thread:\r\n```\r\n/**\r\n * Default config. Only used when there is no active SparkSession for the thread.\r\n * See [[get]] for more information.\r\n */\r\nprivate lazy val fallbackConf = new ThreadLocal[SQLConf] {\r\n  override def initialValue: SQLConf = new SQLConf\r\n}\r\n```\r\nThus we don't need to worry about modifying the SQLConf will break the other concurrent tests here.",
        "createdAt" : "2020-11-18T14:06:01Z",
        "updatedAt" : "2020-11-19T06:36:46Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "6003bef62c59d623ca59e51532b4fa5006c56fa2",
    "line" : 933,
    "diffHunk" : "@@ -1,1 +1512,1516 @@  override def beforeAll(): Unit = {\n    super.beforeAll()\n    SQLConf.get.setConf(SQLConf.ANSI_ENABLED, true)\n  }\n"
  },
  {
    "id" : "31cc167b-596a-4ca1-a669-1939fa7cb586",
    "prId" : 29731,
    "prUrl" : "https://github.com/apache/spark/pull/29731#pullrequestreview-488694250",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "af293e36-7bac-4fb6-9dbe-f68d32dec34c",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Is this behaivour different between ANSI enabled/disabled? I think this test should only include specific behaivours in the ANSI mode.",
        "createdAt" : "2020-09-14T07:18:28Z",
        "updatedAt" : "2020-09-16T05:34:25Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "d23a1771-b878-4233-b3e3-77fb0e15fcf6",
        "parentId" : "af293e36-7bac-4fb6-9dbe-f68d32dec34c",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "Yes. It should throw exception In ANSI mode.",
        "createdAt" : "2020-09-15T13:40:30Z",
        "updatedAt" : "2020-09-16T05:34:25Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      }
    ],
    "commit" : "abf2f7e45b60f15742bf04c47ad1ff6d0ab130dc",
    "line" : 37,
    "diffHunk" : "@@ -1,1 +1432,1436 @@  test(\"Fast fail for cast string type to decimal type in ansi mode\") {\n    checkEvaluation(cast(\"12345678901234567890123456789012345678\", DecimalType(38, 0)),\n      Decimal(\"12345678901234567890123456789012345678\"))\n    checkExceptionInExpression[ArithmeticException](\n      cast(\"123456789012345678901234567890123456789\", DecimalType(38, 0)),"
  },
  {
    "id" : "ed55937a-3340-4662-a127-ba597197e5d4",
    "prId" : 28593,
    "prUrl" : "https://github.com/apache/spark/pull/28593#pullrequestreview-417777351",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0bb30901-f7d5-409f-ab7c-b365d701971c",
        "parentId" : null,
        "authorId" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "body" : "How about the following style to make it small?\r\n\r\n```\r\n  Seq(true, false).foreach { enabled =>\r\n    withSQLConf(SQLConf.LEGACY_AllOW_CAST_NUMERIC_TO_TIMESTAMP.key -> enabled.toString) {\r\n      assert(cast(2.toByte, TimestampType).resolved == enabled)\r\n      ...\r\n    }\r\n  }\r\n```",
        "createdAt" : "2020-05-27T05:21:26Z",
        "updatedAt" : "2020-06-15T17:23:35Z",
        "lastEditedBy" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "tags" : [
        ]
      },
      {
        "id" : "4d1db66c-9428-4c4b-8f7e-81059c81f6ff",
        "parentId" : "0bb30901-f7d5-409f-ab7c-b365d701971c",
        "authorId" : "a67e5600-3f69-4b96-9c53-73795f48a0f6",
        "body" : "Nice !  @kiszk",
        "createdAt" : "2020-05-27T07:09:12Z",
        "updatedAt" : "2020-06-15T17:23:35Z",
        "lastEditedBy" : "a67e5600-3f69-4b96-9c53-73795f48a0f6",
        "tags" : [
        ]
      }
    ],
    "commit" : "12b42396f058569354040d466962904794fa5c5e",
    "line" : 139,
    "diffHunk" : "@@ -1,1 +1337,1341 @@      }\n    }\n  }\n}\n"
  },
  {
    "id" : "6ee84b61-578c-48b9-bf3c-3c832a6c5632",
    "prId" : 28570,
    "prUrl" : "https://github.com/apache/spark/pull/28570#pullrequestreview-413544286",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5f706e8f-6c71-4229-944f-ad3f6c090550",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "new line",
        "createdAt" : "2020-05-18T12:32:54Z",
        "updatedAt" : "2020-05-18T12:33:29Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "0557f7397328398b80236fed56ed5a6cb3ca3164",
    "line" : 45,
    "diffHunk" : "@@ -1,1 +1383,1387 @@    }\n  }\n}"
  },
  {
    "id" : "2e10916a-405c-42f7-98c8-7b24c0f4078a",
    "prId" : 28570,
    "prUrl" : "https://github.com/apache/spark/pull/28570#pullrequestreview-413544286",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4f808f56-42dd-4d45-bd15-83f4a3004874",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "What is the reason to test all time zones?",
        "createdAt" : "2020-05-18T12:33:15Z",
        "updatedAt" : "2020-05-18T12:33:29Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "0557f7397328398b80236fed56ed5a6cb3ca3164",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +1358,1362 @@    withSQLConf(\n      SQLConf.LONG_TIMESTAMP_CONVERSION_IN_SECONDS.key -> \"false\") {\n      for (tz <- ALL_TIMEZONES) {\n        def checkLongToTimestamp(str: Long, expected: Long): Unit = {\n          checkEvaluation(cast(str, TimestampType, Option(tz.getID)), expected)"
  },
  {
    "id" : "cdf189ac-7d70-4d5e-b190-65c76e2eebec",
    "prId" : 26933,
    "prUrl" : "https://github.com/apache/spark/pull/26933#pullrequestreview-339992459",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "00c798f3-a20a-48de-8c2f-44640ac5521d",
        "parentId" : null,
        "authorId" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "body" : "`cast('nan' as float)` is working fine.\r\nAlthough `CAST(CAST(nan AS DECIMAL(10,0)) AS DOUBLE) ` is returning `NaN` in pgsql.",
        "createdAt" : "2020-01-08T16:37:46Z",
        "updatedAt" : "2020-01-08T16:37:47Z",
        "lastEditedBy" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "tags" : [
        ]
      }
    ],
    "commit" : "0cb4edc3a42badfff3f2ecca7b2ec468ad0f0c2d",
    "line" : 130,
    "diffHunk" : "@@ -1,1 +850,854 @@    Seq(\"nan\", \"nAn\", \" nan \").foreach { value =>\n      checkEvaluation(cast(value, DoubleType), Double.NaN)\n    }\n  }\n"
  },
  {
    "id" : "c0d6fe8e-1094-4269-ba86-f08d13120295",
    "prId" : 26651,
    "prUrl" : "https://github.com/apache/spark/pull/26651#pullrequestreview-322012009",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "376ec99f-e407-42b0-8264-b4d8b1773589",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Shall we check the negative case `ArrayType(IntegerType, true)`, too?",
        "createdAt" : "2019-11-24T18:21:25Z",
        "updatedAt" : "2019-11-25T15:27:05Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "7b7d7c7d-4b29-465d-9f7a-5f9e713edc5b",
        "parentId" : "376ec99f-e407-42b0-8264-b4d8b1773589",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "we set to src array type(`containsNull = false`), then it should be able to convert to the dist both the dist array type is `containsNull` or not. So the case you list here is not negative and it is not a bug. thanks.",
        "createdAt" : "2019-11-25T02:05:25Z",
        "updatedAt" : "2019-11-25T15:27:05Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "ff9d524aea2171ba4a515b50a9d7e52c90d3d090",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +1219,1223 @@  test(\"collect_list/collect_set can cast to ArrayType not containsNull\") {\n    val list = CollectList(Literal(1))\n    assert(Cast.canCast(list.dataType, ArrayType(IntegerType, false)))\n    val set = CollectSet(Literal(1))\n    assert(Cast.canCast(set.dataType, ArrayType(StringType, false)))"
  },
  {
    "id" : "ed52f770-6bfd-4241-a91b-3e395bc43600",
    "prId" : 26651,
    "prUrl" : "https://github.com/apache/spark/pull/26651#pullrequestreview-322011227",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e3104dbb-1e21-483f-b117-bf5be64fedc8",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "And, the following PR description is correct?\r\n```\r\nFix bug. i.e. casting collect_list(a) to ArrayType(_, false) will fail.\r\n```",
        "createdAt" : "2019-11-24T18:23:48Z",
        "updatedAt" : "2019-11-25T15:27:05Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "38de9b7d-4f69-4a61-a0cf-bc5fcd081478",
        "parentId" : "e3104dbb-1e21-483f-b117-bf5be64fedc8",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "Thanks, should be  `Fix bug. i.e. casting collect_list(a) to ArrayType(_, false) will fail **before this fix**.`",
        "createdAt" : "2019-11-25T01:59:53Z",
        "updatedAt" : "2019-11-25T15:27:05Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "ff9d524aea2171ba4a515b50a9d7e52c90d3d090",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +1222,1226 @@    val set = CollectSet(Literal(1))\n    assert(Cast.canCast(set.dataType, ArrayType(StringType, false)))\n  }\n}\n"
  },
  {
    "id" : "73f65f3c-b2e4-451c-a9b0-78c7ac7ad5c9",
    "prId" : 26134,
    "prUrl" : "https://github.com/apache/spark/pull/26134#pullrequestreview-309813055",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ab405c7d-18c7-4811-9f4e-93d9e7a385bb",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "@MaxGekk @dongjoon-hyun this is another instance we can think of: I feel `9 days` is more readable than `1 week 2 days`.",
        "createdAt" : "2019-10-31T11:33:55Z",
        "updatedAt" : "2019-11-01T05:44:13Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "2f901894eb24d7deec31947708b9afdaae2a4866",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +670,674 @@      new CalendarInterval(15, 9, -3 * CalendarInterval.MICROS_PER_HOUR), CalendarIntervalType),\n      StringType),\n      \"interval 1 years 3 months 1 weeks 2 days -3 hours\")\n    checkEvaluation(Cast(Literal(\"INTERVAL 1 Second 1 microsecond\"), CalendarIntervalType),\n      new CalendarInterval(0, 0, 1000001))"
  },
  {
    "id" : "c9d4e261-15bd-47de-bee6-d3d5d375c8b9",
    "prId" : 25997,
    "prUrl" : "https://github.com/apache/spark/pull/25997#pullrequestreview-296697931",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ebe0a599-ab55-4384-aaff-d1285c87abcc",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Can you talk about the rationale of this test refactor? I would keep the test suite unchanged, and just add a few new test cases for `AnsiCastSuite`.\r\n\r\nOne day if we have two totally different cast (like `AnsiCast` and `SafeCast`), then I would refactor the test suite and test these 2 casts separately.\r\n\r\nFor now, `AnsiSuite` is just a special case of `Cast` (with `ansiEnable=true`).",
        "createdAt" : "2019-10-02T09:07:16Z",
        "updatedAt" : "2019-10-03T16:26:28Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "a2c46659-c438-417a-b787-61dc54134d96",
        "parentId" : "ebe0a599-ab55-4384-aaff-d1285c87abcc",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "See the comment in https://github.com/apache/spark/pull/25997#discussion_r330434072\r\nThere are cases that will fail with `AnsiCast`.",
        "createdAt" : "2019-10-02T09:17:04Z",
        "updatedAt" : "2019-10-03T16:26:28Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "a45f0843-62a7-45b9-930b-6c3917c00045",
        "parentId" : "ebe0a599-ab55-4384-aaff-d1285c87abcc",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "The tests create `Cast` and check it with ansi mode on and off. How is it related to `AnsiCast`?",
        "createdAt" : "2019-10-02T13:50:36Z",
        "updatedAt" : "2019-10-03T16:26:28Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "8ecab480-fd2c-4bec-8bea-237598ddeb28",
        "parentId" : "ebe0a599-ab55-4384-aaff-d1285c87abcc",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "My point is, I don't think `AnsiCast` worth a separated suite. It's exactly the same with `Cast` and ansi=true, and we have many tests for it already,",
        "createdAt" : "2019-10-02T13:52:30Z",
        "updatedAt" : "2019-10-03T16:26:28Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "a6d59d0b-94e5-4a1a-aca0-9121c5110883",
        "parentId" : "ebe0a599-ab55-4384-aaff-d1285c87abcc",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "I think we should fully test it for the future development in the new expression.\r\nFor the overflow test cases, we can reduce duplicated code in this way.",
        "createdAt" : "2019-10-03T07:56:22Z",
        "updatedAt" : "2019-10-03T16:26:28Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "1dff96babdd76cf04aae4a1379a7b6811ee34e33",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +36,40 @@import org.apache.spark.unsafe.types.UTF8String\n\nabstract class CastSuiteBase extends SparkFunSuite with ExpressionEvalHelper {\n\n  // Whether it is required to set SQLConf.ANSI_ENABLED as true for testing numeric overflow."
  },
  {
    "id" : "aa32bc3f-23be-4407-9b83-8ad85c462551",
    "prId" : 25980,
    "prUrl" : "https://github.com/apache/spark/pull/25980#pullrequestreview-295596779",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "66bcd728-d7cb-4253-b247-6ad290afe38e",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "`ALL_TIMEZONES` is `Seq` here. Maybe, `ParSeq` instead of `ParVector`?",
        "createdAt" : "2019-10-01T10:43:56Z",
        "updatedAt" : "2019-10-01T13:28:47Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "67b69e0d-f983-4b93-93c3-b608f19ec62a",
        "parentId" : "66bcd728-d7cb-4253-b247-6ad290afe38e",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "ParSeq is a trait unfortunately. I think this is the right impl for this case.",
        "createdAt" : "2019-10-01T13:21:34Z",
        "updatedAt" : "2019-10-01T13:28:47Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      }
    ],
    "commit" : "18b6298d7434e34aa3794f3a78536ac480116167",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +116,120 @@\n  test(\"cast string to timestamp\") {\n    new ParVector(ALL_TIMEZONES.toVector).foreach { tz =>\n      def checkCastStringToTimestamp(str: String, expected: Timestamp): Unit = {\n        checkEvaluation(cast(Literal(str), TimestampType, Option(tz.getID)), expected)"
  },
  {
    "id" : "92b52157-474e-49a8-b2a5-456247a93eff",
    "prId" : 25461,
    "prUrl" : "https://github.com/apache/spark/pull/25461#pullrequestreview-278437582",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8032cf14-92a8-4a23-b57e-f208985aa692",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "the `dt` can only be byte/short/int, can we add an assert?",
        "createdAt" : "2019-08-22T13:57:28Z",
        "updatedAt" : "2019-08-23T08:30:44Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "9f4002c30bb44c120ccf5489874c86d1061f216f",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1077,1081 @@  }\n\n  private def testIntMaxAndMin(dt: DataType): Unit = {\n    assert(Seq(IntegerType, ShortType, ByteType).contains(dt))\n    Seq(Int.MaxValue + 1L, Int.MinValue - 1L).foreach { value =>"
  },
  {
    "id" : "614535ae-9a11-4eee-8d5d-5e8af7572b5d",
    "prId" : 25461,
    "prUrl" : "https://github.com/apache/spark/pull/25461#pullrequestreview-278437669",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "80564a51-18ab-49ff-9d3d-48b437bee737",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ditto",
        "createdAt" : "2019-08-22T13:57:35Z",
        "updatedAt" : "2019-08-23T08:30:44Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "9f4002c30bb44c120ccf5489874c86d1061f216f",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +1091,1095 @@  }\n\n  private def testLongMaxAndMin(dt: DataType): Unit = {\n    assert(Seq(LongType, IntegerType).contains(dt))\n    Seq(Decimal(Long.MaxValue) + Decimal(1), Decimal(Long.MinValue) - Decimal(1)).foreach { value =>"
  },
  {
    "id" : "d15d5f1a-f0b3-4db7-b35a-60f65f954c0a",
    "prId" : 25461,
    "prUrl" : "https://github.com/apache/spark/pull/25461#pullrequestreview-278708166",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3c2e9a92-94ed-4b9f-8aeb-dc858b987564",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "why we need to test `cast int.max +1 to byte`? I think it's good enough to test `cast byte.max +1 to byte`",
        "createdAt" : "2019-08-22T13:59:13Z",
        "updatedAt" : "2019-08-23T08:30:44Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "8056186c-7f60-40a9-ab33-c1964440c6a2",
        "parentId" : "3c2e9a92-94ed-4b9f-8aeb-dc858b987564",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "I think it is always good to have more test cases here if it doesn't increase the testing time by a few seconds.\r\nFor example, \r\nIf casting double to byte is implemented as:\r\n```\r\nval x = doubleValue.toShort\r\nif (x.toByte == x) {\r\n  x.toByte\r\n} else {\r\n  throw new ...\r\n}\r\n```\r\nWe can find that it is wrong with this test case, because\r\n```\r\n (Int.MaxValue+1.0).toShort.toByte == (Int.MaxValue+1.0).toShort\r\n```\r\nis true.",
        "createdAt" : "2019-08-22T21:56:16Z",
        "updatedAt" : "2019-08-23T08:30:44Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "9f4002c30bb44c120ccf5489874c86d1061f216f",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +1105,1109 @@  test(\"Cast to byte with option FAIL_ON_INTEGER_OVERFLOW enabled\") {\n    withSQLConf(SQLConf.FAIL_ON_INTEGRAL_TYPE_OVERFLOW.key -> \"true\") {\n      testIntMaxAndMin(ByteType)\n      Seq(Byte.MaxValue + 1, Byte.MinValue - 1).foreach { value =>\n        checkExceptionInExpression[ArithmeticException](cast(value, ByteType), \"overflow\")"
  },
  {
    "id" : "13474e84-3318-4cfa-b3a9-993ac5192b09",
    "prId" : 25461,
    "prUrl" : "https://github.com/apache/spark/pull/25461#pullrequestreview-278439071",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "53f5457e-24e4-4780-98f5-af56bba39166",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ditto",
        "createdAt" : "2019-08-22T13:59:23Z",
        "updatedAt" : "2019-08-23T08:30:44Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "9f4002c30bb44c120ccf5489874c86d1061f216f",
    "line" : 58,
    "diffHunk" : "@@ -1,1 +1130,1134 @@  test(\"Cast to short with option FAIL_ON_INTEGER_OVERFLOW enabled\") {\n    withSQLConf(SQLConf.FAIL_ON_INTEGRAL_TYPE_OVERFLOW.key -> \"true\") {\n      testIntMaxAndMin(ShortType)\n      Seq(Short.MaxValue + 1, Short.MinValue - 1).foreach { value =>\n        checkExceptionInExpression[ArithmeticException](cast(value, ShortType), \"overflow\")"
  },
  {
    "id" : "95aed0b3-7630-4502-90ac-9181329205d5",
    "prId" : 25458,
    "prUrl" : "https://github.com/apache/spark/pull/25458#pullrequestreview-281846809",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5d3fee4a-9b9f-41bd-8577-e9e7c8103d8d",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "@younggyuchun, just for doubly sure, did you double check the behaviours against PostgreSQL?",
        "createdAt" : "2019-08-23T02:40:52Z",
        "updatedAt" : "2019-08-30T18:32:37Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "328b0922-4431-4be8-9636-fdc771d9a205",
        "parentId" : "5d3fee4a-9b9f-41bd-8577-e9e7c8103d8d",
        "authorId" : "4e84a572-ebe7-42c7-ba1f-55b902bd71ee",
        "body" : "@HyukjinKwon Here it is:\r\n![image](https://user-images.githubusercontent.com/1910477/63601427-62cd5900-c593-11e9-93bc-9a93c8a187d3.png)\r\n",
        "createdAt" : "2019-08-23T14:47:47Z",
        "updatedAt" : "2019-08-30T18:32:37Z",
        "lastEditedBy" : "4e84a572-ebe7-42c7-ba1f-55b902bd71ee",
        "tags" : [
        ]
      },
      {
        "id" : "6e7d2742-d87f-4eb6-94e1-2f4cf347f06a",
        "parentId" : "5d3fee4a-9b9f-41bd-8577-e9e7c8103d8d",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This is not documented: https://www.postgresql.org/docs/devel/datatype-boolean.html\r\n\r\nPostgres may support `of` for history reasons, I don't think we have to follow it.",
        "createdAt" : "2019-08-28T04:37:14Z",
        "updatedAt" : "2019-08-30T18:32:38Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "4df2d326-b7ce-4a9b-9d5f-a30fd9dc2fbf",
        "parentId" : "5d3fee4a-9b9f-41bd-8577-e9e7c8103d8d",
        "authorId" : "4e84a572-ebe7-42c7-ba1f-55b902bd71ee",
        "body" : "@cloud-fan @dongjoon-hyun @HyukjinKwon \r\nThis build accepts several unique prefixes for the boolean data type. For example, tru, tr, ye, fals, fal, fa and of, which are not documented. Do we want to not to accept these prefixes?",
        "createdAt" : "2019-08-28T13:08:08Z",
        "updatedAt" : "2019-08-30T18:32:38Z",
        "lastEditedBy" : "4e84a572-ebe7-42c7-ba1f-55b902bd71ee",
        "tags" : [
        ]
      },
      {
        "id" : "e41b4933-671f-4dcb-a428-341e4f60d572",
        "parentId" : "5d3fee4a-9b9f-41bd-8577-e9e7c8103d8d",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "@cloud-fan . It's a documented feature in that document. We had better support it.\r\n> Unique prefixes of these strings are also accepted, for example t or n. Leading or trailing whitespace is ignored, and case does not matter.\r\n\r\ncc @gatorsmile ",
        "createdAt" : "2019-08-30T01:01:14Z",
        "updatedAt" : "2019-08-30T18:32:38Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "5d9f8a8d-afdb-4331-8618-5bda1e201260",
        "parentId" : "5d3fee4a-9b9f-41bd-8577-e9e7c8103d8d",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "BTW, @younggyuchun . Please add a negative test case.\r\n`o` is not supported because it's not unique. It's a common prefix for `on` and `off`.\r\nIt should be `null`.",
        "createdAt" : "2019-08-30T01:03:48Z",
        "updatedAt" : "2019-08-30T18:32:38Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "3e025bc3-438d-4878-a4ac-e8f1da4e189a",
        "parentId" : "5d3fee4a-9b9f-41bd-8577-e9e7c8103d8d",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Seems okay to me",
        "createdAt" : "2019-08-30T01:33:33Z",
        "updatedAt" : "2019-08-30T18:32:38Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "34bed4b0-d16e-4280-930a-bcb14eec284b",
        "parentId" : "5d3fee4a-9b9f-41bd-8577-e9e7c8103d8d",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "SGTM",
        "createdAt" : "2019-08-30T06:24:28Z",
        "updatedAt" : "2019-08-30T18:32:38Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "b78748379992e37f6d7f550265451e549e0c5cc0",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +845,849 @@    checkCast(\"0\", false)\n    checkCast(\"off\", false)\n    checkCast(\"of\", false)\n\n    checkEvaluation(cast(\"o\", BooleanType), null)"
  },
  {
    "id" : "7604364d-481a-41de-b82a-2a6d4d39c061",
    "prId" : 25458,
    "prUrl" : "https://github.com/apache/spark/pull/25458#pullrequestreview-281802283",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1af52911-10d8-4022-a753-3f9d2c8b2a0a",
        "parentId" : null,
        "authorId" : "4e84a572-ebe7-42c7-ba1f-55b902bd71ee",
        "body" : "@dongjoon-hyun \r\nAdd a negative test for \"o\"",
        "createdAt" : "2019-08-30T02:19:50Z",
        "updatedAt" : "2019-08-30T18:32:38Z",
        "lastEditedBy" : "4e84a572-ebe7-42c7-ba1f-55b902bd71ee",
        "tags" : [
        ]
      }
    ],
    "commit" : "b78748379992e37f6d7f550265451e549e0c5cc0",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +847,851 @@    checkCast(\"of\", false)\n\n    checkEvaluation(cast(\"o\", BooleanType), null)\n    checkEvaluation(cast(\"abc\", BooleanType), null)\n    checkEvaluation(cast(\"\", BooleanType), null)"
  },
  {
    "id" : "56b10211-256d-40df-8dcb-b61ce0e68f00",
    "prId" : 25331,
    "prUrl" : "https://github.com/apache/spark/pull/25331#pullrequestreview-269897980",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8c239d94-5557-4deb-bfab-cea01a968c58",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "nit. empty line.",
        "createdAt" : "2019-08-01T21:52:39Z",
        "updatedAt" : "2019-08-13T05:04:51Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "1a5d978707d519fc6cea5eb7caa1b3fe1eb4933f",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +1046,1050 @@    }\n  }\n\n  test(\"Process Infinity, -Infinity, NaN in case insensitive manner\") {\n    Seq(\"inf\", \"+inf\", \"infinity\", \"+infiNity\", \" infinity \").foreach { value =>"
  },
  {
    "id" : "a165e474-34e9-4aa9-a81f-f69c41471d3e",
    "prId" : 25300,
    "prUrl" : "https://github.com/apache/spark/pull/25300#pullrequestreview-269958810",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0f453978-fc58-4a2e-aaea-841876d3279b",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "In this test, you tried to check this case? https://github.com/apache/spark/pull/25300/files#r309043580\r\nIf so, how about describing what's tested in comments?\r\nAlso, can you add boundary tests for null, e.g.,  `checkEvaluation(cast(214748364?.?f, IntegerType), null)`?",
        "createdAt" : "2019-08-02T02:20:42Z",
        "updatedAt" : "2019-08-02T07:09:25Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "63a6e62dd127f1d774ddf6c823527276d481af1d",
    "line" : 82,
    "diffHunk" : "@@ -1,1 +1102,1106 @@      checkEvaluation(cast(Literal(value * 1.0, DoubleType), IntegerType), value)\n    }\n    checkEvaluation(cast(2147483647.4f, IntegerType), 2147483647)\n    checkEvaluation(cast(-2147483648.4f, IntegerType), -2147483648)\n    checkEvaluation(cast(2147483647.4D, IntegerType), 2147483647)"
  },
  {
    "id" : "b1ba76e0-fd07-4686-ad08-bfdc8daf26a6",
    "prId" : 25300,
    "prUrl" : "https://github.com/apache/spark/pull/25300#pullrequestreview-273289460",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6adec70e-f389-4a49-afe5-ee4fd3efb9fa",
        "parentId" : null,
        "authorId" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "body" : "Is it better to use `????.9` for fraction value to show cutoff truncation semantics? ",
        "createdAt" : "2019-08-09T18:14:16Z",
        "updatedAt" : "2019-08-09T18:14:16Z",
        "lastEditedBy" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "tags" : [
        ]
      }
    ],
    "commit" : "63a6e62dd127f1d774ddf6c823527276d481af1d",
    "line" : 82,
    "diffHunk" : "@@ -1,1 +1102,1106 @@      checkEvaluation(cast(Literal(value * 1.0, DoubleType), IntegerType), value)\n    }\n    checkEvaluation(cast(2147483647.4f, IntegerType), 2147483647)\n    checkEvaluation(cast(-2147483648.4f, IntegerType), -2147483648)\n    checkEvaluation(cast(2147483647.4D, IntegerType), 2147483647)"
  },
  {
    "id" : "86dbf827-ed5f-4c03-b133-8ec4832c0a9e",
    "prId" : 24576,
    "prUrl" : "https://github.com/apache/spark/pull/24576#pullrequestreview-236357082",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6e03cd3c-9705-4d55-98bc-b33790d9b3e9",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Could you simplify this test case like the following by removing three irrelevant fields `a`, `b`, `c`?\r\n```scala\r\n    atomicTypes.foreach { atomicType =>\r\n      val struct = Literal.create(\r\n        InternalRow(null),\r\n        StructType(Seq(StructField(\"d\", NullType, nullable = true))))\r\n\r\n      val ret = cast(struct, StructType(Seq(StructField(\"d\", atomicType, nullable = true))))\r\n      assert(ret.resolved)\r\n      checkEvaluation(ret, InternalRow(null))\r\n    }\r\n```",
        "createdAt" : "2019-05-10T21:53:00Z",
        "updatedAt" : "2019-05-11T10:08:47Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "8b2f2edf-4cc0-4936-aa9d-d63ae40e9a36",
        "parentId" : "6e03cd3c-9705-4d55-98bc-b33790d9b3e9",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Removed.",
        "createdAt" : "2019-05-11T01:39:13Z",
        "updatedAt" : "2019-05-11T10:08:47Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "a5c2416807d720074958eab19e144c54d7ac45b2",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +1005,1009 @@      checkEvaluation(ret, InternalRow(null))\n    }\n  }\n}"
  }
]