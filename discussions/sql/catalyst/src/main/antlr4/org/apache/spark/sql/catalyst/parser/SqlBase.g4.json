[
  {
    "id" : "af510764-c4ca-4990-b018-6f31c5823072",
    "prId" : 32858,
    "prUrl" : "https://github.com/apache/spark/pull/32858#pullrequestreview-681477384",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c49ee2f2-5c12-44b5-8c22-450c2cd62ddc",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Could you update the SQL doc? https://github.com/apache/spark/blame/master/docs/sql-ref-datatypes.md#L197",
        "createdAt" : "2021-06-11T03:12:52Z",
        "updatedAt" : "2021-06-11T03:12:53Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "46c641e1-17cd-4c33-bd1b-d86af55a8faf",
        "parentId" : "c49ee2f2-5c12-44b5-8c22-450c2cd62ddc",
        "authorId" : "c5e50a39-baa7-4db5-8cdd-ad281bb7e7e5",
        "body" : "OK",
        "createdAt" : "2021-06-11T06:05:55Z",
        "updatedAt" : "2021-06-11T06:05:55Z",
        "lastEditedBy" : "c5e50a39-baa7-4db5-8cdd-ad281bb7e7e5",
        "tags" : [
        ]
      }
    ],
    "commit" : "b2aab4bee66baf1f1f17feb1a4df8334951cfccf",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +931,935 @@\ncomplexColType\n    : identifier ':'? dataType (NOT NULL)? commentSpec?\n    ;\n"
  },
  {
    "id" : "f455d30a-0175-4e36-b4ed-df3c729b099b",
    "prId" : 32442,
    "prUrl" : "https://github.com/apache/spark/pull/32442#pullrequestreview-655396422",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8c8591eb-2443-4b42-ab3b-3d32bffe6f9b",
        "parentId" : null,
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "Why do not support `SHOW TABLE EXTENDED`?",
        "createdAt" : "2021-05-10T00:49:40Z",
        "updatedAt" : "2021-05-10T08:41:36Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      },
      {
        "id" : "9ade4fb0-0386-4d76-83a0-f3638a3fabc6",
        "parentId" : "8c8591eb-2443-4b42-ab3b-3d32bffe6f9b",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "OK",
        "createdAt" : "2021-05-10T08:42:02Z",
        "updatedAt" : "2021-05-10T08:42:03Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "3312ac00fad514d9fa68e9b6999f7037cccf15b6",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +364,368 @@informationQuery\n    : SHOW (DATABASES | NAMESPACES) ((FROM | IN) multipartIdentifier)? (LIKE? pattern=STRING)?              #showNamespaces\n    | SHOW TABLES ((FROM | IN) multipartIdentifier)? (LIKE? pattern=STRING)?                                #showTables\n    | SHOW TABLE EXTENDED ((FROM | IN) ns=multipartIdentifier)? LIKE pattern=STRING partitionSpec?          #showTableExtended\n    | SHOW TBLPROPERTIES table=multipartIdentifier ('(' key=tablePropertyKey ')')?                          #showTblProperties"
  },
  {
    "id" : "4993fb8d-8952-4e32-acd1-bba2d7f0e438",
    "prId" : 32303,
    "prUrl" : "https://github.com/apache/spark/pull/32303#pullrequestreview-666322715",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "339e7c1d-7eb3-4e48-99b3-45f5c64af0a6",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Oh, super cleaner than the previous one. Nice.",
        "createdAt" : "2021-05-24T00:25:51Z",
        "updatedAt" : "2021-05-24T01:53:20Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "01fa70ec156ad5540b862c4b13dd1257062f31fb",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +649,653 @@joinRelation\n    : (joinType) JOIN LATERAL? right=relationPrimary joinCriteria?\n    | NATURAL joinType JOIN LATERAL? right=relationPrimary\n    ;\n"
  },
  {
    "id" : "191dc036-9aaf-464c-a0fb-d0cbf6b8764c",
    "prId" : 30648,
    "prUrl" : "https://github.com/apache/spark/pull/30648#pullrequestreview-547907341",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "144d7619-8d60-41c6-ab4d-8a61384d8a23",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "If` identifier` is only for `NOSCAN`, how about defining a new ANTLR token for that?",
        "createdAt" : "2020-12-07T23:35:40Z",
        "updatedAt" : "2021-02-25T03:06:41Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "97d85e23-56eb-4a13-a4d3-e13aa854e821",
        "parentId" : "144d7619-8d60-41c6-ab4d-8a61384d8a23",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "analyze also uses this `identifier `, how about do it in a separate pr?",
        "createdAt" : "2020-12-09T06:59:00Z",
        "updatedAt" : "2021-02-25T03:06:41Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      },
      {
        "id" : "903db6f0-ae19-4dfe-95be-46b3a347093b",
        "parentId" : "144d7619-8d60-41c6-ab4d-8a61384d8a23",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "sgtm",
        "createdAt" : "2020-12-09T07:39:38Z",
        "updatedAt" : "2021-02-25T03:06:41Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "81efb9d1f0dc43b3053d03d3ea183e436a972576",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +136,140 @@        (identifier | FOR COLUMNS identifierSeq | FOR ALL COLUMNS)?    #analyze\n    | ANALYZE TABLES ((FROM | IN) multipartIdentifier)? COMPUTE STATISTICS\n        (identifier)?                                                  #analyzeTables\n    | ALTER TABLE multipartIdentifier\n        ADD (COLUMN | COLUMNS)"
  },
  {
    "id" : "9f9584c4-a0d0-43b1-a6ba-6541ca80c407",
    "prId" : 30332,
    "prUrl" : "https://github.com/apache/spark/pull/30332#pullrequestreview-528729815",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "aa87f0e5-cbef-4032-8441-6c8d00b8ddef",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "nit: `SET configKey (EQ anything)?`",
        "createdAt" : "2020-11-11T13:35:00Z",
        "updatedAt" : "2020-11-12T06:07:38Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "42c0df13-8435-4c0d-b31f-b1c45123cda3",
        "parentId" : "aa87f0e5-cbef-4032-8441-6c8d00b8ddef",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "`anything` is unsuitable as it omits spaces, I have changed the related back to `.*?`",
        "createdAt" : "2020-11-12T03:44:42Z",
        "updatedAt" : "2020-11-12T06:07:38Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "c049bd953a3b01ad3f47173e02ba7f926890d193",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +248,252 @@    | SET TIME ZONE .*?                                                #setTimeZone\n    | SET configKey EQ configValue                                     #setQuotedConfiguration\n    | SET configKey (EQ .*?)?                                          #setQuotedConfiguration\n    | SET .*? EQ configValue                                           #setQuotedConfiguration\n    | SET .*?                                                          #setConfiguration"
  },
  {
    "id" : "6e4f7f8d-84ce-4634-b623-ca89ce4feada",
    "prId" : 30212,
    "prUrl" : "https://github.com/apache/spark/pull/30212#pullrequestreview-539723269",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a7dab057-7ad0-4cd6-9bf0-5d5a9f719b3d",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Why do we still need this def?",
        "createdAt" : "2020-11-24T11:38:38Z",
        "updatedAt" : "2021-03-30T05:55:49Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "7d9631a5-39f1-4a36-9a33-6748633d7cde",
        "parentId" : "a7dab057-7ad0-4cd6-9bf0-5d5a9f719b3d",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> Why do we still need this def?\r\n\r\nGROUP BY A, B grouping sets(a,  (a, b )\r\nGROUP BY A, B `, `grouping sets(a, (a, b))\r\nBoth support , so we still need this.",
        "createdAt" : "2020-11-24T12:16:46Z",
        "updatedAt" : "2021-03-30T05:55:49Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "7adcaba7-bcd7-440d-b761-58df298ba933",
        "parentId" : "a7dab057-7ad0-4cd6-9bf0-5d5a9f719b3d",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "Do you mean  this line ?\r\n```\r\n  | GROUP BY kind=GROUPING SETS '(' groupingSet (',' groupingSet)* ')'\r\n```",
        "createdAt" : "2020-11-24T16:09:02Z",
        "updatedAt" : "2021-03-30T05:55:49Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "5434fcbe-c322-4687-a99b-e90329fde763",
        "parentId" : "a7dab057-7ad0-4cd6-9bf0-5d5a9f719b3d",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "> GROUP BY A, B , grouping sets(a, (a, b))\r\n\r\nAh, you mean `GROUP BY A, B  grouping sets(a, (a, b))`? It seems the parser cannot accpet `GROUP BY A, B , grouping sets(a, (a, b))` now.",
        "createdAt" : "2020-11-27T05:33:38Z",
        "updatedAt" : "2021-03-30T05:55:49Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "f159c543-cd59-43e7-bed9-f212a0e965ed",
        "parentId" : "a7dab057-7ad0-4cd6-9bf0-5d5a9f719b3d",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> > GROUP BY A, B , grouping sets(a, (a, b))\r\n> \r\n> Ah, you mean `GROUP BY A, B grouping sets(a, (a, b))`? It seems the parser cannot accpet `GROUP BY A, B , grouping sets(a, (a, b))`.\r\n\r\nI mean we need  \r\n```\r\n| kind=GROUPING SETS '(' groupingSet (',' groupingSet)* ')')?\r\n```\r\nto support `group by a, b grouping sets(a, (a, b))`\r\nand since we add `GROUPING SET` in   groupingExpressionWithGroupingAnalytics\r\nso we  support `group by a, b, grouping sets(a, (a, b))`. Also \r\n`| GROUP BY kind=GROUPING SETS '(' groupingSet (',' groupingSet)* ')'` this line can be remove since  we add `GROUPING SETS` in  groupingExpressionWithGroupingAnalytics\r\n\r\nCurrently we only support this in grammar, but can't execute because of https://github.com/apache/spark/pull/30144",
        "createdAt" : "2020-11-27T05:41:02Z",
        "updatedAt" : "2021-03-30T05:55:49Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "16ff65a4-2e79-4fdb-b231-63cb01b7bf97",
        "parentId" : "a7dab057-7ad0-4cd6-9bf0-5d5a9f719b3d",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "> since we add GROUPING SET in groupingExpressionWithGroupingAnalytics\r\nso we support group by a, b, grouping sets(a, (a, b))\r\n\r\nCould you add tests?",
        "createdAt" : "2020-11-27T05:45:13Z",
        "updatedAt" : "2021-03-30T05:55:49Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "4f02cc3b-a10c-44c9-b9e5-363dff6448e7",
        "parentId" : "a7dab057-7ad0-4cd6-9bf0-5d5a9f719b3d",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "After this work done the I will change code about https://github.com/apache/spark/pull/30144 base on this pr, then we can support  \r\n` GROUP BY A, B , grouping sets(a, (a, b))`\r\n` GROUP BY A, B , cube(a, (a, b))` etc..",
        "createdAt" : "2020-11-27T05:46:42Z",
        "updatedAt" : "2021-03-30T05:55:49Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "131903b5-931b-4da5-83d8-3de0037420c9",
        "parentId" : "a7dab057-7ad0-4cd6-9bf0-5d5a9f719b3d",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> > since we add GROUPING SET in groupingExpressionWithGroupingAnalytics\r\n> > so we support group by a, b, grouping sets(a, (a, b))\r\n> \r\n> Could you add tests?\r\n\r\nSince for https://github.com/apache/spark/pull/30212#discussion_r531393983\r\nwe just add this test in PlanParserSuite in this pr, ok ?",
        "createdAt" : "2020-11-27T05:55:17Z",
        "updatedAt" : "2021-03-30T05:55:49Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "bfc03afaf9fc0974cb218b3b3121829ae9e5c413",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +594,598 @@      WITH kind=ROLLUP\n    | WITH kind=CUBE\n    | kind=GROUPING SETS '(' groupingSet (',' groupingSet)* ')')?\n    ;\n"
  },
  {
    "id" : "d6cc96c4-72ea-4d20-b9e4-f3d894115e4e",
    "prId" : 30212,
    "prUrl" : "https://github.com/apache/spark/pull/30212#pullrequestreview-539735498",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a869da80-3432-45e8-bbeb-ddd9fa96cd2c",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "If this PR includes the `groupingSet` support for `CUBE`/`ROLLUP`, please add tests for the new feature.",
        "createdAt" : "2020-11-24T11:41:22Z",
        "updatedAt" : "2021-03-30T05:55:49Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "ba827b6b-e63c-4d35-807c-32281bca5272",
        "parentId" : "a869da80-3432-45e8-bbeb-ddd9fa96cd2c",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "`(ROLLUP | CUBE | GROUPING SETS) ` => `kind=(ROLLUP | CUBE | GROUPING SETS) `?",
        "createdAt" : "2020-11-24T11:41:44Z",
        "updatedAt" : "2021-03-30T05:55:49Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "4519597f-67d6-44d2-be09-68d469e934e2",
        "parentId" : "a869da80-3432-45e8-bbeb-ddd9fa96cd2c",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> `(ROLLUP | CUBE | GROUPING SETS) ` => `kind=(ROLLUP | CUBE | GROUPING SETS) `?\r\n\r\nKind can't be assigned to not a set.",
        "createdAt" : "2020-11-24T12:19:26Z",
        "updatedAt" : "2021-03-30T05:55:49Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "da25d79d-88f0-4d9b-ac4f-6200c292f5b4",
        "parentId" : "a869da80-3432-45e8-bbeb-ddd9fa96cd2c",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> If this PR includes the `groupingSet` support for `CUBE`/`ROLLUP`, please add tests for the new feature.\r\n\r\nyea",
        "createdAt" : "2020-11-24T12:20:41Z",
        "updatedAt" : "2021-03-30T05:55:49Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "75727483-047a-4188-bc76-38c8cd65ad4c",
        "parentId" : "a869da80-3432-45e8-bbeb-ddd9fa96cd2c",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "> Kind can't be assigned to a set.\r\n\r\nhttps://github.com/apache/spark/blob/d082ad0abfe0bc26760626ae0ecb415a8d508a1f/sql/catalyst/src/main/antlr4/org/apache/spark/sql/catalyst/parser/SqlBase.g4#L776 ?",
        "createdAt" : "2020-11-27T05:38:20Z",
        "updatedAt" : "2021-03-30T05:55:49Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "72ead8b6-0a0a-4bcd-af80-0746342f7a3c",
        "parentId" : "a869da80-3432-45e8-bbeb-ddd9fa96cd2c",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "==\r\n![image](https://user-images.githubusercontent.com/46485123/100415463-29996800-30b7-11eb-80ea-830f678491d7.png)\r\n![image](https://user-images.githubusercontent.com/46485123/100415472-2d2cef00-30b7-11eb-8a84-b166f6a59760.png)",
        "createdAt" : "2020-11-27T05:48:17Z",
        "updatedAt" : "2021-03-30T05:55:49Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "57fe0d86-25c3-4c2d-85cb-b7cbe013aa32",
        "parentId" : "a869da80-3432-45e8-bbeb-ddd9fa96cd2c",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "Sorry for my mistake in https://github.com/apache/spark/pull/30212#discussion_r529502777\r\n\r\n`Kind can't be assigned to a set. ` is wrong , should be `Kind can't be assigned to not a set.`",
        "createdAt" : "2020-11-27T05:49:33Z",
        "updatedAt" : "2021-03-30T05:55:49Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "1a55714a-8948-40fb-8cff-5dcc96b6b643",
        "parentId" : "a869da80-3432-45e8-bbeb-ddd9fa96cd2c",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ah, ok.",
        "createdAt" : "2020-11-27T06:35:30Z",
        "updatedAt" : "2021-03-30T05:55:50Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "bfc03afaf9fc0974cb218b3b3121829ae9e5c413",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +603,607 @@\ngroupingAnalytics\n    : (ROLLUP | CUBE | GROUPING SETS)  '(' groupingSet (',' groupingSet)* ')'\n    ;\n"
  },
  {
    "id" : "654b9e56-a8bd-40d4-90dc-32e5013b63e0",
    "prId" : 29627,
    "prUrl" : "https://github.com/apache/spark/pull/29627#pullrequestreview-481431562",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f3ec5958-e0c9-4fea-b056-c1c5674370f9",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can you explain how the bug triggers?",
        "createdAt" : "2020-09-02T13:42:25Z",
        "updatedAt" : "2020-09-03T06:32:19Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "2518ece7-981b-4046-8964-0c3c8afaeb0d",
        "parentId" : "f3ec5958-e0c9-4fea-b056-c1c5674370f9",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "OK, I will update pr description after ci passes",
        "createdAt" : "2020-09-02T13:51:04Z",
        "updatedAt" : "2020-09-03T06:32:19Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "4ececc25-69fd-40d0-8f81-b936cb9624d8",
        "parentId" : "f3ec5958-e0c9-4fea-b056-c1c5674370f9",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "Before this PR, these cases will be captured by grammar rule `multiUnitsInterval` but not `typedLiteral`, e.g. for interval '1 day' day, the value is `1 day` and the unit is dayï¼Œ which actually should be parsed as `((interval 1 day) as day)`\r\n\r\nIn this PR, I add a new rule \"INTERVAL STRING AS? identifier? \" to handle interval typed literals(maybe aliasing) and 1-stingvalue-unit interval together and before the rule `multiUnitsInterval`.\r\n\r\nwhen the \"AS\" key is not null, the `STRING` must be the whole context of the interval whether it is valid or not, the identifier should be the alias name or else the \"AS\" itself as alias name.\r\n\r\nwhen the \"AS\" key is null\r\n    1 and when the `STRING` contains any alphabet, we can assume that the  `STRING` is the whole context of the interval whether it is valid or not. the identifier part will be alias name if present\r\n    2 and when the `STRING` contains no alphabet, e.g. '1' day, '-1' day, '\\t1' day, so the identifier here should be the unit part whether it is valid or not.\r\n\r\nAlso updated in PR desc.",
        "createdAt" : "2020-09-02T14:15:52Z",
        "updatedAt" : "2020-09-03T06:32:19Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "d4b90d4b-f9bd-4b7f-99d0-f1cadbd0d9b9",
        "parentId" : "f3ec5958-e0c9-4fea-b056-c1c5674370f9",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can you check `interval '1 day' day` in other systems? To see if they also treat '1 day' as the number of days and fail.",
        "createdAt" : "2020-09-02T16:19:20Z",
        "updatedAt" : "2020-09-03T06:32:19Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "cd22d626-549d-439d-ad05-3918bf0e8472",
        "parentId" : "f3ec5958-e0c9-4fea-b056-c1c5674370f9",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "```\r\npostgres=# select interval '1 day' day;\r\n interval\r\n----------\r\n 1 day\r\n(1 row)\r\n\r\npostgres=# select interval '1' day day;\r\nERROR:  syntax error at or near \"day\"\r\nLINE 1: select interval '1' day day;\r\n                                ^\r\npostgres=# select interval '1' day;\r\n interval\r\n----------\r\n 1 day\r\n(1 row)\r\n```\r\n\r\n\r\n\r\n",
        "createdAt" : "2020-09-03T01:58:07Z",
        "updatedAt" : "2020-09-03T06:32:19Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "7141f28c-3d5e-42e8-8453-8768a4790f27",
        "parentId" : "f3ec5958-e0c9-4fea-b056-c1c5674370f9",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "```sql\r\npresto> select interval '1 day' day;\r\nQuery 20200903_015817_00008_gec8v failed: Invalid INTERVAL DAY value: 1 day\r\n\r\npresto> select interval '1' day day;\r\n      day\r\n----------------\r\n 1 00:00:00.000\r\n(1 row)\r\n\r\nQuery 20200903_015821_00009_gec8v, FINISHED, 1 node\r\nSplits: 17 total, 17 done (100.00%)\r\n0:00 [0 rows, 0B] [0 rows/s, 0B/s]\r\n\r\npresto> select interval '1' day;\r\n     _col0\r\n----------------\r\n 1 00:00:00.000\r\n(1 row)\r\n\r\nQuery 20200903_015825_00010_gec8v, FINISHED, 1 node\r\nSplits: 17 total, 17 done (100.00%)\r\n0:00 [0 rows, 0B] [0 rows/s, 0B/s]\r\n\r\npresto>\r\n```",
        "createdAt" : "2020-09-03T01:58:53Z",
        "updatedAt" : "2020-09-03T06:32:19Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "34c3801a-52fa-4857-b6ab-9f9ce17792ba",
        "parentId" : "f3ec5958-e0c9-4fea-b056-c1c5674370f9",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "presto does not support typed literal for intervals",
        "createdAt" : "2020-09-03T02:01:14Z",
        "updatedAt" : "2020-09-03T06:32:19Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "0ea121ee778243fb229ddbf70474c9dc37159e11",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +819,823 @@constant\n    : NULL                                                                                     #nullLiteral\n    | INTERVAL STRING AS? identifier?                                                          #maybeAliasedIntervalLiteral\n    | interval                                                                                 #intervalLiteral\n    | identifier STRING                                                                        #typeConstructor"
  },
  {
    "id" : "5e97ff45-c9c3-4b73-808f-f5f1eff7e70e",
    "prId" : 29064,
    "prUrl" : "https://github.com/apache/spark/pull/29064#pullrequestreview-447091917",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b4c88d7f-50c9-4385-91c3-b011e3e3d32c",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "so we add this only for better parser message?",
        "createdAt" : "2020-07-13T09:31:11Z",
        "updatedAt" : "2020-07-16T09:19:56Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "9e6fa174-0532-498f-96fe-a72821ffd657",
        "parentId" : "b4c88d7f-50c9-4385-91c3-b011e3e3d32c",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "this is used to fail invalid set time zone syntax explicitly, cuz' now we support \r\n\r\n```sql\r\nspark-sql (default)> set time zone abcd;\r\nkey\tvalue\r\ntime zone abcd\t<undefined>\r\n```",
        "createdAt" : "2020-07-13T09:39:20Z",
        "updatedAt" : "2020-07-16T09:19:56Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "a4c60f3c84f2e1a90eea87fbc41d35741519f5af",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +243,247 @@    | SET TIME ZONE interval                                           #setTimeZone\n    | SET TIME ZONE timezone=(STRING | LOCAL)                          #setTimeZone\n    | SET TIME ZONE .*?                                                #setTimeZone\n    | SET .*?                                                          #setConfiguration\n    | RESET                                                            #resetConfiguration"
  },
  {
    "id" : "832a2011-6849-4726-8ea5-294ea23ed032",
    "prId" : 29064,
    "prUrl" : "https://github.com/apache/spark/pull/29064#pullrequestreview-468265044",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "212cc2b7-acfb-4d85-8f24-adc0ec8aeb66",
        "parentId" : null,
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "It sounds like none of the systems are following ANSI SQL syntax completely. \r\n\r\n- https://www.ibm.com/support/knowledgecenter/SSEPEK_10.0.0/sqlref/src/tpc/db2z_sql_setsessiontimezone.html\r\n- https://www.postgresql.org/docs/12/sql-set.html\r\n- https://dev.mysql.com/doc/refman/8.0/en/time-zone-support.html\r\n- https://docs.oracle.com/cd/E11882_01/server.112/e10729/ch4datetime.htm#NLSPG263\r\n",
        "createdAt" : "2020-08-16T03:57:40Z",
        "updatedAt" : "2020-08-16T03:58:01Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      },
      {
        "id" : "b2ee5d06-479e-4be3-a5d5-259ee4bca8b4",
        "parentId" : "212cc2b7-acfb-4d85-8f24-adc0ec8aeb66",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "We are close to the DB2 syntax, except that we support interval and `LOCAL`, and we don't allow the optional `SESSION` keyword.",
        "createdAt" : "2020-08-17T08:27:08Z",
        "updatedAt" : "2020-08-17T08:27:08Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "a4c60f3c84f2e1a90eea87fbc41d35741519f5af",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +243,247 @@    | SET TIME ZONE interval                                           #setTimeZone\n    | SET TIME ZONE timezone=(STRING | LOCAL)                          #setTimeZone\n    | SET TIME ZONE .*?                                                #setTimeZone\n    | SET .*?                                                          #setConfiguration\n    | RESET                                                            #resetConfiguration"
  },
  {
    "id" : "0c7789dc-3f51-45bc-913a-57afd1fa656a",
    "prId" : 28840,
    "prUrl" : "https://github.com/apache/spark/pull/28840#pullrequestreview-433725502",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "362257ae-9ad4-4da2-9bf5-6dd0861c490c",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "nit. Shall we put this before `REFRESH TABLE`?",
        "createdAt" : "2020-06-18T22:00:47Z",
        "updatedAt" : "2020-07-21T12:12:05Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "59898c7a-12b6-459a-9946-bf680834c723",
        "parentId" : "362257ae-9ad4-4da2-9bf5-6dd0861c490c",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "Sorry for that is there any reason ?  Seems existing function command always after the table.",
        "createdAt" : "2020-06-19T00:11:01Z",
        "updatedAt" : "2020-07-21T12:12:05Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      },
      {
        "id" : "34ffe4a6-2269-4210-a608-8367c2fcab75",
        "parentId" : "362257ae-9ad4-4da2-9bf5-6dd0861c490c",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Oh, never mind. You're right.",
        "createdAt" : "2020-06-19T00:14:19Z",
        "updatedAt" : "2020-07-21T12:12:05Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "b18437c5998f5df50172732015f66b33c3908d2a",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +230,234 @@    | COMMENT ON TABLE multipartIdentifier IS comment=(STRING | NULL)  #commentTable\n    | REFRESH TABLE multipartIdentifier                                #refreshTable\n    | REFRESH FUNCTION multipartIdentifier                             #refreshFunction\n    | REFRESH (STRING | .*?)                                           #refreshResource\n    | CACHE LAZY? TABLE multipartIdentifier"
  },
  {
    "id" : "6ee0326a-0f45-43dc-b759-d4407dc43996",
    "prId" : 28026,
    "prUrl" : "https://github.com/apache/spark/pull/28026#pullrequestreview-382209907",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c9399ae7-75f9-4d1d-b723-9dbbeb3e9ccf",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "shall we put `tableProvider` into `createTableClauses` as well?",
        "createdAt" : "2020-03-26T03:36:06Z",
        "updatedAt" : "2020-11-24T17:03:15Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "bf276dc2-7fb6-45a6-92ab-a0046c18a627",
        "parentId" : "c9399ae7-75f9-4d1d-b723-9dbbeb3e9ccf",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "You're welcome to do that in a follow-up. Here, I'm avoiding unnecessary changes.",
        "createdAt" : "2020-03-26T16:53:56Z",
        "updatedAt" : "2020-11-24T17:03:15Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      }
    ],
    "commit" : "25ec746753f29acd5e248d03db48211a3876a7c1",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +120,124 @@    | SHOW (DATABASES | NAMESPACES) ((FROM | IN) multipartIdentifier)?\n        (LIKE? pattern=STRING)?                                        #showNamespaces\n    | createTableHeader ('(' colTypeList ')')? tableProvider?\n        createTableClauses\n        (AS? query)?                                                   #createTable"
  },
  {
    "id" : "3c90748c-6c64-412d-a816-d1a8015b10ca",
    "prId" : 28026,
    "prUrl" : "https://github.com/apache/spark/pull/28026#pullrequestreview-382783999",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7cc58715-c3ae-457a-bedc-24b6272fe053",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "It's a bit weird if we allow mixed usage, like `PARTITION BY (year(a), b string)`, shall we just define 2 `PARTITIONED BY` clauses?",
        "createdAt" : "2020-03-26T03:37:45Z",
        "updatedAt" : "2020-11-24T17:03:15Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "8dd32eac-8ab8-40e9-b6c0-7964bb4821d6",
        "parentId" : "7cc58715-c3ae-457a-bedc-24b6272fe053",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "This is allowed in the grammar to give a better error message later. Otherwise it is confusing that `b string` works sometimes, but not others.",
        "createdAt" : "2020-03-26T16:53:23Z",
        "updatedAt" : "2020-11-24T17:03:15Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "6af54972-c8dc-4245-a2ae-5a444525e23b",
        "parentId" : "7cc58715-c3ae-457a-bedc-24b6272fe053",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "I'd understand that we will have assertion to force using only one side of pattern at a time.",
        "createdAt" : "2020-03-27T11:41:09Z",
        "updatedAt" : "2020-11-24T17:03:15Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      }
    ],
    "commit" : "25ec746753f29acd5e248d03db48211a3876a7c1",
    "line" : 54,
    "diffHunk" : "@@ -1,1 +738,742 @@    ;\n\npartitionField\n    : transform  #partitionTransform\n    | colType    #partitionColumn"
  },
  {
    "id" : "47fa97d8-9fbc-48e8-978b-0fc8d431e3ea",
    "prId" : 28026,
    "prUrl" : "https://github.com/apache/spark/pull/28026#pullrequestreview-515853457",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "96772d2d-c9bf-4ba7-b6c2-715460d3a1a4",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I think an easier way to merge the two syntaxes is\r\n```\r\n(PARTITIONED BY partitioning=partitionFieldList) |\r\n(PARTITIONED BY '(' partitionColumns=colTypeList ')' |\r\n```\r\nThen antlr can help us to guarantee that users can't mix different PARTITION BY syntaxes, and it requires fewer changes in `AstBuilder`.",
        "createdAt" : "2020-10-22T12:15:01Z",
        "updatedAt" : "2020-11-24T17:03:15Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "2e974ea7-8bf1-4765-94da-403897fe51f3",
        "parentId" : "96772d2d-c9bf-4ba7-b6c2-715460d3a1a4",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "The result of doing this is a worse error message for a user because the parser would generate an error, instead of the user-friendly error message that is generated by `AstBuilder`. I think an overall worse experience for users isn't worth changing this.",
        "createdAt" : "2020-10-23T17:07:14Z",
        "updatedAt" : "2020-11-24T17:03:15Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      }
    ],
    "commit" : "25ec746753f29acd5e248d03db48211a3876a7c1",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +383,387 @@createTableClauses\n    :((OPTIONS options=tablePropertyList) |\n     (PARTITIONED BY partitioning=partitionFieldList) |\n     skewSpec |\n     bucketSpec |"
  },
  {
    "id" : "ef201f64-55a4-44a6-b2aa-9d8d8a863037",
    "prId" : 27920,
    "prUrl" : "https://github.com/apache/spark/pull/27920#pullrequestreview-391991387",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "48d69464-7703-4ed3-bbfb-a4b42b6633fe",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Please add tests in `PlanParserSuite`, too.",
        "createdAt" : "2020-04-13T07:04:51Z",
        "updatedAt" : "2020-04-13T13:03:50Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "0571f21a0c058e0e1c14efd54e174d64f9420b01",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1815,1819 @@\nSIMPLE_COMMENT\n    : '--' ('\\\\\\n' | ~[\\r\\n])* '\\r'? '\\n'? -> channel(HIDDEN)\n    ;\n"
  },
  {
    "id" : "ccc68d30-7e58-49a5-9c04-86a32c8c156b",
    "prId" : 27920,
    "prUrl" : "https://github.com/apache/spark/pull/27920#pullrequestreview-407062394",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "31d36f4f-ce90-4c5f-9b40-619bb2c71d7d",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ur, one more comment; could you add tests in `sql-tests/inputs/comments.sql`, too?",
        "createdAt" : "2020-05-06T23:50:21Z",
        "updatedAt" : "2020-05-06T23:50:21Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "0571f21a0c058e0e1c14efd54e174d64f9420b01",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1815,1819 @@\nSIMPLE_COMMENT\n    : '--' ('\\\\\\n' | ~[\\r\\n])* '\\r'? '\\n'? -> channel(HIDDEN)\n    ;\n"
  },
  {
    "id" : "acbb8950-c9e8-43c8-a791-b4bd48e4fc7c",
    "prId" : 27897,
    "prUrl" : "https://github.com/apache/spark/pull/27897#pullrequestreview-374024597",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1ac81055-9617-4467-9a6e-ab126d6271af",
        "parentId" : null,
        "authorId" : "c48b13f0-9ce5-4910-a8eb-aee1ac73ffcb",
        "body" : "fix indent",
        "createdAt" : "2020-03-13T03:02:10Z",
        "updatedAt" : "2020-04-07T16:02:30Z",
        "lastEditedBy" : "c48b13f0-9ce5-4910-a8eb-aee1ac73ffcb",
        "tags" : [
        ]
      }
    ],
    "commit" : "f6132c0e40e8cd20ed9620f27ad5ba0983891a3f",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +175,179 @@    | ALTER (TABLE | VIEW) multipartIdentifier\n        UNSET TBLPROPERTIES (IF EXISTS)? tablePropertyList             #unsetTableProperties\n    | ALTER TABLE table=multipartIdentifier\n        (ALTER | CHANGE) COLUMN? column=multipartIdentifier\n        alterColumnAction?                                             #alterTableAlterColumn"
  },
  {
    "id" : "6d943f9a-dbca-4713-95ed-f4a508238635",
    "prId" : 27495,
    "prUrl" : "https://github.com/apache/spark/pull/27495#pullrequestreview-361839749",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a9635ad8-06e0-4644-bd5b-565fbff0e00e",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "the hint and comment syntax are so similar and it's too hacky to put one as parser rule and one as lexer rule.\r\n\r\nYour fix looks correct, but it's hard to reason about and @gengliangwang has pointed our issues twice.\r\n\r\nI think we should make them both parser rules (hint needs to create a plan so can't be lexer rule)",
        "createdAt" : "2020-02-18T04:57:01Z",
        "updatedAt" : "2020-02-21T11:33:15Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "1d58e23d-d1a3-427d-9048-b9e33a49cac4",
        "parentId" : "a9635ad8-06e0-4644-bd5b-565fbff0e00e",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "+1 with @cloud-fan \r\nThe latest code will still fail\r\n```\r\n/*/*foo*//*bar*/*/\r\n```\r\nsince you just match the starting `BRACKETED_EMPTY_COMMENT` once.",
        "createdAt" : "2020-02-18T05:00:01Z",
        "updatedAt" : "2020-02-21T11:33:15Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "c5dc2c98-ab70-4a81-9aa6-7d458f91be7d",
        "parentId" : "a9635ad8-06e0-4644-bd5b-565fbff0e00e",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "I think even though to create a plan, we still need to distinguish hint and comment syntax.\r\n@gengliangwang I improve the syntax again, please take a look again.",
        "createdAt" : "2020-02-18T05:52:56Z",
        "updatedAt" : "2020-02-21T11:33:15Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      },
      {
        "id" : "38943dd4-0c9a-48ac-8d65-d453f2c94dfa",
        "parentId" : "a9635ad8-06e0-4644-bd5b-565fbff0e00e",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "> we still need to distinguish hint and comment syntax\r\n\r\nWe can distinguish them better if they are both parser rules.",
        "createdAt" : "2020-02-18T06:06:31Z",
        "updatedAt" : "2020-02-21T11:33:15Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "00eff200-6826-4f1f-8ae7-46efce22b689",
        "parentId" : "a9635ad8-06e0-4644-bd5b-565fbff0e00e",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "If this problem could be solved in g4, things would be even simpler. Let me do some hard work and try.",
        "createdAt" : "2020-02-18T06:37:20Z",
        "updatedAt" : "2020-02-21T11:33:15Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      },
      {
        "id" : "5fba3b64-a561-440b-995d-4a412d715b49",
        "parentId" : "a9635ad8-06e0-4644-bd5b-565fbff0e00e",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Since hint can appear at any position, it's not possible to create a parser rule for it.",
        "createdAt" : "2020-02-20T11:50:23Z",
        "updatedAt" : "2020-02-21T11:33:15Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "48814c356794ea97191c09416958296be5b01e7f",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +1813,1817 @@    ;\n\nBRACKETED_COMMENT\n    : '/*' {!isHint()}? (BRACKETED_COMMENT|.)*? '*/' -> channel(HIDDEN)\n    ;"
  },
  {
    "id" : "20256735-d713-4af0-840b-af02112139a2",
    "prId" : 27345,
    "prUrl" : "https://github.com/apache/spark/pull/27345#pullrequestreview-347453640",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7d628a6f-0629-4d2d-82a9-c99558f3fab3",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "TODO: move it to a separate PR.",
        "createdAt" : "2020-01-23T16:52:15Z",
        "updatedAt" : "2020-01-23T17:32:27Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "f10d256a99de9505b4ebd761bb86e485f7bf8493",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +134,138 @@        locationSpec |\n        (TBLPROPERTIES tableProps=tablePropertyList))*                 #createTableLike\n    | replaceTableHeader ('(' colTypeList ')')? tableProvider?\n        createTableClauses\n        (AS? query)?                                                   #replaceTable"
  },
  {
    "id" : "fec01d20-9c39-4fe9-bfae-11344a62ef4c",
    "prId" : 27076,
    "prUrl" : "https://github.com/apache/spark/pull/27076#pullrequestreview-337772957",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f35a940c-e19c-4ca3-bb07-e9f09d4e820f",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "`colName` was `errorCapturingIdentifier` before. We want it to be `multipartIdentifier`?",
        "createdAt" : "2020-01-02T16:55:50Z",
        "updatedAt" : "2020-01-02T16:55:50Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "237e82bd-dbc0-44ef-924c-ab351656e070",
        "parentId" : "f35a940c-e19c-4ca3-bb07-e9f09d4e820f",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Though it is fine because `ResolveSessionCatalog` will detect and throw `AnalysisException(\"ALTER COLUMN with qualified column is only supported with v2 tables.\")`.",
        "createdAt" : "2020-01-02T17:00:42Z",
        "updatedAt" : "2020-01-02T17:00:42Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "1302aa4b-7f85-445e-a8a5-65c9058416d6",
        "parentId" : "f35a940c-e19c-4ca3-bb07-e9f09d4e820f",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This is to be consistent with the other ALTER COLUMN syntax.",
        "createdAt" : "2020-01-02T17:43:23Z",
        "updatedAt" : "2020-01-02T17:43:23Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "e8cd5334178879a98d7735d236d189e19a635754",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +164,168 @@    | ALTER TABLE table=multipartIdentifier partitionSpec?\n        CHANGE COLUMN?\n        colName=multipartIdentifier colType colPosition?               #hiveChangeColumn\n    | ALTER TABLE multipartIdentifier (partitionSpec)?\n        SET SERDE STRING (WITH SERDEPROPERTIES tablePropertyList)?     #setTableSerDe"
  },
  {
    "id" : "c61440d8-0ac3-4775-863e-371a79dc15a9",
    "prId" : 27027,
    "prUrl" : "https://github.com/apache/spark/pull/27027#pullrequestreview-337007082",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a77f3565-dcfb-4034-a9c0-3260e2b76b52",
        "parentId" : null,
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "Should commands like `USE NAMESPACE` and `SHOW CURRENT NAMESPACE ` utilize `namespace`?",
        "createdAt" : "2019-12-28T03:34:52Z",
        "updatedAt" : "2019-12-28T03:34:52Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      },
      {
        "id" : "561572a9-0e3b-4e08-aee2-46482f2f4e5d",
        "parentId" : "a77f3565-dcfb-4034-a9c0-3260e2b76b52",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "For new commands, I think we shouldn't support DATABASE.",
        "createdAt" : "2019-12-30T06:11:46Z",
        "updatedAt" : "2019-12-30T06:11:46Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "0931abd526332c6093ddecb866eb92a66534e3c8",
    "line" : 3,
    "diffHunk" : "@@ -1,1 +95,99 @@    : query                                                            #statementDefault\n    | ctes? dmlStatementNoWith                                         #dmlStatement\n    | USE NAMESPACE? multipartIdentifier                               #use\n    | CREATE namespace (IF NOT EXISTS)? multipartIdentifier\n        ((COMMENT comment=STRING) |"
  },
  {
    "id" : "7838c17f-7323-44a6-83f3-f87533b7d131",
    "prId" : 26779,
    "prUrl" : "https://github.com/apache/spark/pull/26779#pullrequestreview-330038061",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6746c23f-c269-4ec8-9cc5-90c39a1ab031",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "should it be `(STRING | .*)?`",
        "createdAt" : "2019-12-10T03:25:23Z",
        "updatedAt" : "2019-12-11T08:22:47Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "078c4387-148f-4f58-972a-87fe497ef6f4",
        "parentId" : "6746c23f-c269-4ec8-9cc5-90c39a1ab031",
        "authorId" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "body" : "I think (STRING | .*?) should also work fine. ",
        "createdAt" : "2019-12-10T04:35:54Z",
        "updatedAt" : "2019-12-11T08:22:47Z",
        "lastEditedBy" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "tags" : [
        ]
      },
      {
        "id" : "f41f35b5-7202-42a6-b123-8b68904ae4ee",
        "parentId" : "6746c23f-c269-4ec8-9cc5-90c39a1ab031",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "yea, but isn't `(STRING | .*)?` more logical? or there are some perf concerns?",
        "createdAt" : "2019-12-10T11:51:35Z",
        "updatedAt" : "2019-12-11T08:22:47Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "96963828-827f-42c9-855c-c2899fb2d52e",
        "parentId" : "6746c23f-c269-4ec8-9cc5-90c39a1ab031",
        "authorId" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "body" : "`(STRING | .*)?` will do greedy matching. `.*` will take any amount of input and thus its made non-greedy by using `.*?` .",
        "createdAt" : "2019-12-10T17:00:22Z",
        "updatedAt" : "2019-12-11T08:22:47Z",
        "lastEditedBy" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "tags" : [
        ]
      },
      {
        "id" : "e558dbec-d0d9-447e-9f2f-0908cd9c916b",
        "parentId" : "6746c23f-c269-4ec8-9cc5-90c39a1ab031",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "i see, thanks for the clarification!",
        "createdAt" : "2019-12-10T18:07:07Z",
        "updatedAt" : "2019-12-11T08:22:47Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "b808d51a05a4c382550b4648690ca68660ae0e3a",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +222,226 @@    | TRUNCATE TABLE multipartIdentifier partitionSpec?                #truncateTable\n    | MSCK REPAIR TABLE multipartIdentifier                            #repairTable\n    | op=(ADD | LIST) identifier (STRING | .*?)                        #manageResource\n    | SET ROLE .*?                                                     #failNativeCommand\n    | SET .*?                                                          #setConfiguration"
  },
  {
    "id" : "b7c9b11b-c057-4acb-b210-a1e87c835595",
    "prId" : 26775,
    "prUrl" : "https://github.com/apache/spark/pull/26775#pullrequestreview-328066608",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c57a934a-f279-4962-a655-1ebad1347158",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "we also need to update `sql-keywords.md`",
        "createdAt" : "2019-12-06T08:54:46Z",
        "updatedAt" : "2020-01-09T11:12:33Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "514b78a4d574ea48736a31770136d6b4eae6a25e",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +1610,1614 @@OVERLAY: 'OVERLAY';\nOVERWRITE: 'OVERWRITE';\nOWNER: 'OWNER';\nPARTITION: 'PARTITION';\nPARTITIONED: 'PARTITIONED';"
  },
  {
    "id" : "55b55c88-01b5-4df2-9f89-ffecb56c4bc9",
    "prId" : 26775,
    "prUrl" : "https://github.com/apache/spark/pull/26775#pullrequestreview-340333395",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a5b57626-1a69-4543-b435-fcb580e7940d",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "this should also be put in `ansiNonReserved`",
        "createdAt" : "2020-01-09T07:42:20Z",
        "updatedAt" : "2020-01-09T11:12:33Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "514b78a4d574ea48736a31770136d6b4eae6a25e",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +1351,1355 @@    | OVERLAY\n    | OVERWRITE\n    | OWNER\n    | PARTITION\n    | PARTITIONED"
  },
  {
    "id" : "3fe76a23-eb0a-434e-a3f3-8b8cdcb2014e",
    "prId" : 26740,
    "prUrl" : "https://github.com/apache/spark/pull/26740#pullrequestreview-329563013",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "827c2834-669f-4d57-843c-f147b6063e52",
        "parentId" : null,
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "Why add the table alias?",
        "createdAt" : "2019-12-09T00:29:48Z",
        "updatedAt" : "2019-12-09T00:29:49Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "16ae38d7-2114-46db-8b84-614120dbb8b1",
        "parentId" : "827c2834-669f-4d57-843c-f147b6063e52",
        "authorId" : "b1186675-6994-424b-9d5b-209b07a918d9",
        "body" : "Removed.",
        "createdAt" : "2019-12-10T02:54:26Z",
        "updatedAt" : "2019-12-10T02:54:26Z",
        "lastEditedBy" : "b1186675-6994-424b-9d5b-209b07a918d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "cab9c673099d9043cb0d39565440f9263a386231",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +392,396 @@    | fromClause multiInsertQueryBody+                                             #multiInsertQuery\n    | DELETE FROM multipartIdentifier tableAlias whereClause?                      #deleteFromTable\n    | VACUUM multipartIdentifier tableAlias                                        #vacuumFromTable\n    | UPDATE multipartIdentifier tableAlias setClause whereClause?                 #updateTable\n    | MERGE INTO target=multipartIdentifier targetAlias=tableAlias"
  },
  {
    "id" : "95a8e225-56ed-429e-9335-28fc0da3ab5e",
    "prId" : 26736,
    "prUrl" : "https://github.com/apache/spark/pull/26736#pullrequestreview-326571917",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "567f6e55-f205-4012-93fd-8292e5d8d27e",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "how about\r\n```\r\ncreateTableClause\r\n  : (OPTIONS options=tablePropertyList) | ...\r\n  ;\r\n```\r\nThen we can reuse it in more places\r\n```\r\ncreateTableHeader ... createTableClause*                              #createTable\r\ncreateTableHeader ... (createTableClause | rowFormat | createFileFormat | ...)* . #createHiveTable\r\nreplaceTableHeader ... createTableClause*\r\n```",
        "createdAt" : "2019-12-03T13:22:58Z",
        "updatedAt" : "2019-12-06T07:45:19Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "3577bf60-064d-4886-bf67-cb2f7c8e6323",
        "parentId" : "567f6e55-f205-4012-93fd-8292e5d8d27e",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Good idea!",
        "createdAt" : "2019-12-04T02:38:24Z",
        "updatedAt" : "2019-12-06T07:45:19Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "a2013079277494504af75ac5257652cd24f71e57",
    "line" : 52,
    "diffHunk" : "@@ -1,1 +354,358 @@    ;\n\ncreateTableClauses\n    :((OPTIONS options=tablePropertyList) |\n     (PARTITIONED BY partitioning=transformList) |"
  },
  {
    "id" : "6b3340e0-a15b-422a-887a-73bbd79f341f",
    "prId" : 33599,
    "prUrl" : "https://github.com/apache/spark/pull/33599#pullrequestreview-728767841",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "294ebe61-3129-463b-8be2-eec2012242e2",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "shall we define a new token for it? then the parser can choose to not call `unescapeSQLString` for raw string token.",
        "createdAt" : "2021-08-12T08:56:24Z",
        "updatedAt" : "2021-08-12T08:56:24Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "7e9360e9-3032-4f57-bc27-01edbdd8e391",
        "parentId" : "294ebe61-3129-463b-8be2-eec2012242e2",
        "authorId" : "3a227965-84e0-47cf-9974-11293764f028",
        "body" : "If we have a new token aside from `STRING`, we need to care all the places in `SqlBase.g4` and `ASTBuilder.scala` where `STRING` is referred. Is it acceptable?",
        "createdAt" : "2021-08-12T15:25:34Z",
        "updatedAt" : "2021-08-12T15:25:34Z",
        "lastEditedBy" : "3a227965-84e0-47cf-9974-11293764f028",
        "tags" : [
        ]
      }
    ],
    "commit" : "ec963efa51cd02cf6816d4eebcf645c709e43f09",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1807,1811 @@    | '\"' ( ~('\"'|'\\\\') | ('\\\\' .) )* '\"'\n    | 'R\\'' (~'\\'')* '\\''\n    | 'R\"'(~'\"')* '\"'\n    ;\n"
  },
  {
    "id" : "5f33f205-2c29-4547-937d-d7ec6d5c5ba2",
    "prId" : 26369,
    "prUrl" : "https://github.com/apache/spark/pull/26369#pullrequestreview-310779921",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "981f4506-9870-40f1-8620-683562c7e4eb",
        "parentId" : null,
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "I am combining these two since ALTER VIEW is not supported for ADD PARTITION and this rule is compatible with the view rule.",
        "createdAt" : "2019-11-02T17:14:33Z",
        "updatedAt" : "2019-11-02T17:15:53Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "7a2464d41861ce858bbb3ffed0ed79a4f6feb921",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +159,163 @@    | ALTER TABLE tableIdentifier (partitionSpec)?\n        SET SERDEPROPERTIES tablePropertyList                          #setTableSerDe\n    | ALTER (TABLE | VIEW) multipartIdentifier ADD (IF NOT EXISTS)?\n        partitionSpecLocation+                                         #addTablePartition\n    | ALTER TABLE multipartIdentifier"
  },
  {
    "id" : "f7e43801-3642-4ca4-af1f-fce7889e86cb",
    "prId" : 26366,
    "prUrl" : "https://github.com/apache/spark/pull/26366#pullrequestreview-310798562",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "709e3c0b-6b4d-4e8c-9aaf-89494f181530",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ur, I see. Looks reasonable to me.",
        "createdAt" : "2019-11-03T04:02:42Z",
        "updatedAt" : "2019-11-03T09:06:19Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "5db6d6d528d9e7fd88a1d3301cfbba877a38cfb7",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +720,724 @@       (OVER windowSpec)?                                                                      #functionCall\n    | identifier '->' expression                                                               #lambda\n    | '(' identifier (',' identifier)+ ')' '->' expression                                     #lambda\n    | value=primaryExpression '[' index=valueExpression ']'                                    #subscript\n    | identifier                                                                               #columnReference"
  },
  {
    "id" : "347f9c31-d61a-4b86-a7dd-bcb8b57584f9",
    "prId" : 26338,
    "prUrl" : "https://github.com/apache/spark/pull/26338#pullrequestreview-312043479",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e3d73777-1ab2-4e74-a422-c53ed30dbe7b",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Previously we use `qualifiedName: identifier ('.' identifier)*` to capture column name. \r\n\r\nThis conflicts a test in ErrorParserSuite that `test-col` is not allowed in `ALTER TABLE t CHANGE COLUMN test-col TYPE BIGINT`.\r\n\r\nThe column name should be multiple errorCapturingIdentifier. So I changed it to multipartIdentifier:\r\n```\r\nmultipartIdentifier\r\n    : parts+=errorCapturingIdentifier ('.' parts+=errorCapturingIdentifier)*\r\n    ;\r\n```\r\n\r\n@cloud-fan ",
        "createdAt" : "2019-11-05T16:14:00Z",
        "updatedAt" : "2019-11-05T16:14:01Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "232e966d-c468-4de4-add1-200c7800e8ed",
        "parentId" : "e3d73777-1ab2-4e74-a422-c53ed30dbe7b",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "it looks like we should replace `qualifiedName` with `multipartIdentifier` in all other places. We can do it in a followup.",
        "createdAt" : "2019-11-05T16:40:58Z",
        "updatedAt" : "2019-11-05T16:40:59Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "818aba64-8bb0-4ce1-b5d8-36a4d2e4992a",
        "parentId" : "e3d73777-1ab2-4e74-a422-c53ed30dbe7b",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "ok. will make a followup later.",
        "createdAt" : "2019-11-05T21:08:29Z",
        "updatedAt" : "2019-11-05T21:08:30Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "b2acddbddbdab3926f54356ea4b5d6f59011c14a",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +150,154 @@        UNSET TBLPROPERTIES (IF EXISTS)? tablePropertyList             #unsetTableProperties\n    | ALTER TABLE multipartIdentifier\n        (ALTER | CHANGE) COLUMN? multipartIdentifier\n        (TYPE dataType)? (COMMENT comment=STRING)? colPosition?        #alterTableColumn\n    | ALTER TABLE multipartIdentifier (partitionSpec)?"
  },
  {
    "id" : "674cf13a-cbe2-405e-a28c-00fd9c8650c3",
    "prId" : 26338,
    "prUrl" : "https://github.com/apache/spark/pull/26338#pullrequestreview-312172012",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "491d6557-a837-4cbc-bd71-6bf22425058c",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "we can distinguish the two `multipartIdentifier`\r\n```\r\nALTER TABLE table=multipartIdentifier ... COLUMN? column=multipartIdentifier\r\n```\r\n\r\nYou can fix it in your followup",
        "createdAt" : "2019-11-06T02:26:05Z",
        "updatedAt" : "2019-11-06T02:26:05Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "81dbb6a9-0612-4ee1-920c-dd752732b36b",
        "parentId" : "491d6557-a837-4cbc-bd71-6bf22425058c",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "ok.",
        "createdAt" : "2019-11-06T03:07:01Z",
        "updatedAt" : "2019-11-06T03:07:02Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "b2acddbddbdab3926f54356ea4b5d6f59011c14a",
    "line" : 3,
    "diffHunk" : "@@ -1,1 +149,153 @@    | ALTER (TABLE | VIEW) multipartIdentifier\n        UNSET TBLPROPERTIES (IF EXISTS)? tablePropertyList             #unsetTableProperties\n    | ALTER TABLE multipartIdentifier\n        (ALTER | CHANGE) COLUMN? multipartIdentifier\n        (TYPE dataType)? (COMMENT comment=STRING)? colPosition?        #alterTableColumn"
  },
  {
    "id" : "1ac249f1-60a3-4155-b2be-dc3f74c8ef40",
    "prId" : 26304,
    "prUrl" : "https://github.com/apache/spark/pull/26304#pullrequestreview-308952768",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a2d0040f-42cf-41c9-89eb-d05931730b0e",
        "parentId" : null,
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "Please let me know if this needs to be parsed separately.",
        "createdAt" : "2019-10-30T03:52:41Z",
        "updatedAt" : "2019-10-30T17:10:01Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "1f5907288ee76d0b67cc0ed4eb426b5607c898dc",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +170,174 @@        DROP (IF EXISTS)? partitionSpec (',' partitionSpec)*           #dropTablePartitions\n    | ALTER TABLE multipartIdentifier\n        (partitionSpec)? SET locationSpec                              #setTableLocation\n    | ALTER TABLE multipartIdentifier RECOVER PARTITIONS               #recoverPartitions\n    | DROP TABLE (IF EXISTS)? multipartIdentifier PURGE?               #dropTable"
  },
  {
    "id" : "1a53155d-bdb0-4471-b9de-8c1479498466",
    "prId" : 26285,
    "prUrl" : "https://github.com/apache/spark/pull/26285#pullrequestreview-309102425",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8c47788d-a0ac-4e32-bda8-4fc9eb763819",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "`{ansi}? (errorCapturingMultiUnitsInterval | errorCapturingUnitToUnitInterval)?` is illegal as it can match anything. Note that we need to make `(errorCapturingMultiUnitsInterval | errorCapturingUnitToUnitInterval)` optional so that we can detect `select interval` and give precise error message.",
        "createdAt" : "2019-10-30T10:38:35Z",
        "updatedAt" : "2019-11-01T12:57:38Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "044257d2dfce8ebbf2e553b4cc52145beea5354a",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +761,765 @@interval\n    : INTERVAL (errorCapturingMultiUnitsInterval | errorCapturingUnitToUnitInterval)?\n    | {ansi}? (errorCapturingMultiUnitsInterval | errorCapturingUnitToUnitInterval)\n    ;\n"
  },
  {
    "id" : "44e481cd-4908-4ff3-a6be-cf97d6c5e3dd",
    "prId" : 26280,
    "prUrl" : "https://github.com/apache/spark/pull/26280#pullrequestreview-334516754",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8d5be36a-4e8f-4b75-a1a5-153b488679e8",
        "parentId" : null,
        "authorId" : "808d9715-b3bd-4481-9935-20d7ca698e42",
        "body" : "One suggestion, can we replace constant with expression? In our PROD environment, there are some requirements like 'ALTER TABLE xxx DROP PARTITION (col <  CURRENT_DATE)'.",
        "createdAt" : "2019-12-19T09:51:04Z",
        "updatedAt" : "2019-12-19T09:51:05Z",
        "lastEditedBy" : "808d9715-b3bd-4481-9935-20d7ca698e42",
        "tags" : [
        ]
      }
    ],
    "commit" : "c2639d06b57ace7d5eaa7a268434a02c6c1240c1",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +334,338 @@\ndropPartitionVal\n    : identifier (comparisonOperator constant)?\n    ;\n"
  },
  {
    "id" : "3519bf74-df91-4314-a93f-4ddfc64736c9",
    "prId" : 26190,
    "prUrl" : "https://github.com/apache/spark/pull/26190#pullrequestreview-305608721",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "13182aa7-5a6c-4209-a8a4-f1636a5b5c8f",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This is the existing behavior in 3.0, but I wonder if we really want to allow `SELECT INTERVAL 'interval 1 year'`, or only `SELECT INTERVAL '1 year'`. cc @MaxGekk @maropu @dongjoon-hyun ",
        "createdAt" : "2019-10-21T11:17:55Z",
        "updatedAt" : "2019-10-24T05:40:30Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "92426ea5-9ca2-4f95-890c-6054e259d45e",
        "parentId" : "13182aa7-5a6c-4209-a8a4-f1636a5b5c8f",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "The SQL standard doesn't define interval strings in such format with the `'interval'` prefix (or I haven't found that). If we look at other DBMS, for instance PostgreSQL, it supports strings without the prefix only.\r\n\r\nI think we could support only strings without the prefix since Spark 3.0 because we haven't support bulk saving interval strings so far (in JSON or CSV, for example).",
        "createdAt" : "2019-10-21T14:10:58Z",
        "updatedAt" : "2019-10-24T05:40:30Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "f88a96ec-13a6-48c7-a12e-fc215a79e82c",
        "parentId" : "13182aa7-5a6c-4209-a8a4-f1636a5b5c8f",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Thank you for pinging me, @cloud-fan . It seems to be a corner case which we overlooked before. +1 for banning the case `SELECT INTERVAL 'INTERVAL 1 year'` in Apache Spark 3.0. What we need is only `SELECT INTERVAL '1 year'`. In other words,\r\n- `SELECT INTERVAL 'INTERVAL 1 year'` (X)\r\n- `SELECT INTERVAL '1 year'` (O)",
        "createdAt" : "2019-10-21T21:37:58Z",
        "updatedAt" : "2019-10-24T05:40:30Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "8bbf2960-0a69-41ef-a8dc-76b964a866b9",
        "parentId" : "13182aa7-5a6c-4209-a8a4-f1636a5b5c8f",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "The @dongjoon-hyun suggested one looks ok to me.",
        "createdAt" : "2019-10-23T00:48:15Z",
        "updatedAt" : "2019-10-24T05:40:30Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "9e1eb741-d8cc-410d-9f3e-23e162e7da7f",
        "parentId" : "13182aa7-5a6c-4209-a8a4-f1636a5b5c8f",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I'll send a followup PR to change this behavior and update related tests. Thanks for joining the discussion!",
        "createdAt" : "2019-10-23T02:56:48Z",
        "updatedAt" : "2019-10-24T05:40:30Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "48b7ef4c42c2bf98ffda16e77e2ef10bd78f5d9f",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +81,85 @@\nsingleInterval\n    : INTERVAL? (intervalValue intervalUnit)+ EOF\n    ;\n"
  },
  {
    "id" : "981b12c9-0f4b-4f90-90fb-87c8059ad461",
    "prId" : 26167,
    "prUrl" : "https://github.com/apache/spark/pull/26167#pullrequestreview-309714087",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0a0d4097-e634-474f-b34b-cce78655ff2e",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "`query` can have cte like `WITH ... SELECT ...`, should we support it as MERGE source?\r\n\r\nIf you look at `dmlStatementNoWith`, INSERT INTO doesn't support cte in the input query.",
        "createdAt" : "2019-10-30T13:13:49Z",
        "updatedAt" : "2019-11-08T10:56:38Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "b5b4c1bc-70cd-4946-aceb-f197b1862e65",
        "parentId" : "0a0d4097-e634-474f-b34b-cce78655ff2e",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "nvm, I checked with pgsql and we can have cte in multiple places. Below is a valid SQL:\r\n`with s(i) as (select 1) insert into t with d(i) as (select 2) select i from d`.\r\n\r\nWe should fix it in Spark later.",
        "createdAt" : "2019-10-30T13:28:57Z",
        "updatedAt" : "2019-11-08T10:56:38Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "5bbe2232-cb1a-4624-854f-3deb4a11dc34",
        "parentId" : "0a0d4097-e634-474f-b34b-cce78655ff2e",
        "authorId" : "8afcf008-6988-44a5-92fa-2bef54bb4058",
        "body" : "Yea, I also tried postgres and checked some docs but I didn't find any strong argue why we should/should not support cte in MERGE (MERGE was committed to pg code but later reverted due to some unknown reason). I think there's no bad to support this.\r\n\r\nIâ€˜ll to add a case for this syntax.",
        "createdAt" : "2019-10-31T08:38:25Z",
        "updatedAt" : "2019-11-08T10:56:38Z",
        "lastEditedBy" : "8afcf008-6988-44a5-92fa-2bef54bb4058",
        "tags" : [
        ]
      }
    ],
    "commit" : "391559d9457678eee74f40cba52b09a935b9beb9",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +220,224 @@    | MERGE INTO target=multipartIdentifier targetAlias=tableAlias\n        USING (source=multipartIdentifier |\n          '(' sourceQuery=query')') sourceAlias=tableAlias\n        ON mergeCondition=booleanExpression\n        matchedClause*"
  },
  {
    "id" : "fbbabee5-0046-47bf-831f-0c6d1c973af5",
    "prId" : 26167,
    "prUrl" : "https://github.com/apache/spark/pull/26167#pullrequestreview-309201664",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ff8921e6-7a40-4f27-9ed9-f8ba9efb9302",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "We should move it to `dmlStatementNoWith`. DELETE/UPDATE should be there as well, but we can move them later.",
        "createdAt" : "2019-10-30T13:34:13Z",
        "updatedAt" : "2019-11-08T10:56:38Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "391559d9457678eee74f40cba52b09a935b9beb9",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +218,222 @@    | DELETE FROM multipartIdentifier tableAlias whereClause?          #deleteFromTable\n    | UPDATE multipartIdentifier tableAlias setClause whereClause?     #updateTable\n    | MERGE INTO target=multipartIdentifier targetAlias=tableAlias\n        USING (source=multipartIdentifier |\n          '(' sourceQuery=query')') sourceAlias=tableAlias"
  },
  {
    "id" : "f8a5837b-f99b-48ba-bad9-3a012023d06a",
    "prId" : 26167,
    "prUrl" : "https://github.com/apache/spark/pull/26167#pullrequestreview-314130677",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bd369d82-87b3-483d-a972-c3792d57758b",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "we can inline it since it's only used once.",
        "createdAt" : "2019-11-08T09:55:41Z",
        "updatedAt" : "2019-11-08T10:56:38Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "eb115f1e-9268-448e-98a1-d2a20ecfa024",
        "parentId" : "bd369d82-87b3-483d-a972-c3792d57758b",
        "authorId" : "8afcf008-6988-44a5-92fa-2bef54bb4058",
        "body" : "There's `setClause` also uses it.",
        "createdAt" : "2019-11-08T10:57:35Z",
        "updatedAt" : "2019-11-08T10:57:35Z",
        "lastEditedBy" : "8afcf008-6988-44a5-92fa-2bef54bb4058",
        "tags" : [
        ]
      }
    ],
    "commit" : "391559d9457678eee74f40cba52b09a935b9beb9",
    "line" : 41,
    "diffHunk" : "@@ -1,1 +506,510 @@    ;\n\nassignmentList\n    : assignment (',' assignment)*\n    ;"
  },
  {
    "id" : "29a93cb7-cabc-4cfe-9049-349877a484b9",
    "prId" : 25601,
    "prUrl" : "https://github.com/apache/spark/pull/25601#pullrequestreview-283351595",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e5cc9081-7aea-4c67-9e3d-d31207c4e010",
        "parentId" : null,
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "I put both `FROM` and `IN` similar to `SHOW TABLES`. Please let me know if `FROM` is not needed.",
        "createdAt" : "2019-09-04T02:44:57Z",
        "updatedAt" : "2019-09-09T23:58:04Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "9a55a03acf84fe67595817c8fef409a9e4912a51",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +93,97 @@        (RESTRICT | CASCADE)?                                          #dropDatabase\n    | SHOW DATABASES (LIKE? pattern=STRING)?                           #showDatabases\n    | SHOW NAMESPACES ((FROM | IN) multipartIdentifier)?\n        (LIKE? pattern=STRING)?                                        #showNamespaces\n    | createTableHeader ('(' colTypeList ')')? tableProvider"
  },
  {
    "id" : "a1b63ec3-b5ad-46b9-88f4-ed39f225bf29",
    "prId" : 25601,
    "prUrl" : "https://github.com/apache/spark/pull/25601#pullrequestreview-283351595",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "99e0fd05-8cf4-49b2-845e-075dba32bd80",
        "parentId" : null,
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "I need to update `docs/sql-keywords.md`",
        "createdAt" : "2019-09-04T02:46:47Z",
        "updatedAt" : "2019-09-09T23:58:04Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "9a55a03acf84fe67595817c8fef409a9e4912a51",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +1520,1524 @@MONTHS: 'MONTHS';\nMSCK: 'MSCK';\nNAMESPACES: 'NAMESPACES';\nNATURAL: 'NATURAL';\nNO: 'NO';"
  },
  {
    "id" : "5bcafe12-4067-4904-a5af-f5a9ecf1c569",
    "prId" : 25416,
    "prUrl" : "https://github.com/apache/spark/pull/25416#pullrequestreview-299240192",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d4a1931d-60e4-4c0e-b134-f15029d6330f",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "We should also update doc/sql-keywords.md",
        "createdAt" : "2019-10-09T08:18:13Z",
        "updatedAt" : "2019-10-09T08:18:13Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "e50aff7cbf96f443eff6124962864296a1eecb5d",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +1524,1528 @@NULLS: 'NULLS';\nOF: 'OF';\nOFFSET: 'OFFSET';\nON: 'ON';\nONLY: 'ONLY';"
  },
  {
    "id" : "2b5f4b2d-8aa7-4b5e-8565-21932991289d",
    "prId" : 25416,
    "prUrl" : "https://github.com/apache/spark/pull/25416#pullrequestreview-299258318",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c230b7f8-221a-4241-bfa1-d7f503e31864",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "does SQL standard define the order of LIMIT and OFFSET clauses? Here we force users to write LIMIT clause first.",
        "createdAt" : "2019-10-09T08:20:53Z",
        "updatedAt" : "2019-10-09T08:20:53Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "c0385bb9-bdd7-41c9-abf6-9f2a2fe3525e",
        "parentId" : "c230b7f8-221a-4241-bfa1-d7f503e31864",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "Yes, SQL standard defined the order for `LIMIT` and `OFFSET` clauses. `LIMIT` at the front of `OFFSET`.\r\nThe behavior looks contrary to MySQL direction. \r\n`MySQL` support `LIMIT 10,10`. \r\n",
        "createdAt" : "2019-10-09T08:50:28Z",
        "updatedAt" : "2019-10-10T02:16:20Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "e50aff7cbf96f443eff6124962864296a1eecb5d",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +400,404 @@      windowClause?\n      (LIMIT (ALL | limit=expression))?\n      (OFFSET offset=expression)?\n    ;\n"
  },
  {
    "id" : "e36eec67-1298-4dcc-97ce-01255e037e30",
    "prId" : 25013,
    "prUrl" : "https://github.com/apache/spark/pull/25013#pullrequestreview-257244821",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "59779e95-820f-4ca0-a7fc-45a8fecd080f",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "This describes this parser change, too. This is more important change than a test suite change.",
        "createdAt" : "2019-07-03T03:29:41Z",
        "updatedAt" : "2019-07-03T03:29:42Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "a31522bd15ea84b249052b6010a051e850231379",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +1012,1016 @@    | PERCENTLIT\n    | PIVOT\n    | PLACING\n    | POSITION\n    | PRECEDING"
  },
  {
    "id" : "d4360a17-30b7-4cb4-b722-cc84b5ec7712",
    "prId" : 25001,
    "prUrl" : "https://github.com/apache/spark/pull/25001#pullrequestreview-326664258",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ecf1b674-56aa-4abd-bc0d-c374d9d2c95e",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "we should also add it in `ansiNonReserved`",
        "createdAt" : "2019-12-03T18:11:05Z",
        "updatedAt" : "2019-12-06T03:12:10Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "5b7f958b-7957-4895-bd68-c9bfed5ef724",
        "parentId" : "ecf1b674-56aa-4abd-bc0d-c374d9d2c95e",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "OK.",
        "createdAt" : "2019-12-04T06:58:49Z",
        "updatedAt" : "2019-12-06T03:12:10Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      },
      {
        "id" : "6855899e-d3b7-4762-ac83-ad1c274baca7",
        "parentId" : "ecf1b674-56aa-4abd-bc0d-c374d9d2c95e",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ah sorry I misread the document. So we expect to make `ESCAPE` to be reserved under ansi mode. This makes sense, let's change it back.",
        "createdAt" : "2019-12-04T07:53:48Z",
        "updatedAt" : "2019-12-06T03:12:10Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "d1dddfa8-5d93-489b-8b0e-af52817d42e3",
        "parentId" : "ecf1b674-56aa-4abd-bc0d-c374d9d2c95e",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "OK. I restored it.",
        "createdAt" : "2019-12-04T08:17:57Z",
        "updatedAt" : "2019-12-06T03:12:10Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "4cc9e0a8b970071e19864f64ee15d40b3d3097db",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +1204,1208 @@    | ELSE\n    | END\n    | ESCAPE\n    | ESCAPED\n    | EXCHANGE"
  },
  {
    "id" : "2858105a-d4af-4a41-b6fd-51a6f293bb24",
    "prId" : 25001,
    "prUrl" : "https://github.com/apache/spark/pull/25001#pullrequestreview-326585659",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "039ba8e2-4f03-4b98-b9c3-96dd6a56fe4e",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "this doesn't apply to RLIKE?",
        "createdAt" : "2019-12-03T18:13:45Z",
        "updatedAt" : "2019-12-06T03:12:10Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "9e8da832-81b0-41b4-ab6b-9d364cfccc24",
        "parentId" : "039ba8e2-4f03-4b98-b9c3-96dd6a56fe4e",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "Yes.",
        "createdAt" : "2019-12-04T03:35:42Z",
        "updatedAt" : "2019-12-06T03:12:10Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "4cc9e0a8b970071e19864f64ee15d40b3d3097db",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +686,690 @@    | NOT? kind=IN '(' query ')'\n    | NOT? kind=RLIKE pattern=valueExpression\n    | NOT? kind=LIKE pattern=valueExpression (ESCAPE escapeChar=STRING)?\n    | IS NOT? kind=NULL\n    | IS NOT? kind=(TRUE | FALSE | UNKNOWN)"
  },
  {
    "id" : "99bd5b74-0cce-4ac7-bf18-ba7ae0365245",
    "prId" : 24859,
    "prUrl" : "https://github.com/apache/spark/pull/24859#pullrequestreview-253113896",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "88ec892f-da2d-419f-85c8-3313fec4b826",
        "parentId" : null,
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "Could you add a comment above line 667? \r\n> Note: check the operator precedence when adding the new operator. ",
        "createdAt" : "2019-06-22T23:42:56Z",
        "updatedAt" : "2019-06-23T03:00:37Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      },
      {
        "id" : "53c69ea6-40b8-4aaf-a98a-53902b551f5f",
        "parentId" : "88ec892f-da2d-419f-85c8-3313fec4b826",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "OK. ",
        "createdAt" : "2019-06-23T02:55:04Z",
        "updatedAt" : "2019-06-23T03:00:37Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      }
    ],
    "commit" : "ef1bafc11a80aa260185015a1496baf23cfd010a",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +670,674 @@// Note: check the operator precedence when adding the new operator.\nvalueExpression\n    : primaryExpression                                                                      #valueExpressionDefault\n    | operator=(MINUS | PLUS | TILDE) valueExpression                                        #arithmeticUnary\n    | left=valueExpression operator=(ASTERISK | SLASH | PERCENT | DIV) right=valueExpression #arithmeticBinary"
  },
  {
    "id" : "f49e7561-fef4-4418-a28a-2d2369c5ee28",
    "prId" : 24842,
    "prUrl" : "https://github.com/apache/spark/pull/24842#pullrequestreview-253154377",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bcfc7a32-438b-4f7e-b9ce-260d722ff6d6",
        "parentId" : null,
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "Duplicate names within a single CTE definition are not allowed. ",
        "createdAt" : "2019-06-23T23:20:44Z",
        "updatedAt" : "2019-06-23T23:20:44Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      }
    ],
    "commit" : "0a00a036148e898bd88bf3dd6e7b7ca0c67fa270",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +320,324 @@\nnamedQuery\n    : name=identifier (columnAliases=identifierList)? AS? '(' query ')'\n    ;\n"
  },
  {
    "id" : "b4ab2d1d-7c83-4b4d-a62f-2e1c6df2e4ec",
    "prId" : 24832,
    "prUrl" : "https://github.com/apache/spark/pull/24832#pullrequestreview-266789412",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5d8cc9cf-f3d6-4ba9-a305-5d0d38fc64a9",
        "parentId" : null,
        "authorId" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "body" : "do we need to wrap with parentheses `(partitionSpec (IF NOT EXISTS)?)?` like above? Otherwise, what happens if there's no `partitionSpec` but the `IF NOT EXISTS`? \r\n - If the table not exists? Then wouldn't that be CTAS?",
        "createdAt" : "2019-07-24T23:13:19Z",
        "updatedAt" : "2019-07-25T16:05:47Z",
        "lastEditedBy" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "tags" : [
        ]
      },
      {
        "id" : "02a86331-f56f-4b6b-9cf4-36f89d4f4f3c",
        "parentId" : "5d8cc9cf-f3d6-4ba9-a305-5d0d38fc64a9",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "It isn't supported either way, so why combine the two?",
        "createdAt" : "2019-07-25T15:53:42Z",
        "updatedAt" : "2019-07-25T16:05:47Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "0aa803ad-8ce0-478f-ba67-375a7728e846",
        "parentId" : "5d8cc9cf-f3d6-4ba9-a305-5d0d38fc64a9",
        "authorId" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "body" : "got it",
        "createdAt" : "2019-07-25T17:56:14Z",
        "updatedAt" : "2019-07-25T17:56:14Z",
        "lastEditedBy" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "tags" : [
        ]
      }
    ],
    "commit" : "7f193ca074b7fd0dea9f7b28b4e1776819e6d512",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +296,300 @@insertInto\n    : INSERT OVERWRITE TABLE? multipartIdentifier (partitionSpec (IF NOT EXISTS)?)?                         #insertOverwriteTable\n    | INSERT INTO TABLE? multipartIdentifier partitionSpec? (IF NOT EXISTS)?                                #insertIntoTable\n    | INSERT OVERWRITE LOCAL? DIRECTORY path=STRING rowFormat? createFileFormat?                            #insertOverwriteHiveDir\n    | INSERT OVERWRITE LOCAL? DIRECTORY (path=STRING)? tableProvider (OPTIONS options=tablePropertyList)?   #insertOverwriteDir"
  },
  {
    "id" : "a15d5251-0ad8-4598-a2a1-84566cb8e6fd",
    "prId" : 24832,
    "prUrl" : "https://github.com/apache/spark/pull/24832#pullrequestreview-266723702",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4613d867-0223-4055-bdeb-81e959aea92c",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I think `(partitionSpec (IF NOT EXISTS)?)?` is better? `INSERT INTO TABLE ... IF NOT EXISTS`  doesn't make sense. The `IF NOT EXISTS` is only for partitions.",
        "createdAt" : "2019-07-25T08:03:02Z",
        "updatedAt" : "2019-07-25T16:05:47Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "b8e3d0e5-f608-46f2-bd00-e7f6142b31a9",
        "parentId" : "4613d867-0223-4055-bdeb-81e959aea92c",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Actually, `IF NOT EXISTS` doesn't make sense to partition either. It's append not overwrite, and it seems weird to me if we can't append to an existing partition.",
        "createdAt" : "2019-07-25T08:08:08Z",
        "updatedAt" : "2019-07-25T16:05:47Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "8d6c606c-eca7-40d6-a7c2-57a2cf52a3dc",
        "parentId" : "4613d867-0223-4055-bdeb-81e959aea92c",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Can we keep this unchanged and not add `IF NOT EXISTS` here?",
        "createdAt" : "2019-07-25T08:08:31Z",
        "updatedAt" : "2019-07-25T16:05:47Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "6a9c3ea9-3a01-4a4d-8f6d-4c44c4da8a97",
        "parentId" : "4613d867-0223-4055-bdeb-81e959aea92c",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "This was changed to get a better error message. Instead of a parse exception that lists symbols, this is now a useful error message with a test.",
        "createdAt" : "2019-07-25T15:52:12Z",
        "updatedAt" : "2019-07-25T16:05:47Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      }
    ],
    "commit" : "7f193ca074b7fd0dea9f7b28b4e1776819e6d512",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +296,300 @@insertInto\n    : INSERT OVERWRITE TABLE? multipartIdentifier (partitionSpec (IF NOT EXISTS)?)?                         #insertOverwriteTable\n    | INSERT INTO TABLE? multipartIdentifier partitionSpec? (IF NOT EXISTS)?                                #insertIntoTable\n    | INSERT OVERWRITE LOCAL? DIRECTORY path=STRING rowFormat? createFileFormat?                            #insertOverwriteHiveDir\n    | INSERT OVERWRITE LOCAL? DIRECTORY (path=STRING)? tableProvider (OPTIONS options=tablePropertyList)?   #insertOverwriteDir"
  },
  {
    "id" : "3b9799f2-9eb9-4cf8-be6f-021d22cd8806",
    "prId" : 24809,
    "prUrl" : "https://github.com/apache/spark/pull/24809#pullrequestreview-246816447",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ac437290-eef7-44fb-9651-06bfb23fe7ab",
        "parentId" : null,
        "authorId" : "88f0c774-9c59-4485-885d-f6aee36efcea",
        "body" : "The clause can be either select/transform/map/reduce etc. Thus rename this to `fromStatementBody`.",
        "createdAt" : "2019-06-06T21:07:34Z",
        "updatedAt" : "2019-06-11T21:14:51Z",
        "lastEditedBy" : "88f0c774-9c59-4485-885d-f6aee36efcea",
        "tags" : [
        ]
      }
    ],
    "commit" : "7b174e52b6f7bad2ea85f6fa844af3f1e1ffbbb1",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +392,396 @@\nmultiInsertQueryBody\n    : insertInto fromStatementBody\n    ;\n"
  },
  {
    "id" : "d7d7c1be-62b9-4a0f-bae5-c7339e86bfae",
    "prId" : 24809,
    "prUrl" : "https://github.com/apache/spark/pull/24809#pullrequestreview-246816777",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2446a889-3947-4c4d-a60b-42f979092bf8",
        "parentId" : null,
        "authorId" : "88f0c774-9c59-4485-885d-f6aee36efcea",
        "body" : "According to Hive compatibility test, `fromStatement` should be in the same level as queries such as `SELECT * FROM table`.",
        "createdAt" : "2019-06-06T21:08:14Z",
        "updatedAt" : "2019-06-11T21:14:51Z",
        "lastEditedBy" : "88f0c774-9c59-4485-885d-f6aee36efcea",
        "tags" : [
        ]
      }
    ],
    "commit" : "7b174e52b6f7bad2ea85f6fa844af3f1e1ffbbb1",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +407,411 @@queryPrimary\n    : querySpecification                                                    #queryPrimaryDefault\n    | fromStatement                                                         #fromStmt\n    | TABLE tableIdentifier                                                 #table\n    | inlineTable                                                           #inlineTableDefault1"
  },
  {
    "id" : "08185bbf-e8c0-4554-a35d-2eb48065333b",
    "prId" : 24809,
    "prUrl" : "https://github.com/apache/spark/pull/24809#pullrequestreview-247377743",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "54205550-4a00-4587-81b9-c45a39d375a9",
        "parentId" : null,
        "authorId" : "88f0c774-9c59-4485-885d-f6aee36efcea",
        "body" : "Re-write `querySpecification` to show the fact that transform and select are two different kinds of queries.",
        "createdAt" : "2019-06-06T21:10:05Z",
        "updatedAt" : "2019-06-11T21:14:51Z",
        "lastEditedBy" : "88f0c774-9c59-4485-885d-f6aee36efcea",
        "tags" : [
        ]
      },
      {
        "id" : "61ab5cb4-030b-4832-84e9-beac5d6e93dd",
        "parentId" : "54205550-4a00-4587-81b9-c45a39d375a9",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "This is a good refactoring for Spark 3.0.",
        "createdAt" : "2019-06-08T18:41:58Z",
        "updatedAt" : "2019-06-11T21:14:51Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "7b174e52b6f7bad2ea85f6fa844af3f1e1ffbbb1",
    "line" : 77,
    "diffHunk" : "@@ -1,1 +435,439 @@\nquerySpecification\n    : transformClause\n      fromClause?\n      whereClause?                                                          #transformQuerySpecification"
  },
  {
    "id" : "b0cf4d6b-6bbc-467e-abbd-b13636b09d79",
    "prId" : 24809,
    "prUrl" : "https://github.com/apache/spark/pull/24809#pullrequestreview-246817728",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6af3c8b3-223e-4d0a-a9d8-f11fd7843243",
        "parentId" : null,
        "authorId" : "88f0c774-9c59-4485-885d-f6aee36efcea",
        "body" : "Rename to be consistent in `querySpecification`.",
        "createdAt" : "2019-06-06T21:10:32Z",
        "updatedAt" : "2019-06-11T21:14:51Z",
        "lastEditedBy" : "88f0c774-9c59-4485-885d-f6aee36efcea",
        "tags" : [
        ]
      }
    ],
    "commit" : "7b174e52b6f7bad2ea85f6fa844af3f1e1ffbbb1",
    "line" : 119,
    "diffHunk" : "@@ -1,1 +484,488 @@    ;\n\naggregationClause\n    : GROUP BY groupingExpressions+=expression (',' groupingExpressions+=expression)* (\n      WITH kind=ROLLUP"
  },
  {
    "id" : "7d9ff333-b014-4eef-99d6-17d074d07923",
    "prId" : 24809,
    "prUrl" : "https://github.com/apache/spark/pull/24809#pullrequestreview-246817834",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "664893ff-4332-4d19-b460-402b7cd9268c",
        "parentId" : null,
        "authorId" : "88f0c774-9c59-4485-885d-f6aee36efcea",
        "body" : "ditto.",
        "createdAt" : "2019-06-06T21:10:45Z",
        "updatedAt" : "2019-06-11T21:14:51Z",
        "lastEditedBy" : "88f0c774-9c59-4485-885d-f6aee36efcea",
        "tags" : [
        ]
      }
    ],
    "commit" : "7b174e52b6f7bad2ea85f6fa844af3f1e1ffbbb1",
    "line" : 128,
    "diffHunk" : "@@ -1,1 +802,806 @@    ;\n\nwindowClause\n    : WINDOW namedWindow (',' namedWindow)*\n    ;"
  },
  {
    "id" : "65d0dae4-b644-417c-86e9-35cf34426129",
    "prId" : 24798,
    "prUrl" : "https://github.com/apache/spark/pull/24798#pullrequestreview-249063723",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8f72e795-f1eb-4469-8a46-d9d5f2d2c485",
        "parentId" : null,
        "authorId" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "body" : "Are there other flavors of `REPLACE TABLE` that we need to support?",
        "createdAt" : "2019-06-05T02:01:11Z",
        "updatedAt" : "2019-07-19T19:00:59Z",
        "lastEditedBy" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "tags" : [
        ]
      },
      {
        "id" : "ac28098f-1f35-419d-b31f-443ff8f5d88e",
        "parentId" : "8f72e795-f1eb-4469-8a46-d9d5f2d2c485",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "I'm not sure that we should support all of what's already here, at least not to begin with.\r\n\r\nI think that the main use of `REPLACE TABLE` as an atomic operation is `REPLACE TABLE ... AS SELECT`. That's because the replacement should only happen if the write succeeds and the write could easily fail for a lot of reasons. Without a write, this is just syntactic sugar for a combined drop and create.\r\n\r\nI think the initial PR should focus on just the RTAS case. That simplifies this because it no longer needs the type list. What do you think?",
        "createdAt" : "2019-06-06T21:42:43Z",
        "updatedAt" : "2019-07-19T19:00:59Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "7381ffff-0552-4131-b4f6-a0eaf741d14f",
        "parentId" : "8f72e795-f1eb-4469-8a46-d9d5f2d2c485",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "I think this should support the `USING` clause that is used to pass the provider name.",
        "createdAt" : "2019-06-06T21:45:15Z",
        "updatedAt" : "2019-07-19T19:00:59Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "d61e4098-19a6-4a9f-8c75-01a6620ff1a5",
        "parentId" : "8f72e795-f1eb-4469-8a46-d9d5f2d2c485",
        "authorId" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "body" : "Because of the `tableProvider` field at the end I think `USING` is still supported right? As mentioned elsewhere, this is copied from CTAS.",
        "createdAt" : "2019-06-06T22:31:15Z",
        "updatedAt" : "2019-07-19T19:00:59Z",
        "lastEditedBy" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "tags" : [
        ]
      },
      {
        "id" : "13d6647f-b0c2-4b0a-8fa3-78e23615f98f",
        "parentId" : "8f72e795-f1eb-4469-8a46-d9d5f2d2c485",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "Is there a test for it?",
        "createdAt" : "2019-06-12T23:18:01Z",
        "updatedAt" : "2019-07-19T19:00:59Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      }
    ],
    "commit" : "05a827df7094b07a492add875c6e649df52db41f",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +114,118 @@    | CREATE TABLE (IF NOT EXISTS)? target=tableIdentifier\n        LIKE source=tableIdentifier locationSpec?                      #createTableLike\n    | replaceTableHeader ('(' colTypeList ')')? tableProvider\n        ((OPTIONS options=tablePropertyList) |\n        (PARTITIONED BY partitioning=transformList) |"
  },
  {
    "id" : "8f8ea384-8e1c-444b-a000-8b41db29bb0a",
    "prId" : 24798,
    "prUrl" : "https://github.com/apache/spark/pull/24798#pullrequestreview-246846514",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a61594a8-2d63-45ab-a382-41ad6652929b",
        "parentId" : null,
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "Should bucketing be added using `BUCKET BY`? Or should we rely on `bucket` as a transform in the `PARTITIONED BY` clause?",
        "createdAt" : "2019-06-06T21:43:23Z",
        "updatedAt" : "2019-07-19T19:00:59Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "e16d7192-4b87-4443-a648-0b5631bb4f62",
        "parentId" : "a61594a8-2d63-45ab-a382-41ad6652929b",
        "authorId" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "body" : "Same as https://github.com/apache/spark/pull/24798#discussion_r291395947 - this is copied from the create table spec.",
        "createdAt" : "2019-06-06T22:29:45Z",
        "updatedAt" : "2019-07-19T19:00:59Z",
        "lastEditedBy" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "tags" : [
        ]
      }
    ],
    "commit" : "05a827df7094b07a492add875c6e649df52db41f",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +117,121 @@        ((OPTIONS options=tablePropertyList) |\n        (PARTITIONED BY partitioning=transformList) |\n        bucketSpec |\n        locationSpec |\n        (COMMENT comment=STRING) |"
  },
  {
    "id" : "52c78520-b9c7-44d8-8e93-5b34efb563b4",
    "prId" : 24798,
    "prUrl" : "https://github.com/apache/spark/pull/24798#pullrequestreview-247172244",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a999cbdc-2780-46c9-a1a5-e323bf316c15",
        "parentId" : null,
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "Should OPTIONS be supported in v2? Right now, we copy options into table properties because v2 has no separate options. I also think it is confusing to users that there are table properties and options.",
        "createdAt" : "2019-06-06T21:46:07Z",
        "updatedAt" : "2019-07-19T19:00:59Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "919d0d18-5993-4ec2-bd86-75cda443c695",
        "parentId" : "a999cbdc-2780-46c9-a1a5-e323bf316c15",
        "authorId" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "body" : "In general I copied this entirely from the equivalent create table statement. How does the syntax for `REPLACE TABLE` differ from that of the existing `CREATE TABLE`? My understanding is `REPLACE TABLE` is exactly equivalent to `CREATE TABLE` with the exception of not having an `IF NOT EXISTS` option.",
        "createdAt" : "2019-06-06T22:29:20Z",
        "updatedAt" : "2019-07-19T19:00:59Z",
        "lastEditedBy" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "tags" : [
        ]
      },
      {
        "id" : "afb123d5-b1d5-4027-a9f0-a6fe0c654a2c",
        "parentId" : "a999cbdc-2780-46c9-a1a5-e323bf316c15",
        "authorId" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "body" : "The chunk I copied I believe is https://github.com/apache/spark/pull/24798/files/bc8d3b568988c904dff4f31a19f6dc0aa33f4a8b#diff-8c1cb2af4aa1109e08481dae79052cc3R93.",
        "createdAt" : "2019-06-06T22:31:28Z",
        "updatedAt" : "2019-07-19T19:00:59Z",
        "lastEditedBy" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "tags" : [
        ]
      },
      {
        "id" : "3876795e-fcf7-4435-ad4f-e6080d2df346",
        "parentId" : "a999cbdc-2780-46c9-a1a5-e323bf316c15",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "True, it should be the same a `CREATE TABLE`. That's a good reason to carry this forward.",
        "createdAt" : "2019-06-07T15:46:53Z",
        "updatedAt" : "2019-07-19T19:00:59Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      }
    ],
    "commit" : "05a827df7094b07a492add875c6e649df52db41f",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +115,119 @@        LIKE source=tableIdentifier locationSpec?                      #createTableLike\n    | replaceTableHeader ('(' colTypeList ')')? tableProvider\n        ((OPTIONS options=tablePropertyList) |\n        (PARTITIONED BY partitioning=transformList) |\n        bucketSpec |"
  },
  {
    "id" : "13c353ee-1db0-450b-9595-f05dcc603352",
    "prId" : 24798,
    "prUrl" : "https://github.com/apache/spark/pull/24798#pullrequestreview-259163120",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "de37b6ff-f79e-4618-9fa8-d61a2b83af85",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I'm worried about creating new SQL syntax in Spark. AFAIK a similar syntax is `CREATE OR REPLACE TABLE`, which is implemented in [DB2](https://www.ibm.com/support/knowledgecenter/en/ssw_ibm_i_72/sqlp/rbafyreplacetable.htm) and [google BigQuery](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language).\r\n\r\nThis is not a standard SQL syntax, so it's not surprising to see that Oracle doesn't support it. If Spark want a API for replace table, I think it's more reasonable to follow DB2 and BigQuery here.",
        "createdAt" : "2019-07-04T08:49:44Z",
        "updatedAt" : "2019-07-19T19:00:59Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "bec87d7b-c2fd-4d11-b287-df0875f54d0e",
        "parentId" : "de37b6ff-f79e-4618-9fa8-d61a2b83af85",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "I'm fine using `[CREATE OR] REPLACE TABLE` instead of `REPLACE TABLE [IF NOT EXISTS]`. I think that is better syntax.",
        "createdAt" : "2019-07-04T17:17:26Z",
        "updatedAt" : "2019-07-19T19:00:59Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "c92b2c0b-5758-4d44-a17a-c1e73b17674a",
        "parentId" : "de37b6ff-f79e-4618-9fa8-d61a2b83af85",
        "authorId" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "body" : "So do we remove the existing support for the `IF NOT EXISTS` syntax in the SQL syntax? I think we'd want to avoid breaking existing SQL queries even in the 3.0 release.\r\n\r\nOr do we support:\r\n\r\n```\r\nCREATE (OR REPLACE)? TABLE ... (IF NOT EXISTS)?\r\n```\r\n\r\nand then throw `AnalysisException` if: `CREATE OR REPLACE TABLE ... IF NOT EXISTS`?",
        "createdAt" : "2019-07-08T20:23:47Z",
        "updatedAt" : "2019-07-19T19:00:59Z",
        "lastEditedBy" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "tags" : [
        ]
      },
      {
        "id" : "03b23ffe-d495-488f-9ae5-1da2c31f2170",
        "parentId" : "de37b6ff-f79e-4618-9fa8-d61a2b83af85",
        "authorId" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "body" : "> I'm fine using `[CREATE OR] REPLACE TABLE` instead of `REPLACE TABLE [IF NOT EXISTS]`. I think that is better syntax.\r\n\r\nWe don't support `REPLACE... IF NOT EXISTS` in this PR. It's only either `CREATE TABLE IF NOT EXISTS` or `REPLACE TABLE`. I don't see any reason to include `CREATE OR REPLACE` table if we don't want to replace the `IF NOT EXISTS` parameter in existing spark-sql, but removing support for `IF NOT EXISTS` risks breaking existing SQL workflows as I've described above.",
        "createdAt" : "2019-07-08T20:29:43Z",
        "updatedAt" : "2019-07-19T19:00:59Z",
        "lastEditedBy" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "tags" : [
        ]
      },
      {
        "id" : "45ea12d4-537a-48d4-8a46-13ee9ca759aa",
        "parentId" : "de37b6ff-f79e-4618-9fa8-d61a2b83af85",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "I'd say let's remove `IF NOT EXISTS` from the parser, but just for `REPLACE TABLE`.\r\n\r\nThen, we should add an option to add `CREATE OR`, to the start, which would set an `orCreate` flag to true. If that is true, and the table doesn't exist, then create the table instead of replacing it. If that is false, then throw an exception that the table doesn't exist.",
        "createdAt" : "2019-07-08T20:37:37Z",
        "updatedAt" : "2019-07-19T19:00:59Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "db402a8b-fcfd-4580-adec-1c18ed43c76e",
        "parentId" : "de37b6ff-f79e-4618-9fa8-d61a2b83af85",
        "authorId" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "body" : "I think that makes sense, though the current implementation doesn't have a rule supporting `REPLACE TABLE IF NOT EXISTS`.",
        "createdAt" : "2019-07-08T20:40:59Z",
        "updatedAt" : "2019-07-19T19:00:59Z",
        "lastEditedBy" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "tags" : [
        ]
      },
      {
        "id" : "7c4d3a60-4ca8-4e84-9b35-e10242d49fd0",
        "parentId" : "de37b6ff-f79e-4618-9fa8-d61a2b83af85",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "It it isn't supported, then we can throw an exception.",
        "createdAt" : "2019-07-08T20:55:34Z",
        "updatedAt" : "2019-07-19T19:00:59Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "4d174dfe-951b-481d-bea7-148a7a592314",
        "parentId" : "de37b6ff-f79e-4618-9fa8-d61a2b83af85",
        "authorId" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "body" : "Since that clause isn't supported in the `SqlBase.g4` file itself, I'd expect the parser to throw an exception for us.",
        "createdAt" : "2019-07-08T21:20:55Z",
        "updatedAt" : "2019-07-19T19:00:59Z",
        "lastEditedBy" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "tags" : [
        ]
      }
    ],
    "commit" : "05a827df7094b07a492add875c6e649df52db41f",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +270,274 @@    ;\n\nreplaceTableHeader\n    : (CREATE OR)? REPLACE TABLE multipartIdentifier\n    ;"
  },
  {
    "id" : "f84786e2-82a6-4e66-a8bb-d055b1a34a5b",
    "prId" : 24780,
    "prUrl" : "https://github.com/apache/spark/pull/24780#pullrequestreview-250517512",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "733ab8b0-0a3c-4e16-8da7-1dcb4ca8cd74",
        "parentId" : null,
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "I am fine to add this syntax, but this only supports changing column comments, right?",
        "createdAt" : "2019-06-04T23:55:02Z",
        "updatedAt" : "2019-06-05T13:46:26Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      },
      {
        "id" : "62f30f7d-1632-43c9-992c-30c80a4f3a14",
        "parentId" : "733ab8b0-0a3c-4e16-8da7-1dcb4ca8cd74",
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "Dropping the column is still risky to us. When you adding the columns back, we might see the unexpected values. ",
        "createdAt" : "2019-06-04T23:57:04Z",
        "updatedAt" : "2019-06-05T13:46:26Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      },
      {
        "id" : "282683ae-4037-4952-8875-eaec6c52b7ab",
        "parentId" : "733ab8b0-0a3c-4e16-8da7-1dcb4ca8cd74",
        "authorId" : "5a447b79-39cd-420f-947f-1689950564a6",
        "body" : "@gatorsmile the idea is actually to implement `alter table replace colu\u001dmns` fully:\r\n- drop column if not preset in the new schema\r\n- add column, if not preset in the tableâ€™s schema\r\n- keep column if colum_name and colum_type match between schemas\r\n- raise exception if trying to replace an existing column with a different data type\r\n\r\nI believe this is a much needed feature to be able to manage meta-stores fully from Spark; however I understand the complexity and risks of this operation, so please letâ€™s take the time to ensure itâ€™s the right thing to do and all possibile ramifications.\r\n\r\nI tried to make the commit history as clean and as descriptive as possibile and just added some more details in the PR description `known issues` section.\r\n\r\nI've also added an extra validation step to prevent columns to be replaced if the data type doesn't match (8b6da23)\r\n\r\nLet me know if anything isnâ€™t clear and I'll be happy add more details.\r\n\r\nThanks!",
        "createdAt" : "2019-06-05T12:02:36Z",
        "updatedAt" : "2019-06-05T13:46:26Z",
        "lastEditedBy" : "5a447b79-39cd-420f-947f-1689950564a6",
        "tags" : [
        ]
      },
      {
        "id" : "54cac258-9a85-41f9-bee1-10df87ee796d",
        "parentId" : "733ab8b0-0a3c-4e16-8da7-1dcb4ca8cd74",
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "Let me give a typical scenario. For an existing table, if we drop the column `col1`, the data will not be visible to the end users. This is expected. However, if we add `col1` back, the previous values of the column `col1` should not be visible to the end users too. This is how the other database systems work. What is your thought? ",
        "createdAt" : "2019-06-05T15:48:44Z",
        "updatedAt" : "2019-06-05T15:48:44Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      },
      {
        "id" : "f6b96b4d-778d-4a3c-947e-9f09885c2fed",
        "parentId" : "733ab8b0-0a3c-4e16-8da7-1dcb4ca8cd74",
        "authorId" : "5a447b79-39cd-420f-947f-1689950564a6",
        "body" : "i understand your point, it makes total sense and i would completely agree if hive was like the other dbms.  according to your scenario, also the below should not be possibile, but it is:  \r\n\r\n```\r\n>>> spark.sql(\"CREATE EXTERNAL TABLE test_table (c1 string, c2 int ) STORED AS PARQUET LOCATION '/tmp/test_table'\")\r\nDataFrame[]\r\n\r\n>>> spark.sql(\"INSERT INTO test_table VALUES ('c1', 2)\")\r\nDataFrame[]\r\n\r\n>>> spark.sql(\"SELECT * FROM test_table\").show()\r\n+---+---+\r\n| c1| c2|\r\n+---+---+\r\n| c1|  2|\r\n+---+---+\r\n\r\n>>> spark.sql(\"DROP TABLE test_table\")\r\nDataFrame[]\r\n\r\n>>> spark.catalog.listTables()\r\n[]\r\n\r\n>>> spark.sql(\"CREATE EXTERNAL TABLE test_table (c1 string, c2 int, c3 boolean) STORED AS PARQUET LOCATION '/tmp/test_table'\")\r\nDataFrame[]\r\n\r\n>>> spark.sql(\"SELECT * FROM test_table\").show()\r\n+---+---+----+\r\n| c1| c2|  c3|\r\n+---+---+----+\r\n| c1|  2|null|\r\n+---+---+----+\r\n``` \r\n\r\ndo you agree it's the same behaviour you explained in the \"drop / re-create column\" example?",
        "createdAt" : "2019-06-05T16:29:14Z",
        "updatedAt" : "2019-06-05T16:29:14Z",
        "lastEditedBy" : "5a447b79-39cd-420f-947f-1689950564a6",
        "tags" : [
        ]
      },
      {
        "id" : "deaf5968-7b31-4e3c-867d-543c9d09d338",
        "parentId" : "733ab8b0-0a3c-4e16-8da7-1dcb4ca8cd74",
        "authorId" : "5a447b79-39cd-420f-947f-1689950564a6",
        "body" : "@gatorsmile any thoughts about my previous comment?\r\n\r\ni was wandering if this could be just a miscommunication issue as you are referring to the behaviour of `alter table replace columns` with \"normal tables\", while i'm manly talking about \"external tables\"?\r\n\r\nmaybe `replace columns` could be enabled only for `external tables`?  would that be acceptable / less risky in your opinion?",
        "createdAt" : "2019-06-17T14:06:30Z",
        "updatedAt" : "2019-06-17T14:06:32Z",
        "lastEditedBy" : "5a447b79-39cd-420f-947f-1689950564a6",
        "tags" : [
        ]
      },
      {
        "id" : "40667e01-f256-4bab-905c-ad6e7036e783",
        "parentId" : "733ab8b0-0a3c-4e16-8da7-1dcb4ca8cd74",
        "authorId" : "5a447b79-39cd-420f-947f-1689950564a6",
        "body" : "@gatorsmile any thoughts about my previous comment?\r\n\r\ni was wandering if this could be just a miscommunication issue as you are referring to the behaviour of `alter table replace columns` with \"normal tables\", while i'm manly talking about \"external tables\"?\r\n\r\nmaybe `replace columns` could be enabled only for `external tables`?  would that be acceptable / less risky in your opinion?",
        "createdAt" : "2019-06-17T14:06:43Z",
        "updatedAt" : "2019-06-17T14:06:43Z",
        "lastEditedBy" : "5a447b79-39cd-420f-947f-1689950564a6",
        "tags" : [
        ]
      }
    ],
    "commit" : "30641eb6114d7af6deb009423531bb261bce1600",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +117,121 @@        ADD COLUMNS '(' columns=colTypeList ')'                        #addTableColumns\n    | ALTER TABLE tableIdentifier\n        REPLACE COLUMNS '(' columns=colTypeList ')'                    #replaceTableColumns\n    | ALTER (TABLE | VIEW) from=tableIdentifier\n        RENAME TO to=tableIdentifier                                   #renameTable"
  },
  {
    "id" : "d70d547d-4c11-4b6f-b98e-dfb031faf696",
    "prId" : 24749,
    "prUrl" : "https://github.com/apache/spark/pull/24749#pullrequestreview-246171454",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "aa26bbc8-36c5-4139-a4da-80052de624be",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "This is a good change. I mean `ctx.db` instead of `ctx.errorCapturingIdentifier` in `visitDropDatabase`. Could you improve the other db identifiers like this, too?",
        "createdAt" : "2019-06-05T03:08:51Z",
        "updatedAt" : "2019-06-18T20:09:57Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "e2ceca75-a8ac-4425-a3c6-071f778919d0",
        "parentId" : "aa26bbc8-36c5-4139-a4da-80052de624be",
        "authorId" : "88f0c774-9c59-4485-885d-f6aee36efcea",
        "body" : "done",
        "createdAt" : "2019-06-05T05:51:36Z",
        "updatedAt" : "2019-06-18T20:09:57Z",
        "lastEditedBy" : "88f0c774-9c59-4485-885d-f6aee36efcea",
        "tags" : [
        ]
      },
      {
        "id" : "742f110d-d252-424a-8e20-cda3c7b7641a",
        "parentId" : "aa26bbc8-36c5-4139-a4da-80052de624be",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Thanks!",
        "createdAt" : "2019-06-05T18:07:49Z",
        "updatedAt" : "2019-06-18T20:09:57Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "e1996b8bc7aaa3dcaac61a3c93d904a9ef2ce696",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +90,94 @@    | ALTER database db=errorCapturingIdentifier\n        SET DBPROPERTIES tablePropertyList                             #setDatabaseProperties\n    | DROP database (IF EXISTS)? db=errorCapturingIdentifier\n        (RESTRICT | CASCADE)?                                          #dropDatabase\n    | SHOW DATABASES (LIKE? pattern=STRING)?                           #showDatabases"
  },
  {
    "id" : "28a45d65-7d31-4c7d-a34f-9181503178c3",
    "prId" : 24749,
    "prUrl" : "https://github.com/apache/spark/pull/24749#pullrequestreview-247311573",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6caffe30-1ab1-4fd2-9a67-38cf15b50215",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "@yeshengm . Can we have a test coverage for this?",
        "createdAt" : "2019-06-07T21:21:32Z",
        "updatedAt" : "2019-06-18T20:09:57Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "e1996b8bc7aaa3dcaac61a3c93d904a9ef2ce696",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +139,143 @@    | ALTER TABLE tableIdentifier partitionSpec?\n        CHANGE COLUMN?\n        colName=errorCapturingIdentifier colType colPosition?          #changeColumn\n    | ALTER TABLE tableIdentifier (partitionSpec)?\n        SET SERDE STRING (WITH SERDEPROPERTIES tablePropertyList)?     #setTableSerDe"
  },
  {
    "id" : "ee7b438b-15de-43d9-9bd2-c6be38ca35b8",
    "prId" : 24749,
    "prUrl" : "https://github.com/apache/spark/pull/24749#pullrequestreview-247317458",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c59b9ed7-901f-470a-b026-cd4a094a899a",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Can we have a test coverage for this?",
        "createdAt" : "2019-06-07T21:41:47Z",
        "updatedAt" : "2019-06-18T20:09:57Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "e1996b8bc7aaa3dcaac61a3c93d904a9ef2ce696",
    "line" : 44,
    "diffHunk" : "@@ -1,1 +183,187 @@        ('(' key=tablePropertyKey ')')?                                #showTblProperties\n    | SHOW COLUMNS (FROM | IN) tableIdentifier\n        ((FROM | IN) db=errorCapturingIdentifier)?                     #showColumns\n    | SHOW PARTITIONS tableIdentifier partitionSpec?                   #showPartitions\n    | SHOW identifier? FUNCTIONS"
  },
  {
    "id" : "94abea06-ae63-4400-85a3-0f9bbf7b996e",
    "prId" : 24749,
    "prUrl" : "https://github.com/apache/spark/pull/24749#pullrequestreview-247319166",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "602d81d0-bbc7-47a8-813d-4690cd310446",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Test coverage for this?",
        "createdAt" : "2019-06-07T21:48:07Z",
        "updatedAt" : "2019-06-18T20:09:57Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "e1996b8bc7aaa3dcaac61a3c93d904a9ef2ce696",
    "line" : 51,
    "diffHunk" : "@@ -1,1 +189,193 @@    | SHOW CREATE TABLE tableIdentifier                                #showCreateTable\n    | (DESC | DESCRIBE) FUNCTION EXTENDED? describeFuncName            #describeFunction\n    | (DESC | DESCRIBE) database EXTENDED? db=errorCapturingIdentifier #describeDatabase\n    | (DESC | DESCRIBE) TABLE? option=(EXTENDED | FORMATTED)?\n        tableIdentifier partitionSpec? describeColName?                #describeTable"
  },
  {
    "id" : "6038809a-f170-4959-b2fa-a915482ed58f",
    "prId" : 24749,
    "prUrl" : "https://github.com/apache/spark/pull/24749#pullrequestreview-271760666",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e2785dd6-3ee7-4550-8b84-5865e1e5c19f",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "is it possible to break `1 AS a-b`? We can interpret it as `(1 AS a) - b`, which is valid if b is a valid column. ",
        "createdAt" : "2019-08-07T06:42:32Z",
        "updatedAt" : "2019-08-07T06:42:32Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "bd4e344a-fb1d-4f8e-ad79-d6ca4681c7b6",
        "parentId" : "e2785dd6-3ee7-4550-8b84-5865e1e5c19f",
        "authorId" : "88f0c774-9c59-4485-885d-f6aee36efcea",
        "body" : "I just tried on Postgres, and it's a syntax error.",
        "createdAt" : "2019-08-07T06:51:34Z",
        "updatedAt" : "2019-08-07T06:51:34Z",
        "lastEditedBy" : "88f0c774-9c59-4485-885d-f6aee36efcea",
        "tags" : [
        ]
      },
      {
        "id" : "bad86302-2880-42c0-8a4e-6f9c50e56b82",
        "parentId" : "e2785dd6-3ee7-4550-8b84-5865e1e5c19f",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ah nvm, `AS` means the end of an expression in the select list, so only `1 AS a, ...` is allowed",
        "createdAt" : "2019-08-07T06:52:20Z",
        "updatedAt" : "2019-08-07T06:52:21Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "e178d0e9-8e91-4ead-a54a-a3a3c15bab08",
        "parentId" : "e2785dd6-3ee7-4550-8b84-5865e1e5c19f",
        "authorId" : "88f0c774-9c59-4485-885d-f6aee36efcea",
        "body" : "In fact, in ANSI-SQL, select statements in a query spec are only allowed to be the format of `expr1 AS alias2, expr2 AS alias2`.",
        "createdAt" : "2019-08-07T06:53:53Z",
        "updatedAt" : "2019-08-07T06:53:53Z",
        "lastEditedBy" : "88f0c774-9c59-4485-885d-f6aee36efcea",
        "tags" : [
        ]
      },
      {
        "id" : "82f2fda2-e83d-4ef7-aa20-16ed8b337b4c",
        "parentId" : "e2785dd6-3ee7-4550-8b84-5865e1e5c19f",
        "authorId" : "88f0c774-9c59-4485-885d-f6aee36efcea",
        "body" : "FYI https://ronsavage.github.io/SQL/sql-2003-2.bnf.html#select%20list",
        "createdAt" : "2019-08-07T06:54:17Z",
        "updatedAt" : "2019-08-07T06:54:18Z",
        "lastEditedBy" : "88f0c774-9c59-4485-885d-f6aee36efcea",
        "tags" : [
        ]
      }
    ],
    "commit" : "e1996b8bc7aaa3dcaac61a3c93d904a9ef2ce696",
    "line" : 111,
    "diffHunk" : "@@ -1,1 +625,629 @@\nnamedExpression\n    : expression (AS? (name=errorCapturingIdentifier | identifierList))?\n    ;\n"
  },
  {
    "id" : "662d5f85-82ab-4fba-a258-9fcad9b1a07f",
    "prId" : 24723,
    "prUrl" : "https://github.com/apache/spark/pull/24723#pullrequestreview-245575618",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e0183e72-91fb-4ef4-91b7-695b90eca5bb",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "we should also add it to `ansiNonReserved`.\r\n\r\nBTW is this a non-reserved keyword? @maropu ",
        "createdAt" : "2019-06-02T02:14:03Z",
        "updatedAt" : "2019-06-04T19:04:01Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "2a8fc1c8-a208-445a-a981-790f2b3b509a",
        "parentId" : "e0183e72-91fb-4ef4-91b7-695b90eca5bb",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "This is not an [ANSI reserved keyword](http://infocenter.sybase.com/help/index.jsp?topic=/com.sybase.infocenter.dc36271.1550/html/blocks/BEIJHIFE.htm), but it is reserved in [MySQL](https://dev.mysql.com/doc/refman/8.0/en/keywords.html), [PostgreSQL](https://www.postgresql.org/docs/11/sql-keywords-appendix.html), and [DB2](https://www.ibm.com/support/knowledgecenter/en/SSEPEK_11.0.0/sqlref/src/tpc/db2z_reservedwords.html). It is also on the list of [potential ANSI reserved keywords](http://infocenter.sybase.com/help/index.jsp?topic=/com.sybase.infocenter.dc36271.1550/html/blocks/BEIJCJHC.htm).",
        "createdAt" : "2019-06-04T16:55:24Z",
        "updatedAt" : "2019-06-04T19:04:01Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      }
    ],
    "commit" : "bd7d8c8f7c6a2c378deba5927c96a8eb4dc6ef54",
    "line" : 81,
    "diffHunk" : "@@ -1,1 +1271,1275 @@    | TRUE\n    | TRUNCATE\n    | TYPE\n    | UNARCHIVE\n    | UNBOUNDED"
  },
  {
    "id" : "09fe5c6c-d3da-4ad7-98fa-5444a53a1844",
    "prId" : 24723,
    "prUrl" : "https://github.com/apache/spark/pull/24723#pullrequestreview-245565458",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "76b3ea26-5d2e-4ae1-9d2a-9f91ed990745",
        "parentId" : null,
        "authorId" : "43998e22-6c2f-401d-9914-8cecf6fad929",
        "body" : "Do we need to modify this? I'm not sure what happens if something like:\r\n\r\n```\r\nALTER TABLE tbl ADD a.b.c ... AFTER x.y\r\n```\r\n",
        "createdAt" : "2019-06-04T11:08:38Z",
        "updatedAt" : "2019-06-04T19:04:01Z",
        "lastEditedBy" : "43998e22-6c2f-401d-9914-8cecf6fad929",
        "tags" : [
        ]
      },
      {
        "id" : "001639db-e489-4132-b456-c64ed510f43f",
        "parentId" : "76b3ea26-5d2e-4ae1-9d2a-9f91ed990745",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "Yes, this is needed because columns are identified by `qualifiedName`. The parser shouldn't fail if a nested column name is used. Instead, analysis should catch problems.",
        "createdAt" : "2019-06-04T16:28:05Z",
        "updatedAt" : "2019-06-04T19:04:01Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "ec4f1304-c66f-4a24-b44d-bcdf12ac5c89",
        "parentId" : "76b3ea26-5d2e-4ae1-9d2a-9f91ed990745",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "I should also add that it is valid to reorder nested fields:\r\n\r\n```\r\nALTER TABLE tbl ADD point.z bigint AFTER point.y\r\n```",
        "createdAt" : "2019-06-04T16:35:35Z",
        "updatedAt" : "2019-06-04T19:04:01Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      }
    ],
    "commit" : "bd7d8c8f7c6a2c378deba5927c96a8eb4dc6ef54",
    "line" : 47,
    "diffHunk" : "@@ -1,1 +735,739 @@\ncolPosition\n    : FIRST | AFTER qualifiedName\n    ;\n"
  },
  {
    "id" : "f58c8c14-3250-4679-be6e-ddb914bc7839",
    "prId" : 24723,
    "prUrl" : "https://github.com/apache/spark/pull/24723#pullrequestreview-245666859",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8e49644f-7859-47a2-bd1e-ff449de4f6a9",
        "parentId" : null,
        "authorId" : "43998e22-6c2f-401d-9914-8cecf6fad929",
        "body" : "How will we handle this version of `CHANGE COLUMN` command?\r\nShould we merge this in the `(ALTER | CHANGE) COLUMN` command above?",
        "createdAt" : "2019-06-04T11:25:23Z",
        "updatedAt" : "2019-06-04T19:04:01Z",
        "lastEditedBy" : "43998e22-6c2f-401d-9914-8cecf6fad929",
        "tags" : [
        ]
      },
      {
        "id" : "fb018902-2ab6-4424-aaed-aad3b00b8b71",
        "parentId" : "8e49644f-7859-47a2-bd1e-ff449de4f6a9",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "I think we need to discuss deprecating this form of the command, which is why I haven't updated it.\r\n\r\nThe problem is that this requires the user to specify too much of a column's metadata when it isn't changing. For example, if I'm updating an int to a long, I also need to specify that it should have the same name (`UPDATE a a BIGINT`). Similarly, to rename you have to pass the type back in (`UPDATE a b INT`). This can easily lead to unintended changes that can't be reverted, like widening a type accidentally.\r\n\r\nI think that this form of the command should not be supported in v2. We can decide that later because all this is doing is updating the parser to add commands that we need to support.",
        "createdAt" : "2019-06-04T19:53:03Z",
        "updatedAt" : "2019-06-04T19:53:03Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      }
    ],
    "commit" : "bd7d8c8f7c6a2c378deba5927c96a8eb4dc6ef54",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +136,140 @@        (TYPE dataType)? (COMMENT comment=STRING)? colPosition?        #alterTableColumn\n    | ALTER TABLE tableIdentifier partitionSpec?\n        CHANGE COLUMN? identifier colType colPosition?                 #changeColumn\n    | ALTER TABLE tableIdentifier (partitionSpec)?\n        SET SERDE STRING (WITH SERDEPROPERTIES tablePropertyList)?     #setTableSerDe"
  },
  {
    "id" : "3835e6d8-c3ee-46d1-84f5-0f60417c5bff",
    "prId" : 24686,
    "prUrl" : "https://github.com/apache/spark/pull/24686#pullrequestreview-243902622",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "967cf9db-c996-46f5-8323-82e8b7a17656",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "do we have view support in DS v2? This is surprising to me, as I thought we may treat table/view differently in DS v2. Personally I think it's a bad idea that hive unifies table and view, it's weird to see the `sqlText` field in Hive `Table` class.",
        "createdAt" : "2019-05-30T00:24:16Z",
        "updatedAt" : "2019-05-30T03:06:36Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "0749e1d6-60ca-409a-a635-0ca4b7aa986a",
        "parentId" : "967cf9db-c996-46f5-8323-82e8b7a17656",
        "authorId" : "f5b3f57a-75a6-496c-af94-c32580ada13a",
        "body" : "Echo your sentiment towards Hive view handling. That is why I separated visitDropView from visitDropTable and added DropView operator in preparation for enhancements, possibly even view catalog.",
        "createdAt" : "2019-05-30T01:36:50Z",
        "updatedAt" : "2019-05-30T03:07:31Z",
        "lastEditedBy" : "f5b3f57a-75a6-496c-af94-c32580ada13a",
        "tags" : [
        ]
      },
      {
        "id" : "626af800-28f4-410f-83d4-d277fe9405ac",
        "parentId" : "967cf9db-c996-46f5-8323-82e8b7a17656",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Are you going to add `DropView` operator in this PR? If not I think it's better to not add `DropViewStatement` in this PR. We can have a separated PR to add the view support.\r\n\r\nI think we haven't reached a consensus that DROP VIEW is implemented via `TableCatalog.dropTable`.",
        "createdAt" : "2019-05-30T03:33:59Z",
        "updatedAt" : "2019-05-30T03:33:59Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "4b502e61-4b9d-4936-b456-67b733d7298b",
        "parentId" : "967cf9db-c996-46f5-8323-82e8b7a17656",
        "authorId" : "f5b3f57a-75a6-496c-af94-c32580ada13a",
        "body" : "I see, separate visitDropView makes it possible to delay moving DropView to catalyst. I am ok either way.",
        "createdAt" : "2019-05-30T04:29:35Z",
        "updatedAt" : "2019-05-30T04:29:35Z",
        "lastEditedBy" : "f5b3f57a-75a6-496c-af94-c32580ada13a",
        "tags" : [
        ]
      },
      {
        "id" : "fc7b7686-a993-48a1-8bd9-cb0642ebb59a",
        "parentId" : "967cf9db-c996-46f5-8323-82e8b7a17656",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "I think since these were mixed together originally, it makes sense to move both statements to create parsed plans at the same time. We are going to need to do this eventually anyway.\r\n\r\nWhy change to use a separate `visitDropView`, but not also move it to Catalyst and use a parsed plan? Is there value in keeping it that way?",
        "createdAt" : "2019-05-30T15:52:50Z",
        "updatedAt" : "2019-05-30T15:52:50Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "4f246ffd-7375-4e4f-89a2-7a49d7a99e6c",
        "parentId" : "967cf9db-c996-46f5-8323-82e8b7a17656",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Yes Hive mixes DROP TABLE and DROP VIEW, but it doesn't mean we have to follow it in data source v2. At least this needs to be discussed.\r\n\r\nIt seems weird to me that we forward the DROP VIEW request to `TableCatalog` implementations, without official view support in data source v2.",
        "createdAt" : "2019-05-30T16:05:08Z",
        "updatedAt" : "2019-05-30T16:05:08Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "c09d1d84-7408-4b99-aefe-435470e63b52",
        "parentId" : "967cf9db-c996-46f5-8323-82e8b7a17656",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "@cloud-fan, that's not what this PR does. This PR moves parsing into Catalyst by introducing a parsed plan, `DropViewStatement`, for `DROP VIEW`. We can still convert that to a `DropTable` in the analyzer if we choose to later, like we do for v1. (But I think it makes much more sense to use a `ViewCatalog`.)\r\n\r\nThe important thing is that we want to keep moving parsing code into Catalyst using parsed plans to separate the implementation (DataSource logical plans) from the parsing logic so that the parser isn't tightly coupled to DataSource v1.",
        "createdAt" : "2019-05-30T16:11:55Z",
        "updatedAt" : "2019-05-30T16:11:56Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "0dd9074c-bdac-4ec2-bee2-bfbe0a22011a",
        "parentId" : "967cf9db-c996-46f5-8323-82e8b7a17656",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ah you are right! sorry I read the PR too fast",
        "createdAt" : "2019-05-30T16:45:53Z",
        "updatedAt" : "2019-05-30T16:45:53Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "d5b0d4ad5f276a9f9fd52154c782418b8fa80a28",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +141,145 @@    | ALTER TABLE tableIdentifier RECOVER PARTITIONS                   #recoverPartitions\n    | DROP TABLE (IF EXISTS)? multipartIdentifier PURGE?               #dropTable\n    | DROP VIEW (IF EXISTS)? multipartIdentifier                       #dropView\n    | CREATE (OR REPLACE)? (GLOBAL? TEMPORARY)?\n        VIEW (IF NOT EXISTS)? tableIdentifier"
  },
  {
    "id" : "c1ce26a8-9780-4b49-8c2c-6fb4e3c30db2",
    "prId" : 24624,
    "prUrl" : "https://github.com/apache/spark/pull/24624#pullrequestreview-238377356",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "41a25dcf-e4c4-470e-b10f-930ef37f1d6b",
        "parentId" : null,
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "Do we need to recreate the data after changing the bucket info?",
        "createdAt" : "2019-05-16T13:05:00Z",
        "updatedAt" : "2019-05-16T13:05:00Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      }
    ],
    "commit" : "ead21674251cef4b1058efb5c36a2ecf7e812a14",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +139,143 @@    | ALTER TABLE tableIdentifier partitionSpec? SET locationSpec      #setTableLocation\n    | ALTER TABLE tableIdentifier RECOVER PARTITIONS                   #recoverPartitions\n    | ALTER TABLE tableIdentifier bucketSpec                           #updateTableBucket\n    | DROP TABLE (IF EXISTS)? tableIdentifier PURGE?                   #dropTable\n    | DROP VIEW (IF EXISTS)? tableIdentifier                           #dropTable"
  }
]