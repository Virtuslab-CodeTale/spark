[
  {
    "id" : "4ebe24ed-28af-4554-8cdd-79a1ff3639bd",
    "prId" : 30706,
    "prUrl" : "https://github.com/apache/spark/pull/30706#pullrequestreview-549648892",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0e4fe5c5-9891-43fc-b8c0-239fdf56caa3",
        "parentId" : null,
        "authorId" : "4a94765a-5775-4d88-b283-6ee68d76ecc7",
        "body" : "@sunchao, I thought abou defaulting these implementations as `build().toBatch()` but it will introduce a circular dependency between these methods. Data sources may only implement `buildForBatch`, for example. Right now, calling `buildForStreaming` will produce an exception for them. If we default, this will result in a stackoverflow exception.",
        "createdAt" : "2020-12-10T11:56:43Z",
        "updatedAt" : "2020-12-10T13:39:15Z",
        "lastEditedBy" : "4a94765a-5775-4d88-b283-6ee68d76ecc7",
        "tags" : [
        ]
      },
      {
        "id" : "d47da54d-6dfe-42cf-a862-09ef9737c644",
        "parentId" : "0e4fe5c5-9891-43fc-b8c0-239fdf56caa3",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "I think you'll also need to change `WriteBuilder.build` to not override `toBatch` and `toStreaming`? such as\r\n```scala\r\n  default Write build() {\r\n    return new Write() {\r\n    };\r\n  }\r\n```\r\n\r\nwith this, Spark users just need to override `build` method in their DS implementations and the old APIs `buildForBatch` and `buildForStreaming` will automatically pick up the logic in the other methods. ",
        "createdAt" : "2020-12-10T18:49:32Z",
        "updatedAt" : "2020-12-10T18:49:33Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "d35c121a-2e53-4155-9279-68a73d8ed8d6",
        "parentId" : "0e4fe5c5-9891-43fc-b8c0-239fdf56caa3",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "@sunchao, I think because of the circular call that @aokolnychyi pointed out, we can either provide a default for `build` or a default for `buildForBatch` / `buildForStreaming`. Anton's approach throws an exception in the old methods, while your approach throws an exception in the new methods.\r\n\r\nI think Anton's approach is the right one because it provides backward-compatibility for sources that currently implement the old methods (`buildForBatch`). Those sources are still compatible without being modified. If we removed the implementation of `toBatch` then we would not be able to call `build` unless the source supported it.\r\n\r\nCompatibility with existing code is the more important concern.",
        "createdAt" : "2020-12-10T21:18:15Z",
        "updatedAt" : "2020-12-10T21:18:15Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "cc43b1d6-4430-470b-806f-b0330f84a3df",
        "parentId" : "0e4fe5c5-9891-43fc-b8c0-239fdf56caa3",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "You are right. I overlooked the compatibility issue. Sorry for the wrong suggestion.",
        "createdAt" : "2020-12-10T22:16:46Z",
        "updatedAt" : "2020-12-10T22:16:46Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      }
    ],
    "commit" : "cc19fd614d9df81d425c95ec81e4c6f34cac2a08",
    "line" : 46,
    "diffHunk" : "@@ -1,1 +61,65 @@  @Deprecated\n  default BatchWrite buildForBatch() {\n    throw new UnsupportedOperationException(getClass().getName() +\n      \" does not support batch write\");\n  }"
  },
  {
    "id" : "ebc54361-23dc-4909-9359-d52dfec4d5a7",
    "prId" : 30706,
    "prUrl" : "https://github.com/apache/spark/pull/30706#pullrequestreview-549123760",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c5a04416-a365-4eb1-b15a-ad9b2d971f8d",
        "parentId" : null,
        "authorId" : "4a94765a-5775-4d88-b283-6ee68d76ecc7",
        "body" : "I decided to deprecate these.",
        "createdAt" : "2020-12-10T11:56:58Z",
        "updatedAt" : "2020-12-10T13:39:15Z",
        "lastEditedBy" : "4a94765a-5775-4d88-b283-6ee68d76ecc7",
        "tags" : [
        ]
      }
    ],
    "commit" : "cc19fd614d9df81d425c95ec81e4c6f34cac2a08",
    "line" : 44,
    "diffHunk" : "@@ -1,1 +59,63 @@   * @deprecated use {@link #build()} instead.\n   */\n  @Deprecated\n  default BatchWrite buildForBatch() {\n    throw new UnsupportedOperationException(getClass().getName() +"
  },
  {
    "id" : "3bb76ace-ebea-43d3-8c17-537ba39194ba",
    "prId" : 29066,
    "prUrl" : "https://github.com/apache/spark/pull/29066#pullrequestreview-546404764",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "09484aba-a41b-479e-8e30-bc93c6a5fafa",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "This API looks like overlapping in function with `buildForBatch` and `buildForStreaming`? Which one we should use? `build` then `toBatch`/`toStream` or `buildForBatch`/`buildForStreaming`?",
        "createdAt" : "2020-08-08T23:42:54Z",
        "updatedAt" : "2020-12-07T14:50:31Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "c53eacca-3ddc-4ea3-b199-aad82ce989e4",
        "parentId" : "09484aba-a41b-479e-8e30-bc93c6a5fafa",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "The `buildForBatch` method (and stream equivalent) are already released, so this generic `Write` implementation makes the new structure, `build` + `toBatch`, work for existing sources. It also allows sources to implement the version that they choose. So if none of the features that require the `Write` are used, I guess they could avoid a mostly-boilerplate class.",
        "createdAt" : "2020-10-02T00:43:51Z",
        "updatedAt" : "2020-12-07T14:50:31Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "5b33ebce-fa1a-409d-89eb-7d450e7641b8",
        "parentId" : "09484aba-a41b-479e-8e30-bc93c6a5fafa",
        "authorId" : "4a94765a-5775-4d88-b283-6ee68d76ecc7",
        "body" : "Correct, this method was introduced to keep the compatibility.",
        "createdAt" : "2020-11-25T02:27:04Z",
        "updatedAt" : "2020-12-07T14:50:31Z",
        "lastEditedBy" : "4a94765a-5775-4d88-b283-6ee68d76ecc7",
        "tags" : [
        ]
      },
      {
        "id" : "3139b5ab-84ef-499d-a820-6b7c8919aeed",
        "parentId" : "09484aba-a41b-479e-8e30-bc93c6a5fafa",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "Have you considered to change the default impl for `buildForBatch` to:\r\n```scala\r\n  default BatchWrite buildForBatch() {\r\n    build().toBatch()\r\n  }\r\n```\r\n\r\nand also the `build()` to just return a simple anonymous `new Write() {}`? \r\n\r\nOtherwise, I can see that we'll have the `buildForBatch` (and similarly `buildForStreaming`) logic in two different places: `WriteBuilder` and `Write`. It is easy to miss one or another.",
        "createdAt" : "2020-12-02T20:02:33Z",
        "updatedAt" : "2020-12-07T14:50:31Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "ed13b17a-0f2d-43b9-9d29-66604c1e5a8c",
        "parentId" : "09484aba-a41b-479e-8e30-bc93c6a5fafa",
        "authorId" : "4a94765a-5775-4d88-b283-6ee68d76ecc7",
        "body" : "I am not sure I understood. Could you elaborate a bit more, @sunchao?\r\n\r\nSpark will now always call `build()` and work with the `Write` abstraction. I added the default implementation so that  existing data sources that already implement the current API will continue to work as before. Spark will is not supposed to call `buildForBatch` after this change.",
        "createdAt" : "2020-12-07T14:40:12Z",
        "updatedAt" : "2020-12-07T14:50:31Z",
        "lastEditedBy" : "4a94765a-5775-4d88-b283-6ee68d76ecc7",
        "tags" : [
        ]
      },
      {
        "id" : "2c7b75d2-ed7f-448f-98cf-2d2f0116c4d4",
        "parentId" : "09484aba-a41b-479e-8e30-bc93c6a5fafa",
        "authorId" : "4a94765a-5775-4d88-b283-6ee68d76ecc7",
        "body" : "New data sources should be encouraged to implement only `build`.",
        "createdAt" : "2020-12-07T14:53:28Z",
        "updatedAt" : "2020-12-07T14:53:28Z",
        "lastEditedBy" : "4a94765a-5775-4d88-b283-6ee68d76ecc7",
        "tags" : [
        ]
      },
      {
        "id" : "2a596b7f-286e-43b6-9927-596edcaea052",
        "parentId" : "09484aba-a41b-479e-8e30-bc93c6a5fafa",
        "authorId" : "4a94765a-5775-4d88-b283-6ee68d76ecc7",
        "body" : "We should probably deprecate the other ones.",
        "createdAt" : "2020-12-07T14:53:45Z",
        "updatedAt" : "2020-12-07T14:53:46Z",
        "lastEditedBy" : "4a94765a-5775-4d88-b283-6ee68d76ecc7",
        "tags" : [
        ]
      },
      {
        "id" : "a014a4d2-bfd5-405f-b71e-38f3534b5e38",
        "parentId" : "09484aba-a41b-479e-8e30-bc93c6a5fafa",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "What I mean is now we can potentially have two copies of the `toBatch` implementation: one in `WriteBuilder.buildForBatch` and one in `Write.toBatch`, when users start to override `build`, `buildForBatch` and `buildForStreaming`. If moving forward we want `build` to be the canonical impl, perhaps we can make `buildForBatch` and `buildForStreaming` to just call `build.toBatch()` internally so that users just need to override `build`. ",
        "createdAt" : "2020-12-07T18:07:47Z",
        "updatedAt" : "2020-12-07T18:07:47Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      }
    ],
    "commit" : "32f5687fd628a4ffca38fa0840fd52447db7d680",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +38,42 @@   * Returns a logical {@link Write} shared between batch and streaming.\n   */\n  default Write build() {\n    return new Write() {\n      @Override"
  }
]