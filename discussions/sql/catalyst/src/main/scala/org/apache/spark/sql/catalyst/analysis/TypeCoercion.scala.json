[
  {
    "id" : "e43824a5-57dc-4202-8a77-8beb62919121",
    "prId" : 33750,
    "prUrl" : "https://github.com/apache/spark/pull/33750#pullrequestreview-730660945",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8d729ce8-ed95-4645-b34a-b1dad2c040f8",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "is it possible to share this code between ansi and non-ansi?",
        "createdAt" : "2021-08-16T11:38:04Z",
        "updatedAt" : "2021-08-16T11:38:04Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "b0f0b997-a682-4667-bfd0-3753f4834c18",
        "parentId" : "8d729ce8-ed95-4645-b34a-b1dad2c040f8",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "Yes and no. Here is for binary comparison, while in ANSI mode it is for binary operators...It is hard to create a function name for this.",
        "createdAt" : "2021-08-16T12:36:04Z",
        "updatedAt" : "2021-08-16T12:36:04Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "9f01da13cd628426be63e2d610a20c0600cabbd4",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +864,868 @@\n  // Return whether a string literal can be promoted as the give data type in a binary comparison.\n  private def canPromoteAsInBinaryComparison(dt: DataType) = dt match {\n    // If a binary comparison contains interval type and string type, we can't decide which\n    // interval type the string should be promoted as. There are many possible interval"
  },
  {
    "id" : "f79e48b4-078c-4bfe-8904-c33c10d6ab8d",
    "prId" : 33344,
    "prUrl" : "https://github.com/apache/spark/pull/33344#pullrequestreview-706219094",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7554f017-089e-48fc-b390-cd5c13ab8b0f",
        "parentId" : null,
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "This is needed for a test case with mixed `Date` & `TimestampNTZ` partition columns",
        "createdAt" : "2021-07-14T12:35:34Z",
        "updatedAt" : "2021-07-14T12:35:35Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "aa853c5660d21f2e53439d076a851a9e67c037fc",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +868,872 @@        Some(TimestampType)\n\n      case (_: TimestampNTZType, _: DateType) | (_: DateType, _: TimestampNTZType) =>\n        Some(TimestampNTZType)\n"
  },
  {
    "id" : "2ff39d9c-690c-4e1e-b343-31006fc37319",
    "prId" : 33156,
    "prUrl" : "https://github.com/apache/spark/pull/33156#pullrequestreview-696227981",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "73593936-d4a9-480b-a319-7158992f0b07",
        "parentId" : null,
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "This addresses comment in https://github.com/apache/spark/pull/33136#discussion_r661468789",
        "createdAt" : "2021-06-30T14:20:37Z",
        "updatedAt" : "2021-06-30T14:20:37Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "afa6903e1d779f9b5de4104997df74d3cc21f2d0",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +962,966 @@      // Implicit cast between date time types\n      case (DateType, TimestampType) => TimestampType\n      case (DateType, AnyTimestampType) => AnyTimestampType.defaultConcreteType\n      case (TimestampType | TimestampWithoutTZType, DateType) => DateType\n"
  },
  {
    "id" : "850e2132-f9b4-4a9e-a0b5-b588eaa00517",
    "prId" : 33136,
    "prUrl" : "https://github.com/apache/spark/pull/33136#pullrequestreview-695908229",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "31d03340-c681-4eb8-ab2e-50d19717becb",
        "parentId" : null,
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "Here the result is the same if casting both to `TimestampWithoutTZType` or `TimestampType`.  Casting to TimestampWithoutTZType is more straightforward.",
        "createdAt" : "2021-06-30T09:35:37Z",
        "updatedAt" : "2021-06-30T09:35:38Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "c206f2a9d05a3413494e6634c48d84cfc396225c",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +640,644 @@      case s @ SubtractTimestamps(AnyTimestampType(), AnyTimestampType(), _, _)\n        if s.left.dataType != s.right.dataType =>\n        val newLeft = castIfNotSameType(s.left, TimestampWithoutTZType)\n        val newRight = castIfNotSameType(s.right, TimestampWithoutTZType)\n        s.copy(left = newLeft, right = newRight)"
  },
  {
    "id" : "24e52734-0029-4c7b-af5a-6a94e29dc967",
    "prId" : 33136,
    "prUrl" : "https://github.com/apache/spark/pull/33136#pullrequestreview-696163874",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "118303fc-c59d-43d6-bc8a-3120b541cc6d",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "here should be `AnyTimestampType.defaultConcreteType` as well",
        "createdAt" : "2021-06-30T13:23:10Z",
        "updatedAt" : "2021-06-30T13:23:11Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "65a91252-79ec-454d-b277-29e44c39a590",
        "parentId" : "118303fc-c59d-43d6-bc8a-3120b541cc6d",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "I will address this in the PR for extracting date fields.",
        "createdAt" : "2021-06-30T13:30:26Z",
        "updatedAt" : "2021-06-30T13:30:26Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "c206f2a9d05a3413494e6634c48d84cfc396225c",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +962,966 @@      // Implicit cast between date time types\n      case (DateType, TimestampType) => TimestampType\n      case (DateType, AnyTimestampType) => TimestampType\n      case (TimestampType, DateType) => DateType\n"
  },
  {
    "id" : "e33b7daa-ea9d-41f8-9e23-9c4cc90cf375",
    "prId" : 31349,
    "prUrl" : "https://github.com/apache/spark/pull/31349#pullrequestreview-582467158",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "342ca765-6023-4f7f-a038-ff85a462673a",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "we should document it",
        "createdAt" : "2021-01-27T15:16:28Z",
        "updatedAt" : "2021-02-24T04:07:09Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "29fa6b83-a250-4003-8d70-780eedcb8047",
        "parentId" : "342ca765-6023-4f7f-a038-ff85a462673a",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "Done",
        "createdAt" : "2021-02-03T15:09:04Z",
        "updatedAt" : "2021-02-24T04:07:09Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "1f5ecdc58e7ca1a87675880f722f74ae2777f753",
    "line" : 94,
    "diffHunk" : "@@ -1,1 +45,49 @@   * the operation. Those rules are implemented in [[DecimalPrecision]].\n   */\n  def findTightestCommonType(type1: DataType, type2: DataType): Option[DataType]\n\n  /**"
  },
  {
    "id" : "8ebec8d9-3c85-4310-a7f7-6a55c3af15ec",
    "prId" : 31349,
    "prUrl" : "https://github.com/apache/spark/pull/31349#pullrequestreview-596510718",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a1aba983-f1b9-498d-99b1-5c524b0e62f8",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "this can be final",
        "createdAt" : "2021-02-23T08:02:24Z",
        "updatedAt" : "2021-02-24T04:07:09Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "d9e347ad-0230-4874-b28e-ad11ed362dcc",
        "parentId" : "a1aba983-f1b9-498d-99b1-5c524b0e62f8",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "Let's skip `final` for now",
        "createdAt" : "2021-02-23T16:07:28Z",
        "updatedAt" : "2021-02-24T04:07:09Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "1f5ecdc58e7ca1a87675880f722f74ae2777f753",
    "line" : 155,
    "diffHunk" : "@@ -1,1 +77,81 @@  def canCast(from: DataType, to: DataType): Boolean\n\n  protected def findTypeForComplex(\n      t1: DataType,\n      t2: DataType,"
  },
  {
    "id" : "7ebcc3f5-f1db-4456-ab04-c7812d1594cf",
    "prId" : 29643,
    "prUrl" : "https://github.com/apache/spark/pull/29643#pullrequestreview-483598067",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "17055334-a168-4dc5-893c-d773d2deb323",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Out of curiosity; why we need to set timezone here?",
        "createdAt" : "2020-09-07T14:12:06Z",
        "updatedAt" : "2020-09-07T14:12:06Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "c544af8d-828a-4112-acad-2f994df4c962",
        "parentId" : "17055334-a168-4dc5-893c-d773d2deb323",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "otherwise `WidenSetOperationTypes` will return invalid attribute mapping (unresolved Alias with unresolved cast) when calling `resolveOperatorsUpWithNewOutput`",
        "createdAt" : "2020-09-07T14:30:20Z",
        "updatedAt" : "2020-09-07T14:30:20Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "0857791bc310f54dd8ed1f4bcf5a5b274ffa33c6",
    "line" : 85,
    "diffHunk" : "@@ -1,1 +405,409 @@      val casted = plan.output.zip(targetTypes).map {\n        case (e, dt) if e.dataType != dt =>\n          Alias(Cast(e, dt, Some(SQLConf.get.sessionLocalTimeZone)), e.name)()\n        case (e, _) => e\n      }"
  },
  {
    "id" : "fb2e0a9b-d183-479b-8409-06ebb79d0fc5",
    "prId" : 29485,
    "prUrl" : "https://github.com/apache/spark/pull/29485#pullrequestreview-481891667",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dda1783d-cfed-400c-bb6e-6edd292a5d7e",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "what are we doing here?",
        "createdAt" : "2020-09-03T12:46:03Z",
        "updatedAt" : "2020-09-03T12:46:04Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "2c0eb1f7-4414-4893-90b3-dc5059677603",
        "parentId" : "dda1783d-cfed-400c-bb6e-6edd292a5d7e",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "This generates a rewrite map used for `Analyzer.rewritePlan`. The `rewritePlan` assumes a plan structure is the same before/after plan rewriting, so this `WidenSetOperationTypes` rule does two-phase transformation now as follows;\r\n```\r\n### Input Plan (Query described in the PR description) ###\r\nProject [v#1]\r\n+- SubqueryAlias t\r\n   +- Union\r\n      :+- Project [v#1]\r\n      :   +- SubqueryAlias t3\r\n      :      ...\r\n      +- Project [v#2]\r\n         +- Project [CheckOverflow((promote_precision(cast(v#1 as decimal(11,0))) + promote_precision(cast(v#1 as decimal(11,0)))), DecimalType(11,0), true) AS v#2]\r\n            +- SubqueryAlias t3\r\n               ...\r\n\r\n### Phase-1 (Adds Project, but not update ExprId) ###\r\nProject [v#1]\r\n+- SubqueryAlias t\r\n   +- Union\r\n      :- Project [cast(v#1 as decimal(11,0)) AS v#1] <--- !!!Adds Project to widen a type!!!\r\n      :  +- Project [v#1]\r\n      :     +- SubqueryAlias t3\r\n      :        ...\r\n      +- Project [v#2]\r\n         +- Project [CheckOverflow((promote_precision(cast(v#1 as decimal(11,0))) + promote_precision(cast(v#1 as decimal(11,0)))), DecimalType(11,0), true) AS v#2]\r\n            ...\r\n\r\n### Phase-2 ###\r\n// Analyzer.rewritePlan updates ExprIds based on a rewrite map:\r\n// `Project [cast(v#1 as decimal(11,0)) AS v#1]` => Project [cast(v#1 as decimal(11,0)) AS v#3]\r\nProject [v#3] <--- !!!Updates ExprId!!!\r\n+- SubqueryAlias t\r\n   +- Union\r\n      :- Project [cast(v#1 as decimal(11,0)) AS v#3] <--- !!!Updates ExprId!!!\r\n      :  +- Project [v#1]\r\n      :     +- SubqueryAlias t3\r\n      :        ...\r\n      +- Project [v#2]\r\n         +- Project [CheckOverflow((promote_precision(cast(v#1 as decimal(11,0))) + promote_precision(cast(v#1 as decimal(11,0)))), DecimalType(11,0), true) AS v#2]\r\n            ...\r\n```",
        "createdAt" : "2020-09-03T14:23:20Z",
        "updatedAt" : "2020-09-03T14:23:21Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "6372515769c1d3c299b865d4ec4b8378bdc5e84c",
    "line" : 101,
    "diffHunk" : "@@ -1,1 +418,422 @@          e -> e\n      }.unzip\n      Project(casted._1, plan) -> Project(casted._2, plan)\n    }\n  }"
  }
]