[
  {
    "id" : "3618d4ec-4169-4c0a-915e-b9cc6a389d51",
    "prId" : 31318,
    "prUrl" : "https://github.com/apache/spark/pull/31318#pullrequestreview-594422796",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "685961d2-529f-4f1f-afba-a7e293049074",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Could you update the comment about how to handle this case?\r\n\r\nhttps://github.com/apache/spark/pull/31318/files#diff-d43484d56a4d9991066b5c00d12ec2465c75131e055fc02ee7fb6dfd45b5006fR347-R351",
        "createdAt" : "2021-02-18T00:41:01Z",
        "updatedAt" : "2021-03-02T17:16:19Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "0ae75ce4-2e4f-4568-889d-8c65c0d26cb1",
        "parentId" : "685961d2-529f-4f1f-afba-a7e293049074",
        "authorId" : "605e7a2d-bf9d-4823-9271-c5d6bf39e485",
        "body" : "updated the comment, thanks.",
        "createdAt" : "2021-02-19T17:49:12Z",
        "updatedAt" : "2021-03-02T17:16:19Z",
        "lastEditedBy" : "605e7a2d-bf9d-4823-9271-c5d6bf39e485",
        "tags" : [
        ]
      }
    ],
    "commit" : "699c1f4241354f623b996643b0b44c15e623dd7b",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +354,358 @@        //    for example lhs = (a && b), rhs = (a && c) => all = (a, b, a, c), distinct = (a, b, c)\n        //    optimized predicate: (a && b && c)\n        val lhs = splitDisjunctivePredicates(left)\n        val rhs = splitDisjunctivePredicates(right)\n        val common = lhs.filter(e => rhs.exists(e.semanticEquals))"
  },
  {
    "id" : "5ca82e50-c558-47ce-a4bc-7cc408ec637e",
    "prId" : 31318,
    "prUrl" : "https://github.com/apache/spark/pull/31318#pullrequestreview-594423197",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4644fbcb-c63d-40de-9ba1-3c2d23b3a59e",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "nit: could you add an example case here like the comment above (` // (a || b || c || ...) && (a || b) => (a || b)`)?",
        "createdAt" : "2021-02-18T00:42:19Z",
        "updatedAt" : "2021-03-02T17:16:19Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "da2a6ad5-579a-40b3-8070-f933e3205d63",
        "parentId" : "4644fbcb-c63d-40de-9ba1-3c2d23b3a59e",
        "authorId" : "605e7a2d-bf9d-4823-9271-c5d6bf39e485",
        "body" : "done, added comment `// (((a && b) && a && (a && c))) => a && b && c`",
        "createdAt" : "2021-02-19T17:49:44Z",
        "updatedAt" : "2021-03-02T17:16:19Z",
        "lastEditedBy" : "605e7a2d-bf9d-4823-9271-c5d6bf39e485",
        "tags" : [
        ]
      }
    ],
    "commit" : "699c1f4241354f623b996643b0b44c15e623dd7b",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +369,373 @@          }\n        } else {\n          // No common factors from disjunctive predicates, reduce common factor from conjunction\n          val all = splitConjunctivePredicates(left) ++ splitConjunctivePredicates(right)\n          val distinct = ExpressionSet(all)"
  },
  {
    "id" : "b781ab61-8f74-4fce-b3e0-4fae4fbeb4b1",
    "prId" : 31318,
    "prUrl" : "https://github.com/apache/spark/pull/31318#pullrequestreview-605682626",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bb7f56cb-48ba-4c4e-bbc6-b264bcedab28",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "so the improvement is to handle the mix of `&` and `|` ?",
        "createdAt" : "2021-02-18T09:01:08Z",
        "updatedAt" : "2021-03-02T17:16:19Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "497a1363-fe13-4256-be46-4ca6bea51cf2",
        "parentId" : "bb7f56cb-48ba-4c4e-bbc6-b264bcedab28",
        "authorId" : "605e7a2d-bf9d-4823-9271-c5d6bf39e485",
        "body" : "Currently, `and` of common disjunctive predicates is optimized  Example: `(a || b || c || ...) && (a || b) => (a || b)`\r\nbut `and` of common conjunctive predicates is not optimized. Example: `((a && b) && (a && c))) => a && b && c`\r\nThe improvement is to optimize for common conjunctive predicate which can have mix of `&` and `|`\r\n\r\nSimilarly for `Or`, case of common disjunctive predicate is added in this PR.\r\n",
        "createdAt" : "2021-02-19T18:01:56Z",
        "updatedAt" : "2021-03-02T17:16:19Z",
        "lastEditedBy" : "605e7a2d-bf9d-4823-9271-c5d6bf39e485",
        "tags" : [
        ]
      },
      {
        "id" : "d17a011d-c679-42d3-8185-2cb6fa30e91d",
        "parentId" : "bb7f56cb-48ba-4c4e-bbc6-b264bcedab28",
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "It seems that we are improving to handle conjunctive and disjunctive cases separately. I am wondering could we do a better job to handle the expression with mix of `&&` and `||`?\r\n\r\ne.g.\r\n\r\n```\r\n(a || b) && (a && b)\r\n```\r\n\r\nto\r\n\r\n```\r\na && b\r\n```",
        "createdAt" : "2021-02-22T09:36:41Z",
        "updatedAt" : "2021-03-02T17:16:19Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      },
      {
        "id" : "0cad9a90-ca4f-4fa1-b2d0-58f4fd6632aa",
        "parentId" : "bb7f56cb-48ba-4c4e-bbc6-b264bcedab28",
        "authorId" : "605e7a2d-bf9d-4823-9271-c5d6bf39e485",
        "body" : "Many thanks @c21 for suggestion and review.\r\nI was thinking about this. We can handle this as described in 3.\r\nFor `And(left, right)`\r\n1. CommonFactorsInDisjunctions\r\n2. else CommonFactorsInConjunctions.\r\n3. else Mix of && and ||'s.\r\n```\r\nsplit lhs on || to get leftOrs.\r\n\tif( leftOrs.size > 1)\r\n\t\tsplit rhs on && to get rightAnds.\r\n\t\tforeach p in leftOrs\r\n\t\t\tdistinct = Set(p, rightAnds)\r\n\t\t\tif (distinct < rightAnds.size + 1)\r\n\t\t\t\tOutputOrs +=  distinct.reduce(And)\r\n\t\tOutputOrs.reduce(||)\r\n\telse\r\n\t\tsplit rhs on || to gt rightOrs\r\n\t\tif( rightOrs.size > 1)\r\n\t\t\tsplit lhs on && to get leftAnds.\r\n\t\t\tforeach p in rightOrs\r\n\t\t\t\tdistinct = Set(p, leftAnds)\r\n\t\t\t\tif (distinct < rightAnds.size + 1)\r\n\t\t\t\t\tOutputOrs +=  distinct.reduce(And)\r\n\t\t\tOutputOrs.reduce(||)                                      //OutputOrs is a set.\r\n```\r\n\r\nGiven example would be optimized:\r\n```\r\n=> (a || b) && (a && b)\r\n=> (a && (a && b)) || (b && (a && b))\r\n=> a && b || a && b\r\n=> a && b\r\n```\r\nBut for examples like this: \r\n```\r\n=> (a || b) && (a && c)\r\n=> (a && (a && c)) || (b && (a && c))\r\n=> (a && c) || (a && b && c)\r\n```\r\n`(a && c) || (a && b && c)` will be reduced in next iteration of `BooleanSimplification` rule to `a && b && c`.\r\nHence handling mix of &&'s and ||'s in this way can be inefficient. Do you have any suggestions around how to optimize this in single iteration of `BooleanSimplification` rule.",
        "createdAt" : "2021-03-02T03:33:44Z",
        "updatedAt" : "2021-03-02T17:16:20Z",
        "lastEditedBy" : "605e7a2d-bf9d-4823-9271-c5d6bf39e485",
        "tags" : [
        ]
      },
      {
        "id" : "d0197395-f023-4941-b7d4-96c5bca8f128",
        "parentId" : "bb7f56cb-48ba-4c4e-bbc6-b264bcedab28",
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "Thank you @Swinky ! let me think more about this and get back to you later.",
        "createdAt" : "2021-03-05T23:27:22Z",
        "updatedAt" : "2021-03-05T23:27:22Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      }
    ],
    "commit" : "699c1f4241354f623b996643b0b44c15e623dd7b",
    "line" : 35,
    "diffHunk" : "@@ -1,1 +370,374 @@        } else {\n          // No common factors from disjunctive predicates, reduce common factor from conjunction\n          val all = splitConjunctivePredicates(left) ++ splitConjunctivePredicates(right)\n          val distinct = ExpressionSet(all)\n          if (all.size == distinct.size) {"
  },
  {
    "id" : "31971391-124b-4378-8ed7-1a386abc2f93",
    "prId" : 31318,
    "prUrl" : "https://github.com/apache/spark/pull/31318#pullrequestreview-605914589",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e1c8bfaa-5719-4ff3-99ee-79c11153324b",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Do we consider determinism here? \r\n\r\n```\r\n(a && b) && a && (a && c) => a && b && c\r\n```\r\n\r\ne.g.) if multiple calls of `a` changes its return value, the result would be incorrect here.",
        "createdAt" : "2021-03-07T23:55:05Z",
        "updatedAt" : "2021-03-07T23:55:05Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "4788f8ad-8c85-46e7-99ac-19b964b9160d",
        "parentId" : "e1c8bfaa-5719-4ff3-99ee-79c11153324b",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "In the case above, `ExpressionSet` regards `a` elements as different ones and it seems no optimisation happens? Anyway, we forgot to add tests for the case, so I think we need to add them. cc: @Swinky ",
        "createdAt" : "2021-03-08T01:05:35Z",
        "updatedAt" : "2021-03-08T01:05:35Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "b4b53554-3031-4dd1-bc50-db75b44598e4",
        "parentId" : "e1c8bfaa-5719-4ff3-99ee-79c11153324b",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Oh I see. Thanks @maropu.",
        "createdAt" : "2021-03-08T01:32:54Z",
        "updatedAt" : "2021-03-08T01:32:54Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "699c1f4241354f623b996643b0b44c15e623dd7b",
    "line" : 41,
    "diffHunk" : "@@ -1,1 +376,380 @@            and\n          } else {\n            // (a && b) && a && (a && c) => a && b && c\n            buildBalancedPredicate(distinct.toSeq, And)\n          }"
  },
  {
    "id" : "77359e39-8d67-458f-a18b-ee69c4fd2509",
    "prId" : 31318,
    "prUrl" : "https://github.com/apache/spark/pull/31318#pullrequestreview-610353664",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4db53ca9-156e-4e14-b931-94319d7a8080",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Is it okay to call `distinct.toSeq` here? The current implementation of `ExpressionSet` keeps the original order of expressions, but I'm not sure that its design guarantees the order.",
        "createdAt" : "2021-03-08T01:09:43Z",
        "updatedAt" : "2021-03-08T01:09:43Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "913720d1-3db1-4759-af9d-03b46a52e0a5",
        "parentId" : "4db53ca9-156e-4e14-b931-94319d7a8080",
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "@maropu - `ExpressionSet` implements [`Iterable.iterator()` method](https://github.com/apache/spark/blob/master/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/ExpressionSet.scala#L132), so `.toSeq` will return the expressions in original order, right? Do you think we need to add more documentation on `ExpressionSet` to harden this assumption? ",
        "createdAt" : "2021-03-11T21:25:59Z",
        "updatedAt" : "2021-03-11T21:25:59Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      },
      {
        "id" : "0094705a-aaa3-4db5-a36a-cc61c35ad1e9",
        "parentId" : "4db53ca9-156e-4e14-b931-94319d7a8080",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "> Do you think we need to add more documentation on ExpressionSet to harden this assumption?\r\n\r\nYea, documenting it explicitly looks better to me.",
        "createdAt" : "2021-03-12T00:25:22Z",
        "updatedAt" : "2021-03-12T00:25:22Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "699c1f4241354f623b996643b0b44c15e623dd7b",
    "line" : 87,
    "diffHunk" : "@@ -1,1 +415,419 @@          } else {\n            // (a || b) || a || (a || c) => a || b || c\n            buildBalancedPredicate(distinct.toSeq, Or)\n          }\n        }"
  },
  {
    "id" : "9653f33c-1e3e-4e8e-bb16-2f1483a5e35e",
    "prId" : 30975,
    "prUrl" : "https://github.com/apache/spark/pull/30975#pullrequestreview-563260214",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "32d33969-5952-422b-9579-f9f184bf713f",
        "parentId" : null,
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "It may cause `StackOverflowError`.\r\n```\r\nscala> spark.sql(\"drop table SPARK_33938\")\r\nres6: org.apache.spark.sql.DataFrame = []\r\n\r\nscala> spark.sql(\"create table SPARK_33938(id string) using parquet\")\r\nres7: org.apache.spark.sql.DataFrame = []\r\n\r\nscala> val values = Range(1, 10000)\r\nvalues: scala.collection.immutable.Range = Range 1 until 10000\r\n\r\nscala> spark.sql(s\"select * from SPARK_33938 where id like all (${values.map(s => s\"'$s'\").mkString(\", \")})\").show\r\njava.lang.StackOverflowError\r\n  at java.lang.ThreadLocal.set(ThreadLocal.java:201)\r\n  at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.set(TreeNode.scala:62)\r\n  at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:72)\r\n  at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:317)\r\n  at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDown$3(TreeNode.scala:322)\r\n  at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$mapChildren$1(TreeNode.scala:407)\r\n  at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:243)\r\n  at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:405)\r\n  at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:358)\r\n  at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:322)\r\n  at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDown$3(TreeNode.scala:322)\r\n  at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$mapChildren$1(TreeNode.scala:407)\r\n  at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:243)\r\n  at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:405)\r\n  at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:358)\r\n```",
        "createdAt" : "2021-01-07T04:52:31Z",
        "updatedAt" : "2021-01-07T04:52:32Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      },
      {
        "id" : "322a9f78-6e10-4970-ae4b-5d8c56593716",
        "parentId" : "32d33969-5952-422b-9579-f9f184bf713f",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "@wangyum I will fix this issue.",
        "createdAt" : "2021-01-07T05:29:20Z",
        "updatedAt" : "2021-01-07T05:29:21Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      },
      {
        "id" : "db6c9581-e92c-45e4-aec3-77c891b037e3",
        "parentId" : "32d33969-5952-422b-9579-f9f184bf713f",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "For example, patterns a, b, c, d, e, and f. Suppose a, b, c, and d are patterns that can be optimized with `startsWith`. According to the current logic, it is `startsWith(a)&startsWith(b)&startsWith(c)&startsWith(d)&LikeAll(e,f).` Their hierarchy is not shown here.\r\nWe can use the threshold to determine the number of patterns that can be optimized, for example, only two patterns can be optimized. Then it is `startsWith(a)&startsWith(b)&LikeAll(c,d,e,f)`",
        "createdAt" : "2021-01-07T07:26:01Z",
        "updatedAt" : "2021-01-07T07:27:06Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "6acf1c1b200f78f2c509e3a9cde312556f7b4ab9",
    "line" : 61,
    "diffHunk" : "@@ -1,1 +676,680 @@    } else {\n      multi match {\n        case l: LikeAll => And(replacements.reduceLeft(And), l.copy(patterns = remainPatterns))\n        case l: NotLikeAll =>\n          And(replacements.map(Not(_)).reduceLeft(And), l.copy(patterns = remainPatterns))"
  },
  {
    "id" : "d59d5dc7-9305-460d-b99a-1402ae6e75e7",
    "prId" : 30955,
    "prUrl" : "https://github.com/apache/spark/pull/30955#pullrequestreview-559399262",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "11bae76c-4fdb-43fc-9389-fcd12135a9c3",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "let's include `ExtractValue` as well, which is common with nested fields.",
        "createdAt" : "2020-12-29T06:51:38Z",
        "updatedAt" : "2020-12-29T09:00:40Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "029fb53bc4484432973bf8f5eda9204dbd01ae89",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +560,564 @@    case _: ArraySetLike => true\n    case _: ExtractValue => true\n    case _ => false\n  }\n"
  },
  {
    "id" : "05d77a82-e4f4-40d1-a1ef-bd79554e2975",
    "prId" : 30955,
    "prUrl" : "https://github.com/apache/spark/pull/30955#pullrequestreview-559399695",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f295dfea-4ba9-49e9-8168-9b695fc28c71",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "let's add comments as well.",
        "createdAt" : "2020-12-29T06:53:17Z",
        "updatedAt" : "2020-12-29T09:00:40Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "029fb53bc4484432973bf8f5eda9204dbd01ae89",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +564,568 @@\n  // Not all BinaryExpression can be pushed into (if / case) branches.\n  private def supportedBinaryExpression(e: BinaryExpression): Boolean = e match {\n    case _: BinaryComparison | _: StringPredicate | _: StringRegexExpression => true\n    case _: BinaryArithmetic => true"
  },
  {
    "id" : "ea6b9c45-fbec-4f3b-8b87-07eee211f4b4",
    "prId" : 30955,
    "prUrl" : "https://github.com/apache/spark/pull/30955#pullrequestreview-618856255",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fe7ab9a3-420d-4c3e-9a00-87e6fba1a1dc",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "What the property should the expression have to be here? For example, can I add `DateAddYMInterval`, `TimestampAddYMInterval` and `TimeAdd`?",
        "createdAt" : "2021-03-23T15:28:43Z",
        "updatedAt" : "2021-03-23T15:28:50Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "4e539b28-4653-44f8-9340-30bc2ec5e970",
        "parentId" : "fe7ab9a3-420d-4c3e-9a00-87e6fba1a1dc",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I think so",
        "createdAt" : "2021-03-23T16:25:12Z",
        "updatedAt" : "2021-03-23T16:25:12Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "26dfdd06-c74e-4188-a496-2aa5273d4021",
        "parentId" : "fe7ab9a3-420d-4c3e-9a00-87e6fba1a1dc",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "ok. I opened the JIRA for that: SPARK-34841",
        "createdAt" : "2021-03-23T17:08:19Z",
        "updatedAt" : "2021-03-23T17:08:19Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "029fb53bc4484432973bf8f5eda9204dbd01ae89",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +568,572 @@    case _: BinaryArithmetic => true\n    case _: BinaryMathExpression => true\n    case _: AddMonths | _: DateAdd | _: DateAddInterval | _: DateDiff | _: DateSub => true\n    case _: FindInSet | _: RoundBase => true\n    case _ => false"
  },
  {
    "id" : "760183eb-2b38-4cb7-a965-bf0634426e93",
    "prId" : 30853,
    "prUrl" : "https://github.com/apache/spark/pull/30853#pullrequestreview-559392661",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "af6a9ce0-6227-47bd-aa0b-d51da745021f",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "`Alias` is not the only exception, we can't apply this optimization for `Generator` as well, as the logical plan `Generate` requires explicit type `Generator`.\r\n\r\nIt happened many times that an optimization rule introduces bugs because it uses denylist instead of allowlist. Let's avoid similar mistakes here, and explicitly list what expressions we should support.\r\n\r\nAn initial list from my mind:\r\n1. IsNull, IsNotNull\r\n2. UnaryMathExpression\r\n3. String2StringExpression\r\n4. Cast\r\n5. BinaryComparison\r\n6. BinaryArithmetic",
        "createdAt" : "2020-12-28T19:16:05Z",
        "updatedAt" : "2020-12-28T19:16:05Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "c4b2291a-1a32-44ef-87da-181427243a80",
        "parentId" : "af6a9ce0-6227-47bd-aa0b-d51da745021f",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "Do you think `BinaryExpression` also has this issue?",
        "createdAt" : "2020-12-29T02:42:27Z",
        "updatedAt" : "2020-12-29T02:42:28Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      },
      {
        "id" : "80b39e65-2867-4085-ae21-a3656cbbbcb3",
        "parentId" : "af6a9ce0-6227-47bd-aa0b-d51da745021f",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I'm not sure, but it's safer to start with an allowlist.  We can extend it later.",
        "createdAt" : "2020-12-29T04:53:00Z",
        "updatedAt" : "2020-12-29T04:53:01Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "121c9f2e-4247-4665-bd08-51b4f459f005",
        "parentId" : "af6a9ce0-6227-47bd-aa0b-d51da745021f",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "https://github.com/apache/spark/pull/30955",
        "createdAt" : "2020-12-29T06:24:54Z",
        "updatedAt" : "2020-12-29T06:24:55Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      }
    ],
    "commit" : "a0995d6404208cc05995ffbb3fd84ac3caf4156f",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +543,547 @@  def apply(plan: LogicalPlan): LogicalPlan = plan transform {\n    case q: LogicalPlan => q transformExpressionsUp {\n      case a: Alias => a // Skip an alias.\n      case u @ UnaryExpression(i @ If(_, trueValue, falseValue))\n          if atMostOneUnfoldable(Seq(trueValue, falseValue)) =>"
  },
  {
    "id" : "cf8b5eea-b99a-4255-8226-03b9233e28eb",
    "prId" : 30852,
    "prUrl" : "https://github.com/apache/spark/pull/30852#pullrequestreview-557446698",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4993ad86-6805-428b-a851-8fab9c540a9e",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Since this is `all branches are null literal`, could you revise the PR title from `Replace None of elseValue inside CaseWhen if all branches are FalseLiteral` to mention that together?",
        "createdAt" : "2020-12-23T00:51:34Z",
        "updatedAt" : "2020-12-23T09:56:43Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "d20fedeac9fcca59faea28da418f546d4fd07e20",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +528,532 @@\n      case e @ CaseWhen(branches, None)\n          if branches.forall(_._2.semanticEquals(Literal(null, e.dataType))) =>\n        Literal(null, e.dataType)\n    }"
  },
  {
    "id" : "db5fceb4-d482-4f26-a3a1-124cada5bddc",
    "prId" : 30790,
    "prUrl" : "https://github.com/apache/spark/pull/30790#pullrequestreview-555097367",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dbf7708d-cdbb-4a97-a990-fa9ad3d6f26a",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "nit: we cannot use `transformAllExpressions` here?",
        "createdAt" : "2020-12-17T07:47:20Z",
        "updatedAt" : "2020-12-18T08:14:14Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "f9a50535-7eda-4f20-bfbe-87c9edac51c4",
        "parentId" : "dbf7708d-cdbb-4a97-a990-fa9ad3d6f26a",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "This copied from https://github.com/apache/spark/blob/8ccc3c1f8804e34b46fd9bec19a017db61b37f54/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/expressions.scala#L474",
        "createdAt" : "2020-12-17T08:19:42Z",
        "updatedAt" : "2020-12-18T08:14:14Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      },
      {
        "id" : "a22deb82-7a47-4662-9658-2faea7d56cfb",
        "parentId" : "dbf7708d-cdbb-4a97-a990-fa9ad3d6f26a",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ah, I see. I think its okay to simply use `transformAllExpressions` here.",
        "createdAt" : "2020-12-18T00:43:58Z",
        "updatedAt" : "2020-12-18T08:14:14Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "cfac0e8655755f770f725f7ec5cd2dc2db950ff6",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +541,545 @@  }\n\n  def apply(plan: LogicalPlan): LogicalPlan = plan transform {\n    case q: LogicalPlan => q transformExpressionsUp {\n      case b @ BinaryExpression(i @ If(_, trueValue, falseValue), right)"
  },
  {
    "id" : "32522095-d558-4598-909b-c2598c821920",
    "prId" : 30790,
    "prUrl" : "https://github.com/apache/spark/pull/30790#pullrequestreview-555092968",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bbbe4af1-7f89-492d-a001-083a7c0027b0",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Nice idea.",
        "createdAt" : "2020-12-18T00:30:53Z",
        "updatedAt" : "2020-12-18T08:14:14Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "cfac0e8655755f770f725f7ec5cd2dc2db950ff6",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +532,536 @@ * Push the foldable expression into (if / case) branches.\n */\nobject PushFoldableIntoBranches extends Rule[LogicalPlan] with PredicateHelper {\n\n  // To be conservative here: it's only a guaranteed win if all but at most only one branch"
  },
  {
    "id" : "8bf21bef-e1d3-4dce-9343-9b735ffa55c1",
    "prId" : 30625,
    "prUrl" : "https://github.com/apache/spark/pull/30625#pullrequestreview-546134957",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "35206e27-edd4-4361-b1b3-10ea4e819163",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "correct me if I was wrong: we need to make sure this rule doesn't change result. If the pattern is invalid, `Like` should fail. However, it's expensive to validate the pattern (need to compile it). Here we use `p.contains(escapeChar)` as a shortcut to know if the pattern might be invalid.\r\n\r\nCan we add some comments to explain it?",
        "createdAt" : "2020-12-07T08:04:42Z",
        "updatedAt" : "2020-12-08T02:44:47Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "c095de84-45c0-4cf9-961f-80871af58b88",
        "parentId" : "35206e27-edd4-4361-b1b3-10ea4e819163",
        "authorId" : "93b5fa84-bae4-4106-88af-f5f0f56a8164",
        "body" : "done",
        "createdAt" : "2020-12-07T13:13:52Z",
        "updatedAt" : "2020-12-08T02:44:47Z",
        "lastEditedBy" : "93b5fa84-bae4-4106-88af-f5f0f56a8164",
        "tags" : [
        ]
      }
    ],
    "commit" : "58b8bd28945a4f9e95a2da2707d62d6eb5f33fa9",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +556,560 @@          // Although there are patterns can be optimized if we handle the escape first, we just\n          // skip this rule if pattern contains any escapeChar for simplicity.\n          case p if p.contains(escapeChar) => l\n          case startsWith(prefix) =>\n            StartsWith(input, Literal(prefix))"
  },
  {
    "id" : "445dc902-4c58-4b24-abc1-ca79e41e12fc",
    "prId" : 30504,
    "prUrl" : "https://github.com/apache/spark/pull/30504#pullrequestreview-542217231",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fbacccd5-7f34-426c-819e-1f462c5076bf",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Since the PR content seems to be finalized, could you revise the PR title to focus on this a little more? Of course, this PR is originated to fix the described problem.",
        "createdAt" : "2020-12-01T19:15:56Z",
        "updatedAt" : "2020-12-02T00:41:11Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "f72bf818bfc54a8e58d6ac5b57116338f4d6d941",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +60,64 @@        Literal(c.children.length)\n      case Size(c: CreateMap, _) if c.children.forall(hasNoSideEffect) =>\n        Literal(c.children.length / 2)\n\n      // Fold expressions that are foldable."
  },
  {
    "id" : "815c25e4-77e2-4a0b-a6f5-7542e575f63f",
    "prId" : 30222,
    "prUrl" : "https://github.com/apache/spark/pull/30222#pullrequestreview-524874971",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "60c0fd2f-880c-4ac0-a172-3c7f8fd80fa4",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "More precisely, I think we only need to make sure the skipped branches are all deterministic.\r\n```\r\nval (picked, skipped) = branches.partition(_._2.equals(right))\r\nif (skipped.forall(_._1.determinisitc)) {\r\n  ...\r\n} else {\r\n  original\r\n}\r\n```",
        "createdAt" : "2020-11-06T05:59:04Z",
        "updatedAt" : "2020-12-11T14:56:43Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "312c6139ff209472a5cea6f4fe5bd1fdc2040a08",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +526,530 @@\n      case e @ EqualTo(c @ CaseWhen(branches, elseValue), right)\n          if c.deterministic &&\n            right.isInstanceOf[Literal] && branches.forall(_._2.isInstanceOf[Literal]) &&\n            elseValue.forall(_.isInstanceOf[Literal]) =>"
  },
  {
    "id" : "27f300c7-f79d-4096-919e-b87cd4680f4a",
    "prId" : 30222,
    "prUrl" : "https://github.com/apache/spark/pull/30222#pullrequestreview-551142230",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "63c8a28b-2108-467f-b2ce-35c372e38e88",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can we use an `EqualTo` expression to compare literals? and how about the null semantic?",
        "createdAt" : "2020-12-14T08:36:37Z",
        "updatedAt" : "2020-12-14T08:36:37Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "312c6139ff209472a5cea6f4fe5bd1fdc2040a08",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +529,533 @@            right.isInstanceOf[Literal] && branches.forall(_._2.isInstanceOf[Literal]) &&\n            elseValue.forall(_.isInstanceOf[Literal]) =>\n        if ((branches.map(_._2) ++ elseValue).forall(!_.equals(right))) {\n          FalseLiteral\n        } else {"
  },
  {
    "id" : "bcb0f214-c9ca-497a-a7a6-22d93e7ea9d5",
    "prId" : 30222,
    "prUrl" : "https://github.com/apache/spark/pull/30222#pullrequestreview-553265621",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a29154b1-e85d-4cb2-965f-c387fdde0ebc",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Let's update the JIRA/PR title, as it's a different optimization now.",
        "createdAt" : "2020-12-14T08:37:09Z",
        "updatedAt" : "2020-12-14T08:37:09Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "0afccc02-c81b-4511-b202-5468ebc50fd9",
        "parentId" : "a29154b1-e85d-4cb2-965f-c387fdde0ebc",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "https://github.com/apache/spark/pull/30790/files",
        "createdAt" : "2020-12-16T01:37:02Z",
        "updatedAt" : "2020-12-16T01:37:02Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      }
    ],
    "commit" : "312c6139ff209472a5cea6f4fe5bd1fdc2040a08",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +530,534 @@            elseValue.forall(_.isInstanceOf[Literal]) =>\n        if ((branches.map(_._2) ++ elseValue).forall(!_.equals(right))) {\n          FalseLiteral\n        } else {\n          e"
  },
  {
    "id" : "5d70cc66-9f03-4f04-9929-d0c9af1cd116",
    "prId" : 29816,
    "prUrl" : "https://github.com/apache/spark/pull/29816#pullrequestreview-492754243",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ca4622d3-a8fc-4621-b52e-00fd4ddca8a0",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can we merge this comment with ```// Handling `Project` is moved to `propagateFoldables`.```?",
        "createdAt" : "2020-09-21T15:45:20Z",
        "updatedAt" : "2020-09-21T15:57:15Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "12f75eaa-4cae-4ae0-9776-8c963667f8b7",
        "parentId" : "ca4622d3-a8fc-4621-b52e-00fd4ddca8a0",
        "authorId" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "body" : "Ok, will change it.",
        "createdAt" : "2020-09-21T15:50:02Z",
        "updatedAt" : "2020-09-21T15:57:15Z",
        "lastEditedBy" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "tags" : [
        ]
      }
    ],
    "commit" : "474c7c03e4409f41e6792f7f5d13fd61775689c5",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +722,726 @@    case _: Filter => true\n    case _: SubqueryAlias => true\n    // Handling `Aggregate` is moved to `propagateFoldables`.\n    case _: Window => true\n    case _: Sample => true"
  },
  {
    "id" : "c664f10d-baf8-4376-bf90-be177812c4fb",
    "prId" : 29661,
    "prUrl" : "https://github.com/apache/spark/pull/29661#pullrequestreview-487198329",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "869b62d4-0e59-46ad-a246-4389eee01f60",
        "parentId" : null,
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "perhaps we should add a default case to handle other types which are not short, int or long.",
        "createdAt" : "2020-09-10T22:37:35Z",
        "updatedAt" : "2020-09-12T09:39:11Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "c4949db0-7725-4ccf-827d-5ab1dec4d033",
        "parentId" : "869b62d4-0e59-46ad-a246-4389eee01f60",
        "authorId" : "74aa957d-5b4e-4cef-9ecb-8c90d712facb",
        "body" : "I have fixed this to use ordering as suggested ",
        "createdAt" : "2020-09-12T03:12:18Z",
        "updatedAt" : "2020-09-12T09:39:11Z",
        "lastEditedBy" : "74aa957d-5b4e-4cef-9ecb-8c90d712facb",
        "tags" : [
        ]
      }
    ],
    "commit" : "36024757c4e81ebfc71d4d3b142c16b6a6f7413e",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +260,264 @@    } else {\n      None\n    }\n  }\n"
  },
  {
    "id" : "87a14783-dc7f-414a-ab95-0e9b57c68851",
    "prId" : 29603,
    "prUrl" : "https://github.com/apache/spark/pull/29603#pullrequestreview-479418329",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dfa3c9aa-21ec-4fb0-bfba-95befbcdc3a2",
        "parentId" : null,
        "authorId" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "body" : "minor, can we call `l` as `nullLiteral`?\r\n\r\n```\r\n      case If(cond, nullLiteral @ Literal(null, _), FalseLiteral) if !cond.nullable => And(cond, nullLiteral)\r\n      case If(cond, nullLiteral @ Literal(null, _), TrueLiteral) if !cond.nullable => Or(Not(cond), nullLiteral)\r\n      case If(cond, FalseLiteral, nullLiteral @ Literal(null, _)) if !cond.nullable => And(Not(cond), nullLiteral)\r\n      case If(cond, TrueLiteral, nullLiteral @ Literal(null, _)) if !cond.nullable => Or(cond, nullLiteral)\r\n```",
        "createdAt" : "2020-09-01T04:26:03Z",
        "updatedAt" : "2020-09-01T05:53:17Z",
        "lastEditedBy" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "tags" : [
        ]
      },
      {
        "id" : "04b0c573-8ea7-452a-b6fe-4596c5894c70",
        "parentId" : "dfa3c9aa-21ec-4fb0-bfba-95befbcdc3a2",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "Hmm that will break each of these into two lines which may affect readability, also I think given these are already `Literal(null, _)`, naming the variable to `nullLiteral` doesn't add much value maybe? ",
        "createdAt" : "2020-09-01T05:51:47Z",
        "updatedAt" : "2020-09-01T05:53:17Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      }
    ],
    "commit" : "34e3d38fd0fb9158acdfae119ad796e33aa928ec",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +467,471 @@      case If(cond, l @ Literal(null, _), TrueLiteral) if !cond.nullable => Or(Not(cond), l)\n      case If(cond, FalseLiteral, l @ Literal(null, _)) if !cond.nullable => And(Not(cond), l)\n      case If(cond, TrueLiteral, l @ Literal(null, _)) if !cond.nullable => Or(cond, l)\n\n      case e @ CaseWhen(branches, elseValue) if branches.exists(x => falseOrNullLiteral(x._1)) =>"
  },
  {
    "id" : "6a66f2ba-b626-4850-b497-fe7aa17e6ed5",
    "prId" : 29567,
    "prUrl" : "https://github.com/apache/spark/pull/29567#pullrequestreview-478366447",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "871bafe3-1da0-486f-bac8-02da64f1fb9f",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "`cond.deterministic` seems to be required, doesn't it?",
        "createdAt" : "2020-08-30T22:06:09Z",
        "updatedAt" : "2020-08-31T20:45:46Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "f2e10653-071c-4d1c-9251-20c16c10cdcb",
        "parentId" : "871bafe3-1da0-486f-bac8-02da64f1fb9f",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "For a Spark `Expression`, deterministic means that for fixed input it should always return the same result (e.g., a deterministic function), while `nullable` means whether it will be evaluated to null. In this case we need the latter.",
        "createdAt" : "2020-08-31T00:05:19Z",
        "updatedAt" : "2020-08-31T20:45:46Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "2aa359c6-8820-430a-82d0-355f7e400c6c",
        "parentId" : "871bafe3-1da0-486f-bac8-02da64f1fb9f",
        "authorId" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "body" : "@sunchao I think the concern @dongjoon-hyun has is it's possible that `cond` is non-deterministic or has side-effect (all the expressions that have side effects in Spark, we consider them as non-deterministic). If we naively simplify them, we might change the final result. \r\n\r\nFor example, `If(cond, TrueLiteral, TrueLiteral)` can be always simplified to `TrueLiteral`; however, this will skip evaluating `cond` which might have side-effect such as counting the number of times we call `cond`. \r\n\r\nIn the first case, the `cond` in `And(cond, l)` will be alway evaluated, and in the second case, `Or(Not(cond), l)`, since `l` will never be `true`, `Not(cond)` will always be evaluated.\r\n\r\nAs a result, maybe we don't need such strong requirement that `cond` has to be deterministic. ",
        "createdAt" : "2020-08-31T02:57:14Z",
        "updatedAt" : "2020-08-31T20:45:46Z",
        "lastEditedBy" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "tags" : [
        ]
      },
      {
        "id" : "08db12a8-675f-4ca3-9059-24a96cb0d974",
        "parentId" : "871bafe3-1da0-486f-bac8-02da64f1fb9f",
        "authorId" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "body" : "FYI,\r\n```\r\n      case If(cond, trueValue, falseValue)\r\n        if cond.deterministic && trueValue.semanticEquals(falseValue) => trueValue\r\n```\r\nThis rule is an example why `cond` has to be deterministic in other case that Dongjoon raised the concern. ",
        "createdAt" : "2020-08-31T03:18:23Z",
        "updatedAt" : "2020-08-31T20:45:46Z",
        "lastEditedBy" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "tags" : [
        ]
      },
      {
        "id" : "9ac02891-b208-40af-8a1a-4e41e7656e7c",
        "parentId" : "871bafe3-1da0-486f-bac8-02da64f1fb9f",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "In the added patterns, `cond` isn't skipped or changed with evaluation order, I think `cond.deterministic` shouldn't be required.",
        "createdAt" : "2020-08-31T03:26:31Z",
        "updatedAt" : "2020-08-31T20:45:46Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "92d4c86e-861b-4fcc-a60d-13d366f3ff0d",
        "parentId" : "871bafe3-1da0-486f-bac8-02da64f1fb9f",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "I see. Thanks @dbtsai @dongjoon-hyun and @viirya , yeah I think in this case we don't require `cond` to be deterministic. ",
        "createdAt" : "2020-08-31T07:03:22Z",
        "updatedAt" : "2020-08-31T20:45:46Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      }
    ],
    "commit" : "71bd033bfa58365ceabd108a791fd0748a27e1e0",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +465,469 @@        if cond.deterministic && trueValue.semanticEquals(falseValue) => trueValue\n      case If(cond, l @ Literal(null, _), FalseLiteral) if !cond.nullable => And(cond, l)\n      case If(cond, l @ Literal(null, _), TrueLiteral) if !cond.nullable => Or(Not(cond), l)\n\n      case e @ CaseWhen(branches, elseValue) if branches.exists(x => falseOrNullLiteral(x._1)) =>"
  },
  {
    "id" : "2cf9316d-76e3-49b9-99fd-ebc52870f13a",
    "prId" : 29567,
    "prUrl" : "https://github.com/apache/spark/pull/29567#pullrequestreview-479366139",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "89050138-6a03-4a07-936b-be9f1b90facf",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "what about the other way around? e.g. `case If(cond, FalseLiteral, l @ Literal(null, _))`",
        "createdAt" : "2020-09-01T02:53:47Z",
        "updatedAt" : "2020-09-01T02:53:47Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "5ebe5027-37dd-4253-974d-166a844b2d1e",
        "parentId" : "89050138-6a03-4a07-936b-be9f1b90facf",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ah it's covered in the followup https://github.com/apache/spark/pull/29603",
        "createdAt" : "2020-09-01T02:54:37Z",
        "updatedAt" : "2020-09-01T02:54:37Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "71bd033bfa58365ceabd108a791fd0748a27e1e0",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +464,468 @@      case If(cond, trueValue, falseValue)\n        if cond.deterministic && trueValue.semanticEquals(falseValue) => trueValue\n      case If(cond, l @ Literal(null, _), FalseLiteral) if !cond.nullable => And(cond, l)\n      case If(cond, l @ Literal(null, _), TrueLiteral) if !cond.nullable => Or(Not(cond), l)\n"
  },
  {
    "id" : "f59960c4-484e-43c8-a217-334d31daaa13",
    "prId" : 27231,
    "prUrl" : "https://github.com/apache/spark/pull/27231#pullrequestreview-346159487",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "18b0d932-83c7-4c17-92ad-d08c93f0b511",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "nit: How about this style?\r\n```\r\n  private def isRedundantNullCheck(\r\n      ifNullExpr: Expression,\r\n      ifNotNullExpr: Expression,\r\n      checkedExpr: Expression): Boolean = {\r\n    ifNotNullExpr.isInstanceOf[NullIntolerant] && {\r\n      (ifNullExpr == checkedExpr || ifNullExpr == Literal.create(null, checkedExpr.dataType)) &&\r\n        ifNotNullExpr.children.contains(checkedExpr)\r\n    }\r\n  }\r\n```",
        "createdAt" : "2020-01-20T04:53:37Z",
        "updatedAt" : "2020-01-21T20:33:39Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "0c0ea147-24ed-42dd-a5e0-eab6cf5db6a1",
        "parentId" : "18b0d932-83c7-4c17-92ad-d08c93f0b511",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "The first condition `ifNullExpr == checkedExpr` -> `ifNullExpr.semanticEquals(checkedExpr)`? e.g., `if isnull(a + b)  b + a else xxx`",
        "createdAt" : "2020-01-20T04:56:16Z",
        "updatedAt" : "2020-01-21T20:33:39Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "ace40ff6-db8d-499f-b584-222727647a57",
        "parentId" : "18b0d932-83c7-4c17-92ad-d08c93f0b511",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "The second condition `ifNullExpr == Literal.create(null, checkedExpr.dataType)` -> `ifNullExpr.foldable && ifNullExpr.eval() == null`?",
        "createdAt" : "2020-01-20T04:57:52Z",
        "updatedAt" : "2020-01-21T20:33:39Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "34e33674-973b-431f-b742-3ac424593838",
        "parentId" : "18b0d932-83c7-4c17-92ad-d08c93f0b511",
        "authorId" : "b9451478-f7c7-4435-bc9c-f33568f01263",
        "body" : "Makes sense.",
        "createdAt" : "2020-01-20T07:04:25Z",
        "updatedAt" : "2020-01-21T20:33:39Z",
        "lastEditedBy" : "b9451478-f7c7-4435-bc9c-f33568f01263",
        "tags" : [
        ]
      },
      {
        "id" : "b12b7f37-ef2d-497a-8a27-61dee66f49cc",
        "parentId" : "18b0d932-83c7-4c17-92ad-d08c93f0b511",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Can you generalize the last condition more? e.g., how about the case, `substring(other_func(title#5), 0, 3)` in the example you described?",
        "createdAt" : "2020-01-21T01:26:10Z",
        "updatedAt" : "2020-01-21T20:33:39Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "dcdbc3a5-111c-4588-bb25-a770cd5ea57b",
        "parentId" : "18b0d932-83c7-4c17-92ad-d08c93f0b511",
        "authorId" : "b9451478-f7c7-4435-bc9c-f33568f01263",
        "body" : "yes, that should be possible.",
        "createdAt" : "2020-01-21T20:11:03Z",
        "updatedAt" : "2020-01-21T20:33:39Z",
        "lastEditedBy" : "b9451478-f7c7-4435-bc9c-f33568f01263",
        "tags" : [
        ]
      }
    ],
    "commit" : "956413fca6ed683be56614756e79c30b56e70930",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +454,458 @@        ifNotNullExpr.find(x => x.semanticEquals(checkedExpr)).nonEmpty\n    }\n  }\n\n  def apply(plan: LogicalPlan): LogicalPlan = plan transform {"
  },
  {
    "id" : "50c1862c-99fd-4210-a9d5-f850eeba6fbe",
    "prId" : 27231,
    "prUrl" : "https://github.com/apache/spark/pull/27231#pullrequestreview-349143841",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c342d952-0a71-4973-8aa6-98f37541ba3d",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "How about this format?;\r\n```\r\n      // If the null-check is redundant, remove it\r\n      case If(IsNull(child), trueValue, falseValue)\r\n        if isRedundantNullCheck(trueValue, falseValue, child) => falseValue\r\n      case If(IsNotNull(child), trueValue, falseValue)\r\n        if isRedundantNullCheck(falseValue, trueValue, child) => trueValue\r\n```",
        "createdAt" : "2020-01-21T01:31:12Z",
        "updatedAt" : "2020-01-21T20:33:39Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "4c6c3965-d7be-4a7f-924b-6adb0cb14d97",
        "parentId" : "c342d952-0a71-4973-8aa6-98f37541ba3d",
        "authorId" : "b9451478-f7c7-4435-bc9c-f33568f01263",
        "body" : "Ok",
        "createdAt" : "2020-01-21T20:19:37Z",
        "updatedAt" : "2020-01-21T20:33:39Z",
        "lastEditedBy" : "b9451478-f7c7-4435-bc9c-f33568f01263",
        "tags" : [
        ]
      },
      {
        "id" : "0fbce74f-d6c1-4f67-8478-0a92d3b26109",
        "parentId" : "c342d952-0a71-4973-8aa6-98f37541ba3d",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Why did you add the inner pattern-matching (`cond match {` )? I think its better to avoid unnecessary pattern matching (In the current fix, all the cases for `If` exprs can be matched in the line 466).",
        "createdAt" : "2020-01-28T00:57:02Z",
        "updatedAt" : "2020-01-28T00:57:15Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "e5554562-a510-4b97-a28b-43c127f79276",
        "parentId" : "c342d952-0a71-4973-8aa6-98f37541ba3d",
        "authorId" : "b9451478-f7c7-4435-bc9c-f33568f01263",
        "body" : "I see. You are right, i do not need the inner pattern match, i will fix that.",
        "createdAt" : "2020-01-28T05:58:29Z",
        "updatedAt" : "2020-01-28T05:58:29Z",
        "lastEditedBy" : "b9451478-f7c7-4435-bc9c-f33568f01263",
        "tags" : [
        ]
      }
    ],
    "commit" : "956413fca6ed683be56614756e79c30b56e70930",
    "line" : 39,
    "diffHunk" : "@@ -1,1 +471,475 @@          if isRedundantNullCheck(falseValue, trueValue, child) => trueValue\n        case _ => i\n      }\n\n      case e @ CaseWhen(branches, elseValue) if branches.exists(x => falseOrNullLiteral(x._1)) =>"
  },
  {
    "id" : "017d8922-6737-4852-af0a-6676a32bb7ed",
    "prId" : 27231,
    "prUrl" : "https://github.com/apache/spark/pull/27231#pullrequestreview-346161970",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ccb6569c-505f-4bab-9f78-67f73da794ca",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "How about this?\r\n```\r\n      // remove redundant null checks for CaseWhen with one branch\r\n      case CaseWhen(Seq((IsNotNull(child), trueValue)), Some(falseValue))\r\n        if isRedundantNullCheck(falseValue, trueValue, child) => trueValue\r\n      case CaseWhen(Seq((IsNull(child), trueValue)), Some(falseValue))\r\n        if isRedundantNullCheck(trueValue, falseValue, child) => falseValue\r\n      case CaseWhen(Seq((IsNotNull(child), trueValue)), None)\r\n        if isRedundantNullCheck(Literal.create(null, child.dataType), trueValue, child) => trueValue\r\n      case e @ CaseWhen(Seq((IsNull(child), trueValue)), None) =>\r\n        val nullValue = Literal.create(null, child.dataType)\r\n        if (isRedundantNullCheck(trueValue, nullValue, child)) {\r\n          nullValue\r\n        } else {\r\n          e\r\n        }\r\n```",
        "createdAt" : "2020-01-21T02:06:33Z",
        "updatedAt" : "2020-01-21T20:33:39Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "3926702e-1499-49dd-829c-415d00c6180d",
        "parentId" : "ccb6569c-505f-4bab-9f78-67f73da794ca",
        "authorId" : "b9451478-f7c7-4435-bc9c-f33568f01263",
        "body" : "Alright",
        "createdAt" : "2020-01-21T20:15:27Z",
        "updatedAt" : "2020-01-21T20:33:39Z",
        "lastEditedBy" : "b9451478-f7c7-4435-bc9c-f33568f01263",
        "tags" : [
        ]
      }
    ],
    "commit" : "956413fca6ed683be56614756e79c30b56e70930",
    "line" : 62,
    "diffHunk" : "@@ -1,1 +528,532 @@        } else {\n          e\n        }\n    }\n  }"
  },
  {
    "id" : "b3bc7474-9321-4e4b-8dfb-c5b945a4c5fe",
    "prId" : 27231,
    "prUrl" : "https://github.com/apache/spark/pull/27231#pullrequestreview-355797317",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8ec6bead-bdb5-4d97-b004-a8b08b3a3c38",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "The same logic? https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/basicPhysicalOperators.scala#L105-L109",
        "createdAt" : "2020-01-28T00:52:21Z",
        "updatedAt" : "2020-01-28T00:57:15Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "6dbe37b9-b4f6-415d-81e9-73938bfd7f17",
        "parentId" : "8ec6bead-bdb5-4d97-b004-a8b08b3a3c38",
        "authorId" : "b9451478-f7c7-4435-bc9c-f33568f01263",
        "body" : "Actually i think we need slightly different logic. Consider these two examples where `x` will be the null-checked column: \r\n\r\n1. `substring(x, coalesce(a, b), c)`\r\n\r\n2. `substring(coalesce(x, d), a, c)`\r\n\r\nFor 1. we need to be null-intolerant (even though `coalesce` is null-tolerant), so if `x` is null, we replace the `substring` with null value no matter what are the other children. For 2. we need to be null-tolerant and we will not replace the `substring` by null value. So we need to check the expression with respect to the position of `x` (the column that is being null-checked). Does it make sense?",
        "createdAt" : "2020-01-28T06:38:08Z",
        "updatedAt" : "2020-01-28T06:38:08Z",
        "lastEditedBy" : "b9451478-f7c7-4435-bc9c-f33568f01263",
        "tags" : [
        ]
      },
      {
        "id" : "b5f04f95-277f-4cdc-8229-0a70054ad0dc",
        "parentId" : "8ec6bead-bdb5-4d97-b004-a8b08b3a3c38",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Probably, you meant `FiterExec.isNullIntolerant(ifNotNullExpr) || additional checks for the case having null-tolerant exprs inside ifNotNullExpr`? (`FiterExec.isNullIntolerant` is private though...)",
        "createdAt" : "2020-02-05T07:01:50Z",
        "updatedAt" : "2020-02-05T07:01:51Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "a878771f-d1e8-41be-917a-cbad0fda99b7",
        "parentId" : "8ec6bead-bdb5-4d97-b004-a8b08b3a3c38",
        "authorId" : "b9451478-f7c7-4435-bc9c-f33568f01263",
        "body" : "Yeah, `FilterExec.isNullIntolerant(ifNotNullExpr)` is a stronger condition than we need so in case there is null-tolerant expr inside we need to check if the null-checked column is in its subtree. Using the logic from `FilterExec.isNullIntolerant` the function could look like this:\r\n```\r\ndef isNullIntolerant(expr: Expression): Boolean = expr match {\r\n  case e: NullIntolerant => e.children.forall(isNullIntolerant)\r\n  case e if e.find(x => x.semanticEquals(checkedExpr)).isEmpty => true\r\n  case _ => false\r\n}\r\n```",
        "createdAt" : "2020-02-07T06:47:08Z",
        "updatedAt" : "2020-02-07T06:47:08Z",
        "lastEditedBy" : "b9451478-f7c7-4435-bc9c-f33568f01263",
        "tags" : [
        ]
      },
      {
        "id" : "5edd0d34-62d0-4da9-b0af-cd3009bf5220",
        "parentId" : "8ec6bead-bdb5-4d97-b004-a8b08b3a3c38",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ah, I see. For better code readability, could you split the condition into the two parts as I suggested above? Also, I think its better to leave some comments about why we need more checks there.",
        "createdAt" : "2020-02-07T06:51:04Z",
        "updatedAt" : "2020-02-07T06:51:04Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "7a2d8bb3-3bbf-4b7a-bdaa-19ff9944271e",
        "parentId" : "8ec6bead-bdb5-4d97-b004-a8b08b3a3c38",
        "authorId" : "b9451478-f7c7-4435-bc9c-f33568f01263",
        "body" : "I agree that the committed code is not very intuitive so i can think of this way which seems to be more readable (added also some comments):\r\n\r\n```\r\nprivate def isRedundantNullCheck(\r\n    ifNullExpr: Expression,\r\n    ifNotNullExpr: Expression,\r\n    checkedExpr: Expression): Boolean = {\r\n  \r\n  // checks if expr is null-intolerant with respect to checkedExpr\r\n  def isNullIntolerant(expr: Expression): Boolean = expr match {\r\n    case e: NullIntolerant => e.children.forall(isNullIntolerant)\r\n    // if some child is null-tolerant but the checkedEpxr is not in its subtree\r\n    // we can still consider the whole expr as null-intolerant \r\n    // with respect to checkedExpr\r\n    case e if e.find(x => x.semanticEquals(checkedExpr)).isEmpty => true\r\n    case _ => false\r\n  }\r\n  \r\n  isNullIntolerant(ifNotNullExpr) && {\r\n    (ifNullExpr.semanticEquals(checkedExpr) ||\r\n      (ifNullExpr.foldable && ifNullExpr.eval() == null)) &&\r\n      // we still need to make sure that checkedExpr is inside ifNotNullExpr\r\n      ifNotNullExpr.find(x => x.semanticEquals(checkedExpr)).nonEmpty\r\n  }\r\n}\r\n```\r\nBut not sure if this is what you had in mind when suggesting to split the condition. Can you think of a better way how to compose this?",
        "createdAt" : "2020-02-10T06:15:20Z",
        "updatedAt" : "2020-02-10T06:15:21Z",
        "lastEditedBy" : "b9451478-f7c7-4435-bc9c-f33568f01263",
        "tags" : [
        ]
      },
      {
        "id" : "54586ada-a914-433e-a822-a76004c11c3f",
        "parentId" : "8ec6bead-bdb5-4d97-b004-a8b08b3a3c38",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Hmmm, that still looks complicated.. If we cannot avoid the complexity for the stronger condition, as another option, I think we can cover the simple case (`FiterExec.isNullIntolerant(ifNotNullExpr)`) only in this pr. If necessary, we might be able to optimize the condition in future work. I think keeping the code simple is more important. WDYT?",
        "createdAt" : "2020-02-10T08:44:19Z",
        "updatedAt" : "2020-02-10T08:44:19Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "5b8a77bf-7022-429e-a819-e733fbabba20",
        "parentId" : "8ec6bead-bdb5-4d97-b004-a8b08b3a3c38",
        "authorId" : "b9451478-f7c7-4435-bc9c-f33568f01263",
        "body" : "Well, the think is that if we use the simple version with `FilterExec.isNullIntolerant(ifNutNullExpr)` we will loose (because of the recursive check) all expressions that contain literals (because literals are null-tolerant), so for example expressions like this `substring(title#5, 0, 3)` will not be included in the optimization (which the jira was targeted for in the first place). So I suggest one of these 2 options:\r\n\r\n1. Use the complex version of the code and thus include more expressions in the optimization\r\n2. Have the code more simple and use the original version before the generalization step, i.e. \r\n```\r\nprivate def isRedundantNullCheck(\r\n    ifNullExpr: Expression,\r\n    ifNotNullExpr: Expression,\r\n    checkedExpr: Expression): Boolean = {\r\n  ifNotNullExpr.isInstanceOf[NullIntolerant] && {\r\n    (ifNullExpr == checkedExpr || ifNullExpr == Literal.create(null, checkedExpr.dataType)) &&\r\n      ifNotNullExpr.children.contains(checkedExpr)\r\n  }\r\n}\r\n```\r\nwhere `checkedExpr` must be direct child and thus we don't have to check the whole subtree for null-intolerance (so expressions that have Literals in the subtree are still included).\r\nI am fine with either of these 2 options. What do you think?",
        "createdAt" : "2020-02-10T09:42:02Z",
        "updatedAt" : "2020-02-10T09:42:02Z",
        "lastEditedBy" : "b9451478-f7c7-4435-bc9c-f33568f01263",
        "tags" : [
        ]
      }
    ],
    "commit" : "956413fca6ed683be56614756e79c30b56e70930",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +446,450 @@      checkedExpr: Expression): Boolean = {\n    val isNullIntolerant = ifNotNullExpr.find { x =>\n      !x.isInstanceOf[NullIntolerant] && x.find(e => e.semanticEquals(checkedExpr)).nonEmpty\n    }.isEmpty\n"
  },
  {
    "id" : "fab5f2e4-b6a1-450a-bdbb-77aed9caf826",
    "prId" : 27119,
    "prUrl" : "https://github.com/apache/spark/pull/27119#pullrequestreview-340996290",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "30d7a2f2-ba97-43f6-9dee-d0af584c2696",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ah, I see. Good catch. Can you leave some comments (w/ an example query) here for easy-to-understand (about what this condition intend to avoid)?",
        "createdAt" : "2020-01-10T00:15:47Z",
        "updatedAt" : "2020-01-10T07:41:38Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "026a9ee4-804d-4376-bbdc-ce0eed811e8b",
        "parentId" : "30d7a2f2-ba97-43f6-9dee-d0af584c2696",
        "authorId" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "body" : "Ok, added. Let me know if it needs rewording.",
        "createdAt" : "2020-01-10T07:47:46Z",
        "updatedAt" : "2020-01-10T07:47:46Z",
        "lastEditedBy" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "tags" : [
        ]
      }
    ],
    "commit" : "c8a21cc29682800e79213ef371f51871e9c44551",
    "line" : 76,
    "diffHunk" : "@@ -1,1 +154,158 @@  // NOT prevents us to do the substitution as NOT flips the context (`nullIsFalse`) of what a\n  // null result of the enclosed expression means.\n  private def safeToReplace(ar: AttributeReference, nullIsFalse: Boolean) =\n    !ar.nullable || nullIsFalse\n"
  },
  {
    "id" : "4065afcd-18e9-41c2-87bb-f77ec8b9dd73",
    "prId" : 27008,
    "prUrl" : "https://github.com/apache/spark/pull/27008#pullrequestreview-336981704",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ee7c5bb7-0642-4532-9601-d7410d4ccee0",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "How about this?\r\n```\r\n  private def canSimplifyComparison(\r\n      plan: LogicalPlan, left: Expression, right: Expression): Boolean = {\r\n    if (!left.nullable && !right.nullable && left.semanticEquals(right)) {\r\n      true\r\n    } else {\r\n      // We do more checks for non-nullable cases\r\n      plan match {\r\n        case Filter(fc, _) =>\r\n          splitConjunctivePredicates(fc).exists { condition =>\r\n            condition.semanticEquals(IsNotNull(left)) && condition.semanticEquals(IsNotNull(right))\r\n          }\r\n        case _ =>\r\n          false\r\n      }\r\n    }\r\n  }\r\n```",
        "createdAt" : "2019-12-28T08:11:22Z",
        "updatedAt" : "2020-01-10T08:18:11Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "5fe8bdc5-4968-4551-8651-694e2dd1222f",
        "parentId" : "ee7c5bb7-0642-4532-9601-d7410d4ccee0",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "Looks fine.",
        "createdAt" : "2019-12-30T00:12:39Z",
        "updatedAt" : "2020-01-10T08:18:11Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "af0fbd60f6561d989160c1b9fbaedfa2996f00d0",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +408,412 @@    } else {\n      false\n    }\n  }\n"
  },
  {
    "id" : "0f097de5-1f5e-4514-ad29-a2587ec94a9d",
    "prId" : 24553,
    "prUrl" : "https://github.com/apache/spark/pull/24553#pullrequestreview-235054652",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8a84affd-10e0-48de-834c-3ae2670f50dd",
        "parentId" : null,
        "authorId" : "24e1dd39-ae3f-4bbb-a391-f60afb62d075",
        "body" : "shall we do this only if `equalityPredicatesLeft ` is not empty?",
        "createdAt" : "2019-05-08T12:51:16Z",
        "updatedAt" : "2020-02-13T10:48:57Z",
        "lastEditedBy" : "24e1dd39-ae3f-4bbb-a391-f60afb62d075",
        "tags" : [
        ]
      },
      {
        "id" : "4609f8e8-fdb1-4de4-9d21-a663bb364dbd",
        "parentId" : "8a84affd-10e0-48de-834c-3ae2670f50dd",
        "authorId" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "body" : "Thanks, fixed.",
        "createdAt" : "2019-05-08T13:26:47Z",
        "updatedAt" : "2020-02-13T10:48:57Z",
        "lastEditedBy" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "tags" : [
        ]
      }
    ],
    "commit" : "6d994abcf76b6ee48e8d6dd635a894b931bf8725",
    "line" : 139,
    "diffHunk" : "@@ -1,1 +122,126 @@      case a @ And(left, right) =>\n        val (newLeft, equalityPredicatesLeft) = traverse(left, nullValue)\n        val replacedRight = replaceConstants(right, equalityPredicatesLeft)\n        val (replacedNewRight, equalityPredicatesRight) = traverse(replacedRight, nullValue)\n        val replacedNewLeft = replaceConstants(newLeft, equalityPredicatesRight)"
  },
  {
    "id" : "b75215b4-576c-4b3d-82fc-42e6a911528a",
    "prId" : 24553,
    "prUrl" : "https://github.com/apache/spark/pull/24553#pullrequestreview-235069682",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9562dafc-d923-4a66-8437-2f68f5cb12bb",
        "parentId" : null,
        "authorId" : "24e1dd39-ae3f-4bbb-a391-f60afb62d075",
        "body" : "are we sure this is safe? Since it is a mutable map, can we ensure that it is not modified for places where it shouldn't be?",
        "createdAt" : "2019-05-08T12:53:47Z",
        "updatedAt" : "2020-02-13T10:48:57Z",
        "lastEditedBy" : "24e1dd39-ae3f-4bbb-a391-f60afb62d075",
        "tags" : [
        ]
      },
      {
        "id" : "88cfa0f7-3908-4ad9-aac0-b473689bec5f",
        "parentId" : "9562dafc-d923-4a66-8437-2f68f5cb12bb",
        "authorId" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "body" : "Could you please elaborate on this Marco?",
        "createdAt" : "2019-05-08T12:59:53Z",
        "updatedAt" : "2020-02-13T10:48:57Z",
        "lastEditedBy" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "tags" : [
        ]
      },
      {
        "id" : "40f6a3b7-7ccd-4677-af8b-1ee9fb2c7d8d",
        "parentId" : "9562dafc-d923-4a66-8437-2f68f5cb12bb",
        "authorId" : "24e1dd39-ae3f-4bbb-a391-f60afb62d075",
        "body" : "yes, this is a `mutable.Map`. What you'd like is that this map is populated bottom-up. But the map here is modified, so any other reference to it gets the modifications (additions) performed here and I am not sure this pattern is safe. Actually I have not been able to figure out an example which may cause issues, but I am not confident it is safe. Have you thought about this and can you ensure/explain whether this is safe? ",
        "createdAt" : "2019-05-08T13:11:38Z",
        "updatedAt" : "2020-02-13T10:48:57Z",
        "lastEditedBy" : "24e1dd39-ae3f-4bbb-a391-f60afb62d075",
        "tags" : [
        ]
      },
      {
        "id" : "45c71318-8f9a-42a9-8477-c666ac7d935e",
        "parentId" : "9562dafc-d923-4a66-8437-2f68f5cb12bb",
        "authorId" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "body" : "I see your point, but isn't the fact that I use `equalityPredicatesLeft` for replacing before I update its content with `equalityPredicatesRight` and propagate it up means that it is safe? IMHO if `transformUp` were executed on a different thread then it would be an issue, but that's not the case.\r\nDo you still have this concern?",
        "createdAt" : "2019-05-08T13:35:06Z",
        "updatedAt" : "2020-02-13T10:48:57Z",
        "lastEditedBy" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "tags" : [
        ]
      },
      {
        "id" : "35a896e6-2e08-4fc6-8e50-294cf8b27e7b",
        "parentId" : "9562dafc-d923-4a66-8437-2f68f5cb12bb",
        "authorId" : "24e1dd39-ae3f-4bbb-a391-f60afb62d075",
        "body" : "mmmh, yes you're right, I don't see any issue possible in the current code. Sorry, disregard this comment. Thanks.",
        "createdAt" : "2019-05-08T13:53:33Z",
        "updatedAt" : "2020-02-13T10:48:57Z",
        "lastEditedBy" : "24e1dd39-ae3f-4bbb-a391-f60afb62d075",
        "tags" : [
        ]
      }
    ],
    "commit" : "6d994abcf76b6ee48e8d6dd635a894b931bf8725",
    "line" : 143,
    "diffHunk" : "@@ -1,1 +126,130 @@        val replacedNewLeft = replaceConstants(newLeft, equalityPredicatesRight)\n        val newAnd = a.withNewChildren(Seq(replacedNewLeft, replacedNewRight))\n        (newAnd, equalityPredicatesLeft ++= equalityPredicatesRight)\n      case o: Or => (o.mapChildren(traverse(_, nullValue)._1), Map.empty)\n      case n: Not => (n.mapChildren(traverse(_, nullValue.map(!_))._1), Map.empty)"
  }
]