[
  {
    "id" : "214e66a8-eb65-4e3c-b773-40e58c91a316",
    "prId" : 31932,
    "prUrl" : "https://github.com/apache/spark/pull/31932#pullrequestreview-624637882",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d0ce124c-858c-4544-931d-5ced0b3d719e",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "2 space indent",
        "createdAt" : "2021-03-30T19:46:51Z",
        "updatedAt" : "2021-03-30T19:50:21Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "3c0e5077722d39b25680870ba9d435aafc62466c",
    "line" : 165,
    "diffHunk" : "@@ -1,1 +743,747 @@// scalastyle:on line.size.limit line.contains.tab\ncase class NTile(buckets: Expression) extends RowNumberLike with SizeBasedWindowFunction\n    with UnaryLike[Expression] {\n\n  def this() = this(Literal(1))"
  },
  {
    "id" : "c576df2a-0e18-43f0-b462-8ebf03d3a203",
    "prId" : 29886,
    "prUrl" : "https://github.com/apache/spark/pull/29886#pullrequestreview-498030533",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "311e349d-acc2-489a-a40a-eda1f3866fd7",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "nit: `NthValue` -> `Nth value` in the doc\r\nCan we also add an example about `ignore nulls` while we're here?",
        "createdAt" : "2020-09-28T04:38:52Z",
        "updatedAt" : "2020-09-28T06:39:49Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "0d03965a-8736-4568-8f5d-ab6bb0ecedc0",
        "parentId" : "311e349d-acc2-489a-a40a-eda1f3866fd7",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Unfortunately there is no SQL API for it yet. It's only available in DataFrame API. We will add examples when we add the SQL API.",
        "createdAt" : "2020-09-28T05:47:44Z",
        "updatedAt" : "2020-09-28T06:39:49Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "cc200892-81ca-47d7-8210-e72578c85dc7",
        "parentId" : "311e349d-acc2-489a-a40a-eda1f3866fd7",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "@cloud-fan, isn't it registered in SQL side? I see the example added in the original PR https://github.com/apache/spark/commit/8b09536cdf5c5477114cc11601c8b68c70408279#diff-5e6cbbb39e10b12ccd9d6a0bc3de31a4R153",
        "createdAt" : "2020-09-29T01:59:56Z",
        "updatedAt" : "2020-09-29T01:59:57Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "54c400f3-ffe0-40dd-be7a-5994f9a88976",
        "parentId" : "311e349d-acc2-489a-a40a-eda1f3866fd7",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "The current `ignore nulls` is very ustomized. I think it needs to be redesigned to be more common to all window functions.",
        "createdAt" : "2020-09-29T02:56:33Z",
        "updatedAt" : "2020-09-29T02:56:33Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      },
      {
        "id" : "bfa0469b-08ba-4f87-abd7-f314d4a4163e",
        "parentId" : "311e349d-acc2-489a-a40a-eda1f3866fd7",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "ahh gotya",
        "createdAt" : "2020-09-29T02:57:25Z",
        "updatedAt" : "2020-09-29T02:57:26Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "94037a35-af4f-49d6-91f3-909f7024836b",
        "parentId" : "311e349d-acc2-489a-a40a-eda1f3866fd7",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I mean the `ignore nulls` feature.",
        "createdAt" : "2020-09-29T02:59:40Z",
        "updatedAt" : "2020-09-29T02:59:41Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "fe9b8ab88f1b515110d80cc0223111f4fcbf254a",
    "line" : 1,
    "diffHunk" : "@@ -1,1 +667,671 @@    }\n  }\n\n  override lazy val evaluateExpression: AttributeReference = result\n"
  },
  {
    "id" : "8ff842de-692d-4be8-9115-72a6b039efe3",
    "prId" : 29800,
    "prUrl" : "https://github.com/apache/spark/pull/29800#pullrequestreview-506469502",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1af66617-6293-4f7d-9fc2-771e19439cdb",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "this is not needed as it's the same in `WindowFunction`",
        "createdAt" : "2020-10-12T09:26:48Z",
        "updatedAt" : "2020-10-28T02:15:58Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "b88dc0b6-1567-4e23-a210-ea31e18a31e2",
        "parentId" : "1af66617-6293-4f7d-9fc2-771e19439cdb",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "`NthValue` extends `AggregateWindowFunction` and later override frame as:\r\n`override val frame: WindowFrame = SpecifiedWindowFrame(RowFrame, UnboundedPreceding, CurrentRow)`",
        "createdAt" : "2020-10-12T09:53:14Z",
        "updatedAt" : "2020-10-28T02:15:58Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "1c0e82ba0ab95af7871b4b16f8be1e0662d49c78",
    "line" : 123,
    "diffHunk" : "@@ -1,1 +641,645 @@  override def children: Seq[Expression] = input :: offset :: Nil\n\n  override val frame: WindowFrame = UnspecifiedFrame\n\n  override def dataType: DataType = input.dataType"
  },
  {
    "id" : "cf67c92c-1acb-41b8-8e3c-b78356226f57",
    "prId" : 29800,
    "prUrl" : "https://github.com/apache/spark/pull/29800#pullrequestreview-517413426",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5846ddee-3fcc-41a5-898b-a310d8063097",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "`by a number of rows according to the current row`",
        "createdAt" : "2020-10-27T06:50:49Z",
        "updatedAt" : "2020-10-28T02:15:58Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "453dba8a-3340-43a4-b084-7f6722a1615b",
        "parentId" : "5846ddee-3fcc-41a5-898b-a310d8063097",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "I make a mistake.",
        "createdAt" : "2020-10-27T07:36:07Z",
        "updatedAt" : "2020-10-28T02:15:58Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "1c0e82ba0ab95af7871b4b16f8be1e0662d49c78",
    "line" : 56,
    "diffHunk" : "@@ -1,1 +368,372 @@/**\n * A frameless offset window function is a window function that cannot specify window frame and\n * returns the value of the input column offset by a number of rows within the partition.\n * For instance: a FrameLessOffsetWindowFunction for value x with offset -2, will get the value of\n * x 2 rows back in the partition."
  },
  {
    "id" : "64194041-35f9-41c4-91ee-56de130ef226",
    "prId" : 29743,
    "prUrl" : "https://github.com/apache/spark/pull/29743#pullrequestreview-487481711",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9d16493f-6337-4785-974c-9aed48006d3f",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Can we just we whitepsaces instead? I think that's what other examples do IIRC.",
        "createdAt" : "2020-09-13T23:54:48Z",
        "updatedAt" : "2020-09-19T19:00:31Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "6d822425-ae53-4209-93d1-6ce2f69e56c1",
        "parentId" : "9d16493f-6337-4785-974c-9aed48006d3f",
        "authorId" : "a8e23d47-3ae4-4385-848c-38a216d1bd08",
        "body" : "Do you mean using spaces instead of tabs?\r\nThe `check outputs of expression examples` in `ExpressionInfoSuite` does a string comparison and requires a tab to be the column separator. \r\nAll the other examples I checked also use tabs.",
        "createdAt" : "2020-09-14T07:27:09Z",
        "updatedAt" : "2020-09-19T19:00:31Z",
        "lastEditedBy" : "a8e23d47-3ae4-4385-848c-38a216d1bd08",
        "tags" : [
        ]
      }
    ],
    "commit" : "4162b41d325da3f9b732d835168a546916b50499",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +434,438 @@       A1\t1\t2\n       A1\t2\tNULL\n       A2\t3\tNULL\n  \"\"\",\n  since = \"2.0.0\","
  },
  {
    "id" : "83d9eefb-b4a7-428d-880b-ce13cdc20e7d",
    "prId" : 29604,
    "prUrl" : "https://github.com/apache/spark/pull/29604#pullrequestreview-489235127",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a8828393-ade4-4407-a12c-8aece479331f",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This doesn't match the usage doc: ```If the value of `input` at the `offset`th row is null, null is returned```",
        "createdAt" : "2020-09-15T14:49:27Z",
        "updatedAt" : "2020-09-18T02:29:36Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "cd0748d1-1553-489b-a3b5-919e57c26b75",
        "parentId" : "a8828393-ade4-4407-a12c-8aece479331f",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "How about `If the value of `input` at the `offset`th row is null, null is returned (respecting nulls)`",
        "createdAt" : "2020-09-16T02:26:55Z",
        "updatedAt" : "2020-09-18T02:29:36Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      },
      {
        "id" : "e840e360-351e-4541-a4be-8301d8d4387d",
        "parentId" : "a8828393-ade4-4407-a12c-8aece479331f",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "If ignoreNulls=true, we will skip nulls when finding the `offset`th row. Otherwise, every row counts for the `offset`.",
        "createdAt" : "2020-09-16T02:45:18Z",
        "updatedAt" : "2020-09-18T02:29:36Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "501d5645a16e5477ca5e84fb7638a912abab829b",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +563,567 @@      * offset - a positive int literal to indicate the offset in the window frame. It starts\n          with 1.\n      * ignoreNulls - an optional specification that indicates the NthValue should skip null\n          values in the determination of which row to use.\n  \"\"\","
  },
  {
    "id" : "d4f26a4e-d788-4fdd-b069-559490bec04d",
    "prId" : 29604,
    "prUrl" : "https://github.com/apache/spark/pull/29604#pullrequestreview-489253930",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "31c0cf79-a42e-49b9-ac60-80a0f59f040c",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can we add a TODO to optimize it using `OffsetWindowFunction`?",
        "createdAt" : "2020-09-15T14:56:34Z",
        "updatedAt" : "2020-09-18T02:29:36Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "e08f9591-38bc-4ffa-9a6c-c08291f7c586",
        "parentId" : "31c0cf79-a42e-49b9-ac60-80a0f59f040c",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "BTW, which window frames does `OffsetWindowFunction` support?",
        "createdAt" : "2020-09-15T14:56:53Z",
        "updatedAt" : "2020-09-18T02:29:36Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "fa058f9d-7f7e-47ea-8193-c91b2cbb176d",
        "parentId" : "31c0cf79-a42e-49b9-ac60-80a0f59f040c",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "`OffsetWindowFunction` not support any specified frame now.\r\n`OffsetWindowFunction`  limit it with\r\n```\r\n  override lazy val frame: WindowFrame = {\r\n    val boundary = direction match {\r\n      case Ascending => offset\r\n      case Descending => UnaryMinus(offset) match {\r\n          case e: Expression if e.foldable => Literal.create(e.eval(EmptyRow), e.dataType)\r\n          case o => o\r\n      }\r\n    }\r\n    SpecifiedWindowFrame(RowFrame, boundary, boundary)\r\n  }\r\n```",
        "createdAt" : "2020-09-16T03:53:41Z",
        "updatedAt" : "2020-09-18T02:29:36Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "501d5645a16e5477ca5e84fb7638a912abab829b",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +568,572 @@  since = \"3.1.0\",\n  group = \"window_funcs\")\ncase class NthValue(input: Expression, offsetExpr: Expression, ignoreNulls: Boolean)\n    extends AggregateWindowFunction with ImplicitCastInputTypes {\n"
  },
  {
    "id" : "6507c6b0-7c8b-4306-b9b2-2040de8fd9ce",
    "prId" : 29604,
    "prUrl" : "https://github.com/apache/spark/pull/29604#pullrequestreview-497155001",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "07de8532-212e-4b29-80f3-8f0e44fe9a86",
        "parentId" : null,
        "authorId" : "e5beb795-ac0e-4bd6-ad66-708215b8ae58",
        "body" : "This should `override def prettyName: String = \"nth_value\"`, to match the name of the expression.\r\nShould it also `override def sql`, to show the ignoreNulls parameter correctly?\r\nIs support of ignore nulls / respect nulls for nth_value to be done in a followup? I don't see in SqlBase.g4, like for FIRST/LAST?\r\ncc @beliefer @cloud-fan ",
        "createdAt" : "2020-09-27T17:59:07Z",
        "updatedAt" : "2020-09-27T17:59:44Z",
        "lastEditedBy" : "e5beb795-ac0e-4bd6-ad66-708215b8ae58",
        "tags" : [
        ]
      },
      {
        "id" : "8a7c10ff-68b3-4590-8373-fb8afb1bf7a3",
        "parentId" : "07de8532-212e-4b29-80f3-8f0e44fe9a86",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "Thanks for your remind. I will add `prettyName` and `sql`.\r\nWe will reactor FIRST/FIRST_VALUE in SqlBase.g4.\r\n",
        "createdAt" : "2020-09-28T02:39:50Z",
        "updatedAt" : "2020-09-28T02:39:50Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "501d5645a16e5477ca5e84fb7638a912abab829b",
    "line" : 84,
    "diffHunk" : "@@ -1,1 +621,625 @@  override lazy val evaluateExpression: AttributeReference = result\n\n  override def toString: String = s\"$prettyName($input, $offset)${if (ignoreNulls) \" ignore nulls\"}\"\n}\n"
  },
  {
    "id" : "079dc210-a9fd-469a-a386-852f65e9c3c6",
    "prId" : 28685,
    "prUrl" : "https://github.com/apache/spark/pull/28685#pullrequestreview-474124983",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "47580a3e-9bb2-43b2-936d-8a4a2d1ebcb7",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "let's document how it interacts with `direction`",
        "createdAt" : "2020-08-24T15:00:04Z",
        "updatedAt" : "2020-08-25T10:38:37Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "428954d0-dced-4c21-9b9e-af3126401c65",
        "parentId" : "47580a3e-9bb2-43b2-936d-8a4a2d1ebcb7",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "OK.",
        "createdAt" : "2020-08-25T04:23:41Z",
        "updatedAt" : "2020-08-25T10:38:37Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "301a847982445b01fdd75794d9780d23c4e58276",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +370,374 @@   * the offset is start with the current row. otherwise, the offset is start with the first\n   * row of the entire window frame.\n   */\n  val isRelative: Boolean = true\n"
  },
  {
    "id" : "ccfb6e2a-3b7b-44ae-a123-61b78170ef9a",
    "prId" : 28685,
    "prUrl" : "https://github.com/apache/spark/pull/28685#pullrequestreview-474274191",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ca364000-fdbd-4766-871e-0039c0d8b6f0",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "what if the value is byte or short? shall we allow them? Or it's long but the value is small?",
        "createdAt" : "2020-08-24T15:02:53Z",
        "updatedAt" : "2020-08-25T10:38:37Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "e66217b0-5f84-4fda-be37-3f10f2f00795",
        "parentId" : "ca364000-fdbd-4766-871e-0039c0d8b6f0",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can you check other databases?",
        "createdAt" : "2020-08-24T15:03:22Z",
        "updatedAt" : "2020-08-25T10:38:37Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "7259799c-1e0c-4058-8fdb-b7aa34a79fb8",
        "parentId" : "ca364000-fdbd-4766-871e-0039c0d8b6f0",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "postgresql: integer\r\noracle:integer\r\nredshift:integer\r\nvertica:integer",
        "createdAt" : "2020-08-25T02:54:49Z",
        "updatedAt" : "2020-08-25T10:38:37Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      },
      {
        "id" : "cd2639cb-baae-4106-89a2-e22fd857d36b",
        "parentId" : "ca364000-fdbd-4766-871e-0039c0d8b6f0",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "so when the offset is byte/short, the query fails?",
        "createdAt" : "2020-08-25T08:55:05Z",
        "updatedAt" : "2020-08-25T10:38:37Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "301a847982445b01fdd75794d9780d23c4e58276",
    "line" : 82,
    "diffHunk" : "@@ -1,1 +522,526 @@          }\n        case _ => TypeCheckFailure(\n          s\"The 'offset' parameter must be a int literal but it is ${offset.dataType}.\")\n      }\n    } else {"
  },
  {
    "id" : "c1c7048b-41d9-4c96-8353-d1fb9cecf381",
    "prId" : 27440,
    "prUrl" : "https://github.com/apache/spark/pull/27440#pullrequestreview-356538857",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3d476f62-6887-4daf-8dd6-b68c3ebd57d5",
        "parentId" : null,
        "authorId" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "body" : "Just special case the NTH_VALUE aggregate function instead of doing this.",
        "createdAt" : "2020-02-09T14:06:58Z",
        "updatedAt" : "2020-05-30T12:22:52Z",
        "lastEditedBy" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "tags" : [
        ]
      },
      {
        "id" : "a959c6bd-238d-460f-9fca-3a2e0d2ea766",
        "parentId" : "3d476f62-6887-4daf-8dd6-b68c3ebd57d5",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "I want `NTH_VALUE/FIRST_VALUE/LAST_VALUE` use this.",
        "createdAt" : "2020-02-10T05:58:56Z",
        "updatedAt" : "2020-05-30T12:22:52Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      },
      {
        "id" : "fbd30285-3fe5-47a5-a0be-f790443496e7",
        "parentId" : "3d476f62-6887-4daf-8dd6-b68c3ebd57d5",
        "authorId" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "body" : "Why would we use this for `FIRST` and `LAST`? How would you deal with `IGNORE NULLS`?",
        "createdAt" : "2020-02-11T09:52:46Z",
        "updatedAt" : "2020-05-30T12:22:52Z",
        "lastEditedBy" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "tags" : [
        ]
      },
      {
        "id" : "44fe73fb-f7b2-4a30-957f-244dbef13dec",
        "parentId" : "3d476f62-6887-4daf-8dd6-b68c3ebd57d5",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "`FIRST` and `LAST` is aggregate function, there were PRs who used them as `FIRST_VALUE/LAST_VALUE`.\r\nYou can reference https://github.com/apache/spark/pull/25082. \r\nThe above mentioned PR has been reverted.\r\nAll of `LEAD/LAG/NTH_VALUE/FIRST_VALUE/LAST_VALUE` need `IGNORE NULLS`, I think we should handle in a consistent way.",
        "createdAt" : "2020-02-11T10:07:50Z",
        "updatedAt" : "2020-05-30T12:22:52Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      },
      {
        "id" : "38a06898-158b-41de-84a3-599095ce6d8b",
        "parentId" : "3d476f62-6887-4daf-8dd6-b68c3ebd57d5",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "`LEAD/LAG` not support `IGNORE NULLS` now. Maybe the current implement only considered `postgreSQL`. So I think as long as `NTH_VALUE/FIRST_VALUE/LAST_VALUE` use the same way as `LEAD/LAG`, once the time is right, we can uniformly provide them with support for `IGNORE NULLS`.",
        "createdAt" : "2020-02-11T10:15:07Z",
        "updatedAt" : "2020-05-30T12:22:52Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "f3930f626877014e61c1635741e351ed0d1591d8",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +367,371 @@   * Whether the offset is based on the entire frame.\n   */\n  val isWholeBased: Boolean = false\n\n  override def children: Seq[Expression] = Seq(input, offset, default)"
  },
  {
    "id" : "43388f06-cac4-4fcb-8528-d5265a7f1b4b",
    "prId" : 27440,
    "prUrl" : "https://github.com/apache/spark/pull/27440#pullrequestreview-355711496",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f3f381f3-9f6e-4edd-a8fc-ccd737b853c9",
        "parentId" : null,
        "authorId" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "body" : "greater or equal to?",
        "createdAt" : "2020-02-09T14:07:27Z",
        "updatedAt" : "2020-05-30T12:22:52Z",
        "lastEditedBy" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "tags" : [
        ]
      },
      {
        "id" : "6fd59998-2126-4137-aa35-21d3fe67bf68",
        "parentId" : "f3f381f3-9f6e-4edd-a8fc-ccd737b853c9",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "No, 'offset' must greater than zero.\r\nThe description of Redshift\r\n```\r\noffset\r\nDetermines the row number relative to the first row in the window for which to return the expression. The offset can be a constant or an expression and must be a positive integer that is greater than 0.\r\n```\r\nThe description of Vertica\r\n`row‑number | Specifies the row to evaluate, where row‑number evaluates to an integer ≥ 1.`\r\nThe description of Presto\r\n` It is an error for the offset to be zero or negative.`\r\nThe description of Oracle\r\n`n determines the nth row for which the measure value is to be returned. n can be a constant, bind variable, column, or an expression involving them, as long as it resolves to a positive integer. The function returns NULL if the data source window has fewer than n rows. If n is null, then the function returns an error.`\r\nThe description of Postgresql\r\n`returns value evaluated at the row that is the nth row of the window frame (counting from 1); null if no such row`\r\n",
        "createdAt" : "2020-02-10T06:28:39Z",
        "updatedAt" : "2020-05-30T12:22:52Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "f3930f626877014e61c1635741e351ed0d1591d8",
    "line" : 49,
    "diffHunk" : "@@ -1,1 +513,517 @@      offset.eval() match {\n        case i: Int if i <= 0 => TypeCheckFailure(\n          s\"The 'offset' argument of nth_value must be greater than zero but it is $i.\")\n        case i: Int => TypeCheckSuccess\n        case other => TypeCheckFailure("
  },
  {
    "id" : "c410bad5-8a66-4ab6-889b-00cf4303e813",
    "prId" : 27440,
    "prUrl" : "https://github.com/apache/spark/pull/27440#pullrequestreview-355711201",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c9f726f8-d9e5-452b-861f-59ff61c859bd",
        "parentId" : null,
        "authorId" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "body" : "add a check to make sure it is foldable",
        "createdAt" : "2020-02-09T14:08:02Z",
        "updatedAt" : "2020-05-30T12:22:52Z",
        "lastEditedBy" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "tags" : [
        ]
      },
      {
        "id" : "91f2dd7d-a1f2-42a6-9635-f5f21dea783c",
        "parentId" : "c9f726f8-d9e5-452b-861f-59ff61c859bd",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "Ok. Thanks.",
        "createdAt" : "2020-02-10T06:27:40Z",
        "updatedAt" : "2020-05-30T12:22:52Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "f3930f626877014e61c1635741e351ed0d1591d8",
    "line" : 47,
    "diffHunk" : "@@ -1,1 +511,515 @@      check\n    } else if (offset.foldable) {\n      offset.eval() match {\n        case i: Int if i <= 0 => TypeCheckFailure(\n          s\"The 'offset' argument of nth_value must be greater than zero but it is $i.\")"
  },
  {
    "id" : "16ee6297-5fe0-49cd-a030-0aeb15597dd8",
    "prId" : 25831,
    "prUrl" : "https://github.com/apache/spark/pull/25831#pullrequestreview-291014962",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "aebd9812-3594-45ec-9c20-311f286253cd",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "`DeclarativeAggregate` (e.g., `updateExpressions`) uses DSLs `org.apache.spark.sql.catalyst.dsl._` in many places. IIUC these DSLs are assumed to be checked by the analyzer (e.g., type coercion), but some DSLs in `DeclarativeAggregate` are evaluated directly without the analyzer check. I personally think this is error-prone...",
        "createdAt" : "2019-09-19T03:41:33Z",
        "updatedAt" : "2019-09-20T09:36:17Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "1b9ca21e-0536-4ff2-a1e4-07c363f523da",
        "parentId" : "aebd9812-3594-45ec-9c20-311f286253cd",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "the DSL is just a shortcut of writing expressions directly. It's error-prone to create expressions that won't go through analyzer, but it's nothing to do with DSL.",
        "createdAt" : "2019-09-20T08:14:11Z",
        "updatedAt" : "2019-09-20T09:36:17Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "b85c6642c80159acd5ca2b133a11b70cf996979c",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +607,611 @@    zero,\n    zero,\n    (n.cast(DecimalType.IntDecimal) / buckets.cast(DecimalType.IntDecimal)).cast(IntegerType),\n    (n % buckets).cast(IntegerType)\n  )"
  }
]