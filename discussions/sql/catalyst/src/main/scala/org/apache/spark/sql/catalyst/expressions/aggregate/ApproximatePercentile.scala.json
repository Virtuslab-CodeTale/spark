[
  {
    "id" : "54274c9e-7477-40fc-9ac9-3da2425b69dc",
    "prId" : 29835,
    "prUrl" : "https://github.com/apache/spark/pull/29835#pullrequestreview-493408266",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9a30e28e-9123-4c12-9dee-9790adb4539e",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Shall we update Scala, Python and R functions too?",
        "createdAt" : "2020-09-22T09:57:06Z",
        "updatedAt" : "2020-09-22T13:37:06Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "1fc36d91-8446-4136-ae4e-93d20d11c1ec",
        "parentId" : "9a30e28e-9123-4c12-9dee-9790adb4539e",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "I will do if you are ok with semantic of the changes.",
        "createdAt" : "2020-09-22T10:10:32Z",
        "updatedAt" : "2020-09-22T13:37:06Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "047bbd46-c91e-498a-a46f-f5d2533f2752",
        "parentId" : "9a30e28e-9123-4c12-9dee-9790adb4539e",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Yeah looks good",
        "createdAt" : "2020-09-22T12:32:07Z",
        "updatedAt" : "2020-09-22T13:37:06Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "1daac421f4adfebf6a5df3b9d25a213302ede57b",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +56,60 @@      parameter (default: 10000) is a positive numeric literal which controls approximation accuracy\n      at the cost of memory. Higher value of `accuracy` yields better accuracy, `1.0/accuracy` is\n      the relative error of the approximation.\n      When `percentage` is an array, each value of the percentage array must be between 0.0 and 1.0.\n      In this case, returns the approximate percentile array of column `col` at the given"
  },
  {
    "id" : "4f471c61-9294-416d-8977-c63814a9bff3",
    "prId" : 26905,
    "prUrl" : "https://github.com/apache/spark/pull/26905#pullrequestreview-334578497",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "07656039-1fc3-4e76-8e69-0ad308df2607",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "hmm, seems like this change and https://github.com/apache/spark/pull/26905/files#diff-7448088085a868386c669c69629c8169R86 can fix the bug already?",
        "createdAt" : "2019-12-19T08:36:51Z",
        "updatedAt" : "2019-12-23T05:59:38Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "cba6178b-05a2-4841-8ae4-63ba6614146f",
        "parentId" : "07656039-1fc3-4e76-8e69-0ad308df2607",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "Do you mean re-enable ImplicitCastInputTypes?",
        "createdAt" : "2019-12-19T08:40:53Z",
        "updatedAt" : "2019-12-23T05:59:38Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "95af52d0-9ee0-4a84-8586-eda8f0a73672",
        "parentId" : "07656039-1fc3-4e76-8e69-0ad308df2607",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "this change disable nulls in percentages array, the change in the link fix accuracy overflow, there is still a match error if percentage is null",
        "createdAt" : "2019-12-19T08:54:02Z",
        "updatedAt" : "2019-12-23T05:59:38Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "1cffe156-32e7-42c0-91f7-03119a981867",
        "parentId" : "07656039-1fc3-4e76-8e69-0ad308df2607",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "yea re-enable `ImplicitCastInputTypes`.\r\n\r\nWe can implicitly add a check in `checkIntputTypes` for null percentage.",
        "createdAt" : "2019-12-19T09:06:23Z",
        "updatedAt" : "2019-12-23T05:59:38Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "6cdd79b3-5391-46d1-9699-f25ded2e7313",
        "parentId" : "07656039-1fc3-4e76-8e69-0ad308df2607",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "we will support `accuracy` with fractions, but it's trivial",
        "createdAt" : "2019-12-19T09:10:35Z",
        "updatedAt" : "2019-12-23T05:59:38Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "b41e1967-6737-470b-ab0b-4fc6a76f633e",
        "parentId" : "07656039-1fc3-4e76-8e69-0ad308df2607",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Then we can accept all `NumericType`, and in `checkInputDataTypes` we fail if the `accuracy` is actually not integral type.",
        "createdAt" : "2019-12-19T11:34:11Z",
        "updatedAt" : "2019-12-23T05:59:38Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "1a161631-512c-4aab-a4a3-9130bb2c8333",
        "parentId" : "07656039-1fc3-4e76-8e69-0ad308df2607",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "I was wrong about https://github.com/apache/spark/pull/26905/files#r359753430, there is no proper rule for `FractionalType` to `IntergralType` in ImplicitTypeCast. It will fail when doing type checking later if it is not an integral, so it just fine here",
        "createdAt" : "2019-12-19T11:42:31Z",
        "updatedAt" : "2019-12-23T05:59:38Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "6f50b772-f5d4-451e-a282-67e3e785bd61",
        "parentId" : "07656039-1fc3-4e76-8e69-0ad308df2607",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "This is can be verified by function percentile it is `ImplicitCastInputTypes` and its 3rd arg is `IntergralType`\r\n\r\n```sql\r\n         > select percentile(1, '0.1', 1.2);\r\nError in query: cannot resolve 'percentile(1, CAST('0.1' AS DOUBLE), 1.2BD)' due to data type mismatch: argument 3 requires integral type, however, '1.2BD' is of decimal(2,1) type.; line 1 pos 7;\r\n'Aggregate [unresolvedalias(percentile(1, cast(0.1 as double), 1.2, 0, 0), None)]\r\n+- OneRowRelation\r\n```",
        "createdAt" : "2019-12-19T11:44:28Z",
        "updatedAt" : "2019-12-23T05:59:38Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "7a3014fb90958c82cf6bbb700f5012d70cba833f",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +90,94 @@    // and can be easily cast to double for processing.\n    Seq(TypeCollection(NumericType, DateType, TimestampType),\n      TypeCollection(DoubleType, ArrayType(DoubleType, containsNull = false)), IntegralType)\n  }\n"
  }
]