[
  {
    "id" : "e92c88d2-dca4-41b9-9fa2-812f78ee1256",
    "prId" : 31120,
    "prUrl" : "https://github.com/apache/spark/pull/31120#pullrequestreview-565107131",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "62846b5f-d6ab-4130-b218-669b47b0d6b9",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "The doc example of `CreateNamedStruct` is\r\n```\r\n> SELECT _FUNC_(\"a\", 1, \"b\", 2, \"c\", 3);\r\n       {\"a\":1,\"b\":2,\"c\":3}\r\n```\r\n\r\nI think it's a valid syntax for named rows.",
        "createdAt" : "2021-01-11T07:01:26Z",
        "updatedAt" : "2021-01-11T07:01:26Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "fb1727ea-e8e6-4bf6-88bd-71189d857daf",
        "parentId" : "62846b5f-d6ab-4130-b218-669b47b0d6b9",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> The doc example of `CreateNamedStruct` is\r\n> \r\n> ```\r\n> > SELECT _FUNC_(\"a\", 1, \"b\", 2, \"c\", 3);\r\n>        {\"a\":1,\"b\":2,\"c\":3}\r\n> ```\r\n> \r\n> I think it's a valid syntax for named rows.\r\n\r\nI got it, seems because I run this  SQL in normal UT, i just return struct data's value part. I was misled.",
        "createdAt" : "2021-01-11T07:19:41Z",
        "updatedAt" : "2021-01-11T07:19:41Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "fffc4501d64d3678d53cd23c92e8bf229e6d5e98",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +510,514 @@    Examples:\n      > SELECT _FUNC_('{\"a\":1, \"b\":0.8}', 'a INT, b DOUBLE');\n       {1, 0.8}\n      > SELECT _FUNC_('{\"time\":\"26/08/2015\"}', 'time Timestamp', map('timestampFormat', 'dd/MM/yyyy'));\n       {2015-08-26 00:00:00}"
  },
  {
    "id" : "fb7692ca-cbb2-423d-b178-b0112a01d4bd",
    "prId" : 30172,
    "prUrl" : "https://github.com/apache/spark/pull/30172#pullrequestreview-519268851",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1552a69e-9ed3-4084-978f-992f03aa6f05",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Can we update migration guide?",
        "createdAt" : "2020-10-28T14:34:46Z",
        "updatedAt" : "2020-10-28T18:00:11Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "bd9919d5-69c5-45c1-8b47-282dfacaed49",
        "parentId" : "1552a69e-9ed3-4084-978f-992f03aa6f05",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Will it break user queries?",
        "createdAt" : "2020-10-28T15:43:48Z",
        "updatedAt" : "2020-10-28T18:00:11Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "77174b4d-4484-419e-8542-7e2d91f9b322",
        "parentId" : "1552a69e-9ed3-4084-978f-992f03aa6f05",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Nope but the output from this function becomes different",
        "createdAt" : "2020-10-28T15:45:55Z",
        "updatedAt" : "2020-10-28T18:00:11Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "8133f80b-aba9-4d61-b311-2200a58df3d1",
        "parentId" : "1552a69e-9ed3-4084-978f-992f03aa6f05",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Should I add a SQL config, just in case? or this is overkill already ...",
        "createdAt" : "2020-10-28T15:53:39Z",
        "updatedAt" : "2020-10-28T18:00:11Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "f20c740c-608a-4670-a0f6-268f5bd0f032",
        "parentId" : "1552a69e-9ed3-4084-978f-992f03aa6f05",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Okay .. NVM ..",
        "createdAt" : "2020-10-29T01:28:32Z",
        "updatedAt" : "2020-10-29T01:28:33Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "349615db819b3257fd74a690ca38e8effe7a63f0",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +802,806 @@    }\n\n    UTF8String.fromString(dt.sql)\n  }\n"
  },
  {
    "id" : "c96a13b5-9367-4686-a2c7-72f1bc73d2c8",
    "prId" : 28167,
    "prUrl" : "https://github.com/apache/spark/pull/28167#pullrequestreview-390937734",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0037b212-a7c6-4bd7-86d5-b9dfdd78870f",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Do you check that only top level fields are valid?",
        "createdAt" : "2020-04-09T15:58:19Z",
        "updatedAt" : "2020-04-10T09:13:05Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "36f941c4-757f-4de7-95cb-1ab4ac89a746",
        "parentId" : "0037b212-a7c6-4bd7-86d5-b9dfdd78870f",
        "authorId" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "body" : "no, nested fields are checked by `JsonParser` as well.",
        "createdAt" : "2020-04-09T16:15:09Z",
        "updatedAt" : "2020-04-10T09:13:05Z",
        "lastEditedBy" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "tags" : [
        ]
      }
    ],
    "commit" : "c06abe06086a3a50a2c126cfe68ea94dd1647af2",
    "line" : 51,
    "diffHunk" : "@@ -1,1 +981,985 @@          // parse the JSON string\n          while (parser.nextToken() != null) {\n            parser.skipChildren()\n          }\n          return true"
  },
  {
    "id" : "91124c1e-6278-4e6a-be9d-31c2ea6dc427",
    "prId" : 28167,
    "prUrl" : "https://github.com/apache/spark/pull/28167#pullrequestreview-391324283",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3e3ec2e1-a974-41dc-a989-fc8509792cc2",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Could you add nested cases in the examples?",
        "createdAt" : "2020-04-10T08:04:06Z",
        "updatedAt" : "2020-04-10T09:13:05Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "65207f0c-c25b-42b7-99b3-2bfcf149c463",
        "parentId" : "3e3ec2e1-a974-41dc-a989-fc8509792cc2",
        "authorId" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "body" : "Yes. Sure.",
        "createdAt" : "2020-04-10T08:13:49Z",
        "updatedAt" : "2020-04-10T09:13:05Z",
        "lastEditedBy" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "tags" : [
        ]
      }
    ],
    "commit" : "c06abe06086a3a50a2c126cfe68ea94dd1647af2",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +949,953 @@      > Select _FUNC_('{\"key\" : \"valid JSON\"}');\n        true\n      > Select _FUNC_('{\"invalid JSON\"}');\n        false\n      > Select _FUNC_('{\"jobj\": {\"id\": 1}}');"
  },
  {
    "id" : "99b54fc5-7b16-408f-b9b9-638a282a7bf5",
    "prId" : 27854,
    "prUrl" : "https://github.com/apache/spark/pull/27854#pullrequestreview-371036658",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "485b1b22-519b-457c-bafb-20ad782e7dd0",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Here is about the actual fix.\r\n\r\nThe reason why there are differences compared to JSON datasource is:\r\n\r\n1. JSON datasource always expects `StructType`. Array of JSON objects is still inferred as `StructType`. Other types are disallowed as a root type.\r\n2. `schema_of_json` infers the type as is. Array of JSON objects is inferred as `ArrayType(StructType)`. Other types are allowed as a root type.",
        "createdAt" : "2020-03-09T10:00:42Z",
        "updatedAt" : "2020-03-09T14:59:59Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "4ca013b68dca9a97c24997752218736348458492",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +789,793 @@        case other: DataType =>\n          jsonInferSchema.canonicalizeType(other, jsonOptions).getOrElse(StringType)\n      }\n    }\n"
  },
  {
    "id" : "62e336f4-1357-4a16-b261-b6a8929dc377",
    "prId" : 27836,
    "prUrl" : "https://github.com/apache/spark/pull/27836#pullrequestreview-384397335",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "19f2bce6-24f3-4c65-a6dd-bb18efa76c9c",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Apparently, the current implementation seems to have the same limitations: `NullPointerException` and `ClassCastException`. Please add more unit test cases with `null` and `Integer` input.",
        "createdAt" : "2020-03-31T04:29:50Z",
        "updatedAt" : "2020-04-08T08:37:05Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "ec2fb881-e46e-4d8a-aa64-b26f3c967683",
        "parentId" : "19f2bce6-24f3-4c65-a6dd-bb18efa76c9c",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "I checked.\r\n```\r\nscala> sql(\"select json_object_keys(null)\").show\r\njava.lang.NullPointerException\r\n\r\nscala> sql(\"select json_object_keys(1)\").show\r\njava.lang.ClassCastException: class java.lang.Integer cannot be cast to class org.apache.spark.unsafe.types.UTF8String (java.lang.Integer is in module java.base of loader 'bootstrap'; org.apache.spark.unsafe.types.UTF8String is in unnamed module of loader 'app')\r\n```",
        "createdAt" : "2020-03-31T04:39:18Z",
        "updatedAt" : "2020-04-08T08:37:05Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "faa35719770475e35b5970dc4bd703d3e6cea9d4",
    "line" : 63,
    "diffHunk" : "@@ -1,1 +917,921 @@    } catch {\n      case _: JsonProcessingException | _: IOException => null\n    }\n  }\n"
  },
  {
    "id" : "c6403fb9-45dd-4aaa-905f-9c7e1c0d8b05",
    "prId" : 27836,
    "prUrl" : "https://github.com/apache/spark/pull/27836#pullrequestreview-387729925",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "56980c35-fd40-4e9d-9330-51a37afffe65",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "If you don't mind, please add a comment before this line.",
        "createdAt" : "2020-04-04T19:56:10Z",
        "updatedAt" : "2020-04-08T08:37:06Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "faa35719770475e35b5970dc4bd703d3e6cea9d4",
    "line" : 46,
    "diffHunk" : "@@ -1,1 +900,904 @@    val json = child.eval(input).asInstanceOf[UTF8String]\n    // return null for `NULL` input\n    if(json == null) {\n      return null\n    }"
  },
  {
    "id" : "c06c4a97-fd0e-4254-961f-772ae8f1d917",
    "prId" : 27759,
    "prUrl" : "https://github.com/apache/spark/pull/27759#pullrequestreview-368713103",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b1f6f6f6-c210-42ca-995a-732a90825168",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Can nextToken return null? Looks like it can:\r\nhttps://github.com/apache/spark/blob/8e280cebf25e47bf40df224461a76fc4c84cc997/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/json/JacksonUtils.scala#L28-L33",
        "createdAt" : "2020-03-04T08:01:58Z",
        "updatedAt" : "2020-04-06T12:25:27Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "c9e9fa82-d6eb-4297-bd78-fbb06c515052",
        "parentId" : "b1f6f6f6-c210-42ca-995a-732a90825168",
        "authorId" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "body" : "It returns null when end of input is reached.\r\nIf it returns null before returning `END_ARRAY` then our json is invalid. Invalid input was already handled.\r\nAnyway now i will add one more check for null.",
        "createdAt" : "2020-03-04T11:49:02Z",
        "updatedAt" : "2020-04-06T12:25:27Z",
        "lastEditedBy" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "tags" : [
        ]
      }
    ],
    "commit" : "f44e24ec66e11fdb71c1a9a813f04f6e37244b61",
    "line" : 64,
    "diffHunk" : "@@ -1,1 +857,861 @@    }\n    // Keep traversing until the end of JSON array\n    while(parser.nextToken() != JsonToken.END_ARRAY) {\n      length += 1\n      // skip all the child of inner object or array"
  },
  {
    "id" : "ea93dd67-e258-47a5-beca-d109507629b4",
    "prId" : 27759,
    "prUrl" : "https://github.com/apache/spark/pull/27759#pullrequestreview-384345672",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b9d29a27-69e6-4a43-b84e-6474139af953",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Hi, @iRakson . Please use `ExpectsInputTypes` to prevent `ClassCastException` like the following.\r\n```\r\nspark-sql> SELECT json_array_length(1);\r\n20/03/30 18:19:11 ERROR SparkSQLDriver: Failed in [SELECT json_array_length(1)]\r\njava.lang.ClassCastException: class java.lang.Integer cannot be cast to class org.apache.spark.unsafe.types.UTF8String (java.lang.Integer is in module java.base of loader 'bootstrap'; org.apache.spark.unsafe.types.UTF8String is in unnamed module of loader 'app')\r\n```",
        "createdAt" : "2020-03-31T01:21:36Z",
        "updatedAt" : "2020-04-06T12:25:27Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "370aa638-7d97-4f1a-b775-9e5e12aa1850",
        "parentId" : "b9d29a27-69e6-4a43-b84e-6474139af953",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Especially, please add a test case for `null` since `NullPointerException` is the worst one.\r\n```\r\nspark-sql> SELECT json_array_length(null);\r\n20/03/30 18:34:38 ERROR SparkSQLDriver: Failed in [SELECT json_array_length(null)]\r\njava.lang.NullPointerException\r\n\tat org.apache.spark.sql.catalyst.json.CreateJacksonParser$.utf8String(CreateJacksonParser.scala:38)\r\n```\r\n\r\nThe expected output for the `null` input is `null`.",
        "createdAt" : "2020-03-31T01:35:34Z",
        "updatedAt" : "2020-04-06T12:25:27Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "f44e24ec66e11fdb71c1a9a813f04f6e37244b61",
    "line" : 35,
    "diffHunk" : "@@ -1,1 +828,832 @@\n  override def eval(input: InternalRow): Any = {\n    val json = child.eval(input).asInstanceOf[UTF8String]\n    // return null for null input\n    if (json == null) {"
  },
  {
    "id" : "ef97434e-ab3c-4d73-852a-1aad42319f9c",
    "prId" : 27759,
    "prUrl" : "https://github.com/apache/spark/pull/27759#pullrequestreview-387726123",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "39f357c4-f5cc-4565-ac57-21b06fb8b543",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "`NullPointerException` is not catched here.",
        "createdAt" : "2020-03-31T01:38:01Z",
        "updatedAt" : "2020-04-06T12:25:27Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "2e7c04f4-8139-4a4a-8c82-bee410ffd4d2",
        "parentId" : "39f357c4-f5cc-4565-ac57-21b06fb8b543",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Maybe, do we need to catch `case NonFatal(e) =>` in general?",
        "createdAt" : "2020-03-31T01:38:48Z",
        "updatedAt" : "2020-04-06T12:25:27Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "1f808a24-965e-4cc4-aba5-3718e4954b68",
        "parentId" : "39f357c4-f5cc-4565-ac57-21b06fb8b543",
        "authorId" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "body" : "I think we do not need to catch `NullPointerException` here.",
        "createdAt" : "2020-04-04T14:35:54Z",
        "updatedAt" : "2020-04-06T12:25:27Z",
        "lastEditedBy" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "tags" : [
        ]
      },
      {
        "id" : "bc239d44-62fa-45ff-a009-072fab3a8eb7",
        "parentId" : "39f357c4-f5cc-4565-ac57-21b06fb8b543",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "The added line 831 looks okay.",
        "createdAt" : "2020-04-04T19:08:10Z",
        "updatedAt" : "2020-04-06T12:25:27Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "f44e24ec66e11fdb71c1a9a813f04f6e37244b61",
    "line" : 53,
    "diffHunk" : "@@ -1,1 +846,850 @@      }\n    } catch {\n      case _: JsonProcessingException | _: IOException => null\n    }\n  }"
  },
  {
    "id" : "b14a9753-f3f5-4a28-8ff3-6c285cf0a2ad",
    "prId" : 27759,
    "prUrl" : "https://github.com/apache/spark/pull/27759#pullrequestreview-387739055",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f485ca94-263b-4ff2-8de9-6f780f135719",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Just a question. We still check the invalidity of the content inside children because we should return `null` if there is an invalidity in there. Did I understand correctly?",
        "createdAt" : "2020-04-04T19:47:10Z",
        "updatedAt" : "2020-04-06T12:25:27Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "3bd348f1-cfe2-42a2-b091-07d2f261bcea",
        "parentId" : "f485ca94-263b-4ff2-8de9-6f780f135719",
        "authorId" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "body" : "Yes.\r\nActually Jackson parser will throw JsonProcessingException in case of invalid JSON. So, it is not required to check here. ",
        "createdAt" : "2020-04-04T20:52:53Z",
        "updatedAt" : "2020-04-06T12:25:27Z",
        "lastEditedBy" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "tags" : [
        ]
      }
    ],
    "commit" : "f44e24ec66e11fdb71c1a9a813f04f6e37244b61",
    "line" : 67,
    "diffHunk" : "@@ -1,1 +860,864 @@      length += 1\n      // skip all the child of inner object or array\n      parser.skipChildren()\n    }\n    length"
  },
  {
    "id" : "6b6afd19-70ea-4a74-9dfe-ea60518bfa3d",
    "prId" : 26965,
    "prUrl" : "https://github.com/apache/spark/pull/26965#pullrequestreview-335739037",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ddf08665-5d83-492f-8fc5-b46039661d75",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "@HyukjinKwon Do you know why we don't use settings from JSONOptions:\r\nhttps://github.com/apache/spark/blob/67b644c3d74b0587dd5d498b903383ac4de932fe/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/json/JSONOptions.scala#L133-L147",
        "createdAt" : "2019-12-20T20:36:34Z",
        "updatedAt" : "2019-12-25T11:37:06Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "7c683685-9d74-457e-9691-f64b30a86616",
        "parentId" : "ddf08665-5d83-492f-8fc5-b46039661d75",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "I think both functions were added mainly to support Hive compatibility, and I think that's why.",
        "createdAt" : "2019-12-23T07:22:21Z",
        "updatedAt" : "2019-12-25T11:37:06Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "dc0d9dd2-6185-4c0e-8aad-4ea71540c0f5",
        "parentId" : "ddf08665-5d83-492f-8fc5-b46039661d75",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "I am not sure if we should match them or not for now considering the original intention of both functions.",
        "createdAt" : "2019-12-23T07:23:30Z",
        "updatedAt" : "2019-12-25T11:37:06Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "0c55b10eed21dc9320b8b8b522a34b71af330666",
    "line" : 3,
    "diffHunk" : "@@ -1,1 +101,105 @@\nprivate[this] object SharedFactory {\n  val jsonFactory = new JsonFactoryBuilder()\n    // The two options below enabled for Hive compatibility\n    .enable(JsonReadFeature.ALLOW_UNESCAPED_CONTROL_CHARS)"
  },
  {
    "id" : "30c7e559-8826-404c-aa3f-9a49abac6330",
    "prId" : 26965,
    "prUrl" : "https://github.com/apache/spark/pull/26965#pullrequestreview-403190645",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fc2824f3-c504-4a4e-b1d3-2082de21ab34",
        "parentId" : null,
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "We also have the other Json built-in functions, but only these two functions behave differently from the others. It looks weird especially when Hive compatibility is not important for us.  ",
        "createdAt" : "2020-04-17T00:54:46Z",
        "updatedAt" : "2020-04-17T00:54:46Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      },
      {
        "id" : "172ad884-bbae-419a-a73a-9441e6a51e35",
        "parentId" : "fc2824f3-c504-4a4e-b1d3-2082de21ab34",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "But the main reason why these were added is for Hive compatibility IIRC. It's a minimised change to keep the compatibility. Also, I guess these are all instances for Spark JSON functions corresponding to Hive?",
        "createdAt" : "2020-04-17T12:30:52Z",
        "updatedAt" : "2020-04-17T12:30:53Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "bbbf2638-e19a-46e1-8c11-5c04fd935fb2",
        "parentId" : "fc2824f3-c504-4a4e-b1d3-2082de21ab34",
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "I am afraid that end users expect all our JSON functions have the same behavior. That means, either all the functions support SINGLE QUOTE or none of them supports it. Make the behavior configurable? For reading the external JSON data sources, users can control it https://github.com/apache/spark/blob/master/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/json/JSONOptions.scala#L141-L149 \r\n\r\nBTW, will this change cause the query result difference? ",
        "createdAt" : "2020-04-20T16:42:16Z",
        "updatedAt" : "2020-04-20T16:42:16Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      },
      {
        "id" : "aaf1f47c-586e-4b0d-a068-22fae676d67f",
        "parentId" : "fc2824f3-c504-4a4e-b1d3-2082de21ab34",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "> I am afraid that end users expect all our JSON functions have the same behavior. That means, either all the functions support SINGLE QUOTE or none of them supports it. Make the behavior configurable? For reading the external JSON data sources, users can control it\r\n\r\nIf we make it configurable, could we make all the behaivours configurable by using `JSONOptions` here as max suggested in https://github.com/apache/spark/pull/26965/files#r360562916 ? Some users might expect the same behaivours between json functions and json external reading, too.\r\n\r\n> BTW, will this change cause the query result difference?\r\n\r\nAh, I think yes; after this PR, some query results have changed from `null` to a correct answer. We need to update the migration guide for 3.0. We need to add a legacy config to keep the old behaivour, too?",
        "createdAt" : "2020-04-21T00:59:41Z",
        "updatedAt" : "2020-04-21T01:01:37Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "f3987305-187f-47ea-8949-4cb00b02be41",
        "parentId" : "fc2824f3-c504-4a4e-b1d3-2082de21ab34",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "It's too corner case to document .. who will rely on the behaviour of `null` from a single quote JSON ... Users from Hive might depend on the single quote behaviours but It's pretty unlikely for Spark users to depend on single quoted JSONs.\r\n\r\nWhat about we think about fixing it when it's actually requested from users?",
        "createdAt" : "2020-04-21T01:51:33Z",
        "updatedAt" : "2020-04-21T01:51:33Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "4f591586-7e0f-40e8-93a8-4a9426bc8a53",
        "parentId" : "fc2824f3-c504-4a4e-b1d3-2082de21ab34",
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "OK. That sounds OK to me. Let us wait for user requests. ",
        "createdAt" : "2020-04-30T04:21:34Z",
        "updatedAt" : "2020-04-30T04:21:34Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      }
    ],
    "commit" : "0c55b10eed21dc9320b8b8b522a34b71af330666",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +104,108 @@    // The two options below enabled for Hive compatibility\n    .enable(JsonReadFeature.ALLOW_UNESCAPED_CONTROL_CHARS)\n    .enable(JsonReadFeature.ALLOW_SINGLE_QUOTES)\n    .build()\n}"
  }
]