[
  {
    "id" : "571a1568-4372-4552-9d76-08e3357330d4",
    "prId" : 33213,
    "prUrl" : "https://github.com/apache/spark/pull/33213#pullrequestreview-698945652",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "862688d0-b05f-420c-9f50-e4db24778eef",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This is to match https://github.com/apache/spark/pull/33213/files#diff-583171e935b2dc349378063a5841c5b98b30a2d57ac3743a9eccfe7bffcb8f2aL472",
        "createdAt" : "2021-07-05T08:51:05Z",
        "updatedAt" : "2021-07-05T08:51:06Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "52383baf47bdea4097a9ebbcd8722d03ca1c2b9c",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +373,377 @@\n            case _ =>\n              throw QueryCompilationErrors.invalidFieldName(fieldNames, normalizedPath)\n          }\n        }"
  },
  {
    "id" : "5d567a79-e1eb-44e5-b46b-639ce102956d",
    "prId" : 32448,
    "prUrl" : "https://github.com/apache/spark/pull/32448#pullrequestreview-658528270",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d586c077-6059-4e82-aea0-8c4376c9b1ab",
        "parentId" : null,
        "authorId" : "92aa9573-b64a-4a86-aebf-54c827df3ed0",
        "body" : "I can add tests for this if we want to keep this behavior",
        "createdAt" : "2021-05-06T01:36:25Z",
        "updatedAt" : "2021-05-06T01:36:25Z",
        "lastEditedBy" : "92aa9573-b64a-4a86-aebf-54c827df3ed0",
        "tags" : [
        ]
      },
      {
        "id" : "e2b60d31-03b3-437a-bc93-ba9205b988aa",
        "parentId" : "d586c077-6059-4e82-aea0-8c4376c9b1ab",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "+1 for adding some tests for it.",
        "createdAt" : "2021-05-10T19:51:39Z",
        "updatedAt" : "2021-05-10T19:51:39Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "1dc06b2e-5d0f-4f59-b58c-f253803c70b2",
        "parentId" : "d586c077-6059-4e82-aea0-8c4376c9b1ab",
        "authorId" : "92aa9573-b64a-4a86-aebf-54c827df3ed0",
        "body" : "Done",
        "createdAt" : "2021-05-13T02:09:15Z",
        "updatedAt" : "2021-05-13T02:09:15Z",
        "lastEditedBy" : "92aa9573-b64a-4a86-aebf-54c827df3ed0",
        "tags" : [
        ]
      }
    ],
    "commit" : "5762ddc83e96b640ffdd4125c182646bf9fb03ff",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +556,560 @@    }\n\n  private[sql] def merge(resolver: Resolver)(left: DataType, right: DataType): DataType =\n    (left, right) match {\n      case (ArrayType(leftElementType, leftContainsNull),"
  },
  {
    "id" : "f75b8afc-378d-46f1-bbe8-98f2acfba675",
    "prId" : 29587,
    "prUrl" : "https://github.com/apache/spark/pull/29587#pullrequestreview-478753912",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f4d65cf2-f9a5-48f7-970f-2a5f811cf100",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "~Where does this limitation come?; we don't need to support this case, or supporting it is technically difficult?~ Ah, I see. Is this an unsupported case, right?\r\nhttps://github.com/apache/spark/pull/29587/files#diff-4d656d696512d6bcb03a48f7e0af6251R106-R107",
        "createdAt" : "2020-08-31T08:39:21Z",
        "updatedAt" : "2020-10-16T19:47:41Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "acf23c99-a5b1-4739-a362-53a8b64b0f95",
        "parentId" : "f4d65cf2-f9a5-48f7-970f-2a5f811cf100",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "I leverage `WithFields` to add missing nested fields into structs. `WithFields` doesn't support array or map types currently.",
        "createdAt" : "2020-08-31T16:16:39Z",
        "updatedAt" : "2020-10-16T19:47:41Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "3d907d07233851d6169533d0475c5a53b02cb4a7",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +645,649 @@  /**\n   * Returns a `StructType` that contains missing fields recursively from `source` to `target`.\n   * Note that this doesn't support looking into array type and map type recursively.\n   */\n  def findMissingFields("
  },
  {
    "id" : "f8d7f61c-7f9a-4ee9-b871-e20e2b0e15c6",
    "prId" : 27350,
    "prUrl" : "https://github.com/apache/spark/pull/27350#pullrequestreview-350793183",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ff2a8c7e-ecfe-4532-9ee4-b57376797ee4",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can we reuse `CatalogV2Implicits.MultipartIdentifierHelper.quoted` ?",
        "createdAt" : "2020-01-30T12:42:31Z",
        "updatedAt" : "2020-01-30T18:27:08Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "2b364e23927fbcdd8a6d219c9ae6bd861dbe3f17",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +319,323 @@      includeCollections: Boolean = false,\n      resolver: Resolver = _ == _): Option[(Seq[String], StructField)] = {\n    def prettyFieldName(nameParts: Seq[String]): String = {\n      import org.apache.spark.sql.connector.catalog.CatalogV2Implicits._\n      nameParts.quoted"
  },
  {
    "id" : "b6001aba-62c0-4119-9bb3-ffa79ba12429",
    "prId" : 27117,
    "prUrl" : "https://github.com/apache/spark/pull/27117#pullrequestreview-339461305",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3d493ef7-fc68-49b4-8214-1ae95dca5cba",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "```scala\r\n    val stringConcat = new StringUtils.StringConcat()\r\n    val len = fields.length\r\n    stringConcat.append(\"struct<\")\r\n    var i = 0\r\n    while (i < len) {\r\n      stringConcat.append(s\"${fields(i).name}:${fields(i).dataType.catalogString}\")\r\n      i += 1\r\n      if (i < len) stringConcat.append(\",\")\r\n    }\r\n    stringConcat.append(\">\")\r\n    stringConcat.toString\r\n```",
        "createdAt" : "2020-01-07T19:34:36Z",
        "updatedAt" : "2020-01-07T19:51:29Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "ac600fec-3eb7-4d0c-ab70-ff71c648b386",
        "parentId" : "3d493ef7-fc68-49b4-8214-1ae95dca5cba",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Thanks! I was wanting to use `init` to make it looks simple. Now seems not simpler than while loop...",
        "createdAt" : "2020-01-07T19:39:03Z",
        "updatedAt" : "2020-01-07T19:51:29Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "5f25d79e6908778303a205b4db077fcd4ead2d65",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +406,410 @@  }\n\n  override def catalogString: String = {\n    // in catalogString, we should not truncate\n    val stringConcat = new StringUtils.StringConcat()"
  }
]