[
  {
    "id" : "40ef8395-1e0f-4b16-b9ba-1829d06933d5",
    "prId" : 28764,
    "prUrl" : "https://github.com/apache/spark/pull/28764#pullrequestreview-426830244",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "18feac2a-fe76-47de-8f9e-971b605a8a47",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "I added the error checks to follow the PostgreSQL behaviour: https://github.com/postgres/postgres/blob/master/src/test/regress/expected/numeric.out#L778-L796\r\nhttps://github.com/postgres/postgres/blob/master/src/test/regress/expected/numeric.out#L837-L842\r\nThe current logic returns null instead of throwing a runtime exception.\r\n",
        "createdAt" : "2020-06-09T06:42:19Z",
        "updatedAt" : "2020-06-11T02:54:14Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "9e8eab25eeffba0260d1a98a199f832251809c1d",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +1333,1337 @@        jl.Double.isNaN(min) || jl.Double.isInfinite(min) ||\n        jl.Double.isNaN(max) || jl.Double.isInfinite(max)) {\n      return null\n    }\n"
  },
  {
    "id" : "364059df-ff5c-49b3-9867-81dd45778a97",
    "prId" : 28764,
    "prUrl" : "https://github.com/apache/spark/pull/28764#pullrequestreview-426831286",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "793ca042-93e5-40e9-b1d2-9b2549542517",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "This logic follows the PostgreSQL one: https://github.com/postgres/postgres/blob/master/src/backend/utils/adt/float.c#L3916-L3943",
        "createdAt" : "2020-06-09T06:44:14Z",
        "updatedAt" : "2020-06-11T02:54:14Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "9e8eab25eeffba0260d1a98a199f832251809c1d",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +1339,1343 @@    val upper = Math.max(min, max)\n\n    if (min < max) {\n      if (value < lower) {\n        0L"
  },
  {
    "id" : "770d9ad3-bf27-4c08-befb-adee8614645b",
    "prId" : 28764,
    "prUrl" : "https://github.com/apache/spark/pull/28764#pullrequestreview-427676073",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "66c4ab4d-c5e0-4436-a48a-111e0c59359d",
        "parentId" : null,
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "Can we add tests for these cases?",
        "createdAt" : "2020-06-10T02:30:35Z",
        "updatedAt" : "2020-06-11T02:54:14Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "141c6793-88e8-4110-b4a2-b9e66eada0dd",
        "parentId" : "66c4ab4d-c5e0-4436-a48a-111e0c59359d",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "This case?\r\nhttps://github.com/apache/spark/pull/28764/files#diff-f97e8257cf76e8ae2bbdd3b79ac926beR822\r\nhttps://github.com/apache/spark/pull/28764/files#diff-f97e8257cf76e8ae2bbdd3b79ac926beR817\r\nhttps://github.com/apache/spark/pull/28764/files#diff-5cba125bd3e3b7e831d3ba7f81da6d3fR4548",
        "createdAt" : "2020-06-10T02:50:52Z",
        "updatedAt" : "2020-06-11T02:54:14Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "77e82d73-5aba-4849-855e-c4369c6d3ba0",
        "parentId" : "66c4ab4d-c5e0-4436-a48a-111e0c59359d",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "ah, I see. thanks",
        "createdAt" : "2020-06-10T02:52:06Z",
        "updatedAt" : "2020-06-11T02:54:14Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "74dbc0c1-33b9-42dc-b4e5-0d6f34a0b490",
        "parentId" : "66c4ab4d-c5e0-4436-a48a-111e0c59359d",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Yea, thanks for the check, anyway!",
        "createdAt" : "2020-06-10T02:53:01Z",
        "updatedAt" : "2020-06-11T02:54:14Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "9e8eab25eeffba0260d1a98a199f832251809c1d",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +1343,1347 @@        0L\n      } else if (value >= upper) {\n        numBucket + 1L\n      } else {\n        (numBucket.toDouble * (value - lower) / (upper - lower)).toLong + 1L"
  },
  {
    "id" : "a91fdb44-72a7-4126-96c0-68e8ac48a5f8",
    "prId" : 28764,
    "prUrl" : "https://github.com/apache/spark/pull/28764#pullrequestreview-428513887",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8427906b-1e52-4c0d-9a7c-e909b9931f6b",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Is the behavior of min > max the same across all DBs implementing `WidthBucket`?",
        "createdAt" : "2020-06-11T00:00:09Z",
        "updatedAt" : "2020-06-11T02:54:14Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "d65a6f98-5b06-4edc-a186-b420291bc6ae",
        "parentId" : "8427906b-1e52-4c0d-9a7c-e909b9931f6b",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "I checked now Oracle behaviour: http://sqlfiddle.com/#!4/598652/1/0\r\nIt seems Oracle has the same results for the `min > max` case, but the answers of edge cases (e.g., col=WB_2 and  row=1.99999) is different... I think this is an implementation-specific issue and its difficult to follow them.",
        "createdAt" : "2020-06-11T00:25:07Z",
        "updatedAt" : "2020-06-11T02:54:14Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "9e8eab25eeffba0260d1a98a199f832251809c1d",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +1347,1351 @@        (numBucket.toDouble * (value - lower) / (upper - lower)).toLong + 1L\n      }\n    } else { // `min > max` case\n      if (value > upper) {\n        0L"
  },
  {
    "id" : "16a07274-3012-469a-9978-437312403ff7",
    "prId" : 28764,
    "prUrl" : "https://github.com/apache/spark/pull/28764#pullrequestreview-428519003",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b329381c-884a-412d-9974-b9f130f3bc8f",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "missing `;`?",
        "createdAt" : "2020-06-11T00:04:33Z",
        "updatedAt" : "2020-06-11T02:54:14Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "25bd5eb0-377a-43fb-a838-42355d2f9ebb",
        "parentId" : "b329381c-884a-412d-9974-b9f130f3bc8f",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "We don't need `;` here because `defineCodeGen` adds `;`: https://github.com/apache/spark/blob/master/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/Expression.scala#L503\r\nBut, the compiler just skips blank lines with `;` (e.g., `;;`), so adding `;` here will cause no error. Actually, the `Overlay` Impl adds `;`: https://github.com/apache/spark/blob/master/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/stringExpressions.scala#L565",
        "createdAt" : "2020-06-11T00:30:44Z",
        "updatedAt" : "2020-06-11T02:54:14Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "6aeef46a-8c46-4ecd-a5e1-04917df200c0",
        "parentId" : "b329381c-884a-412d-9974-b9f130f3bc8f",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Oh, right, that's correct. Thanks for checking.",
        "createdAt" : "2020-06-11T00:42:21Z",
        "updatedAt" : "2020-06-11T02:54:14Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "9e8eab25eeffba0260d1a98a199f832251809c1d",
    "line" : 97,
    "diffHunk" : "@@ -1,1 +1419,1423 @@    defineCodeGen(ctx, ev, (input, min, max, numBucket) =>\n      \"org.apache.spark.sql.catalyst.expressions.WidthBucket\" +\n        s\".computeBucketNumber($input, $min, $max, $numBucket)\")\n  }\n}"
  },
  {
    "id" : "b96d996a-4cff-4669-81e0-b72a11849220",
    "prId" : 28764,
    "prUrl" : "https://github.com/apache/spark/pull/28764#pullrequestreview-428531715",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "45f5bbc8-9a18-4f7c-8d15-9c9db4336b0e",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "I think `value` also cannot be infinite? Or it could be actually?",
        "createdAt" : "2020-06-11T01:14:16Z",
        "updatedAt" : "2020-06-11T02:54:14Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "c6fc25fe-0e14-4dcc-80e0-78fed852ebd8",
        "parentId" : "45f5bbc8-9a18-4f7c-8d15-9c9db4336b0e",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "At least, Pg can accept the infinity: https://github.com/postgres/postgres/blob/master/src/test/regress/expected/numeric.out#L843-L848\r\nCurrently, this PR follows that behaviour.",
        "createdAt" : "2020-06-11T01:20:38Z",
        "updatedAt" : "2020-06-11T02:54:14Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "009086c9-19b3-4a2b-bd20-5db9f39f202b",
        "parentId" : "45f5bbc8-9a18-4f7c-8d15-9c9db4336b0e",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "It seems Oracle can accept it: http://sqlfiddle.com/#!4/db9c1/2/0",
        "createdAt" : "2020-06-11T01:24:31Z",
        "updatedAt" : "2020-06-11T02:54:14Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "9e8eab25eeffba0260d1a98a199f832251809c1d",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +1332,1336 @@    if (numBucket <= 0 || numBucket == Long.MaxValue || jl.Double.isNaN(value) || min == max ||\n        jl.Double.isNaN(min) || jl.Double.isInfinite(min) ||\n        jl.Double.isNaN(max) || jl.Double.isInfinite(max)) {\n      return null\n    }"
  },
  {
    "id" : "29aa5d00-def2-472a-b240-67d8512761a7",
    "prId" : 28764,
    "prUrl" : "https://github.com/apache/spark/pull/28764#pullrequestreview-428566826",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fe4ba8b9-c7e1-4552-8ad3-fdf7ebffe438",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Is this feature described in the function description?",
        "createdAt" : "2020-06-11T02:03:19Z",
        "updatedAt" : "2020-06-11T02:54:14Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "153feac0-aed4-4624-bd75-deba60b7ae23",
        "parentId" : "fe4ba8b9-c7e1-4552-8ad3-fdf7ebffe438",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "sorry, but what's the feature here?",
        "createdAt" : "2020-06-11T02:56:27Z",
        "updatedAt" : "2020-06-11T02:56:28Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "8ee9c54e-a9a3-40b8-9279-fa9b34438a49",
        "parentId" : "fe4ba8b9-c7e1-4552-8ad3-fdf7ebffe438",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "This comment is resolved via the function description~",
        "createdAt" : "2020-06-11T03:14:29Z",
        "updatedAt" : "2020-06-11T03:14:29Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "3e807386-1b99-4dee-9e63-a870e54ffdee",
        "parentId" : "fe4ba8b9-c7e1-4552-8ad3-fdf7ebffe438",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ah, nice. Thanks!",
        "createdAt" : "2020-06-11T03:23:53Z",
        "updatedAt" : "2020-06-11T03:23:53Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "9e8eab25eeffba0260d1a98a199f832251809c1d",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +1337,1341 @@\n    val lower = Math.min(min, max)\n    val upper = Math.max(min, max)\n\n    if (min < max) {"
  },
  {
    "id" : "6eaecdc1-ff57-4eef-a907-c3e61716a5b5",
    "prId" : 28764,
    "prUrl" : "https://github.com/apache/spark/pull/28764#pullrequestreview-428560188",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "af654c6a-7e91-4c2d-b690-19dfcbdaf1de",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "It would be great if we have a description for the case `min > max` .",
        "createdAt" : "2020-06-11T02:05:42Z",
        "updatedAt" : "2020-06-11T02:54:14Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "bd355d9b-cd30-4960-8306-9826b7422826",
        "parentId" : "af654c6a-7e91-4c2d-b690-19dfcbdaf1de",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Could you cehck the latest commit? Is that okay to you?",
        "createdAt" : "2020-06-11T02:55:09Z",
        "updatedAt" : "2020-06-11T02:55:09Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "050d9d01-c714-4b45-a71b-c3dd7365f501",
        "parentId" : "af654c6a-7e91-4c2d-b690-19dfcbdaf1de",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Thanks! Yes.",
        "createdAt" : "2020-06-11T03:00:29Z",
        "updatedAt" : "2020-06-11T03:00:29Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "9e8eab25eeffba0260d1a98a199f832251809c1d",
    "line" : 53,
    "diffHunk" : "@@ -1,1 +1375,1379 @@ * @param value is the expression to compute a bucket number in the histogram\n * @param minValue is the minimum value of the histogram\n * @param maxValue is the maximum value of the histogram\n * @param numBucket is the number of buckets\n */"
  },
  {
    "id" : "949bb7f7-b020-4fce-836e-258817aafc9f",
    "prId" : 28764,
    "prUrl" : "https://github.com/apache/spark/pull/28764#pullrequestreview-428544513",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b5734ac5-c2aa-46ae-9151-d52eeabfc267",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Thanks for adding this example.",
        "createdAt" : "2020-06-11T02:07:08Z",
        "updatedAt" : "2020-06-11T02:54:14Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "9e8eab25eeffba0260d1a98a199f832251809c1d",
    "line" : 71,
    "diffHunk" : "@@ -1,1 +1393,1397 @@       5\n      > SELECT _FUNC_(-0.9, 5.2, 0.5, 2);\n       3\n  \"\"\",\n  since = \"3.1.0\")"
  },
  {
    "id" : "4c686bc6-fd64-463c-87e7-cf0c99ab395c",
    "prId" : 28764,
    "prUrl" : "https://github.com/apache/spark/pull/28764#pullrequestreview-452087693",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "64c33eb8-8f83-42bb-9391-b5de8476307b",
        "parentId" : null,
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "override def prettyName: String = \"width_bucket\" ?",
        "createdAt" : "2020-07-21T02:43:47Z",
        "updatedAt" : "2020-07-21T02:43:47Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      }
    ],
    "commit" : "9e8eab25eeffba0260d1a98a199f832251809c1d",
    "line" : 84,
    "diffHunk" : "@@ -1,1 +1406,1410 @@  override def inputTypes: Seq[AbstractDataType] = Seq(DoubleType, DoubleType, DoubleType, LongType)\n  override def dataType: DataType = LongType\n  override def nullable: Boolean = true\n\n  override protected def nullSafeEval(input: Any, min: Any, max: Any, numBucket: Any): Any = {"
  }
]