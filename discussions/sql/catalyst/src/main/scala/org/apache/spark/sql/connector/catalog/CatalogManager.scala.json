[
  {
    "id" : "c7063bcc-e2d4-42fd-8b42-4f7cc001851b",
    "prId" : 30385,
    "prUrl" : "https://github.com/apache/spark/pull/30385#pullrequestreview-531087497",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "67f2b2fd-878a-4d6e-85a0-6dc409581e4a",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "https://github.com/apache/spark/blob/234711a328dd4cd888d6a73145984987eabc483b/sql/catalyst/src/main/scala/org/apache/spark/sql/internal/SQLConf.scala#L2071",
        "createdAt" : "2020-11-16T08:34:43Z",
        "updatedAt" : "2020-11-16T08:34:43Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "a0d35b0359e424dd47844129e88caa936043a88c",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +79,83 @@   * session catalog is responsible for an identifier, but the source requires the v2 catalog API.\n   * This happens when the source implementation extends the v2 TableProvider API and is not listed\n   * in the fallback configuration, spark.sql.sources.useV1SourceList\n   */\n  private[sql] def v2SessionCatalog: CatalogPlugin = {"
  },
  {
    "id" : "7c3120c7-5cd9-4e69-b4ac-84b16e39da2b",
    "prId" : 27900,
    "prUrl" : "https://github.com/apache/spark/pull/27900#pullrequestreview-375745992",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d1499e0c-f505-4c43-91d6-bbb76d5bca96",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "It's very likely that the underlying catalog can't report namespace existence directly, but can throw namespace not found error when calling APIs like `loadTable(ident)`",
        "createdAt" : "2020-03-17T04:24:08Z",
        "updatedAt" : "2020-07-02T04:16:51Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "a43e119a-5d4d-4fd1-929e-e3af94e1c2fc",
        "parentId" : "d1499e0c-f505-4c43-91d6-bbb76d5bca96",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "And we should allow users to set current namespace when working with these catalogs.",
        "createdAt" : "2020-03-17T04:24:35Z",
        "updatedAt" : "2020-07-02T04:16:51Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "ebaf03d2-8f53-4138-9f15-657089a73907",
        "parentId" : "d1499e0c-f505-4c43-91d6-bbb76d5bca96",
        "authorId" : "0f4ef4e8-09be-436f-b743-bf8fbc343490",
        "body" : "> It's very likely that the underlying catalog can't report namespace existence directly, but can throw namespace not found error when calling APIs like `loadTable(ident)`\r\n\r\nFirst, the user needs to sense whether the namespace exists.\r\nSecondly, Those who cannot obtain the namespace status can return true directly in namespaceExists.\r\nFinally, for those don't support namespaces, users should be allowed to set the defaultNamespace, I will add this.",
        "createdAt" : "2020-03-17T05:17:53Z",
        "updatedAt" : "2020-07-02T04:16:51Z",
        "lastEditedBy" : "0f4ef4e8-09be-436f-b743-bf8fbc343490",
        "tags" : [
        ]
      }
    ],
    "commit" : "d888906993c1d8616463a53ba2f944e004e8c425",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +114,118 @@        throw new NoSuchNamespaceException(namespace)\n      case catalog: SupportsNamespaces if !catalog.namespaceExists(namespace) =>\n        throw new NoSuchNamespaceException(namespace)\n      case _ =>\n        _currentNamespace = Some(namespace)"
  },
  {
    "id" : "827cc30d-e5dd-4ba8-9f99-3a92a83c42c1",
    "prId" : 26071,
    "prUrl" : "https://github.com/apache/spark/pull/26071#pullrequestreview-301210947",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fd2f7b5d-949c-42b4-a102-8982fe26d0ff",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "As we see, this cause a test case failure. Could you describe a little bit why we change this in this PR since this is not a documentation change (`refine the document of v2 session catalog config`).",
        "createdAt" : "2019-10-12T23:26:02Z",
        "updatedAt" : "2019-10-14T13:42:41Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "102f5a18-08a9-4d4d-9385-f42dcb2b73df",
        "parentId" : "fd2f7b5d-949c-42b4-a102-8982fe26d0ff",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "The config name/document includes the catalog name, so I put them together.\r\n\r\nThe new name was discussed in a DS v2 community meeting. I'm proposing it in this PR to get more visibility.",
        "createdAt" : "2019-10-14T10:08:16Z",
        "updatedAt" : "2019-10-14T13:42:41Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "e973e419c1ab04b75a0a5dddbb538c9355a3336c",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +147,151 @@\nprivate[sql] object CatalogManager {\n  val SESSION_CATALOG_NAME: String = \"spark_catalog\"\n}"
  }
]