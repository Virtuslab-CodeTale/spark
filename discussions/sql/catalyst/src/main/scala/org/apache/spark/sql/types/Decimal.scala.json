[
  {
    "id" : "cc6da715-b115-41f4-a9a7-e80a3e21da8b",
    "prId" : 33011,
    "prUrl" : "https://github.com/apache/spark/pull/33011#pullrequestreview-690920806",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8a3d0bef-99fa-4c62-a68c-b513c8dfe863",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "does it only count the number of digits before the dot?",
        "createdAt" : "2021-06-22T14:05:49Z",
        "updatedAt" : "2021-06-22T14:05:49Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "df856a34-870e-421a-83b3-6e01b8b43c03",
        "parentId" : "8a3d0bef-99fa-4c62-a68c-b513c8dfe863",
        "authorId" : "87a71d79-d4d2-4f2c-8e9a-be56cf39b035",
        "body" : "yes, as precision is the total number of digits (number of digit of a) and scale is the exponent (x) in 0.a * e ^x",
        "createdAt" : "2021-06-22T17:57:34Z",
        "updatedAt" : "2021-06-22T17:57:34Z",
        "lastEditedBy" : "87a71d79-d4d2-4f2c-8e9a-be56cf39b035",
        "tags" : [
        ]
      },
      {
        "id" : "a4428df9-5f87-4cb3-8d6e-e17262895673",
        "parentId" : "8a3d0bef-99fa-4c62-a68c-b513c8dfe863",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "then how about we rename it to `numDigitsInIntegralPart`?",
        "createdAt" : "2021-06-22T18:32:49Z",
        "updatedAt" : "2021-06-22T18:33:04Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "947c4e15-cba7-4143-96f5-2a4468463f68",
        "parentId" : "8a3d0bef-99fa-4c62-a68c-b513c8dfe863",
        "authorId" : "87a71d79-d4d2-4f2c-8e9a-be56cf39b035",
        "body" : "okay",
        "createdAt" : "2021-06-23T16:57:21Z",
        "updatedAt" : "2021-06-23T16:57:21Z",
        "lastEditedBy" : "87a71d79-d4d2-4f2c-8e9a-be56cf39b035",
        "tags" : [
        ]
      }
    ],
    "commit" : "7407838ab778030c7e1171a921ab4f59a93cc709",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +589,593 @@\n  private def numDigitsInIntegralPart(bigDecimal: JavaBigDecimal): Int = {\n      bigDecimal.precision - bigDecimal.scale\n  }\n"
  },
  {
    "id" : "8a60cf05-ad5c-4260-8b0d-3ed8f664e499",
    "prId" : 27524,
    "prUrl" : "https://github.com/apache/spark/pull/27524#pullrequestreview-356455733",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "53ada132-d481-4f64-9454-2a8a0652029a",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "`POW_10` is needed in the wrapper of `FastDateFormat` to support parsing/formatting in microsecond precision. Similar changes were made in Spark 2.4.",
        "createdAt" : "2020-02-11T07:38:37Z",
        "updatedAt" : "2020-02-11T09:52:10Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "93f3ae1c32f893cc3cc22ae075753098440e76b5",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +542,546 @@  val MAX_LONG_DIGITS = 18\n\n  val POW_10 = Array.tabulate[Long](MAX_LONG_DIGITS + 1)(i => math.pow(10, i).toLong)\n\n  private val BIG_DEC_ZERO = BigDecimal(0)"
  },
  {
    "id" : "60adff97-aeb2-4592-ab5e-914bf3f0c9e4",
    "prId" : 26881,
    "prUrl" : "https://github.com/apache/spark/pull/26881#pullrequestreview-341635737",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "eef1c3f8-fbb5-402f-bfa1-1df254cf6ddb",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Do you mean allowing negative scale here?",
        "createdAt" : "2020-01-11T01:01:01Z",
        "updatedAt" : "2020-01-17T14:23:59Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "9f5c9597-fb31-4328-90b9-92554bb096b9",
        "parentId" : "eef1c3f8-fbb5-402f-bfa1-1df254cf6ddb",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Yeah. But the negative scale is not from end-user, but from java BigDecimal(e.g. `1E10` will has precision=2 and scale=-9 using java BigDecimal).",
        "createdAt" : "2020-01-13T03:44:19Z",
        "updatedAt" : "2020-01-17T14:23:59Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "c6b51da1-8718-4f72-98b0-f48458a3e568",
        "parentId" : "eef1c3f8-fbb5-402f-bfa1-1df254cf6ddb",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Oh I see. Thanks.",
        "createdAt" : "2020-01-13T04:27:10Z",
        "updatedAt" : "2020-01-17T14:23:59Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "563853b4d7b9a460c44b3a3de6552335d59fb3c0",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +143,147 @@    } else if (decimal.scale < 0 && !SQLConf.get.allowNegativeScaleOfDecimalEnabled) {\n      this._precision = decimal.precision - decimal.scale\n      this._scale = 0\n      // set scale to 0 to correct unscaled value\n      this.decimalVal = decimal.setScale(0)"
  },
  {
    "id" : "3db8a88e-5206-4225-a943-e88c0331246a",
    "prId" : 26881,
    "prUrl" : "https://github.com/apache/spark/pull/26881#pullrequestreview-343002798",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8c00238c-3dda-4879-9388-b8c92b66b191",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "No chance that this `_precision` goes over the max precision?",
        "createdAt" : "2020-01-14T00:16:15Z",
        "updatedAt" : "2020-01-17T14:23:59Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "3aeaf9f8-95cd-4118-ad9b-6c8697cacd8d",
        "parentId" : "8c00238c-3dda-4879-9388-b8c92b66b191",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "It's possible. But we have `DecimalType` aside to do the check and fail if we goes over the max precision.",
        "createdAt" : "2020-01-14T01:11:23Z",
        "updatedAt" : "2020-01-17T14:23:59Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "34fdb129-8bea-4ad0-ada0-0e4d09201ded",
        "parentId" : "8c00238c-3dda-4879-9388-b8c92b66b191",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Yea, but I personally think it'd be better to check the max precision in the setter of a `Decimal` side, too, for safeguards. It seems the other setter has the check: https://github.com/apache/spark/blob/1846b0261b84ce1bca079bc59fb4518bff910c18/sql/catalyst/src/main/scala/org/apache/spark/sql/types/Decimal.scala#L117.",
        "createdAt" : "2020-01-14T04:00:36Z",
        "updatedAt" : "2020-01-17T14:23:59Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "04388c28-1852-486f-8f38-7bc68a50145a",
        "parentId" : "8c00238c-3dda-4879-9388-b8c92b66b191",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "if we add check for this, do we also have to add check for https://github.com/apache/spark/blob/1846b0261b84ce1bca079bc59fb4518bff910c18/sql/catalyst/src/main/scala/org/apache/spark/sql/types/Decimal.scala#L138 ?",
        "createdAt" : "2020-01-14T09:35:07Z",
        "updatedAt" : "2020-01-17T14:23:59Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "a637c60b-de0f-43c7-a0e5-5bb66f803574",
        "parentId" : "8c00238c-3dda-4879-9388-b8c92b66b191",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "+1",
        "createdAt" : "2020-01-14T09:36:49Z",
        "updatedAt" : "2020-01-17T14:23:59Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "590699b3-de01-4a67-9b70-7a8401e2373c",
        "parentId" : "8c00238c-3dda-4879-9388-b8c92b66b191",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "yea, I think so.",
        "createdAt" : "2020-01-15T06:04:11Z",
        "updatedAt" : "2020-01-17T14:23:59Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "563853b4d7b9a460c44b3a3de6552335d59fb3c0",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +142,146 @@      this._scale = decimal.scale\n    } else if (decimal.scale < 0 && !SQLConf.get.allowNegativeScaleOfDecimalEnabled) {\n      this._precision = decimal.precision - decimal.scale\n      this._scale = 0\n      // set scale to 0 to correct unscaled value"
  },
  {
    "id" : "be932720-17a4-48b6-8673-1fead455ddd4",
    "prId" : 26769,
    "prUrl" : "https://github.com/apache/spark/pull/26769#pullrequestreview-327903039",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6437887d-3a92-4ba4-9fc5-e6c91efc7676",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Shall we make this as an IDed TODO?",
        "createdAt" : "2019-12-05T22:22:31Z",
        "updatedAt" : "2019-12-06T15:12:47Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "60b97b0e-d3c4-4520-8b46-7ba10f8728f3",
        "parentId" : "6437887d-3a92-4ba4-9fc5-e6c91efc7676",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Do you mean it shouldn't be a TODO, or should be recorded differently? I just want to leave something in place so when one day I search for \"Scala 2.12\" because we're cutting out the 2.12-specific stuff, I find this one :)",
        "createdAt" : "2019-12-05T22:25:58Z",
        "updatedAt" : "2019-12-06T15:12:47Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "81811ec4-8d02-4e48-9edb-9bbcb37cd492",
        "parentId" : "6437887d-3a92-4ba4-9fc5-e6c91efc7676",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Oh, what I meant is to have the official JIRA ID and make this `TODO(SPARK-XXX)` style. It'll give more visibility to the community and contributors can easily find both here and Apache Spark JIRA.",
        "createdAt" : "2019-12-05T22:45:38Z",
        "updatedAt" : "2019-12-06T15:12:47Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "a4996b64d07b08d4a0b3a8cf405615e486757b53",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +625,629 @@    override def compare(x: Decimal, y: Decimal): Int = x.compare(y)\n    // Added from Scala 2.13; don't override to work in 2.12\n    // TODO revisit once Scala 2.12 support is dropped\n    def parseString(str: String): Option[Decimal] = Try(Decimal(str)).toOption\n  }"
  }
]