[
  {
    "id" : "847108f5-d779-4a63-b1e0-5f9da9e66342",
    "prId" : 32448,
    "prUrl" : "https://github.com/apache/spark/pull/32448#pullrequestreview-656000760",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2b8aae0d-ceaf-4e48-8fe8-fb7f8e3772a9",
        "parentId" : null,
        "authorId" : "92aa9573-b64a-4a86-aebf-54c827df3ed0",
        "body" : "Don't know enough about this code to know if this could cause any issues",
        "createdAt" : "2021-05-06T01:34:38Z",
        "updatedAt" : "2021-05-06T01:34:38Z",
        "lastEditedBy" : "92aa9573-b64a-4a86-aebf-54c827df3ed0",
        "tags" : [
        ]
      },
      {
        "id" : "acd3b394-e7db-4149-aae3-7353b2714131",
        "parentId" : "2b8aae0d-ceaf-4e48-8fe8-fb7f8e3772a9",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "This merges some required fields at root level as a single `StructType`. Looks okay.",
        "createdAt" : "2021-05-10T19:14:16Z",
        "updatedAt" : "2021-05-10T19:14:16Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "5762ddc83e96b640ffdd4125c182646bf9fb03ff",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +39,43 @@    val mergedSchema = requestedRootFields\n      .map { root: RootField => StructType(Array(root.field)) }\n      .reduceLeft((left, right) => left.merge(right, resolver))\n    val mergedDataSchema =\n      StructType(dataSchema.map(d => mergedSchema.find(m => resolver(m.name, d.name)).getOrElse(d)))"
  },
  {
    "id" : "8ddbd45d-6126-4501-9d43-c82021fa0c72",
    "prId" : 32354,
    "prUrl" : "https://github.com/apache/spark/pull/32354#pullrequestreview-649704592",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "eab22d40-48b2-4018-baa6-8fc964697b39",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Can we add a unit test in `SchemaPruningSuite`? We can make `getRootFields` as `private[spark]` to test it.",
        "createdAt" : "2021-04-30T21:19:28Z",
        "updatedAt" : "2021-05-04T18:00:49Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "1d644431-7cce-41a2-b9fe-61ac02524e1f",
        "parentId" : "eab22d40-48b2-4018-baa6-8fc964697b39",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "Good point. Let me add a test.",
        "createdAt" : "2021-05-01T01:42:12Z",
        "updatedAt" : "2021-05-04T18:00:49Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      }
    ],
    "commit" : "a67dde0b2ddea64bf1eb5bb67e0b1cd938146ee6",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +129,133 @@    expr match {\n      case att: Attribute =>\n        RootField(StructField(att.name, att.dataType, att.nullable, att.metadata),\n          derivedFromAtt = true) :: Nil\n      case SelectedField(field) => RootField(field, derivedFromAtt = false) :: Nil"
  },
  {
    "id" : "2d71d00c-1096-4e1b-b457-71f761230c68",
    "prId" : 31993,
    "prUrl" : "https://github.com/apache/spark/pull/31993#pullrequestreview-637306577",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5950e28a-be51-443d-a3b0-290692db025b",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Hmm, doesn't it mean we miss the change to prune top-level columns?",
        "createdAt" : "2021-04-16T01:02:15Z",
        "updatedAt" : "2021-04-21T09:55:49Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "704c1336-05e6-49ac-a3fc-ea5904247327",
        "parentId" : "5950e28a-be51-443d-a3b0-290692db025b",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "No. Top-level columns pruned by:\r\nhttps://github.com/apache/spark/blob/7a5647a93aaea9d1d78d9262e24fc8c010db04d0/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/FileSourceStrategy.scala#L208-L213",
        "createdAt" : "2021-04-16T02:35:07Z",
        "updatedAt" : "2021-04-21T09:55:49Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      },
      {
        "id" : "6922fc05-3896-4454-b3b1-3b3ac4f3630b",
        "parentId" : "5950e28a-be51-443d-a3b0-290692db025b",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "I think v2 column pruning should be handled by `V2ScanRelationPushDown`.",
        "createdAt" : "2021-04-16T03:23:27Z",
        "updatedAt" : "2021-04-21T09:55:49Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "c348a542-e669-4ccf-9857-948584b8e665",
        "parentId" : "5950e28a-be51-443d-a3b0-290692db025b",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "Yes, I have updated the v2 part:\r\nhttps://github.com/apache/spark/blob/a966bac379ff6fed20c57cf3c748cada9da28b4c/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/v2/PushDownUtils.scala#L79-L110",
        "createdAt" : "2021-04-16T03:40:43Z",
        "updatedAt" : "2021-04-21T09:55:49Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      }
    ],
    "commit" : "4d0b510e10da4fe1fca07583ddecc5f5fe6d6392",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +28,32 @@   * Note that:\n   *   1. The schema field ordering at original schema is still preserved in pruned schema.\n   *   2. The top-level fields are not pruned here.\n   */\n  def pruneDataSchema("
  }
]