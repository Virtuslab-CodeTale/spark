[
  {
    "id" : "fd96bdec-d02a-410f-9f3b-045a3e913a24",
    "prId" : 30543,
    "prUrl" : "https://github.com/apache/spark/pull/30543#pullrequestreview-547821433",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "faec70af-bc41-4167-a7a1-b29ebace8f52",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "hm, since RLIKE/LIKE syntaxes are already documented in [the SQL doc](https://spark.apache.org/docs/latest/sql-ref-syntax-qry-select-like.html) , how about updating the usage (`str _FUNC_ regexp` -> `_FUNC_(str, regext)`), too? ",
        "createdAt" : "2020-12-07T13:31:34Z",
        "updatedAt" : "2020-12-17T03:29:11Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "52fc4d80-e4d8-4441-b31f-0611ae755345",
        "parentId" : "faec70af-bc41-4167-a7a1-b29ebace8f52",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "`[ NOT ] { LIKE search_pattern [ ESCAPE esc_char ] | [ RLIKE | REGEXP ] regex_pattern }` is a syntax, but `_FUNC_(str, regext)` is a function call.",
        "createdAt" : "2020-12-08T02:12:47Z",
        "updatedAt" : "2020-12-17T03:29:11Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      },
      {
        "id" : "ee122e9d-290a-4785-85d7-0b329823f850",
        "parentId" : "faec70af-bc41-4167-a7a1-b29ebace8f52",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "What do you mean? I meant the current generated doc is incorrect (`str regexp_like regex` in the usage);\r\n\r\n<img width=\"500\" alt=\"Screen Shot 2020-12-08 at 22 14 34\" src=\"https://user-images.githubusercontent.com/692303/101488973-9e1bb300-39a3-11eb-92bc-9d0f654afae4.png\">\r\n\r\n```\r\nscala> sql(\"select 'aaa' regexp_like 'aaa'\").show()\r\norg.apache.spark.sql.catalyst.parser.ParseException:\r\nextraneous input ''aaa'' expecting {<EOF>, ';'}(line 1, pos 25)\r\n\r\n== SQL ==\r\nselect 'aaa' regexp_like 'aaa'\r\n-------------------------^^^\r\n```",
        "createdAt" : "2020-12-08T13:24:22Z",
        "updatedAt" : "2020-12-17T03:29:11Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "8184114e-ff3a-49ed-b5c8-44f13ca5a7f9",
        "parentId" : "faec70af-bc41-4167-a7a1-b29ebace8f52",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "And, the column name below looks weird;\r\n```\r\nscala> sql(\"select regexp_like('aaa', 'aaa')\").show()\r\n+-------------------+                                                           \r\n|aaa REGEXP_LIKE aaa| --> should be REGEXP_LIKE(aaa, aaa)?\r\n+-------------------+\r\n|               true|\r\n+-------------------+\r\n```",
        "createdAt" : "2020-12-08T13:25:44Z",
        "updatedAt" : "2020-12-17T03:29:11Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "0f10a51b-0789-47fc-8aea-720d9ed801b6",
        "parentId" : "faec70af-bc41-4167-a7a1-b29ebace8f52",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "I understand your mean now.",
        "createdAt" : "2020-12-09T04:11:05Z",
        "updatedAt" : "2020-12-17T03:29:11Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "e1cd719a0996c7bc3d74f7002393bad44000e4be",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +349,353 @@      > SET spark.sql.parser.escapedStringLiterals=true;\n      spark.sql.parser.escapedStringLiterals\ttrue\n      > SELECT _FUNC_('%SystemDrive%\\Users\\John', '%SystemDrive%\\\\Users.*');\n      true\n      > SET spark.sql.parser.escapedStringLiterals=false;"
  },
  {
    "id" : "044f8455-69b5-426d-b3a7-5e8bba0c39f3",
    "prId" : 29999,
    "prUrl" : "https://github.com/apache/spark/pull/29999#pullrequestreview-527919095",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "435cec39-deee-40ca-ba47-a976db886018",
        "parentId" : null,
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "`null` -> `false`?",
        "createdAt" : "2020-11-11T04:39:48Z",
        "updatedAt" : "2020-11-19T06:48:14Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      },
      {
        "id" : "d567089c-90e1-4b29-8952-739b03b1b49f",
        "parentId" : "435cec39-deee-40ca-ba47-a976db886018",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "```sql\r\nspark-sql> select 'a' like all ('%a%', null);\r\nNULL\r\nspark-sql> select 'a' not like all ('%a%', null);\r\nfalse\r\nspark-sql> select 'a' like any ('%a%', null);\r\ntrue\r\nspark-sql> select 'a' not like any ('%a%', null);\r\nNULL\r\n```",
        "createdAt" : "2020-11-11T06:17:06Z",
        "updatedAt" : "2020-11-19T06:48:14Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      },
      {
        "id" : "87200d1d-b954-4567-8340-9c370919663e",
        "parentId" : "435cec39-deee-40ca-ba47-a976db886018",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "Thanks!",
        "createdAt" : "2020-11-11T07:22:19Z",
        "updatedAt" : "2020-11-19T06:48:14Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "001eb38f603267c6a6f4e1c25430b8900644f5b7",
    "line" : 46,
    "diffHunk" : "@@ -1,1 +210,214 @@    val exprValue = child.eval(input)\n    if (exprValue == null) {\n      null\n    } else {\n      if (cache.forall(matchFunc(_, exprValue.toString))) {"
  },
  {
    "id" : "c62ff332-0d8b-4e58-92cb-5fd28626646c",
    "prId" : 29999,
    "prUrl" : "https://github.com/apache/spark/pull/29999#pullrequestreview-534109856",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "eddcf387-c3e2-43ff-a4f6-3a91bdc3fbe6",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "we can exit the loop if `allMatched` is false.",
        "createdAt" : "2020-11-19T05:58:50Z",
        "updatedAt" : "2020-11-19T06:48:14Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "b8c1b268-ed5d-4427-b24d-b28cd5c90aac",
        "parentId" : "eddcf387-c3e2-43ff-a4f6-3a91bdc3fbe6",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "Yeah! Thanks!",
        "createdAt" : "2020-11-19T06:17:45Z",
        "updatedAt" : "2020-11-19T06:48:14Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "001eb38f603267c6a6f4e1c25430b8900644f5b7",
    "line" : 79,
    "diffHunk" : "@@ -1,1 +243,247 @@            |} else {\n            |  $javaDataType $valueArg = ${eval.value};\n            |  for ($patternClass $pattern: $patternCache) {\n            |    if ($checkNotMatchCode) {\n            |      ${ev.value} = false;"
  },
  {
    "id" : "5774cbd1-8b9c-41a4-b7ed-3a37588dbe25",
    "prId" : 29891,
    "prUrl" : "https://github.com/apache/spark/pull/29891#pullrequestreview-507047006",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1bc1ed13-ccc2-456f-b870-6254a0d279fe",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "We need this restriction?",
        "createdAt" : "2020-10-13T00:59:05Z",
        "updatedAt" : "2020-10-16T09:33:03Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "952f596e-aded-4a61-9179-62e95f58f172",
        "parentId" : "1bc1ed13-ccc2-456f-b870-6254a0d279fe",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "Yes. Because all the database tell us pos must be positive",
        "createdAt" : "2020-10-13T03:38:19Z",
        "updatedAt" : "2020-10-16T09:33:03Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "5ea2cbbfd7c4ab743bab2d52be9f2ddb03e64d56",
    "line" : 48,
    "diffHunk" : "@@ -1,1 +353,357 @@\n  override def checkInputDataTypes(): TypeCheckResult = {\n    if (!pos.foldable) {\n      return TypeCheckFailure(s\"Position expression must be foldable, but got $pos\")\n    }"
  },
  {
    "id" : "aa126b94-ba0e-4e57-a1f9-19be68644232",
    "prId" : 27531,
    "prUrl" : "https://github.com/apache/spark/pull/27531#pullrequestreview-356880946",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f125da13-ea4d-4f23-9556-c1dcc4040d5a",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Note for me: This part is a logical reverting.",
        "createdAt" : "2020-02-11T18:12:59Z",
        "updatedAt" : "2020-02-11T18:13:11Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "ff569c44fe089becf5054f1fa4e07243ae4173ca",
    "line" : 157,
    "diffHunk" : "@@ -1,1 +173,177 @@          $patternClass $pattern = $patternClass.compile(\n            $escapeFunc($rightStr, '$newEscapeChar'));\n          ${ev.value} = $pattern.matcher($eval1.toString()).matches();\n        \"\"\"\n      })"
  },
  {
    "id" : "1d6d77bc-73e0-4876-a62a-9b4a2bf0452d",
    "prId" : 27502,
    "prUrl" : "https://github.com/apache/spark/pull/27502#pullrequestreview-355631956",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cb42384a-50c0-4814-8d33-9d8236f32530",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "This will consider `'a' + 'b'` from now. I prefer to consider SPARK-30759 as a performance improvement and merge to `master` only.",
        "createdAt" : "2020-02-08T23:32:35Z",
        "updatedAt" : "2020-02-10T07:46:52Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "66a894e5-fd76-43e3-bc3e-e24681e09b26",
        "parentId" : "cb42384a-50c0-4814-8d33-9d8236f32530",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "The changes don't impact on behavior in any case, so, they can be considered only as an optimization. ",
        "createdAt" : "2020-02-09T20:39:44Z",
        "updatedAt" : "2020-02-10T07:46:52Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "7bc5d9e4bb2a35add0e4f6dc2c4571b9c02a9319",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +44,48 @@  // try cache foldable pattern\n  private lazy val cache: Pattern = pattern match {\n    case p: Expression if p.foldable =>\n      compile(p.eval().asInstanceOf[UTF8String].toString)\n    case _ => null"
  },
  {
    "id" : "54d42561-b8a9-4dba-bd7c-2efde90f7f73",
    "prId" : 27497,
    "prUrl" : "https://github.com/apache/spark/pull/27497#pullrequestreview-355575357",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a5b5c1c1-371e-4959-8b40-077af50fad58",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "You can keep `lastPattern` as `Pattern`, and compare it to the current pattern via `lastPattern.pattern() == patternStr`. No need to keep `lastPattern` as a string.",
        "createdAt" : "2020-02-08T18:11:12Z",
        "updatedAt" : "2020-02-08T18:21:10Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "4fc3e6b7-efb2-48a2-af1e-d55cfc3ecd0a",
        "parentId" : "a5b5c1c1-371e-4959-8b40-077af50fad58",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "Thanks for your review.\r\nOf courseï¼ŒI can do like this. I just followed the way of `RegExpExtract` and `RegExpReplace` here.",
        "createdAt" : "2020-02-08T23:59:00Z",
        "updatedAt" : "2020-02-09T00:00:00Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "6a8fda8f814da4e6f9788e6eaff2e4d34edbe161",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +55,59 @@  }\n\n  var lastPatternStr: String = null\n  var compiledPattern: Pattern = null\n"
  },
  {
    "id" : "c3bddbd4-bffc-4993-9b1f-8776104a4be8",
    "prId" : 27497,
    "prUrl" : "https://github.com/apache/spark/pull/27497#pullrequestreview-355567729",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b320cf85-7648-4b69-be77-d94c95958de6",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Are there any reasons to not use `patternStr != lastPatternStr`?",
        "createdAt" : "2020-02-08T18:20:50Z",
        "updatedAt" : "2020-02-08T18:21:10Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "50a2fbec-da76-49cd-8aab-ac96576faba3",
        "parentId" : "b320cf85-7648-4b69-be77-d94c95958de6",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "oh, I see this is a copy-paste from Java codegen",
        "createdAt" : "2020-02-08T20:37:27Z",
        "updatedAt" : "2020-02-08T20:37:28Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "6a8fda8f814da4e6f9788e6eaff2e4d34edbe161",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +61,65 @@    val patternStr = input2.asInstanceOf[UTF8String].toString\n    val regex = if (cache == null) {\n      if (!(patternStr).equals(lastPatternStr)) {\n        compiledPattern = compile(patternStr)\n        lastPatternStr = patternStr"
  },
  {
    "id" : "e6cb8a45-d7da-43c4-b9eb-004090db2742",
    "prId" : 27355,
    "prUrl" : "https://github.com/apache/spark/pull/27355#pullrequestreview-348642700",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1973b61b-a8bd-45de-8edf-c00a437b6557",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "We need `lazy` here? I personally think its better to check error conditions as soon as possible.",
        "createdAt" : "2020-01-26T12:01:59Z",
        "updatedAt" : "2020-01-26T16:58:01Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "e8942105-dfe0-4970-b8be-15eef22d93eb",
        "parentId" : "1973b61b-a8bd-45de-8edf-c00a437b6557",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "When I remove `lazy`, I get the exception:\r\n```\r\nmakeCopy, tree: str#13580 LIKE pattern#13581 ESCAPE '@'\r\norg.apache.spark.sql.catalyst.errors.package$TreeNodeException: makeCopy, tree: str#13580 LIKE pattern#13581 ESCAPE '@'\r\n\tat org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:56)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.makeCopy(TreeNode.scala:435)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:408)\r\n...\r\nCaused by: org.apache.spark.sql.AnalysisException: The 'escape' parameter must be a string literal.;\r\n\tat org.apache.spark.sql.catalyst.expressions.Like.<init>(regexpExpressions.scala:135)\r\n```\r\nSee `escape` is `PrettyAttribute`:\r\n<img width=\"721\" alt=\"Screen Shot 2020-01-26 at 19 51 34\" src=\"https://user-images.githubusercontent.com/1580697/73138597-8716ef80-4075-11ea-9cb5-b92baef6d4c5.png\">\r\n",
        "createdAt" : "2020-01-26T16:53:52Z",
        "updatedAt" : "2020-01-26T16:58:01Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "1240fd9f-1d3a-457f-bdc0-c133f458774d",
        "parentId" : "1973b61b-a8bd-45de-8edf-c00a437b6557",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "I got the error when I run new test in `DataFrameFunctionsSuite`, and I remember I got the error on other tests as well.  PrettyAttribute is not foldable.",
        "createdAt" : "2020-01-26T17:09:23Z",
        "updatedAt" : "2020-01-26T17:10:04Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "6dac0ed8-a176-4a26-8a88-73419a11a20d",
        "parentId" : "1973b61b-a8bd-45de-8edf-c00a437b6557",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ur, ok. Thanks for the check. The current one looks ok to me.",
        "createdAt" : "2020-01-27T12:59:11Z",
        "updatedAt" : "2020-01-27T12:59:11Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "39e4bd264b26c7840d7f1815b926c28837a50889",
    "line" : 79,
    "diffHunk" : "@@ -1,1 +126,130 @@  override def children: Seq[Expression] = Seq(str, pattern, escape)\n\n  private lazy val escapeChar: Char = if (escape.foldable) {\n    escape.eval() match {\n      case s: UTF8String if s != null && s.numChars() == 1 => s.toString.charAt(0)"
  },
  {
    "id" : "c668ea86-ba83-4868-ad15-66927823e929",
    "prId" : 27355,
    "prUrl" : "https://github.com/apache/spark/pull/27355#pullrequestreview-348392267",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1317dc67-fb1c-4a2d-8205-a83ef638eb49",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Can you add tests for this path and line 131 (error cases)?",
        "createdAt" : "2020-01-26T12:02:47Z",
        "updatedAt" : "2020-01-26T16:58:01Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "a1fbdc2b-689e-4ec0-979a-08973babb478",
        "parentId" : "1317dc67-fb1c-4a2d-8205-a83ef638eb49",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Added",
        "createdAt" : "2020-01-26T16:58:19Z",
        "updatedAt" : "2020-01-26T16:58:20Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "39e4bd264b26c7840d7f1815b926c28837a50889",
    "line" : 86,
    "diffHunk" : "@@ -1,1 +133,137 @@    }\n  } else {\n    throw new AnalysisException(\"The 'escape' parameter must be a string literal.\")\n  }\n"
  },
  {
    "id" : "b536223f-3746-4857-a12e-ea5686ae0bc6",
    "prId" : 27355,
    "prUrl" : "https://github.com/apache/spark/pull/27355#pullrequestreview-356405689",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9fb5c884-5965-4f8c-93b3-6572e914724e",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This kind of thing should be done in `checkInputDataTypes`.",
        "createdAt" : "2020-02-11T03:46:56Z",
        "updatedAt" : "2020-02-11T03:46:56Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "39e4bd264b26c7840d7f1815b926c28837a50889",
    "line" : 86,
    "diffHunk" : "@@ -1,1 +133,137 @@    }\n  } else {\n    throw new AnalysisException(\"The 'escape' parameter must be a string literal.\")\n  }\n"
  },
  {
    "id" : "4c238554-3e8c-4a2a-84fd-f112ac5e43ff",
    "prId" : 27323,
    "prUrl" : "https://github.com/apache/spark/pull/27323#pullrequestreview-346975678",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b2feded1-a90a-4703-847b-35ff25e399dd",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Thank you for adding this test coverage. I noticed that the other test cases are handled by different parser code path.",
        "createdAt" : "2020-01-22T23:28:28Z",
        "updatedAt" : "2020-01-22T23:30:30Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "6d935edd4ac90ad431a52008f2e34c644b27d3d2",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +96,100 @@  examples = \"\"\"\n    Examples:\n      > SELECT _FUNC_('Spark', '_park');\n      true\n      > SET spark.sql.parser.escapedStringLiterals=true;"
  },
  {
    "id" : "d1154e6d-6b81-4a6e-9e26-10311751f01c",
    "prId" : 26875,
    "prUrl" : "https://github.com/apache/spark/pull/26875#pullrequestreview-434491517",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c8c0ecb8-b685-498d-ba0c-1983ecb6f402",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "The positive cases are good enough. The concern I heard was actually here we add some overhead for string comparison, and it could be worse when the strings are very long.\r\n\r\nCan we identify the worst cases? It's okay to show the trade-off explicitly. I tend to agree with compiling the pattern once is better in general. Feel free to reopen the PR once we're clear on the trade-off.\r\n\r\ncc @rednaxelafx as well FYI.",
        "createdAt" : "2020-06-21T11:05:15Z",
        "updatedAt" : "2020-06-21T11:07:28Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "d6650e1c71b86f7076da53df292fa1c59044663b",
    "line" : 40,
    "diffHunk" : "@@ -1,1 +252,256 @@        s\"\"\"\n          String $rightStr = $eval2.toString();\n          if (!$rightStr.equals($lastRightStr)) {\n            $pattern = $patternClass.compile($rightStr);\n            $lastRightStr = $rightStr;"
  }
]