[
  {
    "id" : "3e66b2bd-4ac8-4fa9-a7b4-919582bd09b2",
    "prId" : 32825,
    "prUrl" : "https://github.com/apache/spark/pull/32825#pullrequestreview-679483831",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dd693258-9cb2-411d-b9af-b98edb408aac",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "`IllegalArgumentException`?",
        "createdAt" : "2021-06-09T09:39:46Z",
        "updatedAt" : "2021-06-09T09:39:46Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "3b28a6b4-8b5e-4141-af66-b40ce91107fa",
        "parentId" : "dd693258-9cb2-411d-b9af-b98edb408aac",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Since it's user-facing, can we put it in `QueryCompilationError`?",
        "createdAt" : "2021-06-09T09:40:08Z",
        "updatedAt" : "2021-06-09T09:40:08Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "5a16676b-edf5-463d-85f9-464d86bb61ab",
        "parentId" : "dd693258-9cb2-411d-b9af-b98edb408aac",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "I followed the existing approach:\r\nhttps://github.com/apache/spark/blob/0494dc90af48ce7da0625485a4dc6917a244d580/sql/catalyst/src/main/scala/org/apache/spark/sql/types/DecimalType.scala#L47-L55",
        "createdAt" : "2021-06-09T10:32:47Z",
        "updatedAt" : "2021-06-09T10:32:47Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "ef97d29888c5b42a47b530e56b1bfe6ec235e158",
    "line" : 41,
    "diffHunk" : "@@ -1,1 +70,74 @@    case (YEAR, YEAR) => \"interval year\"\n    case (MONTH, MONTH) => \"interval month\"\n    case _ => throw new AnalysisException(\n      s\"\"\"Invalid interval units: ($start, $end). Supported units:\n         | (0, 0) - interval year"
  },
  {
    "id" : "4557e37f-03a2-4b58-ac13-2684a2879a25",
    "prId" : 32825,
    "prUrl" : "https://github.com/apache/spark/pull/32825#pullrequestreview-679680628",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0dc3a103-bca4-4f43-89b4-38e7cf307bb1",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Shall we follow `DecinalType` and extends `AbstractDataType`? This is useful when a function accepts all kinds of year month intervals.",
        "createdAt" : "2021-06-09T09:41:28Z",
        "updatedAt" : "2021-06-09T09:41:28Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "e3fa7d81-4dc8-4256-9c20-4888afca5a05",
        "parentId" : "0dc3a103-bca4-4f43-89b4-38e7cf307bb1",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "I didn't understand this. Could you explain me, please. For now, the code works:\r\n```scala\r\n  test(\"aaa\") {\r\n    def f(y: YearMonthIntervalType): Int = {\r\n      y.defaultSize\r\n    }\r\n    f(YearMonthIntervalType(0, 1))\r\n  }\r\n```\r\n@cloud-fan or mean a different use case?",
        "createdAt" : "2021-06-09T10:30:29Z",
        "updatedAt" : "2021-06-09T10:30:29Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "af94a4dd-cf40-45ad-a15b-e033049d150b",
        "parentId" : "0dc3a103-bca4-4f43-89b4-38e7cf307bb1",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I mean `ExpectsInputTypes.inputTypes`. The \"function\" I mentioned is SQL function (expression).",
        "createdAt" : "2021-06-09T13:50:20Z",
        "updatedAt" : "2021-06-09T13:50:20Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "ef97d29888c5b42a47b530e56b1bfe6ec235e158",
    "line" : 61,
    "diffHunk" : "@@ -1,1 +85,89 @@ */\n@Unstable\nobject YearMonthIntervalType {\n  val YEAR: Byte = 0\n  val MONTH: Byte = 1"
  },
  {
    "id" : "865ea1ff-58cf-441c-91e5-5f7a27c4fc7e",
    "prId" : 31810,
    "prUrl" : "https://github.com/apache/spark/pull/31810#pullrequestreview-609975754",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8a0607fb-c973-4052-95c9-6ec4d47772f9",
        "parentId" : null,
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "according to the standard，year-month and day-time is italic，so I guess interval here is unnecessary. ",
        "createdAt" : "2021-03-11T16:21:50Z",
        "updatedAt" : "2021-03-11T16:21:50Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "4c45fadf-a2d2-4b2f-b808-1a78a5f4c79b",
        "parentId" : "8a0607fb-c973-4052-95c9-6ec4d47772f9",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "1. I haven't found any places in the SQL standard where `year-month` and `day-time` are used without the `interval(s)` word(s).\r\n2. Actual type name is `INTERVAL`, `year-month` and `day-time` just define (sub-)classes of the type.\r\n3. Since the `typeName()` method is used in error messages, I do believe we should leave `interval` in type names for readability. ",
        "createdAt" : "2021-03-11T16:42:50Z",
        "updatedAt" : "2021-03-11T16:42:50Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "9755022cc907641e9435b815c11d15f14e2d1857",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +56,60 @@  private[spark] override def asNullable: YearMonthIntervalType = this\n\n  override def typeName: String = \"year-month interval\"\n}\n"
  }
]