[
  {
    "id" : "95a1389e-8dc4-4b6e-b526-9ed7107bbf00",
    "prId" : 33284,
    "prUrl" : "https://github.com/apache/spark/pull/33284#pullrequestreview-706807360",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a811a713-757c-4a87-a7cb-fed2bf1ec998",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "do we need to handle nested subqueries here? I think the rule `OptimizeSubqueries` will run this rule again to optimize nested subqueries.",
        "createdAt" : "2021-07-14T13:20:08Z",
        "updatedAt" : "2021-07-14T13:20:08Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "011407d7-d97f-46cb-b465-58c3b3b3c301",
        "parentId" : "a811a713-757c-4a87-a7cb-fed2bf1ec998",
        "authorId" : "b3ba992a-312c-46eb-b3c3-8d861d15ac40",
        "body" : "The reason why we need to check subqueries is to deal with nested subqueries:\r\n```\r\nProject [scalar-subquery [a]]\r\n:  +- Project [scalar-subquery [b]] <-- collapsible if transform with nested subqueries first\r\n:     :  +- Project [outer(b) + 1]\r\n:     :     +- OneRowRelation\r\n:     +- Project [outer(a) as b]\r\n:         +- OneRowRelation\r\n+- Relation [a]\r\n```\r\nA subquery's plan should only be rewritten if it doesn't contain another correlated subquery. If we do not transform the nested subqueries first, we will miss out cases like the one above.",
        "createdAt" : "2021-07-14T23:48:22Z",
        "updatedAt" : "2021-07-14T23:48:22Z",
        "lastEditedBy" : "b3ba992a-312c-46eb-b3c3-8d861d15ac40",
        "tags" : [
        ]
      }
    ],
    "commit" : "7ba19740668cc8d0f28a83482344b7828ccaafff",
    "line" : 35,
    "diffHunk" : "@@ -1,1 +736,740 @@   * if there is no nested subqueries in the subquery plan.\n   */\n  private def rewrite(plan: LogicalPlan): LogicalPlan = plan.transformUpWithSubqueries {\n    case LateralJoin(left, right @ LateralSubquery(OneRowSubquery(projectList), _, _, _), _, None)\n        if !hasCorrelatedSubquery(right.plan) && right.joinCond.isEmpty =>"
  },
  {
    "id" : "70d45a8c-5824-44f0-a90a-969c1119632d",
    "prId" : 33284,
    "prUrl" : "https://github.com/apache/spark/pull/33284#pullrequestreview-706833354",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a662cc10-df70-4ac5-9a50-cd21277c343d",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "if the lateral join has a condition, can we just add a filter above project?",
        "createdAt" : "2021-07-14T13:21:58Z",
        "updatedAt" : "2021-07-14T13:21:59Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "3932ac71-ef19-4b77-87c7-a94b57e93c8b",
        "parentId" : "a662cc10-df70-4ac5-9a50-cd21277c343d",
        "authorId" : "b3ba992a-312c-46eb-b3c3-8d861d15ac40",
        "body" : "It should be fine for inner join but for left outer join, it's trickier. This also applies to subqueries after pulling out correlated filters as join conditions. Maybe this can be a separate optimization before RewriteCorrelatedScalarSubqueries / RewriteLateralSubqueries.",
        "createdAt" : "2021-07-15T01:02:13Z",
        "updatedAt" : "2021-07-15T01:02:13Z",
        "lastEditedBy" : "b3ba992a-312c-46eb-b3c3-8d861d15ac40",
        "tags" : [
        ]
      }
    ],
    "commit" : "7ba19740668cc8d0f28a83482344b7828ccaafff",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +739,743 @@    case LateralJoin(left, right @ LateralSubquery(OneRowSubquery(projectList), _, _, _), _, None)\n        if !hasCorrelatedSubquery(right.plan) && right.joinCond.isEmpty =>\n      Project(left.output ++ projectList, left)\n    case p: LogicalPlan => p.transformExpressionsUpWithPruning(\n      _.containsPattern(SCALAR_SUBQUERY)) {"
  },
  {
    "id" : "6f3f723e-31fb-4156-9ed2-def66e3e28f3",
    "prId" : 33004,
    "prUrl" : "https://github.com/apache/spark/pull/33004#pullrequestreview-688798136",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1bff2beb-8889-41ee-80b5-45b3832b470a",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Changes in this file are not quite necessary, but just to match the code in the analyzer side: when we need to pass around an outer plan, just pass it instead of its children.",
        "createdAt" : "2021-06-21T19:39:58Z",
        "updatedAt" : "2021-06-21T19:39:58Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "01f5833e2b22b8601963f791dedfa9be6e092d78",
    "line" : 1,
    "diffHunk" : "@@ -1,1 +218,222 @@   /**\n    * Returns the correlated predicates and a updated plan that removes the outer references.\n    */\n  private def pullOutCorrelatedPredicates(\n      sub: LogicalPlan,"
  },
  {
    "id" : "3ba9b64e-2a1d-4462-b77b-4ef621321b51",
    "prId" : 31712,
    "prUrl" : "https://github.com/apache/spark/pull/31712#pullrequestreview-606501010",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6b522811-7192-461b-ab54-49a8ec909109",
        "parentId" : null,
        "authorId" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "body" : "Nit: can we pay attention to the indent here? should go 2 spaces further in.",
        "createdAt" : "2021-03-08T16:56:34Z",
        "updatedAt" : "2021-03-08T16:56:34Z",
        "lastEditedBy" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "tags" : [
        ]
      }
    ],
    "commit" : "1de70e4e73c8da2705268f2b6ad7e9d101f7603d",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +95,99 @@  def apply(plan: LogicalPlan): LogicalPlan = plan transform {\n    case Filter(condition, child)\n      if SubqueryExpression.hasInOrCorrelatedExistsSubquery(condition) =>\n      val (withSubquery, withoutSubquery) =\n        splitConjunctivePredicates(condition)"
  },
  {
    "id" : "06a96e4f-667d-4705-84aa-dc6ceb93b7c5",
    "prId" : 30555,
    "prUrl" : "https://github.com/apache/spark/pull/30555#pullrequestreview-541927651",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f3fc9c9b-aadb-41dd-a2b3-e0c87e8ea1f4",
        "parentId" : null,
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "Add a comment above this line? To be honest, it is hard to tell that this trait means UPDATE/MERGE/DELETE. \r\n\r\nAlso, I think this change is just part of the whole changes for supporting the subquery in UPDATE/MERGE/DELETE. We need the other changes in Analyzer and Optimizer rules.  For example, CheckAnalysis. ",
        "createdAt" : "2020-12-01T02:36:42Z",
        "updatedAt" : "2020-12-01T02:36:42Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      },
      {
        "id" : "cce60732-dbd3-4c03-8e05-4e3f86388b5a",
        "parentId" : "f3fc9c9b-aadb-41dd-a2b3-e0c87e8ea1f4",
        "authorId" : "4a94765a-5775-4d88-b283-6ee68d76ecc7",
        "body" : "> Add a comment above this line? To be honest, it is hard to tell that this trait means UPDATE/MERGE/DELETE.\r\n\r\nSure, what kind of comment would make sense? `SupportsSubquery` seems generic to me and may cover different rules in the future. Here, I match the behavior in the analyzer.\r\n\r\n> Also, I think this change is just part of the whole changes for supporting the subquery in UPDATE/MERGE/DELETE. We need the other changes in Analyzer and Optimizer rules. For example, CheckAnalysis.\r\n\r\nYou are right it is the first step and potentially more changes will be needed. At the same time, I think we've updated the analyzer already. Here is what we have in `CheckAnalysis`:\r\n\r\n```\r\n// Only certain operators are allowed to host subquery expression containing\r\n// outer references.\r\nplan match {\r\n   case _: Filter | _: Aggregate | _: Project | _: SupportsSubquery => // Ok\r\n   case other => failAnalysis(\r\n       \"Correlated scalar sub-queries can only be used in a \" +\r\n       s\"Filter/Aggregate/Project and a few commands: $plan\")\r\n}\r\n```\r\n",
        "createdAt" : "2020-12-01T08:33:25Z",
        "updatedAt" : "2020-12-01T08:33:25Z",
        "lastEditedBy" : "4a94765a-5775-4d88-b283-6ee68d76ecc7",
        "tags" : [
        ]
      },
      {
        "id" : "e8f32137-4f37-47c8-88f8-79af5815c1a5",
        "parentId" : "f3fc9c9b-aadb-41dd-a2b3-e0c87e8ea1f4",
        "authorId" : "4a94765a-5775-4d88-b283-6ee68d76ecc7",
        "body" : "If we decide to implement `SupportsSubquery` in other nodes and remove `UnaryNode` from here, I think the comment above may be sufficient (with minor tweaks once we remove `UnaryNode`). ",
        "createdAt" : "2020-12-01T14:08:24Z",
        "updatedAt" : "2020-12-01T14:08:24Z",
        "lastEditedBy" : "4a94765a-5775-4d88-b283-6ee68d76ecc7",
        "tags" : [
        ]
      }
    ],
    "commit" : "b92852d16d85fc79af1d1fa4f62cef6e6181bf48",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +329,333 @@    case q: UnaryNode =>\n      rewriteSubQueries(q, q.children)\n    case s: SupportsSubquery =>\n      rewriteSubQueries(s, s.children)\n  }"
  },
  {
    "id" : "533e5d33-6c91-478e-96e5-2197adca9768",
    "prId" : 30555,
    "prUrl" : "https://github.com/apache/spark/pull/30555#pullrequestreview-541904236",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c0700269-d36c-45b8-af5d-5ecc755f57e6",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "shall we make `Filter`, `Aggregate` and `Project` extend `SupportsSubquery` and only match `SupportsSubquery` here?",
        "createdAt" : "2020-12-01T11:25:04Z",
        "updatedAt" : "2020-12-01T11:25:04Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "b3bc731d-76e3-4e0c-8ca8-de3c475e54eb",
        "parentId" : "c0700269-d36c-45b8-af5d-5ecc755f57e6",
        "authorId" : "4a94765a-5775-4d88-b283-6ee68d76ecc7",
        "body" : "Sounds good to me. We can also simplify the check inside `CheckAnalysis` in a follow-up PR.\r\n\r\nLet me submit a separate PR for this one.",
        "createdAt" : "2020-12-01T13:40:15Z",
        "updatedAt" : "2020-12-01T13:40:35Z",
        "lastEditedBy" : "4a94765a-5775-4d88-b283-6ee68d76ecc7",
        "tags" : [
        ]
      },
      {
        "id" : "c65cd6bf-24de-4091-a3b4-1d4c199a3e7d",
        "parentId" : "c0700269-d36c-45b8-af5d-5ecc755f57e6",
        "authorId" : "4a94765a-5775-4d88-b283-6ee68d76ecc7",
        "body" : "Actually, we can get this one in first. How does it sound, @cloud-fan?",
        "createdAt" : "2020-12-01T13:42:42Z",
        "updatedAt" : "2020-12-01T13:42:42Z",
        "lastEditedBy" : "4a94765a-5775-4d88-b283-6ee68d76ecc7",
        "tags" : [
        ]
      }
    ],
    "commit" : "b92852d16d85fc79af1d1fa4f62cef6e6181bf48",
    "line" : 2,
    "diffHunk" : "@@ -1,1 +327,331 @@      rewriteSubQueries(f, Seq(a, a.child))\n    // Only a few unary nodes (Project/Filter/Aggregate) can contain subqueries.\n    case q: UnaryNode =>\n      rewriteSubQueries(q, q.children)\n    case s: SupportsSubquery =>"
  },
  {
    "id" : "153736b7-ac7f-4914-bc53-f4dd40f69768",
    "prId" : 29585,
    "prUrl" : "https://github.com/apache/spark/pull/29585#pullrequestreview-490556051",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "43a7b83c-5bbd-45c3-949d-f8b965aa28a3",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "why do we need a new expr id here?",
        "createdAt" : "2020-09-17T12:31:35Z",
        "updatedAt" : "2020-09-29T12:28:36Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "6b763ca8-ffc9-4faf-8b9e-f95a50e20b5a",
        "parentId" : "43a7b83c-5bbd-45c3-949d-f8b965aa28a3",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Rewritten expressions in a parent node, `Aggregate` or `Project`, need to refer to an attribute with `newExprId` in this child `Project`. The rewritten exprs are generated in `extractCorrelatedScalarSubqueries`:\r\nhttps://github.com/apache/spark/pull/29585/files#diff-597bd2d5f41c767bfbca973b9c0c4766R343-R353",
        "createdAt" : "2020-09-17T12:49:11Z",
        "updatedAt" : "2020-09-29T12:28:36Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "e3c87429e7e6f463c4e7740c7a42e8b2def528b0",
    "line" : 41,
    "diffHunk" : "@@ -1,1 +525,529 @@          // CASE 1: Subquery guaranteed not to have the COUNT bug\n          Project(\n            currentChild.output :+ Alias(origOutput, origOutput.name)(exprId = newExprId),\n            Join(currentChild, query, LeftOuter, conditions.reduceOption(And), JoinHint.NONE))\n        } else {"
  },
  {
    "id" : "fccff45a-5f75-49e8-9f2b-0143d202d5d2",
    "prId" : 29585,
    "prUrl" : "https://github.com/apache/spark/pull/29585#pullrequestreview-490718130",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "90313836-726e-40c5-9fab-bea6ce685d3a",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Can we just let `Alias` to generate a new expr id here?",
        "createdAt" : "2020-09-17T12:33:39Z",
        "updatedAt" : "2020-09-29T12:28:36Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "f5edc05c-6396-48f5-be1d-452a0a857a20",
        "parentId" : "90313836-726e-40c5-9fab-bea6ce685d3a",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "We might be able to do so, but we need more logic so that a parent node, `Aggregate` and `Project`, can refer to an attribute with a newly-generated expr ID (This topic is related to the comment: \r\nhttps://github.com/apache/spark/pull/29585/files#r490216289).\r\n\r\nIn the current master, the parent node just refer to an attribute with the expr Id of the original output (`origOutput.exprId`) because `origOutput.exprId` is reused in this `Project`. If we generate a new expr Id here, we need to rewrite the parent node later by using the generated expr ID.\r\n\r\nIf necessary, I will try this approach tomorrow, so please let me know.\r\n",
        "createdAt" : "2020-09-17T15:25:17Z",
        "updatedAt" : "2020-09-29T12:28:36Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "e3c87429e7e6f463c4e7740c7a42e8b2def528b0",
    "line" : 50,
    "diffHunk" : "@@ -1,1 +550,554 @@                  If(IsNull(alwaysTrueRef),\n                    resultWithZeroTups.get,\n                    aggValRef), origOutput.name)(exprId = newExprId),\n              Join(currentChild,\n                Project(query.output :+ alwaysTrueExpr, query),"
  },
  {
    "id" : "68d91442-8d5b-416f-abb1-d0680bdddf03",
    "prId" : 29585,
    "prUrl" : "https://github.com/apache/spark/pull/29585#pullrequestreview-491198972",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4e32379e-8428-421b-a40c-1e9348db4de5",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "we need more comments to explain what's going on here: we will rewrite the subqueries later and reference their results here by a new attribute.",
        "createdAt" : "2020-09-17T16:05:14Z",
        "updatedAt" : "2020-09-29T12:28:36Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "d55f90ca-f41f-43cb-90a7-cf117d2c021e",
        "parentId" : "4e32379e-8428-421b-a40c-1e9348db4de5",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "BTW I feel it's more natural to replace attributes after the subquery rewriting, instead of generating the expr id here.",
        "createdAt" : "2020-09-17T16:06:26Z",
        "updatedAt" : "2020-09-29T12:28:36Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "a2245062-7f74-4fdf-8d10-23c0bf7c6214",
        "parentId" : "4e32379e-8428-421b-a40c-1e9348db4de5",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "> BTW I feel it's more natural to replace attributes after the subquery rewriting, instead of generating the expr id here.\r\n\r\nYea, that refactoring looks reasonable and the current logic (top-down rewriting) looks a bit weird. But, I wanna keep the current logic in this PR in order to avoid making new bugs. Is it okay to do it in a separate PR?",
        "createdAt" : "2020-09-18T00:34:55Z",
        "updatedAt" : "2020-09-29T12:28:36Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "d757e073-e859-489b-9843-4b335997fd78",
        "parentId" : "4e32379e-8428-421b-a40c-1e9348db4de5",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Added comments there.",
        "createdAt" : "2020-09-18T00:54:12Z",
        "updatedAt" : "2020-09-29T12:28:36Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "f71ea96b-5047-4114-9377-52112b316171",
        "parentId" : "4e32379e-8428-421b-a40c-1e9348db4de5",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "If it's top-down now, let's defer to change it and fix it in a new PR.",
        "createdAt" : "2020-09-18T07:01:23Z",
        "updatedAt" : "2020-09-29T12:28:36Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "e3c87429e7e6f463c4e7740c7a42e8b2def528b0",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +352,356 @@        val newExprId = NamedExpression.newExprId\n        subqueries += s -> newExprId\n        s.plan.output.head.withExprId(newExprId)\n    }\n    newExpression.asInstanceOf[E]"
  },
  {
    "id" : "5de8ae09-2693-481e-a42c-5349b6d73a36",
    "prId" : 28158,
    "prUrl" : "https://github.com/apache/spark/pull/28158#pullrequestreview-391256003",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "87a24401-e84c-4339-a73f-dc49d6da994e",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can we add some comments to explain it?",
        "createdAt" : "2020-04-09T13:03:42Z",
        "updatedAt" : "2020-04-10T08:27:26Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "12c01e36-ee15-4f84-893b-42fedb88c5fe",
        "parentId" : "87a24401-e84c-4339-a73f-dc49d6da994e",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "ok",
        "createdAt" : "2020-04-09T23:09:57Z",
        "updatedAt" : "2020-04-10T08:27:26Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "e550a7a6-1a8d-4aed-bfed-0a0330460f95",
        "parentId" : "87a24401-e84c-4339-a73f-dc49d6da994e",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Added.",
        "createdAt" : "2020-04-10T03:59:59Z",
        "updatedAt" : "2020-04-10T08:27:26Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "be9dc0abc0ac6fcac42472721c1cb355c70e52f8",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +186,190 @@          //     :- Relation[id#78,v#79] parquet\n          //     +- Relation[id#80] parquet\n          val nullAwareJoinConds = inConditions.map(c => Or(c, IsNull(c)))\n          val finalJoinCond = (nullAwareJoinConds ++ conditions).reduceLeft(And)\n          newPlan = Join(newPlan, newSub, ExistenceJoin(exists), Some(finalJoinCond), JoinHint.NONE)"
  },
  {
    "id" : "7806153f-64c9-4aac-b277-9b224c67abb7",
    "prId" : 26437,
    "prUrl" : "https://github.com/apache/spark/pull/26437#pullrequestreview-338413864",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9a0f0250-648f-41ac-aaf4-5cb0939c9277",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Unrelated change?",
        "createdAt" : "2020-01-05T18:08:19Z",
        "updatedAt" : "2020-01-06T03:57:21Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "40519e77-9057-497a-8a6d-1cbcabf7b63b",
        "parentId" : "9a0f0250-648f-41ac-aaf4-5cb0939c9277",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Oh, nvm, I saw it.",
        "createdAt" : "2020-01-05T18:08:42Z",
        "updatedAt" : "2020-01-06T03:57:21Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "26258b0bb285644ea9d1b43f7ac20a7e02c5d6f4",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +98,102 @@      val (withSubquery, withoutSubquery) =\n        splitConjunctivePredicates(condition)\n          .partition(SubqueryExpression.hasInOrCorrelatedExistsSubquery)\n\n      // Construct the pruned filter condition."
  },
  {
    "id" : "569216da-76c7-40e9-89d6-32c69529c78a",
    "prId" : 25268,
    "prUrl" : "https://github.com/apache/spark/pull/25268#pullrequestreview-267565723",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3fd4d6ac-7632-4c1a-bb2f-4eb8a27e2eb7",
        "parentId" : null,
        "authorId" : "88f0c774-9c59-4485-885d-f6aee36efcea",
        "body" : "Is it true that this function is to workaround cases where the `newCond` is empty, while outer references is not empty? Maybe we should add some comment here since it might be tricky to understand...",
        "createdAt" : "2019-07-29T04:45:55Z",
        "updatedAt" : "2019-07-29T05:33:58Z",
        "lastEditedBy" : "88f0c774-9c59-4485-885d-f6aee36efcea",
        "tags" : [
        ]
      }
    ],
    "commit" : "3b224f094f50a5be61d77868ed9f6ee3e0202417",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +282,286 @@     * subquery expression.\n     */\n    def getJoinCondition(newCond: Seq[Expression], oldCond: Seq[Expression]): Seq[Expression] = {\n      if (newCond.isEmpty) oldCond else newCond\n    }"
  }
]