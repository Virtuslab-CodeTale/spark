[
  {
    "id" : "1006393a-1dcd-46cb-9648-f462f3c15105",
    "prId" : 33655,
    "prUrl" : "https://github.com/apache/spark/pull/33655#pullrequestreview-724508457",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6f771c2c-d596-4ca9-a339-a39044e93897",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Could you add this check into `spark.sql.adaptive.advisoryPartitionSizeInBytes`, too?",
        "createdAt" : "2021-08-05T19:11:39Z",
        "updatedAt" : "2021-08-05T19:11:39Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "2f3635cd-b39d-4b85-bc81-36325b1b97f7",
        "parentId" : "6f771c2c-d596-4ca9-a339-a39044e93897",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "We can't add check in `ADVISORY_PARTITION_SIZE_IN_BYTES`, because it falls back to `SHUFFLE_TARGET_POSTSHUFFLE_INPUT_SIZE`, which is this conf.",
        "createdAt" : "2021-08-06T03:21:40Z",
        "updatedAt" : "2021-08-06T03:21:41Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "7d5b09ab-ea22-4004-b963-7a431f6b59bc",
        "parentId" : "6f771c2c-d596-4ca9-a339-a39044e93897",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "@cloud-fan . If we set negative values to `advisoryPartitionSizeInBytes` explicitly, it will not fallback to here. If we want to say, `advisoryPartitionSizeInBytes must be positive`, we should check both places, shouldn't we?",
        "createdAt" : "2021-08-06T16:06:34Z",
        "updatedAt" : "2021-08-06T16:06:34Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "eeeff3ae6bb62eedeb09011cc99514d240a8b7d0",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +481,485 @@      .version(\"1.6.0\")\n      .bytesConf(ByteUnit.BYTE)\n      .checkValue(_ > 0, \"advisoryPartitionSizeInBytes must be positive\")\n      .createWithDefaultString(\"64MB\")\n"
  },
  {
    "id" : "98d04720-367d-4e9e-8c61-371061b7bdc3",
    "prId" : 33444,
    "prUrl" : "https://github.com/apache/spark/pull/33444#pullrequestreview-711555608",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "23cb04d3-961d-4052-92fa-d13cc850bf24",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "indentation ?",
        "createdAt" : "2021-07-21T10:35:50Z",
        "updatedAt" : "2021-07-21T10:38:09Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      },
      {
        "id" : "ec7c2243-c1ee-4f0d-a674-6cd9958f62a0",
        "parentId" : "23cb04d3-961d-4052-92fa-d13cc850bf24",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "Oh, this is on purpose.",
        "createdAt" : "2021-07-21T11:40:24Z",
        "updatedAt" : "2021-07-21T11:40:25Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "221e62227f09d7e29fbab5c674af29b1f829b91e",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +3978,3982 @@  def timestampType: AtomicType = getConf(TIMESTAMP_TYPE) match {\n    // SPARK-36227: Remove TimestampNTZ type support in Spark 3.2 with minimal code changes.\n    //              The configuration `TIMESTAMP_TYPE` is only effective for testing in Spark 3.2.\n    case \"TIMESTAMP_NTZ\" if Utils.isTesting =>\n      TimestampNTZType"
  }
]