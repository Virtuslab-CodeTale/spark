[
  {
    "id" : "7dac3978-7a0c-41e8-b19a-41ebda309537",
    "prId" : 26905,
    "prUrl" : "https://github.com/apache/spark/pull/26905#pullrequestreview-335146933",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0da99e20-66ce-4bfe-bef4-0502660c3512",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "where do we fail for null?",
        "createdAt" : "2019-12-20T09:24:03Z",
        "updatedAt" : "2019-12-23T05:59:38Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "c6607f80-e50d-41b8-ba98-f8ede074ca16",
        "parentId" : "0da99e20-66ce-4bfe-bef4-0502660c3512",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "```sql\r\npark-sql> select percentile(1, null);\r\n19/12/20 17:25:00 ERROR SparkSQLDriver: Failed in [select percentile(1, null)]\r\nscala.MatchError: null\r\n\tat org.apache.spark.sql.catalyst.expressions.aggregate.Percentile.percentages$lzycompute(Percentile.scala:87)\r\n```",
        "createdAt" : "2019-12-20T09:25:41Z",
        "updatedAt" : "2019-12-23T05:59:38Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "7a3014fb90958c82cf6bbb700f5012d70cba833f",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +94,98 @@  @transient\n  private lazy val percentages = percentageExpression.eval() match {\n    case null => null\n    case num: Double => Array(num)\n    case arrayData: ArrayData => arrayData.toDoubleArray()"
  },
  {
    "id" : "d13dba8d-48b1-4b06-8083-cb35c0f2fbb6",
    "prId" : 24779,
    "prUrl" : "https://github.com/apache/spark/pull/24779#pullrequestreview-275477105",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d900bb44-a8ee-4b42-92c1-948ed00d38a4",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "This is hacky.\r\nIs this all just so you can pass \"0.75\" instead of \"75\"? I don't think that's worth it.",
        "createdAt" : "2019-07-31T14:35:38Z",
        "updatedAt" : "2019-07-31T14:35:38Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "fde5569a-08bc-45ae-b7bd-bd9073add8ca",
        "parentId" : "d900bb44-a8ee-4b42-92c1-948ed00d38a4",
        "authorId" : "548432e4-830e-420d-a327-7881fd5b4875",
        "body" : "@srowen \r\nIf data had only discrete frequencies, your suggestion would be enough (0.75 -> 75)\r\nBut, the suggestion isn't enough for fractional number like water with 1/3 L.\r\n1/3 frequency can't be converted to integer. I think existing api isn't enough for receiving fractional frequency, which needs to be improved.",
        "createdAt" : "2019-08-13T17:34:07Z",
        "updatedAt" : "2019-08-13T17:47:11Z",
        "lastEditedBy" : "548432e4-830e-420d-a327-7881fd5b4875",
        "tags" : [
        ]
      },
      {
        "id" : "794bb0bf-b06d-4034-8c39-d7df2cc018c7",
        "parentId" : "d900bb44-a8ee-4b42-92c1-948ed00d38a4",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Oh I misunderstood this a little. This is extending the implementation of weighted percentile.\r\nStill, I doubt you need to add a new expression here. Just expand the allowed types to any `NumericType`, which should be backwards compatible. The math wouldn't change, right?",
        "createdAt" : "2019-08-13T18:35:28Z",
        "updatedAt" : "2019-08-13T18:35:28Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "e9700e1c-88c5-4b9f-9927-023f8ee9ef4e",
        "parentId" : "d900bb44-a8ee-4b42-92c1-948ed00d38a4",
        "authorId" : "548432e4-830e-420d-a327-7881fd5b4875",
        "body" : "At first, I already implemented it only with NumericType, as you said.\r\n\r\nBut my first implementation wasn't compatible with hive(hive unittest had failed).\r\nI had found the existing IntegralType implementation which is compatible with hive is only for integer, not rational number.\r\n\r\nI couldn't find the way to resolve the problem without additional parameter...",
        "createdAt" : "2019-08-13T18:53:59Z",
        "updatedAt" : "2019-08-13T18:53:59Z",
        "lastEditedBy" : "548432e4-830e-420d-a327-7881fd5b4875",
        "tags" : [
        ]
      },
      {
        "id" : "1fbb9dcf-1f06-44a1-afbf-798508ec4be3",
        "parentId" : "d900bb44-a8ee-4b42-92c1-948ed00d38a4",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Does Hive support this? I didn't see it supports weighted percentile. \r\nYou're also changing the implementation here, right... is it possible that is causing the test to fail without two branches of the logic? I don't think it makes sense to have the caller tell the type of the column; you already know it in the implementation. But I'm wondering how the same calculation can come out differently if it just allows decimal types too. Is it a rounding thing?",
        "createdAt" : "2019-08-13T18:58:21Z",
        "updatedAt" : "2019-08-13T18:58:22Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "a6b38c65-55fc-4df8-9cfb-f6907703ba36",
        "parentId" : "d900bb44-a8ee-4b42-92c1-948ed00d38a4",
        "authorId" : "548432e4-830e-420d-a327-7881fd5b4875",
        "body" : "You are right. The logics are different. So the additional parameter is for logic switching.\r\nI thought the interpolation of value was based on the assumption that weight is integer, which cannot be implemented with floating number. But I can't remember the reason exactly. I'll put concrete example.\r\n",
        "createdAt" : "2019-08-13T19:20:58Z",
        "updatedAt" : "2019-08-13T19:20:59Z",
        "lastEditedBy" : "548432e4-830e-420d-a327-7881fd5b4875",
        "tags" : [
        ]
      },
      {
        "id" : "e20a666c-ba3a-4910-9c67-295c5a4047c7",
        "parentId" : "d900bb44-a8ee-4b42-92c1-948ed00d38a4",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "At the least, I think you can switch logic based on the type of the column, rather than add a new parameter.\r\n\r\nI don't know the logic here, but I'd imagine that anything that works for integer weights (1, 2) should work identically for continuous ones (1.0, 2.0). It's possible that the current tests are actually expecting the 'wrong' value if the code is using an unsuitable approximation for integer values or something.\r\n\r\nI'd be interested in knowing what fails, as I don't expect Hive-related tests to fail - it doesn't implement weighted percentiles, I thought? ",
        "createdAt" : "2019-08-15T14:53:18Z",
        "updatedAt" : "2019-08-15T14:53:18Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      }
    ],
    "commit" : "c36194e3855fff8b51c786890a120dffd5ff4eec",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +68,72 @@    percentageExpression: Expression,\n    frequencyExpression : Expression,\n    isIntFreqExpression: Expression,\n    mutableAggBufferOffset: Int = 0,\n    inputAggBufferOffset: Int = 0)"
  }
]