[
  {
    "id" : "7dac3978-7a0c-41e8-b19a-41ebda309537",
    "prId" : 26905,
    "prUrl" : "https://github.com/apache/spark/pull/26905#pullrequestreview-335146933",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0da99e20-66ce-4bfe-bef4-0502660c3512",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "where do we fail for null?",
        "createdAt" : "2019-12-20T09:24:03Z",
        "updatedAt" : "2019-12-23T05:59:38Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "c6607f80-e50d-41b8-ba98-f8ede074ca16",
        "parentId" : "0da99e20-66ce-4bfe-bef4-0502660c3512",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "```sql\r\npark-sql> select percentile(1, null);\r\n19/12/20 17:25:00 ERROR SparkSQLDriver: Failed in [select percentile(1, null)]\r\nscala.MatchError: null\r\n\tat org.apache.spark.sql.catalyst.expressions.aggregate.Percentile.percentages$lzycompute(Percentile.scala:87)\r\n```",
        "createdAt" : "2019-12-20T09:25:41Z",
        "updatedAt" : "2019-12-23T05:59:38Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "7a3014fb90958c82cf6bbb700f5012d70cba833f",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +94,98 @@  @transient\n  private lazy val percentages = percentageExpression.eval() match {\n    case null => null\n    case num: Double => Array(num)\n    case arrayData: ArrayData => arrayData.toDoubleArray()"
  }
]