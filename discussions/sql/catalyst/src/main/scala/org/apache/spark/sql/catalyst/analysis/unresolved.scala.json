[
  {
    "id" : "67403d37-6e12-4bfe-b4be-0665d2f105c1",
    "prId" : 32470,
    "prUrl" : "https://github.com/apache/spark/pull/32470#pullrequestreview-683792915",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1d902288-27ee-4546-9061-05ca87c07d68",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Is its child always a named expression?",
        "createdAt" : "2021-06-11T20:36:29Z",
        "updatedAt" : "2021-06-11T20:36:29Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "03cc87b6-e8f6-4203-8871-a6fa9497efcd",
        "parentId" : "1d902288-27ee-4546-9061-05ca87c07d68",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Yes, I'll refine the type.",
        "createdAt" : "2021-06-14T14:10:16Z",
        "updatedAt" : "2021-06-14T14:10:16Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "201fef8c-7736-4708-8e10-3fa5b1df5bbb",
        "parentId" : "1d902288-27ee-4546-9061-05ca87c07d68",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Actually, we don't require it to be a named expression, so it's more robust to keep the type as `Expression`.",
        "createdAt" : "2021-06-15T09:46:55Z",
        "updatedAt" : "2021-06-15T09:46:56Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "b362a098978be65ab1fc033fe0213a78a467b6ae",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +658,662 @@ * column resolution and use this expression to keep the original column name.\n */\ncase class TempResolvedColumn(child: Expression, nameParts: Seq[String]) extends UnaryExpression\n  with Unevaluable {\n  override lazy val canonicalized = child.canonicalized"
  },
  {
    "id" : "1f4e95f2-7be0-4d77-873c-5af6b742cac8",
    "prId" : 31854,
    "prUrl" : "https://github.com/apache/spark/pull/31854#pullrequestreview-616859914",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a3ba589f-5a18-4680-9e67-2b75976436ea",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "maybe we should get rid of this hand-written parser and simply call `CatalystSqlParser.parseMultipartIdentifier` here.",
        "createdAt" : "2021-03-18T14:15:35Z",
        "updatedAt" : "2021-03-19T22:47:25Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "8ff38d81-5661-44b5-9387-15e5338d4331",
        "parentId" : "a3ba589f-5a18-4680-9e67-2b75976436ea",
        "authorId" : "3a227965-84e0-47cf-9974-11293764f028",
        "body" : "Thanks. I'll try to replace it with `CatalystSqlParser.parseMultipartIdentifier`.",
        "createdAt" : "2021-03-18T14:25:14Z",
        "updatedAt" : "2021-03-19T22:47:25Z",
        "lastEditedBy" : "3a227965-84e0-47cf-9974-11293764f028",
        "tags" : [
        ]
      },
      {
        "id" : "f502e693-897c-49d0-bd34-c3703862f65a",
        "parentId" : "a3ba589f-5a18-4680-9e67-2b75976436ea",
        "authorId" : "3a227965-84e0-47cf-9974-11293764f028",
        "body" : "I found replacing with `CatlystSqlParser.parseMultipartIdentifier` breaks API compatibility.\r\nIf a string passed to `UnresolvedAttribute.parseAttributeName` contains quoted parts,  each of them is regarded as a complete name part.\r\nOtherwise, each unquoted part is regarded as name parts which can be separated by `.` and each name part doesn't need to be quoted.\r\n\r\nSo, this is valid for `parseAttributeName` but not for `parseMultipartIdentifier`.\r\n```\r\nUnresolvedAttribute.parseAttributeName(\"*#  !.`abc`\")\r\n```\r\n\r\nSo, I restore this part.",
        "createdAt" : "2021-03-20T00:05:27Z",
        "updatedAt" : "2021-03-20T00:05:46Z",
        "lastEditedBy" : "3a227965-84e0-47cf-9974-11293764f028",
        "tags" : [
        ]
      }
    ],
    "commit" : "249f8ccf3c910b58fe3440ace768700b267e623f",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +207,211 @@      if (inBacktick) {\n        if (char == '`') {\n          if (i + 1 < name.length && name(i + 1) == '`') {\n            tmp += '`'\n            i += 1"
  },
  {
    "id" : "96b575c2-ed71-4644-a21b-0014c3e30acb",
    "prId" : 31548,
    "prUrl" : "https://github.com/apache/spark/pull/31548#pullrequestreview-592910476",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "47dd6a80-8888-4dfa-a016-9144b91d9e28",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "We cannot add a new built-in function for this purpose instead? The implementation will be simpler than the current syntax-based approach, I think.",
        "createdAt" : "2021-02-18T02:13:02Z",
        "updatedAt" : "2021-04-27T06:11:08Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "813a06db-0b7a-416d-8435-3dfccaa85327",
        "parentId" : "47dd6a80-8888-4dfa-a016-9144b91d9e28",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "First, this PR references the table-valued-function. So, I call the syntax is table-valued-command.\r\nSecond, Users want use filter clause, group by, ... on table-valued-command. In fact, This PR adopt the syntax-based approach is much simpler than built-in function.",
        "createdAt" : "2021-02-18T03:07:47Z",
        "updatedAt" : "2021-04-27T06:11:08Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      },
      {
        "id" : "82e30bcc-95ea-4d3c-97f7-0bacc47844c8",
        "parentId" : "47dd6a80-8888-4dfa-a016-9144b91d9e28",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "Yes. This implementation can make these command easy to use:\r\n1. Save result to table.\r\n2. Query the specified column.\r\n3. Filter / Group by / Order by the specified column.\r\n\r\nThis is the syntax of Teradata:\r\n```sql\r\nSELECT  tbl.DatabaseName,\r\n        tbl.TableName,\r\n        SUM(spc.CurrentPerm)/1024.00 as TableSize\r\nFROM    DBC.TablesV tbl\r\nJOIN    DBC.TableSize spc\r\nON  tbl.DatabaseName = spc.DatabaseName\r\nAND tbl.TableName = spc.TableName\r\nWHERE   tbl.DatabaseName NOT IN ('All', 'Crashdumps', 'DBC', 'dbcmngr', \r\n        'Default', 'External_AP', 'EXTUSER', 'LockLogShredder', 'PUBLIC',\r\n        'Sys_Calendar', 'SysAdmin', 'SYSBAR', 'SYSJDBC', 'SYSLIB', \r\n        'SystemFe', 'SYSUDTLIB', 'SYSUIF', 'TD_SERVER_DB',  'TDStats',\r\n        'TD_SYSGPL', 'TD_SYSXML', 'TDMaps', 'TDPUSER', 'TDQCD',\r\n        'tdwm',  'SQLJ', 'TD_SYSFNLIB',  'SYSSPATIAL')\r\nAND TableKind = 'T'\r\nGROUP BY    tbl.DatabaseName,\r\n            tbl.TableName\r\nORDER BY TableSize DESC;\r\n```",
        "createdAt" : "2021-02-18T07:19:30Z",
        "updatedAt" : "2021-04-27T06:11:08Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      }
    ],
    "commit" : "1d4a6b35c90c6f6bdc6b1c684709a0ebe10c1400",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +149,153 @@ * A table-valued command, e.g.\n * {{{\n *   select tableName from command(\"show tables\");\n *\n *   // Assign alias names"
  },
  {
    "id" : "7f7d000f-2423-4391-9c79-e7b5ef913a19",
    "prId" : 29939,
    "prUrl" : "https://github.com/apache/spark/pull/29939#pullrequestreview-504400416",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "279b89a2-7a26-4f5a-a4d9-44edd14fbcf5",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Is `partitions` only for the JDBC V2 path? If so, could we use `options` instead for passing partition info into the JDBC scan?",
        "createdAt" : "2020-10-06T05:54:45Z",
        "updatedAt" : "2020-10-06T17:09:05Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "44f113a6-0145-42ab-9c55-bd29410b5e14",
        "parentId" : "279b89a2-7a26-4f5a-a4d9-44edd14fbcf5",
        "authorId" : "99765afe-8dbe-4d5f-9ad3-d5bc40f0462b",
        "body" : "Yes, `partitions` is only for JDBC V2 path, but it seems to me that we can't use `options` to pass the partition info into JDBC Scan. In `JDBCTable.newScanBuilder`, it merges `jdbcOptions` with `options` in `CaseInsensitiveStringMap`, but partitions is not a `JDBCOptions`, so it won't be passed to `JDBCScanBuilder`. I am not sure if we should add partitions into `JDBCOptions`.",
        "createdAt" : "2020-10-06T17:09:06Z",
        "updatedAt" : "2020-10-06T17:09:06Z",
        "lastEditedBy" : "99765afe-8dbe-4d5f-9ad3-d5bc40f0462b",
        "tags" : [
        ]
      },
      {
        "id" : "83a3f94c-3375-4ef6-8014-cee40c1a1bfd",
        "parentId" : "279b89a2-7a26-4f5a-a4d9-44edd14fbcf5",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "IMHO adding it in `JDBCOptions` looks better than adding it in `UnresolvedRelation` because the partition info is dedicated for JDBC scans and having physical partition info in a class field of the logical plan is a bit weird. But, its okay to wait for the comments of other reviewers.",
        "createdAt" : "2020-10-08T03:13:48Z",
        "updatedAt" : "2020-10-08T03:13:48Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "135eb08a14dbee9fa5e9ae9b9748a0da43035710",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +49,53 @@    options: CaseInsensitiveStringMap = CaseInsensitiveStringMap.empty(),\n    override val isStreaming: Boolean = false,\n    partitions: Seq[Partition] = Seq.empty[Partition])\n  extends LeafNode with NamedRelation {\n  import org.apache.spark.sql.connector.catalog.CatalogV2Implicits._"
  }
]