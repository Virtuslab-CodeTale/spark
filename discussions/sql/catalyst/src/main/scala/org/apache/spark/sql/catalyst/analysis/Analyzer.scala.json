[
  {
    "id" : "01a73ee2-5d29-4bf4-9936-e9f4212784ab",
    "prId" : 33574,
    "prUrl" : "https://github.com/apache/spark/pull/33574#pullrequestreview-718331844",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c27663bb-b0d6-4922-b886-3d4b151d5581",
        "parentId" : null,
        "authorId" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "body" : "What's the difference between underscore?",
        "createdAt" : "2021-07-29T09:54:52Z",
        "updatedAt" : "2021-07-29T09:56:06Z",
        "lastEditedBy" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "tags" : [
        ]
      },
      {
        "id" : "67cc877e-1473-41fa-8991-865f9251a6de",
        "parentId" : "c27663bb-b0d6-4922-b886-3d4b151d5581",
        "authorId" : "f850781e-b750-4a78-9a80-1e68e9b4f9b7",
        "body" : "Using the underscore, the aggsBuffer is outside the scope of the map function at runtime and it will save the results of all elements.\r\nusing normal parameters, the aggsBuffer will only be recreated each time inside the map function loop.\r\n\r\nI suspect that Scala syntactic sugar in the conversion of the code made changes to cause, I also debugged this code many times before I found this difference, here is a simplified code to test separately.\r\n\r\n```\r\n    def testMap(seq: Seq[Int]): Seq[Int] = {\r\n      seq.map {\r\n        val buf = ArrayBuffer[Int]()\r\n        _ match {\r\n          case e: Int if e < 1 =>\r\n            val r = e + 1\r\n            println(s\"add to buf: $r\")\r\n            buf += r\r\n            r\r\n          case e: Int if buf.contains(e) =>\r\n            println(\"already in buf\")\r\n            0\r\n          case e =>\r\n            println(\"not in buf\")\r\n            e\r\n        }\r\n      }\r\n    }\r\n\r\n    testMap(Seq(0, 1))\r\n\r\n```",
        "createdAt" : "2021-07-29T12:36:51Z",
        "updatedAt" : "2021-07-29T12:51:53Z",
        "lastEditedBy" : "f850781e-b750-4a78-9a80-1e68e9b4f9b7",
        "tags" : [
        ]
      },
      {
        "id" : "39338740-00a7-46fa-9edd-d57c54915570",
        "parentId" : "c27663bb-b0d6-4922-b886-3d4b151d5581",
        "authorId" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "body" : "Thank you for the detailed explanation.",
        "createdAt" : "2021-07-29T17:00:21Z",
        "updatedAt" : "2021-07-29T17:00:21Z",
        "lastEditedBy" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "tags" : [
        ]
      }
    ],
    "commit" : "321374d87a1f50e458be42e55b08472befa846e3",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +589,593 @@        aggsBuffer.exists(a => a.find(_ eq e).isDefined)\n      }\n      replaceGroupingFunc(agg, groupByExprs, gid).transformDown {\n        // AggregateExpression should be computed on the unmodified value of its argument\n        // expressions, so we should not replace any references to grouping expression"
  },
  {
    "id" : "0ba97497-c1fe-4957-a185-3a359639f69c",
    "prId" : 33498,
    "prUrl" : "https://github.com/apache/spark/pull/33498#pullrequestreview-729193442",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f32c3e3a-753d-4efb-965f-1937d8405652",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Let's use a single brace next time for `map` in this case: https://github.com/databricks/scala-style-guide#anonymous-methods",
        "createdAt" : "2021-08-13T01:24:55Z",
        "updatedAt" : "2021-08-13T01:24:55Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "fb3931c6149d0d1d5962c5475f3d67b8430db07e",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +2554,2558 @@              // GROUP BY c1 HAVING c2 = 0`, even though we can resolve column `c2` here, we\n              // should undo it later and fail with \"Column c2 not found\".\n              agg.child.resolve(u.nameParts, resolver).map({\n                case a: Alias => TempResolvedColumn(a.child, u.nameParts)\n                case o => TempResolvedColumn(o, u.nameParts)"
  },
  {
    "id" : "c33c8016-5be7-44a1-9131-b1e815d5d99d",
    "prId" : 33468,
    "prUrl" : "https://github.com/apache/spark/pull/33468#pullrequestreview-712437184",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "55fc3b7f-928c-4de9-8d6c-a5c43b58325d",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "since it's a new code path, I didn't take care of the legacy mode and use ansi behavior directly.",
        "createdAt" : "2021-07-22T07:30:15Z",
        "updatedAt" : "2021-07-22T07:30:22Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "984b511adb2ca5b60f6acf1a84e1bbacc6effc30",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +3318,3322 @@          }\n          val casted = if (assignment.key.dataType != nullHandled.dataType) {\n            AnsiCast(nullHandled, assignment.key.dataType)\n          } else {\n            nullHandled"
  },
  {
    "id" : "943361ec-06d7-4ee9-b343-534112a2b7c0",
    "prId" : 33113,
    "prUrl" : "https://github.com/apache/spark/pull/33113#pullrequestreview-698906121",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bb9ab4d3-d602-4950-acfe-f6a66e588deb",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Do we need to put `fieldName` in `UnresolvedFieldPosition`? We can easily get it via `AlterTableAlterColumn.column.name`",
        "createdAt" : "2021-07-05T05:17:43Z",
        "updatedAt" : "2021-07-05T05:17:43Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "4e74bca2-f5aa-4e5b-913d-c460047d1d53",
        "parentId" : "bb9ab4d3-d602-4950-acfe-f6a66e588deb",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "https://github.com/apache/spark/pull/33213",
        "createdAt" : "2021-07-05T08:07:36Z",
        "updatedAt" : "2021-07-05T08:07:36Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "6a75c920df97a13ac547056eb7eb286b3accf973",
    "line" : 35,
    "diffHunk" : "@@ -1,1 +3537,3541 @@          case u: UnresolvedFieldPosition => u.position match {\n            case after: After =>\n              resolveFieldNames(table.schema, u.fieldName.init :+ after.column())\n                .map { resolved =>\n                  ResolvedFieldPosition(ColumnPosition.after(resolved.field.name))"
  },
  {
    "id" : "1c587e8f-a9b7-4fd2-bf38-8ea860264a63",
    "prId" : 32854,
    "prUrl" : "https://github.com/apache/spark/pull/32854#pullrequestreview-680375089",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0c52a681-96ea-466d-8b5a-78747e0b53c2",
        "parentId" : null,
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "This is a copied/modified version of https://github.com/apache/spark/blob/cadd3a0588eeed42c6742ae1b7a2eaa85bd8a3af/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/Analyzer.scala#L3687",
        "createdAt" : "2021-06-10T06:07:41Z",
        "updatedAt" : "2021-06-10T06:11:41Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "c9c545b559c69c3ddee408588b1ada341f7b3ae9",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +3535,3539 @@     * not found. An error will be thrown in CheckAnalysis for columns that can't be resolved.\n     */\n    private def resolveFieldNames(\n        schema: StructType,\n        fieldNames: Seq[String]): Option[Seq[String]] = {"
  },
  {
    "id" : "746ab13f-2b8d-4bed-9047-faef78b7001f",
    "prId" : 32854,
    "prUrl" : "https://github.com/apache/spark/pull/32854#pullrequestreview-680375089",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "83679b7a-ef66-4cc9-9d21-d61f13e6b5cb",
        "parentId" : null,
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "We can remove `ResolveAlterTableChanges` once all the alter table commands are migrated to `ResolveAlterTableCommands`.",
        "createdAt" : "2021-06-10T06:11:36Z",
        "updatedAt" : "2021-06-10T06:11:41Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "c9c545b559c69c3ddee408588b1ada341f7b3ae9",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +300,304 @@      postHocResolutionRules: _*),\n    Batch(\"Normalize Alter Table Field Names\", Once, ResolveFieldNames),\n    Batch(\"Normalize Alter Table\", Once, ResolveAlterTableChanges),\n    Batch(\"Remove Unresolved Hints\", Once,\n      new ResolveHints.RemoveAllHints),"
  },
  {
    "id" : "fb39b0ef-b5ac-4245-96f9-809f63eb473e",
    "prId" : 32854,
    "prUrl" : "https://github.com/apache/spark/pull/32854#pullrequestreview-691073052",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5ff03d52-5c32-412c-a468-39d40f93bb1a",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Shall we fail here instead of in `CheckAnalysis`? Then we can avoid repeating the field name resolution logic in `CheckAnalysis`.",
        "createdAt" : "2021-06-10T17:54:28Z",
        "updatedAt" : "2021-06-10T17:54:28Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "b19e5d01-719e-4b49-946f-6132efef5e5f",
        "parentId" : "5ff03d52-5c32-412c-a468-39d40f93bb1a",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Another idea is to follow `UnresolvedPartitionSpec`/`ResolvedPartitionSpec`. We add `UnresolvedFieldName` and `ResolvedFieldName`, to do the resolution in a general way like `ResolvePartitionSpec`",
        "createdAt" : "2021-06-10T17:56:35Z",
        "updatedAt" : "2021-06-10T17:56:35Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "0b647f89-2928-4b0f-ae5e-a7d650ad941a",
        "parentId" : "5ff03d52-5c32-412c-a468-39d40f93bb1a",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "I updated the PR with the `UnresolvedFieldName`/`ResolvedFieldName` approach. Please let me know what you think.",
        "createdAt" : "2021-06-23T18:05:16Z",
        "updatedAt" : "2021-06-23T18:05:20Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      },
      {
        "id" : "3841f9db-7a5d-442e-b951-3abb0c5fac43",
        "parentId" : "5ff03d52-5c32-412c-a468-39d40f93bb1a",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "Also, please let me know if you want to see more commands migrated in this PR.",
        "createdAt" : "2021-06-23T19:41:25Z",
        "updatedAt" : "2021-06-23T19:41:28Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "c9c545b559c69c3ddee408588b1ada341f7b3ae9",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +3533,3537 @@    /**\n     * Returns the resolved field name if the field can be resolved, returns None if the column is\n     * not found. An error will be thrown in CheckAnalysis for columns that can't be resolved.\n     */\n    private def resolveFieldNames("
  },
  {
    "id" : "ac55f5ac-617d-4172-a657-b1fd26f8a6ab",
    "prId" : 32832,
    "prUrl" : "https://github.com/apache/spark/pull/32832#pullrequestreview-688058198",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fdd1db32-a392-4762-b7d5-15232f113b5d",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "We can allow an expression tree that contains only `ExtractValue` and attributes",
        "createdAt" : "2021-06-21T06:10:16Z",
        "updatedAt" : "2021-06-21T06:10:16Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "751a55e65033e9bb2c279acee6a300e6d61c6317",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +463,467 @@            case g: Generator => MultiAlias(g, Nil)\n            case c @ Cast(ne: NamedExpression, _, _, _) => Alias(c, ne.name)()\n            case e: ExtractValue =>\n              if (extractOnly(e)) {\n                Alias(e, toPrettySQL(e))()"
  },
  {
    "id" : "0e46698e-30a5-4a09-bbfb-5bd2cfab3660",
    "prId" : 32832,
    "prUrl" : "https://github.com/apache/spark/pull/32832#pullrequestreview-696773027",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "616eb6aa-cfa5-4d6a-9570-ba01a361c252",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "since we allow literal here, maybe we should allow it in the non `ExtractValue` case as well",
        "createdAt" : "2021-06-28T16:44:31Z",
        "updatedAt" : "2021-06-28T16:44:31Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "9cdea9a0-3600-4003-8217-5f61f02f6b34",
        "parentId" : "616eb6aa-cfa5-4d6a-9570-ba01a361c252",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "or maybe we shouldn't allow literal here either",
        "createdAt" : "2021-06-28T16:45:47Z",
        "updatedAt" : "2021-06-28T16:45:47Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "4f34a1a5-b44c-46e7-946e-838e95963a74",
        "parentId" : "616eb6aa-cfa5-4d6a-9570-ba01a361c252",
        "authorId" : "29c89154-22f7-40ee-b295-115a55734d6c",
        "body" : "@cloud-fan I don't think the alias of literal will be changed. And in order to keep current test cases passing. I prefer allowing the literal for non ExtractValue as well. Is this OK?",
        "createdAt" : "2021-06-30T17:03:24Z",
        "updatedAt" : "2021-06-30T17:03:25Z",
        "lastEditedBy" : "29c89154-22f7-40ee-b295-115a55734d6c",
        "tags" : [
        ]
      },
      {
        "id" : "d7a8480d-cce9-4b5c-ab5b-9d9719d7cc36",
        "parentId" : "616eb6aa-cfa5-4d6a-9570-ba01a361c252",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "sure",
        "createdAt" : "2021-07-01T03:13:45Z",
        "updatedAt" : "2021-07-01T03:13:45Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "751a55e65033e9bb2c279acee6a300e6d61c6317",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +446,450 @@      def extractOnly(e: Expression): Boolean = e match {\n        case _: ExtractValue => e.children.forall(extractOnly)\n        case _: Literal => true\n        case _: Attribute => true\n        case _ => false"
  }
]