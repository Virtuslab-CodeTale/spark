[
  {
    "id" : "3b9a7468-81d0-42d8-92fe-6ba4169c3dc0",
    "prId" : 33751,
    "prUrl" : "https://github.com/apache/spark/pull/33751#pullrequestreview-730792516",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "436c5ae9-b6ab-48d6-a504-836fc4debd8f",
        "parentId" : null,
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "This one is used in the type constructor. ",
        "createdAt" : "2021-08-16T14:36:36Z",
        "updatedAt" : "2021-08-16T14:36:36Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "7a03c24491af59c76744d791d76e06d68fe37b3f",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +220,224 @@  def fromYearMonthString(input: String, startField: Byte, endField: Byte): CalendarInterval = {\n    require(input != null, \"Interval year-month string must be not null\")\n    val months = castStringToYMIntervalAnsi(UTF8String.fromString(input), startField, endField)\n    new CalendarInterval(months, 0, 0)\n  }"
  },
  {
    "id" : "5db72206-0510-4846-b685-00b36107094f",
    "prId" : 33242,
    "prUrl" : "https://github.com/apache/spark/pull/33242#pullrequestreview-700670239",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "78581c6a-6aca-451e-a019-eb9d2d28f30a",
        "parentId" : null,
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "Here fix a bug about parse `INTERVAL '111' day` failed issue. FYI @MaxGekk  @cloud-fan ",
        "createdAt" : "2021-07-07T07:33:13Z",
        "updatedAt" : "2021-07-07T07:36:16Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "12e83e6da7a931dd17109c4632f8332c2ef33294",
    "line" : 132,
    "diffHunk" : "@@ -1,1 +368,372 @@        safeToInterval(\"day-time\") {\n          val sign = finalSign(firstSign, secondSign)\n          unit.toUpperCase(Locale.ROOT) match {\n            case \"DAY\" if suffix == null && value.length <= 9 && checkTargetType(DT.DAY, DT.DAY) =>\n              sign * value.toLong * MICROS_PER_DAY"
  },
  {
    "id" : "6a8b5a48-8f2c-4bcd-a8d3-da0685f3718a",
    "prId" : 33231,
    "prUrl" : "https://github.com/apache/spark/pull/33231#pullrequestreview-701142060",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e0a770c5-1fc0-4a3d-b4af-a0696c167d7f",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Do we have tests for MAX_DAY + 1 and MAX_DAY, and for MIN_DAY-1 and MIN_DAY?",
        "createdAt" : "2021-07-07T14:45:54Z",
        "updatedAt" : "2021-07-07T14:51:12Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "765659a3-24a4-4284-b2a6-74eeaa17f102",
        "parentId" : "e0a770c5-1fc0-4a3d-b4af-a0696c167d7f",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "Added in interval.sql",
        "createdAt" : "2021-07-07T15:18:49Z",
        "updatedAt" : "2021-07-07T15:18:49Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "3a569e2db1636d2dcd89a0d877193b335ae7283f",
    "line" : 52,
    "diffHunk" : "@@ -1,1 +410,414 @@      sign: Int): Long = {\n    var micros = 0L\n    val days = toLongWithRange(DAY, dayStr, 0, MAX_DAY).toInt\n    micros = Math.addExact(micros, sign * days * MICROS_PER_DAY)\n    val hours = toLongWithRange(HOUR, hourStr, 0, 23)"
  },
  {
    "id" : "c9fe4d0f-0b77-41ec-b31e-ae697f6cd221",
    "prId" : 33217,
    "prUrl" : "https://github.com/apache/spark/pull/33217#pullrequestreview-699495917",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1cc7fc79-e0fb-4ce3-8fc6-ccb471ba76ce",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Should we add a gap between the two line?\r\nCould you show an example of the error message, please. I just wonder is it readable ...",
        "createdAt" : "2021-07-05T17:59:30Z",
        "updatedAt" : "2021-07-05T18:11:28Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "1f1c1a91-46d3-4439-ad8a-3076610166af",
        "parentId" : "1cc7fc79-e0fb-4ce3-8fc6-ccb471ba76ce",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> Should we add a gap between the two line?\r\n> Could you show an example of the error message, please. I just wonder is it readable ...\r\n\r\n```\r\nInterval string does not match day-time format of `[+|-]d h`, `INTERVAL [+|-]'[+|-]d h' DAY TO HOUR` when cast to interval day to hour: INTERVAL '1 01:01:01.12345' DAY TO SECOND, set spark.sql.legacy.fromDayTimeString.enabled to true to restore the behavior before Spark 3.0.\r\n```",
        "createdAt" : "2021-07-06T02:53:19Z",
        "updatedAt" : "2021-07-06T02:53:19Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "e6bdf8167866183300cc779c0efb61e178ca9939",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +130,134 @@      s\"Interval string does not match $intervalStr format of \" +\n        s\"${supportedFormat((startFiled, endField)).map(format => s\"`$format`\").mkString(\", \")} \" +\n        s\"when cast to $typeName: ${input.toString}\" +\n        s\"${fallBackNotice.map(s => s\", $s\").getOrElse(\"\")}\")\n  }"
  },
  {
    "id" : "2e5bfc11-37ec-4882-b30f-538d3140a5d3",
    "prId" : 33217,
    "prUrl" : "https://github.com/apache/spark/pull/33217#pullrequestreview-699496576",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "61c081d8-ee4c-48f7-8407-b5d62b6e1865",
        "parentId" : null,
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "FYI @MaxGekk rename the parameter make it more clear",
        "createdAt" : "2021-07-06T02:55:15Z",
        "updatedAt" : "2021-07-06T02:55:15Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "e6bdf8167866183300cc779c0efb61e178ca9939",
    "line" : 41,
    "diffHunk" : "@@ -1,1 +139,143 @@      targetEndField: Byte,\n      inputIntervalType: DataType,\n      fallBackNotice: Option[String] = None): Unit = {\n    val (intervalStr, typeName, inputStartField, inputEndField) = inputIntervalType match {\n      case DT(startField, endField) =>"
  },
  {
    "id" : "7dcc8c07-b1c5-44e4-a4db-290a1289f150",
    "prId" : 32940,
    "prUrl" : "https://github.com/apache/spark/pull/32940#pullrequestreview-687481456",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "26a0f00e-cfe1-4e80-b45a-a207f511dda6",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Could you change the error message, please. It should reflect `startField` and `endField`.",
        "createdAt" : "2021-06-17T19:17:30Z",
        "updatedAt" : "2021-06-17T19:25:14Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "7ecac15f-5305-4086-8e2f-109e11b364c8",
        "parentId" : "26a0f00e-cfe1-4e80-b45a-a207f511dda6",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> Could you change the error message, please. It should reflect `startField` and `endField`.\r\n\r\nHow about current?",
        "createdAt" : "2021-06-18T14:38:28Z",
        "updatedAt" : "2021-06-18T14:38:28Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "bb9f055ad27514f574d4bdbe2f91a0a4bf3b43ff",
    "line" : 83,
    "diffHunk" : "@@ -1,1 +177,181 @@          }\n        }\n      case _ => throw new IllegalArgumentException(\n        s\"Interval string does not match year-month format of \" +\n          s\"${supportedFormat((YM.YEAR, YM.MONTH))"
  },
  {
    "id" : "15fa383f-c192-4200-8cc9-dbd07e042263",
    "prId" : 32940,
    "prUrl" : "https://github.com/apache/spark/pull/32940#pullrequestreview-691451928",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2bd85d04-c075-417d-af5f-694373af01e6",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "The regex\r\n```scala\r\n  private val yearMonthLiteralRegex =\r\n    (s\"(?i)^INTERVAL\\\\s+([+|-])?'$yearMonthPatternString'\\\\s+YEAR\\\\s+TO\\\\s+MONTH$$\").r\r\n```\r\ndoesn't support other year-month interval types, for instance `INTERVAL MONTH`. @cloud-fan Again, this is a duplicate of SQL parser logic.",
        "createdAt" : "2021-06-17T19:21:30Z",
        "updatedAt" : "2021-06-17T19:25:14Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "8accd3fe-96ae-4452-8517-58f9a389bf6b",
        "parentId" : "2bd85d04-c075-417d-af5f-694373af01e6",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Let's unify them later",
        "createdAt" : "2021-06-23T08:10:00Z",
        "updatedAt" : "2021-06-23T08:10:00Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "af653e69-25c8-4753-918b-8c97e836bb8e",
        "parentId" : "2bd85d04-c075-417d-af5f-694373af01e6",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "@AngersZhuuuu Could you open JIRA ticket for this, please.",
        "createdAt" : "2021-06-24T07:49:37Z",
        "updatedAt" : "2021-06-24T07:49:37Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "769e5382-1cf4-4935-a90b-0fa8c606f641",
        "parentId" : "2bd85d04-c075-417d-af5f-694373af01e6",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> @AngersZhuuuu Could you open JIRA ticket for this, please.\r\n\r\nSure and will work for ths.",
        "createdAt" : "2021-06-24T08:00:48Z",
        "updatedAt" : "2021-06-24T08:00:48Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "bb9f055ad27514f574d4bdbe2f91a0a4bf3b43ff",
    "line" : 49,
    "diffHunk" : "@@ -1,1 +148,152 @@        checkStringIntervalType(YM.YEAR, YM.MONTH)\n        toYMInterval(year, month, 1)\n      case yearMonthLiteralRegex(firstSign, secondSign, year, month) =>\n        checkStringIntervalType(YM.YEAR, YM.MONTH)\n        toYMInterval(year, month, getSign(firstSign, secondSign))"
  },
  {
    "id" : "c72ad714-24b8-49a2-812a-adaf651f61b4",
    "prId" : 32601,
    "prUrl" : "https://github.com/apache/spark/pull/32601#pullrequestreview-684806678",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d7cbb07e-993c-4bec-a40c-ebca83586a5b",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Should hours (and other fields) be in some range? See the table from the SQL:2016\r\n<img width=\"595\" alt=\"Screenshot 2021-06-14 at 20 41 45\" src=\"https://user-images.githubusercontent.com/1580697/121935371-07b0bb80-cd51-11eb-851d-000c865f99c4.png\">\r\nIf not, please, explain.",
        "createdAt" : "2021-06-14T17:43:43Z",
        "updatedAt" : "2021-06-14T17:45:07Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "3425010b-0bc2-4c3f-b541-c64977c914dc",
        "parentId" : "d7cbb07e-993c-4bec-a40c-ebca83586a5b",
        "authorId" : "924ae4ed-b84b-4216-9852-5db80e7d0e1b",
        "body" : "Well, it's true that the range of fields such as hour breaks SQL:2016. And other interval related functions such as `make_interval` and `make_ym_interval` have same problem. Further more, MySQL and PostgreSQL have same behavior, following is the example of PG:\r\n![image](https://user-images.githubusercontent.com/2949045/122197365-b0cef180-ceca-11eb-81af-4427dc6e55a2.png)\r\n\r\nSo, I think we should keep the consistency with other functions first, and launch a discussion for further decision.\r\nBy the way, could you give me the link of the SQL:2016 image by adding a new comment?",
        "createdAt" : "2021-06-16T09:48:16Z",
        "updatedAt" : "2021-06-17T01:16:00Z",
        "lastEditedBy" : "924ae4ed-b84b-4216-9852-5db80e7d0e1b",
        "tags" : [
        ]
      }
    ],
    "commit" : "b2ab3a08c47129b96ecdd6aa0aca124a370cfbdb",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +871,875 @@    var micros = secs.toUnscaledLong\n    micros = Math.addExact(micros, Math.multiplyExact(days, MICROS_PER_DAY))\n    micros = Math.addExact(micros, Math.multiplyExact(hours, MICROS_PER_HOUR))\n    micros = Math.addExact(micros, Math.multiplyExact(mins, MICROS_PER_MINUTE))\n    micros"
  },
  {
    "id" : "ae91a8bc-2862-45ab-8e6b-5b69759589cf",
    "prId" : 32271,
    "prUrl" : "https://github.com/apache/spark/pull/32271#pullrequestreview-654436695",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ed3c26f9-f89f-40ac-9622-957de1d46e65",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "`unquotedDaySecondRegex`?",
        "createdAt" : "2021-05-07T12:58:59Z",
        "updatedAt" : "2021-05-07T12:58:59Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "c793b794-75e5-4b83-a953-1da002e3c09a",
        "parentId" : "ed3c26f9-f89f-40ac-9622-957de1d46e65",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> `unquotedDaySecondRegex`?\r\n\r\nChange this in https://github.com/apache/spark/pull/32444",
        "createdAt" : "2021-05-07T13:06:37Z",
        "updatedAt" : "2021-05-07T13:06:38Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "4e2608c92809bc1e1e08271c98060592e3861728",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +153,157 @@  private val unquotedDaySecondPattern =\n    \"([+|-])?(\\\\d+) (\\\\d{1,2}):(\\\\d{1,2}):(\\\\d{1,2})(\\\\.\\\\d{1,9})?\"\n  private val quotedDaySecondPattern = (s\"^$unquotedDaySecondPattern$$\").r\n  private val daySecondLiteralPattern =\n    (s\"(?i)^INTERVAL\\\\s+([+|-])?\\\\'$unquotedDaySecondPattern\\\\'\\\\s+DAY\\\\s+TO\\\\s+SECOND$$\").r"
  },
  {
    "id" : "91d1d73a-db28-4927-abbb-81bf5fb4482a",
    "prId" : 32266,
    "prUrl" : "https://github.com/apache/spark/pull/32266#pullrequestreview-646891606",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "31328577-f096-4b4b-af8a-597f8d0f784e",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Now I understand why we need a new version of `fromYearMonthString`, as we need to allow `INTERVAL ... YEAR TO MONTH`. Let's make it clear in the PR description.\r\n\r\nLet's add a new method `castStringToYMInterval`, and define a new regex for it.",
        "createdAt" : "2021-04-27T08:03:51Z",
        "updatedAt" : "2021-04-30T02:48:23Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "c83493dc-6de9-4c19-a058-e0f429824393",
        "parentId" : "31328577-f096-4b4b-af8a-597f8d0f784e",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "Doneï¼Œ how about current?",
        "createdAt" : "2021-04-28T10:27:05Z",
        "updatedAt" : "2021-04-30T02:48:23Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "5ca83abe001897216575fad9f00906de553626c6",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +118,122 @@   * adapted from HiveIntervalYearMonth.valueOf\n   */\n  def fromYearMonthString(input: String): CalendarInterval = {\n    require(input != null, \"Interval year-month string must be not null\")\n    input.trim match {"
  },
  {
    "id" : "e8163b6a-f139-4d8e-919b-09d844047b8a",
    "prId" : 32070,
    "prUrl" : "https://github.com/apache/spark/pull/32070#pullrequestreview-629754020",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e37415a5-9796-4baa-a420-3204b00bf5b1",
        "parentId" : null,
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "nice catch!",
        "createdAt" : "2021-04-07T08:50:27Z",
        "updatedAt" : "2021-04-07T08:50:28Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "0bb44e39ca3060d8217c81b72fdc6dee202a02c1",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +864,868 @@    var rest = micros\n    if (micros < 0) {\n      if (micros == Long.MinValue) {\n        // Especial handling of minimum `Long` value because negate op overflows `Long`.\n        // seconds = 106751991 * (24 * 60 * 60) + 4 * 60 * 60 + 54 = 9223372036854"
  },
  {
    "id" : "16ceaf4b-52ac-45f8-a5f0-99ba59fec630",
    "prId" : 31765,
    "prUrl" : "https://github.com/apache/spark/pull/31765#pullrequestreview-606052999",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a1b178b4-1d55-428d-b2d9-dfd1a29323c0",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Shall we fail if the day field is not 0? Or at least give a warning?",
        "createdAt" : "2021-03-08T07:58:04Z",
        "updatedAt" : "2021-03-08T07:58:05Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "fd5c4f1d-01b1-46c1-a557-769567953599",
        "parentId" : "a1b178b4-1d55-428d-b2d9-dfd1a29323c0",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "We don't fail when we convert:\r\n\r\n1. `java.sql.Date` has time component with millisecond precision but we ignore it when we convert to days at https://github.com/apache/spark/blob/56e664c7179eadeb5134b4418f3aaa6a9d742ef6/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/util/DateTimeUtils.scala#L93\r\n2. `java.sql.Timestamp` which has nanoseconds precision: https://github.com/apache/spark/blob/56e664c7179eadeb5134b4418f3aaa6a9d742ef6/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/util/DateTimeUtils.scala#L166\r\n3. `java.time.Instant` which contains nanoseconds, and we don't fail when we convert it to microseconds: https://github.com/apache/spark/blob/56e664c7179eadeb5134b4418f3aaa6a9d742ef6/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/util/DateTimeUtils.scala#L383\r\n\r\nTo be consistent with current implementation for other types, I do believe we should not fail.\r\n\r\n> Or at least give a warning?\r\n\r\nThis will just fill in the logs by useless records, and this is again inconsistent with current implementation.",
        "createdAt" : "2021-03-08T08:23:50Z",
        "updatedAt" : "2021-03-08T08:26:46Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "c22e01ed0e66a959619cfcb2b2dc253786512971",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +803,807 @@   * @throws ArithmeticException If numeric overflow occurs\n   */\n  def periodToMonths(period: Period): Int = {\n    val monthsInYears = Math.multiplyExact(period.getYears, MONTHS_PER_YEAR)\n    Math.addExact(monthsInYears, period.getMonths)"
  },
  {
    "id" : "488360ba-14b1-4b79-8bea-b8062df2534c",
    "prId" : 28886,
    "prUrl" : "https://github.com/apache/spark/pull/28886#pullrequestreview-435690739",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1659c22c-c2ef-41f0-894c-5e6c8cc397a3",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "shall we check the precision as well?",
        "createdAt" : "2020-06-23T06:47:52Z",
        "updatedAt" : "2020-06-23T06:47:53Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "a497622d-1221-46c5-af04-11250c8fecc6",
        "parentId" : "1659c22c-c2ef-41f0-894c-5e6c8cc397a3",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "We can check it but `precision` value is not important for this code...or I am wrong?",
        "createdAt" : "2020-06-23T07:01:42Z",
        "updatedAt" : "2020-06-23T07:01:42Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "5888e9d2-b775-4456-9013-b205484a3ca9",
        "parentId" : "1659c22c-c2ef-41f0-894c-5e6c8cc397a3",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "So, `Decimal` guarantees that `precision` >= `scale` (@Ngone51 correct?). That's enough for the code.",
        "createdAt" : "2020-06-23T07:40:10Z",
        "updatedAt" : "2020-06-23T07:40:11Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "31c888cd-393d-4329-b7c6-f7ba16f8d486",
        "parentId" : "1659c22c-c2ef-41f0-894c-5e6c8cc397a3",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Technically, I think we should say `DecimalType`  guarantees `precision` >= `scale`. But since any `Decimal` is directly or indirectly bounded with a `DecimalType`. Therefore, `Decimal` also guarantees `precision` >= `scale`.",
        "createdAt" : "2020-06-23T08:11:00Z",
        "updatedAt" : "2020-06-23T08:11:01Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "4b8b82e7-e99a-4ebc-b00c-bc7fa04c23df",
        "parentId" : "1659c22c-c2ef-41f0-894c-5e6c8cc397a3",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I just want to be consistent with https://github.com/apache/spark/pull/28886/files#diff-b83497f7bc11578a0b63a814a2a30f48R2003",
        "createdAt" : "2020-06-23T09:12:27Z",
        "updatedAt" : "2020-06-23T09:12:27Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "5681e0d3-dc04-4cf7-b6fa-4c7e3efdb308",
        "parentId" : "1659c22c-c2ef-41f0-894c-5e6c8cc397a3",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "I added assert there to guarantee that Int will not overflow. What would you like to assert here?",
        "createdAt" : "2020-06-23T09:16:01Z",
        "updatedAt" : "2020-06-23T09:16:01Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "8ab60cb1-e869-4bb6-a4e4-373a2579218c",
        "parentId" : "1659c22c-c2ef-41f0-894c-5e6c8cc397a3",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "for sanity check? The `precision` must be `<= 8` here, right?",
        "createdAt" : "2020-06-23T11:26:44Z",
        "updatedAt" : "2020-06-23T11:26:44Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "dd570fa2-2834-4ff8-a231-c6be761bd65a",
        "parentId" : "1659c22c-c2ef-41f0-894c-5e6c8cc397a3",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Not anymore, please, take a look at https://github.com/apache/spark/pull/28873 and https://issues.apache.org/jira/browse/SPARK-32021",
        "createdAt" : "2020-06-23T11:31:22Z",
        "updatedAt" : "2020-06-23T11:32:17Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "b9e2ee097bdbe6c6ff1d5680025ade7cc9fca9e7",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +752,756 @@    val totalMonths = Math.addExact(months, Math.multiplyExact(years, MONTHS_PER_YEAR))\n    val totalDays = Math.addExact(days, Math.multiplyExact(weeks, DAYS_PER_WEEK))\n    assert(secs.scale == 6, \"Seconds fractional must have 6 digits for microseconds\")\n    var micros = secs.toUnscaledLong\n    micros = Math.addExact(micros, Math.multiplyExact(hours, MICROS_PER_HOUR))"
  },
  {
    "id" : "f66250d7-8965-4890-9411-64580816663a",
    "prId" : 26995,
    "prUrl" : "https://github.com/apache/spark/pull/26995#pullrequestreview-336687245",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "87d53853-900c-46fa-8286-d8978aa9bab1",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ah, seems better to follow the java naming conversion: `negate` and `negateExact`. ",
        "createdAt" : "2019-12-27T06:27:38Z",
        "updatedAt" : "2020-01-02T09:09:38Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "895373be-7d9e-498b-9b93-f39cf3c8a46c",
        "parentId" : "87d53853-900c-46fa-8286-d8978aa9bab1",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "sgtm",
        "createdAt" : "2019-12-27T07:01:46Z",
        "updatedAt" : "2020-01-02T09:09:38Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "f80f0f37c0e26eba797ee9ab047e7df3ec4ffb1f",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +422,426 @@   */\n  def negateExact(interval: CalendarInterval): CalendarInterval = {\n    val months = Math.negateExact(interval.months)\n    val days = Math.negateExact(interval.days)\n    val microseconds = Math.negateExact(interval.microseconds)"
  },
  {
    "id" : "70cd0b7e-6bd7-4962-825a-482e73040d5c",
    "prId" : 26573,
    "prUrl" : "https://github.com/apache/spark/pull/26573#pullrequestreview-318840455",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "18495ccd-437e-4c35-8dbb-60eb9298359d",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "do we still need it now?",
        "createdAt" : "2019-11-19T08:02:37Z",
        "updatedAt" : "2019-11-19T08:02:37Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "f6b0edd79aac4c415afc1bad3ca3c9cd6cf21cbc",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +506,510 @@    var microseconds: Long = 0\n    var fractionScale: Int = 0\n    val initialFractionScale = (NANOS_PER_SECOND / 10).toInt\n    var fraction: Int = 0\n    var pointPrefixed: Boolean = false"
  },
  {
    "id" : "99a01b35-9bef-43e1-8266-240114cb0365",
    "prId" : 26573,
    "prUrl" : "https://github.com/apache/spark/pull/26573#pullrequestreview-318847648",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d35b178c-4b6c-4af5-8c28-a777806d888d",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "since `1.` is allowed, I don't think `fractionScale < initialFractionScale` is a valid check any more.",
        "createdAt" : "2019-11-19T08:03:20Z",
        "updatedAt" : "2019-11-19T08:03:21Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "2f2666a2-7c2a-4121-bba9-d915c1e5550a",
        "parentId" : "d35b178c-4b6c-4af5-8c28-a777806d888d",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "we need this, the cases are (`1.0`, `0.1`, `.1`,  `1.`) + (`.`), this condition is equal to `!(pointPrefixed && fractionScale == initialFractionScale)`",
        "createdAt" : "2019-11-19T08:10:30Z",
        "updatedAt" : "2019-11-19T08:10:30Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "d0fb8579-5072-4f72-8a30-2dc77ab98bb9",
        "parentId" : "d35b178c-4b6c-4af5-8c28-a777806d888d",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "rm `fractionScale < initialFractionScale` forbiding `.1` case",
        "createdAt" : "2019-11-19T08:11:32Z",
        "updatedAt" : "2019-11-19T08:11:32Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "daf92ce4-c3fe-4c07-9fab-b8c6e2c12b1f",
        "parentId" : "d35b178c-4b6c-4af5-8c28-a777806d888d",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ah i see!",
        "createdAt" : "2019-11-19T08:16:59Z",
        "updatedAt" : "2019-11-19T08:16:59Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "f6b0edd79aac4c415afc1bad3ca3c9cd6cf21cbc",
    "line" : 42,
    "diffHunk" : "@@ -1,1 +587,591 @@              fraction += (b - '0') * fractionScale\n              fractionScale /= 10\n            case ' ' if !pointPrefixed || fractionScale < initialFractionScale =>\n              fraction /= NANOS_PER_MICROS.toInt\n              state = TRIM_BEFORE_UNIT"
  },
  {
    "id" : "987f07ad-fe7a-4b37-a143-30a64ea37944",
    "prId" : 26572,
    "prUrl" : "https://github.com/apache/spark/pull/26572#pullrequestreview-318293183",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bf486f4b-e1a2-4eb2-ada6-f909545de626",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "probably add a comment saying that the `toString` implementation is the multi-units format.",
        "createdAt" : "2019-11-18T12:26:33Z",
        "updatedAt" : "2019-11-19T00:10:16Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "eefd45733435f7afa851449605bbaf7d18ccf9e8",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +334,338 @@\n  // `toString` implementation in CalendarInterval is the multi-units format currently.\n  def toMultiUnitsString(interval: CalendarInterval): String = interval.toString\n\n  def toSqlStandardString(interval: CalendarInterval): String = {"
  },
  {
    "id" : "e9e684bf-c806-47ea-b1f9-09e6fdf759cf",
    "prId" : 26514,
    "prUrl" : "https://github.com/apache/spark/pull/26514#pullrequestreview-316978590",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dac02fae-9614-4292-bbfc-54fd313bbb43",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "The comment is useless from my point of view. It describes what is obvious from the code but does not say why.",
        "createdAt" : "2019-11-14T09:11:40Z",
        "updatedAt" : "2019-11-14T14:17:54Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "8a362d36-cf87-484f-ba83-b726167afdc9",
        "parentId" : "dac02fae-9614-4292-bbfc-54fd313bbb43",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "agree. @yaooqinn can you refine the comments to explain why? We should mention that it's to support `.1 second`",
        "createdAt" : "2019-11-14T12:54:13Z",
        "updatedAt" : "2019-11-14T14:17:54Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "cfc509e6-4e25-486f-af55-32735309b831",
        "parentId" : "dac02fae-9614-4292-bbfc-54fd313bbb43",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "OK",
        "createdAt" : "2019-11-14T14:09:13Z",
        "updatedAt" : "2019-11-14T14:17:54Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "76ba7ef9eff79276d6e4099527ce231fe8e60d6f",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +499,503 @@          currentValue = 0\n          fraction = 0\n          // We preset next state from SIGN to TRIM_BEFORE_VALUE. If we meet '.' in the SIGN state,\n          // it means that the interval value we deal with here is a numeric with only fractional\n          // part, such as '.11 second', which can be parsed to 0.11 seconds. In this case, we need"
  },
  {
    "id" : "7641a9b7-a849-4a00-9cdf-a379da32445c",
    "prId" : 26455,
    "prUrl" : "https://github.com/apache/spark/pull/26455#pullrequestreview-314578065",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ea653413-f257-4716-8eb3-8b8581f4c2ae",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "This may be an old idea, but I thought the java Enum class was the preferred way to define enums in scala, even? ",
        "createdAt" : "2019-11-09T20:52:18Z",
        "updatedAt" : "2019-11-10T07:23:30Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "c89aab5f-7a2c-40fe-8064-b432d2ecf2ca",
        "parentId" : "ea653413-f257-4716-8eb3-8b8581f4c2ae",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "I haven't found this requirement in the Scala coding guide. Where does it come from (do you have some links for related discussions)?",
        "createdAt" : "2019-11-09T20:58:52Z",
        "updatedAt" : "2019-11-10T07:23:30Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "da79ad9d-e32a-4c57-9fb9-b681867ecbae",
        "parentId" : "ea653413-f257-4716-8eb3-8b8581f4c2ae",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "At least, there are 46 places where Scala's `Numeration` is used:\r\n```shell\r\n$ find . -name \"*.scala\" -print0|xargs -0 grep -n 'extends Enumeration'|wc -l\r\n      46\r\n```",
        "createdAt" : "2019-11-09T21:04:57Z",
        "updatedAt" : "2019-11-10T07:23:30Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "994679d5-802d-434a-8f99-433da3c8d824",
        "parentId" : "ea653413-f257-4716-8eb3-8b8581f4c2ae",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "It's stuff like: https://groups.google.com/forum/#!topic/scala-internals/8RWkccSRBxQ%5B1-25%5D\r\n\r\nBut indeed we use scala.Enumeration widely, and I think the issues crop up when interoperating with Java, or in more obscure cases. I think it's fine here.",
        "createdAt" : "2019-11-09T21:13:29Z",
        "updatedAt" : "2019-11-10T07:23:30Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      }
    ],
    "commit" : "1667a330dbe5634b3ee7c476d87b5e93901cc159",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +29,33 @@object IntervalUtils {\n\n  object IntervalUnit extends Enumeration {\n    type IntervalUnit = Value\n"
  },
  {
    "id" : "245492a5-9854-443f-bc44-5a1f02224bad",
    "prId" : 26455,
    "prUrl" : "https://github.com/apache/spark/pull/26455#pullrequestreview-314577355",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9646a356-6421-4ff0-8ec5-16f41d236b49",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "This is intended to be internal only?",
        "createdAt" : "2019-11-09T20:52:42Z",
        "updatedAt" : "2019-11-10T07:23:30Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "70bb9ec8-8629-4a99-a69a-662baacbcc9f",
        "parentId" : "9646a356-6421-4ff0-8ec5-16f41d236b49",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "yes",
        "createdAt" : "2019-11-09T20:54:00Z",
        "updatedAt" : "2019-11-10T07:23:30Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "1667a330dbe5634b3ee7c476d87b5e93901cc159",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +29,33 @@object IntervalUtils {\n\n  object IntervalUnit extends Enumeration {\n    type IntervalUnit = Value\n"
  },
  {
    "id" : "3fd4096d-98d5-41df-95e5-47d6e4b03e1a",
    "prId" : 26418,
    "prUrl" : "https://github.com/apache/spark/pull/26418#pullrequestreview-313184441",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a68da6c8-d00c-475f-9cbb-04e95b3659e8",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "we can move `CalendarInterval.toString` to here with name `toMultiUnitsString`. `CalendarInterval.toString` should be as simple as `CalendarInterval(months = ..., days = ..., microseconds = ...)`",
        "createdAt" : "2019-11-07T08:47:30Z",
        "updatedAt" : "2019-11-16T15:45:17Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "f046f556-2d30-43dc-9d87-a82d1becca5e",
        "parentId" : "a68da6c8-d00c-475f-9cbb-04e95b3659e8",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "We can do it in a followup",
        "createdAt" : "2019-11-07T08:47:42Z",
        "updatedAt" : "2019-11-16T15:45:17Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "f6755364-9d93-430e-ac5c-165ac715a60d",
        "parentId" : "a68da6c8-d00c-475f-9cbb-04e95b3659e8",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "Yea sounds great",
        "createdAt" : "2019-11-07T08:51:40Z",
        "updatedAt" : "2019-11-16T15:45:17Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "0f54af89b8641ee7df80991dcca63e183a03d5ff",
    "line" : 41,
    "diffHunk" : "@@ -1,1 +455,459 @@  }\n\n  def toSqlStandardString(interval: CalendarInterval): String = {\n    val yearMonthPart = if (interval.months < 0) {\n      val ma = math.abs(interval.months)"
  },
  {
    "id" : "31445e85-a5a9-4fa3-8a08-7256918a9d6f",
    "prId" : 26418,
    "prUrl" : "https://github.com/apache/spark/pull/26418#pullrequestreview-315964671",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4f8e084d-9910-4c45-ab6e-24e1778550ac",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "shouldn't we add `-`?",
        "createdAt" : "2019-11-12T16:52:34Z",
        "updatedAt" : "2019-11-16T15:45:17Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "c8800b79-347a-4839-a2b1-347f1775e33b",
        "parentId" : "4f8e084d-9910-4c45-ab6e-24e1778550ac",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "yes it is likely `-1.toString` here",
        "createdAt" : "2019-11-13T02:17:59Z",
        "updatedAt" : "2019-11-16T15:45:17Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "0f54af89b8641ee7df80991dcca63e183a03d5ff",
    "line" : 52,
    "diffHunk" : "@@ -1,1 +466,470 @@\n    val dayPart = if (interval.days < 0) {\n      interval.days.toString\n    } else if (interval.days > 0) {\n      \"+\" + interval.days"
  },
  {
    "id" : "a399e4c4-a7e3-4cf9-bac4-8a928014e425",
    "prId" : 26418,
    "prUrl" : "https://github.com/apache/spark/pull/26418#pullrequestreview-315964107",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "db839705-dc37-43a8-9a40-f5df9aa15514",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "wow, a single `0` is also SQL standard?",
        "createdAt" : "2019-11-12T16:54:41Z",
        "updatedAt" : "2019-11-16T15:45:17Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "c1939bf2-08ca-4d56-a90c-d1a70c7523d4",
        "parentId" : "db839705-dc37-43a8-9a40-f5df9aa15514",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "```sql\r\npostgres=# set IntervalStyle=sql_standard;\r\nSET\r\npostgres=# select interval '0';\r\n interval\r\n----------\r\n 0\r\n(1 row)\r\n\r\npostgres=# set IntervalStyle=postgres;\r\nSET\r\npostgres=# select interval '0';\r\n interval\r\n----------\r\n 00:00:00\r\n(1 row)\r\n```",
        "createdAt" : "2019-11-13T02:15:59Z",
        "updatedAt" : "2019-11-16T15:45:17Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "0f54af89b8641ee7df80991dcca63e183a03d5ff",
    "line" : 85,
    "diffHunk" : "@@ -1,1 +499,503 @@\n    val intervalList = Seq(yearMonthPart, dayPart, timePart).filter(_.nonEmpty)\n    if (intervalList.nonEmpty) intervalList.mkString(\" \") else \"0\"\n  }\n"
  },
  {
    "id" : "d164bb7d-0ff8-4159-8b75-0eace02493e8",
    "prId" : 26410,
    "prUrl" : "https://github.com/apache/spark/pull/26410#pullrequestreview-312502803",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a03cdba2-3543-4eef-a827-baab72788d2f",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "we should move `add`, `subtract`, `negate` to `IntervalUtils` as well. Maybe we need to change the overflow behavior later on.\r\n\r\n@yaooqinn can you do this later?",
        "createdAt" : "2019-11-06T14:31:16Z",
        "updatedAt" : "2019-11-06T14:31:16Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "9f485e82-b3ee-4b32-ba12-e75b9e6b7ef6",
        "parentId" : "a03cdba2-3543-4eef-a827-baab72788d2f",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "Yes, I am willing to do this, thanks.",
        "createdAt" : "2019-11-06T15:07:51Z",
        "updatedAt" : "2019-11-06T15:07:51Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "550e4dd9b6e5da42dd42f3286512c5088eb582b9",
    "line" : 3,
    "diffHunk" : "@@ -1,1 +386,390 @@  }\n\n  def divide(interval: CalendarInterval, num: Double): CalendarInterval = {\n    if (num == 0) throw new java.lang.ArithmeticException(\"divide by zero\")\n    fromDoubles(interval.months / num, interval.days / num, interval.microseconds / num)"
  },
  {
    "id" : "0a405bab-7b80-415c-b2ef-833f315e1969",
    "prId" : 26314,
    "prUrl" : "https://github.com/apache/spark/pull/26314#pullrequestreview-309189509",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "75fb7235-5b86-4634-87f9-d2ed637372cf",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This looks like a new feature to me. Can we fix the bug first and then propose new features?",
        "createdAt" : "2019-10-30T09:14:34Z",
        "updatedAt" : "2019-10-31T08:14:45Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "7fa4a4da-7e20-43a1-81ed-1f7caab1ffe4",
        "parentId" : "75fb7235-5b86-4634-87f9-d2ed637372cf",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "+1 for @cloud-fan 's comment.",
        "createdAt" : "2019-10-30T09:16:42Z",
        "updatedAt" : "2019-10-31T08:14:45Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "5d4b0b75-e64c-42b0-a29a-b7a79dbf126b",
        "parentId" : "75fb7235-5b86-4634-87f9-d2ed637372cf",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "OK, I will fix the bug first, a followup for [SPARK-29532]? or do we need a jira to track?",
        "createdAt" : "2019-10-30T09:22:28Z",
        "updatedAt" : "2019-10-31T08:14:45Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "c3590967-41eb-441b-abac-daccb442e6bf",
        "parentId" : "75fb7235-5b86-4634-87f9-d2ed637372cf",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Yes. A follow-up for the original JIRA.",
        "createdAt" : "2019-10-30T09:42:21Z",
        "updatedAt" : "2019-10-31T08:14:45Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "8b2f91ec-fae9-4fa2-8ce5-ae11e2a3c7a4",
        "parentId" : "75fb7235-5b86-4634-87f9-d2ed637372cf",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "Sorry, I already create a new Jira in a hurry. also, this line may not blame to SPARK-29532",
        "createdAt" : "2019-10-30T09:55:12Z",
        "updatedAt" : "2019-10-31T08:14:45Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "39e1733f-f68b-4c56-aad8-cd9b800ee14c",
        "parentId" : "75fb7235-5b86-4634-87f9-d2ed637372cf",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "I'd just make a follow-up PR to the other JIRA to fix the bug.",
        "createdAt" : "2019-10-30T13:17:14Z",
        "updatedAt" : "2019-10-31T08:14:45Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      }
    ],
    "commit" : "b071e09a2914dcfb566112cb77d8e187ab0d5a7b",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +257,261 @@        units(i) match {\n          case \"year\" =>\n            months = new BigDecimal(values(i)).multiply(new BigDecimal(MONTHS_PER_YEAR))\n              .setScale(0, RoundingMode.DOWN)\n              .intValueExact"
  },
  {
    "id" : "a3c22886-359d-4783-aaec-383fe026641c",
    "prId" : 26261,
    "prUrl" : "https://github.com/apache/spark/pull/26261#pullrequestreview-307500427",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "998d3f04-6d58-49d2-9bb3-6a22e50d13c8",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "nit. redundant empty line.",
        "createdAt" : "2019-10-26T00:35:02Z",
        "updatedAt" : "2019-10-28T19:03:08Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "38f7c78e51ed4a19a24aee6aca08fc58dd101f20",
    "line" : 198,
    "diffHunk" : "@@ -1,1 +307,311 @@      toLongWithRange(\"nanosecond\", nanosStr, 0L, 999999999L) / DateTimeUtils.NANOS_PER_MICROS\n    }\n\n    secondNano.split(\"\\\\.\") match {\n      case Array(secondsStr) => parseSeconds(secondsStr)"
  },
  {
    "id" : "5d3443ea-75e2-4eb5-9f1e-f5d0a09fa2fc",
    "prId" : 26256,
    "prUrl" : "https://github.com/apache/spark/pull/26256#pullrequestreview-307517589",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f0df62bd-5b49-41db-b256-f8ceda2e2f90",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "I know you added `final` for performance reasons, but do we have actual performance diffs of the benchmarks below with/without this `final`? (Just out of curiosity...",
        "createdAt" : "2019-10-26T02:42:27Z",
        "updatedAt" : "2019-11-06T18:14:14Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "fb3bed4b-86ff-49ee-87c6-3179972f9f98",
        "parentId" : "f0df62bd-5b49-41db-b256-f8ceda2e2f90",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "I re-ran `IntervalBenchmark` without `final`s, there is no difference, actually. ",
        "createdAt" : "2019-10-26T08:39:19Z",
        "updatedAt" : "2019-11-06T18:14:14Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "2222f13f8c83de2fec995746541096bf988fa65e",
    "line" : 41,
    "diffHunk" : "@@ -1,1 +410,414 @@  private final val secondStr = UTF8String.fromString(\"second\")\n  private final val millisStr = UTF8String.fromString(\"millisecond\")\n  private final val microsStr = UTF8String.fromString(\"microsecond\")\n\n  def stringToInterval(input: UTF8String): CalendarInterval = {"
  },
  {
    "id" : "95ef4fc9-a9cf-4146-9e48-f8d801ed5d7f",
    "prId" : 26256,
    "prUrl" : "https://github.com/apache/spark/pull/26256#pullrequestreview-307696066",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cc93d324-4fbd-4947-9ccc-7511e3db32d3",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "We can simplify it if we don't allow leading \"interval\"",
        "createdAt" : "2019-10-28T08:34:03Z",
        "updatedAt" : "2019-11-06T18:14:14Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "2222f13f8c83de2fec995746541096bf988fa65e",
    "line" : 70,
    "diffHunk" : "@@ -1,1 +439,443 @@      state match {\n        case PREFIX =>\n          if (s.startsWith(intervalStr)) {\n            if (s.numBytes() == intervalStr.numBytes()) {\n              return null"
  },
  {
    "id" : "ccfe4f6c-b272-470e-8b8e-c4abb79451f9",
    "prId" : 26256,
    "prUrl" : "https://github.com/apache/spark/pull/26256#pullrequestreview-312379668",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c2b58b22-2bb5-40dc-ba95-be789191d2b5",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "how about `1. hour` and `1. second`?",
        "createdAt" : "2019-11-06T11:24:04Z",
        "updatedAt" : "2019-11-06T18:14:14Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "c9b1be16-0224-4e5a-868d-02dd800aba30",
        "parentId" : "c2b58b22-2bb5-40dc-ba95-be789191d2b5",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "```sql\r\nspark-sql> select cast('1. seconds' as interval);\r\ninterval 1 seconds\r\nspark-sql> select cast('1. days' as interval);\r\ninterval 1 days\r\n```",
        "createdAt" : "2019-11-06T12:01:34Z",
        "updatedAt" : "2019-11-06T18:14:14Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "2222f13f8c83de2fec995746541096bf988fa65e",
    "line" : 122,
    "diffHunk" : "@@ -1,1 +491,495 @@              fraction += (b - '0') * fractionScale\n              fractionScale /= 10\n            case ' ' =>\n              fraction /= DateTimeUtils.NANOS_PER_MICROS.toInt\n              state = BEGIN_UNIT_NAME"
  },
  {
    "id" : "7f9b1ab3-2094-455d-952c-64c18433affa",
    "prId" : 26190,
    "prUrl" : "https://github.com/apache/spark/pull/26190#pullrequestreview-304574639",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7e5790da-506f-4cd0-8abe-b5805586f64e",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "not related, but we should use final to declare constant, for sure.",
        "createdAt" : "2019-10-21T08:55:08Z",
        "updatedAt" : "2019-10-24T05:40:30Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "7f5f2372-b743-4457-8b9c-2c180c4d2df1",
        "parentId" : "7e5790da-506f-4cd0-8abe-b5805586f64e",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "It's already read-only; this ensures it can't be overridden in a subclass?",
        "createdAt" : "2019-10-21T13:31:24Z",
        "updatedAt" : "2019-10-24T05:40:30Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "7b5edf5d-7543-4943-aaa3-05613e455eb0",
        "parentId" : "7e5790da-506f-4cd0-8abe-b5805586f64e",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "AFAIK `final` is better for performance. The compiled byte code would contain the constant directly instead of variable.",
        "createdAt" : "2019-10-21T13:49:05Z",
        "updatedAt" : "2019-10-24T05:40:30Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "48b7ef4c42c2bf98ffda16e77e2ef10bd78f5d9f",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +35,39 @@  final val MICROS_PER_MONTH: Long = DAYS_PER_MONTH * DateTimeUtils.SECONDS_PER_DAY\n  /* 365.25 days per year assumes leap year every four years */\n  final val MICROS_PER_YEAR: Long = (36525L * DateTimeUtils.MICROS_PER_DAY) / 100\n\n  def getYears(interval: CalendarInterval): Int = {"
  },
  {
    "id" : "15ba322d-b27b-4992-819b-ebcaa045f33d",
    "prId" : 26190,
    "prUrl" : "https://github.com/apache/spark/pull/26190#pullrequestreview-305690442",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "73c65320-f119-4f61-b517-125ce3e1977c",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Can `IllegalArgumentException` come to here from `fromUnitString`?",
        "createdAt" : "2019-10-23T06:57:29Z",
        "updatedAt" : "2019-10-24T05:40:30Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "4e6bb37a-4f36-45da-a929-3936ae846770",
        "parentId" : "73c65320-f119-4f61-b517-125ce3e1977c",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "after the fix, only parser exception can be thrown now.",
        "createdAt" : "2019-10-23T07:47:32Z",
        "updatedAt" : "2019-10-24T05:40:30Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "48b7ef4c42c2bf98ffda16e77e2ef10bd78f5d9f",
    "line" : 49,
    "diffHunk" : "@@ -1,1 +102,106 @@    try {\n      CatalystSqlParser.parseInterval(str)\n    } catch {\n      case e: ParseException =>\n        val ex = new IllegalArgumentException(s\"Invalid interval string: $str\\n\" + e.message)"
  },
  {
    "id" : "90686ce8-8dce-4022-bd87-42639cdceb12",
    "prId" : 26190,
    "prUrl" : "https://github.com/apache/spark/pull/26190#pullrequestreview-305658359",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bf89580b-6f83-45fc-8a8d-0889d085587b",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "`case NonFatal(e) =>`?",
        "createdAt" : "2019-10-23T06:58:32Z",
        "updatedAt" : "2019-10-24T05:40:30Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "48b7ef4c42c2bf98ffda16e77e2ef10bd78f5d9f",
    "line" : 50,
    "diffHunk" : "@@ -1,1 +103,107 @@      CatalystSqlParser.parseInterval(str)\n    } catch {\n      case e: ParseException =>\n        val ex = new IllegalArgumentException(s\"Invalid interval string: $str\\n\" + e.message)\n        ex.setStackTrace(e.getStackTrace)"
  },
  {
    "id" : "5e84b1e4-d7ca-403b-8c3f-57c13c724dca",
    "prId" : 26190,
    "prUrl" : "https://github.com/apache/spark/pull/26190#pullrequestreview-306031116",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "db98ce72-2371-4750-9260-1bd07fcc0157",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "How about keeping the method comment of `fromCaseInsensitiveString` above?",
        "createdAt" : "2019-10-23T13:51:58Z",
        "updatedAt" : "2019-10-24T05:40:30Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "9be28187-81f5-40f0-a84e-af5c08e21211",
        "parentId" : "db98ce72-2371-4750-9260-1bd07fcc0157",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "done",
        "createdAt" : "2019-10-23T16:36:42Z",
        "updatedAt" : "2019-10-24T05:40:30Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "48b7ef4c42c2bf98ffda16e77e2ef10bd78f5d9f",
    "line" : 45,
    "diffHunk" : "@@ -1,1 +98,102 @@   * @throws IllegalArgumentException if the input string is not in valid interval format.\n   */\n  def fromString(str: String): CalendarInterval = {\n    if (str == null) throw new IllegalArgumentException(\"Interval string cannot be null\")\n    try {"
  },
  {
    "id" : "3bf1570f-1725-4f6c-b85d-b7c65eb5c764",
    "prId" : 26190,
    "prUrl" : "https://github.com/apache/spark/pull/26190#pullrequestreview-305907077",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1a40c1b2-d054-4462-a190-2b0d0fc6ea98",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "ditto: keeps the comment as much as possible?",
        "createdAt" : "2019-10-23T13:52:23Z",
        "updatedAt" : "2019-10-24T05:40:30Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "48b7ef4c42c2bf98ffda16e77e2ef10bd78f5d9f",
    "line" : 60,
    "diffHunk" : "@@ -1,1 +113,117 @@   * A safe version of `fromString`. It returns null for invalid input string.\n   */\n  def safeFromString(str: String): CalendarInterval = {\n    try {\n      fromString(str)"
  },
  {
    "id" : "1cdbe334-7cb5-4cdc-bd69-2c71ca632a15",
    "prId" : 26190,
    "prUrl" : "https://github.com/apache/spark/pull/26190#pullrequestreview-309045746",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "70222188-2abf-4ac0-be0a-2cf89c2beaa5",
        "parentId" : null,
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "`MICROS_PER_MONTH` is wrong here, which should be `DAYS_PER_MONTH * DateTimeUtils. MICROS_PER_DAY` I will fix this in https://github.com/apache/spark/pull/26314 ",
        "createdAt" : "2019-10-30T09:04:52Z",
        "updatedAt" : "2019-10-30T09:04:53Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "48b7ef4c42c2bf98ffda16e77e2ef10bd78f5d9f",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +33,37 @@    DateTimeUtils.MILLIS_PER_MINUTE * DateTimeUtils.MICROS_PER_MILLIS\n  final val DAYS_PER_MONTH: Byte = 30\n  final val MICROS_PER_MONTH: Long = DAYS_PER_MONTH * DateTimeUtils.SECONDS_PER_DAY\n  /* 365.25 days per year assumes leap year every four years */\n  final val MICROS_PER_YEAR: Long = (36525L * DateTimeUtils.MICROS_PER_DAY) / 100"
  },
  {
    "id" : "68842a1b-1c40-4e1e-a1ba-55373d39e189",
    "prId" : 26177,
    "prUrl" : "https://github.com/apache/spark/pull/26177#pullrequestreview-307316576",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "11152cb6-0049-445f-b38c-f1cdd9e8f0ae",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "where do we specify `daysPerMonth`?",
        "createdAt" : "2019-10-25T15:24:25Z",
        "updatedAt" : "2019-10-29T18:56:41Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "6ecdbfbf-48a6-44a4-aa06-be260f68c078",
        "parentId" : "11152cb6-0049-445f-b38c-f1cdd9e8f0ae",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Are there any other places we need to get a duration of interval except for stream watermark? If not I think it's simpler to call it `getDurationForWaterwark`, and explain why we pick 1 month = 31 days, according to https://github.com/apache/spark/pull/16304#discussion_r92753590",
        "createdAt" : "2019-10-25T15:29:34Z",
        "updatedAt" : "2019-10-29T18:56:41Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "aacbf7c1-70ac-4d35-9456-9d60cdf31817",
        "parentId" : "11152cb6-0049-445f-b38c-f1cdd9e8f0ae",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "What do you propose is ad-hoc interface which solves current issue only. I don't like it because it makes interval interface not reusable.\r\n- Next time when we need durations in another place, are you going to add `getDurationForAnotherPlace1`?\r\n- If someone will need a duration with 31 days per month for different purpose but not for watermarks, he/she cannot use it even in Structured Streaming.",
        "createdAt" : "2019-10-25T16:01:20Z",
        "updatedAt" : "2019-10-29T18:56:41Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "bded2d25-4c36-4afd-9be1-4c0adc5462ad",
        "parentId" : "11152cb6-0049-445f-b38c-f1cdd9e8f0ae",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "From my understanding, a watermark has type of `TIMESTAMP` semantically but not `INTERVAL`. Probably, it can be even negative. If to rename the method, it could `getDurationOfDelay` or `getDurationOfTimeout` (or following your proposal `getDurationOfDelayForEventTimeWatermark` or `getDurationOfTimeoutForGroupState`)",
        "createdAt" : "2019-10-25T16:26:37Z",
        "updatedAt" : "2019-10-29T18:56:41Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "edad25e70cb07319acc4235b603fc5cd16ed2433",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +334,338 @@      interval: CalendarInterval,\n      targetUnit: TimeUnit,\n      daysPerMonth: Int = 31): Long = {\n    val monthsDuration = Math.multiplyExact(\n      daysPerMonth * DateTimeUtils.MICROS_PER_DAY,"
  },
  {
    "id" : "173bc68b-56e9-4b3d-8b22-3a0a0871002e",
    "prId" : 26177,
    "prUrl" : "https://github.com/apache/spark/pull/26177#pullrequestreview-307854955",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0256cbba-ff0f-433b-819f-a3e40c44132b",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Then we can remove the default value? The caller side should explicitly specify that it wants 31 days per month and why.",
        "createdAt" : "2019-10-28T08:18:34Z",
        "updatedAt" : "2019-10-29T18:56:41Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "00b2e459-5a85-4fec-b190-a739d1e6a30a",
        "parentId" : "0256cbba-ff0f-433b-819f-a3e40c44132b",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "I suggested the default as that is the only value used now. I think callers that specify otherwise can explain why (later)",
        "createdAt" : "2019-10-28T13:34:10Z",
        "updatedAt" : "2019-10-29T18:56:41Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "fe340c89-14dc-468b-9af0-5e5b07e6edcc",
        "parentId" : "0256cbba-ff0f-433b-819f-a3e40c44132b",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "then at least we need to explain why 31 is picked as the default value",
        "createdAt" : "2019-10-28T13:43:54Z",
        "updatedAt" : "2019-10-29T18:56:41Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "edad25e70cb07319acc4235b603fc5cd16ed2433",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +334,338 @@      interval: CalendarInterval,\n      targetUnit: TimeUnit,\n      daysPerMonth: Int = 31): Long = {\n    val monthsDuration = Math.multiplyExact(\n      daysPerMonth * DateTimeUtils.MICROS_PER_DAY,"
  },
  {
    "id" : "395f515f-c656-4a7c-a933-067d1ecae065",
    "prId" : 26134,
    "prUrl" : "https://github.com/apache/spark/pull/26134#pullrequestreview-308039213",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8bdfce07-578e-48b1-b83c-2aa4cfd5b523",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "not related to this PR, but isn't it simply `result += MICROS_PER_MONTH * interval.months`?",
        "createdAt" : "2019-10-28T16:40:08Z",
        "updatedAt" : "2019-11-01T05:44:13Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "5c99948c-8e83-4261-9fc6-24b398ca7111",
        "parentId" : "8bdfce07-578e-48b1-b83c-2aa4cfd5b523",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "It could be if MICROS_PER_YEAR = 12 * MICROS_PER_MONTH . I strictly followed PostgreSQL implementation: https://github.com/postgres/postgres/blob/bffe1bd68457e43925c362d8728ce3b25bdf1c94/src/backend/utils/adt/timestamp.c#L5016-L5022",
        "createdAt" : "2019-10-28T17:54:42Z",
        "updatedAt" : "2019-11-01T05:44:13Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "2f901894eb24d7deec31947708b9afdaae2a4866",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +94,98 @@    result += DateTimeUtils.MICROS_PER_DAY * interval.days\n    result += MICROS_PER_YEAR * (interval.months / MONTHS_PER_YEAR)\n    result += MICROS_PER_MONTH * (interval.months % MONTHS_PER_YEAR)\n    Decimal(result, 18, 6)\n  }"
  },
  {
    "id" : "8939cad9-075f-43c2-9e24-16a830c7e791",
    "prId" : 25981,
    "prUrl" : "https://github.com/apache/spark/pull/25981#pullrequestreview-295896423",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ce03f348-ba9f-4427-9271-014767506c0c",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "This is from https://github.com/postgres/postgres/blob/97c39498e5ca9208d3de5a443a2282923619bf91/src/include/datatype/timestamp.h#L68",
        "createdAt" : "2019-09-30T19:01:28Z",
        "updatedAt" : "2019-10-18T07:28:33Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "60fbb391-1aa3-47d4-af78-db8f41a53911",
        "parentId" : "ce03f348-ba9f-4427-9271-014767506c0c",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Is this consistent with Spark's existing behavior, too?",
        "createdAt" : "2019-10-01T03:44:51Z",
        "updatedAt" : "2019-10-18T07:28:33Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "a152e39f-9cef-4dff-b209-64aedf63e6a5",
        "parentId" : "ce03f348-ba9f-4427-9271-014767506c0c",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "We have the hard-coded `31` days per month in one place: https://github.com/apache/spark/blob/051e691029c456fc2db5f229485d3fb8f5d0e84c/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/util/DateTimeUtils.scala#L614 which looks much more strange than `365.25 days per year`.",
        "createdAt" : "2019-10-01T05:14:38Z",
        "updatedAt" : "2019-10-18T07:28:33Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "e4758b6f-1dba-434c-bbf6-697bb8c4d259",
        "parentId" : "ce03f348-ba9f-4427-9271-014767506c0c",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "What I mean is the possibility of returning different values in a single Apache Spark version. We don't want to see the inconsistency between functions.",
        "createdAt" : "2019-10-01T18:22:10Z",
        "updatedAt" : "2019-10-18T07:28:33Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "80189c10-c92d-4e0c-bbb6-17cb0da4ed52",
        "parentId" : "ce03f348-ba9f-4427-9271-014767506c0c",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Probably, such inconsistency exists on exotic examples because of `monthsBetween` assumes 31 days per months and new functions `getEpoch()` assumes 365.25 / 12 = 30.4375 but on regular examples like:\r\n```sql\r\nspark-sql> select date_part('epoch', '2019-10-01');\r\n1569888000\r\nspark-sql> select months_between('2019-10-01', '1970-01-01');\r\n597.0\r\nspark-sql> select timestamp'1970-01-01 00:00:00' + cast('interval 1569888000 seconds' as interval) - cast('interval 597 months' as interval);\r\n1970-01-01 00:00:00\r\n```\r\nbehavior looks consistent.",
        "createdAt" : "2019-10-01T21:11:06Z",
        "updatedAt" : "2019-10-18T07:28:33Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "5620472a26f57590f2d5a67b24b5295980641f1c",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +31,35 @@  val DAYS_PER_MONTH: Byte = 30\n  val MICROS_PER_MONTH: Long = DAYS_PER_MONTH * DateTimeUtils.SECONDS_PER_DAY\n  /* 365.25 days per year assumes leap year every four years */\n  val MICROS_PER_YEAR: Long = (36525L * DateTimeUtils.MICROS_PER_DAY) / 100\n"
  },
  {
    "id" : "6c2b0ca0-8f92-4f1a-a96f-9543af5b935e",
    "prId" : 25981,
    "prUrl" : "https://github.com/apache/spark/pull/25981#pullrequestreview-297859786",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e1fa6d3c-c669-4a93-a50b-8accf7e48958",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "This implemented as in PostgreSQL https://github.com/postgres/postgres/blob/bffe1bd68457e43925c362d8728ce3b25bdf1c94/src/backend/utils/adt/timestamp.c#L5016-L5022",
        "createdAt" : "2019-10-06T20:47:58Z",
        "updatedAt" : "2019-10-18T07:28:33Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "5620472a26f57590f2d5a67b24b5295980641f1c",
    "line" : 85,
    "diffHunk" : "@@ -1,1 +83,87 @@\n  // Returns total number of seconds with microseconds fractional part in the given interval.\n  def getEpoch(interval: CalendarInterval): Decimal = {\n    var result = interval.microseconds\n    result += MICROS_PER_YEAR * (interval.months / MONTHS_PER_YEAR)"
  }
]