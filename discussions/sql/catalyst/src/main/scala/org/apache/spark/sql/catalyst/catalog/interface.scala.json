[
  {
    "id" : "c30caff2-99aa-44c0-bf30-f3de90b06509",
    "prId" : 31112,
    "prUrl" : "https://github.com/apache/spark/pull/31112#pullrequestreview-564850658",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7cefd5e0-9433-4a9b-b850-7cd2d398ac6d",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "This is the bug fix. Cleaning of `storage` and `createTime` is not enough. `tableMeta` can have other \"temporary\" fields.",
        "createdAt" : "2021-01-10T10:39:18Z",
        "updatedAt" : "2021-01-10T10:39:18Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "6d3058e20ace94502b02a95cb8ec598cc0cee187",
    "line" : 39,
    "diffHunk" : "@@ -1,1 +806,810 @@\n  override def doCanonicalize(): HiveTableRelation = copy(\n    tableMeta = CatalogTable.normalize(tableMeta),\n    dataCols = dataCols.zipWithIndex.map {\n      case (attr, index) => attr.withExprId(ExprId(index))"
  }
]