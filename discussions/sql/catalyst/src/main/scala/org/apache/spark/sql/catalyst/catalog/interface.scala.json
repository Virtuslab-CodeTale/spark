[
  {
    "id" : "c30caff2-99aa-44c0-bf30-f3de90b06509",
    "prId" : 31112,
    "prUrl" : "https://github.com/apache/spark/pull/31112#pullrequestreview-564850658",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7cefd5e0-9433-4a9b-b850-7cd2d398ac6d",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "This is the bug fix. Cleaning of `storage` and `createTime` is not enough. `tableMeta` can have other \"temporary\" fields.",
        "createdAt" : "2021-01-10T10:39:18Z",
        "updatedAt" : "2021-01-10T10:39:18Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "6d3058e20ace94502b02a95cb8ec598cc0cee187",
    "line" : 39,
    "diffHunk" : "@@ -1,1 +806,810 @@\n  override def doCanonicalize(): HiveTableRelation = copy(\n    tableMeta = CatalogTable.normalize(tableMeta),\n    dataCols = dataCols.zipWithIndex.map {\n      case (attr, index) => attr.withExprId(ExprId(index))"
  },
  {
    "id" : "0fc0ee12-e349-44ca-b54b-08bfdb5323cd",
    "prId" : 30799,
    "prUrl" : "https://github.com/apache/spark/pull/30799#pullrequestreview-554323429",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9f17de57-ac10-43d1-8ecd-de0f8f5847cf",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Should we sort by entire strings (._1 and ._2)? For example, if you have `key0 = b` and `key0 = a`, you may get unstable output either `[key0 = b, key0 = a]` or `[key0 = a, key0 = b]`",
        "createdAt" : "2020-12-17T06:52:45Z",
        "updatedAt" : "2020-12-17T06:54:46Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "af414871-a84d-49e4-94a4-167701cd2795",
        "parentId" : "9f17de57-ac10-43d1-8ecd-de0f8f5847cf",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "ah, sorry, we can guarantee uniqueness of keys.",
        "createdAt" : "2020-12-17T06:59:04Z",
        "updatedAt" : "2020-12-17T06:59:04Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "2e908def417f933a993972110df86a43ec0b2f73",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +390,394 @@    val map = new mutable.LinkedHashMap[String, String]()\n    val tableProperties = properties.toSeq.sortBy(_._1)\n      .map(p => p._1 + \"=\" + p._2).mkString(\"[\", \", \", \"]\")\n    val partitionColumns = partitionColumnNames.map(quoteIdentifier).mkString(\"[\", \", \", \"]\")\n    val lastAccess = {"
  },
  {
    "id" : "b0212368-d0dc-4c68-a92e-40821053e111",
    "prId" : 29739,
    "prUrl" : "https://github.com/apache/spark/pull/29739#pullrequestreview-489232886",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "257b24f3-fcad-4505-82ea-3dc16cfa4804",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "The explain output of `HiveTableScanExec` does not have the same issue?",
        "createdAt" : "2020-09-16T02:34:02Z",
        "updatedAt" : "2020-09-17T10:25:55Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "e1c1ea32-3378-4c5c-921b-9e58ee48d2dd",
        "parentId" : "257b24f3-fcad-4505-82ea-3dc16cfa4804",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> The explain output of `HiveTableScanExec` does not have the same issue?\r\n\r\nNo, only caused. by `HiveTableRelation`, Optimized Plan also show too many information too.",
        "createdAt" : "2020-09-16T02:37:08Z",
        "updatedAt" : "2020-09-17T10:25:55Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "2a8fd35899afc4ae6f43ad7afe192fc57e519966",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +696,700 @@    partitionCols = partitionCols.map(_.newInstance()))\n\n  override def simpleString(maxFields: Int): String = {\n    val catalogTable = tableMeta.storage.serde match {\n      case Some(serde) => tableMeta.identifier :: serde :: Nil"
  },
  {
    "id" : "e9fc09b9-33d8-44c8-b912-1d7c253f05de",
    "prId" : 29739,
    "prUrl" : "https://github.com/apache/spark/pull/29739#pullrequestreview-489322453",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6508372f-3cd4-4ebd-bc91-a614317f9c45",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "is it also how file source tables display table info?",
        "createdAt" : "2020-09-16T06:44:50Z",
        "updatedAt" : "2020-09-17T10:25:55Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "d617d9a7-00e4-4f19-ba04-5e7a34575055",
        "parentId" : "6508372f-3cd4-4ebd-bc91-a614317f9c45",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> is it also how file source tables display table info?\r\n\r\nFile source tables won't show this.\r\n```\r\n== Parsed Logical Plan ==\r\n'Project [*]\r\n+- 'Filter ('df.k < 3)\r\n   +- 'UnresolvedRelation [df], []\r\n\r\n== Analyzed Logical Plan ==\r\nid: bigint, k: bigint\r\nProject [id#7L, k#8L]\r\n+- Filter (k#8L < cast(3 as bigint))\r\n   +- SubqueryAlias spark_catalog.default.df\r\n      +- Relation[id#7L,k#8L] parquet\r\n\r\n== Optimized Logical Plan ==\r\nFilter (isnotnull(k#8L) AND (k#8L < 3))\r\n+- Relation[id#7L,k#8L] parquet\r\n\r\n== Physical Plan ==\r\n*(1) ColumnarToRow\r\n+- FileScan parquet default.df[id#7L,k#8L] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex[file:/Users/angerszhu/Documents/project/AngersZhu/spark/sql/hive/target/tmp/hiv..., PartitionFilters: [isnotnull(k#8L), (k#8L < 3)], PushedFilters: [], ReadSchema: struct<id:bigint>\r\n\r\n```",
        "createdAt" : "2020-09-16T06:50:52Z",
        "updatedAt" : "2020-09-17T10:25:55Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "2a8fd35899afc4ae6f43ad7afe192fc57e519966",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +703,707 @@\n    var metadata = Map(\n      \"CatalogTable\" -> catalogTable.mkString(\", \"),\n      \"Data Cols\" -> truncatedString(dataCols, \"[\", \", \", \"]\", maxFields),\n      \"Partition Cols\" -> truncatedString(partitionCols, \"[\", \", \", \"]\", maxFields)"
  },
  {
    "id" : "64328e9a-ef21-49ee-817a-3c6ea669c5f9",
    "prId" : 27453,
    "prUrl" : "https://github.com/apache/spark/pull/27453#pullrequestreview-355273794",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "67f0c709-216f-48a5-9811-bf8f891350c2",
        "parentId" : null,
        "authorId" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "body" : "Why not `Double`?",
        "createdAt" : "2020-02-07T15:03:59Z",
        "updatedAt" : "2020-02-07T16:24:17Z",
        "lastEditedBy" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "tags" : [
        ]
      },
      {
        "id" : "ec176d52-7c90-4ccb-a300-a9cb1192c3cb",
        "parentId" : "67f0c709-216f-48a5-9811-bf8f891350c2",
        "authorId" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "body" : "It is expected to be a bigger number because of the columnar nature of the underlying file. Moreover it is better to take the ceil of a floating number here as being on the edge risks the an OOM.  ",
        "createdAt" : "2020-02-07T16:21:33Z",
        "updatedAt" : "2020-02-07T16:24:17Z",
        "lastEditedBy" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "tags" : [
        ]
      }
    ],
    "commit" : "e78b4b07e566a02580502242df13de6a9c0d2a60",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +426,430 @@case class CatalogStatistics(\n    sizeInBytes: BigInt,\n    deserFactor: Option[Int] = None,\n    rowCount: Option[BigInt] = None,\n    colStats: Map[String, CatalogColumnStat] = Map.empty) {"
  },
  {
    "id" : "2233e0f3-9b99-45a4-9cca-9ac56b9335be",
    "prId" : 26923,
    "prUrl" : "https://github.com/apache/spark/pull/26923#pullrequestreview-337531254",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "00c0a8de-f8de-4004-8423-aaf938695a1c",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Hm, I wonder why we started to use this way (e.g., in `VIEW_QUERY_OUTPUT_COLUMN_NAME_PREFIX`). It's not performance sensitive code path and it needs a manual (de)encoding anyway. I could do it with JSON array which can be done a couple of lines with json4s (except imports), which has a better readability. It's fine as is considering that this is already what we do ...",
        "createdAt" : "2020-01-02T04:22:07Z",
        "updatedAt" : "2020-01-02T06:39:43Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "76842643-04a1-42ed-bdb3-d2abd1b2f3bb",
        "parentId" : "00c0a8de-f8de-4004-8423-aaf938695a1c",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "AFAIK, it's because hive metastore has a size limitation for a single property, so we try to avoid putting everything into one property.",
        "createdAt" : "2020-01-02T04:51:19Z",
        "updatedAt" : "2020-01-02T06:39:43Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "012ddee3538be2020aa9c8049a7a2eaa9a28b653",
    "line" : 66,
    "diffHunk" : "@@ -1,1 +401,405 @@    val props = new mutable.HashMap[String, String]\n    val parts = currentCatalog +: currentNamespace\n    if (parts.nonEmpty) {\n      props.put(VIEW_CATALOG_AND_NAMESPACE, parts.length.toString)\n      parts.zipWithIndex.foreach { case (name, index) =>"
  }
]