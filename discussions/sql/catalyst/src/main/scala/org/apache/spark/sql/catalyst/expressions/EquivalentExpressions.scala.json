[
  {
    "id" : "a1089efc-9266-4130-aed4-4db5294b5a02",
    "prId" : 33142,
    "prUrl" : "https://github.com/apache/spark/pull/33142#pullrequestreview-703488219",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "32e4baac-2fe3-46f8-b847-ac4e2b41d4b4",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This partially solves the perf issue mentioned in https://github.com/apache/spark/pull/32559/files#r633488455\r\n\r\nBy filtering with height first, we can reduce the data to iterate. ",
        "createdAt" : "2021-06-29T19:16:38Z",
        "updatedAt" : "2021-06-29T19:16:38Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "00514198-faa2-457a-b504-da2c6cf0a821",
        "parentId" : "32e4baac-2fe3-46f8-b847-ac4e2b41d4b4",
        "authorId" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "body" : "I opened https://github.com/apache/spark/pull/33281 to improve it further.",
        "createdAt" : "2021-07-10T09:45:59Z",
        "updatedAt" : "2021-07-10T09:45:59Z",
        "lastEditedBy" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "tags" : [
        ]
      }
    ],
    "commit" : "92786a625a7288edf93479f0615bd77a254f589b",
    "line" : 94,
    "diffHunk" : "@@ -1,1 +87,91 @@\n    localEquivalenceMap.foreach { case (commonExpr, state) =>\n      val possibleParents = localEquivalenceMap.filter { case (_, v) => v.height > state.height }\n      val notChild = possibleParents.forall { case (k, _) =>\n        k == commonExpr || k.e.find(_.semanticEquals(commonExpr.e)).isEmpty"
  },
  {
    "id" : "84218b56-c2bf-4bb1-a668-5774a788c05c",
    "prId" : 33142,
    "prUrl" : "https://github.com/apache/spark/pull/33142#pullrequestreview-704379579",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6fbe5b88-c7d3-4944-83ec-f1047fee9cbb",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "not sure we can trigger this bug with some real queries, but it's an obvious bug to me.",
        "createdAt" : "2021-06-29T19:21:03Z",
        "updatedAt" : "2021-06-29T19:21:03Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "fb496fb6-0254-4673-ac80-004184a5dd2f",
        "parentId" : "6fbe5b88-c7d3-4944-83ec-f1047fee9cbb",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "good catch!",
        "createdAt" : "2021-06-30T15:33:41Z",
        "updatedAt" : "2021-06-30T15:33:41Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "bd17faa7-16f5-4f3a-aaec-d077a8f487e5",
        "parentId" : "6fbe5b88-c7d3-4944-83ec-f1047fee9cbb",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "I think if we wrongly recurse into the children of `CodegenFallback`, it only produces unused subexpressions. Some redundant generated codes, i.e..",
        "createdAt" : "2021-06-30T15:36:13Z",
        "updatedAt" : "2021-06-30T15:36:13Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "2c5e69b2-e7d0-4e9a-80c1-aad8d89ac641",
        "parentId" : "6fbe5b88-c7d3-4944-83ec-f1047fee9cbb",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Is it better to backport this part into branch-3.1/3.0?",
        "createdAt" : "2021-07-01T01:48:36Z",
        "updatedAt" : "2021-07-01T01:48:36Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "d1753709-a801-4027-9362-e34e9b00a58e",
        "parentId" : "6fbe5b88-c7d3-4944-83ec-f1047fee9cbb",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "yea will do",
        "createdAt" : "2021-07-01T01:59:54Z",
        "updatedAt" : "2021-07-01T01:59:55Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "8c5aadfd-85d2-47f7-b652-c9f3295f8382",
        "parentId" : "6fbe5b88-c7d3-4944-83ec-f1047fee9cbb",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "https://github.com/apache/spark/pull/33304",
        "createdAt" : "2021-07-12T17:41:01Z",
        "updatedAt" : "2021-07-12T17:41:02Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "92786a625a7288edf93479f0615bd77a254f589b",
    "line" : 116,
    "diffHunk" : "@@ -1,1 +123,127 @@  // recursively add the common expressions shared between all of its children.\n  private def commonChildrenToRecurse(expr: Expression): Seq[Seq[Expression]] = expr match {\n    case _: CodegenFallback => Nil\n    case i: If => Seq(Seq(i.trueValue, i.falseValue))\n    case c: CaseWhen =>"
  },
  {
    "id" : "6da4beed-1f03-4a8f-8d18-0d0d8db8de91",
    "prId" : 33142,
    "prUrl" : "https://github.com/apache/spark/pull/33142#pullrequestreview-696378775",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c2ee3c45-6f62-4666-b2d1-b098f0b27040",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This fixes https://github.com/apache/spark/pull/30245#discussion_r660870034\r\n\r\nBasically it takes all the conditions as the `commonChildrenToRecurse`, so that we only get the common expressions that appear in all the conditions.",
        "createdAt" : "2021-06-29T19:21:45Z",
        "updatedAt" : "2021-06-30T14:41:14Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "8b46ceb2-fb12-4dfe-87f6-04abab3117bb",
        "parentId" : "c2ee3c45-6f62-4666-b2d1-b098f0b27040",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "@Kimahriman I think this fix works? The only drawback is, if there are common subexpressions among the conditions, they will always be counted as \"appear twice\" and gets codegened into methods.\r\n\r\nI think the perf overhead is really small, and if the first condition is false, we evaluate the next condition which gives perf improvement because of common subexpressions elimination.\r\n\r\nFor the value branches of `CaseWhen`, I don't touch them in this PR.",
        "createdAt" : "2021-06-30T14:39:49Z",
        "updatedAt" : "2021-06-30T14:39:50Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "e2266470-ab09-4b4e-903c-a81cf7852360",
        "parentId" : "c2ee3c45-6f62-4666-b2d1-b098f0b27040",
        "authorId" : "92aa9573-b64a-4a86-aebf-54c827df3ed0",
        "body" : "Yeah this definitely fixes a potential bug of creating subexpressions for things that are never evaluated, same with the coalesce update. I think the values are already handled fine, it's just the conditionals that had an issue with short circuiting",
        "createdAt" : "2021-06-30T15:15:20Z",
        "updatedAt" : "2021-06-30T15:15:20Z",
        "lastEditedBy" : "92aa9573-b64a-4a86-aebf-54c827df3ed0",
        "tags" : [
        ]
      },
      {
        "id" : "6db2c21a-c445-4669-8191-b1248c755c44",
        "parentId" : "c2ee3c45-6f62-4666-b2d1-b098f0b27040",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "This fixed https://github.com/apache/spark/pull/30245#discussion_r660870034. \r\n\r\n> The only drawback is, if there are common subexpressions among the conditions, they will always be counted as \"appear twice\" and gets codegened into methods.\r\n\r\nI just don't get this. You mean for `If(a + b > 1, 1, a + b + c > 1, 2, a + b + c > 2, 3)`, `a + b + c` will be counted twice and considered as common subexpression?",
        "createdAt" : "2021-06-30T15:41:59Z",
        "updatedAt" : "2021-06-30T15:41:59Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "41116cd5-9fa9-4aa9-8809-fcd406f3aa29",
        "parentId" : "c2ee3c45-6f62-4666-b2d1-b098f0b27040",
        "authorId" : "92aa9573-b64a-4a86-aebf-54c827df3ed0",
        "body" : "I think he means in `CaseWhen(a + b > 1, 1, a + b + c > 1, 2)`, `a + b` will be a subexpression even though it might only be executed once.",
        "createdAt" : "2021-06-30T16:18:23Z",
        "updatedAt" : "2021-06-30T16:18:23Z",
        "lastEditedBy" : "92aa9573-b64a-4a86-aebf-54c827df3ed0",
        "tags" : [
        ]
      },
      {
        "id" : "111cf594-8c80-44c8-9ed0-86bb46eefb7a",
        "parentId" : "c2ee3c45-6f62-4666-b2d1-b098f0b27040",
        "authorId" : "92aa9573-b64a-4a86-aebf-54c827df3ed0",
        "body" : "But `CaseWhen(a + b > 1, 1, a + b + c > 1, 2, a + b + c > 0, 3)`, `a + b + c` won't even be considered for a subexpression if it's seen elsewhere, which was the bug if CaseWhen supports short circuiting",
        "createdAt" : "2021-06-30T16:20:03Z",
        "updatedAt" : "2021-06-30T16:20:31Z",
        "lastEditedBy" : "92aa9573-b64a-4a86-aebf-54c827df3ed0",
        "tags" : [
        ]
      },
      {
        "id" : "c9949b4d-2c16-46a7-81e4-2928f1b67591",
        "parentId" : "c2ee3c45-6f62-4666-b2d1-b098f0b27040",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Yes, because the first condition of `CaseWhen` is in both `childrenToRecurse` and `commonChildrenToRecurse`",
        "createdAt" : "2021-06-30T16:21:09Z",
        "updatedAt" : "2021-06-30T16:21:10Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "92786a625a7288edf93479f0615bd77a254f589b",
    "line" : 125,
    "diffHunk" : "@@ -1,1 +131,135 @@      // a subexpression among values doesn't need to be in conditions because no matter which\n      // condition is true, it will be evaluated.\n      val conditions = if (c.branches.length > 1) {\n        c.branches.map(_._1)\n      } else {"
  },
  {
    "id" : "e0560ac1-72b3-4b2b-90d4-2ec20c126803",
    "prId" : 33142,
    "prUrl" : "https://github.com/apache/spark/pull/33142#pullrequestreview-698048218",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "70f6d6f9-546e-4f10-830f-5186a280d656",
        "parentId" : null,
        "authorId" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "body" : "This also fixed that, previously, for `Or(Coalesce(expr1, expr2, expr2), Coalesce(expr1, expr2, expr2))`, `expr2` will be extracted and considered as a common subexpression. Currently, no subexpression will be extracted.",
        "createdAt" : "2021-07-02T10:25:46Z",
        "updatedAt" : "2021-07-02T10:26:07Z",
        "lastEditedBy" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "tags" : [
        ]
      }
    ],
    "commit" : "92786a625a7288edf93479f0615bd77a254f589b",
    "line" : 77,
    "diffHunk" : "@@ -1,1 +75,79 @@      map: mutable.HashMap[ExpressionEquals, ExpressionStats]): Unit = {\n    assert(exprs.length > 1)\n    var localEquivalenceMap = mutable.HashMap.empty[ExpressionEquals, ExpressionStats]\n    addExprTree(exprs.head, localEquivalenceMap)\n"
  },
  {
    "id" : "4d148420-951d-4bef-aea5-55ad610c4a24",
    "prId" : 33142,
    "prUrl" : "https://github.com/apache/spark/pull/33142#pullrequestreview-703725433",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "24eac762-ec49-40d4-9148-f6b32a3dec43",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "do you mean depth instead of height?",
        "createdAt" : "2021-07-12T05:08:58Z",
        "updatedAt" : "2021-07-12T05:08:58Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "e77357bd-5cbd-4aac-a7ee-58f72aee7552",
        "parentId" : "24eac762-ec49-40d4-9148-f6b32a3dec43",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I think these two are similar?",
        "createdAt" : "2021-07-12T05:19:23Z",
        "updatedAt" : "2021-07-12T05:19:23Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "d006baa6-d42f-4c43-8bec-65e27e94fe3d",
        "parentId" : "24eac762-ec49-40d4-9148-f6b32a3dec43",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "ohh it's correct! sorry for a false alarm",
        "createdAt" : "2021-07-12T05:25:34Z",
        "updatedAt" : "2021-07-12T05:25:34Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "92786a625a7288edf93479f0615bd77a254f589b",
    "line" : 258,
    "diffHunk" : "@@ -1,1 +229,233 @@case class ExpressionStats(expr: Expression)(var useCount: Int = 1) {\n  // This is used to do a fast pre-check for child-parent relationship. For example, expr1 can\n  // only be a parent of expr2 if expr1.height is larger than expr2.height.\n  lazy val height = getHeight(expr)\n"
  },
  {
    "id" : "08aa4ae1-49b1-4d68-b96d-ec7b7d44c59f",
    "prId" : 32870,
    "prUrl" : "https://github.com/apache/spark/pull/32870#pullrequestreview-681402209",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d0f49169-f715-497d-83ed-0bf33ed2027b",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Just curious, is there a reason of this move?",
        "createdAt" : "2021-06-11T00:16:21Z",
        "updatedAt" : "2021-06-11T00:16:21Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "b93b7d3e-cfde-4c5b-8647-c949f5fd0c60",
        "parentId" : "d0f49169-f715-497d-83ed-0bf33ed2027b",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Oh, as it is a nested class, I cannot allocate it separately, but\r\n\r\n```scala\r\nval equivalence = new EquivalentExpressions\r\nval exprOrdering = new equivalence.ExpressionContainmentOrdering\r\n```\r\n\r\nI can revert to nested class if you think it's unnecessary change.",
        "createdAt" : "2021-06-11T00:38:25Z",
        "updatedAt" : "2021-06-11T00:38:26Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "eb7389b4-3843-4b91-b2d7-df533ad27fd9",
        "parentId" : "d0f49169-f715-497d-83ed-0bf33ed2027b",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Never mind. New one also looks good~",
        "createdAt" : "2021-06-11T02:43:43Z",
        "updatedAt" : "2021-06-11T02:43:43Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "019fababe0cd4f6630fcec56c4b08f9254d71269",
    "line" : 42,
    "diffHunk" : "@@ -1,1 +219,223 @@ * irrelevant expressions does not matter.\n */\nclass ExpressionContainmentOrdering extends Ordering[Expression] {\n  override def compare(x: Expression, y: Expression): Int = {\n    if (x.find(_.semanticEquals(y)).isDefined) {"
  },
  {
    "id" : "8fa849ef-6d27-42c0-8936-42aa26f9f6e1",
    "prId" : 32870,
    "prUrl" : "https://github.com/apache/spark/pull/32870#pullrequestreview-681414474",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3c1d2172-61ff-4b0e-b1e1-94810ed2ef2c",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "To be complete, could you add some description about the semantically-equal expressions?",
        "createdAt" : "2021-06-11T03:12:24Z",
        "updatedAt" : "2021-06-11T03:12:24Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "b7b617ad-5543-4fca-bffc-3775c8e9a2a4",
        "parentId" : "3c1d2172-61ff-4b0e-b1e1-94810ed2ef2c",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Sure. Added.",
        "createdAt" : "2021-06-11T03:22:12Z",
        "updatedAt" : "2021-06-11T03:22:12Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "019fababe0cd4f6630fcec56c4b08f9254d71269",
    "line" : 40,
    "diffHunk" : "@@ -1,1 +217,221 @@ * this is not for general expression ordering. For example, two irrelevant or semantically-equal\n * expressions will be considered as equal by this ordering. But for the usage here, the order of\n * irrelevant expressions does not matter.\n */\nclass ExpressionContainmentOrdering extends Ordering[Expression] {"
  },
  {
    "id" : "316479b0-619e-463c-b3e0-e2c68575e212",
    "prId" : 32595,
    "prUrl" : "https://github.com/apache/spark/pull/32595#pullrequestreview-666284038",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "34b883ee-4875-425c-8e6f-92cdfa0777e1",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "> However, for a statement to be in \"all branches\" of a CaseWhen statement, it must also be in the elseValue.\r\n\r\nIt's better to leave a simple comment here about why we need to check `elseValue`.",
        "createdAt" : "2021-05-22T15:08:41Z",
        "updatedAt" : "2021-05-22T15:12:57Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "2b63c5be-2194-45f4-b94a-dc7062bae65e",
        "parentId" : "34b883ee-4875-425c-8e6f-92cdfa0777e1",
        "authorId" : "92aa9573-b64a-4a86-aebf-54c827df3ed0",
        "body" : "Added a comment in",
        "createdAt" : "2021-05-23T16:16:22Z",
        "updatedAt" : "2021-05-23T16:16:23Z",
        "lastEditedBy" : "92aa9573-b64a-4a86-aebf-54c827df3ed0",
        "tags" : [
        ]
      }
    ],
    "commit" : "5f203d0288ea76953483e7b45c995c3027c0cbbc",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +146,150 @@      // For an expression to be in all branch values of a CaseWhen statement, it must also be in\n      // the elseValue.\n      val values = if (c.elseValue.nonEmpty) {\n        c.branches.map(_._2) ++ c.elseValue\n      } else {"
  },
  {
    "id" : "f881dd31-1706-46f9-9e31-96189e42dada",
    "prId" : 32586,
    "prUrl" : "https://github.com/apache/spark/pull/32586#pullrequestreview-663525832",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ac52c257-acc7-46ec-b024-7efd77a61e6f",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Some irrelevant expressions, e1 and e2, have e1 < e2 and e2 < e1 relation at the same time?",
        "createdAt" : "2021-05-19T17:51:53Z",
        "updatedAt" : "2021-05-19T18:02:24Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "635e3b4f-0ecf-4db7-b614-46017f799430",
        "parentId" : "ac52c257-acc7-46ec-b024-7efd77a61e6f",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Discussed offline. Thanks for the concern. I renamed the ordering class and added more comment.",
        "createdAt" : "2021-05-19T18:18:36Z",
        "updatedAt" : "2021-05-19T18:18:36Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "3819bf3e544a316234f94292a2acdb8aae1d9ab1",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +189,193 @@        1\n      } else {\n        -1\n      }\n    }"
  },
  {
    "id" : "6e2c94d3-a9de-486a-9d5c-fa9b2af2f28a",
    "prId" : 32586,
    "prUrl" : "https://github.com/apache/spark/pull/32586#pullrequestreview-664971360",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fb8811ce-cc2e-40ac-8748-6cea8d87b2e8",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can we run `TPCDSQuerySuite` and see the time of the query compilation phase? This looks like a very expensive sort.",
        "createdAt" : "2021-05-20T06:59:50Z",
        "updatedAt" : "2021-05-20T06:59:51Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "1a45ca19-b41c-4db3-ac8e-c651539ad991",
        "parentId" : "fb8811ce-cc2e-40ac-8748-6cea8d87b2e8",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Ok. Let me compare before/after this PR.",
        "createdAt" : "2021-05-20T07:59:03Z",
        "updatedAt" : "2021-05-20T07:59:03Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "01f644af-2b16-4144-a2be-935cadce21da",
        "parentId" : "fb8811ce-cc2e-40ac-8748-6cea8d87b2e8",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "BTW, I think better approach is to sort after filter (e.g. size > 1 in most use-case), because the number of sub-exprs should be smaller.",
        "createdAt" : "2021-05-20T22:24:28Z",
        "updatedAt" : "2021-05-20T22:24:28Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "939b8754-161a-4ea7-9ded-26d14eeca427",
        "parentId" : "fb8811ce-cc2e-40ac-8748-6cea8d87b2e8",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "I changed the call usage of `getAllEquivalentExprs`. So we filter it first and then do sorting.",
        "createdAt" : "2021-05-20T22:35:37Z",
        "updatedAt" : "2021-05-20T22:35:37Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "a61a1427-c1fb-44ba-b702-5ddb790e5cdd",
        "parentId" : "fb8811ce-cc2e-40ac-8748-6cea8d87b2e8",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Ran `TPCDSQuerySuite`.\r\n\r\nBefore (master):\r\n```\r\n23.233160578 seconds \r\n22.501728011 seconds\r\n23.547332524 seconds\r\n```\r\n\r\nAfter:\r\n\r\n```\r\n23.995751468 seconds \r\n22.262832936 seconds\r\n21.503776059 seconds  \r\n```\r\n\r\nI don't see significant difference there.",
        "createdAt" : "2021-05-20T23:06:05Z",
        "updatedAt" : "2021-05-20T23:06:05Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "3819bf3e544a316234f94292a2acdb8aae1d9ab1",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +186,190 @@      if (x.semanticEquals(y)) {\n        0\n      } else if (x.find(_.semanticEquals(y)).isDefined) {\n        1\n      } else {"
  },
  {
    "id" : "93b96ba7-690c-4a9c-9f00-9a9926d3e605",
    "prId" : 32559,
    "prUrl" : "https://github.com/apache/spark/pull/32559#pullrequestreview-661513678",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a1e97496-3760-43dd-a5f2-b614adcd38ac",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Is this loop not expensive? It seems the time-complexity is big-O(`the total number of expr nodes in candidateExprs)` x `(candidateExprs.size)^2 `)?",
        "createdAt" : "2021-05-17T12:31:59Z",
        "updatedAt" : "2021-05-17T12:33:39Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "34cb1204-510f-437c-806f-2f3e21880f41",
        "parentId" : "a1e97496-3760-43dd-a5f2-b614adcd38ac",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "+1, but I don't have a better idea now...",
        "createdAt" : "2021-05-17T14:40:21Z",
        "updatedAt" : "2021-05-17T14:40:21Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "2a0d34c9-7b4f-4d3f-ad44-bc28c0c74780",
        "parentId" : "a1e97496-3760-43dd-a5f2-b614adcd38ac",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Yea, I considered this part but didn't come out better one.",
        "createdAt" : "2021-05-17T16:18:38Z",
        "updatedAt" : "2021-05-17T16:18:38Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "1686b3a4-cd98-432d-8612-9f8a6283122c",
        "parentId" : "a1e97496-3760-43dd-a5f2-b614adcd38ac",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Yea, okay. I don't have a idea, too... That was just a question.",
        "createdAt" : "2021-05-17T23:37:12Z",
        "updatedAt" : "2021-05-17T23:39:10Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "9973c1a4d6bbaa089b120e47a8418e99b132704d",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +109,113 @@      candidateExprs.forall { expr =>\n        expr == candidateExpr || expr.e.find(_.semanticEquals(candidateExpr.e)).isEmpty\n      }\n    }\n"
  },
  {
    "id" : "7b9aafff-6f4d-4d05-8aee-d2a99ae1b7e4",
    "prId" : 32559,
    "prUrl" : "https://github.com/apache/spark/pull/32559#pullrequestreview-666157015",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f48e0a18-9856-4a21-bee2-e82632e96c1a",
        "parentId" : null,
        "authorId" : "92aa9573-b64a-4a86-aebf-54c827df3ed0",
        "body" : "One potentially unrelated thing I just noticed, do we need to keep track of all of the `Expressions` here as well (as in an `Expr -> Seq[Expression]` map)? It's really basically keeping the first `Expression` found, but the codegen looks like it uses the `Expression` hash (versus the semantic hash) to lookup subexpressions. Very much an edge case, just wondering if I'm understanding things correctly",
        "createdAt" : "2021-05-20T21:15:16Z",
        "updatedAt" : "2021-05-20T21:37:39Z",
        "lastEditedBy" : "92aa9573-b64a-4a86-aebf-54c827df3ed0",
        "tags" : [
        ]
      },
      {
        "id" : "dfa32086-393c-4b0f-852f-c0ebc9ab44c3",
        "parentId" : "f48e0a18-9856-4a21-bee2-e82632e96c1a",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "You mean `equivalenceMap`?",
        "createdAt" : "2021-05-20T22:06:42Z",
        "updatedAt" : "2021-05-20T22:06:42Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "51776c36-772c-48fc-bf1c-eca0e145e13b",
        "parentId" : "f48e0a18-9856-4a21-bee2-e82632e96c1a",
        "authorId" : "92aa9573-b64a-4a86-aebf-54c827df3ed0",
        "body" : "I don't mean add it directly to that here. I'm just thinking of a really stupid example, `when((col + 1) > 0, col + 1).otherwise(1 + col)`. Wouldn't `col + 1` and `1 + col` resolve as a common expression because they're semantically equal, but only `col + 1` is added to `equivalenceMap`, so during codegen `1 + col` wouldn't be resolved to the subexpression?",
        "createdAt" : "2021-05-21T11:12:47Z",
        "updatedAt" : "2021-05-21T11:12:47Z",
        "lastEditedBy" : "92aa9573-b64a-4a86-aebf-54c827df3ed0",
        "tags" : [
        ]
      },
      {
        "id" : "e1ecc67b-c87e-41f0-a7cb-60e234e3d358",
        "parentId" : "f48e0a18-9856-4a21-bee2-e82632e96c1a",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "`col + 1` and `1 + col` will both be recognized as subexpression.",
        "createdAt" : "2021-05-21T17:27:40Z",
        "updatedAt" : "2021-05-21T17:27:40Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "0e324194-6b43-4c66-8fc7-642a14720f8c",
        "parentId" : "f48e0a18-9856-4a21-bee2-e82632e96c1a",
        "authorId" : "92aa9573-b64a-4a86-aebf-54c827df3ed0",
        "body" : "Yeah but won't the codgen stage not replace `1 + col` since only `col + 1` will be added to the `equivalenceMap` entry for `Expr(col + 1)`? For non commonExprs cases, both would be in `equivalenceMap` so that the codegen stage maps both of those expressions to the resulting subexpression. Again, not super related to this PR, but was the easiest place to ask",
        "createdAt" : "2021-05-21T21:04:53Z",
        "updatedAt" : "2021-05-21T21:04:53Z",
        "lastEditedBy" : "92aa9573-b64a-4a86-aebf-54c827df3ed0",
        "tags" : [
        ]
      },
      {
        "id" : "f1d58230-8aa2-4644-b37c-ceb448c6b1f7",
        "parentId" : "f48e0a18-9856-4a21-bee2-e82632e96c1a",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Both `1 + col` and `col + 1` will be replaced with the extracted subexpression during codege. We don't just look of key at `equivalenceMap` when replacing with subexpression.",
        "createdAt" : "2021-05-22T06:26:33Z",
        "updatedAt" : "2021-05-22T06:26:34Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "9973c1a4d6bbaa089b120e47a8418e99b132704d",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +95,99 @@      exprs: Seq[Expression],\n      addFunc: Expression => Boolean = addExpr): Unit = {\n    val exprSetForAll = mutable.Set[Expr]()\n    addExprTree(exprs.head, addExprToSet(_, exprSetForAll))\n"
  },
  {
    "id" : "639ce858-5d83-4a11-b110-4d27ca8697d2",
    "prId" : 30245,
    "prUrl" : "https://github.com/apache/spark/pull/30245#pullrequestreview-524931237",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "561e97ef-ec09-4a7b-bdf2-89d73d30640e",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Do we need to handle `head` and `tail` seperately?",
        "createdAt" : "2020-11-05T22:27:39Z",
        "updatedAt" : "2020-11-10T05:20:11Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "f3e17cab-1715-4dad-98f3-c3a6bf18b4bb",
        "parentId" : "561e97ef-ec09-4a7b-bdf2-89d73d30640e",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "For expression `head`, we add underlying expressions into `exprSetForAll` set. But for expressions in `tail`, we keep intersect between `exprSetForAll` and `exprSet`.\r\n\r\nWe can merge two blocks, but in the block we need to check if current expression is head expression and do different logic based on the check.\r\n\r\nI prefer current one since it looks simpler.",
        "createdAt" : "2020-11-06T08:10:03Z",
        "updatedAt" : "2020-11-10T05:20:11Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "b41572884401d5e02d6cda69068433376c6ab328",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +95,99 @@      addExprTree(expr, addExprToSet(_, otherExprSet))\n      exprSet.intersect(otherExprSet)\n    }\n\n    commonExprSet.foreach(expr => addFunc(expr.e))"
  },
  {
    "id" : "9dcf3a95-5e10-4cf3-81fb-d4f9fa1d3b12",
    "prId" : 30245,
    "prUrl" : "https://github.com/apache/spark/pull/30245#pullrequestreview-526858412",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e42f2d40-fad3-4bec-88fe-14da2f433b1d",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "`childrenToRecurse` is an inner method, shall we make `commonChildrenToRecurse` an inner method as well and put it next to `childrenToRecurse`?",
        "createdAt" : "2020-11-09T09:58:29Z",
        "updatedAt" : "2020-11-10T05:20:11Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "2aed6695-35aa-4bfe-a8ee-295b35708d84",
        "parentId" : "e42f2d40-fad3-4bec-88fe-14da2f433b1d",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Seems like we can merge them like this?\r\n```\r\n    // There are some special expressions that we should not recurse into all of its children.\r\n    //   1. CodegenFallback: it's children will not be used to generate code (call eval() instead)\r\n    //   2. If: common subexpressions will always be evaluated at the beginning, but the true and\r\n    //          false expressions in `If` may not get accessed, according to the predicate\r\n    //          expression. We should only recurse into the predicate expression.\r\n    //   3. CaseWhen: like `If`, the children of `CaseWhen` only get accessed in a certain\r\n    //                condition. We should only recurse into the first condition expression as it\r\n    //                will always get accessed.\r\n    //   4. Coalesce: it's also a conditional expression, we should only recurse into the first\r\n    //                children, because others may not get accessed.\r\n    lazy val (childrenToRecurse, commonChildrenToRecurse) = expr match {\r\n      case _: CodegenFallback => (Nil, Nil)\r\n      case i: If => (i.predicate :: Nil, Seq(Seq(i.trueValue, i.falseValue)))\r\n      case c: CaseWhen =>\r\n        val (Seq(headCondition), otherConditions) = c.branches.map(_._1).splitAt(1)\r\n        val values = c.branches.map(_._2) ++ c.elseValue\r\n        (headCondition :: Nil, Seq(otherConditions, values))\r\n      case c: Coalesce => (c.children.head :: Nil, Seq(c.children.tail))\r\n      case other => (other.children, Nil)\r\n    }\r\n```\r\nThen, I think its better to update the comment above for describing how to handle these \"special expressions (If, CaseWhen, and Coalesce)\".",
        "createdAt" : "2020-11-09T12:19:57Z",
        "updatedAt" : "2020-11-10T05:20:11Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "4500315e-da65-40a6-922b-32f53cf485f7",
        "parentId" : "e42f2d40-fad3-4bec-88fe-14da2f433b1d",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "I prefer to separate them. The merged method looks quite hard to read, IMO.",
        "createdAt" : "2020-11-09T20:03:11Z",
        "updatedAt" : "2020-11-10T05:20:11Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "b6098a79-bd54-4366-bffc-aff5fa2e0998",
        "parentId" : "e42f2d40-fad3-4bec-88fe-14da2f433b1d",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "> childrenToRecurse is an inner method, shall we make commonChildrenToRecurse an inner method as well and put it next to childrenToRecurse?\r\n\r\n@cloud-fan That is what I did initially, but put it outside later for review comment https://github.com/apache/spark/pull/30245#discussion_r518409583. Both work for me. ",
        "createdAt" : "2020-11-09T20:09:18Z",
        "updatedAt" : "2020-11-10T05:20:11Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "08480029-1349-43c1-b585-ee22737e4ddb",
        "parentId" : "e42f2d40-fad3-4bec-88fe-14da2f433b1d",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Then shall we move `childrenToRecurse` out too?",
        "createdAt" : "2020-11-10T04:54:20Z",
        "updatedAt" : "2020-11-10T05:20:11Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "71678749-9537-4f95-82ed-c700d54e8ef8",
        "parentId" : "e42f2d40-fad3-4bec-88fe-14da2f433b1d",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "okay.",
        "createdAt" : "2020-11-10T05:14:28Z",
        "updatedAt" : "2020-11-10T05:20:11Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "b41572884401d5e02d6cda69068433376c6ab328",
    "line" : 110,
    "diffHunk" : "@@ -1,1 +152,156 @@    if (!skip && !addFunc(expr)) {\n      childrenToRecurse(expr).foreach(addExprTree(_, addFunc))\n      commonChildrenToRecurse(expr).filter(_.nonEmpty).foreach(addCommonExprs(_, addFunc))\n    }\n  }"
  },
  {
    "id" : "f4621294-c63c-4386-806e-e0e065642178",
    "prId" : 30245,
    "prUrl" : "https://github.com/apache/spark/pull/30245#pullrequestreview-526735611",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "095234c8-086a-4c8d-8596-08ef7f380d64",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Why do we need to handle `conditions` and `values` separately?",
        "createdAt" : "2020-11-09T12:24:22Z",
        "updatedAt" : "2020-11-10T05:20:11Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "7c4304c5-46bb-4a27-b2d9-d0804378784a",
        "parentId" : "095234c8-086a-4c8d-8596-08ef7f380d64",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "A subexpression in conditions is definitely run because it is shared among `conditions`. It doesn't need to be shared in `values`. Similarly, a subexpression among `values` doesn't need to be in `conditions` because no matter which condition is true, it will be evaluated.",
        "createdAt" : "2020-11-09T20:00:52Z",
        "updatedAt" : "2020-11-10T05:20:11Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "4f1b9ce5-0934-4cb0-8e32-949c065e6091",
        "parentId" : "095234c8-086a-4c8d-8596-08ef7f380d64",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ah, ok. Thanks. Could you leave comments about it in the code side?",
        "createdAt" : "2020-11-09T23:26:14Z",
        "updatedAt" : "2020-11-10T05:20:11Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "b41572884401d5e02d6cda69068433376c6ab328",
    "line" : 68,
    "diffHunk" : "@@ -1,1 +130,134 @@      val conditions = c.branches.tail.map(_._1)\n      val values = c.branches.map(_._2) ++ c.elseValue\n      Seq(conditions, values)\n    case c: Coalesce => Seq(c.children.tail)\n    case _ => Nil"
  },
  {
    "id" : "3390053f-9edd-465b-b664-3a0fe2145354",
    "prId" : 30245,
    "prUrl" : "https://github.com/apache/spark/pull/30245#pullrequestreview-696157440",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f2fc8e37-f6e8-4edf-8da5-79d8321258a2",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "There is a flaw here: we exclude the first condition, so a common subexpressions in the rest of the conditions doesn't mean it's always evaluated.\r\n\r\ne.g. `CaseWhen(cond1, ... cond2, ..., cond2, ...)`, `cond2` is shared between the rest conditions but it's not always evaluated.",
        "createdAt" : "2021-06-29T18:34:51Z",
        "updatedAt" : "2021-06-29T18:34:52Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "de0bb093-1af9-4aec-b6f6-7848c8aa112b",
        "parentId" : "f2fc8e37-f6e8-4edf-8da5-79d8321258a2",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "yes, this is related to #32977. This looks more a aggressive optimization. Consider if we respect short-circuit evaluation practice for CaseWhen, this might be an issue if users reply short-circuit evaluation to guard later conditions.\r\n\r\nSafest approach is to only consider all conditions.",
        "createdAt" : "2021-06-29T18:42:26Z",
        "updatedAt" : "2021-06-29T18:44:54Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "7ff328b9-4ec5-49ea-8ae9-332e75d20aab",
        "parentId" : "f2fc8e37-f6e8-4edf-8da5-79d8321258a2",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "WDYT? Should we only consider all conditions?",
        "createdAt" : "2021-06-29T18:49:32Z",
        "updatedAt" : "2021-06-29T18:49:32Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "b27268ab-8fd9-4c44-8621-eb425976d9d5",
        "parentId" : "f2fc8e37-f6e8-4edf-8da5-79d8321258a2",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I think we should. I hit an issue caused by it in my refactor and I'll open a PR for the refactor with multiple bugs fixed.",
        "createdAt" : "2021-06-29T18:59:02Z",
        "updatedAt" : "2021-06-29T18:59:02Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "19f68321-665f-4932-8554-47b2329fac88",
        "parentId" : "f2fc8e37-f6e8-4edf-8da5-79d8321258a2",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Ok, thanks!",
        "createdAt" : "2021-06-29T19:05:44Z",
        "updatedAt" : "2021-06-29T19:05:44Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "2577a4e4-5ef0-43ab-b20d-5cde0e814aa9",
        "parentId" : "f2fc8e37-f6e8-4edf-8da5-79d8321258a2",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "BTW, does #32980 conflict with your refactor?",
        "createdAt" : "2021-06-29T19:06:15Z",
        "updatedAt" : "2021-06-29T19:06:15Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "970db39c-6bfd-4520-9fa0-06c5d7d0ad9a",
        "parentId" : "f2fc8e37-f6e8-4edf-8da5-79d8321258a2",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "only some trivial conflicts, #32980 should be merged first as it has been reviewed and approved.",
        "createdAt" : "2021-06-29T19:22:30Z",
        "updatedAt" : "2021-06-29T19:22:30Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "0d2e6586-c1f1-4d1a-9057-ff2178f6b2d1",
        "parentId" : "f2fc8e37-f6e8-4edf-8da5-79d8321258a2",
        "authorId" : "92aa9573-b64a-4a86-aebf-54c827df3ed0",
        "body" : "FWIW, I also addressed this issue in https://github.com/apache/spark/pull/32987 which assumed CaseWhen's (and Coalesce) should short circuit and guard later conditions. The main benefit/difference is if you have\r\n\r\n`CaseWhen(cond1, ..., cond1, ..., cond2, ...)`, `cond1` gets pulled out as a subexpression when it wouldn't otherwise even with https://github.com/apache/spark/pull/33142 I think",
        "createdAt" : "2021-06-30T13:25:12Z",
        "updatedAt" : "2021-06-30T13:25:12Z",
        "lastEditedBy" : "92aa9573-b64a-4a86-aebf-54c827df3ed0",
        "tags" : [
        ]
      }
    ],
    "commit" : "b41572884401d5e02d6cda69068433376c6ab328",
    "line" : 66,
    "diffHunk" : "@@ -1,1 +128,132 @@      // a subexpression among values doesn't need to be in conditions because no matter which\n      // condition is true, it will be evaluated.\n      val conditions = c.branches.tail.map(_._1)\n      val values = c.branches.map(_._2) ++ c.elseValue\n      Seq(conditions, values)"
  },
  {
    "id" : "c3b7c316-46d2-4bc0-a459-cd8f8ea5230e",
    "prId" : 27436,
    "prUrl" : "https://github.com/apache/spark/pull/27436#pullrequestreview-354125955",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5ae9caa6-a18a-4dd3-b134-fc399580fae9",
        "parentId" : null,
        "authorId" : "39fe625f-8c54-48bc-ac6f-7279921adf02",
        "body" : "don't think accessedExpressions will be empty since firstExpression is always inside.",
        "createdAt" : "2020-02-06T00:04:12Z",
        "updatedAt" : "2020-02-06T00:04:12Z",
        "lastEditedBy" : "39fe625f-8c54-48bc-ac6f-7279921adf02",
        "tags" : [
        ]
      }
    ],
    "commit" : "37ba243320ecf4029dfbd1f9dc4ffdc886770d5c",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +99,103 @@          udes.nonEmpty && firstUdes.containsSlice(udes)\n        }\n        if (accessedExpressions.nonEmpty) {\n          accessedExpressions\n        } else {"
  },
  {
    "id" : "264fdcd3-aa48-4dc5-ae16-ab1808bdbd37",
    "prId" : 27436,
    "prUrl" : "https://github.com/apache/spark/pull/27436#pullrequestreview-354131526",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ecbe6106-5473-4416-892c-29d6d5b86a7e",
        "parentId" : null,
        "authorId" : "39fe625f-8c54-48bc-ac6f-7279921adf02",
        "body" : "is this requirement: firstUdes must contains udes on the following expression?\r\n",
        "createdAt" : "2020-02-06T00:20:36Z",
        "updatedAt" : "2020-02-06T00:20:36Z",
        "lastEditedBy" : "39fe625f-8c54-48bc-ac6f-7279921adf02",
        "tags" : [
        ]
      }
    ],
    "commit" : "37ba243320ecf4029dfbd1f9dc4ffdc886770d5c",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +97,101 @@        val accessedExpressions = c.children.filter { e =>\n          val udes = e.collect { case u: UserDefinedExpression => u }\n          udes.nonEmpty && firstUdes.containsSlice(udes)\n        }\n        if (accessedExpressions.nonEmpty) {"
  },
  {
    "id" : "aa68a74d-4db0-44d4-accc-1b0bddfd7ec5",
    "prId" : 25925,
    "prUrl" : "https://github.com/apache/spark/pull/25925#pullrequestreview-293498085",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b92fba71-bb18-4d33-aa94-4973a57b19ac",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Just for curiosity, does this issue happen in interpreted code path as well? e.g. we send `PlanExpression` to executor side and eval it, and hit NPE.",
        "createdAt" : "2019-09-26T05:28:46Z",
        "updatedAt" : "2019-09-26T05:28:46Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "f92304be-18dc-4097-b128-764a9d2da62e",
        "parentId" : "b92fba71-bb18-4d33-aa94-4973a57b19ac",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "IIUC,`EquivalentExpressions` is only used in the codegen mode now, e.g., `GenerateUnsafeProjection` uses this class in common subexpr elimination, but `InterpretedUnsafeProject does not elimnate common subexprs.",
        "createdAt" : "2019-09-26T05:41:47Z",
        "updatedAt" : "2019-09-26T05:41:47Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "13f13cd1-3acf-45e0-8ff4-158e52696a08",
        "parentId" : "b92fba71-bb18-4d33-aa94-4973a57b19ac",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Not sure I understand your question correctly. But PlanExpressions of a SparkPlan are evaluated and updated (e.g., ExecSubqueryExpression.updateResult) with values before a query begins to run. The values are kept in PlanExpression, and on executor side when to call eval of PlanExpression, it simply returns the kept value. I think we do not really evaluate a PlanExpression at executor side.\r\n\r\n\r\n",
        "createdAt" : "2019-09-26T05:44:41Z",
        "updatedAt" : "2019-09-26T05:44:41Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "2f2e072c-7850-4a05-99f3-e7f2cc9a6548",
        "parentId" : "b92fba71-bb18-4d33-aa94-4973a57b19ac",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ah got it, so the kept value is serialized and sent to executor side in interpreted code path.",
        "createdAt" : "2019-09-26T05:48:05Z",
        "updatedAt" : "2019-09-26T05:48:06Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "921daffa-0d2f-4890-83fd-90b75c62fa90",
        "parentId" : "b92fba71-bb18-4d33-aa94-4973a57b19ac",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This issue also reminds me that it's better to always do codegen at driver side, even if whole-stage-codegen is false. We can investigate it later.",
        "createdAt" : "2019-09-26T05:49:40Z",
        "updatedAt" : "2019-09-26T05:49:40Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "a24370f1-bf41-4349-a16c-6803d7fb8fbc",
        "parentId" : "b92fba71-bb18-4d33-aa94-4973a57b19ac",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Ok. Please let me know if you have some ideas later.",
        "createdAt" : "2019-09-26T05:58:52Z",
        "updatedAt" : "2019-09-26T05:58:53Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "75109a01011e313ede4ceedc92139ef10f972e53",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +77,81 @@      // `PlanExpression` wraps query plan. To compare query plans of `PlanExpression` on executor,\n      // can cause error like NPE.\n      (expr.isInstanceOf[PlanExpression[_]] && TaskContext.get != null)\n\n    // There are some special expressions that we should not recurse into all of its children."
  },
  {
    "id" : "3584bf06-2442-488a-835d-0fb1cd93eb4c",
    "prId" : 25717,
    "prUrl" : "https://github.com/apache/spark/pull/25717#pullrequestreview-285223515",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "905d25ef-5d5e-4716-abda-99d5fd0dead7",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "We cannot always share a function for non-deterministic cases? e.g.,\r\n```\r\nint subExpr1 = input[0] + random();\r\nint subExpr2 = input[1] + random();\r\n=>\r\nint subExpr1 = subExpr(input[0]);\r\nint subExpr2 = subExpr(input[1]);\r\n\r\nint subExpr(int v) { return v + random(); }\r\n```",
        "createdAt" : "2019-09-08T05:28:09Z",
        "updatedAt" : "2019-09-16T20:29:06Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "1370ef87-7327-4c3f-b271-ee4b7c6700cc",
        "parentId" : "905d25ef-5d5e-4716-abda-99d5fd0dead7",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Non-deterministic expressions can't do sub-expression elimination.",
        "createdAt" : "2019-09-08T05:40:45Z",
        "updatedAt" : "2019-09-16T20:29:06Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "a3d57b53-beb4-43b0-be3f-3f0709e03282",
        "parentId" : "905d25ef-5d5e-4716-abda-99d5fd0dead7",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "oh, I see.",
        "createdAt" : "2019-09-08T05:46:57Z",
        "updatedAt" : "2019-09-16T20:29:06Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "da597459-1038-494e-b090-d90cd57164f0",
        "parentId" : "905d25ef-5d5e-4716-abda-99d5fd0dead7",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "btw, this idea is limited to common subexprs? For example, the idea can cover a case like;\r\n```\r\nselect sum(a + b), sum(b + c), sum(c + d), sum(d + e) from values (1, 1, 1, 1, 1) t(a, b, c, d, e)\r\n```\r\n?",
        "createdAt" : "2019-09-08T06:26:36Z",
        "updatedAt" : "2019-09-16T20:29:06Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "fc168b25-a0fc-4116-a84c-9464abcdccb1",
        "parentId" : "905d25ef-5d5e-4716-abda-99d5fd0dead7",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "It is probably suitable. Only if we want these functions sum(a+b)...etc. to be called in split functions. Their inputs can be parameterized.",
        "createdAt" : "2019-09-08T16:05:34Z",
        "updatedAt" : "2019-09-16T20:29:06Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "4700b89004380e48ed484311018686856df3027e",
    "line" : 74,
    "diffHunk" : "@@ -1,1 +98,102 @@   */\n  def addStructExpr(expr: Expression): Boolean = {\n    if (expr.deterministic) {\n      // For structural equivalent expressions, we need to pass in int type ordinals into\n      // split functions. If the number of ordinals is more than JVM function limit, we skip"
  },
  {
    "id" : "3db83204-7a63-40b3-88e5-4facce59952e",
    "prId" : 25717,
    "prUrl" : "https://github.com/apache/spark/pull/25717#pullrequestreview-285223543",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f058c045-e5b4-4c1d-bb45-29e1d6c49f69",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "If the length goes over the limit, the current logic gives up eliminating common exprs? If so, can we fall back into the non-structural mode?",
        "createdAt" : "2019-09-08T09:14:33Z",
        "updatedAt" : "2019-09-16T20:29:06Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "75e7e8a1-e187-404c-b891-b28a2145a80b",
        "parentId" : "f058c045-e5b4-4c1d-bb45-29e1d6c49f69",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Good idea.",
        "createdAt" : "2019-09-08T16:06:20Z",
        "updatedAt" : "2019-09-16T20:29:06Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "4700b89004380e48ed484311018686856df3027e",
    "line" : 84,
    "diffHunk" : "@@ -1,1 +108,112 @@      }\n      val parameterLength = CodeGenerator.calculateParamLength(refs) + 2\n      if (CodeGenerator.isValidParamLength(parameterLength)) {\n        val e: StructuralExpr = StructuralExpr(expr)\n        val f = structEquivalenceMap.get(e)"
  },
  {
    "id" : "040bf7c9-3d1b-4964-b3a1-aecdd5b03167",
    "prId" : 25717,
    "prUrl" : "https://github.com/apache/spark/pull/25717#pullrequestreview-285238825",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "48dd7be5-1eba-4ef2-a009-f13283855826",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Naturally thinking from the comment, I thought the type's `mutable.HashMap.empty[StructuralExpr, mutable.ArrayBuffer[Expression]]`. Is  the value `EquivalenceMap` because you reuse the existing logic?",
        "createdAt" : "2019-09-08T09:32:35Z",
        "updatedAt" : "2019-09-16T20:29:06Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "dc3e408e-d6ae-47fb-a02e-0b61ac66b225",
        "parentId" : "48dd7be5-1eba-4ef2-a009-f13283855826",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Among expressions with same structure, there are still different sub-set of expressions which are semantically different to each others. I need the EquivalenceMap here to distinguish them. ",
        "createdAt" : "2019-09-08T20:16:11Z",
        "updatedAt" : "2019-09-16T20:29:06Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "e43fd0c8-3843-4c9b-8b8d-184e6726c459",
        "parentId" : "48dd7be5-1eba-4ef2-a009-f13283855826",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Yea, it looks ok. So, could you update the comment to describe more?",
        "createdAt" : "2019-09-08T22:42:56Z",
        "updatedAt" : "2019-09-16T20:29:06Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "4700b89004380e48ed484311018686856df3027e",
    "line" : 41,
    "diffHunk" : "@@ -1,1 +69,73 @@  // which are semantically different to each others. Thus, under each key, the value is\n  // the map structure used to do semantically sub-expression elimination.\n  private val structEquivalenceMap = mutable.HashMap.empty[StructuralExpr, EquivalenceMap]\n\n  /**"
  },
  {
    "id" : "01a47c27-7c80-4b12-987b-d89ecee89c0c",
    "prId" : 25717,
    "prUrl" : "https://github.com/apache/spark/pull/25717#pullrequestreview-288878343",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f4d69e52-5912-4665-95df-73fdcadf0e89",
        "parentId" : null,
        "authorId" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "body" : "nit: Do we need ` = this.equivalenceMap`? It seems that all of the callers pass two arguments.",
        "createdAt" : "2019-09-16T03:26:06Z",
        "updatedAt" : "2019-09-16T20:29:06Z",
        "lastEditedBy" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "tags" : [
        ]
      },
      {
        "id" : "1ddaaf8d-d0f4-407e-8419-afd421534756",
        "parentId" : "f4d69e52-5912-4665-95df-73fdcadf0e89",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "addExpr is also used at PhysicalAggregation:\r\n\r\nhttps://github.com/apache/spark/blob/2f3997fddca44a89b3b8e8b9cc114e26ee4c1d39/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/planning/patterns.scala#L222-L229",
        "createdAt" : "2019-09-16T20:23:47Z",
        "updatedAt" : "2019-09-16T20:29:06Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "4700b89004380e48ed484311018686856df3027e",
    "line" : 49,
    "diffHunk" : "@@ -1,1 +76,80 @@   * Returns true if there was already a matching expression.\n   */\n  def addExpr(expr: Expression, exprMap: EquivalenceMap = this.equivalenceMap): Boolean = {\n    if (expr.deterministic) {\n      val e: Expr = Expr(expr)"
  },
  {
    "id" : "84bb5e10-037d-4c63-bbb3-1c4386a34836",
    "prId" : 25717,
    "prUrl" : "https://github.com/apache/spark/pull/25717#pullrequestreview-288879963",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "83b1a7a2-9444-44a3-81ed-26e25b947b54",
        "parentId" : null,
        "authorId" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "body" : "nit: Do we need some words for `SortPrefix`?",
        "createdAt" : "2019-09-16T03:35:39Z",
        "updatedAt" : "2019-09-16T20:29:06Z",
        "lastEditedBy" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "tags" : [
        ]
      },
      {
        "id" : "ea6fe349-038a-4f0e-a87b-b2bca06a4b76",
        "parentId" : "83b1a7a2-9444-44a3-81ed-26e25b947b54",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "These words are copied from previous place. Let me add one for it.",
        "createdAt" : "2019-09-16T20:26:42Z",
        "updatedAt" : "2019-09-16T20:29:06Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "4700b89004380e48ed484311018686856df3027e",
    "line" : 125,
    "diffHunk" : "@@ -1,1 +147,151 @@  //                will always get accessed.\n  //   4. Coalesce: it's also a conditional expression, we should only recurse into the first\n  //                children, because others may not get accessed.\n  //   5. SortPrefix: skipt the direct child of SortPrefix which is an unevaluable SortOrder.\n  private def childrenToRecurse(expr: Expression): Seq[Expression] = expr match {"
  },
  {
    "id" : "f2bdc527-817f-43d8-9d00-64922e17b723",
    "prId" : 25717,
    "prUrl" : "https://github.com/apache/spark/pull/25717#pullrequestreview-289513982",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9b2464c0-1754-48ee-9671-74fb08dab28e",
        "parentId" : null,
        "authorId" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "body" : "nit: do we want to add `(_)`?",
        "createdAt" : "2019-09-16T03:41:52Z",
        "updatedAt" : "2019-09-16T20:29:06Z",
        "lastEditedBy" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "tags" : [
        ]
      },
      {
        "id" : "b505709b-b672-4a47-94d0-f8137ec05646",
        "parentId" : "9b2464c0-1754-48ee-9671-74fb08dab28e",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "addExprTree doesn't add (_) too. Just followed it. If no special reason, I will leave it.",
        "createdAt" : "2019-09-16T20:27:32Z",
        "updatedAt" : "2019-09-16T20:29:06Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "2663ff7e-ba02-42c9-8efd-4f2e67cd2812",
        "parentId" : "9b2464c0-1754-48ee-9671-74fb08dab28e",
        "authorId" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "body" : "I am neutral on this.   \r\nI was curious why [this line](https://github.com/apache/spark/pull/25717/files#diff-8bcc5aea39c73d4bf38aef6f6951d42cR1042) added `(_)`, but here does not add.",
        "createdAt" : "2019-09-17T08:52:02Z",
        "updatedAt" : "2019-09-17T08:52:03Z",
        "lastEditedBy" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "tags" : [
        ]
      },
      {
        "id" : "e98a8552-7012-4016-8bba-542e2638deef",
        "parentId" : "9b2464c0-1754-48ee-9671-74fb08dab28e",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "At that line, if not add a (_) to call addExprTree, will see compilation error:\r\n\r\n```\r\n[error]  found   : (org.apache.spark.sql.catalyst.expressions.Expression, equivalentExpressions.EquivalenceMap) => Unit                                                               \r\n[error]     (which expands to)  (org.apache.spark.sql.catalyst.expressions.Expression, scala.collection.mutable.HashMap[equivalentExpressions.Expr,scala.collection.mutable.ArrayBuff$r[org.apache.spark.sql.catalyst.expressions.Expression]]) => Unit                                                                                                                     \r\n[error]  required: org.apache.spark.sql.catalyst.expressions.Expression => ?               \r\n[error]     expressions.foreach(equivalentExpressions.addExprTree)     \r\n[error]                                               ^                                                                                                                               \r\n```\r\n\r\nBecause addExprTree actually needs to arguments, it doesn't match foreach's argument type.",
        "createdAt" : "2019-09-17T20:04:52Z",
        "updatedAt" : "2019-09-17T20:04:53Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "4700b89004380e48ed484311018686856df3027e",
    "line" : 176,
    "diffHunk" : "@@ -1,1 +180,184 @@\n    if (!skip && addStructExpr(expr)) {\n      childrenToRecurse(expr).foreach(addStructuralExprTree)\n      true\n    } else {"
  }
]