[
  {
    "id" : "b3cb2d07-9a54-4850-b854-17010241592f",
    "prId" : 32488,
    "prUrl" : "https://github.com/apache/spark/pull/32488#pullrequestreview-669673430",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fe0437d1-d05b-420f-a481-aa5a7ddf6fb9",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I'm not sure we can hit this case, as `OptimizeIn` will turn it into `InSet`.\r\n\r\nCan you try a real query and see if the optimization in this PR takes place?",
        "createdAt" : "2021-05-24T15:49:09Z",
        "updatedAt" : "2021-05-24T15:49:09Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "e7cd4fc5-041f-4b5f-a4aa-5ec0049753ff",
        "parentId" : "fe0437d1-d05b-420f-a481-aa5a7ddf6fb9",
        "authorId" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "body" : "Yes, it does.\r\n\r\n```scala\r\n    spark.range(50)\r\n      .selectExpr(\"cast(id as int) as id\")\r\n      .write\r\n      .mode(\"overwrite\")\r\n      .parquet(\"/tmp/parquet/t1\")\r\n\r\n    spark.sql(\"SET spark.sql.planChangeLog.level=WARN\")\r\n    val in = (1 to 20).map {\r\n      case i => Literal.create(i.toLong)\r\n    }\r\n    spark.read\r\n      .load(\"/tmp/parquet/t1\")\r\n      .filter($\"id\".isin(in: _*))\r\n      .explain\r\n```\r\n\r\nBefore this pr:\r\n```\r\n== Physical Plan ==\r\n*(1) Filter cast(id#105 as bigint) INSET (5,10,14,20,1,6,9,13,2,17,12,7,3,18,16,11,8,19,4,15)\r\n+- *(1) ColumnarToRow\r\n   +- FileScan parquet [id#105] Batched: true, DataFilters: [cast(id#105 as bigint) INSET (5,10,14,20,1,6,9,13,2,17,12,7,3,18,16,11,8,19,4,15)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/tmp/parquet/t1], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<id:int>\r\n```\r\nAfter this pr;\r\n```\r\n15:33:02.191 WARN org.apache.spark.sql.catalyst.rules.PlanChangeLogger: \r\n=== Applying Rule org.apache.spark.sql.catalyst.optimizer.UnwrapCastInBinaryComparison ===\r\n!Filter cast(id#105 as bigint) IN (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20)   Filter id#105 IN (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20)\r\n +- Relation [id#105] parquet                                                            +- Relation [id#105] parquet\r\n\r\n15:33:02.197 WARN org.apache.spark.sql.catalyst.rules.PlanChangeLogger: \r\n=== Applying Rule org.apache.spark.sql.catalyst.optimizer.OptimizeIn ===\r\n!Filter id#105 IN (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20)   Filter id#105 INSET (5,10,14,20,1,6,9,13,2,17,12,7,3,18,16,11,8,19,4,15)\r\n +- Relation [id#105] parquet                                            +- Relation [id#105] parquet\r\n\r\n== Physical Plan ==\r\n*(1) Filter id#105 INSET (5,10,14,20,1,6,9,13,2,17,12,7,3,18,16,11,8,19,4,15)\r\n+- *(1) ColumnarToRow\r\n   +- FileScan parquet [id#105] Batched: true, DataFilters: [id#105 INSET (5,10,14,20,1,6,9,13,2,17,12,7,3,18,16,11,8,19,4,15)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/tmp/parquet/t1], PartitionFilters: [], PushedFilters: [In(id, [5,10,14,20,1,6,9,13,2,17,12,7,3,18,16,11,8,19,4,15])], ReadSchema: struct<id:int>\r\n```",
        "createdAt" : "2021-05-25T07:41:09Z",
        "updatedAt" : "2021-05-25T07:41:10Z",
        "lastEditedBy" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "tags" : [
        ]
      },
      {
        "id" : "18f17eaf-daf3-4a3a-af4b-ed003c5df8dc",
        "parentId" : "fe0437d1-d05b-420f-a481-aa5a7ddf6fb9",
        "authorId" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "body" : "Shall we add an end-to-end test for this case?",
        "createdAt" : "2021-05-25T07:45:38Z",
        "updatedAt" : "2021-05-25T07:45:38Z",
        "lastEditedBy" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "tags" : [
        ]
      },
      {
        "id" : "73f37065-1dbc-4574-b6a0-1c45a5b27ea4",
        "parentId" : "fe0437d1-d05b-420f-a481-aa5a7ddf6fb9",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "So we are relying on the assumption that `UnwrapCastInBinaryComparison` happens before `OptimizeIn`.\r\n\r\nThis is fragile as the execution order of the rules in the same batch is pretty unpredictable, and may change over time if code factor happens, new optimization rules added, etc.\r\n\r\nIt's better to make sure these catalyst rules are orthogonal, and that's why `In` and `InSet` usually appears together: if a rule needs to handle In, it usually should handle InSet as well.",
        "createdAt" : "2021-05-25T13:52:31Z",
        "updatedAt" : "2021-05-25T13:52:38Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "b17fb7b5-e562-45d5-8d24-455f12939715",
        "parentId" : "fe0437d1-d05b-420f-a481-aa5a7ddf6fb9",
        "authorId" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "body" : "Make sense.",
        "createdAt" : "2021-05-26T09:45:55Z",
        "updatedAt" : "2021-05-26T09:45:55Z",
        "lastEditedBy" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "tags" : [
        ]
      },
      {
        "id" : "49649e49-abfd-40ac-9d14-a41cdb57b264",
        "parentId" : "fe0437d1-d05b-420f-a481-aa5a7ddf6fb9",
        "authorId" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "body" : "Updated and add `InSet` support.",
        "createdAt" : "2021-05-27T01:41:09Z",
        "updatedAt" : "2021-05-27T01:41:10Z",
        "lastEditedBy" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "tags" : [
        ]
      }
    ],
    "commit" : "ea0ba385ec38b231a37f871cecf1ca9ffb852c3d",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +33,37 @@ * - `BinaryComparison(Cast(fromExp, toType), Literal(value, toType))`\n * - `BinaryComparison(Literal(value, toType), Cast(fromExp, toType))`\n * - `In(Cast(fromExp, toType), Seq(Literal(v1, toType), Literal(v2, toType), ...)`\n * - `InSet(Cast(fromExp, toType), Set(v1, v2, ...))`\n *"
  },
  {
    "id" : "443c0228-ea2e-4578-981d-be5addcb399d",
    "prId" : 32488,
    "prUrl" : "https://github.com/apache/spark/pull/32488#pullrequestreview-673890722",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "38eadbb9-06f5-4732-ba94-884e5e754312",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "The null literal handling is a bit tricky and I think it's better to put all the steps in the comment. There are 3 kinds of literals in the list:\r\n1. null literals\r\n2. The literals that can cast to `fromExp.dataType`\r\n3. The literals that cannot cast to `fromExp.dataType`\r\n\r\nnull literals is special, because if we call `unwrapCast` directly, null means cannot cast, which is misleading as we can cast null literals to any data type.\r\n\r\nThe ideal steps in my mind:\r\n1. Call `unwrapCast` with non-null literals in the list\r\n2. If there is no literal that can cast to `fromExp.dataType`, return the original expression\r\n3. Otherwise, use the literals that can cast to `fromExp.dataType` and the null literals to create a new `In` expression, with additional `falseIfNotNull` check.",
        "createdAt" : "2021-06-01T12:36:48Z",
        "updatedAt" : "2021-06-01T12:36:49Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "0e15dd9d-a473-4101-b74e-5b4acca5756f",
        "parentId" : "38eadbb9-06f5-4732-ba94-884e5e754312",
        "authorId" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "body" : "Thanks for your suggestion, I'll try your idea.",
        "createdAt" : "2021-06-02T02:19:26Z",
        "updatedAt" : "2021-06-02T02:19:26Z",
        "lastEditedBy" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "tags" : [
        ]
      },
      {
        "id" : "0005dccc-7ba8-490e-a159-53f5761e9e8f",
        "parentId" : "38eadbb9-06f5-4732-ba94-884e5e754312",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Another idea: We can use `AnsiCast(...).eval`, which fails if overflow happens. Then null literal is the same as other literals that can cast to `fromExp.dataType`, and we don't need to distinguish them.",
        "createdAt" : "2021-06-02T03:00:15Z",
        "updatedAt" : "2021-06-02T03:00:15Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "27bd433c-a45d-45a5-a49d-1cbf4e366035",
        "parentId" : "38eadbb9-06f5-4732-ba94-884e5e754312",
        "authorId" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "body" : "> Another idea: We can use AnsiCast(...).eval, which fails if overflow happens. Then null literal is the same as other literals that can cast to fromExp.dataType, and we don't need to distinguish them.\r\n\r\nGood idea,\r\n\r\n>The ideal steps in my mind:\r\n> 1. Call unwrapCast with non-null literals in the list\r\n> 2. If there is no literal that can cast to fromExp.dataType, return the original expression\r\n> 3. Otherwise, use the literals that can cast to fromExp.dataType and the null literals to create a new In expression, with additional falseIfNotNull check.\r\n\r\nbut I think this one is more clear.\r\n\r\nAnother question for stage 2: we should not return original expression when the can not cast literals is non-empty, but return `falseIfNotNull` instead, this is because original expression `In(Cast(fromExp, toType), list)` can't be optimized by other rules and trigger a filter stage, but `falseIfNotNull` can be optimized by `BooleanSimplification`, WDYT?\r\n\r\n",
        "createdAt" : "2021-06-02T07:31:45Z",
        "updatedAt" : "2021-06-02T07:31:46Z",
        "lastEditedBy" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "tags" : [
        ]
      },
      {
        "id" : "e1da46f4-f901-4eeb-b32e-637c618c680d",
        "parentId" : "38eadbb9-06f5-4732-ba94-884e5e754312",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "SGTM, it's still useful to optimize to `falseIfNotNull`",
        "createdAt" : "2021-06-02T07:48:56Z",
        "updatedAt" : "2021-06-02T07:48:56Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "ea0ba385ec38b231a37f871cecf1ca9ffb852c3d",
    "line" : 61,
    "diffHunk" : "@@ -1,1 +137,141 @@    // As the analyzer makes sure that the list of In is already of the same data type, then the\n    // rule can simply check the first literal in `in.list` can implicitly cast to `toType` or not,\n    // and note that:\n    // 1. this rule doesn't convert in when `in.list` is empty or `in.list` contains only null\n    // values."
  },
  {
    "id" : "a9260364-6210-4d23-b2be-18b81c64c1af",
    "prId" : 29792,
    "prUrl" : "https://github.com/apache/spark/pull/29792#pullrequestreview-498732403",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "48eeff62-1320-4de1-bb44-ae0bb19dd841",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "why the upper bound is not `PositiveInfinity`?",
        "createdAt" : "2020-09-29T08:31:19Z",
        "updatedAt" : "2020-10-12T20:16:06Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "aa2ccaa3-bf29-476c-b00b-51c5e0a61f60",
        "parentId" : "48eeff62-1320-4de1-bb44-ae0bb19dd841",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "This is because `PositiveInfinity` is considered to be < `NaN` in Spark. If we treat it as the upper bound, rules handling the upper bounds will not be valid. For instance the following expr:\r\n```sql\r\ncast(e as double) > double('+inf')\r\n```\r\nwould be converted to\r\n```sql\r\ne === double('+inf')\r\n```\r\nwhich won't be correct if `e` evaluates to `double('NaN')`.",
        "createdAt" : "2020-09-29T17:44:41Z",
        "updatedAt" : "2020-10-12T20:16:06Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      }
    ],
    "commit" : "76b9f73862380dda40b332b56464278bfb0b88d3",
    "line" : 270,
    "diffHunk" : "@@ -1,1 +267,271 @@    case IntegerType => Some((Int.MinValue, Int.MaxValue))\n    case LongType => Some((Long.MinValue, Long.MaxValue))\n    case FloatType => Some((Float.NegativeInfinity, Float.NaN))\n    case DoubleType => Some((Double.NegativeInfinity, Double.NaN))\n    case _ => None"
  },
  {
    "id" : "e4861fb4-b637-4390-b2af-9dc93af06c48",
    "prId" : 29792,
    "prUrl" : "https://github.com/apache/spark/pull/29792#pullrequestreview-502755440",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b2115506-3855-49f2-9aa3-0ebc30cc2444",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "why it's safe to skip range check for decimal type?",
        "createdAt" : "2020-09-29T08:37:35Z",
        "updatedAt" : "2020-10-12T20:16:06Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "3fc85a7b-6b07-40f5-a4f5-22137676324c",
        "parentId" : "b2115506-3855-49f2-9aa3-0ebc30cc2444",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "It is safe since knowing min/max for a type just gives us more opportunity for optimizations. I skipped decimal type here because (it seems) there is no min/max defined in the `DecimalType`, unlike other numeric types.",
        "createdAt" : "2020-09-29T17:47:24Z",
        "updatedAt" : "2020-10-12T20:16:06Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "db0a2605-6044-49cc-a062-bcc822e69325",
        "parentId" : "b2115506-3855-49f2-9aa3-0ebc30cc2444",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "makes sense.",
        "createdAt" : "2020-10-06T09:33:32Z",
        "updatedAt" : "2020-10-12T20:16:06Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "76b9f73862380dda40b332b56464278bfb0b88d3",
    "line" : 171,
    "diffHunk" : "@@ -1,1 +203,207 @@\n    // When we reach to this point, it means either there is no min/max for the `fromType` (e.g.,\n    // decimal type), or that the literal `value` is within range `(min, max)`. For these, we\n    // optimize by moving the cast to the literal side.\n"
  },
  {
    "id" : "d8cd1727-453d-42d1-8ad3-5f92f47df8f5",
    "prId" : 29792,
    "prUrl" : "https://github.com/apache/spark/pull/29792#pullrequestreview-498717462",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ee2f792c-2b2c-4c3f-bad2-be5a92a58cca",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "The case I'm worried about is `cast(float_col as double) cmp double_lit`. It's not straightforward to me that a `double -> float -> double` roundtrip can tell rounding up or down. is it because `float -> double` can only be rounding up?",
        "createdAt" : "2020-09-29T08:50:15Z",
        "updatedAt" : "2020-10-12T20:16:06Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "077b3cb8-b001-4621-92df-05699876c319",
        "parentId" : "ee2f792c-2b2c-4c3f-bad2-be5a92a58cca",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "So double to float can result to either rounding up or down. For instance, by casting 3.14 in double to float, even though the value is still 3.14, the binary representation is rounded up:\r\n\r\n3.14 in double:\r\n```\r\n0 10000000000 1001 0001 1110 1011 1000 0101 0001 1110 1011 1000 0101 0001 1111\r\n```\r\n\r\n3.14 in float\r\n```\r\n0 10000000 1001 0001 1110 1011 1000 011\r\n```\r\nHere the sign bit and exponent bits (11 and 8 bits respectively for double and float) are the same for both float and double. However, in the fraction part, the last is rounded up to 1.\r\n\r\nAfter casting back to double, there won't be any rounding up or down - the remaining digits are simply padded with 0:\r\n```\r\n0 10000000000 1001 0001 1110 1011 1000 0110 0000000000000000000000000000\r\n```\r\n",
        "createdAt" : "2020-09-29T16:37:41Z",
        "updatedAt" : "2020-10-12T20:16:06Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "ed6b2bff-c335-493d-aaf5-35284df012b0",
        "parentId" : "ee2f792c-2b2c-4c3f-bad2-be5a92a58cca",
        "authorId" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "body" : "Is it defined as part of IEEE Standard for Floating-Point Arithmetic (IEEE 754)?",
        "createdAt" : "2020-09-29T16:40:07Z",
        "updatedAt" : "2020-10-12T20:16:06Z",
        "lastEditedBy" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "tags" : [
        ]
      },
      {
        "id" : "1bd01b6c-464e-4ad0-a7cc-3dee00753f1e",
        "parentId" : "ee2f792c-2b2c-4c3f-bad2-be5a92a58cca",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "Yes I think both the binary format as well as rounding rules are specified in IEEE 754. There are a few rounding rules and I think the default one is \"rounding to half even\".",
        "createdAt" : "2020-09-29T17:25:51Z",
        "updatedAt" : "2020-10-12T20:16:06Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      }
    ],
    "commit" : "76b9f73862380dda40b332b56464278bfb0b88d3",
    "line" : 180,
    "diffHunk" : "@@ -1,1 +212,216 @@      return exp\n    }\n    val valueRoundTrip = Cast(Literal(newValue, fromType), toType).eval()\n    val lit = Literal(newValue, fromType)\n    val cmp = ordering.compare(value, valueRoundTrip)"
  },
  {
    "id" : "a49fe387-472d-4585-a4d3-f4ed74809647",
    "prId" : 29792,
    "prUrl" : "https://github.com/apache/spark/pull/29792#pullrequestreview-503150938",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3d11374e-280c-4a9f-bedd-3e3bb72dd165",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can you give a real example here?",
        "createdAt" : "2020-10-06T09:34:30Z",
        "updatedAt" : "2020-10-12T20:16:06Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "7159b4a4-8135-45cd-8cb8-29437206f54d",
        "parentId" : "3d11374e-280c-4a9f-bedd-3e3bb72dd165",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I see, it's for decimal only. It's better to make the comment more explicit.",
        "createdAt" : "2020-10-06T12:49:05Z",
        "updatedAt" : "2020-10-12T20:16:06Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "a5bfe5aa-8828-4046-a708-5d7a8f1bd1c0",
        "parentId" : "3d11374e-280c-4a9f-bedd-3e3bb72dd165",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "yup will do - there is also a test case covering this.",
        "createdAt" : "2020-10-06T16:30:04Z",
        "updatedAt" : "2020-10-12T20:16:06Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      }
    ],
    "commit" : "76b9f73862380dda40b332b56464278bfb0b88d3",
    "line" : 177,
    "diffHunk" : "@@ -1,1 +209,213 @@    if (newValue == null) {\n      // This means the cast failed, for instance, due to the value is not representable in the\n      // narrower type. In this case we simply return the original expression.\n      return exp\n    }"
  },
  {
    "id" : "b103ead0-88f0-48be-a743-18a4ebded9bb",
    "prId" : 29792,
    "prUrl" : "https://github.com/apache/spark/pull/29792#pullrequestreview-505844184",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9392b738-d2ab-4387-82e1-d57510f02f93",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Looks it does not have any test for this code path, so could you add some tests for it. (NOTE: I think `byte`, `int`, and `long` are not tested in `UnwrapCastInBinaryComparisonSuite`, too)",
        "createdAt" : "2020-10-09T12:43:28Z",
        "updatedAt" : "2020-10-12T20:16:06Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "b71c5245-a5ec-4256-a4db-eb9ba3c4fc01",
        "parentId" : "9392b738-d2ab-4387-82e1-d57510f02f93",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "Will add a test case (although I think it will be pretty trivial). I only added tests for `short` in the previous PR because the handling for other integral types is exactly the same.",
        "createdAt" : "2020-10-09T16:56:41Z",
        "updatedAt" : "2020-10-12T20:16:06Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      }
    ],
    "commit" : "76b9f73862380dda40b332b56464278bfb0b88d3",
    "line" : 271,
    "diffHunk" : "@@ -1,1 +268,272 @@    case LongType => Some((Long.MinValue, Long.MaxValue))\n    case FloatType => Some((Float.NegativeInfinity, Float.NaN))\n    case DoubleType => Some((Double.NegativeInfinity, Double.NaN))\n    case _ => None\n  }"
  },
  {
    "id" : "c3fe9e03-f943-40cc-a364-94ae0ee27f8d",
    "prId" : 29565,
    "prUrl" : "https://github.com/apache/spark/pull/29565#pullrequestreview-479272314",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a609d6a0-4f9a-446c-95e9-e36cb43c226d",
        "parentId" : null,
        "authorId" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "body" : "```\r\nif `exp < max of exp type < value`, the cases are of following:\r\n```",
        "createdAt" : "2020-08-31T23:46:24Z",
        "updatedAt" : "2020-09-11T20:44:56Z",
        "lastEditedBy" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "tags" : [
        ]
      },
      {
        "id" : "74ac779a-8415-4f0f-be6a-0d30cb77ab61",
        "parentId" : "a609d6a0-4f9a-446c-95e9-e36cb43c226d",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "I think `exp < max of exp type` is slightly confusing here, and`max` and `min` are already defined earlier. How about I switch to:\r\n\r\n```\r\n *  - `cast(fromExp, toType) > value` ==> if(isnull(fromExp), null, false)\r\n *  - `cast(fromExp, toType) >= value` ==> if(isnull(fromExp), null, false)\r\n...\r\n```\r\n\r\nto make it more clear?",
        "createdAt" : "2020-09-01T00:03:08Z",
        "updatedAt" : "2020-09-11T20:44:56Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "980b766a-0a2f-4ff6-aa50-9d5e135dfb45",
        "parentId" : "a609d6a0-4f9a-446c-95e9-e36cb43c226d",
        "authorId" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "body" : "Yeah, it's clear. Should we make it `if(isnotnull(fromExp), false, null)` instead?",
        "createdAt" : "2020-09-01T00:25:23Z",
        "updatedAt" : "2020-09-11T20:44:56Z",
        "lastEditedBy" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "tags" : [
        ]
      },
      {
        "id" : "a0230823-e952-48a8-930a-9dcc3971ea95",
        "parentId" : "a609d6a0-4f9a-446c-95e9-e36cb43c226d",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "I don't see much difference between the two and I think the expression itself should be easy to understand. With that said I don't hold strong opinion on this and either way is OK to me :)",
        "createdAt" : "2020-09-01T01:23:43Z",
        "updatedAt" : "2020-09-11T20:44:56Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      }
    ],
    "commit" : "5f32ee5fda08f4271959589c7f6312195898af08",
    "line" : 53,
    "diffHunk" : "@@ -1,1 +51,55 @@ * cases and try to replace each with simpler constructs.\n *\n * if `value > max`, the cases are of following:\n *  - `cast(fromExp, toType) > value` ==> if(isnull(fromExp), null, false)\n *  - `cast(fromExp, toType) >= value` ==> if(isnull(fromExp), null, false)"
  },
  {
    "id" : "dcf1c47d-2310-4caf-aa65-ad044dcfac7b",
    "prId" : 29565,
    "prUrl" : "https://github.com/apache/spark/pull/29565#pullrequestreview-484704496",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6a362468-42a4-4db2-b219-956b3f0513a2",
        "parentId" : null,
        "authorId" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "body" : "Does it worth to specifically handle `value == max` and `value == min`? Rules will add cost into planning phase, and we probably not going to run into those two cases often in real world queries. Should we handle them as if it's within the range?",
        "createdAt" : "2020-09-01T00:23:19Z",
        "updatedAt" : "2020-09-11T20:44:56Z",
        "lastEditedBy" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "tags" : [
        ]
      },
      {
        "id" : "b5a6114d-db39-4516-b982-39efa3e6da65",
        "parentId" : "6a362468-42a4-4db2-b219-956b3f0513a2",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "It is hard to answer this question without knowing things like how normally user write queries, how much time this rule uses comparing to other rules, and how much time these specific 2 cases use. IMO the optimization on these two cases can offer significant speed up, and the extra cost is just the pattern matching:\r\n\r\n```\r\nelse if (maxCmp == 0) {\r\n      exp match {\r\n        case GreaterThan(_, _) =>\r\n          fromExp.falseIfNotNull\r\n        case LessThanOrEqual(_, _) =>\r\n          fromExp.trueIfNotNull\r\n        case LessThan(_, _) =>\r\n          Not(EqualTo(fromExp, Literal(max, fromType)))\r\n        case GreaterThanOrEqual(_, _) | EqualTo(_, _) | EqualNullSafe(_, _) =>\r\n          EqualTo(fromExp, Literal(max, fromType))\r\n        case _ => exp\r\n      }\r\n```\r\n\r\nwhich I think should be pretty fast? comparing to the rule itself which may require walking the whole plan tree.",
        "createdAt" : "2020-09-01T00:59:37Z",
        "updatedAt" : "2020-09-11T20:44:56Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "a1137982-f96b-4de1-b000-4af4d6684219",
        "parentId" : "6a362468-42a4-4db2-b219-956b3f0513a2",
        "authorId" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "body" : "If we don't have `maxCmp == 0` and `minCmp ==0`, it will be optimized to the following. Those can still be pushed down.\r\n```\r\n      val lit = Cast(Literal(value), fromType)\r\n      exp match {\r\n        case GreaterThan(_, _) => GreaterThan(fromExp, lit)\r\n        case GreaterThanOrEqual(_, _) => GreaterThanOrEqual(fromExp, lit)\r\n        case EqualTo(_, _) => EqualTo(fromExp, lit)\r\n        case EqualNullSafe(_, _) => EqualNullSafe(fromExp, lit)\r\n        case LessThan(_, _) => LessThan(fromExp, lit)\r\n        case LessThanOrEqual(_, _) => LessThanOrEqual(fromExp, lit)\r\n        case _ => exp\r\n      }\r\n```\r\n\r\nMaybe we can have separate rules that optimize from `GreaterThan(fromExp, lit)` to `fromExp.falseIfNotNull` when lit is the max of lit.dataType. So more plans can take advantage of it.",
        "createdAt" : "2020-09-01T04:56:43Z",
        "updatedAt" : "2020-09-11T20:44:56Z",
        "lastEditedBy" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "tags" : [
        ]
      },
      {
        "id" : "5ac49093-cbb8-4154-87f0-8f0c0e84c797",
        "parentId" : "6a362468-42a4-4db2-b219-956b3f0513a2",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "Those filters are not as effective though. We may add separate rules but that may be more expensive I think (we'll need again to check both sides of the comparison, what types the literal is, the min/max, what kind of expression `fromExp` is, and potential edge cases when both sides have different types etc). \r\n\r\nIMO the advantage of doing it here is that we've already done most of the checks and I don't see much extra cost.",
        "createdAt" : "2020-09-01T06:59:22Z",
        "updatedAt" : "2020-09-11T20:44:56Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "ff83573e-2a89-4d3d-94b6-22aa9c12d0b8",
        "parentId" : "6a362468-42a4-4db2-b219-956b3f0513a2",
        "authorId" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "body" : "I was thinking for `value == max`, we can have a separate rule such as\r\n\r\n```\r\n *  - `fromExp > value` where fromExp.type == value.dataType && getRange(fromExp)._2 == value` ==> if(isnull(fromExp), null, false)\r\n...\r\n...\r\n```\r\nwhich should be valid for other types. Thus, we don't need to handle `maxCmp == 0`, and it opens up other opportunities to optimize rules that don't have `cast`. WDYT?",
        "createdAt" : "2020-09-09T05:23:25Z",
        "updatedAt" : "2020-09-11T20:44:56Z",
        "lastEditedBy" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "tags" : [
        ]
      },
      {
        "id" : "0e705c56-fe77-40fa-9f27-af20dec1da75",
        "parentId" : "6a362468-42a4-4db2-b219-956b3f0513a2",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "Yes +1 on exploring that. I think we should keep the `maxCmp == 0` case for now though before that is ready, since this is more optimized with not much extra cost (without the `maxCmp == 0` we still have to do pattern matching in the else case).",
        "createdAt" : "2020-09-09T06:41:48Z",
        "updatedAt" : "2020-09-11T20:44:56Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "48d21e41-f1fe-4cae-ad06-fadc14d04a4c",
        "parentId" : "6a362468-42a4-4db2-b219-956b3f0513a2",
        "authorId" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "body" : "Let's consider it in the followup PR.",
        "createdAt" : "2020-09-09T06:45:14Z",
        "updatedAt" : "2020-09-11T20:44:56Z",
        "lastEditedBy" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "tags" : [
        ]
      }
    ],
    "commit" : "5f32ee5fda08f4271959589c7f6312195898af08",
    "line" : 71,
    "diffHunk" : "@@ -1,1 +69,73 @@ *  - `cast(fromExp, toType) < value` ==> fromExp =!= max\n *\n * Similarly for the cases when `value == min` and `value < min`.\n *\n * Further, the above `if(isnull(fromExp), null, false)` is represented using conjunction"
  },
  {
    "id" : "8280687a-daa4-49c3-bc7c-6d7c10d527d9",
    "prId" : 29565,
    "prUrl" : "https://github.com/apache/spark/pull/29565#pullrequestreview-479406200",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "65a835ee-a5d0-4b21-aeff-4d1d914e605a",
        "parentId" : null,
        "authorId" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "body" : "remove this empty line.",
        "createdAt" : "2020-09-01T05:17:16Z",
        "updatedAt" : "2020-09-11T20:44:56Z",
        "lastEditedBy" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "tags" : [
        ]
      }
    ],
    "commit" : "5f32ee5fda08f4271959589c7f6312195898af08",
    "line" : 100,
    "diffHunk" : "@@ -1,1 +98,102 @@        case _ => e\n      }\n\n      swap(unwrapCast(swap(exp)))\n"
  },
  {
    "id" : "64ac76d3-2436-4bd6-9c5d-910d2eadc48f",
    "prId" : 29565,
    "prUrl" : "https://github.com/apache/spark/pull/29565#pullrequestreview-484776918",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f1b432ba-9165-43ea-962b-27a9cff96a33",
        "parentId" : null,
        "authorId" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "body" : "We typically don't mix `if else` and patten matching. Maybe we can do nested patten matching or\r\n```scala\r\n(minCmp.signum, maxCmp.signum, exp) match {\r\n  case (_, 1,  EqualTo(_, _) | GreaterThan(_, _) | GreaterThanOrEqual(_, _) => ...\r\n  ...\r\n  case (_, 1, EqualNullSafe(_, _) if exp.deterministic => FalseLiteral\r\n  case (-1, _, GreaterThan(_, _) | GreaterThanOrEqual(_, _)) => fromExp.trueIfNotNull\r\n  ...\r\n  ...\r\n}\r\n```",
        "createdAt" : "2020-09-09T05:51:09Z",
        "updatedAt" : "2020-09-11T20:44:56Z",
        "lastEditedBy" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "tags" : [
        ]
      },
      {
        "id" : "672f8961-52ad-443a-956e-0569919880e1",
        "parentId" : "f1b432ba-9165-43ea-962b-27a9cff96a33",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "Yeah I considered this but thought `if else` is easier to understand. I can switch to pattern matching if this is more idiomatic in Spark.",
        "createdAt" : "2020-09-09T06:33:05Z",
        "updatedAt" : "2020-09-11T20:44:56Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "e6d6d63f-ffdd-4f98-93d1-4fd7ea0b8298",
        "parentId" : "f1b432ba-9165-43ea-962b-27a9cff96a33",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "updated - let me know if you think this is better",
        "createdAt" : "2020-09-09T08:28:52Z",
        "updatedAt" : "2020-09-11T20:44:56Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      }
    ],
    "commit" : "5f32ee5fda08f4271959589c7f6312195898af08",
    "line" : 134,
    "diffHunk" : "@@ -1,1 +132,136 @@    val maxCmp = ordering.compare(value, maxInToType)\n\n    if (maxCmp > 0) {\n      exp match {\n        case EqualTo(_, _) | GreaterThan(_, _) | GreaterThanOrEqual(_, _) =>"
  },
  {
    "id" : "d4e1f1f1-fe98-48b4-9ff5-94208343a07b",
    "prId" : 29565,
    "prUrl" : "https://github.com/apache/spark/pull/29565#pullrequestreview-487411760",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5e1353fb-5e32-4e01-b2cd-305f2186d1d7",
        "parentId" : null,
        "authorId" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "body" : "@cloud-fan for safety, we will skip optimization if exp is non deterministic. WDYT?",
        "createdAt" : "2020-09-09T05:52:39Z",
        "updatedAt" : "2020-09-11T20:44:56Z",
        "lastEditedBy" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "tags" : [
        ]
      },
      {
        "id" : "38169bd8-7935-4e95-b4ce-2cd723544925",
        "parentId" : "5e1353fb-5e32-4e01-b2cd-305f2186d1d7",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "SGTM",
        "createdAt" : "2020-09-14T04:44:39Z",
        "updatedAt" : "2020-09-14T04:44:39Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "5f32ee5fda08f4271959589c7f6312195898af08",
    "line" : 142,
    "diffHunk" : "@@ -1,1 +140,144 @@        // make sure the expression is evaluated if it is non-deterministic\n        case EqualNullSafe(_, _) if exp.deterministic =>\n          FalseLiteral\n        case _ => exp\n      }"
  },
  {
    "id" : "1b831519-f55c-4402-bbcc-7c0c550b2b41",
    "prId" : 29565,
    "prUrl" : "https://github.com/apache/spark/pull/29565#pullrequestreview-486154357",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f02e93ca-b183-4cd1-9a2e-b98671787a20",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "You may want to safe guard here; `case _: throw new UnsupportedOperationException`.",
        "createdAt" : "2020-09-09T18:00:13Z",
        "updatedAt" : "2020-09-11T20:44:56Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "a782d36b-c896-49ab-89c6-915b80a480aa",
        "parentId" : "f02e93ca-b183-4cd1-9a2e-b98671787a20",
        "authorId" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "body" : "We probably need to handle this exception in the caller to prevent the job being killed.",
        "createdAt" : "2020-09-09T19:47:45Z",
        "updatedAt" : "2020-09-11T20:44:56Z",
        "lastEditedBy" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "tags" : [
        ]
      },
      {
        "id" : "93cf0efe-1745-43b8-9466-edd95c9cd8f1",
        "parentId" : "f02e93ca-b183-4cd1-9a2e-b98671787a20",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "Will do. Ideally this should never happen though unless someone adds another subclass under `IntegralType` (and in that case the implementor should fulfill their responsibility by checking every place that does pattern matching on the parent type). It's unfortunate that we can't seal the class and rely on Scala's exhaustive pattern match compile-time check :(\r\n\r\nRegarding catching the exception, I don't think it is necessary since it should be an error in query compilation before job starts. I see similar pattern in [ColumnType](https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/columnar/ColumnType.scala#L767).",
        "createdAt" : "2020-09-10T17:25:24Z",
        "updatedAt" : "2020-09-11T20:44:56Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      }
    ],
    "commit" : "5f32ee5fda08f4271959589c7f6312195898af08",
    "line" : 217,
    "diffHunk" : "@@ -1,1 +215,219 @@    case ShortType => (Short.MinValue, Short.MaxValue)\n    case IntegerType => (Int.MinValue, Int.MaxValue)\n    case LongType => (Long.MinValue, Long.MaxValue)\n    case other => throw new IllegalArgumentException(s\"Unsupported type: ${other.catalogString}\")\n  }"
  },
  {
    "id" : "f1b2bb7d-a2ee-4eaf-b0b2-1b1a4d6d4686",
    "prId" : 29565,
    "prUrl" : "https://github.com/apache/spark/pull/29565#pullrequestreview-486349926",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cae0350e-7cbc-40a6-9f09-81bfd2ad2a50",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "For `cast(long_col as int) = int_literal`, we don't support it?",
        "createdAt" : "2020-09-10T03:41:21Z",
        "updatedAt" : "2020-09-11T20:44:56Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "3fa35429-fe95-403c-a5c0-432359e56340",
        "parentId" : "cae0350e-7cbc-40a6-9f09-81bfd2ad2a50",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ah I see, we can't support it, as `cast(long_col as int)` may overflow and we can't move cast to the other side. Can we add a comment here?",
        "createdAt" : "2020-09-10T03:42:13Z",
        "updatedAt" : "2020-09-11T20:44:56Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "4d02a030-f9ee-4f73-a649-3fad84b90c81",
        "parentId" : "cae0350e-7cbc-40a6-9f09-81bfd2ad2a50",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "Yes we don't support this case right now. Will add comment.",
        "createdAt" : "2020-09-10T17:47:28Z",
        "updatedAt" : "2020-09-11T20:44:56Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "a53554fe-8e4c-4a86-8922-e1a54fb8e8bf",
        "parentId" : "cae0350e-7cbc-40a6-9f09-81bfd2ad2a50",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "Added a comment on the top",
        "createdAt" : "2020-09-10T22:18:24Z",
        "updatedAt" : "2020-09-11T20:44:56Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      }
    ],
    "commit" : "5f32ee5fda08f4271959589c7f6312195898af08",
    "line" : 210,
    "diffHunk" : "@@ -1,1 +208,212 @@      fromExp.dataType.isInstanceOf[IntegralType] &&\n      toType.isInstanceOf[IntegralType] &&\n      Cast.canUpCast(fromExp.dataType, toType)\n  }\n"
  },
  {
    "id" : "c5855b95-69be-4a6c-b760-fa0db34c8dee",
    "prId" : 29565,
    "prUrl" : "https://github.com/apache/spark/pull/29565#pullrequestreview-486951421",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b175390c-52ce-440b-814e-a2a92dde6d21",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can we just convert everything to long and compare?",
        "createdAt" : "2020-09-10T04:58:17Z",
        "updatedAt" : "2020-09-11T20:44:56Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "19f51777-4087-4a89-9568-b87898d81d69",
        "parentId" : "b175390c-52ce-440b-814e-a2a92dde6d21",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "In CBO, we convert everything to `BigDecimal` and compare, which simplifies the code a lot.",
        "createdAt" : "2020-09-10T06:02:00Z",
        "updatedAt" : "2020-09-11T20:44:56Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "653d4fa3-a270-4200-8934-db8118b37bb9",
        "parentId" : "b175390c-52ce-440b-814e-a2a92dde6d21",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I don't think perf matters that much here.",
        "createdAt" : "2020-09-10T06:02:26Z",
        "updatedAt" : "2020-09-11T20:44:56Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "a03b7daf-5f91-4ecd-8554-f61c09d365b6",
        "parentId" : "b175390c-52ce-440b-814e-a2a92dde6d21",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "Hmm you mean we can just keep as it is right? I think semantically they are the same?",
        "createdAt" : "2020-09-10T22:21:20Z",
        "updatedAt" : "2020-09-11T20:44:56Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "efb3c772-f446-44ec-bf69-73d57a2b3902",
        "parentId" : "b175390c-52ce-440b-814e-a2a92dde6d21",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "semantically they are the same, but the code is easier to read if we do `if (value > max) ...` instead of `(minCmp.signum, maxCmp.signum, exp) match ...` ",
        "createdAt" : "2020-09-11T07:29:22Z",
        "updatedAt" : "2020-09-11T20:44:56Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "fe7fd88c-73c9-4b7c-b5e4-fa0b65864536",
        "parentId" : "b175390c-52ce-440b-814e-a2a92dde6d21",
        "authorId" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "body" : "This was my bad :) I suggested to use pattern matching instead of mixing `if else` and pattern matching.",
        "createdAt" : "2020-09-11T08:29:04Z",
        "updatedAt" : "2020-09-11T20:44:56Z",
        "lastEditedBy" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "tags" : [
        ]
      },
      {
        "id" : "656e7fba-3e8e-4380-96ed-36e08bf9054a",
        "parentId" : "b175390c-52ce-440b-814e-a2a92dde6d21",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "thanks - let me switch to `if else` for better readability here.",
        "createdAt" : "2020-09-11T16:27:22Z",
        "updatedAt" : "2020-09-11T20:44:56Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      }
    ],
    "commit" : "5f32ee5fda08f4271959589c7f6312195898af08",
    "line" : 130,
    "diffHunk" : "@@ -1,1 +128,132 @@      (Cast(Literal(min), toType).eval(), Cast(Literal(max), toType).eval())\n    }\n    val ordering = toType.ordering.asInstanceOf[Ordering[Any]]\n    val minCmp = ordering.compare(value, minInToType)\n    val maxCmp = ordering.compare(value, maxInToType)"
  },
  {
    "id" : "bbeaad95-d4e8-4615-9a33-eeb20cf2eafd",
    "prId" : 29565,
    "prUrl" : "https://github.com/apache/spark/pull/29565#pullrequestreview-486952105",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3fe46f3b-7cbd-42f0-a97b-d4c676d4c52c",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "This additional check looks good and robust. BTW, do we have a test coverage for this?",
        "createdAt" : "2020-09-11T13:32:22Z",
        "updatedAt" : "2020-09-11T20:44:56Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "8362d7d0-e8d8-4fc6-b4b4-5419452a84e0",
        "parentId" : "3fe46f3b-7cbd-42f0-a97b-d4c676d4c52c",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "I tried to come up with a test for this but it seems the query compiler always wrap a cast to make sure type from both sides are the same.",
        "createdAt" : "2020-09-11T16:28:17Z",
        "updatedAt" : "2020-09-11T20:44:56Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      }
    ],
    "commit" : "5f32ee5fda08f4271959589c7f6312195898af08",
    "line" : 207,
    "diffHunk" : "@@ -1,1 +205,209 @@  private def canImplicitlyCast(fromExp: Expression, toType: DataType,\n      literalType: DataType): Boolean = {\n    toType.sameType(literalType) &&\n      fromExp.dataType.isInstanceOf[IntegralType] &&\n      toType.isInstanceOf[IntegralType] &&"
  },
  {
    "id" : "0ef6daa2-d2c5-46f7-a5fc-7b882182f14b",
    "prId" : 29565,
    "prUrl" : "https://github.com/apache/spark/pull/29565#pullrequestreview-488004402",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9595f31c-d3c7-4109-9155-0bb5924302c9",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "indentation nit:\r\n```\r\ndef func(\r\n    para1: T,\r\n    para2: T,\r\n    para3: T): R = ...\r\n```",
        "createdAt" : "2020-09-14T04:36:25Z",
        "updatedAt" : "2020-09-14T04:36:25Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "c075deb0-5df4-4b70-a611-052959672bc0",
        "parentId" : "9595f31c-d3c7-4109-9155-0bb5924302c9",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "BTW I'll also check `!from.foldable`, otherwise it's simpler to not run this rule.",
        "createdAt" : "2020-09-14T04:37:32Z",
        "updatedAt" : "2020-09-14T04:37:32Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "850b804d-9e20-4624-8d70-5d8f2b145ff5",
        "parentId" : "9595f31c-d3c7-4109-9155-0bb5924302c9",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Ya. +1 for `foldable` checking.",
        "createdAt" : "2020-09-14T04:39:48Z",
        "updatedAt" : "2020-09-14T04:39:48Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "6f603425-0d4c-48da-ba53-818d4a8c2f9a",
        "parentId" : "9595f31c-d3c7-4109-9155-0bb5924302c9",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "Thanks. I'll check `foldable` in the follow-up PR to handle more types. And also fix the indentation.",
        "createdAt" : "2020-09-14T17:44:13Z",
        "updatedAt" : "2020-09-14T17:44:14Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      }
    ],
    "commit" : "5f32ee5fda08f4271959589c7f6312195898af08",
    "line" : 205,
    "diffHunk" : "@@ -1,1 +203,207 @@   * integral type.\n   */\n  private def canImplicitlyCast(fromExp: Expression, toType: DataType,\n      literalType: DataType): Boolean = {\n    toType.sameType(literalType) &&"
  }
]