[
  {
    "id" : "b3cb2d07-9a54-4850-b854-17010241592f",
    "prId" : 32488,
    "prUrl" : "https://github.com/apache/spark/pull/32488#pullrequestreview-669673430",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fe0437d1-d05b-420f-a481-aa5a7ddf6fb9",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I'm not sure we can hit this case, as `OptimizeIn` will turn it into `InSet`.\r\n\r\nCan you try a real query and see if the optimization in this PR takes place?",
        "createdAt" : "2021-05-24T15:49:09Z",
        "updatedAt" : "2021-05-24T15:49:09Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "e7cd4fc5-041f-4b5f-a4aa-5ec0049753ff",
        "parentId" : "fe0437d1-d05b-420f-a481-aa5a7ddf6fb9",
        "authorId" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "body" : "Yes, it does.\r\n\r\n```scala\r\n    spark.range(50)\r\n      .selectExpr(\"cast(id as int) as id\")\r\n      .write\r\n      .mode(\"overwrite\")\r\n      .parquet(\"/tmp/parquet/t1\")\r\n\r\n    spark.sql(\"SET spark.sql.planChangeLog.level=WARN\")\r\n    val in = (1 to 20).map {\r\n      case i => Literal.create(i.toLong)\r\n    }\r\n    spark.read\r\n      .load(\"/tmp/parquet/t1\")\r\n      .filter($\"id\".isin(in: _*))\r\n      .explain\r\n```\r\n\r\nBefore this pr:\r\n```\r\n== Physical Plan ==\r\n*(1) Filter cast(id#105 as bigint) INSET (5,10,14,20,1,6,9,13,2,17,12,7,3,18,16,11,8,19,4,15)\r\n+- *(1) ColumnarToRow\r\n   +- FileScan parquet [id#105] Batched: true, DataFilters: [cast(id#105 as bigint) INSET (5,10,14,20,1,6,9,13,2,17,12,7,3,18,16,11,8,19,4,15)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/tmp/parquet/t1], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<id:int>\r\n```\r\nAfter this pr;\r\n```\r\n15:33:02.191 WARN org.apache.spark.sql.catalyst.rules.PlanChangeLogger: \r\n=== Applying Rule org.apache.spark.sql.catalyst.optimizer.UnwrapCastInBinaryComparison ===\r\n!Filter cast(id#105 as bigint) IN (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20)   Filter id#105 IN (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20)\r\n +- Relation [id#105] parquet                                                            +- Relation [id#105] parquet\r\n\r\n15:33:02.197 WARN org.apache.spark.sql.catalyst.rules.PlanChangeLogger: \r\n=== Applying Rule org.apache.spark.sql.catalyst.optimizer.OptimizeIn ===\r\n!Filter id#105 IN (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20)   Filter id#105 INSET (5,10,14,20,1,6,9,13,2,17,12,7,3,18,16,11,8,19,4,15)\r\n +- Relation [id#105] parquet                                            +- Relation [id#105] parquet\r\n\r\n== Physical Plan ==\r\n*(1) Filter id#105 INSET (5,10,14,20,1,6,9,13,2,17,12,7,3,18,16,11,8,19,4,15)\r\n+- *(1) ColumnarToRow\r\n   +- FileScan parquet [id#105] Batched: true, DataFilters: [id#105 INSET (5,10,14,20,1,6,9,13,2,17,12,7,3,18,16,11,8,19,4,15)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/tmp/parquet/t1], PartitionFilters: [], PushedFilters: [In(id, [5,10,14,20,1,6,9,13,2,17,12,7,3,18,16,11,8,19,4,15])], ReadSchema: struct<id:int>\r\n```",
        "createdAt" : "2021-05-25T07:41:09Z",
        "updatedAt" : "2021-05-25T07:41:10Z",
        "lastEditedBy" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "tags" : [
        ]
      },
      {
        "id" : "18f17eaf-daf3-4a3a-af4b-ed003c5df8dc",
        "parentId" : "fe0437d1-d05b-420f-a481-aa5a7ddf6fb9",
        "authorId" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "body" : "Shall we add an end-to-end test for this case?",
        "createdAt" : "2021-05-25T07:45:38Z",
        "updatedAt" : "2021-05-25T07:45:38Z",
        "lastEditedBy" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "tags" : [
        ]
      },
      {
        "id" : "73f37065-1dbc-4574-b6a0-1c45a5b27ea4",
        "parentId" : "fe0437d1-d05b-420f-a481-aa5a7ddf6fb9",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "So we are relying on the assumption that `UnwrapCastInBinaryComparison` happens before `OptimizeIn`.\r\n\r\nThis is fragile as the execution order of the rules in the same batch is pretty unpredictable, and may change over time if code factor happens, new optimization rules added, etc.\r\n\r\nIt's better to make sure these catalyst rules are orthogonal, and that's why `In` and `InSet` usually appears together: if a rule needs to handle In, it usually should handle InSet as well.",
        "createdAt" : "2021-05-25T13:52:31Z",
        "updatedAt" : "2021-05-25T13:52:38Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "b17fb7b5-e562-45d5-8d24-455f12939715",
        "parentId" : "fe0437d1-d05b-420f-a481-aa5a7ddf6fb9",
        "authorId" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "body" : "Make sense.",
        "createdAt" : "2021-05-26T09:45:55Z",
        "updatedAt" : "2021-05-26T09:45:55Z",
        "lastEditedBy" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "tags" : [
        ]
      },
      {
        "id" : "49649e49-abfd-40ac-9d14-a41cdb57b264",
        "parentId" : "fe0437d1-d05b-420f-a481-aa5a7ddf6fb9",
        "authorId" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "body" : "Updated and add `InSet` support.",
        "createdAt" : "2021-05-27T01:41:09Z",
        "updatedAt" : "2021-05-27T01:41:10Z",
        "lastEditedBy" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "tags" : [
        ]
      }
    ],
    "commit" : "ea0ba385ec38b231a37f871cecf1ca9ffb852c3d",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +33,37 @@ * - `BinaryComparison(Cast(fromExp, toType), Literal(value, toType))`\n * - `BinaryComparison(Literal(value, toType), Cast(fromExp, toType))`\n * - `In(Cast(fromExp, toType), Seq(Literal(v1, toType), Literal(v2, toType), ...)`\n * - `InSet(Cast(fromExp, toType), Set(v1, v2, ...))`\n *"
  },
  {
    "id" : "443c0228-ea2e-4578-981d-be5addcb399d",
    "prId" : 32488,
    "prUrl" : "https://github.com/apache/spark/pull/32488#pullrequestreview-673890722",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "38eadbb9-06f5-4732-ba94-884e5e754312",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "The null literal handling is a bit tricky and I think it's better to put all the steps in the comment. There are 3 kinds of literals in the list:\r\n1. null literals\r\n2. The literals that can cast to `fromExp.dataType`\r\n3. The literals that cannot cast to `fromExp.dataType`\r\n\r\nnull literals is special, because if we call `unwrapCast` directly, null means cannot cast, which is misleading as we can cast null literals to any data type.\r\n\r\nThe ideal steps in my mind:\r\n1. Call `unwrapCast` with non-null literals in the list\r\n2. If there is no literal that can cast to `fromExp.dataType`, return the original expression\r\n3. Otherwise, use the literals that can cast to `fromExp.dataType` and the null literals to create a new `In` expression, with additional `falseIfNotNull` check.",
        "createdAt" : "2021-06-01T12:36:48Z",
        "updatedAt" : "2021-06-01T12:36:49Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "0e15dd9d-a473-4101-b74e-5b4acca5756f",
        "parentId" : "38eadbb9-06f5-4732-ba94-884e5e754312",
        "authorId" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "body" : "Thanks for your suggestion, I'll try your idea.",
        "createdAt" : "2021-06-02T02:19:26Z",
        "updatedAt" : "2021-06-02T02:19:26Z",
        "lastEditedBy" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "tags" : [
        ]
      },
      {
        "id" : "0005dccc-7ba8-490e-a159-53f5761e9e8f",
        "parentId" : "38eadbb9-06f5-4732-ba94-884e5e754312",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Another idea: We can use `AnsiCast(...).eval`, which fails if overflow happens. Then null literal is the same as other literals that can cast to `fromExp.dataType`, and we don't need to distinguish them.",
        "createdAt" : "2021-06-02T03:00:15Z",
        "updatedAt" : "2021-06-02T03:00:15Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "27bd433c-a45d-45a5-a49d-1cbf4e366035",
        "parentId" : "38eadbb9-06f5-4732-ba94-884e5e754312",
        "authorId" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "body" : "> Another idea: We can use AnsiCast(...).eval, which fails if overflow happens. Then null literal is the same as other literals that can cast to fromExp.dataType, and we don't need to distinguish them.\r\n\r\nGood idea,\r\n\r\n>The ideal steps in my mind:\r\n> 1. Call unwrapCast with non-null literals in the list\r\n> 2. If there is no literal that can cast to fromExp.dataType, return the original expression\r\n> 3. Otherwise, use the literals that can cast to fromExp.dataType and the null literals to create a new In expression, with additional falseIfNotNull check.\r\n\r\nbut I think this one is more clear.\r\n\r\nAnother question for stage 2: we should not return original expression when the can not cast literals is non-empty, but return `falseIfNotNull` instead, this is because original expression `In(Cast(fromExp, toType), list)` can't be optimized by other rules and trigger a filter stage, but `falseIfNotNull` can be optimized by `BooleanSimplification`, WDYT?\r\n\r\n",
        "createdAt" : "2021-06-02T07:31:45Z",
        "updatedAt" : "2021-06-02T07:31:46Z",
        "lastEditedBy" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "tags" : [
        ]
      },
      {
        "id" : "e1da46f4-f901-4eeb-b32e-637c618c680d",
        "parentId" : "38eadbb9-06f5-4732-ba94-884e5e754312",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "SGTM, it's still useful to optimize to `falseIfNotNull`",
        "createdAt" : "2021-06-02T07:48:56Z",
        "updatedAt" : "2021-06-02T07:48:56Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "ea0ba385ec38b231a37f871cecf1ca9ffb852c3d",
    "line" : 61,
    "diffHunk" : "@@ -1,1 +137,141 @@    // As the analyzer makes sure that the list of In is already of the same data type, then the\n    // rule can simply check the first literal in `in.list` can implicitly cast to `toType` or not,\n    // and note that:\n    // 1. this rule doesn't convert in when `in.list` is empty or `in.list` contains only null\n    // values."
  },
  {
    "id" : "a9260364-6210-4d23-b2be-18b81c64c1af",
    "prId" : 29792,
    "prUrl" : "https://github.com/apache/spark/pull/29792#pullrequestreview-498732403",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "48eeff62-1320-4de1-bb44-ae0bb19dd841",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "why the upper bound is not `PositiveInfinity`?",
        "createdAt" : "2020-09-29T08:31:19Z",
        "updatedAt" : "2020-10-12T20:16:06Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "aa2ccaa3-bf29-476c-b00b-51c5e0a61f60",
        "parentId" : "48eeff62-1320-4de1-bb44-ae0bb19dd841",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "This is because `PositiveInfinity` is considered to be < `NaN` in Spark. If we treat it as the upper bound, rules handling the upper bounds will not be valid. For instance the following expr:\r\n```sql\r\ncast(e as double) > double('+inf')\r\n```\r\nwould be converted to\r\n```sql\r\ne === double('+inf')\r\n```\r\nwhich won't be correct if `e` evaluates to `double('NaN')`.",
        "createdAt" : "2020-09-29T17:44:41Z",
        "updatedAt" : "2020-10-12T20:16:06Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      }
    ],
    "commit" : "76b9f73862380dda40b332b56464278bfb0b88d3",
    "line" : 270,
    "diffHunk" : "@@ -1,1 +267,271 @@    case IntegerType => Some((Int.MinValue, Int.MaxValue))\n    case LongType => Some((Long.MinValue, Long.MaxValue))\n    case FloatType => Some((Float.NegativeInfinity, Float.NaN))\n    case DoubleType => Some((Double.NegativeInfinity, Double.NaN))\n    case _ => None"
  },
  {
    "id" : "e4861fb4-b637-4390-b2af-9dc93af06c48",
    "prId" : 29792,
    "prUrl" : "https://github.com/apache/spark/pull/29792#pullrequestreview-502755440",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b2115506-3855-49f2-9aa3-0ebc30cc2444",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "why it's safe to skip range check for decimal type?",
        "createdAt" : "2020-09-29T08:37:35Z",
        "updatedAt" : "2020-10-12T20:16:06Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "3fc85a7b-6b07-40f5-a4f5-22137676324c",
        "parentId" : "b2115506-3855-49f2-9aa3-0ebc30cc2444",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "It is safe since knowing min/max for a type just gives us more opportunity for optimizations. I skipped decimal type here because (it seems) there is no min/max defined in the `DecimalType`, unlike other numeric types.",
        "createdAt" : "2020-09-29T17:47:24Z",
        "updatedAt" : "2020-10-12T20:16:06Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "db0a2605-6044-49cc-a062-bcc822e69325",
        "parentId" : "b2115506-3855-49f2-9aa3-0ebc30cc2444",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "makes sense.",
        "createdAt" : "2020-10-06T09:33:32Z",
        "updatedAt" : "2020-10-12T20:16:06Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "76b9f73862380dda40b332b56464278bfb0b88d3",
    "line" : 171,
    "diffHunk" : "@@ -1,1 +203,207 @@\n    // When we reach to this point, it means either there is no min/max for the `fromType` (e.g.,\n    // decimal type), or that the literal `value` is within range `(min, max)`. For these, we\n    // optimize by moving the cast to the literal side.\n"
  },
  {
    "id" : "d8cd1727-453d-42d1-8ad3-5f92f47df8f5",
    "prId" : 29792,
    "prUrl" : "https://github.com/apache/spark/pull/29792#pullrequestreview-498717462",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ee2f792c-2b2c-4c3f-bad2-be5a92a58cca",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "The case I'm worried about is `cast(float_col as double) cmp double_lit`. It's not straightforward to me that a `double -> float -> double` roundtrip can tell rounding up or down. is it because `float -> double` can only be rounding up?",
        "createdAt" : "2020-09-29T08:50:15Z",
        "updatedAt" : "2020-10-12T20:16:06Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "077b3cb8-b001-4621-92df-05699876c319",
        "parentId" : "ee2f792c-2b2c-4c3f-bad2-be5a92a58cca",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "So double to float can result to either rounding up or down. For instance, by casting 3.14 in double to float, even though the value is still 3.14, the binary representation is rounded up:\r\n\r\n3.14 in double:\r\n```\r\n0 10000000000 1001 0001 1110 1011 1000 0101 0001 1110 1011 1000 0101 0001 1111\r\n```\r\n\r\n3.14 in float\r\n```\r\n0 10000000 1001 0001 1110 1011 1000 011\r\n```\r\nHere the sign bit and exponent bits (11 and 8 bits respectively for double and float) are the same for both float and double. However, in the fraction part, the last is rounded up to 1.\r\n\r\nAfter casting back to double, there won't be any rounding up or down - the remaining digits are simply padded with 0:\r\n```\r\n0 10000000000 1001 0001 1110 1011 1000 0110 0000000000000000000000000000\r\n```\r\n",
        "createdAt" : "2020-09-29T16:37:41Z",
        "updatedAt" : "2020-10-12T20:16:06Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "ed6b2bff-c335-493d-aaf5-35284df012b0",
        "parentId" : "ee2f792c-2b2c-4c3f-bad2-be5a92a58cca",
        "authorId" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "body" : "Is it defined as part of IEEE Standard for Floating-Point Arithmetic (IEEE 754)?",
        "createdAt" : "2020-09-29T16:40:07Z",
        "updatedAt" : "2020-10-12T20:16:06Z",
        "lastEditedBy" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "tags" : [
        ]
      },
      {
        "id" : "1bd01b6c-464e-4ad0-a7cc-3dee00753f1e",
        "parentId" : "ee2f792c-2b2c-4c3f-bad2-be5a92a58cca",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "Yes I think both the binary format as well as rounding rules are specified in IEEE 754. There are a few rounding rules and I think the default one is \"rounding to half even\".",
        "createdAt" : "2020-09-29T17:25:51Z",
        "updatedAt" : "2020-10-12T20:16:06Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      }
    ],
    "commit" : "76b9f73862380dda40b332b56464278bfb0b88d3",
    "line" : 180,
    "diffHunk" : "@@ -1,1 +212,216 @@      return exp\n    }\n    val valueRoundTrip = Cast(Literal(newValue, fromType), toType).eval()\n    val lit = Literal(newValue, fromType)\n    val cmp = ordering.compare(value, valueRoundTrip)"
  },
  {
    "id" : "a49fe387-472d-4585-a4d3-f4ed74809647",
    "prId" : 29792,
    "prUrl" : "https://github.com/apache/spark/pull/29792#pullrequestreview-503150938",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3d11374e-280c-4a9f-bedd-3e3bb72dd165",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can you give a real example here?",
        "createdAt" : "2020-10-06T09:34:30Z",
        "updatedAt" : "2020-10-12T20:16:06Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "7159b4a4-8135-45cd-8cb8-29437206f54d",
        "parentId" : "3d11374e-280c-4a9f-bedd-3e3bb72dd165",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I see, it's for decimal only. It's better to make the comment more explicit.",
        "createdAt" : "2020-10-06T12:49:05Z",
        "updatedAt" : "2020-10-12T20:16:06Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "a5bfe5aa-8828-4046-a708-5d7a8f1bd1c0",
        "parentId" : "3d11374e-280c-4a9f-bedd-3e3bb72dd165",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "yup will do - there is also a test case covering this.",
        "createdAt" : "2020-10-06T16:30:04Z",
        "updatedAt" : "2020-10-12T20:16:06Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      }
    ],
    "commit" : "76b9f73862380dda40b332b56464278bfb0b88d3",
    "line" : 177,
    "diffHunk" : "@@ -1,1 +209,213 @@    if (newValue == null) {\n      // This means the cast failed, for instance, due to the value is not representable in the\n      // narrower type. In this case we simply return the original expression.\n      return exp\n    }"
  },
  {
    "id" : "b103ead0-88f0-48be-a743-18a4ebded9bb",
    "prId" : 29792,
    "prUrl" : "https://github.com/apache/spark/pull/29792#pullrequestreview-505844184",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9392b738-d2ab-4387-82e1-d57510f02f93",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Looks it does not have any test for this code path, so could you add some tests for it. (NOTE: I think `byte`, `int`, and `long` are not tested in `UnwrapCastInBinaryComparisonSuite`, too)",
        "createdAt" : "2020-10-09T12:43:28Z",
        "updatedAt" : "2020-10-12T20:16:06Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "b71c5245-a5ec-4256-a4db-eb9ba3c4fc01",
        "parentId" : "9392b738-d2ab-4387-82e1-d57510f02f93",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "Will add a test case (although I think it will be pretty trivial). I only added tests for `short` in the previous PR because the handling for other integral types is exactly the same.",
        "createdAt" : "2020-10-09T16:56:41Z",
        "updatedAt" : "2020-10-12T20:16:06Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      }
    ],
    "commit" : "76b9f73862380dda40b332b56464278bfb0b88d3",
    "line" : 271,
    "diffHunk" : "@@ -1,1 +268,272 @@    case LongType => Some((Long.MinValue, Long.MaxValue))\n    case FloatType => Some((Float.NegativeInfinity, Float.NaN))\n    case DoubleType => Some((Double.NegativeInfinity, Double.NaN))\n    case _ => None\n  }"
  }
]