[
  {
    "id" : "ce225d08-247d-48af-ba01-723a4d22af2a",
    "prId" : 33676,
    "prUrl" : "https://github.com/apache/spark/pull/33676#pullrequestreview-724865922",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ace229d2-9e80-44f7-b3da-5b991e8cfef6",
        "parentId" : null,
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "capturing resolver directly from `alter` variable to simplify.",
        "createdAt" : "2021-08-08T05:55:21Z",
        "updatedAt" : "2021-08-08T05:56:11Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "0b94f7684c7bbf148e0d4686970a468188d35c3c",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +943,947 @@    def checkColumnNotExists(op: String, fieldNames: Seq[String], struct: StructType): Unit = {\n      if (struct.findNestedField(\n          fieldNames, includeCollections = true, alter.conf.resolver).isDefined) {\n        alter.failAnalysis(s\"Cannot $op column, because ${fieldNames.quoted} \" +\n          s\"already exists in ${struct.treeString}\")"
  },
  {
    "id" : "80ea87a1-db8b-4ce0-9108-8c88e404808a",
    "prId" : 33600,
    "prUrl" : "https://github.com/apache/spark/pull/33600#pullrequestreview-720162467",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b61580c2-37db-42df-8344-25c394f625b5",
        "parentId" : null,
        "authorId" : "957f9c71-6f42-4d35-9de9-a731f295e818",
        "body" : "nitï¼šbefore check exists",
        "createdAt" : "2021-08-02T08:43:35Z",
        "updatedAt" : "2021-08-02T08:43:35Z",
        "lastEditedBy" : "957f9c71-6f42-4d35-9de9-a731f295e818",
        "tags" : [
        ]
      },
      {
        "id" : "0dda820d-234c-48ad-b35a-16c890581867",
        "parentId" : "b61580c2-37db-42df-8344-25c394f625b5",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "does the order matter here?",
        "createdAt" : "2021-08-02T09:51:18Z",
        "updatedAt" : "2021-08-02T09:51:19Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "b7f734b4-86b5-47a7-8bb5-cae3fab6f5c5",
        "parentId" : "b61580c2-37db-42df-8344-25c394f625b5",
        "authorId" : "957f9c71-6f42-4d35-9de9-a731f295e818",
        "body" : "Maybe quick fail ?",
        "createdAt" : "2021-08-02T12:47:25Z",
        "updatedAt" : "2021-08-02T12:47:25Z",
        "lastEditedBy" : "957f9c71-6f42-4d35-9de9-a731f295e818",
        "tags" : [
        ]
      }
    ],
    "commit" : "38c093570dd762fee74611596a8f0eb2761e9214",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +953,957 @@          checkColumnNotExists(\"add\", colToAdd.name, table.schema)\n        }\n        SchemaUtils.checkColumnNameDuplication(\n          colsToAdd.map(_.name.quoted),\n          \"in the user specified columns\","
  },
  {
    "id" : "dbe4492c-5b89-4b07-9d45-704ce4cd47ea",
    "prId" : 33200,
    "prUrl" : "https://github.com/apache/spark/pull/33200#pullrequestreview-710854247",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cbc20d99-1e66-400c-bc12-9a83324947d8",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "What if the to-be-added columns have duplicated names? e.g. `ADD COLUMNS a ..., a ...`",
        "createdAt" : "2021-07-20T06:07:09Z",
        "updatedAt" : "2021-07-20T06:07:09Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "46acbf71-5e69-44e0-ac9f-c0f62f2f505a",
        "parentId" : "cbc20d99-1e66-400c-bc12-9a83324947d8",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "For v1 command, this is checked in [AlterTableAddColumnsCommand](https://github.com/apache/spark/blob/c0d84e6cf1046b7944796038414ef21fe9c7e3b5/sql/core/src/main/scala/org/apache/spark/sql/execution/command/tables.scala#L235), but for v2, this is not checked and it's up to the catalog implementation to handle it. Is this a bug? If so, I can fix this as a separate PR.",
        "createdAt" : "2021-07-20T16:42:05Z",
        "updatedAt" : "2021-07-20T16:42:05Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      },
      {
        "id" : "a4e0415f-b8e6-4c3a-81d4-94a1efe0ccfb",
        "parentId" : "cbc20d99-1e66-400c-bc12-9a83324947d8",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "Also, if this is a bug, will the fix be ported to 3.2?\r\n\r\nI am not sure whether this PR will be ported to 3.2, so I need to know whether the fix should come before or after this PR.",
        "createdAt" : "2021-07-20T16:45:35Z",
        "updatedAt" : "2021-07-20T16:45:35Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      },
      {
        "id" : "4902ef4b-46d9-4820-959f-0d7223a40f53",
        "parentId" : "cbc20d99-1e66-400c-bc12-9a83324947d8",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Yea I think it's a bug. We can probably fix it after this PR, as this PR refactors the related code.",
        "createdAt" : "2021-07-20T16:46:03Z",
        "updatedAt" : "2021-07-20T16:46:04Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "c84baf19-85b7-478e-b477-a01f3063e5dc",
        "parentId" : "cbc20d99-1e66-400c-bc12-9a83324947d8",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I'd like to merge this PR to 3.2, as this is the last PR to complete the ALTER TABLE command migration.",
        "createdAt" : "2021-07-20T16:48:35Z",
        "updatedAt" : "2021-07-20T16:48:35Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "d3a82233-2112-4dd0-8157-25b1a03d26f2",
        "parentId" : "cbc20d99-1e66-400c-bc12-9a83324947d8",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "Got it thanks!",
        "createdAt" : "2021-07-20T16:50:32Z",
        "updatedAt" : "2021-07-20T16:50:33Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "d2e691086b80fb7f64d1bce144bd1bdd03428b8d",
    "line" : 130,
    "diffHunk" : "@@ -1,1 +950,954 @@      case AlterTableAddColumns(table: ResolvedTable, colsToAdd) =>\n        colsToAdd.foreach { colToAdd =>\n          checkColumnNotExists(\"add\", colToAdd.name, table.schema)\n        }\n"
  },
  {
    "id" : "da8fc7d0-a87a-46b6-83db-55cbce0b2a3c",
    "prId" : 33113,
    "prUrl" : "https://github.com/apache/spark/pull/33113#pullrequestreview-693537592",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "81cb2344-da87-4f46-8ca7-afc54056a4d1",
        "parentId" : null,
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "`findField` and `findParentStruct` are existing functions in `CheckAnalysis` with a slight modification (e.g., not passing operation argument). The existing functions will be removed once all alter table commands are migrated.",
        "createdAt" : "2021-06-28T04:05:09Z",
        "updatedAt" : "2021-06-28T04:05:13Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "6a75c920df97a13ac547056eb7eb286b3accf973",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +455,459 @@              field.get._2\n            }\n            def findParentStruct(fieldNames: Seq[String]): StructType = {\n              val parent = fieldNames.init\n              val field = if (parent.nonEmpty) {"
  },
  {
    "id" : "e64412a8-d626-4646-a755-ceb59153fb0b",
    "prId" : 33113,
    "prUrl" : "https://github.com/apache/spark/pull/33113#pullrequestreview-698901499",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a4dfc2e1-22d3-410f-9807-599997dd3a66",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Not related to this PR: I think there is a small bug here, if the data type is not changed, we shouldn't fail even if the new data type is struct/array/map. @imback82 can you help to fix it?",
        "createdAt" : "2021-07-05T04:44:33Z",
        "updatedAt" : "2021-07-05T04:44:34Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "edb22ace-b679-40b1-93d0-dd58e677840d",
        "parentId" : "a4dfc2e1-22d3-410f-9807-599997dd3a66",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Actually, this is OK. In the analzer, we will set the `newDataType` to None if it's the same with the existing data type in the table.",
        "createdAt" : "2021-07-05T08:02:12Z",
        "updatedAt" : "2021-07-05T08:02:12Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "6a75c920df97a13ac547056eb7eb286b3accf973",
    "line" : 139,
    "diffHunk" : "@@ -1,1 +1068,1072 @@            .getOrElse(col.field)\n          val newDataType = a.dataType.get\n          newDataType match {\n            case _: StructType =>\n              alter.failAnalysis(s\"Cannot update ${table.name} field $fieldName type: \" +"
  },
  {
    "id" : "f4c4abf3-bd64-4d06-ac6c-12aa891ad24e",
    "prId" : 32978,
    "prUrl" : "https://github.com/apache/spark/pull/32978#pullrequestreview-687930878",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "389107c7-493d-4f14-afeb-8428df7a3870",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Hm, so we should fix all these kind of blacklisting .. while this fix is good, I wonder if we can sweep and fix in batch.",
        "createdAt" : "2021-06-20T02:32:44Z",
        "updatedAt" : "2021-06-20T02:32:44Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "1c33f76c-1fba-4590-bc67-6b3066590ee8",
        "parentId" : "389107c7-493d-4f14-afeb-8428df7a3870",
        "authorId" : "3a227965-84e0-47cf-9974-11293764f028",
        "body" : "Actually, I have found another places where `DayTimeINtervalType` and `YearMonthIntervalType` are not considered.\r\nIn terms of blacklisting, I found this part only (if I didn't miss something).\r\nThe rest of places we need to consider is as follows.\r\n\r\n* https://github.com/apache/spark/blob/4f51e0045e2754035e304979182c0f583c65f174/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/codegen/GenerateUnsafeProjection.scala#L42\r\n* https://github.com/apache/spark/blob/4f51e0045e2754035e304979182c0f583c65f174/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/Cast.scala#L155\r\n* https://github.com/apache/spark/blob/4f51e0045e2754035e304979182c0f583c65f174/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/Cast.scala#L191\r\n* https://github.com/apache/spark/blob/4f51e0045e2754035e304979182c0f583c65f174/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/util/ArrayBasedMapBuilder.scala#L37\r\n* https://github.com/apache/spark/blob/4f51e0045e2754035e304979182c0f583c65f174/sql/hive/src/test/scala/org/apache/spark/sql/hive/orc/OrcHadoopFsRelationSuite.scala#L40\r\n* https://github.com/apache/spark/blob/master/sql/hive/src/test/scala/org/apache/spark/sql/sources/ParquetHadoopFsRelationSuite.scala#L41\r\n* https://github.com/apache/spark/blob/4f51e0045e2754035e304979182c0f583c65f174/sql/hive/src/test/scala/org/apache/spark/sql/sources/JsonHadoopFsRelationSuite.scala#L35\r\n* https://github.com/apache/spark/blob/4f51e0045e2754035e304979182c0f583c65f174/sql/hive/src/test/scala/org/apache/spark/sql/sources/SimpleTextHadoopFsRelationSuite.scala#L36\r\n\r\nI think, we need to fix them with beyond just blacklisting and they need to be more carefully considered while this part can be simply fixed.",
        "createdAt" : "2021-06-20T18:33:37Z",
        "updatedAt" : "2021-06-20T18:33:38Z",
        "lastEditedBy" : "3a227965-84e0-47cf-9974-11293764f028",
        "tags" : [
        ]
      }
    ],
    "commit" : "35389a8805a1ca0571b8e57feb6b33907b99458d",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +535,539 @@                      s\"update a UserDefinedType[${u.sql}] by updating its fields\")\n                  case _: CalendarIntervalType | _: YearMonthIntervalType |\n                       _: DayTimeIntervalType =>\n                    alter.failAnalysis(s\"Cannot update ${table.name} field $fieldName to \" +\n                      s\"interval type\")"
  },
  {
    "id" : "aec3a4c5-6228-4b81-9ab5-48c5690133bf",
    "prId" : 32503,
    "prUrl" : "https://github.com/apache/spark/pull/32503#pullrequestreview-661013339",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ba5a2434-936e-46ca-a5d5-f5229fab6a10",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "To be consistent with previous, shall we pass `SubExprUtils.stripOuterReference(a).sql`? Or `a.sql` is better?",
        "createdAt" : "2021-05-15T06:54:03Z",
        "updatedAt" : "2021-05-15T06:54:15Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "4412c913-23a9-4df8-b1cb-32f630685091",
        "parentId" : "ba5a2434-936e-46ca-a5d5-f5229fab6a10",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I did it intentionally so that people can see the outer reference directly like `min((outer(t1.t1a) + t2.t2a))`",
        "createdAt" : "2021-05-17T14:08:57Z",
        "updatedAt" : "2021-05-17T14:08:57Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "6de4a152b8fb7f075e58d53eaf194acfdccc345b",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +837,841 @@          val local = a.references -- outer\n          if (local.nonEmpty) {\n            throw QueryCompilationErrors.mixedRefsInAggFunc(a.sql)\n          }\n        case _ =>"
  },
  {
    "id" : "12d3fc41-42a4-4af2-9426-a3d706a9c253",
    "prId" : 32179,
    "prUrl" : "https://github.com/apache/spark/pull/32179#pullrequestreview-637077787",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e0f97e83-3cbd-445c-81d8-ffcfb0271558",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "do we have test case for it?",
        "createdAt" : "2021-04-15T19:29:01Z",
        "updatedAt" : "2021-04-19T22:09:55Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "4f06ed4d-74e6-4ece-b7e3-47e9b7341c06",
        "parentId" : "e0f97e83-3cbd-445c-81d8-ffcfb0271558",
        "authorId" : "b3ba992a-312c-46eb-b3c3-8d861d15ac40",
        "body" : "Yes added a test case in SubquerySuite",
        "createdAt" : "2021-04-15T19:58:13Z",
        "updatedAt" : "2021-04-19T22:09:55Z",
        "lastEditedBy" : "b3ba992a-312c-46eb-b3c3-8d861d15ac40",
        "tags" : [
        ]
      }
    ],
    "commit" : "84f91b23578ac4db525911820022a6db30f92adc",
    "line" : 57,
    "diffHunk" : "@@ -1,1 +949,953 @@    // (i.e. only has outer references), it is supported and should return false. E.G.:\n    //   (a = outer(c)) -> false\n    //   (outer(c) = outer(d)) -> false\n    //   (a > outer(c)) -> true\n    //   (a + b = outer(c)) -> true"
  },
  {
    "id" : "c341a75a-0ea3-4c8f-a404-10b40c9b9ffe",
    "prId" : 32179,
    "prUrl" : "https://github.com/apache/spark/pull/32179#pullrequestreview-638482675",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f16da972-4d5b-49b0-bcf1-0258cf0cf126",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "We need the two entries above? It seems the entry in L963 can cover them, too.",
        "createdAt" : "2021-04-19T00:11:05Z",
        "updatedAt" : "2021-04-19T22:09:55Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "a64ab48d-d1eb-44a9-b45c-bbe37c2ccc1b",
        "parentId" : "f16da972-4d5b-49b0-bcf1-0258cf0cf126",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I think L963 only covers outer-reference-only cases, which is different from L961 and L962",
        "createdAt" : "2021-04-19T05:57:19Z",
        "updatedAt" : "2021-04-19T22:09:55Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "84f91b23578ac4db525911820022a6db30f92adc",
    "line" : 68,
    "diffHunk" : "@@ -1,1 +960,964 @@      // OuterReference is a leaf node and will not be found here.\n      case Equality(_: Attribute, b) => containsAttribute(b)\n      case Equality(a, _: Attribute) => containsAttribute(a)\n      case e @ Equality(_, _) => containsAttribute(e)\n      case _ => true"
  },
  {
    "id" : "adff77f4-dcfc-4499-9e62-32e6bec0f90f",
    "prId" : 31637,
    "prUrl" : "https://github.com/apache/spark/pull/31637#pullrequestreview-600404118",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "25513caf-13a1-4b5f-b0ce-4a1bec6bd6c2",
        "parentId" : null,
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "Not related to this PR, but should we also move other commands that do not support v2 tables here from `DataSourceV2Strategy`?",
        "createdAt" : "2021-02-26T17:03:31Z",
        "updatedAt" : "2021-02-26T17:03:36Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      },
      {
        "id" : "be7ffd50-62f2-41a3-9f07-6a1bf4469727",
        "parentId" : "25513caf-13a1-4b5f-b0ce-4a1bec6bd6c2",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Yea we should. I only moved this one because it broke some tests.",
        "createdAt" : "2021-03-01T05:44:36Z",
        "updatedAt" : "2021-03-01T05:44:37Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "a2c6575cf06660bee6245bc6a23da8713205c74c",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +166,170 @@      // `ShowTableExtended` should have been converted to the v1 command if the table is v1.\n      case _: ShowTableExtended =>\n        throw new AnalysisException(\"SHOW TABLE EXTENDED is not supported for v2 tables.\")\n\n      case operator: LogicalPlan =>"
  },
  {
    "id" : "da7120e5-dec8-4a7c-b2b1-dc19bc15f315",
    "prId" : 30878,
    "prUrl" : "https://github.com/apache/spark/pull/30878#pullrequestreview-556709983",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6be6dd24-bab2-4a31-b85d-cc1687e9e6d1",
        "parentId" : null,
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "Do we want to throw this exception at a specific node, or is it not needed?\r\n```scala\r\n    /** Fails the analysis at the point where a specific tree node was parsed. */\r\n    def failAnalysis(msg: String): Nothing = {\r\n      throw new AnalysisException(msg, t.origin.line, t.origin.startPosition)\r\n    }\r\n```",
        "createdAt" : "2020-12-21T22:46:21Z",
        "updatedAt" : "2020-12-21T22:47:35Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "6893510ed0405fef2fd6dab03709151d9da391e0",
    "line" : 46,
    "diffHunk" : "@@ -1,1 +134,138 @@      case write: V2WriteCommand if write.table.isInstanceOf[UnresolvedRelation] =>\n        val tblName = write.table.asInstanceOf[UnresolvedRelation].multipartIdentifier\n        throw new NoSuchTableException(s\"Table or view not found: ${tblName.quoted}\")\n\n      case u: UnresolvedV2Relation if isView(u.originalNameParts) =>"
  },
  {
    "id" : "5fa424ec-f191-4236-9acd-c5fe69d9d06c",
    "prId" : 30878,
    "prUrl" : "https://github.com/apache/spark/pull/30878#pullrequestreview-557731662",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f8ab63bc-9d23-4f32-ba50-1ef29a1d5d3f",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "One benefit of `u.failAnalysis` is that it can report the error position in SQL string. If we can't keep this feature with the new exception, I'd suggest we don't change the exception type.",
        "createdAt" : "2020-12-22T08:39:25Z",
        "updatedAt" : "2020-12-22T08:39:26Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "63242605-dcea-40a9-897e-cdefca138292",
        "parentId" : "f8ab63bc-9d23-4f32-ba50-1ef29a1d5d3f",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "Should we close this PR or update `NoSuchNamespaceException` and `NoSuchTableException` to handle positions?\r\n\r\nBtw, it looks like there is a bug in keeping the position. I will fix it separately.",
        "createdAt" : "2020-12-23T03:27:30Z",
        "updatedAt" : "2020-12-23T03:27:30Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      },
      {
        "id" : "ad16c044-cde6-4a2c-94f4-8f541fa8af5d",
        "parentId" : "f8ab63bc-9d23-4f32-ba50-1ef29a1d5d3f",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "> ... update NoSuchNamespaceException and NoSuchTableException to handle positions?\r\n\r\nIf it's easy to do, let's go for it. Otherwise, we can close this PR as exception type seems not a big deal to me.",
        "createdAt" : "2020-12-23T09:01:38Z",
        "updatedAt" : "2020-12-23T09:01:39Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "6893510ed0405fef2fd6dab03709151d9da391e0",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +100,104 @@\n      case u: UnresolvedNamespace =>\n        throw new NoSuchNamespaceException(s\"Namespace not found: ${u.multipartIdentifier.quoted}\")\n\n      case u: UnresolvedTable =>"
  },
  {
    "id" : "f6d929ec-803e-4768-990b-3784d61f307f",
    "prId" : 30636,
    "prUrl" : "https://github.com/apache/spark/pull/30636#pullrequestreview-546814445",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "18dc30d0-9a51-4012-a568-2ab8bbc809b5",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "do we have a clear rule about when `hint` should be used in error message?",
        "createdAt" : "2020-12-08T06:34:38Z",
        "updatedAt" : "2020-12-08T07:34:14Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "f7b8b90a-6e1a-4466-93cb-59a77ce880b3",
        "parentId" : "18dc30d0-9a51-4012-a568-2ab8bbc809b5",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "The rule I am thinking is if an expected \"type\" of relation is not found. For example, `UnresolvedTable` is resolved to `ResolvedView` or `UnresolvedView` is resolved to `ResolvedTable`.",
        "createdAt" : "2020-12-08T06:39:52Z",
        "updatedAt" : "2020-12-08T07:34:14Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      },
      {
        "id" : "7a8ce9fc-fbee-42fa-ae9d-ec384b30d0ad",
        "parentId" : "18dc30d0-9a51-4012-a568-2ab8bbc809b5",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "then probably we should make the name clearer: `relationTypeMismatchHint`",
        "createdAt" : "2020-12-08T07:27:42Z",
        "updatedAt" : "2020-12-08T07:34:14Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "4ef189cf-390f-46a2-9108-2da628cb17b4",
        "parentId" : "18dc30d0-9a51-4012-a568-2ab8bbc809b5",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "That sounds good, thanks!",
        "createdAt" : "2020-12-08T07:34:30Z",
        "updatedAt" : "2020-12-08T07:34:31Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "8decf274c463c3689d58feb8d2053ad888cee9f9",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +111,115 @@            s\"$cmd expects a view.\")\n\n      case u: UnresolvedView =>\n        u.failAnalysis(s\"View not found for '${u.commandName}': ${u.multipartIdentifier.quoted}\")\n"
  }
]