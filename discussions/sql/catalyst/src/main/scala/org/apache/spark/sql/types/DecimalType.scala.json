[
  {
    "id" : "cffdf0fa-5b6f-4e3b-bbe2-b0c92b961edb",
    "prId" : 26881,
    "prUrl" : "https://github.com/apache/spark/pull/26881#pullrequestreview-346018651",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3361805c-f2ce-4cca-b8ef-c9132e4312d2",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "nit: no need s\"\".",
        "createdAt" : "2020-01-21T16:33:09Z",
        "updatedAt" : "2020-01-21T16:33:09Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "563853b4d7b9a460c44b3a3de6552335d59fb3c0",
    "line" : 43,
    "diffHunk" : "@@ -1,1 +161,165 @@      throw new AnalysisException(s\"Negative scale is not allowed: $scale. \" +\n        s\"You can use spark.sql.legacy.allowNegativeScaleOfDecimal.enabled=true \" +\n        s\"to enable legacy mode to allow it.\")\n    }\n  }"
  }
]