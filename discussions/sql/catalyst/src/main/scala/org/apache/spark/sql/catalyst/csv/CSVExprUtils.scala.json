[
  {
    "id" : "258cf981-ddb0-476b-ad11-d2b71932e673",
    "prId" : 29516,
    "prUrl" : "https://github.com/apache/spark/pull/29516#pullrequestreview-472973398",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fa761161-6ae2-4bb1-974b-26919b8e9965",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "I think it's correct to _not_ trim the string that's checked to see if it starts with a comment, which is a slightly separate issue. `\\u0000` can't be used as a comment char, but other non-printable chars _could_.",
        "createdAt" : "2020-08-23T02:02:14Z",
        "updatedAt" : "2020-08-24T14:45:57Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      }
    ],
    "commit" : "b685f1c0228594965d9daca8e9796d88ecb5680f",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +40,44 @@      val commentPrefix = options.comment.toString\n      iter.dropWhile { line =>\n        line.trim.isEmpty || line.startsWith(commentPrefix)\n      }\n    } else {"
  },
  {
    "id" : "34e87074-8651-469f-a820-ea1aed6fbeeb",
    "prId" : 29516,
    "prUrl" : "https://github.com/apache/spark/pull/29516#pullrequestreview-474127210",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "732890a2-c5db-4fdd-a7ae-a00ba0e8dccc",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "@srowen, I think we should fix here too:\r\n\r\n```diff\r\n--- a/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/csv/CSVUtils.scala\r\n+++ b/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/csv/CSVUtils.scala\r\n@@ -34,12 +34,12 @@ object CSVUtils {\r\n     // might have to be removed in the near future if possible.\r\n     import lines.sqlContext.implicits._\r\n     val aliased = lines.toDF(\"value\")\r\n-    val nonEmptyLines = aliased.filter(length(trim($\"value\")) > 0)\r\n-    if (options.isCommentSet) {\r\n-      nonEmptyLines.filter(!$\"value\".startsWith(options.comment.toString)).as[String]\r\n+    val df = if (options.isCommentSet) {\r\n+      aliased.filter(!$\"value\".startsWith(options.comment.toString))\r\n     } else {\r\n-      nonEmptyLines.as[String]\r\n+      aliased\r\n     }\r\n+    df.filter(length(trim($\"value\")) > 0).as[String]\r\n   }\r\n\r\n   /**\r\n```",
        "createdAt" : "2020-08-25T02:38:55Z",
        "updatedAt" : "2020-08-25T02:38:56Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "2dab9958-2ea9-4651-a104-38c7b970453d",
        "parentId" : "732890a2-c5db-4fdd-a7ae-a00ba0e8dccc",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "I think the existing logic matches the logic of https://github.com/apache/spark/pull/29516/files#diff-7faa93f00223527237747227998e30f1R27 ? maybe I'm missing your point. The logic has always been to drop lines that are empty after trimming no matter what, regardless of comment char. Right or wrong that's separate.",
        "createdAt" : "2020-08-25T04:22:05Z",
        "updatedAt" : "2020-08-25T04:22:05Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "659dbfb0-4eab-40bc-ae8a-7266288d2be9",
        "parentId" : "732890a2-c5db-4fdd-a7ae-a00ba0e8dccc",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Oh, NVM. I misread.",
        "createdAt" : "2020-08-25T04:31:36Z",
        "updatedAt" : "2020-08-25T04:31:36Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "b685f1c0228594965d9daca8e9796d88ecb5680f",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +40,44 @@      val commentPrefix = options.comment.toString\n      iter.dropWhile { line =>\n        line.trim.isEmpty || line.startsWith(commentPrefix)\n      }\n    } else {"
  },
  {
    "id" : "9a24be4e-02ae-408f-907f-94cd7a7ed4eb",
    "prId" : 26027,
    "prUrl" : "https://github.com/apache/spark/pull/26027#pullrequestreview-298218557",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "77867741-53c4-4087-b60a-0c1dc600a60c",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "You might throw in an example here. The idea of a chunk is just to account for expressing a tab as `\\t`, right? That kind of example could clarify this. Really the delimiter is just a string whose backslash escapes have been resolved in the same way that a Scala / Java string does (right?)\r\n\r\nThis documentation is fine here but is even more important in the docs for what the CSV reader accepts.",
        "createdAt" : "2019-10-04T19:50:11Z",
        "updatedAt" : "2019-10-14T20:16:45Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "0b4584ae-6250-42cd-9933-c94e86e52987",
        "parentId" : "77867741-53c4-4087-b60a-0c1dc600a60c",
        "authorId" : "131e32f1-d23a-4a45-83d3-5ba1dac05455",
        "body" : "I added some examples to the Scaladoc, and also a new test suite that shows various inputs and outputs.  And yes, your description is accurate.  This method is a bit analogous to `StringEscapeUtils#unescapeJava` from Apache `commons-text`.\r\n\r\nRegarding the docs, I'm happy to take a look if you point out where that should be.",
        "createdAt" : "2019-10-04T21:29:03Z",
        "updatedAt" : "2019-10-14T20:16:45Z",
        "lastEditedBy" : "131e32f1-d23a-4a45-83d3-5ba1dac05455",
        "tags" : [
        ]
      },
      {
        "id" : "350f985a-4be2-4bfc-a14b-220ddf27a05f",
        "parentId" : "77867741-53c4-4087-b60a-0c1dc600a60c",
        "authorId" : "131e32f1-d23a-4a45-83d3-5ba1dac05455",
        "body" : "Correction: created new test in existing `CSVExprUtilsSuite`.",
        "createdAt" : "2019-10-04T21:59:49Z",
        "updatedAt" : "2019-10-14T20:16:45Z",
        "lastEditedBy" : "131e32f1-d23a-4a45-83d3-5ba1dac05455",
        "tags" : [
        ]
      },
      {
        "id" : "9af5086a-1abf-47c3-bf0a-dcc692b793d6",
        "parentId" : "77867741-53c4-4087-b60a-0c1dc600a60c",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Take a look at `DataFrameReader.scala` and `def csv(paths: String*)`. There's a big chunk of API doc that describes the options. This should be updated, along with the equivalent in Pyspark, and SparkR if it exists (I forget)",
        "createdAt" : "2019-10-04T22:20:16Z",
        "updatedAt" : "2019-10-14T20:16:45Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "1e8929f6-01e4-466c-b012-29a8904a4cfb",
        "parentId" : "77867741-53c4-4087-b60a-0c1dc600a60c",
        "authorId" : "131e32f1-d23a-4a45-83d3-5ba1dac05455",
        "body" : "I updated what I understood to be the correct spots in the Python files, with the same new text (happy to reword as needed).  I searched a few different ways for the equivalent in the `.R` files and couldn't find anything.",
        "createdAt" : "2019-10-07T15:32:14Z",
        "updatedAt" : "2019-10-14T20:16:45Z",
        "lastEditedBy" : "131e32f1-d23a-4a45-83d3-5ba1dac05455",
        "tags" : [
        ]
      }
    ],
    "commit" : "17ebe0cbcd639e2ef436ed105696bac3fd159b40",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +91,95 @@   *   <li>a non-backslash character by itself</li>\n   * </ul>\n   * , in that order of precedence. The result of the converting all chunks is returned as\n   * a [[String]].\n   *"
  },
  {
    "id" : "3480cd49-a738-4859-9f2c-628023ecbf65",
    "prId" : 26027,
    "prUrl" : "https://github.com/apache/spark/pull/26027#pullrequestreview-298343362",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5d57ce17-ca18-4766-adc2-8559bb63713e",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Sorry if I am rushing to read but why do we need this escaping logic? can't we just set the option as `\"\\t\"` instead of `\"\"\"\\t\"\"\"`?\r\n\r\nor .. is something Univocity expects? If this is the case, it would be easier to review if you link Univocity side's doc.",
        "createdAt" : "2019-10-05T04:34:55Z",
        "updatedAt" : "2019-10-14T20:16:45Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "159e19a5-6eac-4bd6-be76-c8ede1b2900f",
        "parentId" : "5d57ce17-ca18-4766-adc2-8559bb63713e",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Yeah it's a fair point @jeff303 ; won't this already be unescaped by virtue of being a string literal? If I pass `\"\\\\\"` then the string literal is a single backslash, by the time it gets here. That would yield an error, not specify a single backslash as delimiter.",
        "createdAt" : "2019-10-07T14:00:49Z",
        "updatedAt" : "2019-10-14T20:16:45Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "f8ff57d2-d666-4e81-a778-9cd04e613e0b",
        "parentId" : "5d57ce17-ca18-4766-adc2-8559bb63713e",
        "authorId" : "131e32f1-d23a-4a45-83d3-5ba1dac05455",
        "body" : "This same question also applies to the existing method (`toChar`), right? I'm attempting to adhere to the same semantics that it's using.  My assumption was that at some level, this input might come from some context that can't directly specify a tab character (web UI, another language, etc.).",
        "createdAt" : "2019-10-07T15:13:36Z",
        "updatedAt" : "2019-10-14T20:16:45Z",
        "lastEditedBy" : "131e32f1-d23a-4a45-83d3-5ba1dac05455",
        "tags" : [
        ]
      },
      {
        "id" : "3b593356-8baf-4783-be9f-234f3e5851ec",
        "parentId" : "5d57ce17-ca18-4766-adc2-8559bb63713e",
        "authorId" : "131e32f1-d23a-4a45-83d3-5ba1dac05455",
        "body" : "It looks like the existing logic was put into place under #22379.",
        "createdAt" : "2019-10-07T15:20:37Z",
        "updatedAt" : "2019-10-14T20:16:45Z",
        "lastEditedBy" : "131e32f1-d23a-4a45-83d3-5ba1dac05455",
        "tags" : [
        ]
      },
      {
        "id" : "52993484-c844-40f2-b479-ee33e4bb175f",
        "parentId" : "5d57ce17-ca18-4766-adc2-8559bb63713e",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Yeah you're right I'm also questioning why this method is there to parse the delimiter at all. Seems like the result of passing `\"\\\\\"` would be surprising. It existed before that change, even. @MaxGekk do you recall anything about this part? why does the string need further unescaping?\r\n\r\nWell.. we could say that's a separate question and just leave this issue aside here entirely.",
        "createdAt" : "2019-10-07T15:48:40Z",
        "updatedAt" : "2019-10-14T20:16:45Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "fab33d5a-d6fb-40b4-ae33-4a9829e8e60c",
        "parentId" : "5d57ce17-ca18-4766-adc2-8559bb63713e",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Let me suggest discussing this point at https://github.com/apache/spark/pull/26027#discussion_r332182154 below",
        "createdAt" : "2019-10-07T19:00:21Z",
        "updatedAt" : "2019-10-14T20:16:45Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      }
    ],
    "commit" : "17ebe0cbcd639e2ef436ed105696bac3fd159b40",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +95,99 @@   *\n   * <br/><br/>Examples:\n   * <ul><li>`\\t` will result in a single tab character as the separator (same as before)\n   * </li><li>`|||` will result in a sequence of three pipe characters as the separator\n   * </li><li>`\\\\` will result in a single backslash as the separator (same as before)"
  },
  {
    "id" : "eb594f1c-1831-4f47-b330-2b7ac909da1e",
    "prId" : 26027,
    "prUrl" : "https://github.com/apache/spark/pull/26027#pullrequestreview-298395855",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "856f90bc-1cdd-4013-b7d4-14ed8f45a6e3",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "`toChar()` can handle `\"\\u0000\"` which is not 2 chars long, I think. Could you check this case and write a test for that.",
        "createdAt" : "2019-10-05T08:12:31Z",
        "updatedAt" : "2019-10-14T20:16:45Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "0744f500-ff14-4bdb-8f53-d3a5847a8a8e",
        "parentId" : "856f90bc-1cdd-4013-b7d4-14ed8f45a6e3",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "I was going to say, it's not worth it, because `toChar` doesn't support general unicode syntax either, and it's Java/Scala syntax anyway, and `\\0` is the more natural way to say it. But `toChar` doesn't support `\\0`. We could at least special-case that in `toChar` as well instead, to support NULL as a delimiter, rather than expand the logic here.",
        "createdAt" : "2019-10-07T13:56:25Z",
        "updatedAt" : "2019-10-14T20:16:45Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "ccc1c79d-3aa2-4a0f-8d30-671f73f16fa9",
        "parentId" : "856f90bc-1cdd-4013-b7d4-14ed8f45a6e3",
        "authorId" : "131e32f1-d23a-4a45-83d3-5ba1dac05455",
        "body" : "I just added a couple more tests, for both varieties of the null character.  They were already being handled.  `\\u0000` was handled because of the special case in `toChar`), and `\\0` was handled because of the normal single character case (i.e. `case Seq(c) => c`).",
        "createdAt" : "2019-10-07T15:30:22Z",
        "updatedAt" : "2019-10-14T20:16:45Z",
        "lastEditedBy" : "131e32f1-d23a-4a45-83d3-5ba1dac05455",
        "tags" : [
        ]
      },
      {
        "id" : "30b915f8-c8a4-49ff-9cc6-257a00abbbb7",
        "parentId" : "856f90bc-1cdd-4013-b7d4-14ed8f45a6e3",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "I don't think anything but Scala is handling the `\\u0000` case. The String is one character by the time any of this executes. I think you'd find this _doesn't_ work if you write `\"\\\\u0000\"`, which is what you would have to do to actually encounter the 6-character string `\\u0000` here. But then you'd interpret the delimiter as `u0000`. Same problem as the `\"\\\\\"` case.\r\n\r\nTo your test case below -- unicode unescaping happens before everything, so `\"\"\"\\u0000\"\"\"` still yields a 1-character delimiter.\r\n\r\nI would suggest punting on this right here, but I am kind of concerned about the '\"\\\\\"` case in general. \r\nI would remove the added comment above about backslash escaping because AFAICT people should just be using the language's string literal syntax for expressing the chars, and we actually shouldn't further unescape them, but we can leave that much unchanged here.\r\n\r\nWe may find this whole loop is unnecessary as a result.",
        "createdAt" : "2019-10-07T18:54:44Z",
        "updatedAt" : "2019-10-14T20:16:45Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "4e88362e-05eb-48af-8cd4-3312ceed582e",
        "parentId" : "856f90bc-1cdd-4013-b7d4-14ed8f45a6e3",
        "authorId" : "131e32f1-d23a-4a45-83d3-5ba1dac05455",
        "body" : "Ah yes, I made an incorrect assumption about how the triple quote interpolator works.  But yes, if the whole partial unescape stuff could be removed, then it would be far simpler here.",
        "createdAt" : "2019-10-07T20:38:23Z",
        "updatedAt" : "2019-10-14T20:16:45Z",
        "lastEditedBy" : "131e32f1-d23a-4a45-83d3-5ba1dac05455",
        "tags" : [
        ]
      }
    ],
    "commit" : "17ebe0cbcd639e2ef436ed105696bac3fd159b40",
    "line" : 47,
    "diffHunk" : "@@ -1,1 +116,120 @@      // if the current character is a backslash, check it plus the next char\n      // in order to use existing escape logic\n      val readAhead = if (str(idx) == '\\\\') 2 else 1\n      // get the chunk of 1 or 2 input characters to convert to a single delimiter char\n      val chunk = StringUtils.substring(str, idx, idx + readAhead)"
  },
  {
    "id" : "b109f070-bb15-423d-9cad-f9101150f1a1",
    "prId" : 26027,
    "prUrl" : "https://github.com/apache/spark/pull/26027#pullrequestreview-298217591",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "521d181b-6248-4f61-b92f-621824d9ecc9",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "You could return a char and consumed chars from `toChar()`, so you won't need to analyze input twice to guess length of currently handled delimiter.",
        "createdAt" : "2019-10-05T08:20:23Z",
        "updatedAt" : "2019-10-14T20:16:45Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "9504ef5b-9db9-4fca-b400-50588b829f95",
        "parentId" : "521d181b-6248-4f61-b92f-621824d9ecc9",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "IMHO not necessarily worth it. perf isn't an issue here, compared to keeping it simple.",
        "createdAt" : "2019-10-07T13:57:10Z",
        "updatedAt" : "2019-10-14T20:16:45Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "da529136-377f-4ed5-b1ef-32bbde76ec1a",
        "parentId" : "521d181b-6248-4f61-b92f-621824d9ecc9",
        "authorId" : "131e32f1-d23a-4a45-83d3-5ba1dac05455",
        "body" : "Done (switched to plain String replacement).",
        "createdAt" : "2019-10-07T15:30:49Z",
        "updatedAt" : "2019-10-14T20:16:45Z",
        "lastEditedBy" : "131e32f1-d23a-4a45-83d3-5ba1dac05455",
        "tags" : [
        ]
      }
    ],
    "commit" : "17ebe0cbcd639e2ef436ed105696bac3fd159b40",
    "line" : 50,
    "diffHunk" : "@@ -1,1 +119,123 @@      // get the chunk of 1 or 2 input characters to convert to a single delimiter char\n      val chunk = StringUtils.substring(str, idx, idx + readAhead)\n      delimiter += toChar(chunk)\n      // advance the counter by the length of input chunk processed\n      idx += chunk.length()"
  },
  {
    "id" : "1c7e3b64-9f92-4a11-a08d-8a1021915ab0",
    "prId" : 26027,
    "prUrl" : "https://github.com/apache/spark/pull/26027#pullrequestreview-298217869",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4eb0f660-2934-4b52-85ae-5275da8ee6af",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Please, take a look at the `StringConcat`: https://github.com/apache/spark/blob/a1213d5f963f6e8815bbfaff308b0a24112fff54/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/util/StringUtils.scala#L101-L106 . You can use it here.",
        "createdAt" : "2019-10-05T08:39:23Z",
        "updatedAt" : "2019-10-14T20:16:45Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "91d524b1-6ac2-48cc-883a-49d7b7508230",
        "parentId" : "4eb0f660-2934-4b52-85ae-5275da8ee6af",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Same, IMHO not worth it. We're concatenating 1-2 strings here usually. I'd still just build up a `var delimiter: String =\"\"`",
        "createdAt" : "2019-10-07T13:58:48Z",
        "updatedAt" : "2019-10-14T20:16:45Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "a367ec84-d3c2-4020-b33b-1c0971f76609",
        "parentId" : "4eb0f660-2934-4b52-85ae-5275da8ee6af",
        "authorId" : "131e32f1-d23a-4a45-83d3-5ba1dac05455",
        "body" : "Done (switched to plain String replacement).",
        "createdAt" : "2019-10-07T15:31:11Z",
        "updatedAt" : "2019-10-14T20:16:45Z",
        "lastEditedBy" : "131e32f1-d23a-4a45-83d3-5ba1dac05455",
        "tags" : [
        ]
      }
    ],
    "commit" : "17ebe0cbcd639e2ef436ed105696bac3fd159b40",
    "line" : 39,
    "diffHunk" : "@@ -1,1 +108,112 @@   * @throws IllegalArgumentException if any of the individual input chunks are illegal\n   */\n  def toDelimiterStr(str: String): String = {\n    var idx = 0\n"
  }
]