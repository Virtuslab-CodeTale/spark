[
  {
    "id" : "9a2f6f84-81e0-4b83-8c05-547595e3e37f",
    "prId" : 32768,
    "prUrl" : "https://github.com/apache/spark/pull/32768#pullrequestreview-675897835",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a675c5ed-ef5e-4a60-a1a4-cdfbe4883385",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "My only concern is that now `externalCatalog` cannot handle `ignoreIfNotExists` properly. Previously the handling was delegated.",
        "createdAt" : "2021-06-04T00:52:34Z",
        "updatedAt" : "2021-06-04T00:52:35Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "1fa9411b-3815-4499-b56c-35297f068b9b",
        "parentId" : "a675c5ed-ef5e-4a60-a1a4-cdfbe4883385",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "Not sure I get your ponit. You mean this `SessionCatalog` can not handle `ignoreIfNotExists` correctly ?",
        "createdAt" : "2021-06-04T02:48:30Z",
        "updatedAt" : "2021-06-04T02:48:30Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      },
      {
        "id" : "6d550c08-fc45-4186-be0d-67579c9d98e5",
        "parentId" : "a675c5ed-ef5e-4a60-a1a4-cdfbe4883385",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "I mean, if the DB already exists, `externalCatalog` cannot handle the case anymore because it will throw an exception in the Spark. Previously it was delegated to `externalCatalog` right?",
        "createdAt" : "2021-06-04T03:27:22Z",
        "updatedAt" : "2021-06-04T03:27:22Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "7aee4d26-f8cb-4b1a-ba36-eafa4d096d3d",
        "parentId" : "a675c5ed-ef5e-4a60-a1a4-cdfbe4883385",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "`externalCatalog` can be not only Hive but can be other implementations, and maybe there could be some special handling for these cases (e.g., cleaning up resources)",
        "createdAt" : "2021-06-04T03:28:28Z",
        "updatedAt" : "2021-06-04T03:28:28Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "2e715c7f-c0c2-4895-8d22-88e1d3e4f6a1",
        "parentId" : "a675c5ed-ef5e-4a60-a1a4-cdfbe4883385",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "thanks for the explaination, I see your concern. Seems we also didn't handle this in `drop table` or `drop function`.. \r\n```\r\nrequireDbExists(db)\r\nif (tableExists(TableIdentifier(table, Option(db)))) {\r\n  externalCatalog.dropTable(db, table, ignoreIfNotExists = true, purge = purge)\r\n} else if (!ignoreIfNotExists) {\r\n  throw new NoSuchTableException(db = db, table = table)\r\n}\r\n```\r\n\r\nSo I'm assuming it's OK in `drop database` ? ",
        "createdAt" : "2021-06-04T03:42:34Z",
        "updatedAt" : "2021-06-04T03:42:34Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      },
      {
        "id" : "26ef98c4-3742-4921-997c-128c9d87b51d",
        "parentId" : "a675c5ed-ef5e-4a60-a1a4-cdfbe4883385",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "hm .. okie",
        "createdAt" : "2021-06-04T03:56:13Z",
        "updatedAt" : "2021-06-04T03:56:14Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "7be58a98-e38c-4831-8883-324c1c1f8740",
        "parentId" : "a675c5ed-ef5e-4a60-a1a4-cdfbe4883385",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "As I see it, we'd better remove `requireDbExists` check from the table and function APIs in the `SessionCatalog`?",
        "createdAt" : "2021-06-04T03:56:55Z",
        "updatedAt" : "2021-06-04T03:56:55Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "db9425d09cf339a5cd7eb588feebb84fda5a07fb",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +267,271 @@    }\n    if (!ignoreIfNotExists) {\n      requireDbExists(dbName)\n    }\n    if (cascade && databaseExists(dbName)) {"
  },
  {
    "id" : "35be5a85-8c4b-4b06-b832-005f78d2513f",
    "prId" : 32589,
    "prUrl" : "https://github.com/apache/spark/pull/32589#pullrequestreview-665386518",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0992abb0-47c8-4435-8704-e4736e8a5a2e",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Hm, this will disable external catalogs to handle on `ignoreIfExists=true`. Other external catalogs might have some logics on this call e.g.) sending a create table event.",
        "createdAt" : "2021-05-21T03:40:25Z",
        "updatedAt" : "2021-05-21T03:40:25Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "60b46f90-4821-4e97-8d3a-46b9683560ab",
        "parentId" : "0992abb0-47c8-4435-8704-e4736e8a5a2e",
        "authorId" : "6a8d0007-eb0f-4236-a65a-2174a14ac689",
        "body" : "Oh, My bad, i will close the title.",
        "createdAt" : "2021-05-21T12:00:34Z",
        "updatedAt" : "2021-05-21T12:00:34Z",
        "lastEditedBy" : "6a8d0007-eb0f-4236-a65a-2174a14ac689",
        "tags" : [
        ]
      }
    ],
    "commit" : "678e2b0adbf9071c590502396f9bafdfc082cc5a",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +368,372 @@        throw new TableAlreadyExistsException(db = db, table = table)\n      }\n      return\n    } else if (validateLocation) {\n      validateTableLocation(newTableDefinition)"
  },
  {
    "id" : "ce69db5a-d54b-4ef5-91ec-80e07957fa91",
    "prId" : 31462,
    "prUrl" : "https://github.com/apache/spark/pull/31462#pullrequestreview-583113596",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1a0b8eb5-dfa1-49ac-baff-09be19300563",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Does this add a `View` wrapper which is not added previously?",
        "createdAt" : "2021-02-04T07:19:23Z",
        "updatedAt" : "2021-02-04T07:19:24Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "e2301afe-804f-474b-8481-86d840d0a990",
        "parentId" : "1a0b8eb5-dfa1-49ac-baff-09be19300563",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "Yes. This is added so we can pass a parsed view plan to `CatalogImpl.uncacheView`. I _think_ it also fixes a potential issue in `refreshTable` where `refresh` is called on `TemporaryViewRelation` instead of `View`. ",
        "createdAt" : "2021-02-04T07:53:29Z",
        "updatedAt" : "2021-02-04T07:53:29Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      }
    ],
    "commit" : "27e86350b7d3802db7e8fcd22e3ec732693570c6",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +915,919 @@      tempViews.get(tableName).map(getTempViewPlan)\n    } else if (formatDatabaseName(name.database.get) == globalTempViewManager.database) {\n      globalTempViewManager.get(tableName).map(getTempViewPlan)\n    } else {\n      None"
  },
  {
    "id" : "e46a0b8b-13ee-4349-b6c3-5f00d2420800",
    "prId" : 31273,
    "prUrl" : "https://github.com/apache/spark/pull/31273#pullrequestreview-595166686",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "01d7e7de-52bc-4dbe-a19e-b97ef8e87941",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "let's update `getGlobalTempView` as well.",
        "createdAt" : "2021-02-22T09:44:58Z",
        "updatedAt" : "2021-02-24T04:37:19Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "82d58baa98235f912141b2b40cdcd3bf0bdbe744",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +623,627 @@\n  /**\n   * Generate a [[View]] operator from the temporary view stored.\n   */\n  def getTempView(name: String): Option[LogicalPlan] = synchronized {"
  },
  {
    "id" : "4986ff1f-25ad-4406-ba49-54789f44b4ad",
    "prId" : 31273,
    "prUrl" : "https://github.com/apache/spark/pull/31273#pullrequestreview-596047754",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2d3f4c68-c14b-4707-a65b-0d64c0537872",
        "parentId" : null,
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "If the current PR's approach is fine, we can remove this `case other => other` and change `createTempView` to use `tableDefinition: TemporaryViewRelation` instead of `tableDefinition: LogicalPlan` once we migrate `ALTER VIEW AS` and `CREATE TEMP VIEW USING`.",
        "createdAt" : "2021-02-23T04:11:49Z",
        "updatedAt" : "2021-02-24T04:37:19Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      },
      {
        "id" : "9643c35d-add8-4426-bcfd-b803daa89fda",
        "parentId" : "2d3f4c68-c14b-4707-a65b-0d64c0537872",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "+1",
        "createdAt" : "2021-02-23T07:22:11Z",
        "updatedAt" : "2021-02-24T04:37:19Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "82d58baa98235f912141b2b40cdcd3bf0bdbe744",
    "line" : 49,
    "diffHunk" : "@@ -1,1 +841,845 @@      case TemporaryViewRelation(tableMeta, Some(plan)) =>\n        View(desc = tableMeta, isTempView = true, child = plan)\n      case other => other\n    }\n  }"
  },
  {
    "id" : "55d59271-d279-48b4-a0ea-36d75b8863b3",
    "prId" : 31273,
    "prUrl" : "https://github.com/apache/spark/pull/31273#pullrequestreview-595984931",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "090f83ec-a5c0-41c3-a24c-00caf7b3421f",
        "parentId" : null,
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "If https://github.com/apache/spark/pull/31273/files#r580757641 is done, `case plan` can also be removed.",
        "createdAt" : "2021-02-23T04:14:27Z",
        "updatedAt" : "2021-02-24T04:37:19Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "82d58baa98235f912141b2b40cdcd3bf0bdbe744",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +683,687 @@      tempViews.get(table).map {\n        case TemporaryViewRelation(metadata, _) => metadata\n        case plan =>\n          CatalogTable(\n            identifier = TableIdentifier(table),"
  },
  {
    "id" : "97d9b3bb-a9ea-4334-83a9-e80f656827ba",
    "prId" : 31206,
    "prUrl" : "https://github.com/apache/spark/pull/31206#pullrequestreview-573708031",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ce387918-091e-476d-8677-925f3bf1ade5",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "if the `name` refers to a temp view, we shouldn't call `invalidateCachedTable` here which may accidentally invalid cache for a table with the same name as the temp view.",
        "createdAt" : "2021-01-20T02:27:19Z",
        "updatedAt" : "2021-01-21T09:07:03Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "fe2f40a7-d3f7-4d59-b9eb-767988e3685a",
        "parentId" : "ce387918-091e-476d-8677-925f3bf1ade5",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "This will not cause any correctness issue, right?\r\n\r\nok. Look at `SessionCatalog.refreshTable`:\r\nhttps://github.com/apache/spark/blob/157b72ac9fa0057d5fd6d7ed52a6c4b22ebd1dfc/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/catalog/SessionCatalog.scala#L990-L1006\r\n\r\nif `name` is a temp view, the function could invalidate a record in `tableRelationCache` for a table. but nothing bad happens, `tableRelationCache` will be filled in next time.",
        "createdAt" : "2021-01-20T07:36:56Z",
        "updatedAt" : "2021-01-21T09:07:03Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "5fcbddb8-52e4-49e1-9ce8-50e5ae9a5601",
        "parentId" : "ce387918-091e-476d-8677-925f3bf1ade5",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "it doesn't matter too much but still better to avoid. If it's already the case before, then we don't need to fix it here.",
        "createdAt" : "2021-01-20T08:52:08Z",
        "updatedAt" : "2021-01-21T09:07:03Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "ed4edc78-26e6-4592-9e79-fa890544c9b1",
        "parentId" : "ce387918-091e-476d-8677-925f3bf1ade5",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Seems it's not the case before according to https://github.com/apache/spark/pull/31206/files#r561316669 , @MaxGekk can you fix it?",
        "createdAt" : "2021-01-21T05:33:19Z",
        "updatedAt" : "2021-01-21T09:07:03Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "22487c64-e57a-4baf-8815-797a0e298067",
        "parentId" : "ce387918-091e-476d-8677-925f3bf1ade5",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "ok. I will wrap the invalidation by the check:\r\n```scala\r\n    if (!sessionCatalog.isTemporaryTable(tableIdent)) {\r\n      sessionCatalog.invalidateCachedTable(tableIdent)\r\n    }\r\n```",
        "createdAt" : "2021-01-21T07:19:43Z",
        "updatedAt" : "2021-01-21T09:07:03Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "6714244b-c7fc-498c-8045-5cf753af63e7",
        "parentId" : "ce387918-091e-476d-8677-925f3bf1ade5",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Here is a fix for `SessionCatalog.refreshTable()`: https://github.com/apache/spark/pull/31265",
        "createdAt" : "2021-01-21T20:26:22Z",
        "updatedAt" : "2021-01-21T20:26:23Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "357c69f888ed4f27ea8db3b78d79d123b4dac019",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +175,179 @@    val dbName = formatDatabaseName(name.database.getOrElse(currentDb))\n    val tableName = formatTableName(name.table)\n    invalidateCachedTable(QualifiedTableName(dbName, tableName))\n  }\n"
  },
  {
    "id" : "22eb0475-c731-43dc-b00d-426e7b39a7f7",
    "prId" : 30567,
    "prUrl" : "https://github.com/apache/spark/pull/30567#pullrequestreview-544683942",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "45dd5056-7647-472c-8def-769f3f3b17ab",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "we can remove this line",
        "createdAt" : "2020-12-04T06:20:50Z",
        "updatedAt" : "2020-12-04T06:20:50Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "db9f0baffd424beba5f9efd19620d781cfb2b22b",
    "line" : 44,
    "diffHunk" : "@@ -1,1 +665,669 @@      }.getOrElse(getTableMetadata(name))\n    } else if (formatDatabaseName(name.database.get) == globalTempViewManager.database) {\n      val a = globalTempViewManager.get(table)\n      globalTempViewManager.get(table).map {\n        case TemporaryViewRelation(metadata) => metadata"
  },
  {
    "id" : "cbc67a6d-b7de-45c8-a2eb-995fd3c68d69",
    "prId" : 30567,
    "prUrl" : "https://github.com/apache/spark/pull/30567#pullrequestreview-544692666",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9d3be2a4-d410-41b6-9503-66e857c67ab3",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "this can be private.",
        "createdAt" : "2020-12-04T06:44:14Z",
        "updatedAt" : "2020-12-04T06:44:14Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "db9f0baffd424beba5f9efd19620d781cfb2b22b",
    "line" : 97,
    "diffHunk" : "@@ -1,1 +813,817 @@  }\n\n  def getTempViewPlan(plan: LogicalPlan): LogicalPlan = {\n    plan match {\n      case viewInfo: TemporaryViewRelation =>"
  },
  {
    "id" : "da90bdd0-8d82-435f-928f-03d305ed4b2c",
    "prId" : 30538,
    "prUrl" : "https://github.com/apache/spark/pull/30538#pullrequestreview-542785232",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "61c10378-5b84-43c5-b083-6b014c755368",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ditto",
        "createdAt" : "2020-12-02T12:27:03Z",
        "updatedAt" : "2021-01-08T08:03:31Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "89c15724d5af9b423a14f512c8764bd26eee6c9f",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1179,1183 @@  private def requireNonEmptyValueInPartitionSpec(specs: Seq[TablePartitionSpec]): Unit = {\n    specs.foreach { s =>\n      if (s.values.exists(v => v != null && v.isEmpty)) {\n        val spec = s.map(p => p._1 + \"=\" + p._2).mkString(\"[\", \", \", \"]\")\n        throw QueryCompilationErrors.invalidPartitionSpecError("
  },
  {
    "id" : "9e113c8b-29e9-4380-8e8f-a578acea56f7",
    "prId" : 29502,
    "prUrl" : "https://github.com/apache/spark/pull/29502#pullrequestreview-480835685",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3d50242c-6656-4080-b19f-b104d03ce28d",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can we reuse the code with `registerFunction`?",
        "createdAt" : "2020-09-02T13:46:25Z",
        "updatedAt" : "2020-09-05T12:23:16Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "3cf971b5603b236f0a877d4804245742de94cbd5",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +1371,1375 @@  def requireFunctionClassExists(funcDefinition: CatalogFunction): Unit = {\n    val className = funcDefinition.className\n    if (!Utils.classIsLoadable(className)) {\n      throw new AnalysisException(s\"Can not load class '$className' when registering \" +\n        s\"the function '${funcDefinition.identifier.unquotedString}', please make sure \" +"
  },
  {
    "id" : "954c9f04-f7f4-4f7a-ba4b-e460c1f450d5",
    "prId" : 29502,
    "prUrl" : "https://github.com/apache/spark/pull/29502#pullrequestreview-481607390",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c1f3af0b-c67e-4cb0-89d5-32d59c2ae046",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "one last thing: shall we fill the default database before putting the function identifier in the error message?",
        "createdAt" : "2020-09-03T06:09:58Z",
        "updatedAt" : "2020-09-05T12:23:16Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "1c7d6e0c-3961-4463-b06d-8c80968e556e",
        "parentId" : "c1f3af0b-c67e-4cb0-89d5-32d59c2ae046",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "Not needed. \r\n\r\nThis method is used by both temporary and permanent function. The temporary has no database name and we can't fill the database name. The permanent follows user created.",
        "createdAt" : "2020-09-03T08:22:21Z",
        "updatedAt" : "2020-09-05T12:23:16Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "3cf971b5603b236f0a877d4804245742de94cbd5",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +1373,1377 @@    if (!Utils.classIsLoadable(className)) {\n      throw new AnalysisException(s\"Can not load class '$className' when registering \" +\n        s\"the function '${funcDefinition.identifier.unquotedString}', please make sure \" +\n        s\"it is on the classpath\")\n    }"
  },
  {
    "id" : "8e6d3ac9-4532-43b7-be21-3ffe15c82181",
    "prId" : 28852,
    "prUrl" : "https://github.com/apache/spark/pull/28852#pullrequestreview-439324427",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e7d6d5b1-7a68-4d36-a9f2-e6c5770db6f8",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "`cacheTTL=0` means that TTL disabled, too?",
        "createdAt" : "2020-06-25T22:52:30Z",
        "updatedAt" : "2020-07-17T04:16:07Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "7d9944d5-cf9a-4851-9275-4a8d686a1655",
        "parentId" : "e7d6d5b1-7a68-4d36-a9f2-e6c5770db6f8",
        "authorId" : "2e177144-1a17-4ac6-8d65-915343e9f2ea",
        "body" : "Yes, I think it makes sense: 0 seconds == no TTL",
        "createdAt" : "2020-06-25T23:05:03Z",
        "updatedAt" : "2020-07-17T04:16:07Z",
        "lastEditedBy" : "2e177144-1a17-4ac6-8d65-915343e9f2ea",
        "tags" : [
        ]
      },
      {
        "id" : "b64d0cc6-af26-47ee-8c8a-0dfc6a487243",
        "parentId" : "e7d6d5b1-7a68-4d36-a9f2-e6c5770db6f8",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Could you update the description in the config?",
        "createdAt" : "2020-06-25T23:09:23Z",
        "updatedAt" : "2020-07-17T04:16:07Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "c0bd381f-56c7-43e0-a028-e7ee5b44e70e",
        "parentId" : "e7d6d5b1-7a68-4d36-a9f2-e6c5770db6f8",
        "authorId" : "2e177144-1a17-4ac6-8d65-915343e9f2ea",
        "body" : "Updated in https://github.com/apache/spark/pull/28852/commits/18feeb02b11407b9eea1457139a91cb40ddc40cf, now it says: ` This configuration only has an effect when this value having a positive value (> 0)`, I think it's good enough.",
        "createdAt" : "2020-06-29T16:45:58Z",
        "updatedAt" : "2020-07-17T04:16:07Z",
        "lastEditedBy" : "2e177144-1a17-4ac6-8d65-915343e9f2ea",
        "tags" : [
        ]
      }
    ],
    "commit" : "3e761dcd790b9c30e5cee7bffe916dfc2c82b7a5",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +142,146 @@      .maximumSize(cacheSize)\n\n    if (cacheTTL > 0) {\n      builder = builder.expireAfterWrite(cacheTTL, TimeUnit.SECONDS)\n    }"
  },
  {
    "id" : "1dd20f4a-fb4d-48de-809f-cd4d9b7950d0",
    "prId" : 28852,
    "prUrl" : "https://github.com/apache/spark/pull/28852#pullrequestreview-450389651",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1aa488da-6228-4a20-bb38-79a991f02cc2",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Not related to this PR. I'm wondering how useful is this cache. The file listing is cached in another place(`FileStatusCache`), and seems this relation cache doesn't give many benefits. cc @viirya @maropu  ",
        "createdAt" : "2020-07-16T14:26:53Z",
        "updatedAt" : "2020-07-17T04:16:07Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "4fd533b6-be05-4817-911d-958f8d531ed8",
        "parentId" : "1aa488da-6228-4a20-bb38-79a991f02cc2",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ah, I see. As you suggested, the most painful part (listed files) has already been cached there. But, it seems some datasources still has somewhat processing costs when resolving a relation (e.g., JDBC datasources send a query to an external database for schema resolution), so I think we need to carefully check performance impacts for removing this cache.\r\n\r\nhttps://github.com/apache/spark/blob/fb519251237892ad474592d19bf4f193e2a9e2b6/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/DataSourceStrategy.scala#L256",
        "createdAt" : "2020-07-17T00:33:22Z",
        "updatedAt" : "2020-07-17T04:16:07Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "a05d4237-56d1-462a-80d4-45c76d125008",
        "parentId" : "1aa488da-6228-4a20-bb38-79a991f02cc2",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "For external data sources, it's common that data are changed outside of Spark. I think it's more important to make sure we get the latest data in a new query. Maybe we should disable this relation cache by default.",
        "createdAt" : "2020-07-17T04:41:56Z",
        "updatedAt" : "2020-07-17T04:41:57Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "3f7fe21d-dac4-4b93-8a5f-87b3e106d578",
        "parentId" : "1aa488da-6228-4a20-bb38-79a991f02cc2",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Hmm, I think this cache is still useful for avoiding inferring schema again. This is also an expensive operation.",
        "createdAt" : "2020-07-17T05:00:19Z",
        "updatedAt" : "2020-07-17T05:00:19Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "214206cc-2a32-4476-aa81-99879cc1ec56",
        "parentId" : "1aa488da-6228-4a20-bb38-79a991f02cc2",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ah that's a good point. We should probably investigate how to design the data source API so that sources don't need to infer schema can skip this cache. It's hard to use the JDBC data source as we need to run REFRESH TABLE (or wait for TTL after this PR) once the table is changed outside of spark (which is common to JDBC source).",
        "createdAt" : "2020-07-17T05:54:04Z",
        "updatedAt" : "2020-07-17T05:54:05Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "3e761dcd790b9c30e5cee7bffe916dfc2c82b7a5",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +135,139 @@  }\n\n  private val tableRelationCache: Cache[QualifiedTableName, LogicalPlan] = {\n    val cacheSize = conf.tableRelationCacheSize\n    val cacheTTL = conf.metadataCacheTTL"
  },
  {
    "id" : "94953b2e-0164-4a23-9fbd-d3928b0b40f3",
    "prId" : 28527,
    "prUrl" : "https://github.com/apache/spark/pull/28527#pullrequestreview-413242855",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e80c79d7-4669-475b-9a43-141ee372cd7f",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "We need to update the location uri here?",
        "createdAt" : "2020-05-17T23:37:13Z",
        "updatedAt" : "2020-07-31T09:27:43Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "ec43d1ac-bb97-4dcc-8419-048922c1082f",
        "parentId" : "e80c79d7-4669-475b-9a43-141ee372cd7f",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "We have `ALTER (DATABASE|SCHEMA) database_name SET LOCATION path` syntax that works for hive 3.x",
        "createdAt" : "2020-05-18T02:23:44Z",
        "updatedAt" : "2020-07-31T09:27:43Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "8dfe0518-537e-4747-8fd3-6159a39241d4",
        "parentId" : "e80c79d7-4669-475b-9a43-141ee372cd7f",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ah, I see.",
        "createdAt" : "2020-05-18T02:51:29Z",
        "updatedAt" : "2020-07-31T09:27:43Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "b471a0e868c54f82178cacc587a9586a26bd6175",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +251,255 @@    requireDbExists(dbName)\n    externalCatalog.alterDatabase(dbDefinition.copy(\n      name = dbName, locationUri = makeQualifiedDBPath(dbDefinition.locationUri)))\n  }\n"
  },
  {
    "id" : "860bb530-4001-4350-91d8-3a9c86063999",
    "prId" : 28527,
    "prUrl" : "https://github.com/apache/spark/pull/28527#pullrequestreview-413643431",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "57bffbb9-f945-4ade-84fd-f2db1c89c5cb",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "what if the database has a custom location?",
        "createdAt" : "2020-05-18T14:07:59Z",
        "updatedAt" : "2020-07-31T09:27:43Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "8b01e5f2-2049-4cfa-9b80-b5fe34ecb0f5",
        "parentId" : "57bffbb9-f945-4ade-84fd-f2db1c89c5cb",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "No matter if it's custom or managed, we should inherit that location for tables as same as we do for partitions\r\nhttps://github.com/apache/spark/blob/a28ed86a387b286745b30cd4d90b3d558205a5a7/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/catalog/SessionCatalog.scala#L1161-L1164",
        "createdAt" : "2020-05-18T14:22:49Z",
        "updatedAt" : "2020-07-31T09:27:43Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "b471a0e868c54f82178cacc587a9586a26bd6175",
    "line" : 61,
    "diffHunk" : "@@ -1,1 +364,368 @@    } else {\n      val dbName = formatDatabaseName(database)\n      val dbLocation = makeQualifiedDBPath(getDatabaseMetadata(dbName).locationUri)\n      new Path(new Path(dbLocation), CatalogUtils.URIToString(locationUri)).toUri\n    }"
  },
  {
    "id" : "c29ba638-5d92-4197-ada5-bda0abb8becb",
    "prId" : 28527,
    "prUrl" : "https://github.com/apache/spark/pull/28527#pullrequestreview-459037924",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ea2ff342-a8d0-4d89-b81c-649adfb58cf2",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "do we still need to call `makeQualifiedPath`? I think the `fullPath` is already qualified here.",
        "createdAt" : "2020-07-31T08:33:40Z",
        "updatedAt" : "2020-07-31T09:27:43Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "850d1ed6-bd09-432a-989d-288facb97b2d",
        "parentId" : "ea2ff342-a8d0-4d89-b81c-649adfb58cf2",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "the warehousePath can accept a relative path, the `fullPath` might not be qualified yet",
        "createdAt" : "2020-07-31T09:11:52Z",
        "updatedAt" : "2020-07-31T09:27:43Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "7afbd8ba-0a25-4d3e-943d-fdd3bbdf88e0",
        "parentId" : "ea2ff342-a8d0-4d89-b81c-649adfb58cf2",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "shall we make sure it's not relative? I think it's confusing if users set a relative path to the warehouse path.\r\n\r\nIt's not related to this PR though.",
        "createdAt" : "2020-07-31T09:18:54Z",
        "updatedAt" : "2020-07-31T09:27:43Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "440fb34b-93a2-4b37-8572-e58dc47883cf",
        "parentId" : "ea2ff342-a8d0-4d89-b81c-649adfb58cf2",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "Now it is relative to $PWD or Hadoop user home directory. I think such a change would bring serious behavior change, I'm not sure whether worth to do it or not.",
        "createdAt" : "2020-07-31T09:26:40Z",
        "updatedAt" : "2020-07-31T09:27:43Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "b471a0e868c54f82178cacc587a9586a26bd6175",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +230,234 @@    } else {\n      val fullPath = new Path(conf.warehousePath, CatalogUtils.URIToString(locationUri))\n      makeQualifiedPath(fullPath.toUri)\n    }\n  }"
  },
  {
    "id" : "db760d62-ac79-42da-b966-730e05bd073b",
    "prId" : 28527,
    "prUrl" : "https://github.com/apache/spark/pull/28527#pullrequestreview-459996329",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "60f8e137-e5ee-4482-bcce-c75785f2fca9",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I'm a bit concerned about it as it adds an extra database lookup. Is it better to push this work to the underlying external catalog?",
        "createdAt" : "2020-08-03T05:00:56Z",
        "updatedAt" : "2020-08-03T05:00:56Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "05936644-d0e2-411c-9bf2-bc2a96411e1f",
        "parentId" : "60f8e137-e5ee-4482-bcce-c75785f2fca9",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "Do you mean that we are calling `requireDbExists(dbName)` repeatedly?",
        "createdAt" : "2020-08-03T09:44:51Z",
        "updatedAt" : "2020-08-03T09:44:51Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "f0afe944-1a4c-4719-b94e-95db6ad8e4d1",
        "parentId" : "60f8e137-e5ee-4482-bcce-c75785f2fca9",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Ideally `createTable` should only do one RPC to the hive metastore. `requireDbExists` is one problem but we can simply remove it. However, the new database lookup seems can't be easily removed.",
        "createdAt" : "2020-08-03T10:03:28Z",
        "updatedAt" : "2020-08-03T10:03:28Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "d704b906-bf7e-470b-bc76-bbb55e6f40e2",
        "parentId" : "60f8e137-e5ee-4482-bcce-c75785f2fca9",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "> However, the new database lookup seems can't be easily removed.\r\n\r\nYes, it seem make no difference even we put this into external catalogs, we have to call the `getDatabase` API in order to get the actual path of the database for this particular case.",
        "createdAt" : "2020-08-03T10:17:08Z",
        "updatedAt" : "2020-08-03T10:17:08Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "8084947d-63bd-469e-a998-030b16f62a1e",
        "parentId" : "60f8e137-e5ee-4482-bcce-c75785f2fca9",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "what happens if we don't qualify the path here and leave it to hive metastore? Will it still be a relative path in the hive metastore?",
        "createdAt" : "2020-08-03T12:26:52Z",
        "updatedAt" : "2020-08-03T12:26:52Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "3576f486-8173-4928-bcc8-31e24668f963",
        "parentId" : "60f8e137-e5ee-4482-bcce-c75785f2fca9",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "FYI, https://github.com/apache/spark/pull/17254",
        "createdAt" : "2020-08-03T12:34:25Z",
        "updatedAt" : "2020-08-03T12:34:25Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "0f1d0163-3fd2-4388-b54f-aa52d51b9943",
        "parentId" : "60f8e137-e5ee-4482-bcce-c75785f2fca9",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ok we did the same thing for partition. LGTM then",
        "createdAt" : "2020-08-03T12:46:45Z",
        "updatedAt" : "2020-08-03T12:46:45Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "b471a0e868c54f82178cacc587a9586a26bd6175",
    "line" : 61,
    "diffHunk" : "@@ -1,1 +364,368 @@    } else {\n      val dbName = formatDatabaseName(database)\n      val dbLocation = makeQualifiedDBPath(getDatabaseMetadata(dbName).locationUri)\n      new Path(new Path(dbLocation), CatalogUtils.URIToString(locationUri)).toUri\n    }"
  },
  {
    "id" : "4169db3d-bbb8-4ad5-924c-85c80464df8b",
    "prId" : 28066,
    "prUrl" : "https://github.com/apache/spark/pull/28066#pullrequestreview-383441268",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ffd5678f-8d00-4af3-b078-6ebbbc6d0981",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "This looks wrong, @AngersZhuuuu . `EXTERNAL TABLE` is used to mount an exiting table location.",
        "createdAt" : "2020-03-29T18:35:29Z",
        "updatedAt" : "2020-03-29T18:35:34Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "5845ac093cfdf954fcdde9aeb9c10406d9b8c5fc",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +329,333 @@  def validateTableLocation(table: CatalogTable): Unit = {\n    // SPARK-19724: the default location of a managed table should be non-existent or empty.\n    // SPARK-31298: when create external table also should be a non-existent or empty\n    val tableLocation = if (table.tableType == CatalogTableType.MANAGED) {\n      new Path(defaultTablePath(table.identifier))"
  },
  {
    "id" : "ca6a12fd-911f-414e-a203-09b87f2c6960",
    "prId" : 27776,
    "prUrl" : "https://github.com/apache/spark/pull/27776#pullrequestreview-368517069",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0b8a2257-803c-48f5-91e9-df9492ae971c",
        "parentId" : null,
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "@cloud-fan Now that session catalog name is always inserted to a qualifier, `matchWithTwoOrLessQualifierParts` will not be used for resolving columns for v1 tables any longer. If we need this in Spark 3.0, I could try to update that function to handle 3 parts qualifier `catalog_name.db.table`.",
        "createdAt" : "2020-03-03T19:11:08Z",
        "updatedAt" : "2020-03-05T01:19:55Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      },
      {
        "id" : "399862cf-ed56-457a-a249-450bc92134d5",
        "parentId" : "0b8a2257-803c-48f5-91e9-df9492ae971c",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Yea let's handle 3 parts qualifier, to avoid perf regression.",
        "createdAt" : "2020-03-04T05:44:31Z",
        "updatedAt" : "2020-03-05T01:19:55Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "fa7560a0b742f8bfca9f9f6293c9fb14d6466d52",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +774,778 @@      SubqueryAlias(multiParts, child)\n    } else {\n      SubqueryAlias(multiParts, UnresolvedCatalogRelation(metadata))\n    }\n  }"
  },
  {
    "id" : "f01a540c-a788-41b0-933a-d372405f8873",
    "prId" : 27423,
    "prUrl" : "https://github.com/apache/spark/pull/27423#pullrequestreview-352027799",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a6a0cab7-f21b-40e2-ae14-02d2bb83a1ba",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "good catch!",
        "createdAt" : "2020-02-03T05:33:55Z",
        "updatedAt" : "2020-02-03T05:33:56Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "b6379c08e9f1060f1c94791667a749469a1d60bb",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +828,832 @@        case _: NoSuchTableException => false\n        case _: NoSuchDatabaseException => false\n        case _: NoSuchNamespaceException => false\n      }\n    }"
  },
  {
    "id" : "6831b38c-f71d-45a4-a851-1cd09fcfbb68",
    "prId" : 26627,
    "prUrl" : "https://github.com/apache/spark/pull/26627#pullrequestreview-321475405",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "be8907b8-b77c-4206-a74b-7c8fb653da0a",
        "parentId" : null,
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "Caches should pass a Callable so that populating the cache can be combined with a get operation (get or initialize).\r\n\r\nInstead of `cacheCatalogTable`, this should be `getOrCacheCatalogTable(qtn: QualifiedTableName, init: Callable[CatalogTable])` that calls `catalogTableCache.get(qtn, init)`.",
        "createdAt" : "2019-11-21T17:12:06Z",
        "updatedAt" : "2019-11-22T13:58:13Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "049f5077-503d-482c-b839-a095d1ecd928",
        "parentId" : "be8907b8-b77c-4206-a74b-7c8fb653da0a",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "OK, fix these.",
        "createdAt" : "2019-11-22T00:14:05Z",
        "updatedAt" : "2019-11-22T13:58:13Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      },
      {
        "id" : "8bc60656-c6eb-478a-9f74-0f8809639655",
        "parentId" : "be8907b8-b77c-4206-a74b-7c8fb653da0a",
        "authorId" : "b15ecdc6-6010-48de-ac9c-e282a635a1f0",
        "body" : "Here `getOrCacheCatalogTable` is just a simple wrapper doing nothing.\r\nI suggest to move the lambda parameter in the caller into this method. It is in fact a part of \"Get or Cache\".",
        "createdAt" : "2019-11-22T12:12:52Z",
        "updatedAt" : "2019-11-22T13:58:13Z",
        "lastEditedBy" : "b15ecdc6-6010-48de-ac9c-e282a635a1f0",
        "tags" : [
        ]
      }
    ],
    "commit" : "be169d8868cc77d1958fc0898dbfc526d963c8b6",
    "line" : 188,
    "diffHunk" : "@@ -1,1 +1536,1540 @@  }\n\n  private[sql] def cacheCatalogTable(qtn: QualifiedTableName, catalogTable: CatalogTable): Unit = {\n    catalogTableCache.put(qtn, catalogTable)\n  }"
  },
  {
    "id" : "0d0a2a43-d36a-488b-90ef-373e1aaa8fbd",
    "prId" : 26627,
    "prUrl" : "https://github.com/apache/spark/pull/26627#pullrequestreview-321475405",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4d4649ae-0239-4f10-ad30-77cc618aac35",
        "parentId" : null,
        "authorId" : "b15ecdc6-6010-48de-ac9c-e282a635a1f0",
        "body" : "These two methods `invalidateCachedTable` and `invalidateCachedCatalogTable` are really confusing in their names. I suggest to introduce some rewording to let the names more intuitive.",
        "createdAt" : "2019-11-22T11:04:55Z",
        "updatedAt" : "2019-11-22T13:58:13Z",
        "lastEditedBy" : "b15ecdc6-6010-48de-ac9c-e282a635a1f0",
        "tags" : [
        ]
      }
    ],
    "commit" : "be169d8868cc77d1958fc0898dbfc526d963c8b6",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +228,232 @@    if (cascade && databaseExists(dbName)) {\n      listTables(dbName).foreach { t =>\n        invalidateCachedTable(QualifiedTableName(dbName, t.table))\n        invalidateCachedCatalogTable(QualifiedTableName(dbName, t.table))\n      }"
  },
  {
    "id" : "e12125c8-0832-442a-b8b4-248d3b40269d",
    "prId" : 26627,
    "prUrl" : "https://github.com/apache/spark/pull/26627#pullrequestreview-321475405",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6dc7c583-dc9b-471f-bf75-7571c93f3624",
        "parentId" : null,
        "authorId" : "b15ecdc6-6010-48de-ac9c-e282a635a1f0",
        "body" : "Add comments. Other new methods as well.",
        "createdAt" : "2019-11-22T11:42:42Z",
        "updatedAt" : "2019-11-22T13:58:13Z",
        "lastEditedBy" : "b15ecdc6-6010-48de-ac9c-e282a635a1f0",
        "tags" : [
        ]
      }
    ],
    "commit" : "be169d8868cc77d1958fc0898dbfc526d963c8b6",
    "line" : 166,
    "diffHunk" : "@@ -1,1 +1514,1518 @@  }\n\n  private[sql] def getCachedCatalogTable(qtn: QualifiedTableName): Option[CatalogTable] = {\n    catalogTableCache.getIfPresent(qtn) match {\n      case null => None"
  },
  {
    "id" : "7de33ecc-8024-4528-8a6b-657ecb301ff7",
    "prId" : 26543,
    "prUrl" : "https://github.com/apache/spark/pull/26543#pullrequestreview-317518685",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fd701c18-81ec-4fae-b1b8-319a46e42888",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "What about `clearTempTables()` - I wonder if it should also uncache? it's only used for testing now, but could be used in closeSession() to uncache if it also uncached temp views.",
        "createdAt" : "2019-11-15T08:44:44Z",
        "updatedAt" : "2019-11-19T01:53:39Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "1c51b22d-c876-4c24-8478-716bc828d6ff",
        "parentId" : "fd701c18-81ec-4fae-b1b8-319a46e42888",
        "authorId" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "body" : "IIUC, SessionCatalog (HiveSessionCatalog) should be GC when session closed. Manually `clearTempTables` here also fine.",
        "createdAt" : "2019-11-15T09:11:35Z",
        "updatedAt" : "2019-11-19T01:53:39Z",
        "lastEditedBy" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "tags" : [
        ]
      },
      {
        "id" : "f8e2b825-8af1-4d20-a6f0-7feee2238dd8",
        "parentId" : "fd701c18-81ec-4fae-b1b8-319a46e42888",
        "authorId" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "body" : "> I wonder if it should also uncache? it's only used for testing now.\r\n\r\nI am sorry, what is used for testing?",
        "createdAt" : "2019-11-15T09:18:06Z",
        "updatedAt" : "2019-11-19T01:53:39Z",
        "lastEditedBy" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "tags" : [
        ]
      },
      {
        "id" : "28ba5343-8e22-45f1-97d7-d8d52286f397",
        "parentId" : "fd701c18-81ec-4fae-b1b8-319a46e42888",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "The comment on `clearTempTables()` says it is currently only used for testing. If used in `closedSession()` we could remove that.",
        "createdAt" : "2019-11-15T09:24:16Z",
        "updatedAt" : "2019-11-19T01:53:39Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "674c417d-7fdd-4bf0-83d3-86e01660b476",
        "parentId" : "fd701c18-81ec-4fae-b1b8-319a46e42888",
        "authorId" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "body" : "Ah, got it.",
        "createdAt" : "2019-11-15T10:07:14Z",
        "updatedAt" : "2019-11-19T01:53:39Z",
        "lastEditedBy" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "tags" : [
        ]
      }
    ],
    "commit" : "fa3e0dc2f509b35a69df99d8be7b539fe34359dd",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +577,581 @@  }\n\n  def getTempViewNames(): Seq[String] = synchronized {\n    tempViews.keySet.toSeq\n  }"
  }
]