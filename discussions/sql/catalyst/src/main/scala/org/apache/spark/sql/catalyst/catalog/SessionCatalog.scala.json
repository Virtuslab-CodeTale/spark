[
  {
    "id" : "9a2f6f84-81e0-4b83-8c05-547595e3e37f",
    "prId" : 32768,
    "prUrl" : "https://github.com/apache/spark/pull/32768#pullrequestreview-675897835",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a675c5ed-ef5e-4a60-a1a4-cdfbe4883385",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "My only concern is that now `externalCatalog` cannot handle `ignoreIfNotExists` properly. Previously the handling was delegated.",
        "createdAt" : "2021-06-04T00:52:34Z",
        "updatedAt" : "2021-06-04T00:52:35Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "1fa9411b-3815-4499-b56c-35297f068b9b",
        "parentId" : "a675c5ed-ef5e-4a60-a1a4-cdfbe4883385",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "Not sure I get your ponit. You mean this `SessionCatalog` can not handle `ignoreIfNotExists` correctly ?",
        "createdAt" : "2021-06-04T02:48:30Z",
        "updatedAt" : "2021-06-04T02:48:30Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      },
      {
        "id" : "6d550c08-fc45-4186-be0d-67579c9d98e5",
        "parentId" : "a675c5ed-ef5e-4a60-a1a4-cdfbe4883385",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "I mean, if the DB already exists, `externalCatalog` cannot handle the case anymore because it will throw an exception in the Spark. Previously it was delegated to `externalCatalog` right?",
        "createdAt" : "2021-06-04T03:27:22Z",
        "updatedAt" : "2021-06-04T03:27:22Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "7aee4d26-f8cb-4b1a-ba36-eafa4d096d3d",
        "parentId" : "a675c5ed-ef5e-4a60-a1a4-cdfbe4883385",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "`externalCatalog` can be not only Hive but can be other implementations, and maybe there could be some special handling for these cases (e.g., cleaning up resources)",
        "createdAt" : "2021-06-04T03:28:28Z",
        "updatedAt" : "2021-06-04T03:28:28Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "2e715c7f-c0c2-4895-8d22-88e1d3e4f6a1",
        "parentId" : "a675c5ed-ef5e-4a60-a1a4-cdfbe4883385",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "thanks for the explaination, I see your concern. Seems we also didn't handle this in `drop table` or `drop function`.. \r\n```\r\nrequireDbExists(db)\r\nif (tableExists(TableIdentifier(table, Option(db)))) {\r\n  externalCatalog.dropTable(db, table, ignoreIfNotExists = true, purge = purge)\r\n} else if (!ignoreIfNotExists) {\r\n  throw new NoSuchTableException(db = db, table = table)\r\n}\r\n```\r\n\r\nSo I'm assuming it's OK in `drop database` ? ",
        "createdAt" : "2021-06-04T03:42:34Z",
        "updatedAt" : "2021-06-04T03:42:34Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      },
      {
        "id" : "26ef98c4-3742-4921-997c-128c9d87b51d",
        "parentId" : "a675c5ed-ef5e-4a60-a1a4-cdfbe4883385",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "hm .. okie",
        "createdAt" : "2021-06-04T03:56:13Z",
        "updatedAt" : "2021-06-04T03:56:14Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "7be58a98-e38c-4831-8883-324c1c1f8740",
        "parentId" : "a675c5ed-ef5e-4a60-a1a4-cdfbe4883385",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "As I see it, we'd better remove `requireDbExists` check from the table and function APIs in the `SessionCatalog`?",
        "createdAt" : "2021-06-04T03:56:55Z",
        "updatedAt" : "2021-06-04T03:56:55Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "db9425d09cf339a5cd7eb588feebb84fda5a07fb",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +267,271 @@    }\n    if (!ignoreIfNotExists) {\n      requireDbExists(dbName)\n    }\n    if (cascade && databaseExists(dbName)) {"
  },
  {
    "id" : "35be5a85-8c4b-4b06-b832-005f78d2513f",
    "prId" : 32589,
    "prUrl" : "https://github.com/apache/spark/pull/32589#pullrequestreview-665386518",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0992abb0-47c8-4435-8704-e4736e8a5a2e",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Hm, this will disable external catalogs to handle on `ignoreIfExists=true`. Other external catalogs might have some logics on this call e.g.) sending a create table event.",
        "createdAt" : "2021-05-21T03:40:25Z",
        "updatedAt" : "2021-05-21T03:40:25Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "60b46f90-4821-4e97-8d3a-46b9683560ab",
        "parentId" : "0992abb0-47c8-4435-8704-e4736e8a5a2e",
        "authorId" : "6a8d0007-eb0f-4236-a65a-2174a14ac689",
        "body" : "Oh, My bad, i will close the title.",
        "createdAt" : "2021-05-21T12:00:34Z",
        "updatedAt" : "2021-05-21T12:00:34Z",
        "lastEditedBy" : "6a8d0007-eb0f-4236-a65a-2174a14ac689",
        "tags" : [
        ]
      }
    ],
    "commit" : "678e2b0adbf9071c590502396f9bafdfc082cc5a",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +368,372 @@        throw new TableAlreadyExistsException(db = db, table = table)\n      }\n      return\n    } else if (validateLocation) {\n      validateTableLocation(newTableDefinition)"
  },
  {
    "id" : "ce69db5a-d54b-4ef5-91ec-80e07957fa91",
    "prId" : 31462,
    "prUrl" : "https://github.com/apache/spark/pull/31462#pullrequestreview-583113596",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1a0b8eb5-dfa1-49ac-baff-09be19300563",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Does this add a `View` wrapper which is not added previously?",
        "createdAt" : "2021-02-04T07:19:23Z",
        "updatedAt" : "2021-02-04T07:19:24Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "e2301afe-804f-474b-8481-86d840d0a990",
        "parentId" : "1a0b8eb5-dfa1-49ac-baff-09be19300563",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "Yes. This is added so we can pass a parsed view plan to `CatalogImpl.uncacheView`. I _think_ it also fixes a potential issue in `refreshTable` where `refresh` is called on `TemporaryViewRelation` instead of `View`. ",
        "createdAt" : "2021-02-04T07:53:29Z",
        "updatedAt" : "2021-02-04T07:53:29Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      }
    ],
    "commit" : "27e86350b7d3802db7e8fcd22e3ec732693570c6",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +915,919 @@      tempViews.get(tableName).map(getTempViewPlan)\n    } else if (formatDatabaseName(name.database.get) == globalTempViewManager.database) {\n      globalTempViewManager.get(tableName).map(getTempViewPlan)\n    } else {\n      None"
  },
  {
    "id" : "e46a0b8b-13ee-4349-b6c3-5f00d2420800",
    "prId" : 31273,
    "prUrl" : "https://github.com/apache/spark/pull/31273#pullrequestreview-595166686",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "01d7e7de-52bc-4dbe-a19e-b97ef8e87941",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "let's update `getGlobalTempView` as well.",
        "createdAt" : "2021-02-22T09:44:58Z",
        "updatedAt" : "2021-02-24T04:37:19Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "82d58baa98235f912141b2b40cdcd3bf0bdbe744",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +623,627 @@\n  /**\n   * Generate a [[View]] operator from the temporary view stored.\n   */\n  def getTempView(name: String): Option[LogicalPlan] = synchronized {"
  },
  {
    "id" : "4986ff1f-25ad-4406-ba49-54789f44b4ad",
    "prId" : 31273,
    "prUrl" : "https://github.com/apache/spark/pull/31273#pullrequestreview-596047754",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2d3f4c68-c14b-4707-a65b-0d64c0537872",
        "parentId" : null,
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "If the current PR's approach is fine, we can remove this `case other => other` and change `createTempView` to use `tableDefinition: TemporaryViewRelation` instead of `tableDefinition: LogicalPlan` once we migrate `ALTER VIEW AS` and `CREATE TEMP VIEW USING`.",
        "createdAt" : "2021-02-23T04:11:49Z",
        "updatedAt" : "2021-02-24T04:37:19Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      },
      {
        "id" : "9643c35d-add8-4426-bcfd-b803daa89fda",
        "parentId" : "2d3f4c68-c14b-4707-a65b-0d64c0537872",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "+1",
        "createdAt" : "2021-02-23T07:22:11Z",
        "updatedAt" : "2021-02-24T04:37:19Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "82d58baa98235f912141b2b40cdcd3bf0bdbe744",
    "line" : 49,
    "diffHunk" : "@@ -1,1 +841,845 @@      case TemporaryViewRelation(tableMeta, Some(plan)) =>\n        View(desc = tableMeta, isTempView = true, child = plan)\n      case other => other\n    }\n  }"
  },
  {
    "id" : "55d59271-d279-48b4-a0ea-36d75b8863b3",
    "prId" : 31273,
    "prUrl" : "https://github.com/apache/spark/pull/31273#pullrequestreview-595984931",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "090f83ec-a5c0-41c3-a24c-00caf7b3421f",
        "parentId" : null,
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "If https://github.com/apache/spark/pull/31273/files#r580757641 is done, `case plan` can also be removed.",
        "createdAt" : "2021-02-23T04:14:27Z",
        "updatedAt" : "2021-02-24T04:37:19Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "82d58baa98235f912141b2b40cdcd3bf0bdbe744",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +683,687 @@      tempViews.get(table).map {\n        case TemporaryViewRelation(metadata, _) => metadata\n        case plan =>\n          CatalogTable(\n            identifier = TableIdentifier(table),"
  },
  {
    "id" : "97d9b3bb-a9ea-4334-83a9-e80f656827ba",
    "prId" : 31206,
    "prUrl" : "https://github.com/apache/spark/pull/31206#pullrequestreview-573708031",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ce387918-091e-476d-8677-925f3bf1ade5",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "if the `name` refers to a temp view, we shouldn't call `invalidateCachedTable` here which may accidentally invalid cache for a table with the same name as the temp view.",
        "createdAt" : "2021-01-20T02:27:19Z",
        "updatedAt" : "2021-01-21T09:07:03Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "fe2f40a7-d3f7-4d59-b9eb-767988e3685a",
        "parentId" : "ce387918-091e-476d-8677-925f3bf1ade5",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "This will not cause any correctness issue, right?\r\n\r\nok. Look at `SessionCatalog.refreshTable`:\r\nhttps://github.com/apache/spark/blob/157b72ac9fa0057d5fd6d7ed52a6c4b22ebd1dfc/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/catalog/SessionCatalog.scala#L990-L1006\r\n\r\nif `name` is a temp view, the function could invalidate a record in `tableRelationCache` for a table. but nothing bad happens, `tableRelationCache` will be filled in next time.",
        "createdAt" : "2021-01-20T07:36:56Z",
        "updatedAt" : "2021-01-21T09:07:03Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "5fcbddb8-52e4-49e1-9ce8-50e5ae9a5601",
        "parentId" : "ce387918-091e-476d-8677-925f3bf1ade5",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "it doesn't matter too much but still better to avoid. If it's already the case before, then we don't need to fix it here.",
        "createdAt" : "2021-01-20T08:52:08Z",
        "updatedAt" : "2021-01-21T09:07:03Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "ed4edc78-26e6-4592-9e79-fa890544c9b1",
        "parentId" : "ce387918-091e-476d-8677-925f3bf1ade5",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Seems it's not the case before according to https://github.com/apache/spark/pull/31206/files#r561316669 , @MaxGekk can you fix it?",
        "createdAt" : "2021-01-21T05:33:19Z",
        "updatedAt" : "2021-01-21T09:07:03Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "22487c64-e57a-4baf-8815-797a0e298067",
        "parentId" : "ce387918-091e-476d-8677-925f3bf1ade5",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "ok. I will wrap the invalidation by the check:\r\n```scala\r\n    if (!sessionCatalog.isTemporaryTable(tableIdent)) {\r\n      sessionCatalog.invalidateCachedTable(tableIdent)\r\n    }\r\n```",
        "createdAt" : "2021-01-21T07:19:43Z",
        "updatedAt" : "2021-01-21T09:07:03Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "6714244b-c7fc-498c-8045-5cf753af63e7",
        "parentId" : "ce387918-091e-476d-8677-925f3bf1ade5",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Here is a fix for `SessionCatalog.refreshTable()`: https://github.com/apache/spark/pull/31265",
        "createdAt" : "2021-01-21T20:26:22Z",
        "updatedAt" : "2021-01-21T20:26:23Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "357c69f888ed4f27ea8db3b78d79d123b4dac019",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +175,179 @@    val dbName = formatDatabaseName(name.database.getOrElse(currentDb))\n    val tableName = formatTableName(name.table)\n    invalidateCachedTable(QualifiedTableName(dbName, tableName))\n  }\n"
  },
  {
    "id" : "22eb0475-c731-43dc-b00d-426e7b39a7f7",
    "prId" : 30567,
    "prUrl" : "https://github.com/apache/spark/pull/30567#pullrequestreview-544683942",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "45dd5056-7647-472c-8def-769f3f3b17ab",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "we can remove this line",
        "createdAt" : "2020-12-04T06:20:50Z",
        "updatedAt" : "2020-12-04T06:20:50Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "db9f0baffd424beba5f9efd19620d781cfb2b22b",
    "line" : 44,
    "diffHunk" : "@@ -1,1 +665,669 @@      }.getOrElse(getTableMetadata(name))\n    } else if (formatDatabaseName(name.database.get) == globalTempViewManager.database) {\n      val a = globalTempViewManager.get(table)\n      globalTempViewManager.get(table).map {\n        case TemporaryViewRelation(metadata) => metadata"
  },
  {
    "id" : "cbc67a6d-b7de-45c8-a2eb-995fd3c68d69",
    "prId" : 30567,
    "prUrl" : "https://github.com/apache/spark/pull/30567#pullrequestreview-544692666",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9d3be2a4-d410-41b6-9503-66e857c67ab3",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "this can be private.",
        "createdAt" : "2020-12-04T06:44:14Z",
        "updatedAt" : "2020-12-04T06:44:14Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "db9f0baffd424beba5f9efd19620d781cfb2b22b",
    "line" : 97,
    "diffHunk" : "@@ -1,1 +813,817 @@  }\n\n  def getTempViewPlan(plan: LogicalPlan): LogicalPlan = {\n    plan match {\n      case viewInfo: TemporaryViewRelation =>"
  },
  {
    "id" : "da90bdd0-8d82-435f-928f-03d305ed4b2c",
    "prId" : 30538,
    "prUrl" : "https://github.com/apache/spark/pull/30538#pullrequestreview-542785232",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "61c10378-5b84-43c5-b083-6b014c755368",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ditto",
        "createdAt" : "2020-12-02T12:27:03Z",
        "updatedAt" : "2021-01-08T08:03:31Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "89c15724d5af9b423a14f512c8764bd26eee6c9f",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1179,1183 @@  private def requireNonEmptyValueInPartitionSpec(specs: Seq[TablePartitionSpec]): Unit = {\n    specs.foreach { s =>\n      if (s.values.exists(v => v != null && v.isEmpty)) {\n        val spec = s.map(p => p._1 + \"=\" + p._2).mkString(\"[\", \", \", \"]\")\n        throw QueryCompilationErrors.invalidPartitionSpecError("
  },
  {
    "id" : "9e113c8b-29e9-4380-8e8f-a578acea56f7",
    "prId" : 29502,
    "prUrl" : "https://github.com/apache/spark/pull/29502#pullrequestreview-480835685",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3d50242c-6656-4080-b19f-b104d03ce28d",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can we reuse the code with `registerFunction`?",
        "createdAt" : "2020-09-02T13:46:25Z",
        "updatedAt" : "2020-09-05T12:23:16Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "3cf971b5603b236f0a877d4804245742de94cbd5",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +1371,1375 @@  def requireFunctionClassExists(funcDefinition: CatalogFunction): Unit = {\n    val className = funcDefinition.className\n    if (!Utils.classIsLoadable(className)) {\n      throw new AnalysisException(s\"Can not load class '$className' when registering \" +\n        s\"the function '${funcDefinition.identifier.unquotedString}', please make sure \" +"
  },
  {
    "id" : "954c9f04-f7f4-4f7a-ba4b-e460c1f450d5",
    "prId" : 29502,
    "prUrl" : "https://github.com/apache/spark/pull/29502#pullrequestreview-481607390",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c1f3af0b-c67e-4cb0-89d5-32d59c2ae046",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "one last thing: shall we fill the default database before putting the function identifier in the error message?",
        "createdAt" : "2020-09-03T06:09:58Z",
        "updatedAt" : "2020-09-05T12:23:16Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "1c7d6e0c-3961-4463-b06d-8c80968e556e",
        "parentId" : "c1f3af0b-c67e-4cb0-89d5-32d59c2ae046",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "Not needed. \r\n\r\nThis method is used by both temporary and permanent function. The temporary has no database name and we can't fill the database name. The permanent follows user created.",
        "createdAt" : "2020-09-03T08:22:21Z",
        "updatedAt" : "2020-09-05T12:23:16Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "3cf971b5603b236f0a877d4804245742de94cbd5",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +1373,1377 @@    if (!Utils.classIsLoadable(className)) {\n      throw new AnalysisException(s\"Can not load class '$className' when registering \" +\n        s\"the function '${funcDefinition.identifier.unquotedString}', please make sure \" +\n        s\"it is on the classpath\")\n    }"
  },
  {
    "id" : "8e6d3ac9-4532-43b7-be21-3ffe15c82181",
    "prId" : 28852,
    "prUrl" : "https://github.com/apache/spark/pull/28852#pullrequestreview-439324427",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e7d6d5b1-7a68-4d36-a9f2-e6c5770db6f8",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "`cacheTTL=0` means that TTL disabled, too?",
        "createdAt" : "2020-06-25T22:52:30Z",
        "updatedAt" : "2020-07-17T04:16:07Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "7d9944d5-cf9a-4851-9275-4a8d686a1655",
        "parentId" : "e7d6d5b1-7a68-4d36-a9f2-e6c5770db6f8",
        "authorId" : "2e177144-1a17-4ac6-8d65-915343e9f2ea",
        "body" : "Yes, I think it makes sense: 0 seconds == no TTL",
        "createdAt" : "2020-06-25T23:05:03Z",
        "updatedAt" : "2020-07-17T04:16:07Z",
        "lastEditedBy" : "2e177144-1a17-4ac6-8d65-915343e9f2ea",
        "tags" : [
        ]
      },
      {
        "id" : "b64d0cc6-af26-47ee-8c8a-0dfc6a487243",
        "parentId" : "e7d6d5b1-7a68-4d36-a9f2-e6c5770db6f8",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Could you update the description in the config?",
        "createdAt" : "2020-06-25T23:09:23Z",
        "updatedAt" : "2020-07-17T04:16:07Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "c0bd381f-56c7-43e0-a028-e7ee5b44e70e",
        "parentId" : "e7d6d5b1-7a68-4d36-a9f2-e6c5770db6f8",
        "authorId" : "2e177144-1a17-4ac6-8d65-915343e9f2ea",
        "body" : "Updated in https://github.com/apache/spark/pull/28852/commits/18feeb02b11407b9eea1457139a91cb40ddc40cf, now it says: ` This configuration only has an effect when this value having a positive value (> 0)`, I think it's good enough.",
        "createdAt" : "2020-06-29T16:45:58Z",
        "updatedAt" : "2020-07-17T04:16:07Z",
        "lastEditedBy" : "2e177144-1a17-4ac6-8d65-915343e9f2ea",
        "tags" : [
        ]
      }
    ],
    "commit" : "3e761dcd790b9c30e5cee7bffe916dfc2c82b7a5",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +142,146 @@      .maximumSize(cacheSize)\n\n    if (cacheTTL > 0) {\n      builder = builder.expireAfterWrite(cacheTTL, TimeUnit.SECONDS)\n    }"
  },
  {
    "id" : "1dd20f4a-fb4d-48de-809f-cd4d9b7950d0",
    "prId" : 28852,
    "prUrl" : "https://github.com/apache/spark/pull/28852#pullrequestreview-450389651",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1aa488da-6228-4a20-bb38-79a991f02cc2",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Not related to this PR. I'm wondering how useful is this cache. The file listing is cached in another place(`FileStatusCache`), and seems this relation cache doesn't give many benefits. cc @viirya @maropu  ",
        "createdAt" : "2020-07-16T14:26:53Z",
        "updatedAt" : "2020-07-17T04:16:07Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "4fd533b6-be05-4817-911d-958f8d531ed8",
        "parentId" : "1aa488da-6228-4a20-bb38-79a991f02cc2",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ah, I see. As you suggested, the most painful part (listed files) has already been cached there. But, it seems some datasources still has somewhat processing costs when resolving a relation (e.g., JDBC datasources send a query to an external database for schema resolution), so I think we need to carefully check performance impacts for removing this cache.\r\n\r\nhttps://github.com/apache/spark/blob/fb519251237892ad474592d19bf4f193e2a9e2b6/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/DataSourceStrategy.scala#L256",
        "createdAt" : "2020-07-17T00:33:22Z",
        "updatedAt" : "2020-07-17T04:16:07Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "a05d4237-56d1-462a-80d4-45c76d125008",
        "parentId" : "1aa488da-6228-4a20-bb38-79a991f02cc2",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "For external data sources, it's common that data are changed outside of Spark. I think it's more important to make sure we get the latest data in a new query. Maybe we should disable this relation cache by default.",
        "createdAt" : "2020-07-17T04:41:56Z",
        "updatedAt" : "2020-07-17T04:41:57Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "3f7fe21d-dac4-4b93-8a5f-87b3e106d578",
        "parentId" : "1aa488da-6228-4a20-bb38-79a991f02cc2",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Hmm, I think this cache is still useful for avoiding inferring schema again. This is also an expensive operation.",
        "createdAt" : "2020-07-17T05:00:19Z",
        "updatedAt" : "2020-07-17T05:00:19Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "214206cc-2a32-4476-aa81-99879cc1ec56",
        "parentId" : "1aa488da-6228-4a20-bb38-79a991f02cc2",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ah that's a good point. We should probably investigate how to design the data source API so that sources don't need to infer schema can skip this cache. It's hard to use the JDBC data source as we need to run REFRESH TABLE (or wait for TTL after this PR) once the table is changed outside of spark (which is common to JDBC source).",
        "createdAt" : "2020-07-17T05:54:04Z",
        "updatedAt" : "2020-07-17T05:54:05Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "3e761dcd790b9c30e5cee7bffe916dfc2c82b7a5",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +135,139 @@  }\n\n  private val tableRelationCache: Cache[QualifiedTableName, LogicalPlan] = {\n    val cacheSize = conf.tableRelationCacheSize\n    val cacheTTL = conf.metadataCacheTTL"
  },
  {
    "id" : "94953b2e-0164-4a23-9fbd-d3928b0b40f3",
    "prId" : 28527,
    "prUrl" : "https://github.com/apache/spark/pull/28527#pullrequestreview-413242855",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e80c79d7-4669-475b-9a43-141ee372cd7f",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "We need to update the location uri here?",
        "createdAt" : "2020-05-17T23:37:13Z",
        "updatedAt" : "2020-07-31T09:27:43Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "ec43d1ac-bb97-4dcc-8419-048922c1082f",
        "parentId" : "e80c79d7-4669-475b-9a43-141ee372cd7f",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "We have `ALTER (DATABASE|SCHEMA) database_name SET LOCATION path` syntax that works for hive 3.x",
        "createdAt" : "2020-05-18T02:23:44Z",
        "updatedAt" : "2020-07-31T09:27:43Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "8dfe0518-537e-4747-8fd3-6159a39241d4",
        "parentId" : "e80c79d7-4669-475b-9a43-141ee372cd7f",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ah, I see.",
        "createdAt" : "2020-05-18T02:51:29Z",
        "updatedAt" : "2020-07-31T09:27:43Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "b471a0e868c54f82178cacc587a9586a26bd6175",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +251,255 @@    requireDbExists(dbName)\n    externalCatalog.alterDatabase(dbDefinition.copy(\n      name = dbName, locationUri = makeQualifiedDBPath(dbDefinition.locationUri)))\n  }\n"
  },
  {
    "id" : "860bb530-4001-4350-91d8-3a9c86063999",
    "prId" : 28527,
    "prUrl" : "https://github.com/apache/spark/pull/28527#pullrequestreview-413643431",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "57bffbb9-f945-4ade-84fd-f2db1c89c5cb",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "what if the database has a custom location?",
        "createdAt" : "2020-05-18T14:07:59Z",
        "updatedAt" : "2020-07-31T09:27:43Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "8b01e5f2-2049-4cfa-9b80-b5fe34ecb0f5",
        "parentId" : "57bffbb9-f945-4ade-84fd-f2db1c89c5cb",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "No matter if it's custom or managed, we should inherit that location for tables as same as we do for partitions\r\nhttps://github.com/apache/spark/blob/a28ed86a387b286745b30cd4d90b3d558205a5a7/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/catalog/SessionCatalog.scala#L1161-L1164",
        "createdAt" : "2020-05-18T14:22:49Z",
        "updatedAt" : "2020-07-31T09:27:43Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "b471a0e868c54f82178cacc587a9586a26bd6175",
    "line" : 61,
    "diffHunk" : "@@ -1,1 +364,368 @@    } else {\n      val dbName = formatDatabaseName(database)\n      val dbLocation = makeQualifiedDBPath(getDatabaseMetadata(dbName).locationUri)\n      new Path(new Path(dbLocation), CatalogUtils.URIToString(locationUri)).toUri\n    }"
  },
  {
    "id" : "c29ba638-5d92-4197-ada5-bda0abb8becb",
    "prId" : 28527,
    "prUrl" : "https://github.com/apache/spark/pull/28527#pullrequestreview-459037924",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ea2ff342-a8d0-4d89-b81c-649adfb58cf2",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "do we still need to call `makeQualifiedPath`? I think the `fullPath` is already qualified here.",
        "createdAt" : "2020-07-31T08:33:40Z",
        "updatedAt" : "2020-07-31T09:27:43Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "850d1ed6-bd09-432a-989d-288facb97b2d",
        "parentId" : "ea2ff342-a8d0-4d89-b81c-649adfb58cf2",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "the warehousePath can accept a relative path, the `fullPath` might not be qualified yet",
        "createdAt" : "2020-07-31T09:11:52Z",
        "updatedAt" : "2020-07-31T09:27:43Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "7afbd8ba-0a25-4d3e-943d-fdd3bbdf88e0",
        "parentId" : "ea2ff342-a8d0-4d89-b81c-649adfb58cf2",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "shall we make sure it's not relative? I think it's confusing if users set a relative path to the warehouse path.\r\n\r\nIt's not related to this PR though.",
        "createdAt" : "2020-07-31T09:18:54Z",
        "updatedAt" : "2020-07-31T09:27:43Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "440fb34b-93a2-4b37-8572-e58dc47883cf",
        "parentId" : "ea2ff342-a8d0-4d89-b81c-649adfb58cf2",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "Now it is relative to $PWD or Hadoop user home directory. I think such a change would bring serious behavior change, I'm not sure whether worth to do it or not.",
        "createdAt" : "2020-07-31T09:26:40Z",
        "updatedAt" : "2020-07-31T09:27:43Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "b471a0e868c54f82178cacc587a9586a26bd6175",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +230,234 @@    } else {\n      val fullPath = new Path(conf.warehousePath, CatalogUtils.URIToString(locationUri))\n      makeQualifiedPath(fullPath.toUri)\n    }\n  }"
  },
  {
    "id" : "db760d62-ac79-42da-b966-730e05bd073b",
    "prId" : 28527,
    "prUrl" : "https://github.com/apache/spark/pull/28527#pullrequestreview-459996329",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "60f8e137-e5ee-4482-bcce-c75785f2fca9",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I'm a bit concerned about it as it adds an extra database lookup. Is it better to push this work to the underlying external catalog?",
        "createdAt" : "2020-08-03T05:00:56Z",
        "updatedAt" : "2020-08-03T05:00:56Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "05936644-d0e2-411c-9bf2-bc2a96411e1f",
        "parentId" : "60f8e137-e5ee-4482-bcce-c75785f2fca9",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "Do you mean that we are calling `requireDbExists(dbName)` repeatedly?",
        "createdAt" : "2020-08-03T09:44:51Z",
        "updatedAt" : "2020-08-03T09:44:51Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "f0afe944-1a4c-4719-b94e-95db6ad8e4d1",
        "parentId" : "60f8e137-e5ee-4482-bcce-c75785f2fca9",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Ideally `createTable` should only do one RPC to the hive metastore. `requireDbExists` is one problem but we can simply remove it. However, the new database lookup seems can't be easily removed.",
        "createdAt" : "2020-08-03T10:03:28Z",
        "updatedAt" : "2020-08-03T10:03:28Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "d704b906-bf7e-470b-bc76-bbb55e6f40e2",
        "parentId" : "60f8e137-e5ee-4482-bcce-c75785f2fca9",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "> However, the new database lookup seems can't be easily removed.\r\n\r\nYes, it seem make no difference even we put this into external catalogs, we have to call the `getDatabase` API in order to get the actual path of the database for this particular case.",
        "createdAt" : "2020-08-03T10:17:08Z",
        "updatedAt" : "2020-08-03T10:17:08Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "8084947d-63bd-469e-a998-030b16f62a1e",
        "parentId" : "60f8e137-e5ee-4482-bcce-c75785f2fca9",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "what happens if we don't qualify the path here and leave it to hive metastore? Will it still be a relative path in the hive metastore?",
        "createdAt" : "2020-08-03T12:26:52Z",
        "updatedAt" : "2020-08-03T12:26:52Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "3576f486-8173-4928-bcc8-31e24668f963",
        "parentId" : "60f8e137-e5ee-4482-bcce-c75785f2fca9",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "FYI, https://github.com/apache/spark/pull/17254",
        "createdAt" : "2020-08-03T12:34:25Z",
        "updatedAt" : "2020-08-03T12:34:25Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "0f1d0163-3fd2-4388-b54f-aa52d51b9943",
        "parentId" : "60f8e137-e5ee-4482-bcce-c75785f2fca9",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ok we did the same thing for partition. LGTM then",
        "createdAt" : "2020-08-03T12:46:45Z",
        "updatedAt" : "2020-08-03T12:46:45Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "b471a0e868c54f82178cacc587a9586a26bd6175",
    "line" : 61,
    "diffHunk" : "@@ -1,1 +364,368 @@    } else {\n      val dbName = formatDatabaseName(database)\n      val dbLocation = makeQualifiedDBPath(getDatabaseMetadata(dbName).locationUri)\n      new Path(new Path(dbLocation), CatalogUtils.URIToString(locationUri)).toUri\n    }"
  }
]