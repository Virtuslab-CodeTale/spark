[
  {
    "id" : "17b9f5b5-e3d7-4e2f-a014-0461722962df",
    "prId" : 32060,
    "prUrl" : "https://github.com/apache/spark/pull/32060#pullrequestreview-629733741",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d98a473a-0f62-4dc8-9aa3-56379dec8176",
        "parentId" : null,
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "nit: This is the same as \r\n```\r\nnodePatterns.foreach {...}\r\n```",
        "createdAt" : "2021-04-07T06:23:21Z",
        "updatedAt" : "2021-04-12T00:32:43Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "bc31dd4a-451f-4a23-8567-f87b8876792a",
        "parentId" : "d98a473a-0f62-4dc8-9aa3-56379dec8176",
        "authorId" : "8b518862-583d-43a2-a10e-b33ef1b6d824",
        "body" : "Lazily constructing `treePatternBits` is a frequent operation and thus I avoided for-loops as the style guide suggests:\r\nhttps://github.com/databricks/scala-style-guide#traversal-and-zipwithindex",
        "createdAt" : "2021-04-07T07:47:15Z",
        "updatedAt" : "2021-04-12T00:32:43Z",
        "lastEditedBy" : "8b518862-583d-43a2-a10e-b33ef1b6d824",
        "tags" : [
        ]
      },
      {
        "id" : "766e3340-a422-4c99-ad6a-bd9ac9983c7f",
        "parentId" : "d98a473a-0f62-4dc8-9aa3-56379dec8176",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "But if you see the defination of `foreach`, you will see the same implementation as you do here.",
        "createdAt" : "2021-04-07T07:51:28Z",
        "updatedAt" : "2021-04-12T00:32:43Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "d8c79c0b-4ebd-4565-9f2a-3a108d36f490",
        "parentId" : "d98a473a-0f62-4dc8-9aa3-56379dec8176",
        "authorId" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "body" : "foreach is more expensive... it calls a function. This is fine.",
        "createdAt" : "2021-04-07T08:01:25Z",
        "updatedAt" : "2021-04-12T00:32:43Z",
        "lastEditedBy" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "tags" : [
        ]
      },
      {
        "id" : "96b8a108-ecb5-4e91-95a8-aebaf4f7d077",
        "parentId" : "d98a473a-0f62-4dc8-9aa3-56379dec8176",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "I see. Thanks for the explanation @sigmod @hvanhovell ",
        "createdAt" : "2021-04-07T08:29:39Z",
        "updatedAt" : "2021-04-12T00:32:44Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "718a92a743e731a698473b9170ace55187755b55",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +58,62 @@    val bits: BitSet = new BitSet(TreePattern.maxId)\n    // Propagate node pattern bits\n    val nodeTypeIterator = nodePatterns.iterator\n    while (nodeTypeIterator.hasNext) {\n      bits.set(nodeTypeIterator.next().id)"
  },
  {
    "id" : "7bac7c53-fe40-41c9-968c-6b311f5a47b7",
    "prId" : 32060,
    "prUrl" : "https://github.com/apache/spark/pull/32060#pullrequestreview-629692459",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "26f183c5-c508-40b0-99a5-d469c204cf60",
        "parentId" : null,
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "ditto",
        "createdAt" : "2021-04-07T06:23:32Z",
        "updatedAt" : "2021-04-12T00:32:43Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "1fd2cf22-1996-44f4-8b8d-a416047516c1",
        "parentId" : "26f183c5-c508-40b0-99a5-d469c204cf60",
        "authorId" : "8b518862-583d-43a2-a10e-b33ef1b6d824",
        "body" : "The same reason as above.",
        "createdAt" : "2021-04-07T07:47:44Z",
        "updatedAt" : "2021-04-12T00:32:43Z",
        "lastEditedBy" : "8b518862-583d-43a2-a10e-b33ef1b6d824",
        "tags" : [
        ]
      }
    ],
    "commit" : "718a92a743e731a698473b9170ace55187755b55",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +63,67 @@    }\n    // Propagate children's pattern bits\n    val childIterator = children.iterator\n    while (childIterator.hasNext) {\n      bits.union(childIterator.next().treePatternBits)"
  },
  {
    "id" : "ee903902-fe03-48a2-814f-cbb2d738afa1",
    "prId" : 32060,
    "prUrl" : "https://github.com/apache/spark/pull/32060#pullrequestreview-629692516",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "51c17cf0-c43d-4c34-8207-88116d571ff6",
        "parentId" : null,
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "ditto",
        "createdAt" : "2021-04-07T06:23:37Z",
        "updatedAt" : "2021-04-12T00:32:43Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "89484546-b573-4b1f-b4d0-5afa2b9c2a72",
        "parentId" : "51c17cf0-c43d-4c34-8207-88116d571ff6",
        "authorId" : "8b518862-583d-43a2-a10e-b33ef1b6d824",
        "body" : "The same reason as above.",
        "createdAt" : "2021-04-07T07:47:47Z",
        "updatedAt" : "2021-04-12T00:32:43Z",
        "lastEditedBy" : "8b518862-583d-43a2-a10e-b33ef1b6d824",
        "tags" : [
        ]
      }
    ],
    "commit" : "718a92a743e731a698473b9170ace55187755b55",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +68,72 @@    }\n    // Propagate expressions' pattern bits\n    val exprIterator = expressions.iterator\n    while (exprIterator.hasNext) {\n      bits.union(exprIterator.next.treePatternBits)"
  },
  {
    "id" : "9c875c26-1b86-4a88-8fc1-bea264fb0c01",
    "prId" : 30173,
    "prUrl" : "https://github.com/apache/spark/pull/30173#pullrequestreview-519039559",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9ed20241-b316-4484-a9a1-7ad365e0ca0d",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "nit: Is this needed to be parameterized? Seems we only need check unresolved logical plan.",
        "createdAt" : "2020-10-28T17:00:34Z",
        "updatedAt" : "2020-10-28T17:00:35Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "14f6be23-fd83-4ebd-add6-8c8dce3a90ee",
        "parentId" : "9ed20241-b316-4484-a9a1-7ad365e0ca0d",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Do you mean something like\r\n```\r\nval canGetOutput = plan match {\r\n  case l: LogicalPlan => l.resolved\r\n  case _ => true\r\n}\r\n```",
        "createdAt" : "2020-10-28T17:55:49Z",
        "updatedAt" : "2020-10-28T17:56:19Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "57f48015-3264-4510-b4dc-7244b997aa0b",
        "parentId" : "9ed20241-b316-4484-a9a1-7ad365e0ca0d",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "One advantage of the current way is we can skip the check for optimizer rules (use the default value true).",
        "createdAt" : "2020-10-28T17:57:20Z",
        "updatedAt" : "2020-10-28T17:57:20Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "e49c2cc6-0423-4471-a7ba-3ce78aae0382",
        "parentId" : "9ed20241-b316-4484-a9a1-7ad365e0ca0d",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Oh, I see. Make sense.",
        "createdAt" : "2020-10-28T20:04:25Z",
        "updatedAt" : "2020-10-28T20:04:25Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "4f94664ab2736475af1ca74b2707496d6bc005e8",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +183,187 @@   * @param canGetOutput a boolean condition to indicate if we can get the output of a plan node\n   *                     to prune the attributes mapping to be propagated. The default value is true\n   *                     as only unresolved logical plan can't get output.\n   */\n  def transformUpWithNewOutput("
  },
  {
    "id" : "01897b19-514b-471f-98aa-6f2b442901ad",
    "prId" : 29643,
    "prUrl" : "https://github.com/apache/spark/pull/29643#pullrequestreview-483768947",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1482f761-bb4f-47a9-90b4-c24cb376dd31",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Just a question. Why we need to return the attribute mapping from old to new? Can we just detect if the output of new plan is different to old plan, then create the mapping inside `transformUpWithNewOutput`?",
        "createdAt" : "2020-09-07T17:06:55Z",
        "updatedAt" : "2020-09-07T17:06:55Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "75a9e17a-b5fe-4810-8352-ced9bf60a3e2",
        "parentId" : "1482f761-bb4f-47a9-90b4-c24cb376dd31",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Because that's too hard. For example, `WidenSetOperationTypes` returns attribute mapping according to the replaced children, not itself, because itself may not be resolved yet. While for self-join dedup, we return attribute mapping according to the current node.",
        "createdAt" : "2020-09-08T03:13:03Z",
        "updatedAt" : "2020-09-08T03:13:04Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "0857791bc310f54dd8ed1f4bcf5a5b274ffa33c6",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +176,180 @@   * the parent nodes accordingly.\n   *\n   * @param rule the function to transform plan nodes, and return new nodes with attributes mapping\n   *             from old attributes to new attributes. The attribute mapping will be used to\n   *             rewrite attribute references in the parent nodes."
  },
  {
    "id" : "6be0b792-f77c-478d-ba21-308b6f29a670",
    "prId" : 28050,
    "prUrl" : "https://github.com/apache/spark/pull/28050#pullrequestreview-382795643",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0aedee1c-dcc7-4f19-9f9d-042fb9afbfee",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "well written. nit: How about adding the example here of the description, `QueryPlan -> Expression (PlanExpression) -> QueryPlan`?",
        "createdAt" : "2020-03-27T12:00:56Z",
        "updatedAt" : "2020-03-27T12:34:17Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "b340493e5a4257b58b2d4ce694ce86c72ccf2e2b",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +32,36 @@ *   QueryPlan -> Expression (subquery) -> QueryPlan\n * The tree traverse APIs like `transform`, `foreach`, `collect`, etc. that are\n * inherited from `TreeNode`, do not traverse into query plans inside subqueries.\n */\nabstract class QueryPlan[PlanType <: QueryPlan[PlanType]] extends TreeNode[PlanType] {"
  },
  {
    "id" : "9aa6ee26-67e3-4c07-8ef5-45c7bf00fa38",
    "prId" : 28050,
    "prUrl" : "https://github.com/apache/spark/pull/28050#pullrequestreview-382875236",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "327ba783-0de7-4870-9d71-cddcff7a8a85",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "@cloud-fan, does this mean all the APIs under `QueryPlan` and its downstream can go through query plans inside subqueries? It sounds like it.",
        "createdAt" : "2020-03-27T13:37:41Z",
        "updatedAt" : "2020-03-27T13:37:42Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "10aa5559-45cb-4c4b-9e72-c4e8d55260cf",
        "parentId" : "327ba783-0de7-4870-9d71-cddcff7a8a85",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Okay, I just read the doc on each method you added. Should we mention what can go through and what can't?",
        "createdAt" : "2020-03-27T13:40:39Z",
        "updatedAt" : "2020-03-27T13:40:40Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "54799e50-12dd-4bb4-b0aa-26bc7b73ecf3",
        "parentId" : "327ba783-0de7-4870-9d71-cddcff7a8a85",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Only the `collectInPlanAndSubqueries` can go through subqueries, and it's documented.",
        "createdAt" : "2020-03-27T13:51:08Z",
        "updatedAt" : "2020-03-27T13:51:09Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "9af2043c-31e4-4b3d-b86c-580ee494382c",
        "parentId" : "327ba783-0de7-4870-9d71-cddcff7a8a85",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "`transformExpressions` is not a traverse API as it only touches the current node.",
        "createdAt" : "2020-03-27T13:51:50Z",
        "updatedAt" : "2020-03-27T13:51:50Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "b340493e5a4257b58b2d4ce694ce86c72ccf2e2b",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +31,35 @@ * Note that, the query plan is a mutually recursive structure:\n *   QueryPlan -> Expression (subquery) -> QueryPlan\n * The tree traverse APIs like `transform`, `foreach`, `collect`, etc. that are\n * inherited from `TreeNode`, do not traverse into query plans inside subqueries.\n */"
  },
  {
    "id" : "f2a248f5-656a-4af1-8aa5-c6c1f51f969c",
    "prId" : 24759,
    "prUrl" : "https://github.com/apache/spark/pull/24759#pullrequestreview-278131210",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0f787dec-08ac-4b56-a838-105be6086b83",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "shall we call `ExplainUtils.getOpId` hereï¼Ÿ",
        "createdAt" : "2019-08-21T13:28:45Z",
        "updatedAt" : "2019-08-26T07:56:18Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "46b7954d-f2b5-49b1-9f60-8f50abcb640d",
        "parentId" : "0f787dec-08ac-4b56-a838-105be6086b83",
        "authorId" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "body" : "@cloud-fan Actually i had tried.. but ExplainUtils is in execution package :-). I couldn't move it to catalyst as it refers to physical operator classes.",
        "createdAt" : "2019-08-21T23:55:22Z",
        "updatedAt" : "2019-08-26T07:56:18Z",
        "lastEditedBy" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "tags" : [
        ]
      }
    ],
    "commit" : "f401175f7bd0e94db1722653734b92c9db57a779",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +182,186 @@\n  override def simpleStringWithNodeId(): String = {\n    val operatorId = getTagValue(QueryPlan.OP_ID_TAG).map(id => s\"$id\").getOrElse(\"unknown\")\n    s\"$nodeName ($operatorId)\".trim\n  }"
  }
]