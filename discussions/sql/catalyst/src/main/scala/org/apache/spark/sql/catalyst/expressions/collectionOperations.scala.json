[
  {
    "id" : "9b3fe2f4-08ed-4516-8523-2176bcab95aa",
    "prId" : 33106,
    "prUrl" : "https://github.com/apache/spark/pull/33106#pullrequestreview-693604377",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4341e28f-a3c5-46c6-a428-9aa9e6bfa5c4",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "shall we follow `CreateStruct.apply` and use `NamePlaceholder`?",
        "createdAt" : "2021-06-28T06:47:03Z",
        "updatedAt" : "2021-06-28T06:47:03Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "ce5d0b163b2c5cefbcdeda57d812125e811a4e70",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +188,192 @@    this(\n      children,\n      children.zipWithIndex.map {\n        case (u: UnresolvedAttribute, _) => Literal(u.nameParts.last)\n        case (e: NamedExpression, _) if e.resolved => Literal(e.name)"
  },
  {
    "id" : "d5a3e9ae-843c-47a0-99af-8f4857347580",
    "prId" : 32311,
    "prUrl" : "https://github.com/apache/spark/pull/32311#pullrequestreview-644114142",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "20243a75-df6e-48b4-ac19-f16009981c31",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "I am not sure it is good idea to use `timestampAddInterval()` in `InternalSequenceBase.eval` for adding months to dates. I guess `DateTimeUtils.dateAddMonths()` and `DateTimeUtils.timestampAddInterval` can return different result, especially taking into account that `dateAddMonths()` **does not depend** on the current time zone.",
        "createdAt" : "2021-04-23T15:31:08Z",
        "updatedAt" : "2021-04-26T03:28:44Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "8a91c80f-2e36-4597-99e1-dd8c33d45e53",
        "parentId" : "20243a75-df6e-48b4-ac19-f16009981c31",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "In fact, the current implement uses `DateTimeUtils.timestampAddInterval` and it's behavior seems good.",
        "createdAt" : "2021-04-25T09:09:26Z",
        "updatedAt" : "2021-04-26T03:28:44Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      },
      {
        "id" : "d54b0671-497b-4b6b-a6b0-3b18d0a281ff",
        "parentId" : "20243a75-df6e-48b4-ac19-f16009981c31",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "ok. Let's use `timestampAddInterval` since we don't have an example that could demonstrate any issues caused by `timestampAddInterval()`.",
        "createdAt" : "2021-04-25T09:11:51Z",
        "updatedAt" : "2021-04-26T03:28:44Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "47853e8610a0bf37d377b552cdf6739b3cbeee36",
    "line" : 145,
    "diffHunk" : "@@ -1,1 +2755,2759 @@  private class PeriodSequenceImpl[T: ClassTag]\n      (dt: IntegralType, scale: Long, fromLong: Long => T, zoneId: ZoneId)\n      (implicit num: Integral[T]) extends InternalSequenceBase(dt, scale, fromLong, zoneId) {\n\n    override val defaultStep: DefaultStep = new DefaultStep("
  },
  {
    "id" : "4e8d4d9c-44bc-4d34-8a3f-cf4a6a26d25b",
    "prId" : 32176,
    "prUrl" : "https://github.com/apache/spark/pull/32176#pullrequestreview-636675225",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "792ff0f7-f489-4e4f-829a-6825288210eb",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Created JIRA SPARK-35088 for ANSI intervals",
        "createdAt" : "2021-04-15T13:18:15Z",
        "updatedAt" : "2021-04-16T11:24:15Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "7668405ebd902cea698b76c373d0c06b1e759426",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +2505,2509 @@       [5,4,3,2,1]\n      > SET spark.sql.legacy.interval.enabled=true;\n       spark.sql.legacy.interval.enabled\ttrue\n      > SELECT _FUNC_(to_date('2018-01-01'), to_date('2018-03-01'), interval 1 month);\n       [2018-01-01,2018-02-01,2018-03-01]"
  }
]