[
  {
    "id" : "454ac5d8-a09e-4146-97b2-31e8f99932f2",
    "prId" : 32301,
    "prUrl" : "https://github.com/apache/spark/pull/32301#pullrequestreview-643695923",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ccc0f886-44e6-4e74-9b3a-613e0eace721",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I think a good first step is to improve the classdoc to explain in detail what we are doing here, with examples.\r\n\r\nA good example is `DecorrelateInnerQuery`.",
        "createdAt" : "2021-04-23T15:09:56Z",
        "updatedAt" : "2021-04-29T04:38:39Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "e0ed6438-346f-48ff-b194-29e99eaf49f1",
        "parentId" : "ccc0f886-44e6-4e74-9b3a-613e0eace721",
        "authorId" : "ada71464-b8c9-4d7b-9020-d49c27251fdb",
        "body" : "I wasn't sure how much to add to the classdoc, but I added some more examples.",
        "createdAt" : "2021-04-23T22:16:02Z",
        "updatedAt" : "2021-04-29T04:38:39Z",
        "lastEditedBy" : "ada71464-b8c9-4d7b-9020-d49c27251fdb",
        "tags" : [
        ]
      }
    ],
    "commit" : "8a29e943447808391c17f860598e3f11ae41d54d",
    "line" : 70,
    "diffHunk" : "@@ -1,1 +80,84 @@ * The schema of the datasource relation will be pruned in the [[SchemaPruning]] optimizer rule.\n */\nobject NestedColumnAliasing {\n\n  def unapply(plan: LogicalPlan): Option[LogicalPlan] = plan match {"
  },
  {
    "id" : "aa0a2d2e-daa4-4868-befe-9e046eac0dfa",
    "prId" : 32301,
    "prUrl" : "https://github.com/apache/spark/pull/32301#pullrequestreview-644464727",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7d092651-d369-4238-9bd1-f18fdeeaa97b",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "we can add more comments:\r\n```\r\n..., because `a.b` means all the inner fields of `b` are needed, and we can't prune `a.b.c`.\r\n```",
        "createdAt" : "2021-04-26T09:37:34Z",
        "updatedAt" : "2021-04-29T04:38:39Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "8a29e943447808391c17f860598e3f11ae41d54d",
    "line" : 290,
    "diffHunk" : "@@ -1,1 +257,261 @@      .flatMap { case (attr: Attribute, nestedFields: Seq[ExtractValue]) =>\n        // Remove redundant [[ExtractValue]]s if they share the same parent nest field.\n        // For example, when `a.b` and `a.b.c` are in project list, we only need to alias `a.b`.\n        // Because `a.b` requires all of the inner fields of `b`, we cannot prune `a.b.c`.\n        val dedupNestedFields = nestedFields.filter {"
  },
  {
    "id" : "ecb816b6-e1eb-478f-af40-931b9ce76109",
    "prId" : 32301,
    "prUrl" : "https://github.com/apache/spark/pull/32301#pullrequestreview-661357736",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "26ac24e5-f51c-49c6-9059-591064df7004",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "we will call `.map(_.canonicalized).distinct` later. Do we need this `.distinct` here?",
        "createdAt" : "2021-04-26T09:42:57Z",
        "updatedAt" : "2021-04-29T04:38:39Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "9f371186-d466-46b5-b467-0cf1535fe0aa",
        "parentId" : "26ac24e5-f51c-49c6-9059-591064df7004",
        "authorId" : "ada71464-b8c9-4d7b-9020-d49c27251fdb",
        "body" : "We use `.map(_.canonicalized).distinct` only for counting the number of nested fields. I believe we still need `.distinct` here to deduplicate the nested fields.",
        "createdAt" : "2021-04-27T21:13:58Z",
        "updatedAt" : "2021-04-29T04:38:39Z",
        "lastEditedBy" : "ada71464-b8c9-4d7b-9020-d49c27251fdb",
        "tags" : [
        ]
      },
      {
        "id" : "ac551030-eb61-4672-a97a-5a480862f728",
        "parentId" : "26ac24e5-f51c-49c6-9059-591064df7004",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "why don't we do `.map(_.canonicalized).distinct` here?",
        "createdAt" : "2021-04-29T04:37:17Z",
        "updatedAt" : "2021-04-29T04:38:39Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "4de75402-1dc7-46b5-9b23-982f5f47e414",
        "parentId" : "26ac24e5-f51c-49c6-9059-591064df7004",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "We can also update the lookup side\r\n`nestedFieldToAlias.contains(f)` -> `nestedFieldToAlias.contains(f.canonicalized)`",
        "createdAt" : "2021-04-29T04:44:55Z",
        "updatedAt" : "2021-04-29T04:44:56Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "264a1833-0890-466b-a377-a05dc2712bae",
        "parentId" : "26ac24e5-f51c-49c6-9059-591064df7004",
        "authorId" : "ada71464-b8c9-4d7b-9020-d49c27251fdb",
        "body" : "When I tried this, the tests failed - turns out that canonicalization strips key information for analysis, such as the name of the AttributeReference (see [ignoreNameTypes](https://github.com/apache/spark/blob/2a335f2d7d1265cb9abd2e727f60d8eb2dfa356b/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/Canonicalize.scala#L44)).",
        "createdAt" : "2021-05-17T19:52:11Z",
        "updatedAt" : "2021-05-17T19:52:11Z",
        "lastEditedBy" : "ada71464-b8c9-4d7b-9020-d49c27251fdb",
        "tags" : [
        ]
      }
    ],
    "commit" : "8a29e943447808391c17f860598e3f11ae41d54d",
    "line" : 309,
    "diffHunk" : "@@ -1,1 +266,270 @@            nestedFields.forall(f => child.find(_.semanticEquals(f)).isEmpty)\n          case _ => true\n        }.distinct\n\n        // If all nested fields of `attr` are used, we don't need to introduce new aliases."
  },
  {
    "id" : "0d1858d5-064d-47bc-8efc-e93d052ca3cb",
    "prId" : 32301,
    "prUrl" : "https://github.com/apache/spark/pull/32301#pullrequestreview-669825938",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b78fa060-7c91-4c28-921e-3a1c78a0477a",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Not related to this PR: does it mean we don't support Project -> Limit -> Filter?",
        "createdAt" : "2021-05-25T15:30:43Z",
        "updatedAt" : "2021-05-25T15:30:43Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "d4406d01-3d9b-4496-842d-e1f831751dfe",
        "parentId" : "b78fa060-7c91-4c28-921e-3a1c78a0477a",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "cc @viirya @maropu ",
        "createdAt" : "2021-05-26T05:38:55Z",
        "updatedAt" : "2021-05-26T05:38:55Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "87a81423-93b5-4344-b977-1e17feeb878e",
        "parentId" : "b78fa060-7c91-4c28-921e-3a1c78a0477a",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "`Limit` is able to be pushed through, no?",
        "createdAt" : "2021-05-26T22:57:53Z",
        "updatedAt" : "2021-05-26T22:57:53Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "9170c80b-4cae-42db-9e0f-aec4bfe3a4ad",
        "parentId" : "b78fa060-7c91-4c28-921e-3a1c78a0477a",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Yea you are right, we will first generate a new project between Limit and Filter (the Project grandchild) to do nested column pruning, then the next batch we can match Project -> Filter and do nested column pruning further.",
        "createdAt" : "2021-05-27T07:22:29Z",
        "updatedAt" : "2021-05-27T07:22:30Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "8a29e943447808391c17f860598e3f11ae41d54d",
    "line" : 78,
    "diffHunk" : "@@ -1,1 +86,90 @@     * This pattern is needed to support [[Filter]] plan cases like\n     * [[Project]]->[[Filter]]->listed plan in [[canProjectPushThrough]] (e.g., [[Window]]).\n     * The reason why we don't simply add [[Filter]] in [[canProjectPushThrough]] is that\n     * the optimizer can hit an infinite loop during the [[PushDownPredicates]] rule.\n     */"
  },
  {
    "id" : "4e81af48-a975-47a6-97b7-76c2e6b1cf50",
    "prId" : 32301,
    "prUrl" : "https://github.com/apache/spark/pull/32301#pullrequestreview-669609196",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f50f5dce-81e6-45c7-b4c7-fcee86f56dd2",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "not related to this PR: we only add a new Project node as grandchild, but the scan node may still be at the bottom. Do we expect other rules to push down the Project through other nodes until it reaches the bottom?",
        "createdAt" : "2021-05-25T15:38:42Z",
        "updatedAt" : "2021-05-25T15:38:42Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "e288d31e-a54a-4179-9622-6bf8be28645b",
        "parentId" : "f50f5dce-81e6-45c7-b4c7-fcee86f56dd2",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "cc @viirya @maropu ",
        "createdAt" : "2021-05-26T05:39:00Z",
        "updatedAt" : "2021-05-26T05:39:01Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "9476847f-c31d-4290-a4f8-addac34b9337",
        "parentId" : "f50f5dce-81e6-45c7-b4c7-fcee86f56dd2",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Yes, this is how nested column pruning works now. The added Project with nested column references will be push down through other nodes until Scan.\r\n\r\nIf there are any nodes we cannot push through, then nested column pruning doesn't work.",
        "createdAt" : "2021-05-26T22:56:05Z",
        "updatedAt" : "2021-05-26T22:56:05Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "8a29e943447808391c17f860598e3f11ae41d54d",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +32,36 @@ * Then:\n * - Substitute the nested field references with alias attributes\n * - Add grandchild [[Project]]s transforming the nested fields to aliases\n *\n * Example 1: Project"
  },
  {
    "id" : "951f6949-8e19-409f-bcbd-bf4b2dcfe7be",
    "prId" : 32301,
    "prUrl" : "https://github.com/apache/spark/pull/32301#pullrequestreview-668023178",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "842e2681-be5f-479f-82ea-22475bf9c790",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I'm still a bit worried about calling distinct on uncanonicalized expressions. how about \r\n```\r\n.groupBy(_.canonicalized).values.map(_.head).toSeq\r\n```",
        "createdAt" : "2021-05-25T15:45:50Z",
        "updatedAt" : "2021-05-25T15:45:50Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "b64a9bfd-f7cd-4b9f-8b7b-232e172e3df4",
        "parentId" : "842e2681-be5f-479f-82ea-22475bf9c790",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Sorry I'm wrong. We can't do this as the caller side will look up the map from extract value to alias using the original expression.",
        "createdAt" : "2021-05-25T15:57:47Z",
        "updatedAt" : "2021-05-25T15:57:47Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "8a29e943447808391c17f860598e3f11ae41d54d",
    "line" : 309,
    "diffHunk" : "@@ -1,1 +266,270 @@            nestedFields.forall(f => child.find(_.semanticEquals(f)).isEmpty)\n          case _ => true\n        }.distinct\n\n        // If all nested fields of `attr` are used, we don't need to introduce new aliases."
  },
  {
    "id" : "1120e809-7c7c-4aa7-aaba-c71bb7ee516a",
    "prId" : 32301,
    "prUrl" : "https://github.com/apache/spark/pull/32301#pullrequestreview-668551472",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "acb3b7d4-d2ff-4ed2-8ce7-b9881143b2b9",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I didn't carefully review the code in the else branch. I assume it's the same as the previous code?",
        "createdAt" : "2021-05-25T16:04:29Z",
        "updatedAt" : "2021-05-25T16:04:29Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "717248d3-401c-4e13-89c9-f29cac3313b6",
        "parentId" : "acb3b7d4-d2ff-4ed2-8ce7-b9881143b2b9",
        "authorId" : "ada71464-b8c9-4d7b-9020-d49c27251fdb",
        "body" : "Most of this is cosmetic, but at the end there is an expression ID-based lookup. The current commit explicitly uses the exprId to look up, but I can wrap more variables as an AttributeMap.",
        "createdAt" : "2021-05-26T02:43:07Z",
        "updatedAt" : "2021-05-26T02:43:07Z",
        "lastEditedBy" : "ada71464-b8c9-4d7b-9020-d49c27251fdb",
        "tags" : [
        ]
      }
    ],
    "commit" : "8a29e943447808391c17f860598e3f11ae41d54d",
    "line" : 476,
    "diffHunk" : "@@ -1,1 +341,345 @@        Some(pushedThrough)\n      } else {\n        // Only one nested column accessor.\n        // E.g., df.select(explode($\"items\").as(\"item\")).select($\"item.a\")\n        val nestedFieldOnGenerator = nestedFieldsOnGenerator.head"
  },
  {
    "id" : "9735d070-2ac2-4038-902e-375083ad8836",
    "prId" : 31966,
    "prUrl" : "https://github.com/apache/spark/pull/31966#pullrequestreview-622850383",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0c3e098a-cfa4-42c2-91d6-00af2a0effa0",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Just a question, according to the logic, is this the same with checking `rewrittenG.generator.elementSchema.toAttributes.length == rewrittenG.generatorOutput`?",
        "createdAt" : "2021-03-27T18:55:14Z",
        "updatedAt" : "2021-04-25T00:49:15Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "4c5735ca-3a5d-48fe-90e5-acac1dba607d",
        "parentId" : "0c3e098a-cfa4-42c2-91d6-00af2a0effa0",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "yea, i think this is the same.",
        "createdAt" : "2021-03-29T03:51:08Z",
        "updatedAt" : "2021-04-25T00:49:15Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "a7194092ebc3a9ca97daba29fda0fcc0ec099cf4",
    "line" : 93,
    "diffHunk" : "@@ -1,1 +320,324 @@                  newAttr.withExprId(oldAttr.exprId).withName(oldAttr.name)\n                }\n                assert(updatedGeneratorOutput.length == rewrittenG.generatorOutput.length,\n                  \"Updated generator output must have the same length \" +\n                    \"with original generator output.\")"
  },
  {
    "id" : "58c84a6d-ec9f-47ae-af63-0d21203aaba7",
    "prId" : 31966,
    "prUrl" : "https://github.com/apache/spark/pull/31966#pullrequestreview-632952328",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cb9e157a-f076-42c3-9187-bf95749591d0",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "We need tests for case-sensitivity?",
        "createdAt" : "2021-03-29T01:43:00Z",
        "updatedAt" : "2021-04-25T00:49:15Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "0759814f-33a9-4ac8-bdd6-b77b7816bb20",
        "parentId" : "cb9e157a-f076-42c3-9187-bf95749591d0",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "let me add one.",
        "createdAt" : "2021-03-29T03:44:51Z",
        "updatedAt" : "2021-04-25T00:49:15Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "bcddb52a-3179-4655-b073-c476ad956137",
        "parentId" : "cb9e157a-f076-42c3-9187-bf95749591d0",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Not add this test case yet. Not related to this PR but seems there is a bug on case-sensitive nested column pruning. Let me figure it out first.",
        "createdAt" : "2021-04-05T07:30:57Z",
        "updatedAt" : "2021-04-25T00:49:15Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "b242bd08-3a89-470b-aa02-2e68d7bec6a8",
        "parentId" : "cb9e157a-f076-42c3-9187-bf95749591d0",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Found a bug and proposed a fix at #32059. cc @maropu @dongjoon-hyun ",
        "createdAt" : "2021-04-06T06:45:32Z",
        "updatedAt" : "2021-04-25T00:49:15Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "9736e9a1-f92b-4350-b0c8-1ce85d686837",
        "parentId" : "cb9e157a-f076-42c3-9187-bf95749591d0",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "As #32059 was merged, I add case-sensitivity test.",
        "createdAt" : "2021-04-10T20:55:50Z",
        "updatedAt" : "2021-04-25T00:49:15Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "a7194092ebc3a9ca97daba29fda0fcc0ec099cf4",
    "line" : 82,
    "diffHunk" : "@@ -1,1 +309,313 @@                        e.child\n                      case g: GetStructField =>\n                        ExtractValue(g.child, Literal(g.extractFieldName), SQLConf.get.resolver)\n                    }\n                    e.withNewChildren(Seq(extractor))"
  },
  {
    "id" : "de011d2c-8171-437c-9601-0aef7568bf9a",
    "prId" : 31966,
    "prUrl" : "https://github.com/apache/spark/pull/31966#pullrequestreview-627711741",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4f62ffec-289d-4888-9023-41b8214895d0",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Since these functions are used only once, how about inlining them?",
        "createdAt" : "2021-03-29T01:43:48Z",
        "updatedAt" : "2021-04-25T00:49:15Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "50eae2ee-9870-4450-a865-a5463cb37335",
        "parentId" : "4f62ffec-289d-4888-9023-41b8214895d0",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "okay for me. Put it as functions not for reuse but for making the code look simpler.",
        "createdAt" : "2021-03-29T03:52:43Z",
        "updatedAt" : "2021-04-25T00:49:15Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "3fd05e32-79f2-46f1-8ba0-57c623609f45",
        "parentId" : "4f62ffec-289d-4888-9023-41b8214895d0",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "If you don't mind, I prefer keep it as functions. This rule is already a bit complicated. Inlining these code make it looks harder to read.",
        "createdAt" : "2021-04-05T06:31:03Z",
        "updatedAt" : "2021-04-25T00:49:15Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "04db3048-5b03-4e6f-90a6-45bafde7c68b",
        "parentId" : "4f62ffec-289d-4888-9023-41b8214895d0",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "sgtm",
        "createdAt" : "2021-04-05T08:38:59Z",
        "updatedAt" : "2021-04-25T00:49:15Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "a7194092ebc3a9ca97daba29fda0fcc0ec099cf4",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +251,255 @@      pair._1.references.subsetOf(generatorOutputSet)\n    }\n  }\n\n  def unapply(plan: LogicalPlan): Option[LogicalPlan] = plan match {"
  },
  {
    "id" : "6d933ef1-f910-48dc-8b90-85f9e4be2978",
    "prId" : 31966,
    "prUrl" : "https://github.com/apache/spark/pull/31966#pullrequestreview-638404962",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "022a12ba-2dac-4ea3-a342-9b77396c439c",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "This PR targets at explode-like generators only? How about the others, e.g., `inline`?",
        "createdAt" : "2021-04-13T02:29:46Z",
        "updatedAt" : "2021-04-25T00:49:15Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "b1ee7d12-1b13-41bd-93f1-7f9562ef4ad9",
        "parentId" : "022a12ba-2dac-4ea3-a342-9b77396c439c",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Ideally it is okay too. We also support other generator pruning through (plz see `canPruneGenerator`). As the reported case is `explode`, I work on it first. We can add more support in follow-ups.",
        "createdAt" : "2021-04-15T07:07:42Z",
        "updatedAt" : "2021-04-25T00:49:15Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "bfab1246-deb3-4bd3-adf9-df53aa96b6a1",
        "parentId" : "022a12ba-2dac-4ea3-a342-9b77396c439c",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "yea, targeting `explode` in this PR sounds okay. Could you write it explicitly in the PR description?",
        "createdAt" : "2021-04-19T01:23:57Z",
        "updatedAt" : "2021-04-25T00:49:15Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "b8791b90-c15c-447f-8858-1a6d2b78ca3d",
        "parentId" : "022a12ba-2dac-4ea3-a342-9b77396c439c",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Thanks. Added a note in the description.",
        "createdAt" : "2021-04-19T01:28:44Z",
        "updatedAt" : "2021-04-25T00:49:15Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "a7194092ebc3a9ca97daba29fda0fcc0ec099cf4",
    "line" : 77,
    "diffHunk" : "@@ -1,1 +304,308 @@                //       df.select(explode($\"items.a\").as(\"item.a\"))\n                val rewrittenG = newG.transformExpressions {\n                  case e: ExplodeBase =>\n                    val extractor = nestedFieldsOnGenerator.head._1.transformUp {\n                      case _: Attribute =>"
  },
  {
    "id" : "b3a8f7fc-6775-46fa-a73a-437c929b0232",
    "prId" : 31966,
    "prUrl" : "https://github.com/apache/spark/pull/31966#pullrequestreview-644086163",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "39e6f218-4170-4376-a0fa-42aeee1dd714",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Got it. Let me play more with this PR for a while. It seems I need more tests.",
        "createdAt" : "2021-04-25T02:51:20Z",
        "updatedAt" : "2021-04-25T02:51:21Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "9cfc2dcb-0fb7-4361-9515-ce631ea4e333",
        "parentId" : "39e6f218-4170-4376-a0fa-42aeee1dd714",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Thank you!",
        "createdAt" : "2021-04-25T03:18:50Z",
        "updatedAt" : "2021-04-25T03:18:51Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "a7194092ebc3a9ca97daba29fda0fcc0ec099cf4",
    "line" : 54,
    "diffHunk" : "@@ -1,1 +281,285 @@          // i.e., attr.field when attr is a ArrayType(ArrayType(...)).\n          // Similarily, we also cannot push through if the child of generator is `MapType`.\n          g.generator.children.head.dataType match {\n            case _: MapType => return Some(pushedThrough)\n            case ArrayType(_: ArrayType, _) => return Some(pushedThrough)"
  }
]