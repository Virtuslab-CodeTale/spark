[
  {
    "id" : "02f7de50-7b38-47b7-9572-c054df0a52c9",
    "prId" : 25368,
    "prUrl" : "https://github.com/apache/spark/pull/25368#pullrequestreview-271379540",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "694a4b8e-73f5-44e6-b9e8-4e62b49bb58a",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This is simply moved from https://github.com/apache/spark/pull/25368/files#diff-ddb77374e054250d0d6ac608a8188729L46",
        "createdAt" : "2019-08-06T14:18:48Z",
        "updatedAt" : "2019-08-20T03:00:48Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "4895a6eab6ec449238192715b78fea61217f7f54",
    "line" : 39,
    "diffHunk" : "@@ -1,1 +37,41 @@\n  def defaultCatalog: Option[CatalogPlugin] = {\n    conf.defaultV2Catalog.flatMap { catalogName =>\n      try {\n        Some(catalog(catalogName))"
  },
  {
    "id" : "cd92cca4-a84c-4ef6-887a-a0b9901ff52e",
    "prId" : 25368,
    "prUrl" : "https://github.com/apache/spark/pull/25368#pullrequestreview-271379852",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "85fc3ba0-8108-488e-92e7-5de755d24215",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This is simply moved from https://github.com/apache/spark/pull/25368/files#diff-ddb77374e054250d0d6ac608a8188729L62",
        "createdAt" : "2019-08-06T14:19:14Z",
        "updatedAt" : "2019-08-20T03:00:48Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "4895a6eab6ec449238192715b78fea61217f7f54",
    "line" : 51,
    "diffHunk" : "@@ -1,1 +49,53 @@\n  def v2SessionCatalog: Option[CatalogPlugin] = {\n    try {\n      Some(catalog(CatalogManager.SESSION_CATALOG_NAME))\n    } catch {"
  },
  {
    "id" : "62d05e8d-58a0-4a16-9279-e27afccb2387",
    "prId" : 25368,
    "prUrl" : "https://github.com/apache/spark/pull/25368#pullrequestreview-275778781",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "adb80821-8be6-4452-9831-af0fe384c735",
        "parentId" : null,
        "authorId" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "body" : "I'm thinking more about whether this should be the duty of the CatalogManager or the catalog itself...\r\n\r\nMy thoughts are:\r\n  1. Once the V2SessionCatalog `SupportsNamespaces`, it can have the default namespace `default` set within it\r\n  2. When you run a command like `USE foo.bar` where `foo` is the catalog, we should set the default namespace within that catalog to be `bar`.\r\n  3. What if the `default` catalog doesn't support namespaces in the first place?\r\n\r\nI'm a bit worried that having the default namespace setting in the CatalogManager can lead to a split brain situation.",
        "createdAt" : "2019-08-14T04:06:33Z",
        "updatedAt" : "2019-08-20T03:00:48Z",
        "lastEditedBy" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "tags" : [
        ]
      },
      {
        "id" : "caaa25ae-d0b7-4968-a449-44098a7b5cac",
        "parentId" : "adb80821-8be6-4452-9831-af0fe384c735",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I think current namespace only make sense to the current catalog, e.g. `SELECT ... FROM t`, `t` can be a table in the current catalog's current namespace. However, for `SELECT ... FROM c1.t`, it's confusing to say `t` is a table in catalog `c1`'s current namespace.\r\n\r\nWhen a table identifier starts with a catalog name, it should be a fully qualified identifier, and we can't apply current namespace here.\r\n\r\ncatalog (including `V2SessionCatalog`) can report its default namespace, which will be used as the current namespace when switching to the catalog at the first time.",
        "createdAt" : "2019-08-14T05:59:30Z",
        "updatedAt" : "2019-08-20T03:00:48Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "21901731-75e9-4976-9335-8021951f351d",
        "parentId" : "adb80821-8be6-4452-9831-af0fe384c735",
        "authorId" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "body" : "I think we're saying the same things. I totally agree that:\r\nfor a catalog `c1` \r\n```sql\r\nSELECT ... FROM c1.t\r\n```\r\n, this should be a fully qualified identifier. I'm saying that we should push the namespace configuration into the catalog that supports it. It shouldn't be part of the CatalogManager.\r\n\r\n",
        "createdAt" : "2019-08-14T06:05:52Z",
        "updatedAt" : "2019-08-20T03:00:48Z",
        "lastEditedBy" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "tags" : [
        ]
      },
      {
        "id" : "7e62ea0c-d553-4aa0-8468-f1caa34469e9",
        "parentId" : "adb80821-8be6-4452-9831-af0fe384c735",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I'm not sure we should ask the catalog implementation to do it. This will make catalog mutable and make it harder to implement. e.g. they need to take care of the current namespace in many methods like `loadTable`, `createTable`, etc. It also brings some risks if the catalog implementation has bugs for tracking the current namespace.\r\n\r\nInstead, I think it's better to let Spark track the current namespace, and always extend the table identifier with the current namespace and make it a fully qualified identifier before calling catalog APIs. I'm fine for not tracking it in `CatalogManager`, but we should track it somewhere in Spark.",
        "createdAt" : "2019-08-14T09:37:33Z",
        "updatedAt" : "2019-08-20T03:00:48Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "fb93721d-3fe9-4ae2-a1bb-123414f9396f",
        "parentId" : "adb80821-8be6-4452-9831-af0fe384c735",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "A side story: Hive can track the current database, but Spark track the current database itself, and always call Hive APIs with fully qualified table identifier.",
        "createdAt" : "2019-08-14T10:56:12Z",
        "updatedAt" : "2019-08-20T03:00:48Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "3ba745b1-1de7-4036-9932-e354a18abdec",
        "parentId" : "adb80821-8be6-4452-9831-af0fe384c735",
        "authorId" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "body" : "Oh, wait, I got the defaultNamespace setting in `SupportsNamespaces` wrong. I thought it was actually tracked there. This looks good to me. Sorry.",
        "createdAt" : "2019-08-16T05:23:00Z",
        "updatedAt" : "2019-08-20T03:00:48Z",
        "lastEditedBy" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "tags" : [
        ]
      }
    ],
    "commit" : "4895a6eab6ec449238192715b78fea61217f7f54",
    "line" : 66,
    "diffHunk" : "@@ -1,1 +64,68 @@\n  private var _currentNamespace = {\n    // The builtin catalog use \"default\" as the default database.\n    defaultCatalog.map(getDefaultNamespace).getOrElse(Array(\"default\"))\n  }"
  },
  {
    "id" : "b140d52a-baad-462e-b3fd-90ceec5d0e8b",
    "prId" : 25368,
    "prUrl" : "https://github.com/apache/spark/pull/25368#pullrequestreview-277905577",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "14b6654e-9288-4dd4-b732-a07e4318f0d6",
        "parentId" : null,
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "@cloud-fan is this the right behavior? Since `CatalogManager` is created in `Analyzer`, unless you set the default catalog (via `spark.sql.default.catalog`) when you create the `SparkSession`, this will be set to `\"default\"`.\r\n\r\nFor #25247, you cannot do the following:\r\n```Scala\r\n// Assume that 'testcat' catalog implements SupportsNamespaces and returns Array() for the defaultNamespace.\r\nspark.conf.set(\"spark.sql.default.catalog\", \"testcat\")\r\n\r\n// Now the following will use `default` as the default namespace instead of ``.\r\nspark.sql(\"SHOW TABLES\")\r\n```\r\n\r\nBut, I see SQL queries where \"spark.sql.default.catalog\" is set/used without creating a new `SparkSession` here: https://github.com/apache/spark/blob/c4257b18a1efa82d98c8fa9911fa3f3dd95a72b4/sql/core/src/test/scala/org/apache/spark/sql/sources/v2/DataSourceV2SQLSuite.scala#L203",
        "createdAt" : "2019-08-21T02:53:14Z",
        "updatedAt" : "2019-08-21T02:53:15Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      },
      {
        "id" : "f8c846e5-2a4c-4302-8e8a-6a3f8939b6d5",
        "parentId" : "14b6654e-9288-4dd4-b732-a07e4318f0d6",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Good catch! The `currentNamespace` and `currentCatalog` are not used anywhere and I was planning to add tests when I implement switching current namespace/catalog. Let me add some simple tests to reflect runtime config changes first.",
        "createdAt" : "2019-08-21T04:07:16Z",
        "updatedAt" : "2019-08-21T04:07:17Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "7332042a-d150-439e-83e6-9f8e3f5232d9",
        "parentId" : "14b6654e-9288-4dd4-b732-a07e4318f0d6",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "Thanks for finding this @imback82!",
        "createdAt" : "2019-08-21T16:05:24Z",
        "updatedAt" : "2019-08-21T16:05:25Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      }
    ],
    "commit" : "4895a6eab6ec449238192715b78fea61217f7f54",
    "line" : 67,
    "diffHunk" : "@@ -1,1 +65,69 @@  private var _currentNamespace = {\n    // The builtin catalog use \"default\" as the default database.\n    defaultCatalog.map(getDefaultNamespace).getOrElse(Array(\"default\"))\n  }\n"
  }
]