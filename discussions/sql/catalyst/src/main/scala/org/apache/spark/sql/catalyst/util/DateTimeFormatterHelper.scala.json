[
  {
    "id" : "e10a8896-c56e-4a3b-87cf-fb3667862c84",
    "prId" : 33019,
    "prUrl" : "https://github.com/apache/spark/pull/33019#pullrequestreview-689383820",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2d069f44-af46-48e9-8f17-1b29ee85b109",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "what's the difference between this one and `QueryExecutionErrors.failToRecognizePatternInDateTimeFormatterError`?",
        "createdAt" : "2021-06-22T10:30:21Z",
        "updatedAt" : "2021-06-22T10:30:21Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "1c4b67e0-27fb-4f6b-9703-b259e5cfa324",
        "parentId" : "2d069f44-af46-48e9-8f17-1b29ee85b109",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "I just renamed `failToRecognizePatternInDateTimeFormatterError` as `failToRecognizePatternAfterUpgradeError`. WDYT?",
        "createdAt" : "2021-06-22T11:27:51Z",
        "updatedAt" : "2021-06-22T11:27:52Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "ea317a0c5620367921bb80ff6b451dc5fc8cf083",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +190,194 @@  protected def checkInvalidPattern(pattern: String): PartialFunction[Throwable, Nothing] = {\n    case e: IllegalArgumentException =>\n      throw QueryExecutionErrors.failToRecognizePatternError(pattern, e)\n  }\n}"
  },
  {
    "id" : "8d7d31d4-9771-4355-945d-5c6d09a813ed",
    "prId" : 28766,
    "prUrl" : "https://github.com/apache/spark/pull/28766#pullrequestreview-427725353",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "efb9b33c-9d1a-4e6b-9d5f-df034ece1d79",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can you show an example of this error message? let's see if it looks good.",
        "createdAt" : "2020-06-10T03:05:51Z",
        "updatedAt" : "2020-06-10T14:24:59Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "b073a10c-d5ee-4cc1-a5c3-09c7038b0fc8",
        "parentId" : "efb9b33c-9d1a-4e6b-9d5f-df034ece1d79",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "OK",
        "createdAt" : "2020-06-10T05:41:41Z",
        "updatedAt" : "2020-06-10T14:24:59Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "78c676e1d60a5c9c785b40d3b42ac756b72c54e4",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +47,51 @@      if (actual != expected) {\n        throw new DateTimeException(s\"Conflict found: Field $field $actual differs from\" +\n          s\" $field $expected derived from $candidate\")\n      }\n    }"
  },
  {
    "id" : "c6237fee-3a15-45ba-902a-8b33e70f3100",
    "prId" : 28736,
    "prUrl" : "https://github.com/apache/spark/pull/28736#pullrequestreview-442092401",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cef8ac98-11cb-4ac4-9d8d-f496dd35fbe5",
        "parentId" : null,
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "@HyukjinKwon Should we combine the JVM stacktrace for SparkUpgradeException in the python side?",
        "createdAt" : "2020-07-02T18:01:19Z",
        "updatedAt" : "2020-07-02T18:01:36Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      },
      {
        "id" : "be9374bd-048a-48d0-af79-565bf697b17f",
        "parentId" : "cef8ac98-11cb-4ac4-9d8d-f496dd35fbe5",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "+1!",
        "createdAt" : "2020-07-03T01:06:27Z",
        "updatedAt" : "2020-07-03T01:06:27Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "54e70b617a2fdfe898af1b425044725bc4c698af",
    "line" : 46,
    "diffHunk" : "@@ -1,1 +144,148 @@        case _: Throwable => throw e\n      }\n      throw new SparkUpgradeException(\"3.0\", s\"Fail to format it to '$resultCandidate' in the new\" +\n        s\" formatter. You can set ${SQLConf.LEGACY_TIME_PARSER_POLICY.key} to LEGACY to restore\" +\n        \" the behavior before Spark 3.0, or set to CORRECTED and treat it as an invalid\" +"
  },
  {
    "id" : "a11bfcff-f039-46fe-a781-60e9fb8fb658",
    "prId" : 28727,
    "prUrl" : "https://github.com/apache/spark/pull/28727#pullrequestreview-424448063",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b15a34f5-2e7c-48ca-909a-fb17301af047",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Yikes, isn't this going to change the Locale's settings for the whole JVM?",
        "createdAt" : "2020-06-04T12:42:47Z",
        "updatedAt" : "2020-06-04T12:43:00Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "bc661204-8344-49a9-ac75-2e871bff2f04",
        "parentId" : "b15a34f5-2e7c-48ca-909a-fb17301af047",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "Only for those trying to use the original value of `SUNDAY FISRT and 1 mininalDay`. This seems not to be a good way though.",
        "createdAt" : "2020-06-04T12:59:32Z",
        "updatedAt" : "2020-06-04T12:59:32Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "7111cf84-69a5-4e2e-a803-e1a190aaeefe",
        "parentId" : "b15a34f5-2e7c-48ca-909a-fb17301af047",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "yea, we shouldn't change a global cache, which is shared in the entire JVM, including user code.",
        "createdAt" : "2020-06-04T13:31:58Z",
        "updatedAt" : "2020-06-04T13:31:58Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "590b40af70bebfe9176d37d6ebd0ad71ecbff9e7",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +162,166 @@\n  def presetSundayStartToMondayStart(): Unit = {\n    val CACHE: Field = classOf[WeekFields].getDeclaredField(\"CACHE\")\n    CACHE.setAccessible(true)\n    val modifiers: Field = CACHE.getClass.getDeclaredField(\"modifiers\")"
  },
  {
    "id" : "648d83f2-349b-425b-a0c3-cf3e2674f697",
    "prId" : 28674,
    "prUrl" : "https://github.com/apache/spark/pull/28674#pullrequestreview-421932813",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "998026d4-da3b-4232-bb11-f634299592b5",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "should this happen when we create the formatter?",
        "createdAt" : "2020-06-01T15:17:37Z",
        "updatedAt" : "2020-06-01T15:17:37Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "0dcd5dffb8c7b74d3570c67aae2639332cebb687",
    "line" : 52,
    "diffHunk" : "@@ -1,1 +61,65 @@    if (weekBased && mayNonWeekBased(accessor)) {\n      throw new DateTimeException(\n        s\"Can not mix week-based and non-week-based date fields together for parsing dates\")\n    } else if (weekBased) {\n"
  },
  {
    "id" : "e35e38ca-03aa-4c7b-8fb6-a5eb5c88879c",
    "prId" : 28673,
    "prUrl" : "https://github.com/apache/spark/pull/28673#pullrequestreview-421406616",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "360d1642-de4b-44e4-a371-058b717c9791",
        "parentId" : null,
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "Shall we use Nonfatal here?",
        "createdAt" : "2020-05-29T08:28:59Z",
        "updatedAt" : "2020-05-30T03:56:59Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "bab2a7cb-ca56-4bfb-b719-2319ffd4818e",
        "parentId" : "360d1642-de4b-44e4-a371-058b717c9791",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This seems like a Java bug to me to throw `ArrayIndexOutOfBoundsException`.\r\n\r\nShall we fail the formatter creation when there are more than 10 `y` in the pattern string? And document this limitation as well.",
        "createdAt" : "2020-05-30T06:54:01Z",
        "updatedAt" : "2020-05-30T06:54:02Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "981a2db0-3b62-473f-a507-8d3a9c01162c",
        "parentId" : "360d1642-de4b-44e4-a371-058b717c9791",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "okay. Do we still need to check the runtime exceptions or `DateTimeException `  for the formatting phase?",
        "createdAt" : "2020-05-30T13:50:29Z",
        "updatedAt" : "2020-05-30T13:54:47Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "a5da8c3db37e19427c8729b645c354bce707bb28",
    "line" : 54,
    "diffHunk" : "@@ -1,1 +144,148 @@   */\n  private def needConvertToSparkUpgradeException(e: Throwable): Boolean = e match {\n    case _: DateTimeException | _: ArrayIndexOutOfBoundsException\n      if SQLConf.get.legacyTimeParserPolicy == EXCEPTION => true\n    case _ => false"
  },
  {
    "id" : "8304594b-468a-45cb-89df-966b5d6db888",
    "prId" : 28673,
    "prUrl" : "https://github.com/apache/spark/pull/28673#pullrequestreview-421375401",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9f916533-2288-4b2a-81bd-42592e5e2009",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "The parser case can get`ArrayIndexOutOfBoundsException`, too?",
        "createdAt" : "2020-05-30T03:06:49Z",
        "updatedAt" : "2020-05-30T03:56:59Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "5f4d93e2-eaf8-4c0d-be7b-5ff70efcc2f2",
        "parentId" : "9f916533-2288-4b2a-81bd-42592e5e2009",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "There could be such a risk for the parser to get it after roughly checked the JCL.",
        "createdAt" : "2020-05-30T03:28:14Z",
        "updatedAt" : "2020-05-30T03:56:59Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "32e5b578-bbec-4c55-aff5-31dfab7b8771",
        "parentId" : "9f916533-2288-4b2a-81bd-42592e5e2009",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "Maybe RuntimeException is more appropriate",
        "createdAt" : "2020-05-30T03:57:38Z",
        "updatedAt" : "2020-05-30T03:57:38Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "a5da8c3db37e19427c8729b645c354bce707bb28",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +108,112 @@  protected def checkDiffParserResult[T](\n      s: String, legacyParseFunc: String => T): PartialFunction[Throwable, T] = {\n    case e if needConvertToSparkUpgradeException(e) =>\n      try {\n        legacyParseFunc(s)"
  },
  {
    "id" : "109cdf6c-80e3-4bcb-847e-34cfd46621a7",
    "prId" : 28673,
    "prUrl" : "https://github.com/apache/spark/pull/28673#pullrequestreview-421372589",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f5fff2c2-ab7c-4d93-bce4-fe013a65dcf3",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Could you leave some comments about what's a condition for `ArrayIndexOutOfBoundsException` to be thrown?",
        "createdAt" : "2020-05-30T03:14:53Z",
        "updatedAt" : "2020-05-30T03:56:59Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "a5da8c3db37e19427c8729b645c354bce707bb28",
    "line" : 55,
    "diffHunk" : "@@ -1,1 +145,149 @@  private def needConvertToSparkUpgradeException(e: Throwable): Boolean = e match {\n    case _: DateTimeException | _: ArrayIndexOutOfBoundsException\n      if SQLConf.get.legacyTimeParserPolicy == EXCEPTION => true\n    case _ => false\n  }"
  },
  {
    "id" : "d24f7ec7-3f57-4677-b53d-7224ba4212a3",
    "prId" : 28646,
    "prUrl" : "https://github.com/apache/spark/pull/28646#pullrequestreview-419088383",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0d9993f6-b08c-4dd5-ad87-0532c7e6c616",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "You checked only 'LLL' pattern in `bugInStandAloneForm()` but throws exception for 'qqq' as well. Are you sure they are directly related?",
        "createdAt" : "2020-05-26T20:51:33Z",
        "updatedAt" : "2020-05-27T12:43:10Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "d9d72fc1-6516-45d8-b316-6e2cc7e2b52a",
        "parentId" : "0d9993f6-b08c-4dd5-ad87-0532c7e6c616",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "In the java doc:\r\n```\r\nPattern letters 'L', 'c', and 'q' specify the stand-alone form of the text styles.\r\n```\r\n\r\nI think they are directly related. And I tested `q` locally as well. `c` is already forbidden in 3.0.",
        "createdAt" : "2020-05-27T07:02:59Z",
        "updatedAt" : "2020-05-27T12:43:10Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "b2e5b4f9-2cf6-4b2a-bb9d-e55ec3f88bbd",
        "parentId" : "0d9993f6-b08c-4dd5-ad87-0532c7e6c616",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "ok. I have double checked the pattern 'qqq'. It has the same problem\r\n\r\nJDK 11:\r\n```sql\r\nspark-sql> select to_csv(named_struct('date', date '1970-01-01'), map('dateFormat', 'qqq', 'locale', 'RU'));\r\n1-й кв.\r\nspark-sql> select to_csv(named_struct('date', date '1970-01-01'), map('dateFormat', 'qqq', 'locale', 'EN'));\r\nQ1\r\n```\r\n\r\nJDK 8\r\n```sql\r\nspark-sql> select to_csv(named_struct('date', date '1970-01-01'), map('dateFormat', 'qqq', 'locale', 'RU'));\r\n1\r\nspark-sql> select to_csv(named_struct('date', date '1970-01-01'), map('dateFormat', 'qqq', 'locale', 'EN'));\r\n1\r\n```",
        "createdAt" : "2020-05-27T11:10:42Z",
        "updatedAt" : "2020-05-27T12:43:10Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "b7cbc8bea2064449174fc2e2c9664e97ee12da20",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +254,258 @@            throw new IllegalArgumentException(s\"Too many pattern letters: ${style.head}\")\n          }\n          if (bugInStandAloneForm && (patternPart.contains(\"LLL\") || patternPart.contains(\"qqq\"))) {\n            throw new IllegalArgumentException(\"Java 8 has a bug to support stand-alone \" +\n              \"form (3 or more 'L' or 'q' in the pattern string). Please use 'M' or 'Q' instead, \" +"
  }
]