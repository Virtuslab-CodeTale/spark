[
  {
    "id" : "e10a8896-c56e-4a3b-87cf-fb3667862c84",
    "prId" : 33019,
    "prUrl" : "https://github.com/apache/spark/pull/33019#pullrequestreview-689383820",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2d069f44-af46-48e9-8f17-1b29ee85b109",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "what's the difference between this one and `QueryExecutionErrors.failToRecognizePatternInDateTimeFormatterError`?",
        "createdAt" : "2021-06-22T10:30:21Z",
        "updatedAt" : "2021-06-22T10:30:21Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "1c4b67e0-27fb-4f6b-9703-b259e5cfa324",
        "parentId" : "2d069f44-af46-48e9-8f17-1b29ee85b109",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "I just renamed `failToRecognizePatternInDateTimeFormatterError` as `failToRecognizePatternAfterUpgradeError`. WDYT?",
        "createdAt" : "2021-06-22T11:27:51Z",
        "updatedAt" : "2021-06-22T11:27:52Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "ea317a0c5620367921bb80ff6b451dc5fc8cf083",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +190,194 @@  protected def checkInvalidPattern(pattern: String): PartialFunction[Throwable, Nothing] = {\n    case e: IllegalArgumentException =>\n      throw QueryExecutionErrors.failToRecognizePatternError(pattern, e)\n  }\n}"
  },
  {
    "id" : "8d7d31d4-9771-4355-945d-5c6d09a813ed",
    "prId" : 28766,
    "prUrl" : "https://github.com/apache/spark/pull/28766#pullrequestreview-427725353",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "efb9b33c-9d1a-4e6b-9d5f-df034ece1d79",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can you show an example of this error message? let's see if it looks good.",
        "createdAt" : "2020-06-10T03:05:51Z",
        "updatedAt" : "2020-06-10T14:24:59Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "b073a10c-d5ee-4cc1-a5c3-09c7038b0fc8",
        "parentId" : "efb9b33c-9d1a-4e6b-9d5f-df034ece1d79",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "OK",
        "createdAt" : "2020-06-10T05:41:41Z",
        "updatedAt" : "2020-06-10T14:24:59Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "78c676e1d60a5c9c785b40d3b42ac756b72c54e4",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +47,51 @@      if (actual != expected) {\n        throw new DateTimeException(s\"Conflict found: Field $field $actual differs from\" +\n          s\" $field $expected derived from $candidate\")\n      }\n    }"
  },
  {
    "id" : "c6237fee-3a15-45ba-902a-8b33e70f3100",
    "prId" : 28736,
    "prUrl" : "https://github.com/apache/spark/pull/28736#pullrequestreview-442092401",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cef8ac98-11cb-4ac4-9d8d-f496dd35fbe5",
        "parentId" : null,
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "@HyukjinKwon Should we combine the JVM stacktrace for SparkUpgradeException in the python side?",
        "createdAt" : "2020-07-02T18:01:19Z",
        "updatedAt" : "2020-07-02T18:01:36Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      },
      {
        "id" : "be9374bd-048a-48d0-af79-565bf697b17f",
        "parentId" : "cef8ac98-11cb-4ac4-9d8d-f496dd35fbe5",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "+1!",
        "createdAt" : "2020-07-03T01:06:27Z",
        "updatedAt" : "2020-07-03T01:06:27Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "54e70b617a2fdfe898af1b425044725bc4c698af",
    "line" : 46,
    "diffHunk" : "@@ -1,1 +144,148 @@        case _: Throwable => throw e\n      }\n      throw new SparkUpgradeException(\"3.0\", s\"Fail to format it to '$resultCandidate' in the new\" +\n        s\" formatter. You can set ${SQLConf.LEGACY_TIME_PARSER_POLICY.key} to LEGACY to restore\" +\n        \" the behavior before Spark 3.0, or set to CORRECTED and treat it as an invalid\" +"
  },
  {
    "id" : "a11bfcff-f039-46fe-a781-60e9fb8fb658",
    "prId" : 28727,
    "prUrl" : "https://github.com/apache/spark/pull/28727#pullrequestreview-424448063",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b15a34f5-2e7c-48ca-909a-fb17301af047",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Yikes, isn't this going to change the Locale's settings for the whole JVM?",
        "createdAt" : "2020-06-04T12:42:47Z",
        "updatedAt" : "2020-06-04T12:43:00Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "bc661204-8344-49a9-ac75-2e871bff2f04",
        "parentId" : "b15a34f5-2e7c-48ca-909a-fb17301af047",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "Only for those trying to use the original value of `SUNDAY FISRT and 1 mininalDay`. This seems not to be a good way though.",
        "createdAt" : "2020-06-04T12:59:32Z",
        "updatedAt" : "2020-06-04T12:59:32Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "7111cf84-69a5-4e2e-a803-e1a190aaeefe",
        "parentId" : "b15a34f5-2e7c-48ca-909a-fb17301af047",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "yea, we shouldn't change a global cache, which is shared in the entire JVM, including user code.",
        "createdAt" : "2020-06-04T13:31:58Z",
        "updatedAt" : "2020-06-04T13:31:58Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "590b40af70bebfe9176d37d6ebd0ad71ecbff9e7",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +162,166 @@\n  def presetSundayStartToMondayStart(): Unit = {\n    val CACHE: Field = classOf[WeekFields].getDeclaredField(\"CACHE\")\n    CACHE.setAccessible(true)\n    val modifiers: Field = CACHE.getClass.getDeclaredField(\"modifiers\")"
  }
]