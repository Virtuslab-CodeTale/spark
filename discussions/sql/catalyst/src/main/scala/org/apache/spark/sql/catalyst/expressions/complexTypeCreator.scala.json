[
  {
    "id" : "fbaf3d82-c221-416d-8000-6535dd24d925",
    "prId" : 31843,
    "prUrl" : "https://github.com/apache/spark/pull/31843#pullrequestreview-614216973",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4b2f8da9-7300-489a-878a-31d17bc16c39",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ah, I see. This change makes `ResolveCreateNamedStruct` simpler. The fix seems smart.",
        "createdAt" : "2021-03-17T11:56:25Z",
        "updatedAt" : "2021-03-17T11:56:25Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "2a45d24340157d92a18aebafda06918d3655664a",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +347,351 @@      // We should always use the last part of the column name (`c` in the above example) as the\n      // alias name inside CreateNamedStruct.\n      case (u: UnresolvedAttribute, _) => Seq(Literal(u.nameParts.last), u)\n      case (e: NamedExpression, _) if e.resolved => Seq(Literal(e.name), e)\n      case (e: NamedExpression, _) => Seq(NamePlaceholder, e)"
  },
  {
    "id" : "c153c5b5-40d4-4a3b-ba0d-8ddcaf9b50d7",
    "prId" : 30867,
    "prUrl" : "https://github.com/apache/spark/pull/30867#pullrequestreview-556090017",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8aaba8e4-5512-4748-9d80-deb72ac6b4d4",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Could you clarify that the difference between `array_funcs` and `collection_funcs` in this context?",
        "createdAt" : "2020-12-21T01:49:21Z",
        "updatedAt" : "2020-12-21T07:20:26Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "4e82580cdc1b44a1680631ad54121e327f37b9e0",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +54,58 @@  \"\"\",\n  since = \"1.1.0\",\n  group = \"array_funcs\")\ncase class CreateArray(children: Seq[Expression], useStringTypeWhenEmpty: Boolean)\n  extends Expression with NoThrow {"
  },
  {
    "id" : "68c1ed9d-9598-4569-a3b5-6d7654381efa",
    "prId" : 30570,
    "prUrl" : "https://github.com/apache/spark/pull/30570#pullrequestreview-543065599",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f3a88a91-9e2e-4ae2-96e5-80fe75daaf86",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Thanks for clarifying this only indicates the expression itself.",
        "createdAt" : "2020-12-02T17:20:43Z",
        "updatedAt" : "2020-12-02T17:20:43Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "36d280577ebcf888ca9ed91ca7f62a45da07db97",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +32,36 @@\n/**\n * Trait to indicate the expression does not throw an exception by itself when they are evaluated.\n * For example, UDFs, [[AssertTrue]], etc can throw an exception when they are executed.\n * In such case, it is necessary to call [[Expression.eval]], and the optimization rule should"
  },
  {
    "id" : "112acfc7-c5d7-4fdc-b2b8-5dacf27fae98",
    "prId" : 29795,
    "prUrl" : "https://github.com/apache/spark/pull/29795#pullrequestreview-491073908",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a1858232-030a-400f-be21-7133da65338c",
        "parentId" : null,
        "authorId" : "6fc88871-fca6-485c-a47e-5e17709c7b68",
        "body" : "@viirya I'm not quite done with this PR yet but I wanted to share it with you early because some of the changes I'm making in here may be helpful for #29587 (assuming this PR is accepted). Specifically, it would be possible to implement sorting of fields in a struct simply by: \r\n```\r\ncase class OrderStructFieldsByName() extends StructFieldsOperation {\r\n  override def apply(values: Seq[(StructField, Expression)]): Seq[(StructField, Expression)] =\r\n    values.sortBy { case (field, _) => field.name }\r\n}\r\n\r\nUpdateFields(structExpr, OrderStructFieldsByName() :: Nil)\r\n``` ",
        "createdAt" : "2020-09-18T00:30:15Z",
        "updatedAt" : "2020-09-29T20:56:48Z",
        "lastEditedBy" : "6fc88871-fca6-485c-a47e-5e17709c7b68",
        "tags" : [
        ]
      }
    ],
    "commit" : "7e51f35580db72fda11153d76caf232b83e617cd",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +556,560 @@   */\n  def apply(values: Seq[(StructField, Expression)]): Seq[(StructField, Expression)]\n}\n\n/**"
  },
  {
    "id" : "e8ea062c-e287-4058-9801-a837bed7ed41",
    "prId" : 29743,
    "prUrl" : "https://github.com/apache/spark/pull/29743#pullrequestreview-487712748",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b17663cd-dfe5-4075-a750-61756bdff1e9",
        "parentId" : null,
        "authorId" : "a8e23d47-3ae4-4385-848c-38a216d1bd08",
        "body" : "Did not find the jira for this. The first pull, where I saw this code was #2936\r\nGuessed the version from the date of that pull request.",
        "createdAt" : "2020-09-13T20:55:06Z",
        "updatedAt" : "2020-09-19T19:00:31Z",
        "lastEditedBy" : "a8e23d47-3ae4-4385-848c-38a216d1bd08",
        "tags" : [
        ]
      },
      {
        "id" : "6cee1422-37f3-46f9-a8e9-3a4ff8cb1a1a",
        "parentId" : "b17663cd-dfe5-4075-a750-61756bdff1e9",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "The decision looks okay to me.",
        "createdAt" : "2020-09-14T13:04:43Z",
        "updatedAt" : "2020-09-19T19:00:31Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "4162b41d325da3f9b732d835168a546916b50499",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +39,43 @@  \"\"\",\n  since = \"1.1.0\")\ncase class CreateArray(children: Seq[Expression], useStringTypeWhenEmpty: Boolean)\n  extends Expression {\n"
  }
]