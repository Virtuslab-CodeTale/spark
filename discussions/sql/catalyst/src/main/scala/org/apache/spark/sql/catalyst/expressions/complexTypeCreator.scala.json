[
  {
    "id" : "fbaf3d82-c221-416d-8000-6535dd24d925",
    "prId" : 31843,
    "prUrl" : "https://github.com/apache/spark/pull/31843#pullrequestreview-614216973",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4b2f8da9-7300-489a-878a-31d17bc16c39",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ah, I see. This change makes `ResolveCreateNamedStruct` simpler. The fix seems smart.",
        "createdAt" : "2021-03-17T11:56:25Z",
        "updatedAt" : "2021-03-17T11:56:25Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "2a45d24340157d92a18aebafda06918d3655664a",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +347,351 @@      // We should always use the last part of the column name (`c` in the above example) as the\n      // alias name inside CreateNamedStruct.\n      case (u: UnresolvedAttribute, _) => Seq(Literal(u.nameParts.last), u)\n      case (e: NamedExpression, _) if e.resolved => Seq(Literal(e.name), e)\n      case (e: NamedExpression, _) => Seq(NamePlaceholder, e)"
  },
  {
    "id" : "c153c5b5-40d4-4a3b-ba0d-8ddcaf9b50d7",
    "prId" : 30867,
    "prUrl" : "https://github.com/apache/spark/pull/30867#pullrequestreview-556090017",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8aaba8e4-5512-4748-9d80-deb72ac6b4d4",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Could you clarify that the difference between `array_funcs` and `collection_funcs` in this context?",
        "createdAt" : "2020-12-21T01:49:21Z",
        "updatedAt" : "2020-12-21T07:20:26Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "4e82580cdc1b44a1680631ad54121e327f37b9e0",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +54,58 @@  \"\"\",\n  since = \"1.1.0\",\n  group = \"array_funcs\")\ncase class CreateArray(children: Seq[Expression], useStringTypeWhenEmpty: Boolean)\n  extends Expression with NoThrow {"
  },
  {
    "id" : "68c1ed9d-9598-4569-a3b5-6d7654381efa",
    "prId" : 30570,
    "prUrl" : "https://github.com/apache/spark/pull/30570#pullrequestreview-543065599",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f3a88a91-9e2e-4ae2-96e5-80fe75daaf86",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Thanks for clarifying this only indicates the expression itself.",
        "createdAt" : "2020-12-02T17:20:43Z",
        "updatedAt" : "2020-12-02T17:20:43Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "36d280577ebcf888ca9ed91ca7f62a45da07db97",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +32,36 @@\n/**\n * Trait to indicate the expression does not throw an exception by itself when they are evaluated.\n * For example, UDFs, [[AssertTrue]], etc can throw an exception when they are executed.\n * In such case, it is necessary to call [[Expression.eval]], and the optimization rule should"
  },
  {
    "id" : "112acfc7-c5d7-4fdc-b2b8-5dacf27fae98",
    "prId" : 29795,
    "prUrl" : "https://github.com/apache/spark/pull/29795#pullrequestreview-491073908",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a1858232-030a-400f-be21-7133da65338c",
        "parentId" : null,
        "authorId" : "6fc88871-fca6-485c-a47e-5e17709c7b68",
        "body" : "@viirya I'm not quite done with this PR yet but I wanted to share it with you early because some of the changes I'm making in here may be helpful for #29587 (assuming this PR is accepted). Specifically, it would be possible to implement sorting of fields in a struct simply by: \r\n```\r\ncase class OrderStructFieldsByName() extends StructFieldsOperation {\r\n  override def apply(values: Seq[(StructField, Expression)]): Seq[(StructField, Expression)] =\r\n    values.sortBy { case (field, _) => field.name }\r\n}\r\n\r\nUpdateFields(structExpr, OrderStructFieldsByName() :: Nil)\r\n``` ",
        "createdAt" : "2020-09-18T00:30:15Z",
        "updatedAt" : "2020-09-29T20:56:48Z",
        "lastEditedBy" : "6fc88871-fca6-485c-a47e-5e17709c7b68",
        "tags" : [
        ]
      }
    ],
    "commit" : "7e51f35580db72fda11153d76caf232b83e617cd",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +556,560 @@   */\n  def apply(values: Seq[(StructField, Expression)]): Seq[(StructField, Expression)]\n}\n\n/**"
  },
  {
    "id" : "e8ea062c-e287-4058-9801-a837bed7ed41",
    "prId" : 29743,
    "prUrl" : "https://github.com/apache/spark/pull/29743#pullrequestreview-487712748",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b17663cd-dfe5-4075-a750-61756bdff1e9",
        "parentId" : null,
        "authorId" : "a8e23d47-3ae4-4385-848c-38a216d1bd08",
        "body" : "Did not find the jira for this. The first pull, where I saw this code was #2936\r\nGuessed the version from the date of that pull request.",
        "createdAt" : "2020-09-13T20:55:06Z",
        "updatedAt" : "2020-09-19T19:00:31Z",
        "lastEditedBy" : "a8e23d47-3ae4-4385-848c-38a216d1bd08",
        "tags" : [
        ]
      },
      {
        "id" : "6cee1422-37f3-46f9-a8e9-3a4ff8cb1a1a",
        "parentId" : "b17663cd-dfe5-4075-a750-61756bdff1e9",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "The decision looks okay to me.",
        "createdAt" : "2020-09-14T13:04:43Z",
        "updatedAt" : "2020-09-19T19:00:31Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "4162b41d325da3f9b732d835168a546916b50499",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +39,43 @@  \"\"\",\n  since = \"1.1.0\")\ncase class CreateArray(children: Seq[Expression], useStringTypeWhenEmpty: Boolean)\n  extends Expression {\n"
  },
  {
    "id" : "02494515-8e62-4585-a6a5-4a04d8d8a050",
    "prId" : 29322,
    "prUrl" : "https://github.com/apache/spark/pull/29322#pullrequestreview-466262091",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b551cfb9-a864-4df8-a3ab-860182f2a24a",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "does this need to extend `Unevaluable`?",
        "createdAt" : "2020-08-12T12:47:08Z",
        "updatedAt" : "2020-08-12T20:42:22Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "b55a105b-d3e7-4162-8ac5-81a8af8f3fe8",
        "parentId" : "b551cfb9-a864-4df8-a3ab-860182f2a24a",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ok I got it. We need it to be part of the `UpdateFields` expression tree, so that analyzer rules can transform and resolve it.",
        "createdAt" : "2020-08-12T13:07:25Z",
        "updatedAt" : "2020-08-12T20:42:22Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "96f04b2e-bbcd-4fd8-ad01-a4fae35bd0b6",
        "parentId" : "b551cfb9-a864-4df8-a3ab-860182f2a24a",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "We should add classdoc to explain it.",
        "createdAt" : "2020-08-12T13:07:54Z",
        "updatedAt" : "2020-08-12T20:42:22Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "f16c41c6-64d0-40d5-b5af-d85778f4b835",
        "parentId" : "b551cfb9-a864-4df8-a3ab-860182f2a24a",
        "authorId" : "6fc88871-fca6-485c-a47e-5e17709c7b68",
        "body" : "Done.",
        "createdAt" : "2020-08-12T20:42:34Z",
        "updatedAt" : "2020-08-12T20:42:34Z",
        "lastEditedBy" : "6fc88871-fca6-485c-a47e-5e17709c7b68",
        "tags" : [
        ]
      }
    ],
    "commit" : "2b0ac348c9ab5854a37e246a5c498d05095c103c",
    "line" : 39,
    "diffHunk" : "@@ -1,1 +562,566 @@ */\ncase class WithField(name: String, valExpr: Expression)\n  extends Unevaluable with StructFieldsOperation {\n\n  override def apply(exprs: Seq[(String, Expression)]): Seq[(String, Expression)] ="
  },
  {
    "id" : "bdb23985-9af3-4d78-a833-48ec2d3212e9",
    "prId" : 29322,
    "prUrl" : "https://github.com/apache/spark/pull/29322#pullrequestreview-466262537",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2ce17d36-fd8b-4e55-97f3-9f4898314c67",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "`case WithField(_, valExpr) => valExpr`",
        "createdAt" : "2020-08-12T12:48:07Z",
        "updatedAt" : "2020-08-12T20:42:22Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "749e3532-cfbf-40fe-9dac-a4316df82e2d",
        "parentId" : "2ce17d36-fd8b-4e55-97f3-9f4898314c67",
        "authorId" : "6fc88871-fca6-485c-a47e-5e17709c7b68",
        "body" : "This won't work. A working alternative is `case w: WithField => w` but I would prefer to leave it as-is (i.e. `case e: Expression => e`) because it is more future-proof. Let me know though if you don't think it's worth it to consider the future here for now. ",
        "createdAt" : "2020-08-12T20:43:16Z",
        "updatedAt" : "2020-08-12T20:43:16Z",
        "lastEditedBy" : "6fc88871-fca6-485c-a47e-5e17709c7b68",
        "tags" : [
        ]
      }
    ],
    "commit" : "2b0ac348c9ab5854a37e246a5c498d05095c103c",
    "line" : 91,
    "diffHunk" : "@@ -1,1 +610,614 @@\n  override def children: Seq[Expression] = structExpr +: fieldOps.collect {\n    case e: Expression => e\n  }\n"
  },
  {
    "id" : "d73dbf43-173f-405b-838c-bfaa55d4cab6",
    "prId" : 29322,
    "prUrl" : "https://github.com/apache/spark/pull/29322#pullrequestreview-466419194",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a7421941-4c76-4d28-8e93-58c0161a3d15",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "do we need to override it? It will not be called anyway.",
        "createdAt" : "2020-08-12T13:08:38Z",
        "updatedAt" : "2020-08-12T20:42:22Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "e10366ea-4ab8-4c34-b574-cf98456256e2",
        "parentId" : "a7421941-4c76-4d28-8e93-58c0161a3d15",
        "authorId" : "6fc88871-fca6-485c-a47e-5e17709c7b68",
        "body" : "I think we do have to override it.\r\n\r\nFor the following query: \r\n```\r\nsql(\"SELECT named_struct('a', 1, 'b', 2) struct_col\")\r\n.select($\"struct_col\".withField(\"c\", lit(3)).dropFields(\"b\").as(\"struct_col\"))\r\n.explain(true)\r\n```\r\n1. With overriding, here's how it shows up in the parsed logical plan: \r\n```\r\n'Project [update_fields(update_fields('struct_col, WithField(c, 3)), DropField(b)) AS struct_col#2]\r\n```\r\n2. Without overriding, here's how it shows up in the parsed logical plan (note that it's now lowercase and inconsistent with DropField): \r\n```\r\n'Project [update_fields(update_fields('struct_col, withfield(c, 3)), DropField(b)) AS struct_col#2]\r\n```\r\n3. Alternatively, we could also do this: \r\n```\r\n'Project [update_fields(update_fields('struct_col, with_field(c, 3)), drop_field(b)) AS struct_col#2]\r\n```\r\nWhich do you prefer? \r\n\r\n",
        "createdAt" : "2020-08-12T20:44:14Z",
        "updatedAt" : "2020-08-12T21:12:51Z",
        "lastEditedBy" : "6fc88871-fca6-485c-a47e-5e17709c7b68",
        "tags" : [
        ]
      },
      {
        "id" : "54c2c376-46d0-47cc-8d35-4f2181ec9874",
        "parentId" : "a7421941-4c76-4d28-8e93-58c0161a3d15",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "`WithField` is fine.",
        "createdAt" : "2020-08-13T03:25:32Z",
        "updatedAt" : "2020-08-13T03:25:33Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "2b0ac348c9ab5854a37e246a5c498d05095c103c",
    "line" : 57,
    "diffHunk" : "@@ -1,1 +580,584 @@  override def nullable: Boolean = throw new UnresolvedException(this, \"nullable\")\n\n  override def prettyName: String = \"WithField\"\n}\n"
  },
  {
    "id" : "1c77738e-6a23-43a3-8bde-0a2cbebb26e2",
    "prId" : 28633,
    "prUrl" : "https://github.com/apache/spark/pull/28633#pullrequestreview-417487389",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0a7bb3d1-5aea-40c5-b74c-f6eeb5a866ef",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Here, I took more conservative approach just by whitelisting. There are some cases that `named_struct` makes arguably more pretty when they are internally used. For example:\r\n\r\n```diff\r\n-| org.apache.spark.sql.catalyst.expressions.ZipWith | zip_with | SELECT zip_with(array(1, 2, 3), array('a', 'b', 'c'), (x, y) -> (y, x)) | struct<zip_with(array(1, 2, 3), array(a, b, c), lambdafunction(named_struct(y, namedlambdavariable(), x, namedlambdavariable()), namedlambdavariable(), namedlambdavariable())):array<struct<y:string,x:int>>> |\r\n+| org.apache.spark.sql.catalyst.expressions.ZipWith | zip_with | SELECT zip_with(array(1, 2, 3), array('a', 'b', 'c'), (x, y) -> (y, x)) | struct<zip_with(array(1, 2, 3), array(a, b, c), lambdafunction(struct(namedlambdavariable(), namedlambdavariable()), namedlambdavariable(), namedlambdavariable())):array<struct<y:string,x:int>>> |\r\n\r\n```",
        "createdAt" : "2020-05-25T06:42:14Z",
        "updatedAt" : "2020-05-26T00:11:34Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "8e1e0a2ea956697c46060b9c43a7203a541ca703",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +325,329 @@    })\n  }\n\n  /**\n   * Returns a named struct with a pretty SQL name. It will show the pretty SQL string"
  },
  {
    "id" : "fdd20be7-543c-47e3-a1ac-00cf489ef5e9",
    "prId" : 28633,
    "prUrl" : "https://github.com/apache/spark/pull/28633#pullrequestreview-417542550",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "98eb3f01-2533-4481-8b93-a592b80ecf42",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "nit tnohgh, we cannot reuse the `ExpressionInfo` of `CreateNameStruct` via reflection here?",
        "createdAt" : "2020-05-25T07:56:41Z",
        "updatedAt" : "2020-05-26T00:11:34Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "408d418f-0249-4fa6-8775-5971bf8486a4",
        "parentId" : "98eb3f01-2533-4481-8b93-a592b80ecf42",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Seems like it will need more changes than the current changes to reuse it because we should have a different description for `struct` specifically.",
        "createdAt" : "2020-05-25T08:22:08Z",
        "updatedAt" : "2020-05-26T00:11:34Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "8e1e0a2ea956697c46060b9c43a7203a541ca703",
    "line" : 44,
    "diffHunk" : "@@ -1,1 +342,346 @@  val registryEntry: (String, (ExpressionInfo, FunctionBuilder)) = {\n    val info: ExpressionInfo = new ExpressionInfo(\n      classOf[CreateNamedStruct].getCanonicalName,\n      null,\n      \"struct\","
  },
  {
    "id" : "06d89a77-95ea-4cc4-90a4-b54eeb96ac44",
    "prId" : 28633,
    "prUrl" : "https://github.com/apache/spark/pull/28633#pullrequestreview-417548718",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "75f549c2-01bc-431b-8650-b9f677911574",
        "parentId" : null,
        "authorId" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "body" : "Shouldn't you override prettyName as well? In general this seems to have been solved with either a mixin or at the Expression level.",
        "createdAt" : "2020-05-25T08:27:01Z",
        "updatedAt" : "2020-05-26T00:11:34Z",
        "lastEditedBy" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "tags" : [
        ]
      },
      {
        "id" : "1e3233ee-4f5b-4712-bc66-0b5719f3268f",
        "parentId" : "75f549c2-01bc-431b-8650-b9f677911574",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Yup, should be better to do that.",
        "createdAt" : "2020-05-25T08:32:14Z",
        "updatedAt" : "2020-05-26T00:11:34Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "8e1e0a2ea956697c46060b9c43a7203a541ca703",
    "line" : 67,
    "diffHunk" : "@@ -1,1 +455,459 @@  override def prettyName: String = getTagValue(FUNC_ALIAS).getOrElse(\"named_struct\")\n\n  override def sql: String = getTagValue(FUNC_ALIAS).map { alias =>\n    val childrenSQL = children.indices.filter(_ % 2 == 1).map(children(_).sql).mkString(\", \")\n    s\"$alias($childrenSQL)\""
  },
  {
    "id" : "41c1af32-1154-4d70-bd00-350201c8c4a9",
    "prId" : 28633,
    "prUrl" : "https://github.com/apache/spark/pull/28633#pullrequestreview-417762879",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "49b15481-8d88-46ba-998b-2900818fba0c",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "maybe better to leave a comment here and refer to `CreateStruct.create`: if there is an alias, it means this is the `struct` function and we should skip the auto-generated alias names in the SQL string.",
        "createdAt" : "2020-05-25T14:57:12Z",
        "updatedAt" : "2020-05-26T00:11:34Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "8e1e0a2ea956697c46060b9c43a7203a541ca703",
    "line" : 67,
    "diffHunk" : "@@ -1,1 +455,459 @@  override def prettyName: String = getTagValue(FUNC_ALIAS).getOrElse(\"named_struct\")\n\n  override def sql: String = getTagValue(FUNC_ALIAS).map { alias =>\n    val childrenSQL = children.indices.filter(_ % 2 == 1).map(children(_).sql).mkString(\", \")\n    s\"$alias($childrenSQL)\""
  },
  {
    "id" : "b3cacc5b-2a6b-4f2b-9cbe-9e0ef606ba3d",
    "prId" : 28631,
    "prUrl" : "https://github.com/apache/spark/pull/28631#pullrequestreview-417375904",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "05523d5f-2225-43ff-a7bc-e8639aa50596",
        "parentId" : null,
        "authorId" : "6fc88871-fca6-485c-a47e-5e17709c7b68",
        "body" : "thank you for fixing this. I remember a while back I wasted a few hours trying to find this mythical       `NamedStruct` class/object without success. ",
        "createdAt" : "2020-05-24T17:17:02Z",
        "updatedAt" : "2020-05-24T17:23:09Z",
        "lastEditedBy" : "6fc88871-fca6-485c-a47e-5e17709c7b68",
        "tags" : [
        ]
      }
    ],
    "commit" : "61945d4340a4160d064be9b1805c2c0195adc975",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +326,330 @@  val registryEntry: (String, (ExpressionInfo, FunctionBuilder)) = {\n    val info: ExpressionInfo = new ExpressionInfo(\n      getClass.getCanonicalName.stripSuffix(\"$\"),\n      null,\n      \"struct\","
  },
  {
    "id" : "9ca13461-11b5-44a3-8256-c5e66208aa28",
    "prId" : 28631,
    "prUrl" : "https://github.com/apache/spark/pull/28631#pullrequestreview-417414037",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8b2f1869-632a-4510-9319-b4d49a0ef6a1",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "hmm, is it actually a `CreateNamedStruct`?",
        "createdAt" : "2020-05-25T00:34:35Z",
        "updatedAt" : "2020-05-25T00:34:35Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "4c03e3af-a1d2-4daf-b621-10c71de0ad41",
        "parentId" : "8b2f1869-632a-4510-9319-b4d49a0ef6a1",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "I guess because `CreateStruct.apply` is the actual `FunctionBuilder`? I think either way seems fine to me. `CreateNamedStruct` sounds fine to me too. This class in `ExpressionInfo` isn't used anywhere in Spark if I am not mistaken so won't be a big deal.",
        "createdAt" : "2020-05-25T01:15:58Z",
        "updatedAt" : "2020-05-25T02:28:05Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "61945d4340a4160d064be9b1805c2c0195adc975",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +326,330 @@  val registryEntry: (String, (ExpressionInfo, FunctionBuilder)) = {\n    val info: ExpressionInfo = new ExpressionInfo(\n      getClass.getCanonicalName.stripSuffix(\"$\"),\n      null,\n      \"struct\","
  },
  {
    "id" : "eea4af97-853d-463e-998a-e19f578c2fd1",
    "prId" : 27657,
    "prUrl" : "https://github.com/apache/spark/pull/27657#pullrequestreview-363381994",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "40ddb5d9-1d4d-4ebd-abff-b955c89f6656",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "we need to override `stringArgs` to exclude the new `useStringTypeWhenEmpty` parameter, otherwise the EXPLAIN result changes.",
        "createdAt" : "2020-02-24T13:20:23Z",
        "updatedAt" : "2020-02-25T05:57:55Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "e2559060d8fd99078d9b25472c45072867531fe8",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +38,42 @@       [1,2,3]\n  \"\"\")\ncase class CreateArray(children: Seq[Expression], useStringTypeWhenEmpty: Boolean)\n  extends Expression {\n"
  },
  {
    "id" : "8518dbfd-623e-4ea7-b440-27c7b91766e1",
    "prId" : 27657,
    "prUrl" : "https://github.com/apache/spark/pull/27657#pullrequestreview-384374215",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "12ab8a09-7b9c-4869-ae96-5becff710293",
        "parentId" : null,
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "@iRakson When you update the code, do not forget update the PR description, which will be part of the commit message.",
        "createdAt" : "2020-03-31T03:12:12Z",
        "updatedAt" : "2020-03-31T03:12:13Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      }
    ],
    "commit" : "e2559060d8fd99078d9b25472c45072867531fe8",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +38,42 @@       [1,2,3]\n  \"\"\")\ncase class CreateArray(children: Seq[Expression], useStringTypeWhenEmpty: Boolean)\n  extends Expression {\n"
  },
  {
    "id" : "12c2ac71-fdb7-4a3f-b0c4-d956b0799bfb",
    "prId" : 27542,
    "prUrl" : "https://github.com/apache/spark/pull/27542#pullrequestreview-357353446",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a02a960f-1eff-43fb-a441-d49d95600667",
        "parentId" : null,
        "authorId" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "body" : "In `ArrayBasedMapBuilder`, we are explicitly asserting that `keyType` can't be `NullType`.  So assigning `NullType` here is causing test failures. \r\n@cloud-fan  ",
        "createdAt" : "2020-02-12T05:50:39Z",
        "updatedAt" : "2020-02-12T18:03:04Z",
        "lastEditedBy" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "tags" : [
        ]
      },
      {
        "id" : "e64796e8-65ae-4ee1-9e03-709827ad505c",
        "parentId" : "a02a960f-1eff-43fb-a441-d49d95600667",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Can we remove that asserting?",
        "createdAt" : "2020-02-12T06:09:00Z",
        "updatedAt" : "2020-02-12T18:03:04Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "02ab72d7-d161-4083-a4fb-2d54a1eb629c",
        "parentId" : "a02a960f-1eff-43fb-a441-d49d95600667",
        "authorId" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "body" : "In `ArrayBaseMapBuilder`, `Nulltype` is not handled for key. This causes following problem:\r\n```\r\nscala> sql(\"select map(null,2)\")\r\nres1: org.apache.spark.sql.DataFrame = [map(NULL, 2): map<null,int>]\r\n\r\nscala> sql(\"select map(null,2)\").collect\r\nscala.MatchError: NullType (of class org.apache.spark.sql.types.NullType$)\r\n  at org.apache.spark.sql.catalyst.util.TypeUtils$.getInterpretedOrdering(TypeUtils.scala:67)\r\n  at org.apache.spark.sql.catalyst.util.ArrayBasedMapBuilder.keyToIndex$lzycompute(ArrayBasedMapBuilder.scala:37)\r\n```  \r\n\r\n\r\nAfter removing the assertion we need to handle this.\r\n @cloud-fan  [#23124(comment)](https://github.com/apache/spark/pull/23124/commits/9df627465d9f9bcdde129baf1304035f082e5ab6?file-filters%5B%5D=.scala#r235929748)",
        "createdAt" : "2020-02-12T08:28:10Z",
        "updatedAt" : "2020-02-12T18:03:04Z",
        "lastEditedBy" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "tags" : [
        ]
      },
      {
        "id" : "99c6aefe-07f2-4b70-a076-eea76870a181",
        "parentId" : "a02a960f-1eff-43fb-a441-d49d95600667",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "yea we need to handle it. Let's add `NullType` to `case _: AtomicType | _: CalendarIntervalType if !keyType.isInstanceOf[BinaryType]`",
        "createdAt" : "2020-02-12T10:32:50Z",
        "updatedAt" : "2020-02-12T18:03:04Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "ae1b3681-909b-4001-b25d-549abc60378a",
        "parentId" : "a02a960f-1eff-43fb-a441-d49d95600667",
        "authorId" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "body" : "Yeah. I updated the PR using that approach only. All the Other review comments are handled as well.",
        "createdAt" : "2020-02-12T10:46:56Z",
        "updatedAt" : "2020-02-12T18:03:04Z",
        "lastEditedBy" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "tags" : [
        ]
      }
    ],
    "commit" : "e873527032ffaed583b211d81f2c9aafebe9fe07",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +176,180 @@    MapType(\n      keyType = TypeCoercion.findCommonTypeDifferentOnlyInNullFlags(keys.map(_.dataType))\n        .getOrElse(defaultElementType),\n      valueType = TypeCoercion.findCommonTypeDifferentOnlyInNullFlags(values.map(_.dataType))\n        .getOrElse(defaultElementType),"
  },
  {
    "id" : "bd9b5b49-927d-4dad-aaa7-268962130da8",
    "prId" : 27066,
    "prUrl" : "https://github.com/apache/spark/pull/27066#pullrequestreview-384932021",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "da39f960-5797-4a12-b295-4c6e97b9109d",
        "parentId" : null,
        "authorId" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "body" : "Can you put it in big if else block? Having return in the middle of function is fragile. ",
        "createdAt" : "2020-03-31T17:02:46Z",
        "updatedAt" : "2020-07-03T12:43:28Z",
        "lastEditedBy" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "tags" : [
        ]
      }
    ],
    "commit" : "4315e9244829cc41ffcf224f29f8fdcbcd88b981",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +561,565 @@\n  override def children: Seq[Expression] = structExpr +: valExprs\n\n  override def dataType: StructType = evalExpr.dataType.asInstanceOf[StructType]\n"
  },
  {
    "id" : "747c1bb0-ff69-4163-b281-cd27713da3ff",
    "prId" : 27066,
    "prUrl" : "https://github.com/apache/spark/pull/27066#pullrequestreview-387845605",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0aad937b-d35e-4dac-81bc-b45323eaa673",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "`override def foldable: Boolean = valExprs.forall(_.foldable)`?",
        "createdAt" : "2020-04-03T13:22:11Z",
        "updatedAt" : "2020-07-03T12:43:28Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "52b5961b-ea75-46ed-a962-02b9fb2f1468",
        "parentId" : "0aad937b-d35e-4dac-81bc-b45323eaa673",
        "authorId" : "6fc88871-fca6-485c-a47e-5e17709c7b68",
        "body" : "CMIIW but wouldn't it be more correct for it to be `override def foldable: Boolean = children.forall(_.foldable)?` My reasoning is that all of the children for this Expression should  be candidates for static evaluation. ",
        "createdAt" : "2020-04-05T18:13:53Z",
        "updatedAt" : "2020-07-03T12:43:28Z",
        "lastEditedBy" : "6fc88871-fca6-485c-a47e-5e17709c7b68",
        "tags" : [
        ]
      }
    ],
    "commit" : "4315e9244829cc41ffcf224f29f8fdcbcd88b981",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +548,552 @@    names: Seq[String],\n    valExprs: Seq[Expression]) extends Unevaluable {\n\n  assert(names.length == valExprs.length)\n"
  },
  {
    "id" : "e8be01be-ba21-4eae-8d7e-a4a4e938f1eb",
    "prId" : 27066,
    "prUrl" : "https://github.com/apache/spark/pull/27066#pullrequestreview-431943780",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "07589571-559a-4675-aba4-4c6a9a4f35bc",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "IIUC, now this expression can only add/replace top-level fields?",
        "createdAt" : "2020-06-16T12:49:23Z",
        "updatedAt" : "2020-07-03T12:43:28Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "1c3a72b3-f94f-4348-8a05-3cce9e7b0ce7",
        "parentId" : "07589571-559a-4675-aba4-4c6a9a4f35bc",
        "authorId" : "6fc88871-fca6-485c-a47e-5e17709c7b68",
        "body" : "Sorry I forgot to do this earlier but I've posted a comment now describing the changes I've made and their impact [here](https://github.com/apache/spark/pull/27066#issuecomment-645047815). \r\n\r\nYes, you are correct. The `WithFields` expression will now only add/replace top-level fields in a struct. It's just a programming exercise to use `WithFields` in conjunction with`GetStructField` to add/replace _nested_ fields in a struct. ",
        "createdAt" : "2020-06-16T22:47:46Z",
        "updatedAt" : "2020-07-03T12:43:28Z",
        "lastEditedBy" : "6fc88871-fca6-485c-a47e-5e17709c7b68",
        "tags" : [
        ]
      }
    ],
    "commit" : "4315e9244829cc41ffcf224f29f8fdcbcd88b981",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +542,546 @@\n/**\n * Adds/replaces field in struct by name.\n */\ncase class WithFields("
  },
  {
    "id" : "ea8d5ae1-fee2-4c36-a6ed-81ef15e7c358",
    "prId" : 27013,
    "prUrl" : "https://github.com/apache/spark/pull/27013#pullrequestreview-336628648",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b8cc711d-d38b-436b-88cd-4236eab03cba",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "When I go to confirm this `since` tag, I looked at the original PR #13990.\r\n\r\nThe author implemented codegen version actually, but did remove it based on the comment: https://github.com/apache/spark/pull/13990#discussion_r69660241\r\n\r\nI think the comment makes sense to me. To add or not codegen looks not a big deal. This implementation looks simple, anyway.\r\n\r\nI have no special option to add it or not. cc @cloud-fan ",
        "createdAt" : "2019-12-26T20:13:15Z",
        "updatedAt" : "2019-12-27T06:18:22Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "8b7979a1-b91c-48ef-8a49-04a5a3889d11",
        "parentId" : "b8cc711d-d38b-436b-88cd-4236eab03cba",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ah, I see. Thanks for the pointer. I have no strong opinion, too, so I'll leave it to the @cloud-fan descision. ",
        "createdAt" : "2019-12-26T22:42:19Z",
        "updatedAt" : "2019-12-27T06:18:22Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "61d9ed47ce70c8b068a2cfec8c6cd6b1bd3bd449",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +405,409 @@       {\"a\":null}\n  \"\"\",\n  since = \"2.0.1\")\n// scalastyle:on line.size.limit\ncase class StringToMap(text: Expression, pairDelim: Expression, keyValueDelim: Expression)"
  }
]