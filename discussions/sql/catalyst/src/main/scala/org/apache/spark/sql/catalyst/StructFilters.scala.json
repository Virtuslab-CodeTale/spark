[
  {
    "id" : "7d043804-1a2f-4b3e-9091-6a4533cfe703",
    "prId" : 27366,
    "prUrl" : "https://github.com/apache/spark/pull/27366#pullrequestreview-351666622",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5c4b5fef-7577-4519-bbd8-b5012e98c3a8",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Actually, the previous `requiredSchema` was more intuitive, but this one also good in this context.",
        "createdAt" : "2020-01-31T07:53:49Z",
        "updatedAt" : "2020-07-15T20:10:16Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "5fc3fab6-0013-4a99-91ba-195d28904605",
        "parentId" : "5c4b5fef-7577-4519-bbd8-b5012e98c3a8",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "The term `requiredSchema` makes sense in CSV datasource because it operates on 2 schemas: `dataSchema` is full schema of CSV records, and `requiredSchema` is requested by the upper layer. JSON datasource operates on only one schema which is `requiredSchema` in terms of CSV. JSON datatsource can do that because it parses input strings in streaming way, and can skip JSON fields are not presented the schema. Comparing to JSON, CSV parses entire input that's why it needs full schema.\r\n\r\n`StructFilters` needs a schema to bind filters attributes to actual position in a row. required or not required schema doesn't matter for `StructFilters`.",
        "createdAt" : "2020-01-31T10:32:50Z",
        "updatedAt" : "2020-07-15T20:10:16Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "48dae339-d211-434f-88e5-49c09a81d423",
        "parentId" : "5c4b5fef-7577-4519-bbd8-b5012e98c3a8",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Yep. I agree.",
        "createdAt" : "2020-01-31T17:41:18Z",
        "updatedAt" : "2020-07-15T20:10:16Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "57524d615680ac6126495ea8fc2e51000156f8ff",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +34,38 @@ * @param pushedFilters The pushed down source filters. The filters should refer to\n *                      the fields of the provided schema.\n * @param schema The required schema of records from datasource files.\n */\nabstract class StructFilters(pushedFilters: Seq[sources.Filter], schema: StructType) {"
  },
  {
    "id" : "395c1e97-41b0-4e93-9e7a-02a2143cc370",
    "prId" : 27366,
    "prUrl" : "https://github.com/apache/spark/pull/27366#pullrequestreview-351883354",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ca62cefa-d894-4964-adaa-91b992243511",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Can we have some case sensitive test case for this code path?",
        "createdAt" : "2020-01-31T20:43:39Z",
        "updatedAt" : "2020-07-15T20:10:16Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "67466660-a556-4b2a-94b3-4469024b4c5e",
        "parentId" : "ca62cefa-d894-4964-adaa-91b992243511",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Added a test which I run w/ and w/o PR's changes. So, this PR doesn't impact on the behavior.",
        "createdAt" : "2020-02-01T12:56:26Z",
        "updatedAt" : "2020-07-15T20:10:16Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "57524d615680ac6126495ea8fc2e51000156f8ff",
    "line" : 72,
    "diffHunk" : "@@ -1,1 +70,74 @@  private def toRef(attr: String): Option[BoundReference] = {\n    // The names have been normalized and case sensitivity is not a concern here.\n    schema.getFieldIndex(attr).map { index =>\n      val field = schema(index)\n      BoundReference(index, field.dataType, field.nullable)"
  },
  {
    "id" : "6e8c0135-b142-4c8d-92c9-978d91d2cd7b",
    "prId" : 27366,
    "prUrl" : "https://github.com/apache/spark/pull/27366#pullrequestreview-351868250",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f26de632-2c1f-4fd7-9684-4e4b4c4fac46",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "This name might need renaming to avoid misleading because `zip` doesn't mean `zip and headOption` in general.",
        "createdAt" : "2020-01-31T20:45:59Z",
        "updatedAt" : "2020-07-15T20:10:16Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "585c7605-7b75-455f-bdc5-e94b5830efcf",
        "parentId" : "f26de632-2c1f-4fd7-9684-4e4b4c4fac46",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Semantically this function does what `zip` should do. The problem is `zip` for Option returns `Iterable[(A, B)]` instead of `Option[(A, B)]`. I cannot agree that the name could mislead.",
        "createdAt" : "2020-02-01T06:09:00Z",
        "updatedAt" : "2020-07-15T20:10:16Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "57524d615680ac6126495ea8fc2e51000156f8ff",
    "line" : 96,
    "diffHunk" : "@@ -1,1 +94,98 @@  }\n\n  private def zip[A, B](a: Option[A], b: Option[B]): Option[(A, B)] = {\n    a.zip(b).headOption\n  }"
  },
  {
    "id" : "f51d0321-9b45-420e-84cd-b719f01ed9d1",
    "prId" : 27366,
    "prUrl" : "https://github.com/apache/spark/pull/27366#pullrequestreview-444809719",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0d67cb9d-f6a2-4300-8c36-b6a0a6e5780a",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "shall we add a comment to say that, the name has been normalized and case sensitivity is not a concern here.",
        "createdAt" : "2020-07-06T12:10:38Z",
        "updatedAt" : "2020-07-15T20:10:16Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "6c12b021-db64-4436-927c-0a9d296faf6d",
        "parentId" : "0d67cb9d-f6a2-4300-8c36-b6a0a6e5780a",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Added a comment",
        "createdAt" : "2020-07-08T14:15:01Z",
        "updatedAt" : "2020-07-15T20:10:16Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "57524d615680ac6126495ea8fc2e51000156f8ff",
    "line" : 82,
    "diffHunk" : "@@ -1,1 +80,84 @@  private def checkFilterRefs(filter: sources.Filter, fieldNames: Set[String]): Boolean = {\n    // The names have been normalized and case sensitivity is not a concern here.\n    filter.references.forall(fieldNames.contains)\n  }\n"
  },
  {
    "id" : "9992b8ae-0f0a-49a3-8e09-28c3a1cf142a",
    "prId" : 27366,
    "prUrl" : "https://github.com/apache/spark/pull/27366#pullrequestreview-445781937",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3b02bb76-e5a0-47ad-9043-ba46ee6047eb",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "maybe we can add the same comment here: https://github.com/apache/spark/pull/27366/files#diff-2e3ca97141aa3554960dacea3d58c606R77",
        "createdAt" : "2020-07-09T16:30:48Z",
        "updatedAt" : "2020-07-15T20:10:16Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "57524d615680ac6126495ea8fc2e51000156f8ff",
    "line" : 72,
    "diffHunk" : "@@ -1,1 +70,74 @@  private def toRef(attr: String): Option[BoundReference] = {\n    // The names have been normalized and case sensitivity is not a concern here.\n    schema.getFieldIndex(attr).map { index =>\n      val field = schema(index)\n      BoundReference(index, field.dataType, field.nullable)"
  }
]