[
  {
    "id" : "98429e3e-4bb2-482a-a107-0b5d7cd0ffbf",
    "prId" : 32761,
    "prUrl" : "https://github.com/apache/spark/pull/32761#pullrequestreview-676530119",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "675f2acd-9448-4a16-ad35-46e65f0a4b16",
        "parentId" : null,
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "Since this is only used in `TypeCoercion.scala`, shall we keep it there?",
        "createdAt" : "2021-06-04T08:42:35Z",
        "updatedAt" : "2021-06-04T08:42:36Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "bb4ebf44-cd23-45f4-b7f0-afadb619bb90",
        "parentId" : "675f2acd-9448-4a16-ad35-46e65f0a4b16",
        "authorId" : "8b518862-583d-43a2-a10e-b33ef1b6d824",
        "body" : "(1) we probably don't want to expose markRuleAsIneffective to the outside of trees? If it can be used arbitrarily in a rule, the behavior would be harder to reason.\r\n(2) resolveOperatorUpWithPruning can potentially call it.  I can do it in a separate PR.",
        "createdAt" : "2021-06-04T16:57:47Z",
        "updatedAt" : "2021-06-04T16:57:47Z",
        "lastEditedBy" : "8b518862-583d-43a2-a10e-b33ef1b6d824",
        "tags" : [
        ]
      },
      {
        "id" : "3961fcde-830e-4079-b0c8-434872e0d03e",
        "parentId" : "675f2acd-9448-4a16-ad35-46e65f0a4b16",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "ok",
        "createdAt" : "2021-06-04T17:43:40Z",
        "updatedAt" : "2021-06-04T17:43:40Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "6c9cd28ac10163cc4878a13b47e43b6c0af92465",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +567,571 @@   *               varying initial state for different invocations.\n   */\n  def transformUpWithBeforeAndAfterRuleOnChildren(\n      cond: BaseType => Boolean, ruleId: RuleId = UnknownRuleId)(\n    rule: PartialFunction[(BaseType, BaseType), BaseType]): BaseType = {"
  },
  {
    "id" : "35d89db7-0002-4b3a-a81c-36c6253dc92c",
    "prId" : 32557,
    "prUrl" : "https://github.com/apache/spark/pull/32557#pullrequestreview-661916719",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0d22e735-68dc-4acf-9e32-f1c7ba218fad",
        "parentId" : null,
        "authorId" : "6b53d819-334a-4038-a2b8-66582f8c76a7",
        "body" : "The `TreeNode` inherits `Product`, I'm wondering if only one check should be kept.\r\n\r\nMaybe this change is redundant, the following one which changes `case p if p.productIterator.exists(_.isInstanceOf[TreeNode[_]]) => true` is the key one.\r\n\r\n",
        "createdAt" : "2021-05-18T02:13:02Z",
        "updatedAt" : "2021-05-18T02:20:45Z",
        "lastEditedBy" : "6b53d819-334a-4038-a2b8-66582f8c76a7",
        "tags" : [
        ]
      },
      {
        "id" : "3dd0ca2a-68d8-480c-9534-b8c2491c6ed2",
        "parentId" : "0d22e735-68dc-4acf-9e32-f1c7ba218fad",
        "authorId" : "cd552757-c9c9-412a-9565-ff23341cdb66",
        "body" : "Nice catch, I think we can remove the TreeNode check. The code change is for Seq,  without this Seq[Product] will be written as null.",
        "createdAt" : "2021-05-18T10:37:11Z",
        "updatedAt" : "2021-05-18T10:37:11Z",
        "lastEditedBy" : "cd552757-c9c9-412a-9565-ff23341cdb66",
        "tags" : [
        ]
      }
    ],
    "commit" : "c307dd0c0c65ceefec69c9612ede4e8ee7670515",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +1001,1005 @@    case t: Seq[_] if t.forall(_.isInstanceOf[Partitioning]) ||\n      t.forall(_.isInstanceOf[DataType]) ||\n      t.forall(_.isInstanceOf[Product]) =>\n      JArray(t.map(parseToJson).toList)\n    case t: Seq[_] if t.length > 0 && t.head.isInstanceOf[String] =>"
  },
  {
    "id" : "fc0ff9bb-1459-49db-84c5-698d1d4bf16c",
    "prId" : 32249,
    "prUrl" : "https://github.com/apache/spark/pull/32249#pullrequestreview-639674506",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b248c448-728f-43fe-a457-0bf5fd28f5ee",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "is double \"this\" a typo?",
        "createdAt" : "2021-04-20T08:32:59Z",
        "updatedAt" : "2021-04-20T10:32:55Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "7c52bd01-ba0e-4edd-9871-5c238db9cf74",
        "parentId" : "b248c448-728f-43fe-a457-0bf5fd28f5ee",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "it's two sentences ðŸ˜‚",
        "createdAt" : "2021-04-20T08:43:38Z",
        "updatedAt" : "2021-04-20T10:32:55Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "b44429dd4e1e5b70bb922cb279b489337af12886",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +76,80 @@  def withOrigin[A](o: Origin)(f: => A): A = {\n    // remember the previous one so it can be reset to this\n    // this way withOrigin can be recursive\n    val previous = get\n    set(o)"
  },
  {
    "id" : "0db994d4-6343-4f67-af9b-77ee5618de79",
    "prId" : 32060,
    "prUrl" : "https://github.com/apache/spark/pull/32060#pullrequestreview-629692656",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ad7c6ff9-d147-443d-a4d9-9b153caf879a",
        "parentId" : null,
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "ditto",
        "createdAt" : "2021-04-07T06:50:24Z",
        "updatedAt" : "2021-04-12T00:32:43Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "431fa7a4-2f6b-4eb0-b8ad-454efaf35881",
        "parentId" : "ad7c6ff9-d147-443d-a4d9-9b153caf879a",
        "authorId" : "8b518862-583d-43a2-a10e-b33ef1b6d824",
        "body" : "The same reason as above.",
        "createdAt" : "2021-04-07T07:47:58Z",
        "updatedAt" : "2021-04-12T00:32:43Z",
        "lastEditedBy" : "8b518862-583d-43a2-a10e-b33ef1b6d824",
        "tags" : [
        ]
      }
    ],
    "commit" : "718a92a743e731a698473b9170ace55187755b55",
    "line" : 45,
    "diffHunk" : "@@ -1,1 +108,112 @@    val bits: BitSet = new BitSet(TreePattern.maxId)\n    // Propagate node pattern bits\n    val nodePatternIterator = nodePatterns.iterator\n    while (nodePatternIterator.hasNext) {\n      bits.set(nodePatternIterator.next().id)"
  },
  {
    "id" : "4d318cba-2b3c-4d78-bfb1-cfd0fce98387",
    "prId" : 32060,
    "prUrl" : "https://github.com/apache/spark/pull/32060#pullrequestreview-629693761",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "19e6228a-47e4-4f4d-b411-1f064d54711c",
        "parentId" : null,
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "ditto",
        "createdAt" : "2021-04-07T06:50:29Z",
        "updatedAt" : "2021-04-12T00:32:43Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "fea5c547-c970-498d-8fa7-cec0236b15e1",
        "parentId" : "19e6228a-47e4-4f4d-b411-1f064d54711c",
        "authorId" : "8b518862-583d-43a2-a10e-b33ef1b6d824",
        "body" : "The same reason as above.",
        "createdAt" : "2021-04-07T07:49:13Z",
        "updatedAt" : "2021-04-12T00:32:43Z",
        "lastEditedBy" : "8b518862-583d-43a2-a10e-b33ef1b6d824",
        "tags" : [
        ]
      }
    ],
    "commit" : "718a92a743e731a698473b9170ace55187755b55",
    "line" : 50,
    "diffHunk" : "@@ -1,1 +113,117 @@    }\n    // Propagate children's pattern bits\n    val childIterator = children.iterator\n    while (childIterator.hasNext) {\n      bits.union(childIterator.next().treePatternBits)"
  },
  {
    "id" : "83d3e8ae-4dbf-472e-b394-463107493c55",
    "prId" : 32030,
    "prUrl" : "https://github.com/apache/spark/pull/32030#pullrequestreview-631669375",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "43826742-daed-4238-b594-ac695841b7fc",
        "parentId" : null,
        "authorId" : "8b518862-583d-43a2-a10e-b33ef1b6d824",
        "body" : "Does it make sense to call legacyWithNewChildren or use its code in the default implementation so that subclasses do not have to call legacyWithNewChildren in withNewChildrenInternal?",
        "createdAt" : "2021-04-08T17:17:43Z",
        "updatedAt" : "2021-04-09T10:49:42Z",
        "lastEditedBy" : "8b518862-583d-43a2-a10e-b33ef1b6d824",
        "tags" : [
        ]
      },
      {
        "id" : "61cdf530-fca8-4442-9af8-f42319cdf73c",
        "parentId" : "43826742-daed-4238-b594-ac695841b7fc",
        "authorId" : "def2dd9f-ce27-41ce-8156-f8225ddc68a9",
        "body" : "Having a default implementation will lead to people who add new expressions don't implement `withNewChildrenInternal` and we again be back to the same situation having many slow `withNewChildren` implementations, so I prefer to make have it like this to enforce `withNewChildrenInternal` implementation. Actually, even now, there are two expressions added to the master and I need to update this PR to implement the `withNewChildrenInternal` for them. The `legacyWithNewChildren` is here for a transition period, we have some expressions that are a bit hard to write `withNewChildrenInternal` for and probably need some refactoring. The goal is to remove `legacyWithNewChildren` altogether at some point.",
        "createdAt" : "2021-04-08T17:29:16Z",
        "updatedAt" : "2021-04-09T10:49:42Z",
        "lastEditedBy" : "def2dd9f-ce27-41ce-8156-f8225ddc68a9",
        "tags" : [
        ]
      },
      {
        "id" : "38d52c4c-b642-4a0e-ba90-cf55f6f76d92",
        "parentId" : "43826742-daed-4238-b594-ac695841b7fc",
        "authorId" : "8b518862-583d-43a2-a10e-b33ef1b6d824",
        "body" : "Ok, makes sense. Thanks for the elaboration!",
        "createdAt" : "2021-04-08T17:36:26Z",
        "updatedAt" : "2021-04-09T10:49:42Z",
        "lastEditedBy" : "8b518862-583d-43a2-a10e-b33ef1b6d824",
        "tags" : [
        ]
      }
    ],
    "commit" : "5bc0ff7e88ec11caa06b3c786bcdea9a01ddfcaf",
    "line" : 41,
    "diffHunk" : "@@ -1,1 +284,288 @@  }\n\n  protected def withNewChildrenInternal(newChildren: IndexedSeq[BaseType]): BaseType\n\n  /**"
  }
]