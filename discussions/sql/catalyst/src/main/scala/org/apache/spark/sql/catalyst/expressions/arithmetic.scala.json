[
  {
    "id" : "7841e21a-14f6-4020-a35f-962ee2a08fe2",
    "prId" : 32260,
    "prUrl" : "https://github.com/apache/spark/pull/32260#pullrequestreview-640718861",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2b9eba57-6473-4852-ab38-193df95a6309",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Is this simply `left.dataType == LongType`? For `Divide`, the child is either double or decimal, so won't hit this branch.\r\n\r\nUnder the hood, what we really want to handle is `Long.MinValue / -1`, so check `left.dataType == LongType` looks reasonable.",
        "createdAt" : "2021-04-21T07:26:44Z",
        "updatedAt" : "2021-04-21T07:26:45Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "be036c2b-f419-4b5b-9482-b6a5b5e2dbff",
        "parentId" : "2b9eba57-6473-4852-ab38-193df95a6309",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "No, Remainder's left can be Long as well",
        "createdAt" : "2021-04-21T07:36:24Z",
        "updatedAt" : "2021-04-21T07:36:24Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "64f1431195e666227094a456f9c4d20fff181004",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +406,410 @@\n  // Whether we should check overflow or not in ANSI mode.\n  protected def checkDivideOverflow: Boolean = false\n\n  override def nullable: Boolean = true"
  },
  {
    "id" : "5bf78fca-4e1b-40db-9fdf-45fa47627037",
    "prId" : 31840,
    "prUrl" : "https://github.com/apache/spark/pull/31840#pullrequestreview-612880343",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1ce07ba7-445c-47ae-b069-8af9996ec4e7",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "shall we put this error message in `QueryExecutionErrors` like `unaryMinusCauseOverflowError`?",
        "createdAt" : "2021-03-16T06:10:52Z",
        "updatedAt" : "2021-03-16T06:10:52Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "ff16782e86da3f16c032dbb4fac7f531aa023f48",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +62,66 @@           |$javaType $originValue = ($javaType)($eval);\n           |if ($originValue == $javaBoxedType.MIN_VALUE) {\n           |  throw new ArithmeticException(\"${dataType.simpleString} overflow\");\n           |}\n           |${ev.value} = ($javaType)(-($originValue));"
  },
  {
    "id" : "8c4a06a5-1736-4ea5-85df-950d3fc38fd1",
    "prId" : 31836,
    "prUrl" : "https://github.com/apache/spark/pull/31836#pullrequestreview-613889194",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "890d7620-b82e-4115-816d-bef053d75d05",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "No test for this code path?",
        "createdAt" : "2021-03-17T00:08:57Z",
        "updatedAt" : "2021-03-17T03:20:28Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "9e09c225-0c09-4e24-bb15-84d9448bee09",
        "parentId" : "890d7620-b82e-4115-816d-bef053d75d05",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "You are right. Added test for this.",
        "createdAt" : "2021-03-17T03:19:23Z",
        "updatedAt" : "2021-03-17T03:20:28Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "f38a2c4b3bb738c3ec1671ee7189569a198faacf",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +169,173 @@          |  throw QueryExecutionErrors.unaryMinusCauseOverflowError($eval);\n          |} else if ($eval < 0) {\n          |  ${ev.value} = ($javaType)-$eval;\n          |} else {\n          |  ${ev.value} = $eval;"
  },
  {
    "id" : "dd154897-9d64-4b40-b0f7-7569dfae0dc6",
    "prId" : 31836,
    "prUrl" : "https://github.com/apache/spark/pull/31836#pullrequestreview-613821978",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "23e490ab-15fe-4af2-bbce-4935b5552b2c",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "ditto",
        "createdAt" : "2021-03-17T00:09:02Z",
        "updatedAt" : "2021-03-17T03:20:28Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "f38a2c4b3bb738c3ec1671ee7189569a198faacf",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +171,175 @@          |  ${ev.value} = ($javaType)-$eval;\n          |} else {\n          |  ${ev.value} = $eval;\n          |}\n          |\"\"\".stripMargin)"
  },
  {
    "id" : "1790a77b-c4fd-414c-b084-6b1dddad12ff",
    "prId" : 31836,
    "prUrl" : "https://github.com/apache/spark/pull/31836#pullrequestreview-613927610",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6f3c51ef-3996-4322-ad71-ce762a46a5a2",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Does the interpreted code has the same behaviour?",
        "createdAt" : "2021-03-17T05:08:44Z",
        "updatedAt" : "2021-03-17T05:08:45Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "f908bf2c-cc1f-429a-b36e-fe5ffe38da57",
        "parentId" : "6f3c51ef-3996-4322-ad71-ce762a46a5a2",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "Yes, it happens on `private lazy val numeric = TypeUtils.getNumeric(dataType, failOnError)`\r\nIt will use exact version of `negate` eventually. \r\nOtherwise, it won't pass unit tests.",
        "createdAt" : "2021-03-17T05:15:24Z",
        "updatedAt" : "2021-03-17T05:15:24Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "f38a2c4b3bb738c3ec1671ee7189569a198faacf",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +146,150 @@  since = \"1.2.0\",\n  group = \"math_funcs\")\ncase class Abs(child: Expression, failOnError: Boolean = SQLConf.get.ansiEnabled)\n  extends UnaryExpression with ExpectsInputTypes with NullIntolerant {\n"
  },
  {
    "id" : "d880800a-21f5-4133-98bc-b1dc4a123688",
    "prId" : 29882,
    "prUrl" : "https://github.com/apache/spark/pull/29882#pullrequestreview-497451976",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a4ad6760-4751-4f09-aec2-17da92be865e",
        "parentId" : null,
        "authorId" : "cce1c782-0596-44b6-8b99-6b77d2cca53c",
        "body" : "make sure test covered with codegen onï¼Œ FYI",
        "createdAt" : "2020-09-28T12:16:44Z",
        "updatedAt" : "2020-10-29T08:16:03Z",
        "lastEditedBy" : "cce1c782-0596-44b6-8b99-6b77d2cca53c",
        "tags" : [
        ]
      }
    ],
    "commit" : "11188c356113b651435508b9137b5c084d4d990f",
    "line" : 235,
    "diffHunk" : "@@ -1,1 +396,400 @@        $javaType ${ev.value} = ${CodeGenerator.defaultValue(dataType)};\n        if ($isZero) {\n          $divByZero\n        } else {\n          ${eval1.code}"
  },
  {
    "id" : "af7cd149-4fad-48e3-be89-9cd7da1578ff",
    "prId" : 27628,
    "prUrl" : "https://github.com/apache/spark/pull/27628#pullrequestreview-361263468",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "818803bb-3b03-478b-b05a-f784aca643ae",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can we just add a `private val returnLong = SQLConf.get.integralDivideReturnLong` in the class body? Then the config value is fixed when the expression is created. And it can be serialized to executors.\r\n\r\nThe spark Expression constructor is kind of exposed to end users when they call functions in SQL. BTW `Cast` already use a `val` to store config values.\r\n",
        "createdAt" : "2020-02-19T05:54:22Z",
        "updatedAt" : "2020-02-19T05:54:23Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "16fcb61e-d64f-44cb-b9b3-b4d6a0899f92",
        "parentId" : "818803bb-3b03-478b-b05a-f784aca643ae",
        "authorId" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "body" : "That can potentially change value every time you transform the tree.",
        "createdAt" : "2020-02-19T11:56:44Z",
        "updatedAt" : "2020-02-19T11:56:45Z",
        "lastEditedBy" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "tags" : [
        ]
      },
      {
        "id" : "12a369a2-33db-4f54-bafb-71c3139208f7",
        "parentId" : "818803bb-3b03-478b-b05a-f784aca643ae",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "or how about we create 2 expressions `IntegralDivide` and `IntegralDivideReturnLong`? I'm just worried about we allow end users to specify the `returnLong` parameter which becomes an API.",
        "createdAt" : "2020-02-19T12:01:37Z",
        "updatedAt" : "2020-02-19T12:01:37Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "eff0cfd2-02ff-4185-91b6-372c98cfd093",
        "parentId" : "818803bb-3b03-478b-b05a-f784aca643ae",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "> I'm just worried about we allow end users to specify the returnLong parameter which becomes an API.\r\n\r\nWe don't allow that:\r\n```sql\r\nSELECT div(3, 2, false);\r\n```\r\nfails with:\r\n```\r\nInvalid number of arguments for function div. Expected: 2; Found: 3; line 1 pos 7\r\norg.apache.spark.sql.AnalysisException: Invalid number of arguments for function div. Expected: 2; Found: 3; line 1 pos 7\r\n\tat org.apache.spark.sql.catalyst.analysis.FunctionRegistry$.$anonfun$expression$7(FunctionRegistry.scala:618)\r\n\tat scala.Option.getOrElse(Option.scala:189)\r\n\tat org.apache.spark.sql.catalyst.analysis.FunctionRegistry$.$anonfun$expression$4(FunctionRegistry.scala:602)\r\n\tat org.apache.spark.sql.catalyst.analysis.SimpleFunctionRegistry.lookupFunction(FunctionRegistry.scala:121)\r\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.lookupFunction(SessionCatalog.scala:1418)\r\n```\r\nI ran the command on the PR changes.",
        "createdAt" : "2020-02-19T13:01:55Z",
        "updatedAt" : "2020-02-19T13:01:55Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "8836b79d-8010-4dbe-b1d3-75d62ba3e617",
        "parentId" : "818803bb-3b03-478b-b05a-f784aca643ae",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "so the non-expression parameter doesn't count? Then I'm fine with it.",
        "createdAt" : "2020-02-19T13:04:35Z",
        "updatedAt" : "2020-02-19T13:04:35Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "0868aa47-aca1-4a74-8626-d9304b03d659",
        "parentId" : "818803bb-3b03-478b-b05a-f784aca643ae",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Yes, we count only expressions, see https://github.com/apache/spark/blob/919d551ddbf7575abe7fe47d4bbba62164d6d845/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/FunctionRegistry.scala#L601-L602",
        "createdAt" : "2020-02-19T16:55:31Z",
        "updatedAt" : "2020-02-19T16:55:32Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "ebeec388f5b6f2a1b3b3cb5e972a7262ee463aef",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +407,411 @@    left: Expression,\n    right: Expression,\n    returnLong: Boolean) extends DivModLike {\n\n  def this(left: Expression, right: Expression) = {"
  },
  {
    "id" : "a9d852c2-0118-4594-96ba-9b604b5d9463",
    "prId" : 27628,
    "prUrl" : "https://github.com/apache/spark/pull/27628#pullrequestreview-361267234",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "518a089b-9f2c-4285-acb2-5e5337c8ab38",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "shall we define `unapply` as well? Most of the time we don't care about the `returnLong` paramter. When we do, we should write `case e @ IntegralDivide(left, right) if e.returnLong`.",
        "createdAt" : "2020-02-19T13:05:41Z",
        "updatedAt" : "2020-02-19T13:05:41Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "251c17cf-ae68-44c1-86df-9825d61be75e",
        "parentId" : "518a089b-9f2c-4285-acb2-5e5337c8ab38",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "There is only one place where we unapply `IntegralDivide`. It is here https://github.com/apache/spark/pull/27628/files#diff-8e1575bb706d6f7e8b5ea0b175eaeafcR178 . And `returnLong` is not checked, it is just extracted and copy-pasted.",
        "createdAt" : "2020-02-19T16:58:09Z",
        "updatedAt" : "2020-02-19T16:58:09Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "e1221afa-bdc9-4602-8553-ed1cacf1073e",
        "parentId" : "518a089b-9f2c-4285-acb2-5e5337c8ab38",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "If I define `unapply`, it will be not used. Not sure that is is needed.",
        "createdAt" : "2020-02-19T16:59:55Z",
        "updatedAt" : "2020-02-19T21:04:49Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "ebeec388f5b6f2a1b3b3cb5e972a7262ee463aef",
    "line" : 47,
    "diffHunk" : "@@ -1,1 +463,467 @@    new IntegralDivide(left, right)\n  }\n}\n\n@ExpressionDescription("
  }
]