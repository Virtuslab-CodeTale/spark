[
  {
    "id" : "ba016c8b-88f4-4747-9832-10c0fa17dc97",
    "prId" : 32577,
    "prUrl" : "https://github.com/apache/spark/pull/32577#pullrequestreview-661663031",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9050e429-6e8e-4b7b-8644-df8b3407ec7a",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Can we switch the above two lines to support numeric set in a more natural way?\r\n```scala\r\n.sorted\r\n.map(elem => Literal(elem, child.dataType).toString)\r\n```",
        "createdAt" : "2021-05-18T04:11:02Z",
        "updatedAt" : "2021-05-18T04:11:02Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "4c7e4113-78d4-4d8c-b17e-0e41f39f00c6",
        "parentId" : "9050e429-6e8e-4b7b-8644-df8b3407ec7a",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "We cannot because `Seq[Any]` cannot be sorted;\r\n```\r\n[error] /Users/maropu/Repositories/spark/spark-master/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/predicates.scala:648:8: No implicit Ordering defined for Any.\r\n[error]       .sorted\r\n```",
        "createdAt" : "2021-05-18T05:03:13Z",
        "updatedAt" : "2021-05-18T05:03:13Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "c7a16854-ed0b-4580-98a4-cf17fb9cbc1a",
        "parentId" : "9050e429-6e8e-4b7b-8644-df8b3407ec7a",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Got it. Thank you for checking.",
        "createdAt" : "2021-05-18T05:58:19Z",
        "updatedAt" : "2021-05-18T05:58:19Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "30945c3e9ca143457447ef3b8a7d51a69a4a07a9",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +549,553 @@      .map(elem => Literal(elem, child.dataType).toString)\n      // Sort elements for deterministic behaviours\n      .sorted\n      .mkString(\", \")\n    s\"$child INSET $listString\""
  },
  {
    "id" : "d9bdf945-a3dc-496f-9c81-66a2f5b1fe41",
    "prId" : 32577,
    "prUrl" : "https://github.com/apache/spark/pull/32577#pullrequestreview-661615007",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d054423f-5f95-4e2a-96c8-0bd88fdbfd92",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Ditto. Can we do `sort` first?",
        "createdAt" : "2021-05-18T04:12:16Z",
        "updatedAt" : "2021-05-18T04:12:17Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "30945c3e9ca143457447ef3b8a7d51a69a4a07a9",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +647,651 @@      .map(elem => Literal(elem, child.dataType).sql)\n      // Sort elements for deterministic behaviours\n      .sorted\n      .mkString(\", \")\n    s\"($valueSQL IN ($listSQL))\""
  },
  {
    "id" : "00588b38-5c28-4fe3-8dff-87a0da158e9b",
    "prId" : 29101,
    "prUrl" : "https://github.com/apache/spark/pull/29101#pullrequestreview-449728803",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fb5bffb7-65df-48e9-8412-a8b0560bc956",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "`a1 and b1 is convertible, , while a2 and b2 is not` -> `the output set is a1 and b1`?",
        "createdAt" : "2020-07-16T10:41:20Z",
        "updatedAt" : "2020-07-17T18:03:34Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "d37c21c25992b29649b6358a02ed483670d32014",
    "line" : 141,
    "diffHunk" : "@@ -1,1 +228,232 @@    // condition: (a1 AND a2) OR (b1 AND b2),\n    // outputSet: AttributeSet(a1, b1)\n    // a1 and b1 is convertible, while a2 and b2 is not.\n    // The predicate can be converted as\n    // (a1 OR b1) AND (a1 OR b2) AND (a2 OR b1) AND (a2 OR b2)"
  },
  {
    "id" : "2a642e02-d9bf-4b43-b99d-7d8d3add1949",
    "prId" : 29101,
    "prUrl" : "https://github.com/apache/spark/pull/29101#pullrequestreview-450030780",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "58ac926d-4f2c-4d08-8327-4072508a46c7",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "`it contains all possible constraints from condition` -> `it's a precondition to satisfy the given condition`",
        "createdAt" : "2020-07-16T16:18:03Z",
        "updatedAt" : "2020-07-17T18:03:34Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "01f7b684-4bb0-4d15-aeab-a0ca4e02b441",
        "parentId" : "58ac926d-4f2c-4d08-8327-4072508a46c7",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "We have to specify the result contains the maximum contrainsts here. Otherwise, any of `a`/`b`/`a&&b`  is  a condition that satisfy `a && b && c && d`  with outputSet as `Set(a,b,c,d)`",
        "createdAt" : "2020-07-16T16:47:09Z",
        "updatedAt" : "2020-07-17T18:03:34Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "d37c21c25992b29649b6358a02ed483670d32014",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +204,208 @@  /**\n   * Returns a filter that its reference is a subset of `outputSet` and it contains the maximum\n   * constraints from `condition`. This is used for predicate pushdown.\n   * When there is no such filter, `None` is returned.\n   */"
  },
  {
    "id" : "80b0087d-b250-4ecd-b29f-e4ad35785a2d",
    "prId" : 29075,
    "prUrl" : "https://github.com/apache/spark/pull/29075#pullrequestreview-447676258",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "45adbaeb-4bdf-4d68-ae57-310cb3632cca",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "nit: `A method to group expressions for reducing the size of pushed down predicates and corresponding codegen`?",
        "createdAt" : "2020-07-13T23:22:06Z",
        "updatedAt" : "2020-07-13T23:22:30Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "6fe106ce84e83641d66d572c45050b25761bbf3d",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +210,214 @@   * @param condition Condition to be converted into CNF.\n   * @param groupExpsFunc A method for grouping intermediate results so that the final result can be\n   *                      shorter.\n   * @return the CNF result as sequence of disjunctive expressions. If the number of expressions\n   *         exceeds threshold on converting `Or`, `Seq.empty` is returned."
  },
  {
    "id" : "8ee55bd4-769a-4779-bdc0-34b718ef36a3",
    "prId" : 28805,
    "prUrl" : "https://github.com/apache/spark/pull/28805#pullrequestreview-429497738",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "838aa0c8-a38d-4c81-b076-23585c61d74f",
        "parentId" : null,
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "Too many duplicate code here. Maybe you can organize code:\r\n```scala\r\n  def conjunctiveNormalFormAndGroupExpsByQualifier(condition: Expression): Seq[Expression] = {\r\n    conjunctiveNormalForm(condition,\r\n      (expressions: Seq[Expression]) =>\r\n        expressions.groupBy(_.references.map(_.qualifier)).map(_._2.reduceLeft(And)).toSeq)\r\n  }\r\n\r\n  def conjunctiveNormalFormAndGroupExpsByReference(condition: Expression): Seq[Expression] = {\r\n    conjunctiveNormalForm(condition,\r\n      (expressions: Seq[Expression]) =>\r\n        expressions.groupBy(_.references).map(_._2.reduceLeft(And)).toSeq)\r\n  }\r\n\r\n  def conjunctiveNormalForm(\r\n      condition: Expression,\r\n      groupExpsFunc: Seq[Expression] => Seq[Expression] = _.toSeq): Seq[Expression] = {\r\n    val postOrderNodes = postOrderTraversal(condition)\r\n    val resultStack = new mutable.Stack[Seq[Expression]]\r\n    val maxCnfNodeCount = SQLConf.get.maxCnfNodeCount\r\n    // Bottom up approach to get CNF of sub-expressions\r\n    while (postOrderNodes.nonEmpty) {\r\n      val cnf = postOrderNodes.pop() match {\r\n        case _: And =>\r\n          val right = resultStack.pop()\r\n          val left = resultStack.pop()\r\n          left ++ right\r\n        case _: Or =>\r\n          val right = groupExpsFunc(resultStack.pop())\r\n          val left = groupExpsFunc(resultStack.pop())\r\n          // Stop the loop whenever the result exceeds the `maxCnfNodeCount`\r\n          if (left.size * right.size > maxCnfNodeCount) {\r\n            logInfo(s\"As the result size exceeds the threshold $maxCnfNodeCount. \" +\r\n              \"The CNF conversion is skipped and returning Seq.empty now. To avoid this, you can \" +\r\n              s\"raise the limit ${SQLConf.MAX_CNF_NODE_COUNT.key}.\")\r\n            return Seq.empty\r\n          } else {\r\n            for { x <- left; y <- right } yield Or(x, y)\r\n          }\r\n        case other => other :: Nil\r\n      }\r\n      resultStack.push(cnf)\r\n    }\r\n    if (resultStack.length != 1) {\r\n      logWarning(\"The length of CNF conversion result stack is supposed to be 1. There might \" +\r\n        \"be something wrong with CNF conversion.\")\r\n      return Seq.empty\r\n    }\r\n    resultStack.top\r\n  }\r\n```",
        "createdAt" : "2020-06-12T06:43:35Z",
        "updatedAt" : "2020-07-01T08:39:56Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      }
    ],
    "commit" : "e2777c99144f91b463924530a0a89e6f1a39ab66",
    "line" : 59,
    "diffHunk" : "@@ -1,1 +283,287 @@        expressions.groupBy(e => AttributeSet(e.references)).map(_._2.reduceLeft(And)).toSeq)\n  }\n\n  /**\n   * Iterative post order traversal over a binary tree built by And/Or clauses with two stacks."
  },
  {
    "id" : "8440493b-b7db-4b03-9fdd-a5312391ef79",
    "prId" : 28805,
    "prUrl" : "https://github.com/apache/spark/pull/28805#pullrequestreview-440478325",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "92a12dc8-fb27-4476-90e0-32748694aaa7",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "nit format:\r\n```\r\n    conjunctiveNormalForm(condition, (expressions: Seq[Expression]) =>\r\n        expressions.groupBy(_.references.map(_.qualifier)).map(_._2.reduceLeft(And)).toSeq)\r\n```",
        "createdAt" : "2020-07-01T00:52:11Z",
        "updatedAt" : "2020-07-01T08:39:56Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "e2777c99144f91b463924530a0a89e6f1a39ab66",
    "line" : 39,
    "diffHunk" : "@@ -1,1 +263,267 @@  def CNFWithGroupExpressionsByQualifier(condition: Expression): Seq[Expression] = {\n    conjunctiveNormalForm(condition, (expressions: Seq[Expression]) =>\n        expressions.groupBy(_.references.map(_.qualifier)).map(_._2.reduceLeft(And)).toSeq)\n  }\n"
  },
  {
    "id" : "9fd76599-49aa-446b-a11b-ff7b879b852f",
    "prId" : 28733,
    "prUrl" : "https://github.com/apache/spark/pull/28733#pullrequestreview-426965671",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "63c1d45e-b51c-45a5-b2ee-fc36754a7978",
        "parentId" : null,
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "For  a test case  `dt = '1' OR (dt = '2' AND id = 1)` passed to   conjunctiveNormalForm, still return   `dt = '1' OR (dt = '2' AND id = 1)`. \r\n\r\nSee qualifier when groupby ,   they are\r\n```\r\nList(List(spark_catalog, default, t))\r\nList(List(spark_catalog, default, t))\r\n```\r\n",
        "createdAt" : "2020-06-08T07:18:27Z",
        "updatedAt" : "2020-06-11T00:53:20Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "507c04c0-86d3-426a-97ae-8916c4b65a62",
        "parentId" : "63c1d45e-b51c-45a5-b2ee-fc36754a7978",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "I think we can try \r\n```\r\nexpressions.groupBy(_.references.flatMap(_.qualifier).toSet).map(_._2.reduceLeft(And)).toSeq\r\n```\r\nI will update this PR later",
        "createdAt" : "2020-06-08T07:38:26Z",
        "updatedAt" : "2020-06-11T00:53:20Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "d1e2e0e6-f49f-4b59-9e25-6af925994f98",
        "parentId" : "63c1d45e-b51c-45a5-b2ee-fc36754a7978",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> ```\r\n> expressions.groupBy(_.references.flatMap(_.qualifier).toSet).map(_._2.reduceLeft(And)).toSeq\r\n> ```\r\n\r\nNot work,  just\r\n```\r\nexpressions.groupBy(_.references).map(_._2.reduceLeft(And)).toSeq\r\n```",
        "createdAt" : "2020-06-08T07:54:53Z",
        "updatedAt" : "2020-06-11T00:53:20Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "b13ec6c6-95ee-4025-b20a-73d0372ea6d9",
        "parentId" : "63c1d45e-b51c-45a5-b2ee-fc36754a7978",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "The qualifier is the table name which is able to be used for aggregating more expressions",
        "createdAt" : "2020-06-08T08:15:55Z",
        "updatedAt" : "2020-06-11T00:53:20Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "f3f66274-46c8-4a84-9f90-194ef96142d2",
        "parentId" : "63c1d45e-b51c-45a5-b2ee-fc36754a7978",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> The qualifier is the table name which is able to be used for aggregating more expressions\r\n\r\nGot the point, you did this for split condition to join children, I want convert scan predicate condition to optimize scan predicate. ",
        "createdAt" : "2020-06-08T08:35:14Z",
        "updatedAt" : "2020-06-11T00:53:20Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "92664ada-7f80-4ebf-beed-56b481840a31",
        "parentId" : "63c1d45e-b51c-45a5-b2ee-fc36754a7978",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "I think this PR is complex enough. Let's keep this part in this way for now.",
        "createdAt" : "2020-06-09T09:33:45Z",
        "updatedAt" : "2020-06-11T00:53:20Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "dd684098-04af-425f-8550-3a25b4f407b8",
        "parentId" : "63c1d45e-b51c-45a5-b2ee-fc36754a7978",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "Yea, I  will raise pr for other problem base on your code and change a little  after your pr merged.",
        "createdAt" : "2020-06-09T09:36:43Z",
        "updatedAt" : "2020-06-11T00:53:20Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "b42ce1dde86069a74ebbda44a1729cde39c2672d",
    "line" : 74,
    "diffHunk" : "@@ -1,1 +252,256 @@  private def groupExpressionsByQualifier(expressions: Seq[Expression]): Seq[Expression] = {\n    expressions.groupBy(_.references.map(_.qualifier)).map(_._2.reduceLeft(And)).toSeq\n  }\n\n  /**"
  },
  {
    "id" : "1829456b-eb60-4f65-9e6d-2361ce0e6bd5",
    "prId" : 28733,
    "prUrl" : "https://github.com/apache/spark/pull/28733#pullrequestreview-428392589",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f5b10638-48f7-446f-899e-9f38d9115d59",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Based on  the the `@return` statement above, how about `conjunctiveNormalForm ` -> `convertToDisjunctiveExpressions`?",
        "createdAt" : "2020-06-10T14:16:10Z",
        "updatedAt" : "2020-06-11T00:53:20Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "e031e8fa-1f8b-494c-aa4a-15e33e81f966",
        "parentId" : "f5b10638-48f7-446f-899e-9f38d9115d59",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "well, let me remove the word `Disjunctive` to avoid misunderstanding.",
        "createdAt" : "2020-06-10T20:12:17Z",
        "updatedAt" : "2020-06-11T00:53:20Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "b42ce1dde86069a74ebbda44a1729cde39c2672d",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +212,216 @@   *         exceeds threshold on converting `Or`, `Seq.empty` is returned.\n   */\n  def conjunctiveNormalForm(condition: Expression): Seq[Expression] = {\n    val postOrderNodes = postOrderTraversal(condition)\n    val resultStack = new mutable.Stack[Seq[Expression]]"
  },
  {
    "id" : "d9356c50-7866-4c57-8157-d53a9212258f",
    "prId" : 28733,
    "prUrl" : "https://github.com/apache/spark/pull/28733#pullrequestreview-428089943",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2f9cbf87-b7fe-4e73-b5ca-2671e111d090",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "`the same references.` -> `the same table references.`?",
        "createdAt" : "2020-06-10T14:26:23Z",
        "updatedAt" : "2020-06-11T00:53:20Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "b42ce1dde86069a74ebbda44a1729cde39c2672d",
    "line" : 46,
    "diffHunk" : "@@ -1,1 +224,228 @@          left ++ right\n        case _: Or =>\n          // For each side, there is no need to expand predicates of the same references.\n          // So here we can aggregate predicates of the same qualifier as one single predicate,\n          // for reducing the size of pushed down predicates and corresponding codegen."
  },
  {
    "id" : "3eeb098a-6ae7-40c8-8517-cc96216f3b6b",
    "prId" : 28733,
    "prUrl" : "https://github.com/apache/spark/pull/28733#pullrequestreview-428089943",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "17b15245-bc35-4816-aa2d-6450ceea1fde",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Could we print some messages here by `logInfo` just like `WholeStageCodegenExec `? https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/WholeStageCodegenExec.scala#L729-L733",
        "createdAt" : "2020-06-10T14:28:33Z",
        "updatedAt" : "2020-06-11T00:53:20Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "b42ce1dde86069a74ebbda44a1729cde39c2672d",
    "line" : 52,
    "diffHunk" : "@@ -1,1 +230,234 @@          val left = groupExpressionsByQualifier(resultStack.pop())\n          // Stop the loop whenever the result exceeds the `maxCnfNodeCount`\n          if (left.size * right.size > maxCnfNodeCount) {\n            logInfo(s\"As the result size exceeds the threshold $maxCnfNodeCount. \" +\n              \"The CNF conversion is skipped and returning Seq.empty now. To avoid this, you can \" +"
  },
  {
    "id" : "ae2d1915-120e-495e-b04b-3b4d085d12db",
    "prId" : 28343,
    "prUrl" : "https://github.com/apache/spark/pull/28343#pullrequestreview-401521616",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "49759f8f-7be4-4aa5-bbca-cd4fd8846bda",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "this converts the internal value to external value, and then `Literal.apply` converts external value to internal value.\r\n\r\nCan we just do `Literal(elem, child.dataType).sql`?",
        "createdAt" : "2020-04-28T05:20:39Z",
        "updatedAt" : "2020-04-28T05:20:39Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "c0654b07-204c-4559-b496-2d2a5800f3da",
        "parentId" : "49759f8f-7be4-4aa5-bbca-cd4fd8846bda",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "@cloud-fan No, Literal fails on UTF8String value, see https://github.com/apache/spark/pull/28328#discussion_r414566719",
        "createdAt" : "2020-04-28T06:01:20Z",
        "updatedAt" : "2020-04-28T06:01:21Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "6a3f45fd-cf56-4dbd-ac6d-6e24daa16086",
        "parentId" : "49759f8f-7be4-4aa5-bbca-cd4fd8846bda",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Another problem is https://github.com/apache/spark/pull/28328#discussion_r415256811",
        "createdAt" : "2020-04-28T06:05:46Z",
        "updatedAt" : "2020-04-28T06:05:46Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "0bf0f009-1538-4b71-b1e4-b68895ff22e6",
        "parentId" : "49759f8f-7be4-4aa5-bbca-cd4fd8846bda",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "So, the problem is Literal requires external types but elem has internal Catalyst's type",
        "createdAt" : "2020-04-28T06:06:52Z",
        "updatedAt" : "2020-04-28T06:06:52Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "d46c177b4cfe191ed73ec319886084f4b482b784",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +522,526 @@    val valueSQL = child.sql\n    val listSQL = hset.toSeq\n      .map(elem => Literal(convertToScala(elem, child.dataType)).sql)\n      .mkString(\", \")\n    s\"($valueSQL IN ($listSQL))\""
  },
  {
    "id" : "b1bc9628-55e2-4ec5-b41f-185cfa93b09e",
    "prId" : 28328,
    "prUrl" : "https://github.com/apache/spark/pull/28328#pullrequestreview-400639828",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4120fb08-f2ab-4e65-948b-43a93a8a1ea4",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Matching internal Catalyst's types to external types is ambiguous. For example,\r\nLong -> Long\r\nLong -> Timestamp\r\n\r\nAlso type of child can be unknown when InSet has to know Catalyst's type of hset elements.\r\n\r\n`hsetElemType` is needed to eliminate the ambiguity",
        "createdAt" : "2020-04-26T08:48:11Z",
        "updatedAt" : "2020-04-27T10:37:01Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "3425e6c8-1b54-4a83-b218-c6b841e8dfe0",
        "parentId" : "4120fb08-f2ab-4e65-948b-43a93a8a1ea4",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Do you think we can make this `Option[DataType]` because only a few things are ambiguous?",
        "createdAt" : "2020-04-26T19:21:14Z",
        "updatedAt" : "2020-04-27T10:37:01Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "9a90d2e5-dbbe-4790-bf1d-9729f7806505",
        "parentId" : "4120fb08-f2ab-4e65-948b-43a93a8a1ea4",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "We can but if a caller passes None, `InSet` will be not able to infer elem types when `child.dataType` is `NullType` like in this case. `dataType` returns `NullType` if `child` is `PrettyAttribute`.",
        "createdAt" : "2020-04-26T20:15:46Z",
        "updatedAt" : "2020-04-27T10:37:01Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "904d17c9-b896-4900-9ddf-6b79a7d1d3a8",
        "parentId" : "4120fb08-f2ab-4e65-948b-43a93a8a1ea4",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "when `hsetElemType` can be different from `child.dataType`?",
        "createdAt" : "2020-04-27T05:19:30Z",
        "updatedAt" : "2020-04-27T10:37:01Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "e4d4bb86-ca24-4c7c-9b1f-417f746f3b94",
        "parentId" : "4120fb08-f2ab-4e65-948b-43a93a8a1ea4",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "When InSet is created from isInCollection, in that case `child.dataType` is `NullType`. For example, it is NullType in the test https://github.com/apache/spark/pull/28328/files#diff-aa655ba249e00d2591b21cf6a360cf82R886 because child is PrettyAttribute when the `sql` method is called.",
        "createdAt" : "2020-04-27T05:31:08Z",
        "updatedAt" : "2020-04-27T10:37:01Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "dd79d798-33ed-49d5-9b9a-d21cb53d0b28",
        "parentId" : "4120fb08-f2ab-4e65-948b-43a93a8a1ea4",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "And `InSet.sql()` is called from `Dataset.select` _.named:\r\n```scala\r\nProject(untypedCols.map(_.named), logicalPlan)\r\n```\r\nThe `named` method calls `toPrettySQL(expr)`:\r\n```scala\r\ncase expr: Expression => Alias(expr, toPrettySQL(expr))()\r\n```\r\nThe `toPrettySQL` method calls `sql`:\r\n```scala\r\ndef toPrettySQL(e: Expression): String = usePrettyExpression(e).sql\r\n```",
        "createdAt" : "2020-04-27T05:42:45Z",
        "updatedAt" : "2020-04-27T10:37:01Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "4bc0e269df9320e9bb9244afb58b6d1fbbf0e95e",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +430,434 @@    child: Expression,\n    hset: Set[Any],\n    hsetElemType: DataType) extends UnaryExpression with Predicate {\n\n  require(hset != null, \"hset could not be null\")"
  },
  {
    "id" : "525c756d-8152-467d-882d-86811deea3b4",
    "prId" : 26604,
    "prUrl" : "https://github.com/apache/spark/pull/26604#pullrequestreview-319501832",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dfbb48a3-76cb-4dd9-868a-015ad363f426",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "It seems reasonable because we renamed `Predicate => BasePredicate` before.",
        "createdAt" : "2019-11-20T04:20:48Z",
        "updatedAt" : "2019-11-20T07:50:42Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "164507ce26ddcf20e9c970cccf7746cc78a6119d",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +35,39 @@ * A base class for generated/interpreted predicate\n */\nabstract class BasePredicate {\n  def eval(r: InternalRow): Boolean\n"
  },
  {
    "id" : "d35fc516-e3e7-4e92-aa43-27dcc39e7b5b",
    "prId" : 26604,
    "prUrl" : "https://github.com/apache/spark/pull/26604#pullrequestreview-319508270",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "344aa881-902c-4feb-b6d3-5ed165de8397",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "do we still need `InterpretedPredicate` for creating interpreted Predicate specifically?\r\n",
        "createdAt" : "2019-11-20T04:36:10Z",
        "updatedAt" : "2019-11-20T07:50:42Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "780947e2-58de-41f3-a398-9a6bb1859010",
        "parentId" : "344aa881-902c-4feb-b6d3-5ed165de8397",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ur, I see. too verbose, so I'll remove it. Thanks!",
        "createdAt" : "2019-11-20T04:51:25Z",
        "updatedAt" : "2019-11-20T07:50:42Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "164507ce26ddcf20e9c970cccf7746cc78a6119d",
    "line" : 41,
    "diffHunk" : "@@ -1,1 +68,72 @@ * The factory object for `BasePredicate`.\n */\nobject Predicate extends CodeGeneratorWithInterpretedFallback[Expression, BasePredicate] {\n\n  override protected def createCodeGeneratedObject(in: Expression): BasePredicate = {"
  },
  {
    "id" : "7c4b470f-f018-4fad-8cc8-80d3c820620a",
    "prId" : 26604,
    "prUrl" : "https://github.com/apache/spark/pull/26604#pullrequestreview-319554376",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "83fba6a1-0dc1-41e6-8632-32761a89ca68",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "We can add a method `def createInterpreted...` for places that want to use interpreted predicates.",
        "createdAt" : "2019-11-20T06:10:27Z",
        "updatedAt" : "2019-11-20T07:50:42Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "c8019ae7-d461-45f7-a9ea-81b90b47502f",
        "parentId" : "83fba6a1-0dc1-41e6-8632-32761a89ca68",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Yea. ok.",
        "createdAt" : "2019-11-20T06:11:31Z",
        "updatedAt" : "2019-11-20T07:50:42Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "164507ce26ddcf20e9c970cccf7746cc78a6119d",
    "line" : 59,
    "diffHunk" : "@@ -1,1 +86,90 @@    createObject(bindReference(e, inputSchema))\n  }\n\n  /**\n   * Returns a BasePredicate for a given bound Expression."
  },
  {
    "id" : "3ddaa023-9256-4c83-a084-663e4a77b326",
    "prId" : 25806,
    "prUrl" : "https://github.com/apache/spark/pull/25806#pullrequestreview-288988304",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "eadb3edb-1563-41e9-b368-c06867459ce9",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "We don't need to compute `caseBranches`, too, if hset is empty?\r\n```\r\n    val valueGen = child.genCode(ctx)\r\n    val switchCode = if (hset.isEmpty) {\r\n      val caseValuesGen = hset.filter(_ != null).map(Literal(_).genCode(ctx))\r\n      val caseBranches = caseValuesGen.map(literal =>\r\n        code\"\"\"\r\n          case ${literal.value}:\r\n            ${ev.value} = true;\r\n            break;\r\n       \"\"\")\r\n\r\n      code\"\"\"\r\n        switch (${valueGen.value}) {\r\n          ${caseBranches.mkString(\"\\n\")}\r\n          default:\r\n            ${ev.isNull} = $hasNull;\r\n        }\r\n       \"\"\"\r\n    } else {\r\n      s\"${ev.isNull} = $hasNull;\"\r\n    }\r\n```",
        "createdAt" : "2019-09-17T02:02:47Z",
        "updatedAt" : "2019-09-17T02:02:47Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "21cbfecd-1e67-4d80-a75b-485c30fc6aa9",
        "parentId" : "eadb3edb-1563-41e9-b368-c06867459ce9",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "btw, can we fold this expr in the optimizer when hset is empty?",
        "createdAt" : "2019-09-17T02:04:18Z",
        "updatedAt" : "2019-09-17T02:04:18Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "897dae53-5750-4783-9ae3-8840a76d8c8e",
        "parentId" : "eadb3edb-1563-41e9-b368-c06867459ce9",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "if `hset` is empty, the computation of `caseBranches` is noop, right?",
        "createdAt" : "2019-09-17T02:07:58Z",
        "updatedAt" : "2019-09-17T02:07:58Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "62b4ac09-0f38-4668-b9d2-0cf72e8fe017",
        "parentId" : "eadb3edb-1563-41e9-b368-c06867459ce9",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This is a special case. Usually `InSet` wouldn't have empty set, as we have a threshold to convert `In` to `Inset`.",
        "createdAt" : "2019-09-17T02:09:53Z",
        "updatedAt" : "2019-09-17T02:09:53Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "baee98de-a54b-4ed7-a513-305f40a21ac1",
        "parentId" : "eadb3edb-1563-41e9-b368-c06867459ce9",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ur, I see.",
        "createdAt" : "2019-09-17T02:18:56Z",
        "updatedAt" : "2019-09-17T02:18:56Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "5ad7538300ce7a15e0262846d89c0d274ed2db6c",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +458,462 @@       \"\"\")\n\n    val switchCode = if (caseBranches.size > 0) {\n      code\"\"\"\n        switch (${valueGen.value}) {"
  }
]