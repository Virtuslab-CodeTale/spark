[
  {
    "id" : "ba016c8b-88f4-4747-9832-10c0fa17dc97",
    "prId" : 32577,
    "prUrl" : "https://github.com/apache/spark/pull/32577#pullrequestreview-661663031",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9050e429-6e8e-4b7b-8644-df8b3407ec7a",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Can we switch the above two lines to support numeric set in a more natural way?\r\n```scala\r\n.sorted\r\n.map(elem => Literal(elem, child.dataType).toString)\r\n```",
        "createdAt" : "2021-05-18T04:11:02Z",
        "updatedAt" : "2021-05-18T04:11:02Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "4c7e4113-78d4-4d8c-b17e-0e41f39f00c6",
        "parentId" : "9050e429-6e8e-4b7b-8644-df8b3407ec7a",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "We cannot because `Seq[Any]` cannot be sorted;\r\n```\r\n[error] /Users/maropu/Repositories/spark/spark-master/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/predicates.scala:648:8: No implicit Ordering defined for Any.\r\n[error]       .sorted\r\n```",
        "createdAt" : "2021-05-18T05:03:13Z",
        "updatedAt" : "2021-05-18T05:03:13Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "c7a16854-ed0b-4580-98a4-cf17fb9cbc1a",
        "parentId" : "9050e429-6e8e-4b7b-8644-df8b3407ec7a",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Got it. Thank you for checking.",
        "createdAt" : "2021-05-18T05:58:19Z",
        "updatedAt" : "2021-05-18T05:58:19Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "30945c3e9ca143457447ef3b8a7d51a69a4a07a9",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +549,553 @@      .map(elem => Literal(elem, child.dataType).toString)\n      // Sort elements for deterministic behaviours\n      .sorted\n      .mkString(\", \")\n    s\"$child INSET $listString\""
  },
  {
    "id" : "d9bdf945-a3dc-496f-9c81-66a2f5b1fe41",
    "prId" : 32577,
    "prUrl" : "https://github.com/apache/spark/pull/32577#pullrequestreview-661615007",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d054423f-5f95-4e2a-96c8-0bd88fdbfd92",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Ditto. Can we do `sort` first?",
        "createdAt" : "2021-05-18T04:12:16Z",
        "updatedAt" : "2021-05-18T04:12:17Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "30945c3e9ca143457447ef3b8a7d51a69a4a07a9",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +647,651 @@      .map(elem => Literal(elem, child.dataType).sql)\n      // Sort elements for deterministic behaviours\n      .sorted\n      .mkString(\", \")\n    s\"($valueSQL IN ($listSQL))\""
  },
  {
    "id" : "00588b38-5c28-4fe3-8dff-87a0da158e9b",
    "prId" : 29101,
    "prUrl" : "https://github.com/apache/spark/pull/29101#pullrequestreview-449728803",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fb5bffb7-65df-48e9-8412-a8b0560bc956",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "`a1 and b1 is convertible, , while a2 and b2 is not` -> `the output set is a1 and b1`?",
        "createdAt" : "2020-07-16T10:41:20Z",
        "updatedAt" : "2020-07-17T18:03:34Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "d37c21c25992b29649b6358a02ed483670d32014",
    "line" : 141,
    "diffHunk" : "@@ -1,1 +228,232 @@    // condition: (a1 AND a2) OR (b1 AND b2),\n    // outputSet: AttributeSet(a1, b1)\n    // a1 and b1 is convertible, while a2 and b2 is not.\n    // The predicate can be converted as\n    // (a1 OR b1) AND (a1 OR b2) AND (a2 OR b1) AND (a2 OR b2)"
  },
  {
    "id" : "2a642e02-d9bf-4b43-b99d-7d8d3add1949",
    "prId" : 29101,
    "prUrl" : "https://github.com/apache/spark/pull/29101#pullrequestreview-450030780",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "58ac926d-4f2c-4d08-8327-4072508a46c7",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "`it contains all possible constraints from condition` -> `it's a precondition to satisfy the given condition`",
        "createdAt" : "2020-07-16T16:18:03Z",
        "updatedAt" : "2020-07-17T18:03:34Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "01f7b684-4bb0-4d15-aeab-a0ca4e02b441",
        "parentId" : "58ac926d-4f2c-4d08-8327-4072508a46c7",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "We have to specify the result contains the maximum contrainsts here. Otherwise, any of `a`/`b`/`a&&b`  is  a condition that satisfy `a && b && c && d`  with outputSet as `Set(a,b,c,d)`",
        "createdAt" : "2020-07-16T16:47:09Z",
        "updatedAt" : "2020-07-17T18:03:34Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "d37c21c25992b29649b6358a02ed483670d32014",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +204,208 @@  /**\n   * Returns a filter that its reference is a subset of `outputSet` and it contains the maximum\n   * constraints from `condition`. This is used for predicate pushdown.\n   * When there is no such filter, `None` is returned.\n   */"
  },
  {
    "id" : "80b0087d-b250-4ecd-b29f-e4ad35785a2d",
    "prId" : 29075,
    "prUrl" : "https://github.com/apache/spark/pull/29075#pullrequestreview-447676258",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "45adbaeb-4bdf-4d68-ae57-310cb3632cca",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "nit: `A method to group expressions for reducing the size of pushed down predicates and corresponding codegen`?",
        "createdAt" : "2020-07-13T23:22:06Z",
        "updatedAt" : "2020-07-13T23:22:30Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "6fe106ce84e83641d66d572c45050b25761bbf3d",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +210,214 @@   * @param condition Condition to be converted into CNF.\n   * @param groupExpsFunc A method for grouping intermediate results so that the final result can be\n   *                      shorter.\n   * @return the CNF result as sequence of disjunctive expressions. If the number of expressions\n   *         exceeds threshold on converting `Or`, `Seq.empty` is returned."
  },
  {
    "id" : "8ee55bd4-769a-4779-bdc0-34b718ef36a3",
    "prId" : 28805,
    "prUrl" : "https://github.com/apache/spark/pull/28805#pullrequestreview-429497738",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "838aa0c8-a38d-4c81-b076-23585c61d74f",
        "parentId" : null,
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "Too many duplicate code here. Maybe you can organize code:\r\n```scala\r\n  def conjunctiveNormalFormAndGroupExpsByQualifier(condition: Expression): Seq[Expression] = {\r\n    conjunctiveNormalForm(condition,\r\n      (expressions: Seq[Expression]) =>\r\n        expressions.groupBy(_.references.map(_.qualifier)).map(_._2.reduceLeft(And)).toSeq)\r\n  }\r\n\r\n  def conjunctiveNormalFormAndGroupExpsByReference(condition: Expression): Seq[Expression] = {\r\n    conjunctiveNormalForm(condition,\r\n      (expressions: Seq[Expression]) =>\r\n        expressions.groupBy(_.references).map(_._2.reduceLeft(And)).toSeq)\r\n  }\r\n\r\n  def conjunctiveNormalForm(\r\n      condition: Expression,\r\n      groupExpsFunc: Seq[Expression] => Seq[Expression] = _.toSeq): Seq[Expression] = {\r\n    val postOrderNodes = postOrderTraversal(condition)\r\n    val resultStack = new mutable.Stack[Seq[Expression]]\r\n    val maxCnfNodeCount = SQLConf.get.maxCnfNodeCount\r\n    // Bottom up approach to get CNF of sub-expressions\r\n    while (postOrderNodes.nonEmpty) {\r\n      val cnf = postOrderNodes.pop() match {\r\n        case _: And =>\r\n          val right = resultStack.pop()\r\n          val left = resultStack.pop()\r\n          left ++ right\r\n        case _: Or =>\r\n          val right = groupExpsFunc(resultStack.pop())\r\n          val left = groupExpsFunc(resultStack.pop())\r\n          // Stop the loop whenever the result exceeds the `maxCnfNodeCount`\r\n          if (left.size * right.size > maxCnfNodeCount) {\r\n            logInfo(s\"As the result size exceeds the threshold $maxCnfNodeCount. \" +\r\n              \"The CNF conversion is skipped and returning Seq.empty now. To avoid this, you can \" +\r\n              s\"raise the limit ${SQLConf.MAX_CNF_NODE_COUNT.key}.\")\r\n            return Seq.empty\r\n          } else {\r\n            for { x <- left; y <- right } yield Or(x, y)\r\n          }\r\n        case other => other :: Nil\r\n      }\r\n      resultStack.push(cnf)\r\n    }\r\n    if (resultStack.length != 1) {\r\n      logWarning(\"The length of CNF conversion result stack is supposed to be 1. There might \" +\r\n        \"be something wrong with CNF conversion.\")\r\n      return Seq.empty\r\n    }\r\n    resultStack.top\r\n  }\r\n```",
        "createdAt" : "2020-06-12T06:43:35Z",
        "updatedAt" : "2020-07-01T08:39:56Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      }
    ],
    "commit" : "e2777c99144f91b463924530a0a89e6f1a39ab66",
    "line" : 59,
    "diffHunk" : "@@ -1,1 +283,287 @@        expressions.groupBy(e => AttributeSet(e.references)).map(_._2.reduceLeft(And)).toSeq)\n  }\n\n  /**\n   * Iterative post order traversal over a binary tree built by And/Or clauses with two stacks."
  },
  {
    "id" : "8440493b-b7db-4b03-9fdd-a5312391ef79",
    "prId" : 28805,
    "prUrl" : "https://github.com/apache/spark/pull/28805#pullrequestreview-440478325",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "92a12dc8-fb27-4476-90e0-32748694aaa7",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "nit format:\r\n```\r\n    conjunctiveNormalForm(condition, (expressions: Seq[Expression]) =>\r\n        expressions.groupBy(_.references.map(_.qualifier)).map(_._2.reduceLeft(And)).toSeq)\r\n```",
        "createdAt" : "2020-07-01T00:52:11Z",
        "updatedAt" : "2020-07-01T08:39:56Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "e2777c99144f91b463924530a0a89e6f1a39ab66",
    "line" : 39,
    "diffHunk" : "@@ -1,1 +263,267 @@  def CNFWithGroupExpressionsByQualifier(condition: Expression): Seq[Expression] = {\n    conjunctiveNormalForm(condition, (expressions: Seq[Expression]) =>\n        expressions.groupBy(_.references.map(_.qualifier)).map(_._2.reduceLeft(And)).toSeq)\n  }\n"
  }
]