[
  {
    "id" : "7e576a3e-749d-43b2-be71-c5e41f05b3f6",
    "prId" : 32550,
    "prUrl" : "https://github.com/apache/spark/pull/32550#pullrequestreview-661734366",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ace51882-e89f-4237-8d04-2081c7ca5360",
        "parentId" : null,
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "what about the case when both left and right sides meet requirement of AQE shuffled hash join (i.e. each partition size < threshold) ? Here we always build left. Shall we build right in case right side is smaller than left side?",
        "createdAt" : "2021-05-18T06:11:16Z",
        "updatedAt" : "2021-05-18T06:15:17Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      },
      {
        "id" : "778e5d7e-cf6a-4eb0-a351-e2abbede2ca5",
        "parentId" : "ace51882-e89f-4237-8d04-2081c7ca5360",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "Yeah,  we have already chose a smaller one since the `LogicalQueryStage` has override the `computeStats`. And see the code in `joins.getBuildSide`:\r\n```\r\nprivate def getBuildSide(\r\n      canBuildLeft: Boolean,\r\n      canBuildRight: Boolean,\r\n      left: LogicalPlan,\r\n      right: LogicalPlan): Option[BuildSide] = {\r\n    if (canBuildLeft && canBuildRight) {\r\n      // returns the smaller side base on its estimated physical size, if we want to build the\r\n      // both sides.\r\n      Some(getSmallerSide(left, right))\r\n    } else if (canBuildLeft) {\r\n      Some(BuildLeft)\r\n    } else if (canBuildRight) {\r\n      Some(BuildRight)\r\n    } else {\r\n      None\r\n    }\r\n  }\r\n```",
        "createdAt" : "2021-05-18T07:28:06Z",
        "updatedAt" : "2021-05-18T07:28:06Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      },
      {
        "id" : "467e7a09-248f-4001-86da-8efae5cb5540",
        "parentId" : "ace51882-e89f-4237-8d04-2081c7ca5360",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "Add an build side check if you worry about this.  [c747a23](https://github.com/apache/spark/pull/32550/commits/c747a23be0e59bcb7edb6e9bb377d2aed7248c96)",
        "createdAt" : "2021-05-18T07:31:43Z",
        "updatedAt" : "2021-05-18T07:31:43Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "957215452e9df57f5e0424f63556897ea928744f",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +254,258 @@      hintToShuffleHashJoinLeft(hint)\n    } else {\n      if (hintToPreferShuffleHashJoinLeft(hint)) {\n        true\n      } else {"
  },
  {
    "id" : "eb3d62d6-aa55-4b88-adfb-f2915faabd4f",
    "prId" : 31908,
    "prUrl" : "https://github.com/apache/spark/pull/31908#pullrequestreview-673956668",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b0e9c98b-6384-421e-bcf1-0d54bf672f64",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Sorry I missed this. It's outer join and it will never reduce data volume of the left side. So we can always remove the join, no matter it's broadcast or not.",
        "createdAt" : "2021-06-02T03:16:45Z",
        "updatedAt" : "2021-06-02T03:16:45Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "4c7a0ba4-a65c-4d4e-b8e0-e7f05302f590",
        "parentId" : "b0e9c98b-6384-421e-bcf1-0d54bf672f64",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "The result may be incorrect if always remove the join. For example:\r\n```\r\n0: jdbc:hive2://hdc49-mcc10-01-0510-2005-006-> create table test11.t1 using parquet as select id % 3 as a, id as b from range(10);\r\n+---------+--+\r\n| Result  |\r\n+---------+--+\r\n+---------+--+\r\nNo rows selected (1.611 seconds)\r\n0: jdbc:hive2://hdc49-mcc10-01-0510-2005-006-> create table test11.t2 using parquet as select id % 3 as x, id as y from range(5);\r\n+---------+--+\r\n| Result  |\r\n+---------+--+\r\n+---------+--+\r\nNo rows selected (1.043 seconds)\r\n0: jdbc:hive2://hdc49-mcc10-01-0510-2005-006-> select t1.a from t1 left join t2 on a = x;\r\n+----+--+\r\n| a  |\r\n+----+--+\r\n| 0  |\r\n| 0  |\r\n| 1  |\r\n| 1  |\r\n| 0  |\r\n| 0  |\r\n| 1  |\r\n| 1  |\r\n| 2  |\r\n| 0  |\r\n| 0  |\r\n| 1  |\r\n| 1  |\r\n| 2  |\r\n| 0  |\r\n| 0  |\r\n| 2  |\r\n+----+--+\r\n17 rows selected (1.409 seconds)\r\n```",
        "createdAt" : "2021-06-02T03:37:07Z",
        "updatedAt" : "2021-06-02T03:37:07Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      },
      {
        "id" : "0ed9ac77-32a2-4ddb-844b-4de58e55fc3d",
        "parentId" : "b0e9c98b-6384-421e-bcf1-0d54bf672f64",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "The aggregate should still be there. I mean we can remove this `canPlanAsBroadcastHashJoin` check",
        "createdAt" : "2021-06-02T03:39:24Z",
        "updatedAt" : "2021-06-02T03:39:24Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "60a20ac1-4a3d-48ec-bdd7-a2b9aab362de",
        "parentId" : "b0e9c98b-6384-421e-bcf1-0d54bf672f64",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "https://github.com/apache/spark/pull/32744",
        "createdAt" : "2021-06-02T09:24:58Z",
        "updatedAt" : "2021-06-02T09:24:58Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      }
    ],
    "commit" : "aae4efea461af0da9f6ddfec4fb7a073ce191a67",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +174,178 @@    case a @ Aggregate(_, _, join @ Join(left, _, LeftOuter, _, _))\n        if a.isDistinct && a.references.subsetOf(AttributeSet(left.output)) &&\n          !canPlanAsBroadcastHashJoin(join, conf) =>\n      a.copy(child = left)\n    case a @ Aggregate(_, _, join @ Join(_, right, RightOuter, _, _))"
  },
  {
    "id" : "99b3b797-a187-441d-8a79-0595afa539da",
    "prId" : 29342,
    "prUrl" : "https://github.com/apache/spark/pull/29342#pullrequestreview-463799522",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "237889eb-ac3c-48a8-a7c3-d9da3f0381cf",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Is it okay to share the param (`autoBroadcastJoinThreshold`) for the threshold? Probably, I think we need a new conf for that.",
        "createdAt" : "2020-08-06T06:13:50Z",
        "updatedAt" : "2020-08-16T18:24:08Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "f878d0fd-d0ee-42b1-9117-b62d24bdaa74",
        "parentId" : "237889eb-ac3c-48a8-a7c3-d9da3f0381cf",
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "@maropu - `autoBroadcastJoinThreshold` has nothing to do with `canBuildShuffledHashJoinLeft/Right` and `canBuildBroadcastLeft/Right`. I am just refactoring the decision related to join type here. `autoBroadcastJoinThreshold` is used in `canBroadcastBySize` and `canBuildLocalHashMapBySize` which I didn't touch. IMO it would be risky to introduce a new config for SHJ here as users would have existing pipelines to be carefully tuning `autoBroadcastJoinThreshold` to enable SHJ.",
        "createdAt" : "2020-08-07T17:34:56Z",
        "updatedAt" : "2020-08-16T18:24:08Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      },
      {
        "id" : "d3cd1594-6b99-4d92-8ae1-648defedd623",
        "parentId" : "237889eb-ac3c-48a8-a7c3-d9da3f0381cf",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ah, I see. That' the existing logic...",
        "createdAt" : "2020-08-08T12:15:12Z",
        "updatedAt" : "2020-08-16T18:24:08Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "526709b73b87687f48f68486b9c8c7be0866291f",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +261,265 @@    }\n    getBuildSide(\n      canBuildShuffledHashJoinLeft(joinType) && buildLeft,\n      canBuildShuffledHashJoinRight(joinType) && buildRight,\n      left,"
  },
  {
    "id" : "a09b5767-412e-43c1-8d3d-e224634413cb",
    "prId" : 28540,
    "prUrl" : "https://github.com/apache/spark/pull/28540#pullrequestreview-417455606",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2f28fa96-b030-4da8-b6f3-e522032c931c",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "We need to pull out this functionality as a helper trait? For example, `PredicateHelper` is used in many places, but this helper trait is only used for `JoinSelection `?",
        "createdAt" : "2020-05-22T01:25:01Z",
        "updatedAt" : "2020-05-27T13:24:30Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "9d4f60f0-94bc-4285-ae1d-51db3fd7902d",
        "parentId" : "2f28fa96-b030-4da8-b6f3-e522032c931c",
        "authorId" : "def2dd9f-ce27-41ce-8156-f8225ddc68a9",
        "body" : "@maropu That's true that currently there are no other uses of this trait, but there are potentially other rules that can use the join selection logic at optimization time, so this refactoring will open up the opportunity for more optimization rules.\r\nAlso, this cleans up the JoinSelection rule quite a bit, and IMO the logic for determining the type of the join is more clear now.",
        "createdAt" : "2020-05-24T17:12:31Z",
        "updatedAt" : "2020-05-27T13:24:30Z",
        "lastEditedBy" : "def2dd9f-ce27-41ce-8156-f8225ddc68a9",
        "tags" : [
        ]
      },
      {
        "id" : "43ef3589-13eb-431d-8ce3-679f04603478",
        "parentId" : "2f28fa96-b030-4da8-b6f3-e522032c931c",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "okay, that sounds fine to me. Thanks for the explanation. btw, if the helper is more general as you said, how about `JoinSelectionHelper` -> `JoinPlanHelper `?",
        "createdAt" : "2020-05-25T04:53:40Z",
        "updatedAt" : "2020-05-27T13:24:30Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "b5cb301c-8892-42c4-ad60-686ebbd827d2",
        "parentId" : "2f28fa96-b030-4da8-b6f3-e522032c931c",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Also, could you add some tests for this new helper?",
        "createdAt" : "2020-05-25T04:56:47Z",
        "updatedAt" : "2020-05-27T13:24:30Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "8fbe29c7e98d656d32fc8702e980eb1c32abb0e5",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +216,220 @@case object BuildLeft extends BuildSide\n\ntrait JoinSelectionHelper {\n\n  def getBroadcastBuildSide("
  },
  {
    "id" : "930fec9f-b474-4db0-bf3a-f6d007fb55a0",
    "prId" : 24563,
    "prUrl" : "https://github.com/apache/spark/pull/24563#pullrequestreview-239907517",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a4a794c9-f120-448a-a2d5-887663aaf7f3",
        "parentId" : null,
        "authorId" : "4db0fc8e-ae25-4ad9-989f-2fb7198f797a",
        "body" : "nit: by the analyzer?",
        "createdAt" : "2019-05-21T08:51:48Z",
        "updatedAt" : "2019-05-21T09:19:00Z",
        "lastEditedBy" : "4db0fc8e-ae25-4ad9-989f-2fb7198f797a",
        "tags" : [
        ]
      }
    ],
    "commit" : "14b1ddf2b73d2339b7618ece4f4a18020acbb4d8",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +51,55 @@        if (isIn(left, arrA) && isIn(right, arrB)) {\n          (arrA, arrB)\n        } else { // other cases would be caught be the analyzer\n          (arrB, arrA)\n        }"
  },
  {
    "id" : "45dd9e7d-4e97-48f1-bf01-1bf8646f787a",
    "prId" : 24563,
    "prUrl" : "https://github.com/apache/spark/pull/24563#pullrequestreview-239907517",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e298383b-3866-4517-b6af-ddcde28fc4a0",
        "parentId" : null,
        "authorId" : "4db0fc8e-ae25-4ad9-989f-2fb7198f797a",
        "body" : "This may fail the scala style test?",
        "createdAt" : "2019-05-21T09:11:38Z",
        "updatedAt" : "2019-05-21T09:19:00Z",
        "lastEditedBy" : "4db0fc8e-ae25-4ad9-989f-2fb7198f797a",
        "tags" : [
        ]
      }
    ],
    "commit" : "14b1ddf2b73d2339b7618ece4f4a18020acbb4d8",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +47,51 @@\n  def apply(plan: LogicalPlan): LogicalPlan = plan transform {\n    case Join(left, right, joinType, Some(ArraysOverlap(arrA: NamedExpression, arrB: NamedExpression))) =>\n      val (leftArray, rightArray) =\n        if (isIn(left, arrA) && isIn(right, arrB)) {"
  },
  {
    "id" : "293cd9f9-9816-40d2-8dd9-1e6e0c6cf551",
    "prId" : 24563,
    "prUrl" : "https://github.com/apache/spark/pull/24563#pullrequestreview-239907517",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "29777308-a6cd-4e5b-ae96-2fced29dfe47",
        "parentId" : null,
        "authorId" : "4db0fc8e-ae25-4ad9-989f-2fb7198f797a",
        "body" : "I remember we usually use `EqualTo(leftExp, rightExp)` instead of the dsl here.\r\n",
        "createdAt" : "2019-05-21T09:12:47Z",
        "updatedAt" : "2019-05-21T09:19:01Z",
        "lastEditedBy" : "4db0fc8e-ae25-4ad9-989f-2fb7198f797a",
        "tags" : [
        ]
      }
    ],
    "commit" : "14b1ddf2b73d2339b7618ece4f4a18020acbb4d8",
    "line" : 40,
    "diffHunk" : "@@ -1,1 +57,61 @@      val (leftPrime, leftExp) = makePrime(left, leftArray, leftAlias)\n      val (rightPrime, rightExp) = makePrime(right, rightArray, rightAlias)\n      val joined = Join(leftPrime, rightPrime, joinType, Some(leftExp === rightExp))\n      val dropped = Project(\n        Seq(left, right).flatMap(_.output.map(_.expr)).map { case e: NamedExpression => e },"
  }
]