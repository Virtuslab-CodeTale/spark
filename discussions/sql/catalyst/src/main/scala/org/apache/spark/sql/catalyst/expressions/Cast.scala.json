[
  {
    "id" : "0448c95c-eaa6-4e24-9725-9e4206b400c2",
    "prId" : 33146,
    "prUrl" : "https://github.com/apache/spark/pull/33146#pullrequestreview-697161729",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a236b0e6-1f0b-4615-8902-92772097fddb",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "if `fields(0).nullable` is false, how can `row.isNullAt(0)` be true?",
        "createdAt" : "2021-06-30T13:11:33Z",
        "updatedAt" : "2021-06-30T13:11:33Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "0d476922-445e-4af8-ab0c-48659f924bb1",
        "parentId" : "a236b0e6-1f0b-4615-8902-92772097fddb",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "(I have the same question)",
        "createdAt" : "2021-07-01T02:03:20Z",
        "updatedAt" : "2021-07-01T02:03:27Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "35b515c3-1bd4-42f3-9113-4306cedb8dbd",
        "parentId" : "a236b0e6-1f0b-4615-8902-92772097fddb",
        "authorId" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "body" : "If user create dataframe from `spark.internalCreateDataFrame()`, the `row.isNullAt()` may be true even though the schema nullable is false.\r\nFor instance:\r\n```scala\r\n  val schema = StructType(Seq(\r\n    StructField(\"x\",\r\n      StructType(Seq(\r\n        StructField(\"y\", IntegerType, true),\r\n        StructField(\"z\", IntegerType, false)\r\n      )))))\r\n  val rdd = spark.sparkContext.parallelize(Seq(InternalRow(InternalRow(1, null))))\r\n  val df = spark.internalCreateDataFrame(rdd, schema)\r\n  df.show\r\n  // current master branch output\r\n  //  +---------+\r\n  //  |        x|\r\n  //  +---------+\r\n  //  |{1, null}|\r\n  //  +---------+\r\n```\r\n\r\nAlthough the `spark.internalCreateDataFrame()` is sql package private API, but `spark.read.json()` and `spark.read.csv()` call it without null value handled.(the example show in pr description)\r\n",
        "createdAt" : "2021-07-01T03:28:58Z",
        "updatedAt" : "2021-07-01T03:34:21Z",
        "lastEditedBy" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "tags" : [
        ]
      },
      {
        "id" : "992483e1-a9e1-40e7-90a8-fde414f35e1d",
        "parentId" : "a236b0e6-1f0b-4615-8902-92772097fddb",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Then we need to fix the nullability. There are so many places in the Spark codebase that relies on nullability to do optimizations. It's not possible to change all of them to not trust the nullability anymore.\r\n\r\nCan we fix `spark.read.json()` to set the nullability correctly?",
        "createdAt" : "2021-07-01T04:54:55Z",
        "updatedAt" : "2021-07-01T04:54:55Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "c637ef51-49df-40ec-bb82-6a4cbd7608ca",
        "parentId" : "a236b0e6-1f0b-4615-8902-92772097fddb",
        "authorId" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "body" : "Ok, let me try.",
        "createdAt" : "2021-07-01T12:05:41Z",
        "updatedAt" : "2021-07-01T12:05:41Z",
        "lastEditedBy" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "tags" : [
        ]
      }
    ],
    "commit" : "25c396c3e30679f11318d3a0c449306b12762af2",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +407,411 @@          val st = fields.map(_.dataType)\n          val toUTF8StringFuncs = st.map(castToString)\n          if (fields(0).nullable && row.isNullAt(0)) {\n            if (!legacyCastToStr) builder.append(\"null\")\n          } else {"
  },
  {
    "id" : "280b6a05-7062-4571-ae27-1d6c0830e972",
    "prId" : 33027,
    "prUrl" : "https://github.com/apache/spark/pull/33027#pullrequestreview-690205328",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7b107d8f-d520-4c9b-a1bd-bdcb16c56f72",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I checked `Add`, I think we should also add a new `def this` to allow omitting the `ansiEnabled` parameter, to get a bit more compatibility, such as `new Cast(...)`",
        "createdAt" : "2021-06-23T04:41:30Z",
        "updatedAt" : "2021-06-23T04:41:30Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "55891cfc9df412ae34dda7d5f3f6c98c832f4c01",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +1949,1953 @@    override val ansiEnabled: Boolean = SQLConf.get.ansiEnabled)\n  extends CastBase {\n\n  def this(child: Expression, dataType: DataType, timeZoneId: Option[String]) =\n    this(child, dataType, timeZoneId, ansiEnabled = SQLConf.get.ansiEnabled)"
  },
  {
    "id" : "6bff4828-50ff-498e-a993-a32d908d241e",
    "prId" : 32869,
    "prUrl" : "https://github.com/apache/spark/pull/32869#pullrequestreview-681084858",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f2f9c149-b314-456f-a022-6388f95f66d6",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "nit: we can add a `protected def dtUtilCls = classOf[DateTimeUtils].getClass.getName` in `CaseBase`, to shorten the code here and other places.",
        "createdAt" : "2021-06-10T17:47:30Z",
        "updatedAt" : "2021-06-10T17:47:30Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "dde4cd800a3d2e9aac55d05b5d99cc00fba0a2e6",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +1211,1215 @@        (c, evPrim, evNull) =>\n          // scalastyle:off line.size.limit\n          code\"$evPrim = org.apache.spark.sql.catalyst.util.DateTimeUtils.microsToDays($c, java.time.ZoneOffset.UTC);\"\n          // scalastyle:on line.size.limit\n      case _ =>"
  },
  {
    "id" : "098dcb66-4af0-4ab7-a427-f003989d7ff0",
    "prId" : 32864,
    "prUrl" : "https://github.com/apache/spark/pull/32864#pullrequestreview-680879169",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cf338e96-5ee6-4573-aaf9-b4944bbce0d9",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "how about the other way around?",
        "createdAt" : "2021-06-10T14:35:53Z",
        "updatedAt" : "2021-06-10T14:35:53Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "7d4e9f7e-8692-4ac1-8c9f-38eb6eb94965",
        "parentId" : "cf338e96-5ee6-4573-aaf9-b4944bbce0d9",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "It will be added in another PR",
        "createdAt" : "2021-06-10T14:43:46Z",
        "updatedAt" : "2021-06-10T14:43:46Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "b47219a0498192ae217ea18582bbc37cd5969bd7",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +69,73 @@    case (DateType, TimestampType) => true\n    case (_: NumericType, TimestampType) => true\n    case (TimestampWithoutTZType, TimestampType) => true\n\n    case (StringType, DateType) => true"
  },
  {
    "id" : "3786e456-6cea-466a-a342-c0721c886ecb",
    "prId" : 31954,
    "prUrl" : "https://github.com/apache/spark/pull/31954#pullrequestreview-621290840",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c96275e9-93fa-4b1f-8685-c95f5114d34f",
        "parentId" : null,
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "Does this affect the coming year-month and day-time interval?",
        "createdAt" : "2021-03-24T16:12:13Z",
        "updatedAt" : "2021-03-25T13:35:48Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "12697dbc-30aa-4972-b28b-464e78d0c3ae",
        "parentId" : "c96275e9-93fa-4b1f-8685-c95f5114d34f",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "Yes",
        "createdAt" : "2021-03-24T16:41:25Z",
        "updatedAt" : "2021-03-25T13:35:48Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "ab3948e9-2c2a-4050-b132-b5475b497c3c",
        "parentId" : "c96275e9-93fa-4b1f-8685-c95f5114d34f",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "@cloud-fan . Usually, we do the explicitly allowed-list approach in case of types. Is this change okay?\r\nIf this PR aims for `complex type` only, why don't we add them explicitly instead of doing this widely. ",
        "createdAt" : "2021-03-24T19:01:29Z",
        "updatedAt" : "2021-03-25T13:35:48Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "2e36f1c3-cc76-4030-83ae-3229a0f1e44b",
        "parentId" : "c96275e9-93fa-4b1f-8685-c95f5114d34f",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Also, cc @MaxGekk ",
        "createdAt" : "2021-03-24T19:02:01Z",
        "updatedAt" : "2021-03-25T13:35:48Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "d9b2e167-6747-41d7-82e2-50a915e86ade",
        "parentId" : "c96275e9-93fa-4b1f-8685-c95f5114d34f",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "`df.show` needs to cast the column to string, I think we need to support casting from all the data types here, otherwise `df.show` may still be broken under some cases.",
        "createdAt" : "2021-03-25T13:29:43Z",
        "updatedAt" : "2021-03-25T13:35:48Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "c878e638-c88a-42e5-b3a5-e3047e62ff65",
        "parentId" : "c96275e9-93fa-4b1f-8685-c95f5114d34f",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "So far, we don't support such casting. I opened the JIRAs for that: SPARK-34667 and SPARK-34668",
        "createdAt" : "2021-03-25T15:56:00Z",
        "updatedAt" : "2021-03-25T15:56:05Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "1707885814cf846d567fdbca65a2ded88643d679",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +1874,1878 @@    case (NullType, _) => true\n\n    case (_, StringType) => true\n\n    case (StringType, _: BinaryType) => true"
  },
  {
    "id" : "09820b11-6540-4755-8565-ad4127963dd0",
    "prId" : 31228,
    "prUrl" : "https://github.com/apache/spark/pull/31228#pullrequestreview-571326802",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f0a7ef35-d48b-420d-9bde-38ba06480885",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "we also need to change the codegen path.",
        "createdAt" : "2021-01-18T13:47:53Z",
        "updatedAt" : "2021-01-21T12:56:18Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "0353a190-8b95-4075-a7e4-53391c984663",
        "parentId" : "f0a7ef35-d48b-420d-9bde-38ba06480885",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "OK",
        "createdAt" : "2021-01-19T04:45:14Z",
        "updatedAt" : "2021-01-21T12:56:18Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      },
      {
        "id" : "e27d4916-700f-46a2-8190-c26bbffc6a05",
        "parentId" : "f0a7ef35-d48b-420d-9bde-38ba06480885",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "OK",
        "createdAt" : "2021-01-19T14:58:07Z",
        "updatedAt" : "2021-01-21T12:56:18Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "182d957ae72a108ea30032bb07368fbf90a72a61",
    "line" : 54,
    "diffHunk" : "@@ -1,1 +634,638 @@          longValue.toByte\n        } else {\n          throw QueryExecutionErrors.castingCauseOverflowError(t, Byte.getClass.getName)\n        }\n      })"
  },
  {
    "id" : "1c225765-da54-4cd4-9b29-d6b159d5a861",
    "prId" : 30874,
    "prUrl" : "https://github.com/apache/spark/pull/30874#pullrequestreview-556515068",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "058cb642-5b37-44fb-93d5-d75a2274606e",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "iff is 'if and only if'",
        "createdAt" : "2020-12-21T16:38:17Z",
        "updatedAt" : "2020-12-21T16:38:17Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "fd32bad5-3383-4a68-9430-c6dc02686869",
        "parentId" : "058cb642-5b37-44fb-93d5-d75a2274606e",
        "authorId" : "6acb4d7a-9c99-4a6f-a3ba-70ff202fef81",
        "body" : "Thank you!",
        "createdAt" : "2020-12-21T16:43:23Z",
        "updatedAt" : "2020-12-21T16:43:41Z",
        "lastEditedBy" : "6acb4d7a-9c99-4a6f-a3ba-70ff202fef81",
        "tags" : [
        ]
      }
    ],
    "commit" : "13e5c4dd49d2daecf337fa31c74312f4f633d680",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +40,44 @@\n  /**\n   * Returns true if we can cast `from` type to `to` type.\n   */\n  def canCast(from: DataType, to: DataType): Boolean = (from, to) match {"
  },
  {
    "id" : "4228df96-0a99-443a-914e-20791dfb027a",
    "prId" : 30329,
    "prUrl" : "https://github.com/apache/spark/pull/30329#pullrequestreview-529198208",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "19219201-947b-455d-b947-08c2da6393d6",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Why the case is not handled by the case above?\r\n```scala\r\ncase (TimestampType | DateType, StringType) => true\r\n```",
        "createdAt" : "2020-11-11T15:29:38Z",
        "updatedAt" : "2020-11-11T15:29:43Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "4d20c5c8-dafd-4b04-bd50-50dd6580a592",
        "parentId" : "19219201-947b-455d-b947-08c2da6393d6",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Yea it's already covered by L111. We should close this PR.",
        "createdAt" : "2020-11-12T15:24:13Z",
        "updatedAt" : "2020-11-12T15:24:13Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "ddd8f01aecf4aa8f6ae24a6ca16e5aa58b62f166",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +111,115 @@    case (TimestampType | DateType, StringType) => true\n    case (DateType, TimestampType) => true\n    case (DateType, StringType) => true\n    case (TimestampType, DateType) => true\n    case (ArrayType(fromType, _), ArrayType(toType, _)) => needsTimeZone(fromType, toType)"
  },
  {
    "id" : "7c8b38b6-7352-498f-838f-5cf30fb78d2c",
    "prId" : 30260,
    "prUrl" : "https://github.com/apache/spark/pull/30260#pullrequestreview-527965554",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f0b5f4d9-bd4d-42ca-901f-1bcfbafa9b4c",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "How about describing this new behaviour in the usage above of `ExpressionDescription`?",
        "createdAt" : "2020-11-10T01:57:50Z",
        "updatedAt" : "2020-11-18T13:36:51Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "344902d6-b549-4f84-b7d1-1e41f070721c",
        "parentId" : "f0b5f4d9-bd4d-42ca-901f-1bcfbafa9b4c",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "well, then we need to mention about the behavior of throwing overflow exceptions when ANSI flag enabled. I will add some content in the `sql-ref-ansi-compliance.md`",
        "createdAt" : "2020-11-11T08:38:55Z",
        "updatedAt" : "2020-11-18T13:36:51Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "6003bef62c59d623ca59e51532b4fa5006c56fa2",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +1761,1765 @@  override protected val ansiEnabled: Boolean = SQLConf.get.ansiEnabled\n\n  override def canCast(from: DataType, to: DataType): Boolean = if (ansiEnabled) {\n    AnsiCast.canCast(from, to)\n  } else {"
  },
  {
    "id" : "8d75ac0d-08b9-4508-a0fa-1fd8b377d624",
    "prId" : 30260,
    "prUrl" : "https://github.com/apache/spark/pull/30260#pullrequestreview-526795322",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "938a7e7b-ac52-46f3-a112-0a5c29477f3c",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Could you leave some comments to summarize the current behaivour of the ANSI explicit cast as described in the PR description (references `section 6.13 of the ANSI SQL standard` and differences from the standard, e.g., `Numeric <=> Boolean`) ?",
        "createdAt" : "2020-11-10T02:02:13Z",
        "updatedAt" : "2020-11-18T13:36:51Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "6003bef62c59d623ca59e51532b4fa5006c56fa2",
    "line" : 49,
    "diffHunk" : "@@ -1,1 +1787,1791 @@}\n\nobject AnsiCast {\n  /**\n   * As per section 6.13 \"cast specification\" in \"Information technology — Database languages \" +"
  },
  {
    "id" : "3f3c5f4f-4b88-4fee-b910-dbc6b993cba0",
    "prId" : 30260,
    "prUrl" : "https://github.com/apache/spark/pull/30260#pullrequestreview-526800432",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "385c327b-f20f-432d-ab12-37af6a86281a",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "(Just a suggestion) For readability, could you reorder these entries according to `Cast.canCast` where possible? For example, the numeric entries for `Cast` seems to be placed just before complex types:\r\nhttps://github.com/apache/spark/blob/35ac314181129374b02f8f8c07341b43a734e1c7/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/Cast.scala#L70-L74",
        "createdAt" : "2020-11-10T02:12:51Z",
        "updatedAt" : "2020-11-18T13:36:51Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "6003bef62c59d623ca59e51532b4fa5006c56fa2",
    "line" : 116,
    "diffHunk" : "@@ -1,1 +1854,1858 @@    case (_: NumericType, _: NumericType) => true\n    case (StringType, _: NumericType) => true\n    case (BooleanType, _: NumericType) => true\n\n    case (_: NumericType, StringType) => true"
  },
  {
    "id" : "80a7878f-4812-46a7-b5ad-58c1a5d41997",
    "prId" : 30260,
    "prUrl" : "https://github.com/apache/spark/pull/30260#pullrequestreview-528998931",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "87a6b003-db69-4cb6-b65b-223bce16d1d7",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Nice update. Thanks!",
        "createdAt" : "2020-11-12T11:41:49Z",
        "updatedAt" : "2020-11-18T13:36:51Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "6003bef62c59d623ca59e51532b4fa5006c56fa2",
    "line" : 51,
    "diffHunk" : "@@ -1,1 +1789,1793 @@object AnsiCast {\n  /**\n   * As per section 6.13 \"cast specification\" in \"Information technology — Database languages \" +\n   * \"- SQL — Part 2: Foundation (SQL/Foundation)\":\n   * If the <cast operand> is a <value expression>, then the valid combinations of TD and SD"
  },
  {
    "id" : "65a3a4db-41ff-4dd9-a946-f73503b34d69",
    "prId" : 30260,
    "prUrl" : "https://github.com/apache/spark/pull/30260#pullrequestreview-528998931",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d99c316e-4155-4b63-a53b-cb30e3cb0ae5",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "How about describing the special case above in `sql-ref-ansi-compliance.md`, too?",
        "createdAt" : "2020-11-12T11:42:13Z",
        "updatedAt" : "2020-11-18T13:36:51Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "6003bef62c59d623ca59e51532b4fa5006c56fa2",
    "line" : 94,
    "diffHunk" : "@@ -1,1 +1832,1836 @@   * straightforward type conversions which are disallowed as per the SQL standard:\n   *   - Numeric <=> Boolean\n   *   - String <=> Binary\n   */\n  def canCast(from: DataType, to: DataType): Boolean = (from, to) match {"
  },
  {
    "id" : "0196aadf-1fd8-4585-9400-aa936ed25654",
    "prId" : 30213,
    "prUrl" : "https://github.com/apache/spark/pull/30213#pullrequestreview-521447487",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8861d41c-b022-4487-955a-82308622b8f1",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "It could be symmetric to line above:\r\n```scala\r\ncase (TimestampType | DateType, StringType) => true\r\n``` \r\nSo we could replace:\r\n```scala\r\ncase (TimestampType, StringType) => true\r\n```",
        "createdAt" : "2020-11-01T19:30:52Z",
        "updatedAt" : "2020-11-01T19:33:42Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "40f9b760-1a53-4f22-af4e-acd9f4107375",
        "parentId" : "8861d41c-b022-4487-955a-82308622b8f1",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can you do a followup to clean this up? thanks!",
        "createdAt" : "2020-11-02T02:56:31Z",
        "updatedAt" : "2020-11-02T02:56:31Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "fc180750-ea39-42de-af73-a9b8c42b6cbc",
        "parentId" : "8861d41c-b022-4487-955a-82308622b8f1",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Here is it: https://github.com/apache/spark/pull/30223",
        "createdAt" : "2020-11-02T09:14:16Z",
        "updatedAt" : "2020-11-02T09:14:16Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "9e3b43b301e14c5b7e3e5d60b953efcc17ccc1b8",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +109,113 @@  def needsTimeZone(from: DataType, to: DataType): Boolean = (from, to) match {\n    case (StringType, TimestampType | DateType) => true\n    case (DateType, StringType) => true\n    case (DateType, TimestampType) => true\n    case (TimestampType, StringType) => true"
  },
  {
    "id" : "e2bb0b47-2595-4192-ad4e-ed755398ddba",
    "prId" : 30189,
    "prUrl" : "https://github.com/apache/spark/pull/30189#pullrequestreview-525429397",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f8cd7716-76ce-4846-bd6d-885509b7423e",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Is this for map type? I saw you only added tests for array and struct.",
        "createdAt" : "2020-11-05T22:51:55Z",
        "updatedAt" : "2020-11-06T14:58:35Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "56eae8f0-084b-4b5e-b802-5bb7cc2ca70e",
        "parentId" : "f8cd7716-76ce-4846-bd6d-885509b7423e",
        "authorId" : "51995e12-6440-47da-9a2d-ad3292ac10dd",
        "body" : "I replaced outNullElem (which always appended \" null\") with appendIfNotLegacyCastToStr (which allows you to pass in the string to be appended).\r\n\r\nBecause the map, struct, and array code all called the outNullElem function, I changed them all to call appendIfNotLegacyCastToStr, even though, in the case of map, I'm not actually changing its behavior.  IOW, the map code was already correct, so I'm not making any changes to its behavior, I only changed that function call because that function is shared with struct and array.\r\n\r\nThis is also why I didn't add any unit tests for map.  I didn't change its behavior.\r\n\r\nHow would you like me to resolve this?  I can put the outNullElem function back, and revert the map code to call it, which will revert all of my changes to the map code.  However, doing that will create what could be considered redundant code (both outNullElem and appendIfNotLegacyCastToStr do almost the same thing, and appendIfNotLegacyCastToStr supercedes outNullElem, rendering outNullElem redundant).\r\n\r\nI'm happy to make whatever change you recommend.  Please advise.",
        "createdAt" : "2020-11-06T15:11:39Z",
        "updatedAt" : "2020-11-06T15:11:40Z",
        "lastEditedBy" : "51995e12-6440-47da-9a2d-ad3292ac10dd",
        "tags" : [
        ]
      },
      {
        "id" : "4ea12d6d-7605-4d2b-98fa-7979923732f5",
        "parentId" : "f8cd7716-76ce-4846-bd6d-885509b7423e",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Oh, so map doesn't have the same a leading space? If so then it is okay. As you actually change map's code, it would be nice to add a test like array/struct to prevent anything wrong.",
        "createdAt" : "2020-11-06T17:05:04Z",
        "updatedAt" : "2020-11-06T17:05:05Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "53fcdc6f-7e89-4619-96f2-dda421c469b4",
        "parentId" : "f8cd7716-76ce-4846-bd6d-885509b7423e",
        "authorId" : "51995e12-6440-47da-9a2d-ad3292ac10dd",
        "body" : "map's behavior is already correct.  For example, when printing a map, it looks like this:\r\n\r\n{A -> B, C -> D}\r\n\r\nSo, the values are already printed with a leading space, as they should be.  Therefore, I didn't need to change map's behavior.\r\n\r\nRegarding a unit test, one already exists.  In CastSuite.scala, beginning on line 731 (in my branch), there's a test named \"SPARK-22973 Cast map to string\" which already exists.  So, yes, I changed map's code, but no, I didn't change map's behavior, and the correct map behavior is already being unit tested.  My code changes didn't change the behavior, and the existing unit test passes successfully after my changes.\r\n\r\nI could add another unit test, but it will literally just be the same as the existing unit test (because I didn't change any behavior).  Do you want me to go ahead and add another unit test?\r\n",
        "createdAt" : "2020-11-06T17:37:28Z",
        "updatedAt" : "2020-11-06T17:37:29Z",
        "lastEditedBy" : "51995e12-6440-47da-9a2d-ad3292ac10dd",
        "tags" : [
        ]
      },
      {
        "id" : "66f3c878-8c22-4fad-b7c6-8e9cf8bcf749",
        "parentId" : "f8cd7716-76ce-4846-bd6d-885509b7423e",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Okay it sounds good to me if we already have test for it. Thanks for clarifying.",
        "createdAt" : "2020-11-06T18:39:59Z",
        "updatedAt" : "2020-11-06T18:39:59Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "50807713-8e09-4f49-9efc-a55db9f503b6",
        "parentId" : "f8cd7716-76ce-4846-bd6d-885509b7423e",
        "authorId" : "51995e12-6440-47da-9a2d-ad3292ac10dd",
        "body" : "Sounds good.  Thanks for the feedback.",
        "createdAt" : "2020-11-06T19:22:33Z",
        "updatedAt" : "2020-11-06T19:22:33Z",
        "lastEditedBy" : "51995e12-6440-47da-9a2d-ad3292ac10dd",
        "tags" : [
        ]
      }
    ],
    "commit" : "601af5e9fb034703f002aa39ce3e695118ab9ffb",
    "line" : 53,
    "diffHunk" : "@@ -1,1 +985,989 @@       |  $buffer.append(\" ->\");\n       |  if ($map.valueArray().isNullAt(0)) {\n       |    ${appendIfNotLegacyCastToStr(buffer, \" null\")}\n       |  } else {\n       |    $buffer.append(\" \");"
  },
  {
    "id" : "019f68fc-6283-4958-aa9a-212bb4757fb1",
    "prId" : 29311,
    "prUrl" : "https://github.com/apache/spark/pull/29311#pullrequestreview-461371870",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f707c8db-1db2-4745-8e90-93a05a3c07f4",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "`if (array.isNullAt(i) && !legacyCastToStr)`",
        "createdAt" : "2020-08-05T05:53:18Z",
        "updatedAt" : "2020-08-05T07:36:14Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "750993a3-e581-4ac1-a746-5116068085d9",
        "parentId" : "f707c8db-1db2-4745-8e90-93a05a3c07f4",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Here, we have 3 branches. Don't think your proposal is applicable.",
        "createdAt" : "2020-08-05T06:24:45Z",
        "updatedAt" : "2020-08-05T07:36:14Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "39daa90e49645d04d13789eb284b46f69eaad6ee",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +322,326 @@          while (i < array.numElements) {\n            builder.append(\",\")\n            if (array.isNullAt(i)) {\n              if (!legacyCastToStr) builder.append(\" null\")\n            } else {"
  },
  {
    "id" : "64789f04-9007-4e75-902a-ed5a5337cd14",
    "prId" : 29311,
    "prUrl" : "https://github.com/apache/spark/pull/29311#pullrequestreview-461358999",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "db1d4656-003f-4714-8d65-682fcdefb5b4",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ditto",
        "createdAt" : "2020-08-05T05:53:38Z",
        "updatedAt" : "2020-08-05T07:36:14Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "39daa90e49645d04d13789eb284b46f69eaad6ee",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +345,349 @@          builder.append(keyToUTF8String(keyArray.get(0, kt)).asInstanceOf[UTF8String])\n          builder.append(\" ->\")\n          if (valueArray.isNullAt(0)) {\n            if (!legacyCastToStr) builder.append(\" null\")\n          } else {"
  },
  {
    "id" : "84e8c583-0bbf-449a-a3dd-0f0a33e9c291",
    "prId" : 29311,
    "prUrl" : "https://github.com/apache/spark/pull/29311#pullrequestreview-461359081",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ca3ab4ab-f2c1-4525-b910-ff9d126320ea",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ditto",
        "createdAt" : "2020-08-05T05:53:49Z",
        "updatedAt" : "2020-08-05T07:36:14Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "39daa90e49645d04d13789eb284b46f69eaad6ee",
    "line" : 39,
    "diffHunk" : "@@ -1,1 +356,360 @@            builder.append(keyToUTF8String(keyArray.get(i, kt)).asInstanceOf[UTF8String])\n            builder.append(\" ->\")\n            if (valueArray.isNullAt(i)) {\n              if (!legacyCastToStr) builder.append(\" null\")\n            } else {"
  },
  {
    "id" : "8ba5c2f0-0887-413b-861d-a69300df7cfe",
    "prId" : 29311,
    "prUrl" : "https://github.com/apache/spark/pull/29311#pullrequestreview-461359129",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dfa9d887-7c57-4a4c-bb7a-0ed7dece7584",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ditto",
        "createdAt" : "2020-08-05T05:53:56Z",
        "updatedAt" : "2020-08-05T07:36:14Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "39daa90e49645d04d13789eb284b46f69eaad6ee",
    "line" : 50,
    "diffHunk" : "@@ -1,1 +376,380 @@          val st = fields.map(_.dataType)\n          val toUTF8StringFuncs = st.map(castToString)\n          if (row.isNullAt(0)) {\n            if (!legacyCastToStr) builder.append(\" null\")\n          } else {"
  },
  {
    "id" : "d736b8c9-387a-4536-9169-d54aeb3f6e08",
    "prId" : 28593,
    "prUrl" : "https://github.com/apache/spark/pull/28593#pullrequestreview-418725274",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a2f5d408-0e16-438d-82aa-0af4f7e66458",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "nit: `  case (_: NumericType, TimestampType) => SQLConf.get.allowCastNumericToTimestamp`?",
        "createdAt" : "2020-05-26T22:35:27Z",
        "updatedAt" : "2020-06-15T17:23:35Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "12b42396f058569354040d466962904794fa5c5e",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +60,64 @@    case (BooleanType, TimestampType) => true\n    case (DateType, TimestampType) => true\n    case (_: NumericType, TimestampType) =>\n      SQLConf.get.getConf(SQLConf.LEGACY_ALLOW_CAST_NUMERIC_TO_TIMESTAMP)\n"
  },
  {
    "id" : "c42d1269-e074-4a55-8fb6-0b80a3d273b3",
    "prId" : 28593,
    "prUrl" : "https://github.com/apache/spark/pull/28593#pullrequestreview-418957662",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4400c34b-ff80-43bf-9b28-12b698fb4055",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "btw, we need the check here? I think its okay just to update our migration guide.",
        "createdAt" : "2020-05-26T22:40:00Z",
        "updatedAt" : "2020-06-15T17:23:35Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "195768bd-1ca7-41be-af59-634447b06420",
        "parentId" : "4400c34b-ff80-43bf-9b28-12b698fb4055",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "it's better to let users know why it's wrong and how to fix, in the error message.",
        "createdAt" : "2020-05-27T08:14:51Z",
        "updatedAt" : "2020-06-15T17:23:35Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "12b42396f058569354040d466962904794fa5c5e",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +268,272 @@    } else {\n      TypeCheckResult.TypeCheckFailure(\n        if (child.dataType.isInstanceOf[NumericType] && dataType.isInstanceOf[TimestampType]) {\n          s\"cannot cast ${child.dataType.catalogString} to ${dataType.catalogString},\" +\n            \"you can enable the casting by setting \" +"
  },
  {
    "id" : "13843540-f04f-43b5-b912-56635ebdeec6",
    "prId" : 28571,
    "prUrl" : "https://github.com/apache/spark/pull/28571#pullrequestreview-414063601",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "23f127a8-a017-44e3-8802-7c61c44f6941",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Let's don't do this. It will require to add the compatibility across all the date time functionality in Spark, e.g.) `from_unixtime`.",
        "createdAt" : "2020-05-19T02:43:58Z",
        "updatedAt" : "2020-05-19T02:43:58Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "4aedd372f778a0b2ef3af21ff22c5765ad4027e0",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +394,398 @@  // converting seconds to us\n  private[this] def longToTimestamp(t: Long): Long = {\n    if (SQLConf.get.getConf(SQLConf.LONG_TIMESTAMP_CONVERSION_IN_SECONDS)) t * 1000000L\n    else t * 1000L\n  }"
  },
  {
    "id" : "fcd002f5-3d5a-4c49-ba27-ef8daa9a027b",
    "prId" : 28570,
    "prUrl" : "https://github.com/apache/spark/pull/28570#pullrequestreview-413566567",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "60b52fc2-1e1b-4105-8105-5303b50b5806",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "I guess checking the flag per each value brings significant performance drop. Could you show by a benchmark that performance is not sacrificed by your changes.",
        "createdAt" : "2020-05-18T12:27:13Z",
        "updatedAt" : "2020-05-18T12:33:28Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "029e131b-e33d-43b2-84f9-932290a4d57d",
        "parentId" : "60b52fc2-1e1b-4105-8105-5303b50b5806",
        "authorId" : "a67e5600-3f69-4b96-9c53-73795f48a0f6",
        "body" : "Hi MaxGekk \r\n i will add new benchmark later",
        "createdAt" : "2020-05-18T12:56:33Z",
        "updatedAt" : "2020-05-18T12:56:33Z",
        "lastEditedBy" : "a67e5600-3f69-4b96-9c53-73795f48a0f6",
        "tags" : [
        ]
      }
    ],
    "commit" : "0557f7397328398b80236fed56ed5a6cb3ca3164",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +456,460 @@  // SPARK-31710 converting seconds to us,Add compatibility flag\n  private[this] def longToTimestamp(t: Long): Long = {\n    if ( SQLConf.get.getConf( SQLConf.LONG_TIMESTAMP_CONVERSION_IN_SECONDS )) t * 1000000L\n    else t * 1000L\n  }"
  },
  {
    "id" : "3ea8931d-46ff-4e73-8114-db8c7823710b",
    "prId" : 28570,
    "prUrl" : "https://github.com/apache/spark/pull/28570#pullrequestreview-413566837",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e7138215-37a8-4f16-b37f-13661cfa724c",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "There are constants in `DateTimeConstants`. Please, use them.",
        "createdAt" : "2020-05-18T12:27:58Z",
        "updatedAt" : "2020-05-18T12:33:28Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "57a2f99c-b57d-4c72-9e4d-cecc5a1c5162",
        "parentId" : "e7138215-37a8-4f16-b37f-13661cfa724c",
        "authorId" : "a67e5600-3f69-4b96-9c53-73795f48a0f6",
        "body" : "Nice suggestion, i will recheck my code",
        "createdAt" : "2020-05-18T12:56:54Z",
        "updatedAt" : "2020-05-18T12:56:54Z",
        "lastEditedBy" : "a67e5600-3f69-4b96-9c53-73795f48a0f6",
        "tags" : [
        ]
      }
    ],
    "commit" : "0557f7397328398b80236fed56ed5a6cb3ca3164",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +457,461 @@  private[this] def longToTimestamp(t: Long): Long = {\n    if ( SQLConf.get.getConf( SQLConf.LONG_TIMESTAMP_CONVERSION_IN_SECONDS )) t * 1000000L\n    else t * 1000L\n  }\n  // converting us to seconds"
  },
  {
    "id" : "d7fd7512-291e-42ab-907d-3a29d3145b5e",
    "prId" : 27991,
    "prUrl" : "https://github.com/apache/spark/pull/27991#pullrequestreview-379920881",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0f7e8489-562e-4f8a-b1cc-8b4d379d9972",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "nit: can we remove the outermost parentheses?",
        "createdAt" : "2020-03-23T23:29:18Z",
        "updatedAt" : "2020-03-25T14:08:21Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "f194b231-9bae-41d0-a5ad-7a48e5bd5154",
        "parentId" : "0f7e8489-562e-4f8a-b1cc-8b4d379d9972",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "This one was a clean revert from this line (https://github.com/apache/spark/commit/d7b97a1d0daf65710317321490a833f696a46f21#diff-258b71121d8d168e4d53cb5b6dc53ffeL81). I would keep this line as is ..",
        "createdAt" : "2020-03-24T00:21:46Z",
        "updatedAt" : "2020-03-25T14:08:21Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "1bf68f03acce3cb46380ecbadd66693cbff39195",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +79,83 @@    case (MapType(fromKey, fromValue, fn), MapType(toKey, toValue, tn)) =>\n      canCast(fromKey, toKey) &&\n        (!forceNullable(fromKey, toKey)) &&\n        canCast(fromValue, toValue) &&\n        resolvableNullability(fn || forceNullable(fromValue, toValue), tn)"
  },
  {
    "id" : "f42c2e3c-1711-40bc-bf93-9dba8a66f08d",
    "prId" : 27608,
    "prUrl" : "https://github.com/apache/spark/pull/27608#pullrequestreview-360152274",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "56222449-ef6f-4d96-9b12-d63cf7f02233",
        "parentId" : null,
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "I think it should be \"ansiCast\" or \"ANSICast\" instead of \"ansi_cast\"",
        "createdAt" : "2020-02-18T07:44:22Z",
        "updatedAt" : "2020-02-18T07:44:22Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "45727ec4-b64f-4e36-a347-4ac377430eac",
        "parentId" : "56222449-ef6f-4d96-9b12-d63cf7f02233",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This follows the existing SQL function naming convention, e.g. `FromUTCTimestamp.prettyName` is `from_utc_timestamp`",
        "createdAt" : "2020-02-18T07:50:47Z",
        "updatedAt" : "2020-02-18T08:02:45Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "e529dfc6-2af8-49c8-9415-9ed31276a6bf",
        "parentId" : "56222449-ef6f-4d96-9b12-d63cf7f02233",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "But the string of `newInstance` is `newInstance($cls)` ..",
        "createdAt" : "2020-02-18T08:19:42Z",
        "updatedAt" : "2020-02-18T08:19:42Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "f010a394-7449-4e55-910c-8e4599a3a581",
        "parentId" : "56222449-ef6f-4d96-9b12-d63cf7f02233",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "`NewInstance` is not really a SQL function/operator...",
        "createdAt" : "2020-02-18T08:21:12Z",
        "updatedAt" : "2020-02-18T08:21:12Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "d72f3c2f-7f05-4489-b96d-4b6ae44bb68c",
        "parentId" : "56222449-ef6f-4d96-9b12-d63cf7f02233",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "I see. It is the first expression the overrides `toString` with 2 words in IDE...haha",
        "createdAt" : "2020-02-18T08:42:59Z",
        "updatedAt" : "2020-02-18T08:42:59Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "4896fb56a4fa600fdba3e9c3600a9adb2effc792",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +253,257 @@\n  override def toString: String = {\n    val ansi = if (ansiEnabled) \"ansi_\" else \"\"\n    s\"${ansi}cast($child as ${dataType.simpleString})\"\n  }"
  },
  {
    "id" : "8d73d7cc-41a1-4d72-92d0-04ae9ca89131",
    "prId" : 26933,
    "prUrl" : "https://github.com/apache/spark/pull/26933#pullrequestreview-338594577",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7e17786b-d51f-48b5-9b4f-e4fb0d4d3f5d",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I'd like to see something like\r\n```\r\ncase StringType if ansiEnabled =>\r\n  buildCast[UTF8String](_, _.toLongExact())\r\ncase StringType =>\r\n  val result = new LongWrapper()\r\n  buildCast[UTF8String](_, s => if (s.toLong(result)) result.value else null)\r\n```\r\nand in codegen\r\n```\r\nval casting = if (ansi) {\r\n  s\"$evPrim = $c.toLongExact();\"\r\n} else {\r\n  s\"\"\"\r\n    if ($c.toLong($wrapper)) {\r\n      $evPrim = $wrapper.value;\r\n    } else {\r\n      $evNull = true;\r\n    }\r\n  \"\"\"\r\n}\r\ncode\"\"\"\r\n  UTF8String.IntWrapper $wrapper = new UTF8String.IntWrapper();\r\n  $casting\r\n  $wrapper = null;\r\n```",
        "createdAt" : "2020-01-05T05:47:55Z",
        "updatedAt" : "2020-01-08T13:27:44Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "9be62c22-92c8-4d7c-92d5-abe98c3f886e",
        "parentId" : "7e17786b-d51f-48b5-9b4f-e4fb0d4d3f5d",
        "authorId" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "body" : "For long, won't it be good to use `LongWrapper` ?",
        "createdAt" : "2020-01-05T13:52:54Z",
        "updatedAt" : "2020-01-08T13:27:44Z",
        "lastEditedBy" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "tags" : [
        ]
      },
      {
        "id" : "c2b5a148-b6bf-4643-b476-7417e9e1f31e",
        "parentId" : "7e17786b-d51f-48b5-9b4f-e4fb0d4d3f5d",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "`LongWrapper` is only needed in `toLong` because we have to return 2 values: the long and a boolean flag. This is not true anymore in `toLongExact`.",
        "createdAt" : "2020-01-06T04:02:13Z",
        "updatedAt" : "2020-01-08T13:27:44Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "fe0e65fa-935e-4e05-8581-f067aa28e2a4",
        "parentId" : "7e17786b-d51f-48b5-9b4f-e4fb0d4d3f5d",
        "authorId" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "body" : "Oh, Thanks for clarification. :)\r\n\r\nI guess here LongWrapper is required .\r\n`UTF8String.IntWrapper $wrapper = new UTF8String.IntWrapper();`\r\n\r\nFor Int,Short and Byte, format should be like this only or previous changes are fine for them?",
        "createdAt" : "2020-01-06T06:40:52Z",
        "updatedAt" : "2020-01-08T13:27:44Z",
        "lastEditedBy" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "tags" : [
        ]
      },
      {
        "id" : "11a2d8fd-a332-4e8b-b74d-f692ad9e5440",
        "parentId" : "7e17786b-d51f-48b5-9b4f-e4fb0d4d3f5d",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Let's create `toByteExact`, `toShortExact`, `toIntExact` and `toLongExact` all together, and use similar approach to implement the cast for them.",
        "createdAt" : "2020-01-06T06:58:44Z",
        "updatedAt" : "2020-01-08T13:27:44Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "6af25a51-d6a4-4c51-ae86-51c35d6b6ba4",
        "parentId" : "7e17786b-d51f-48b5-9b4f-e4fb0d4d3f5d",
        "authorId" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "body" : "The implementation of `toLongExact` will be almost similar to `toLong`. Won't it be duplication of code? \r\nWhat about this implementation ->\r\n\r\n```\r\n  public long toLongExact() {\r\n    LongWrapper result = new LongWrapper();\r\n    if (toLong(result)) {\r\n      return result.value;\r\n    }\r\n    throw new NumberFormatException(\"invalid input syntax for type numeric: \" + this);\r\n  }\r\n```\r\n\r\nHere, i can use the `toLong` code for checking whether string contains valid value or not.\r\n\r\nIf we are not using the wrapper then implementation will be almost similar, as i will be throwing exception whenever a invalid value is there instead of returning `false` in `toLongExact`.",
        "createdAt" : "2020-01-06T11:06:44Z",
        "updatedAt" : "2020-01-08T13:27:44Z",
        "lastEditedBy" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "tags" : [
        ]
      },
      {
        "id" : "6e2ef3d0-4a0b-448e-b577-6fb0844c78c5",
        "parentId" : "7e17786b-d51f-48b5-9b4f-e4fb0d4d3f5d",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I'm fine with it. In the future, if we only have the ANSI behavior, we can unify the code.",
        "createdAt" : "2020-01-06T11:16:14Z",
        "updatedAt" : "2020-01-08T13:27:44Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "74479b73-053e-4263-936f-c5ca9f3d0329",
        "parentId" : "7e17786b-d51f-48b5-9b4f-e4fb0d4d3f5d",
        "authorId" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "body" : "Ok. I will create `toByteExact`, `toShortExact`, `toIntExact` and `toLongExact` using the existing format.",
        "createdAt" : "2020-01-06T11:28:15Z",
        "updatedAt" : "2020-01-08T13:27:44Z",
        "lastEditedBy" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "tags" : [
        ]
      }
    ],
    "commit" : "0cb4edc3a42badfff3f2ecca7b2ec468ad0f0c2d",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +483,487 @@  // LongConverter\n  private[this] def castToLong(from: DataType): Any => Any = from match {\n    case StringType if ansiEnabled =>\n      buildCast[UTF8String](_, _.toLongExact())\n    case StringType =>"
  },
  {
    "id" : "7eff9c90-bc6a-46af-bfa6-7edbaf2300c1",
    "prId" : 26933,
    "prUrl" : "https://github.com/apache/spark/pull/26933#pullrequestreview-339735287",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f57c3290-467a-40c4-86be-4aa5f4b75abc",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can we catch and re-throw `NumberFormatException` with better error message in `changePrecision`? Then here can be simply\r\n```\r\ncase _: NumberFormatException if !ansiEnabled => null\r\n```",
        "createdAt" : "2020-01-06T15:47:21Z",
        "updatedAt" : "2020-01-08T13:27:44Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "3448db32-01e2-4857-b66a-e294064f2791",
        "parentId" : "f57c3290-467a-40c4-86be-4aa5f4b75abc",
        "authorId" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "body" : "@cloud-fan `NumberFormatException` is thrown due to `new JavaBigDecimal(s.toString.trim)`. \r\nAnd this can't be handled in `changePrecision` as its taking a decimal value as input. So i think its better to handle this exception here only.",
        "createdAt" : "2020-01-08T08:21:24Z",
        "updatedAt" : "2020-01-08T13:27:44Z",
        "lastEditedBy" : "832e1988-205f-40f9-89d5-c37ea16224c9",
        "tags" : [
        ]
      },
      {
        "id" : "09634c7e-f6c0-4792-8f23-631132a06bef",
        "parentId" : "f57c3290-467a-40c4-86be-4aa5f4b75abc",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "makes sense",
        "createdAt" : "2020-01-08T09:24:50Z",
        "updatedAt" : "2020-01-08T13:27:44Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "0cb4edc3a42badfff3f2ecca7b2ec468ad0f0c2d",
    "line" : 43,
    "diffHunk" : "@@ -1,1 +647,651 @@        case _: NumberFormatException =>\n          if (ansiEnabled) {\n            throw new NumberFormatException(s\"invalid input syntax for type numeric: $s\")\n          } else {\n            null"
  },
  {
    "id" : "8a858c9b-48c5-4580-a9f5-26241cc38b2f",
    "prId" : 26640,
    "prUrl" : "https://github.com/apache/spark/pull/26640#pullrequestreview-321962931",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e984f85b-7f23-49a3-a22c-64655116d44e",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "`s.trimAll.toString` vs `s.toString.trim`, which one is better? ",
        "createdAt" : "2019-11-22T13:49:00Z",
        "updatedAt" : "2019-11-24T11:53:48Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "3955cc30-0d7f-44b2-89e6-678a898f50e7",
        "parentId" : "e984f85b-7f23-49a3-a22c-64655116d44e",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "`s.toString.trim ` is better\r\n\r\n```\r\n[info] Java HotSpot(TM) 64-Bit Server VM 1.8.0_231-b11 on Mac OS X 10.15.1\r\n[info] Intel(R) Core(TM) i9-9980HK CPU @ 2.40GHz\r\n[info] Cast String to Integral:                  Best Time(ms)   Avg Time(ms)   Stdev(ms)    Rate(M/s)   Per Row(ns)   Relative\r\n[info] ------------------------------------------------------------------------------------------------------------------------\r\n[info] cast(trim(str) as decimal) as c_decimal - with 1 spaces           3473           5428         491          2.4         424.0       1.0X\r\n[info] cast(trim(str) as decimal) as c_decimal - with 3 spaces           3409           4163         706          2.4         416.1       1.0X\r\n[info] cast(trim(str) as decimal) as c_decimal - with 5 spaces           6180           7422         795          1.3         754.3       0.6X\r\n[info] cast(str as decimal) as c_decimal - with 1 spaces           3684           6684        1239          2.2         449.7       0.9X\r\n[info] cast(str as decimal) as c_decimal - with 3 spaces           3516           4815        1443          2.3         429.2       1.0X\r\n[info] cast(str as decimal) as c_decimal - with 5 spaces           6344           7338         755          1.3         774.5       0.5X\r\n```",
        "createdAt" : "2019-11-22T14:41:33Z",
        "updatedAt" : "2019-11-24T11:53:48Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "77d71ec1-5101-42eb-8165-0d3550833ec4",
        "parentId" : "e984f85b-7f23-49a3-a22c-64655116d44e",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "Our UTF8String trim method shows performance isssue then.",
        "createdAt" : "2019-11-22T14:43:10Z",
        "updatedAt" : "2019-11-24T11:53:48Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "fea2760f-fbd6-481c-a9cf-29a67b843d96",
        "parentId" : "e984f85b-7f23-49a3-a22c-64655116d44e",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Can you leave some comments about that here?",
        "createdAt" : "2019-11-24T01:40:30Z",
        "updatedAt" : "2019-11-24T11:53:48Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "df6b21b9-6761-4523-8b58-ed3ca054c9ba",
        "parentId" : "e984f85b-7f23-49a3-a22c-64655116d44e",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "comments added, thanks for the suggestion.",
        "createdAt" : "2019-11-24T13:45:41Z",
        "updatedAt" : "2019-11-24T13:45:42Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "da1c8284f3ef8cfed3c4f6d2a1b33f4500e8a3dd",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +635,639 @@        // According the benchmark test,  `s.toString.trim` is much faster than `s.trim.toString`.\n        // Please refer to https://github.com/apache/spark/pull/26640\n        changePrecision(Decimal(new JavaBigDecimal(s.toString.trim)), target)\n      } catch {\n        case _: NumberFormatException => null"
  },
  {
    "id" : "e087f2c1-d201-4fb6-8a1d-b31623f228cb",
    "prId" : 25834,
    "prUrl" : "https://github.com/apache/spark/pull/25834#pullrequestreview-291538923",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a4af11d5-d03d-4daf-9f72-a45c53068b8a",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "It seems we don't need to pass the reference; its ok to just expand the boolean literal: true or literal against for `supportSpecialValues`?",
        "createdAt" : "2019-09-23T01:02:42Z",
        "updatedAt" : "2019-09-23T12:08:10Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "94abaeaed5e7140a28e3784f5a7e5c89022f0eda",
    "line" : 53,
    "diffHunk" : "@@ -1,1 +1189,1193 @@        code\"\"\"\n          scala.Option<Long> $longOpt =\n            org.apache.spark.sql.catalyst.util.DateTimeUtils.stringToTimestamp($c, $zid, $sv);\n          if ($longOpt.isDefined()) {\n            $evPrim = ((Long) $longOpt.get()).longValue();"
  },
  {
    "id" : "8b6bb2f7-58de-4479-9ab8-fc38574c8740",
    "prId" : 25804,
    "prUrl" : "https://github.com/apache/spark/pull/25804#pullrequestreview-288657487",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "28bf51c3-1e63-4898-9fd4-701b9e0dafdf",
        "parentId" : null,
        "authorId" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "body" : "How about using string interpolation `s\" ... $c ...\"?",
        "createdAt" : "2019-09-16T13:47:43Z",
        "updatedAt" : "2019-09-17T16:03:30Z",
        "lastEditedBy" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "tags" : [
        ]
      },
      {
        "id" : "486237a0-569b-4587-9071-90946b44ff14",
        "parentId" : "28bf51c3-1e63-4898-9fd4-701b9e0dafdf",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "They are different. The change you suggested is the same as what it is originally.\r\nBefore:\r\n```\r\nCasting columnartorow_value_0 to short causes overflow\r\n```\r\nAfter:\r\n```\r\nCasting 4567890123456789 to short causes overflow\r\n```",
        "createdAt" : "2019-09-16T13:54:44Z",
        "updatedAt" : "2019-09-17T16:03:30Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "3719279b-9279-4185-81d7-ca0563da2390",
        "parentId" : "28bf51c3-1e63-4898-9fd4-701b9e0dafdf",
        "authorId" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "body" : "Ah, got it. This is in another interpolation `code\"\"\"`.   \r\nSorry...",
        "createdAt" : "2019-09-16T14:07:28Z",
        "updatedAt" : "2019-09-17T16:03:30Z",
        "lastEditedBy" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "tags" : [
        ]
      },
      {
        "id" : "1bfb1e58-2a14-45cd-b3dc-3cf2ba6a9d51",
        "parentId" : "28bf51c3-1e63-4898-9fd4-701b9e0dafdf",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "It's OK. I made the same mistake :)",
        "createdAt" : "2019-09-16T14:11:46Z",
        "updatedAt" : "2019-09-17T16:03:30Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "c5674e40dc876cef12e5ed1627ecbe496daaad38",
    "line" : 53,
    "diffHunk" : "@@ -1,1 +1276,1280 @@            $evPrim = ($integralType) $longValue;\n          } else {\n            throw new ArithmeticException(\"Casting \" + $c + \" to $integralType causes overflow\");\n          }\n        \"\"\""
  },
  {
    "id" : "03069e52-fce2-4239-869a-9a3243799d8f",
    "prId" : 25804,
    "prUrl" : "https://github.com/apache/spark/pull/25804#pullrequestreview-288640416",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f6acdec2-3b77-40ce-b1f3-fb8a45e9e533",
        "parentId" : null,
        "authorId" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "body" : "ditto",
        "createdAt" : "2019-09-16T13:47:52Z",
        "updatedAt" : "2019-09-17T16:03:30Z",
        "lastEditedBy" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "tags" : [
        ]
      }
    ],
    "commit" : "c5674e40dc876cef12e5ed1627ecbe496daaad38",
    "line" : 62,
    "diffHunk" : "@@ -1,1 +1301,1305 @@          $evPrim = ($integralType) $c;\n        } else {\n          throw new ArithmeticException(\"Casting \" + $c + \" to $integralType causes overflow\");\n        }\n      \"\"\""
  },
  {
    "id" : "e1ee559c-9a8b-4cd2-bb44-cc5b2e4f97a9",
    "prId" : 25804,
    "prUrl" : "https://github.com/apache/spark/pull/25804#pullrequestreview-288640474",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fd0fbb01-5914-4469-bc88-c588eea75e05",
        "parentId" : null,
        "authorId" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "body" : "ditto",
        "createdAt" : "2019-09-16T13:47:57Z",
        "updatedAt" : "2019-09-17T16:03:30Z",
        "lastEditedBy" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "tags" : [
        ]
      }
    ],
    "commit" : "c5674e40dc876cef12e5ed1627ecbe496daaad38",
    "line" : 71,
    "diffHunk" : "@@ -1,1 +1336,1340 @@          $evPrim = ($integralType) $c;\n        } else {\n          throw new ArithmeticException(\"Casting \" + $c + \" to $integralType causes overflow\");\n        }\n      \"\"\""
  },
  {
    "id" : "c554f67c-421a-4fdb-9c86-a3b6430f13d3",
    "prId" : 25708,
    "prUrl" : "https://github.com/apache/spark/pull/25708#pullrequestreview-285193172",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "faffb1b4-d021-45d5-b33f-51822f4cd3f3",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Just put the gen'd code for other reviewers;\r\n```\r\n/* 051 */         boolean project_isNull_0 = columnartorow_isNull_0;\r\n/* 052 */         int project_value_0 = -1;\r\n/* 053 */         if (!columnartorow_isNull_0) {\r\n/* 054 */           scala.Option<Integer> project_intOpt_0 =\r\n/* 055 */           org.apache.spark.sql.catalyst.util.DateTimeUtils.stringToDate(columnartorow_value_0, ((java.time.ZoneId) references[2] /* zoneId */));\r\n/* 056 */           if (project_intOpt_0.isDefined()) {\r\n/* 057 */             project_value_0 = ((Integer) project_intOpt_0.get()).intValue();\r\n/* 058 */           } else {\r\n/* 059 */             project_isNull_0 = true;\r\n/* 060 */           }\r\n/* 061 */         }\r\n```",
        "createdAt" : "2019-09-08T01:15:56Z",
        "updatedAt" : "2019-09-18T15:49:31Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "ff925318b3258ade6b2db13489b078f394a1fdbd",
    "line" : 79,
    "diffHunk" : "@@ -1,1 +1086,1090 @@        (c, evPrim, evNull) => code\"$evNull = true;\"\n    }\n  }\n\n  private[this] def changePrecision(d: ExprValue, decimalType: DecimalType,"
  },
  {
    "id" : "086a50c3-4690-40f2-a8d3-1c0a95309df7",
    "prId" : 25708,
    "prUrl" : "https://github.com/apache/spark/pull/25708#pullrequestreview-285193275",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d67bf253-6ad9-4e6a-ad26-faed26b86d53",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "btw, (this is not related to this pr though), `scala.Option<Integer>` is ok for java compilers/jvm? @rednaxelafx I remember that jdk compilers cannot compile this statement: https://github.com/apache/spark/pull/21770#discussion_r202562989 because it seems the compilers erase the returned type from `scala.Option<Integer>` to `scala.Option<Object>`. I'm not sure why janino accepts this though....\r\n",
        "createdAt" : "2019-09-08T01:22:26Z",
        "updatedAt" : "2019-09-18T15:49:31Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "ff925318b3258ade6b2db13489b078f394a1fdbd",
    "line" : 63,
    "diffHunk" : "@@ -1,1 +1070,1074 @@        (c, evPrim, evNull) =>\n          code\"\"\"\n          scala.Option<Integer> $intOpt =\n            org.apache.spark.sql.catalyst.util.DateTimeUtils.stringToDate($c, $zid);\n          if ($intOpt.isDefined()) {"
  },
  {
    "id" : "cb608b38-78b3-4061-a4f4-f957dc6a33bd",
    "prId" : 25461,
    "prUrl" : "https://github.com/apache/spark/pull/25461#pullrequestreview-276257161",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5e25014f-049d-46ac-a434-da0e4939ead7",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "How about this form below?\r\n```\r\n    case x: NumericType =>\r\n      if (failOnIntegerOverflow) {\r\n        b => x.exactNumeric.asInstanceOf[Numeric[Any]].toLong(b)\r\n      } else {\r\n        b => x.numeric.asInstanceOf[Numeric[Any]].toLong(b)\r\n      }\r\n```",
        "createdAt" : "2019-08-18T01:16:06Z",
        "updatedAt" : "2019-08-23T08:30:44Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "9f4002c30bb44c120ccf5489874c86d1061f216f",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +464,468 @@      buildCast[Long](_, t => timestampToLong(t))\n    case x: NumericType if failOnIntegralTypeOverflow =>\n      b => x.exactNumeric.asInstanceOf[Numeric[Any]].toLong(b)\n    case x: NumericType =>\n      b => x.numeric.asInstanceOf[Numeric[Any]].toLong(b)"
  },
  {
    "id" : "c5409b2e-a9b3-42c2-ae31-3e251390e9a1",
    "prId" : 25461,
    "prUrl" : "https://github.com/apache/spark/pull/25461#pullrequestreview-276286371",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "503702d2-ed81-4653-8927-0b42a54e6edb",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Why do you cast it into int once?",
        "createdAt" : "2019-08-18T01:41:54Z",
        "updatedAt" : "2019-08-23T08:30:44Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "b156c1a7-ccfb-485b-9edc-ca5350da4f56",
        "parentId" : "503702d2-ed81-4653-8927-0b42a54e6edb",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "The trait `Numeric` doesn't have the method `toInt`. Before this code change, the value is also casted to int.",
        "createdAt" : "2019-08-18T08:16:00Z",
        "updatedAt" : "2019-08-23T08:30:44Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "f146412d-d71b-406c-aa2b-93c282a10abb",
        "parentId" : "503702d2-ed81-4653-8927-0b42a54e6edb",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ah, I see.",
        "createdAt" : "2019-08-18T12:53:04Z",
        "updatedAt" : "2019-08-23T08:30:44Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "12a9381c-5b13-4812-93e5-cce90ac1e8eb",
        "parentId" : "503702d2-ed81-4653-8927-0b42a54e6edb",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "We cannot check the valid value range in a single place instead of the current two checks in line 520 and 525?",
        "createdAt" : "2019-08-18T12:59:42Z",
        "updatedAt" : "2019-08-23T08:30:44Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "f17a0bc1-d0e1-46aa-840a-b8f6fa5f6dac",
        "parentId" : "503702d2-ed81-4653-8927-0b42a54e6edb",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "Well, we can do it by match it case by case. Then the code is a bit long. Casting to short/byte should be minor usage. Also, The previous code also cast to `Int` before cast to `Short`.",
        "createdAt" : "2019-08-18T16:32:51Z",
        "updatedAt" : "2019-08-23T08:30:44Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "9f4002c30bb44c120ccf5489874c86d1061f216f",
    "line" : 48,
    "diffHunk" : "@@ -1,1 +515,519 @@      b =>\n        val intValue = try {\n          x.exactNumeric.asInstanceOf[Numeric[Any]].toInt(b)\n        } catch {\n          case _: ArithmeticException =>"
  },
  {
    "id" : "9df1d86c-dea2-484d-8e2c-4545308963db",
    "prId" : 25461,
    "prUrl" : "https://github.com/apache/spark/pull/25461#pullrequestreview-278460118",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "980ff418-a557-454f-a9df-ccce2b7d08a7",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "how about\r\n```\r\nval max = s\"${ctx.primitiveTypeName(integralType).MaxValue}\"\r\nval min = s\"${ctx.primitiveTypeName(integralType).MinValue}\"\r\n```",
        "createdAt" : "2019-08-22T13:51:59Z",
        "updatedAt" : "2019-08-23T08:30:44Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "5180097d-bf49-4cbc-b5a2-6ba86a827ca3",
        "parentId" : "980ff418-a557-454f-a9df-ccce2b7d08a7",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "Then it will be string \"Int.MaxValue\".  Here I am trying to get string like \"2147483647f\" , \"2147483647d\"",
        "createdAt" : "2019-08-22T14:28:09Z",
        "updatedAt" : "2019-08-23T08:30:44Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "9f4002c30bb44c120ccf5489874c86d1061f216f",
    "line" : 151,
    "diffHunk" : "@@ -1,1 +1280,1284 @@    assert(fractionType == \"float\" || fractionType == \"double\")\n    val typeIndicator = fractionType.charAt(0)\n    val (min, max) = integralType.toLowerCase(Locale.ROOT) match {\n      case \"long\" => (Long.MinValue, Long.MaxValue)\n      case \"int\" => (Int.MinValue, Int.MaxValue)"
  },
  {
    "id" : "d42e479e-93df-46c8-9dc8-26a56df9a88f",
    "prId" : 25331,
    "prUrl" : "https://github.com/apache/spark/pull/25331#pullrequestreview-273048488",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "16b46643-5bdc-4015-8e23-44ae8375d7f4",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Should we explicitly match strings we want? We can avoid try-catch of an exception for the known strings.",
        "createdAt" : "2019-08-02T19:56:46Z",
        "updatedAt" : "2019-08-13T05:04:51Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "0bf206a4-0cfa-4291-a715-499056e0dcae",
        "parentId" : "16b46643-5bdc-4015-8e23-44ae8375d7f4",
        "authorId" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "body" : "@viirya So my idea here was that.. since we don't expect these kind of literals a lot i.e its not a common case .. we don't change our normal processing path to add any possible runtime costs. Thats why we keep all these in the exception processing.",
        "createdAt" : "2019-08-02T20:40:59Z",
        "updatedAt" : "2019-08-13T05:04:51Z",
        "lastEditedBy" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "tags" : [
        ]
      },
      {
        "id" : "aac9314e-0dcd-47da-8432-ca6d32793154",
        "parentId" : "16b46643-5bdc-4015-8e23-44ae8375d7f4",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "I like the @viirya approach for readability, but I understand your concern for the performance. So, could you check actual performance changes?",
        "createdAt" : "2019-08-03T13:01:23Z",
        "updatedAt" : "2019-08-13T05:04:51Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "de69f56a-a0fe-4ae4-a733-f1d9fa97059e",
        "parentId" : "16b46643-5bdc-4015-8e23-44ae8375d7f4",
        "authorId" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "body" : "@maropu Oops.. didn't see this comment. I suppose i have to use the benchmark framework for this ? Appreciate any tip on this..",
        "createdAt" : "2019-08-06T05:25:54Z",
        "updatedAt" : "2019-08-13T05:04:51Z",
        "lastEditedBy" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "tags" : [
        ]
      },
      {
        "id" : "50136415-4652-468a-9810-7a7e2079fd08",
        "parentId" : "16b46643-5bdc-4015-8e23-44ae8375d7f4",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Could we check the numbers by a simple query?, e.g.,\r\n```\r\nscala> spark.range(10).selectExpr(\"CAST(double(id) AS STRING) a\").write.save(\"/tmp/test\")\r\nscala> spark.read.load(\"/tmp/test\").selectExpr(\"CAST(a AS DOUBLE)\").write.format(\"noop\").save()\r\n```\r\nIn another pr, I observed that a logic depending on exceptions cause high performance penalties: https://github.com/lz4/lz4-java/pull/143\r\nSo, I'm a bit worried that this current logic has the same issue.",
        "createdAt" : "2019-08-06T23:35:30Z",
        "updatedAt" : "2019-08-13T05:04:51Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "7e4fd649-651d-4a25-bb44-9da8b57188f0",
        "parentId" : "16b46643-5bdc-4015-8e23-44ae8375d7f4",
        "authorId" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "body" : "@maropu Ok.. i will give it a try. One thing to note here is that, we didn't introduce a try/catch in this PR. That was existing before. We just added some extra code in the catch block. However, i will give it a try and get back.",
        "createdAt" : "2019-08-07T00:04:22Z",
        "updatedAt" : "2019-08-13T05:04:51Z",
        "lastEditedBy" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "tags" : [
        ]
      },
      {
        "id" : "503bc7ad-21a2-406c-bc5a-1b66616cd7ba",
        "parentId" : "16b46643-5bdc-4015-8e23-44ae8375d7f4",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Yea, I mean the performance for known strings as @viirya said.",
        "createdAt" : "2019-08-07T00:15:57Z",
        "updatedAt" : "2019-08-13T05:04:51Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "d8f4d7a6-7e55-41e3-b9bd-6154820e3dcb",
        "parentId" : "16b46643-5bdc-4015-8e23-44ae8375d7f4",
        "authorId" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "body" : "@maropu I did the comparison. So our current implementation of handling these special values in the catch block seems to perform better than putting these in the main code path.  Here are the results. I didn't make the change to the codegen path. So lets ignore the second line. The first set of numbers are for the run with current code path. 2nd set of numbers are when these special values are handled in the main code path.\r\n```\r\nJava HotSpot(TM) 64-Bit Server VM 1.8.0_202-b08 on Mac OS X 10.14.6\r\n[info] Intel(R) Core(TM) i7-4870HQ CPU @ 2.50GHz\r\n[info] cast from string to double:               Best Time(ms)   Avg Time(ms)   Stdev(ms)    Rate(M/s)   Per Row(ns)   Relative\r\n[info] ------------------------------------------------------------------------------------------------------------------------\r\n[info] cast from string to double wholestage off           5076           5394         450          0.0       50759.0       1.0X\r\n[info] cast from string to double wholestage on           4709           4876         194          0.0       47093.1       1.1X\r\n[info]\r\n\r\n\r\nJava HotSpot(TM) 64-Bit Server VM 1.8.0_202-b08 on Mac OS X 10.14.6\r\n[info] Intel(R) Core(TM) i7-4870HQ CPU @ 2.50GHz\r\n[info] cast from string to double:               Best Time(ms)   Avg Time(ms)   Stdev(ms)    Rate(M/s)   Per Row(ns)   Relative\r\n[info] ------------------------------------------------------------------------------------------------------------------------\r\n[info] cast from string to double wholestage off           5002           5040          53          0.0       50023.6       1.0X\r\n[info] cast from string to double wholestage on           4926           4976          45          0.0       49258.8       1.0X\r\n~                                                                                                                                 \r\n```\r\n\r\nPlease let me know. Sorry for the delay in getting this to run.",
        "createdAt" : "2019-08-08T09:41:21Z",
        "updatedAt" : "2019-08-13T05:04:51Z",
        "lastEditedBy" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "tags" : [
        ]
      },
      {
        "id" : "ebeee84d-4e9e-4954-a5a2-1f193ee7adce",
        "parentId" : "16b46643-5bdc-4015-8e23-44ae8375d7f4",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Many thanks! I see. What was input data? Some parts of input data include `inf`/`-inf`?",
        "createdAt" : "2019-08-09T01:01:36Z",
        "updatedAt" : "2019-08-13T05:04:51Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "ba1145b4-26c8-4d2c-8194-c0b6d5af7694",
        "parentId" : "16b46643-5bdc-4015-8e23-44ae8375d7f4",
        "authorId" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "body" : "@maropu Actually my input data didn't contain any of these special literals. Basically i was testing with the condition when we don't hit the catch block. Basically we are trying optimize for the best case ?",
        "createdAt" : "2019-08-09T03:55:01Z",
        "updatedAt" : "2019-08-13T05:04:51Z",
        "lastEditedBy" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "tags" : [
        ]
      },
      {
        "id" : "c0c7a6eb-818e-4ae2-911e-cdefbd67e7a2",
        "parentId" : "16b46643-5bdc-4015-8e23-44ae8375d7f4",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "I just make sure that a small number of `inf/-inf` does not worse the prformance. If this is true, I think the current code looks ok to me.",
        "createdAt" : "2019-08-09T04:27:58Z",
        "updatedAt" : "2019-08-13T05:04:51Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "1730c11b-01ad-43c3-94c3-c66353c9d6ce",
        "parentId" : "16b46643-5bdc-4015-8e23-44ae8375d7f4",
        "authorId" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "body" : "@maropu In the mean time i had tried with 1% of data being 'inf' and i can confirm that it does not hurt the performance :-)",
        "createdAt" : "2019-08-09T05:29:00Z",
        "updatedAt" : "2019-08-13T05:04:51Z",
        "lastEditedBy" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "tags" : [
        ]
      },
      {
        "id" : "acb2dd4f-6e6c-49e0-b262-93cb91f8c9ae",
        "parentId" : "16b46643-5bdc-4015-8e23-44ae8375d7f4",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Sounds good.",
        "createdAt" : "2019-08-09T06:01:57Z",
        "updatedAt" : "2019-08-13T05:04:51Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "f60aa399-07bf-4a4a-989e-2d4c9ca89191",
        "parentId" : "16b46643-5bdc-4015-8e23-44ae8375d7f4",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Sounds nice, too ;)",
        "createdAt" : "2019-08-09T09:56:35Z",
        "updatedAt" : "2019-08-13T05:04:51Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "1a5d978707d519fc6cea5eb7caa1b3fe1eb4933f",
    "line" : 55,
    "diffHunk" : "@@ -1,1 +603,607 @@        val floatStr = s.toString\n        try floatStr.toFloat catch {\n          case _: NumberFormatException =>\n            Cast.processFloatingPointSpecialLiterals(floatStr, true)\n        }"
  },
  {
    "id" : "e0fd9f05-0fba-47eb-b263-f555cdafac76",
    "prId" : 25331,
    "prUrl" : "https://github.com/apache/spark/pull/25331#pullrequestreview-272966430",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c58bc43e-b204-47f6-a61d-2a1cd0330a29",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Actually some literals like InFiniTy can be casted, it looks a bit weird. However, postgresql accepts such things. Maybe add a comment here to explain why allowing case insensitive match?",
        "createdAt" : "2019-08-09T06:05:40Z",
        "updatedAt" : "2019-08-13T05:04:51Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "f4a30cd1-c217-40a2-8598-fe3f9d142cd1",
        "parentId" : "c58bc43e-b204-47f6-a61d-2a1cd0330a29",
        "authorId" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "body" : "@viirya Does this look ok ?\r\n\r\nWe process literals such as 'Infinity', 'Inf', '-Infinity' and 'NaN' in case insensitive manner to be compatible with other database systems such as Postgres and DB2.",
        "createdAt" : "2019-08-09T06:22:52Z",
        "updatedAt" : "2019-08-13T05:04:51Z",
        "lastEditedBy" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "tags" : [
        ]
      },
      {
        "id" : "a4b7309d-5aa8-4e19-9cff-86a775ddcd15",
        "parentId" : "c58bc43e-b204-47f6-a61d-2a1cd0330a29",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "I feel ok. Other reviewers may also have advice too.",
        "createdAt" : "2019-08-09T06:41:27Z",
        "updatedAt" : "2019-08-13T05:04:51Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "1a5d978707d519fc6cea5eb7caa1b3fe1eb4933f",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +199,203 @@   * insensitive manner to be compatible with other database systems such as PostgreSQL and DB2.\n   */\n  def processFloatingPointSpecialLiterals(v: String, isFloat: Boolean): Any = {\n    v.trim.toLowerCase(Locale.ROOT) match {\n      case \"inf\" | \"+inf\" | \"infinity\" | \"+infinity\" =>"
  },
  {
    "id" : "5cca87a1-14e6-4e57-b3e4-2eb301ee00aa",
    "prId" : 25300,
    "prUrl" : "https://github.com/apache/spark/pull/25300#pullrequestreview-268784184",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "56fc98bf-d1c1-435b-a2ca-f255652c2662",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "no chance to has the same value accidentally?",
        "createdAt" : "2019-07-31T03:36:57Z",
        "updatedAt" : "2019-08-02T07:09:25Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "5c286e36-f3f1-4d7a-8508-526b8289e856",
        "parentId" : "56fc98bf-d1c1-435b-a2ca-f255652c2662",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "Do you mean: is it possible that`longValue == longValue.toInt` when longValue can't fit into `Int`? \r\nThe `longValue` is long type, so it is impossible.",
        "createdAt" : "2019-07-31T04:49:41Z",
        "updatedAt" : "2019-08-02T07:09:25Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "2346a85a-f578-43bf-9fef-963c02c074f1",
        "parentId" : "56fc98bf-d1c1-435b-a2ca-f255652c2662",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "oh, right. I misunderstood it. Thanks!",
        "createdAt" : "2019-07-31T04:53:28Z",
        "updatedAt" : "2019-08-02T07:09:25Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "63a6e62dd127f1d774ddf6c823527276d481af1d",
    "line" : 66,
    "diffHunk" : "@@ -1,1 +490,494 @@      buildCast[Long](_, t => {\n        val longValue = timestampToLong(t)\n        if (longValue == longValue.toInt) {\n          longValue.toInt\n        } else {"
  },
  {
    "id" : "cab28c51-835e-4ad1-8402-0a1952af963f",
    "prId" : 25300,
    "prUrl" : "https://github.com/apache/spark/pull/25300#pullrequestreview-268828262",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c63fb254-e357-40ad-b430-3d93b95883b7",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "This question might be out-of-scope in this pr though... we don't need round-up here?\r\n```\r\npostgres=# select CAST(3.9 AS INT);\r\n int4 \r\n------\r\n    4\r\n(1 row)\r\n```",
        "createdAt" : "2019-07-31T03:55:34Z",
        "updatedAt" : "2019-08-02T07:09:25Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "2f09e3e4-932e-4b5b-9006-688f06287725",
        "parentId" : "c63fb254-e357-40ad-b430-3d93b95883b7",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "Actually it is tricty to compare float and int if the float value is around Int.MaxValue or Int.MinValue.\r\n```\r\nscala> BigDecimal((Int.MaxValue + 1L).toString).toFloat <= Int.MaxValue\r\nres1: Boolean = true\r\n```\r\nThis is because `float` is also 32 bits long, and it uses 8 bit to represent the exponent field. While `int` is 32 bits long. So the comparison won't be accurate.We don't have to worry about the rounding for Float -> Int.\r\n",
        "createdAt" : "2019-07-31T05:28:01Z",
        "updatedAt" : "2019-08-02T07:09:25Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "5cb8c322-1287-4ea7-8e82-09ade828eb05",
        "parentId" : "c63fb254-e357-40ad-b430-3d93b95883b7",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ur, I see. That behaivour looks interesting...\r\nBut, what I'm just worried about is that the query below has different output;\r\n```\r\n// this pr\r\nscala> sql(\"SELECT CAST(float(3.5) AS INT)\").show\r\n+-------------------------------+\r\n|CAST(CAST(3.5 AS FLOAT) AS INT)|\r\n+-------------------------------+\r\n|                              3|\r\n+-------------------------------+\r\n\r\n// postgresql\r\npostgres=# SELECT CAST(float4 '3.5' AS INT);\r\n int4 \r\n------\r\n    4\r\n(1 row)\r\n\r\n// mysql (no float literal in mysql?)\r\nmysql> SELECT CAST(3.5 AS SIGNED INT);\r\n+-------------------------+\r\n| CAST(3.5 AS SIGNED INT) |\r\n+-------------------------+\r\n|                       4 |\r\n+-------------------------+\r\n1 row in set (0.00 sec)\r\n```\r\nYou mean that, since that comparison is inaccurate, this output difference is ok?",
        "createdAt" : "2019-07-31T07:07:08Z",
        "updatedAt" : "2019-08-02T07:09:25Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "acf9740c-0108-45a8-80cb-70152fdc60c4",
        "parentId" : "c63fb254-e357-40ad-b430-3d93b95883b7",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "Oh I thought you were talking about the corner case.\r\nAs per the SQL standard in section 9.2\r\n> it is implementation- defined whether the approximation is obtained by rounding or by truncation\r\n\r\nSpark always uses truncation. So I think we can simply follow the previous behavior on this. It is out of the scope of this PR.",
        "createdAt" : "2019-07-31T07:20:16Z",
        "updatedAt" : "2019-08-02T07:09:25Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "b9c488d2-ff85-4e6b-bb8a-9a8a3ff8ecd5",
        "parentId" : "c63fb254-e357-40ad-b430-3d93b95883b7",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "yea, ok. thx for your check!",
        "createdAt" : "2019-07-31T07:28:46Z",
        "updatedAt" : "2019-08-02T07:09:25Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "63a6e62dd127f1d774ddf6c823527276d481af1d",
    "line" : 87,
    "diffHunk" : "@@ -1,1 +511,515 @@      buildCast[Float](_, f =>\n        if (f <= Int.MaxValue && f >= Int.MinValue) {\n          f.toInt\n        } else {\n          null"
  },
  {
    "id" : "abd4445e-5163-4559-b530-46b75875588d",
    "prId" : 25300,
    "prUrl" : "https://github.com/apache/spark/pull/25300#pullrequestreview-268781900",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5aa7ff7f-5803-4adc-98d1-190efff84258",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Is this related to this pr?",
        "createdAt" : "2019-07-31T03:59:07Z",
        "updatedAt" : "2019-08-02T07:09:25Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "33beacc6-0188-4e01-b82d-27cf109b6c85",
        "parentId" : "5aa7ff7f-5803-4adc-98d1-190efff84258",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "Yes, converting TimeStamp to Byte/Short/Int type can be null",
        "createdAt" : "2019-07-31T04:41:19Z",
        "updatedAt" : "2019-08-02T07:09:25Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "63a6e62dd127f1d774ddf6c823527276d481af1d",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +181,185 @@    case (FloatType | DoubleType, TimestampType) => true\n    case (TimestampType, DateType) => false\n    case (TimestampType, _: IntegralType) if to != LongType => true\n    case (_, DateType) => true\n    case (DateType, TimestampType) => false"
  },
  {
    "id" : "a24b74bd-145f-40d7-bd0e-7b4f4f452d8a",
    "prId" : 25300,
    "prUrl" : "https://github.com/apache/spark/pull/25300#pullrequestreview-270154735",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "81246983-5514-42c5-8a36-216b229b62f0",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "We need the three entries above? `case x: NumericType` you removed in this pr is enough for those cases?",
        "createdAt" : "2019-08-02T02:24:28Z",
        "updatedAt" : "2019-08-02T07:09:25Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "0a55c580-3d3c-4713-9aae-06c0fc0b09de",
        "parentId" : "81246983-5514-42c5-8a36-216b229b62f0",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "Not sure if there is performance difference here. The motivation is that there are only there types here and by doing this might slightly improve the performance. @rednaxelafx @kiszk ",
        "createdAt" : "2019-08-02T03:22:40Z",
        "updatedAt" : "2019-08-02T07:09:25Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "cce93697-c1d3-4541-b90b-832a0e33ba2e",
        "parentId" : "81246983-5514-42c5-8a36-216b229b62f0",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ur, I see. Good idea to ask the JVM guys, hahaha",
        "createdAt" : "2019-08-02T03:24:15Z",
        "updatedAt" : "2019-08-02T07:09:25Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "90f20413-8ca4-40b1-b765-a91fcc6edace",
        "parentId" : "81246983-5514-42c5-8a36-216b229b62f0",
        "authorId" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "body" : "In summary, I think that this slightly improve improve performance.\r\n\r\nMy guess (I have not seen generated code by HotSpot) is that this cast (e.g. `b.asInstanceOf[Int]`) removes table lookup of invocation of `toLong`. As a result, we expect the code in `toLong` is inlined to caller. On the other hand, the original code (`asInstanceOf[Numeric[Any]].toLong(b)`) has a table lookup for invoking `toLong`. Thus, it is not expected to apply inlining.",
        "createdAt" : "2019-08-02T12:44:29Z",
        "updatedAt" : "2019-08-02T12:44:37Z",
        "lastEditedBy" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "tags" : [
        ]
      }
    ],
    "commit" : "63a6e62dd127f1d774ddf6c823527276d481af1d",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +449,453 @@      b => b.asInstanceOf[Short].toLong\n    case IntegerType =>\n      b => b.asInstanceOf[Int].toLong\n    case FloatType =>\n      buildCast[Float](_, f =>"
  },
  {
    "id" : "f06b4eec-1c1b-4e52-91f4-fe9cf13273fc",
    "prId" : 25300,
    "prUrl" : "https://github.com/apache/spark/pull/25300#pullrequestreview-273287160",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a65aa8c5-d230-455b-9c1f-c19c863fb626",
        "parentId" : null,
        "authorId" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "body" : "Why don't we use the similar condition to others, like `if (f < Int.MaxValue + 1L && f > Int.MinValue - 1L) {`?",
        "createdAt" : "2019-08-09T17:41:07Z",
        "updatedAt" : "2019-08-09T17:41:08Z",
        "lastEditedBy" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "tags" : [
        ]
      },
      {
        "id" : "2ecbc5f4-06d2-4400-aa7d-bc9b4c6f80c7",
        "parentId" : "a65aa8c5-d230-455b-9c1f-c19c863fb626",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "It is quite tricky here. I did some corner tests and decide to do it in this way.  \r\n```\r\nscala> 2147483647.5f < Int.MaxValue + 1L\r\nres2: Boolean = false\r\n\r\nscala> 2147483647.5f <= Int.MaxValue \r\nres3: Boolean = true\r\n```",
        "createdAt" : "2019-08-09T18:09:18Z",
        "updatedAt" : "2019-08-09T18:09:18Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "63a6e62dd127f1d774ddf6c823527276d481af1d",
    "line" : 86,
    "diffHunk" : "@@ -1,1 +510,514 @@    case FloatType =>\n      buildCast[Float](_, f =>\n        if (f <= Int.MaxValue && f >= Int.MinValue) {\n          f.toInt\n        } else {"
  },
  {
    "id" : "6f84d55f-8383-4735-a87c-81c76946ccdb",
    "prId" : 25300,
    "prUrl" : "https://github.com/apache/spark/pull/25300#pullrequestreview-273283092",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "316a3a5d-2830-4882-af1d-71db1df17823",
        "parentId" : null,
        "authorId" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "body" : "Among `castToByteCode`, `castToShortCode`, and `castToIntCode`, can we do refactoring by introducing a helper function that has arguments type as `String`, `MaxValue`, `MinValue`? As a result, we can reduce a similar code.",
        "createdAt" : "2019-08-09T18:00:18Z",
        "updatedAt" : "2019-08-09T18:00:18Z",
        "lastEditedBy" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "tags" : [
        ]
      }
    ],
    "commit" : "63a6e62dd127f1d774ddf6c823527276d481af1d",
    "line" : 258,
    "diffHunk" : "@@ -1,1 +1339,1343 @@      (c, evPrim, evNull) => code\"$evNull = true;\"\n    case TimestampType =>\n      val longValue = ctx.freshName(\"longValue\")\n      (c, evPrim, evNull) =>\n        code\"\"\""
  },
  {
    "id" : "21aad615-4510-48e7-91d6-d81128c5f80e",
    "prId" : 25253,
    "prUrl" : "https://github.com/apache/spark/pull/25253#pullrequestreview-272318782",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1a45d23c-586f-4495-bba4-c81f7fc6102c",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "not a biggie but:\r\n\r\n```scala\r\nif (value.changePrecision(decimalType.precision, decimalType.scale)) {\r\n  value\r\n} else if (nullOnOverflow) {\r\n  null\r\n} else {\r\n  throw new ArithmeticException(s\"${value.toDebugString} cannot be represented as \" +\r\n    s\"Decimal(${decimalType.precision}, ${decimalType.scale}).\")\r\n}\r\n```",
        "createdAt" : "2019-07-25T12:11:47Z",
        "updatedAt" : "2019-08-04T08:02:12Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "9b1759f4-68c6-4bc4-a61f-735f6edb84ae",
        "parentId" : "1a45d23c-586f-4495-bba4-c81f7fc6102c",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "I like the way in this PR. It is more clear about what to do on overflow.",
        "createdAt" : "2019-07-25T18:40:05Z",
        "updatedAt" : "2019-08-04T08:02:12Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "583483f0-c5ba-4943-a07d-3298750a87e7",
        "parentId" : "1a45d23c-586f-4495-bba4-c81f7fc6102c",
        "authorId" : "24e1dd39-ae3f-4bbb-a391-f60afb62d075",
        "body" : "I agree with @gengliangwang but I am fine changing it. Please @HyukjinKwon let me know if you think we should change it, I'll do it. Thanks.",
        "createdAt" : "2019-07-26T07:49:40Z",
        "updatedAt" : "2019-08-04T08:02:12Z",
        "lastEditedBy" : "24e1dd39-ae3f-4bbb-a391-f60afb62d075",
        "tags" : [
        ]
      },
      {
        "id" : "549ab899-007c-4a27-a205-622dd7ffd961",
        "parentId" : "1a45d23c-586f-4495-bba4-c81f7fc6102c",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "ah, that's fine. no big deal.",
        "createdAt" : "2019-08-08T02:43:04Z",
        "updatedAt" : "2019-08-08T02:43:04Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "23b8ee1c815ca3d82fe56d6face945b7de8b4574",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +513,517 @@    if (value.changePrecision(decimalType.precision, decimalType.scale)) {\n      value\n    } else {\n      if (nullOnOverflow) {\n        null"
  },
  {
    "id" : "d5b70cb9-905b-4ce3-b667-ff0fc4a9804b",
    "prId" : 25253,
    "prUrl" : "https://github.com/apache/spark/pull/25253#pullrequestreview-268221372",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3f673fed-f876-4f72-91f2-50020d7726cc",
        "parentId" : null,
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "Nit: should we just use ${decimalType.catalogString} here?",
        "createdAt" : "2019-07-25T18:39:35Z",
        "updatedAt" : "2019-08-04T08:02:12Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "4001faea-9f5d-46c7-abee-d2be20a112e8",
        "parentId" : "3f673fed-f876-4f72-91f2-50020d7726cc",
        "authorId" : "24e1dd39-ae3f-4bbb-a391-f60afb62d075",
        "body" : "this is consistent with other similar error messages. We should change it in all cases, then. WDYT?",
        "createdAt" : "2019-07-26T07:51:20Z",
        "updatedAt" : "2019-08-04T08:02:12Z",
        "lastEditedBy" : "24e1dd39-ae3f-4bbb-a391-f60afb62d075",
        "tags" : [
        ]
      },
      {
        "id" : "33475c9c-9aec-46e0-9259-c768ebdba567",
        "parentId" : "3f673fed-f876-4f72-91f2-50020d7726cc",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "This is trivial. Maybe we can have another PR to fix it.",
        "createdAt" : "2019-07-30T08:08:31Z",
        "updatedAt" : "2019-08-04T08:02:12Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "23b8ee1c815ca3d82fe56d6face945b7de8b4574",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +518,522 @@      } else {\n        throw new ArithmeticException(s\"${value.toDebugString} cannot be represented as \" +\n          s\"Decimal(${decimalType.precision}, ${decimalType.scale}).\")\n      }\n    }"
  },
  {
    "id" : "2d4497e1-1872-4e97-898b-9a252dcc43fe",
    "prId" : 25253,
    "prUrl" : "https://github.com/apache/spark/pull/25253#pullrequestreview-270457946",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b72826c2-6b37-4d8f-b340-52497168afcc",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "nit: can you update the description?",
        "createdAt" : "2019-08-03T12:18:41Z",
        "updatedAt" : "2019-08-04T08:02:12Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "23b8ee1c815ca3d82fe56d6face945b7de8b4574",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +510,514 @@   * NOTE: this modifies `value` in-place, so don't call it on external data.\n   */\n  private[this] def changePrecision(value: Decimal, decimalType: DecimalType): Decimal = {\n    if (value.changePrecision(decimalType.precision, decimalType.scale)) {\n      value"
  },
  {
    "id" : "7a94ac57-d54b-42d8-9f6c-cd137e50197a",
    "prId" : 25242,
    "prUrl" : "https://github.com/apache/spark/pull/25242#pullrequestreview-266066779",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "98d5451d-0be1-4685-81e8-029fbfe6548c",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "How about `UserDefinedType`?",
        "createdAt" : "2019-07-24T12:26:08Z",
        "updatedAt" : "2019-07-25T07:03:21Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "78fe4d4e-6a2e-4129-88aa-419841ebf09e",
        "parentId" : "98d5451d-0be1-4685-81e8-029fbfe6548c",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "I don't think it is valid up-cast.\r\nEven in `Cast`, Spark only allows casting to the same udt.\r\n```\r\ncase udt: UserDefinedType[_]\r\n          if udt.userClass == from.asInstanceOf[UserDefinedType[_]].userClass =>\r\n          identity[Any]\r\ncase _: UserDefinedType[_] =>\r\n          throw new SparkException(s\"Cannot cast $from to $to.\")\r\n```",
        "createdAt" : "2019-07-24T14:20:19Z",
        "updatedAt" : "2019-07-25T07:03:21Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "81ffc621-2794-4039-9729-598e902880fb",
        "parentId" : "98d5451d-0be1-4685-81e8-029fbfe6548c",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Yup, I also think the case is not valid. So, my question is just that the cast is accepted before this pr? If so, it might be better to add tests for that, too.",
        "createdAt" : "2019-07-24T14:37:16Z",
        "updatedAt" : "2019-07-25T07:03:21Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "6c590a0ea0a83bf39825e345341fc8815ed32f3f",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +133,137 @@    case (DateType, TimestampType) => true\n    case (_: AtomicType, StringType) => true\n    case (_: CalendarIntervalType, StringType) => true\n\n    // Spark supports casting between long and timestamp, please see `longToTimestamp` and"
  },
  {
    "id" : "9d89b8f6-9f28-4fa0-9b20-e58a6ff36aae",
    "prId" : 24872,
    "prUrl" : "https://github.com/apache/spark/pull/24872#pullrequestreview-250200929",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f2fcf3f2-a8fe-4d1a-911e-99fc45fed2f4",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "This will be a correct fix. Do we have a possibility of performance regression?",
        "createdAt" : "2019-06-15T17:31:12Z",
        "updatedAt" : "2019-06-18T00:46:07Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "e0ae14b0f827e55f23b94b5ecc60d59c7a0b8bb1",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +434,438 @@    case StringType =>\n      val result = new LongWrapper()\n      buildCast[UTF8String](_, s => if (s.trim.toLong(result)) result.value else null)\n    case BooleanType =>\n      buildCast[Boolean](_, b => if (b) 1L else 0L)"
  },
  {
    "id" : "078f9878-92c8-4e72-a0d5-fa907258d250",
    "prId" : 24872,
    "prUrl" : "https://github.com/apache/spark/pull/24872#pullrequestreview-250939904",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "444616f0-bcf8-44ee-91d2-e5c9dde27c64",
        "parentId" : null,
        "authorId" : "24e1dd39-ae3f-4bbb-a391-f60afb62d075",
        "body" : "nit: `$c.trim().toString()` may be more efficient?",
        "createdAt" : "2019-06-18T08:39:00Z",
        "updatedAt" : "2019-06-18T08:42:27Z",
        "lastEditedBy" : "24e1dd39-ae3f-4bbb-a391-f60afb62d075",
        "tags" : [
        ]
      }
    ],
    "commit" : "e0ae14b0f827e55f23b94b5ecc60d59c7a0b8bb1",
    "line" : 68,
    "diffHunk" : "@@ -1,1 +984,988 @@          code\"\"\"\n            try {\n              Decimal $tmp = Decimal.apply(new java.math.BigDecimal($c.toString().trim()));\n              ${changePrecision(tmp, target, evPrim, evNull, canNullSafeCast)}\n            } catch (java.lang.NumberFormatException e) {"
  },
  {
    "id" : "fc265891-2cbb-4db9-845f-3fdc189fd580",
    "prId" : 24806,
    "prUrl" : "https://github.com/apache/spark/pull/24806#pullrequestreview-248962994",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cd82c85b-793a-40ff-9bbd-59f44cface1d",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Why can't we upcast null to other nullable types? I think it's pretty common to write `INSERT INTO tbl VALUES (1, null)`",
        "createdAt" : "2019-06-12T06:58:18Z",
        "updatedAt" : "2019-06-12T07:26:18Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "8dcd78d9-3bcd-47d9-8db1-5e7d5b6c734a",
        "parentId" : "cd82c85b-793a-40ff-9bbd-59f44cface1d",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "Here we can't know the nullability of the `to` type. We should consider it is not nullable.\r\nFor the case you mentioned, it is handled in https://github.com/apache/spark/pull/24806/files#diff-86e655772e8f7cab055d2c2451b52275R134.",
        "createdAt" : "2019-06-12T07:56:37Z",
        "updatedAt" : "2019-06-12T07:56:37Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "5f7c0ecf-7c12-469d-ad66-e8763058d841",
        "parentId" : "cd82c85b-793a-40ff-9bbd-59f44cface1d",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "I agree with @cloud-fan that this should be allowed. Nullability is an additional check, but the types are compatible.",
        "createdAt" : "2019-06-12T19:10:46Z",
        "updatedAt" : "2019-06-12T19:10:47Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      }
    ],
    "commit" : "3e2949131a8a7579149a7dd4153650461f5b5da2",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +132,136 @@\n    case (DateType, TimestampType) => true\n    case (NullType, _) => false\n    case (_, StringType) => true\n"
  }
]