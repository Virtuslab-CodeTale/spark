[
  {
    "id" : "0448c95c-eaa6-4e24-9725-9e4206b400c2",
    "prId" : 33146,
    "prUrl" : "https://github.com/apache/spark/pull/33146#pullrequestreview-697161729",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a236b0e6-1f0b-4615-8902-92772097fddb",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "if `fields(0).nullable` is false, how can `row.isNullAt(0)` be true?",
        "createdAt" : "2021-06-30T13:11:33Z",
        "updatedAt" : "2021-06-30T13:11:33Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "0d476922-445e-4af8-ab0c-48659f924bb1",
        "parentId" : "a236b0e6-1f0b-4615-8902-92772097fddb",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "(I have the same question)",
        "createdAt" : "2021-07-01T02:03:20Z",
        "updatedAt" : "2021-07-01T02:03:27Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "35b515c3-1bd4-42f3-9113-4306cedb8dbd",
        "parentId" : "a236b0e6-1f0b-4615-8902-92772097fddb",
        "authorId" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "body" : "If user create dataframe from `spark.internalCreateDataFrame()`, the `row.isNullAt()` may be true even though the schema nullable is false.\r\nFor instance:\r\n```scala\r\n  val schema = StructType(Seq(\r\n    StructField(\"x\",\r\n      StructType(Seq(\r\n        StructField(\"y\", IntegerType, true),\r\n        StructField(\"z\", IntegerType, false)\r\n      )))))\r\n  val rdd = spark.sparkContext.parallelize(Seq(InternalRow(InternalRow(1, null))))\r\n  val df = spark.internalCreateDataFrame(rdd, schema)\r\n  df.show\r\n  // current master branch output\r\n  //  +---------+\r\n  //  |        x|\r\n  //  +---------+\r\n  //  |{1, null}|\r\n  //  +---------+\r\n```\r\n\r\nAlthough the `spark.internalCreateDataFrame()` is sql package private API, but `spark.read.json()` and `spark.read.csv()` call it without null value handled.(the example show in pr description)\r\n",
        "createdAt" : "2021-07-01T03:28:58Z",
        "updatedAt" : "2021-07-01T03:34:21Z",
        "lastEditedBy" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "tags" : [
        ]
      },
      {
        "id" : "992483e1-a9e1-40e7-90a8-fde414f35e1d",
        "parentId" : "a236b0e6-1f0b-4615-8902-92772097fddb",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Then we need to fix the nullability. There are so many places in the Spark codebase that relies on nullability to do optimizations. It's not possible to change all of them to not trust the nullability anymore.\r\n\r\nCan we fix `spark.read.json()` to set the nullability correctly?",
        "createdAt" : "2021-07-01T04:54:55Z",
        "updatedAt" : "2021-07-01T04:54:55Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "c637ef51-49df-40ec-bb82-6a4cbd7608ca",
        "parentId" : "a236b0e6-1f0b-4615-8902-92772097fddb",
        "authorId" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "body" : "Ok, let me try.",
        "createdAt" : "2021-07-01T12:05:41Z",
        "updatedAt" : "2021-07-01T12:05:41Z",
        "lastEditedBy" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "tags" : [
        ]
      }
    ],
    "commit" : "25c396c3e30679f11318d3a0c449306b12762af2",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +407,411 @@          val st = fields.map(_.dataType)\n          val toUTF8StringFuncs = st.map(castToString)\n          if (fields(0).nullable && row.isNullAt(0)) {\n            if (!legacyCastToStr) builder.append(\"null\")\n          } else {"
  },
  {
    "id" : "280b6a05-7062-4571-ae27-1d6c0830e972",
    "prId" : 33027,
    "prUrl" : "https://github.com/apache/spark/pull/33027#pullrequestreview-690205328",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7b107d8f-d520-4c9b-a1bd-bdcb16c56f72",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I checked `Add`, I think we should also add a new `def this` to allow omitting the `ansiEnabled` parameter, to get a bit more compatibility, such as `new Cast(...)`",
        "createdAt" : "2021-06-23T04:41:30Z",
        "updatedAt" : "2021-06-23T04:41:30Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "55891cfc9df412ae34dda7d5f3f6c98c832f4c01",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +1949,1953 @@    override val ansiEnabled: Boolean = SQLConf.get.ansiEnabled)\n  extends CastBase {\n\n  def this(child: Expression, dataType: DataType, timeZoneId: Option[String]) =\n    this(child, dataType, timeZoneId, ansiEnabled = SQLConf.get.ansiEnabled)"
  },
  {
    "id" : "6bff4828-50ff-498e-a993-a32d908d241e",
    "prId" : 32869,
    "prUrl" : "https://github.com/apache/spark/pull/32869#pullrequestreview-681084858",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f2f9c149-b314-456f-a022-6388f95f66d6",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "nit: we can add a `protected def dtUtilCls = classOf[DateTimeUtils].getClass.getName` in `CaseBase`, to shorten the code here and other places.",
        "createdAt" : "2021-06-10T17:47:30Z",
        "updatedAt" : "2021-06-10T17:47:30Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "dde4cd800a3d2e9aac55d05b5d99cc00fba0a2e6",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +1211,1215 @@        (c, evPrim, evNull) =>\n          // scalastyle:off line.size.limit\n          code\"$evPrim = org.apache.spark.sql.catalyst.util.DateTimeUtils.microsToDays($c, java.time.ZoneOffset.UTC);\"\n          // scalastyle:on line.size.limit\n      case _ =>"
  },
  {
    "id" : "098dcb66-4af0-4ab7-a427-f003989d7ff0",
    "prId" : 32864,
    "prUrl" : "https://github.com/apache/spark/pull/32864#pullrequestreview-680879169",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cf338e96-5ee6-4573-aaf9-b4944bbce0d9",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "how about the other way around?",
        "createdAt" : "2021-06-10T14:35:53Z",
        "updatedAt" : "2021-06-10T14:35:53Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "7d4e9f7e-8692-4ac1-8c9f-38eb6eb94965",
        "parentId" : "cf338e96-5ee6-4573-aaf9-b4944bbce0d9",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "It will be added in another PR",
        "createdAt" : "2021-06-10T14:43:46Z",
        "updatedAt" : "2021-06-10T14:43:46Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "b47219a0498192ae217ea18582bbc37cd5969bd7",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +69,73 @@    case (DateType, TimestampType) => true\n    case (_: NumericType, TimestampType) => true\n    case (TimestampWithoutTZType, TimestampType) => true\n\n    case (StringType, DateType) => true"
  },
  {
    "id" : "3786e456-6cea-466a-a342-c0721c886ecb",
    "prId" : 31954,
    "prUrl" : "https://github.com/apache/spark/pull/31954#pullrequestreview-621290840",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c96275e9-93fa-4b1f-8685-c95f5114d34f",
        "parentId" : null,
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "Does this affect the coming year-month and day-time interval?",
        "createdAt" : "2021-03-24T16:12:13Z",
        "updatedAt" : "2021-03-25T13:35:48Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "12697dbc-30aa-4972-b28b-464e78d0c3ae",
        "parentId" : "c96275e9-93fa-4b1f-8685-c95f5114d34f",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "Yes",
        "createdAt" : "2021-03-24T16:41:25Z",
        "updatedAt" : "2021-03-25T13:35:48Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "ab3948e9-2c2a-4050-b132-b5475b497c3c",
        "parentId" : "c96275e9-93fa-4b1f-8685-c95f5114d34f",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "@cloud-fan . Usually, we do the explicitly allowed-list approach in case of types. Is this change okay?\r\nIf this PR aims for `complex type` only, why don't we add them explicitly instead of doing this widely. ",
        "createdAt" : "2021-03-24T19:01:29Z",
        "updatedAt" : "2021-03-25T13:35:48Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "2e36f1c3-cc76-4030-83ae-3229a0f1e44b",
        "parentId" : "c96275e9-93fa-4b1f-8685-c95f5114d34f",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Also, cc @MaxGekk ",
        "createdAt" : "2021-03-24T19:02:01Z",
        "updatedAt" : "2021-03-25T13:35:48Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "d9b2e167-6747-41d7-82e2-50a915e86ade",
        "parentId" : "c96275e9-93fa-4b1f-8685-c95f5114d34f",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "`df.show` needs to cast the column to string, I think we need to support casting from all the data types here, otherwise `df.show` may still be broken under some cases.",
        "createdAt" : "2021-03-25T13:29:43Z",
        "updatedAt" : "2021-03-25T13:35:48Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "c878e638-c88a-42e5-b3a5-e3047e62ff65",
        "parentId" : "c96275e9-93fa-4b1f-8685-c95f5114d34f",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "So far, we don't support such casting. I opened the JIRAs for that: SPARK-34667 and SPARK-34668",
        "createdAt" : "2021-03-25T15:56:00Z",
        "updatedAt" : "2021-03-25T15:56:05Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "1707885814cf846d567fdbca65a2ded88643d679",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +1874,1878 @@    case (NullType, _) => true\n\n    case (_, StringType) => true\n\n    case (StringType, _: BinaryType) => true"
  },
  {
    "id" : "09820b11-6540-4755-8565-ad4127963dd0",
    "prId" : 31228,
    "prUrl" : "https://github.com/apache/spark/pull/31228#pullrequestreview-571326802",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f0a7ef35-d48b-420d-9bde-38ba06480885",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "we also need to change the codegen path.",
        "createdAt" : "2021-01-18T13:47:53Z",
        "updatedAt" : "2021-01-21T12:56:18Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "0353a190-8b95-4075-a7e4-53391c984663",
        "parentId" : "f0a7ef35-d48b-420d-9bde-38ba06480885",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "OK",
        "createdAt" : "2021-01-19T04:45:14Z",
        "updatedAt" : "2021-01-21T12:56:18Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      },
      {
        "id" : "e27d4916-700f-46a2-8190-c26bbffc6a05",
        "parentId" : "f0a7ef35-d48b-420d-9bde-38ba06480885",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "OK",
        "createdAt" : "2021-01-19T14:58:07Z",
        "updatedAt" : "2021-01-21T12:56:18Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "182d957ae72a108ea30032bb07368fbf90a72a61",
    "line" : 54,
    "diffHunk" : "@@ -1,1 +634,638 @@          longValue.toByte\n        } else {\n          throw QueryExecutionErrors.castingCauseOverflowError(t, Byte.getClass.getName)\n        }\n      })"
  },
  {
    "id" : "1c225765-da54-4cd4-9b29-d6b159d5a861",
    "prId" : 30874,
    "prUrl" : "https://github.com/apache/spark/pull/30874#pullrequestreview-556515068",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "058cb642-5b37-44fb-93d5-d75a2274606e",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "iff is 'if and only if'",
        "createdAt" : "2020-12-21T16:38:17Z",
        "updatedAt" : "2020-12-21T16:38:17Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "fd32bad5-3383-4a68-9430-c6dc02686869",
        "parentId" : "058cb642-5b37-44fb-93d5-d75a2274606e",
        "authorId" : "6acb4d7a-9c99-4a6f-a3ba-70ff202fef81",
        "body" : "Thank you!",
        "createdAt" : "2020-12-21T16:43:23Z",
        "updatedAt" : "2020-12-21T16:43:41Z",
        "lastEditedBy" : "6acb4d7a-9c99-4a6f-a3ba-70ff202fef81",
        "tags" : [
        ]
      }
    ],
    "commit" : "13e5c4dd49d2daecf337fa31c74312f4f633d680",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +40,44 @@\n  /**\n   * Returns true if we can cast `from` type to `to` type.\n   */\n  def canCast(from: DataType, to: DataType): Boolean = (from, to) match {"
  }
]