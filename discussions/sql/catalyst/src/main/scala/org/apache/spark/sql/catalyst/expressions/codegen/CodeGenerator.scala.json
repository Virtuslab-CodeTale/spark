[
  {
    "id" : "721522b7-f692-40b1-9202-e731f81852c9",
    "prId" : 33082,
    "prUrl" : "https://github.com/apache/spark/pull/33082#pullrequestreview-693355074",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3d4fa73f-a4cc-4b81-bbcc-4e29ecda093b",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Oh, some `SubExprEliminationState` contains not `VariableValue` but still some statements that includes other expressions?",
        "createdAt" : "2021-06-26T15:58:06Z",
        "updatedAt" : "2021-06-26T15:58:06Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "fefae5b8-ef5d-457e-86f4-19e6a8c5b875",
        "parentId" : "3d4fa73f-a4cc-4b81-bbcc-4e29ecda093b",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> Oh, some `SubExprEliminationState` contains not `VariableValue` but still some statements that includes other expressions?\r\n\r\nYes, the expression contains input var  may match `SubExprEliminationState` and just skiped.",
        "createdAt" : "2021-06-26T16:22:45Z",
        "updatedAt" : "2021-06-26T16:22:45Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "cf3acf02-42d3-4d4c-ba3f-06d928eef6fe",
        "parentId" : "3d4fa73f-a4cc-4b81-bbcc-4e29ecda093b",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Hmm, after second look, it looks not root cause. A subexpr should be evaluated before using it. \r\n\r\nSo technically all its children expressions are not needed.\r\n\r\nI found the root cause. `PromotePrecision` overwrites `Expression.genCode` where is subexpression replace happens. So `PromotePrecision` skips subexpression elimination. I will submit another PR and include your test as co-author there. Thanks.",
        "createdAt" : "2021-06-26T20:39:08Z",
        "updatedAt" : "2021-06-26T20:39:55Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "1a90927831a07b6d77c118d4575d1f2c96bd6089",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +1780,1784 @@          val SubExprEliminationState(isNull, value) = subExprs(e)\n          collectLocalVariable(value, e)\n          collectLocalVariable(isNull, e)\n\n        case ref: BoundReference if ctx.currentVars != null &&"
  },
  {
    "id" : "958e51f1-8942-41ef-ba64-648452aacb06",
    "prId" : 32980,
    "prUrl" : "https://github.com/apache/spark/pull/32980#pullrequestreview-688685850",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f03fa64a-e694-4189-ae53-4ca4361a08de",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Now this looks very similar to `ExprCode` with children tracked...",
        "createdAt" : "2021-06-21T17:13:01Z",
        "updatedAt" : "2021-06-21T17:13:01Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "b000798e-8473-4ab3-b6a7-6d18640ef060",
        "parentId" : "f03fa64a-e694-4189-ae53-4ca4361a08de",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Yea, maybe eliminate this and reuse `ExprCode`?",
        "createdAt" : "2021-06-21T17:16:41Z",
        "updatedAt" : "2021-06-21T17:16:41Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "014bc8b69854efd98d1458a01996a9cbf2741721",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +84,88 @@ *                 to make sure we evaluate all children subexpressions too.\n */\ncase class SubExprEliminationState(\n  eval: ExprCode,\n  children: Seq[SubExprEliminationState])"
  },
  {
    "id" : "5e2e9a48-76f4-49d9-af64-a589af8354bc",
    "prId" : 32980,
    "prUrl" : "https://github.com/apache/spark/pull/32980#pullrequestreview-688697308",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "46ebaf9d-3d95-4108-a59c-b1438acd079a",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "We may need to improve the method doc of `subexpressionEliminationForWholeStageCodegen`. I can hardly understand this method now...",
        "createdAt" : "2021-06-21T17:28:51Z",
        "updatedAt" : "2021-06-21T17:28:51Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "3fc0791a-7575-4189-a153-e0cb8996b75d",
        "parentId" : "46ebaf9d-3d95-4108-a59c-b1438acd079a",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Okay, I noticed it grows a bit longer. Let me add more comments.",
        "createdAt" : "2021-06-21T17:30:09Z",
        "updatedAt" : "2021-06-21T17:30:10Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "014bc8b69854efd98d1458a01996a9cbf2741721",
    "line" : 196,
    "diffHunk" : "@@ -1,1 +1205,1209 @@    }\n    SubExprCodes(subExprsMap.toMap, exprCodes.flatten)\n  }\n\n  /**"
  },
  {
    "id" : "b51bdddd-5b36-492f-98f8-bebd1e0486c9",
    "prId" : 32980,
    "prUrl" : "https://github.com/apache/spark/pull/32980#pullrequestreview-689861286",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3551f601-cc77-4496-b3d3-fda90de4fee6",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Your previous PR improves `EquivalentExpressions` to always return child subexpression first. It seems that PR is not useful after this PR because we track the children explicitly?",
        "createdAt" : "2021-06-22T09:30:44Z",
        "updatedAt" : "2021-06-22T09:30:44Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "fb9b7276-158e-4ddb-bb52-5823ca466e0a",
        "parentId" : "3551f601-cc77-4496-b3d3-fda90de4fee6",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Not exactly. We need to return child subexpressions first. So we can make sure child subexpression is codegen-ed and put into the map before parent subexpression. When we want to codegen parent subexpression, it can look up the child subexpression and put it as child of the parent.\r\n\r\n\r\n",
        "createdAt" : "2021-06-22T16:35:18Z",
        "updatedAt" : "2021-06-22T16:35:19Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "130dbd51-9d8c-40be-b6e1-e31562d756ba",
        "parentId" : "3551f601-cc77-4496-b3d3-fda90de4fee6",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Actually I have a new idea for how to codegen subexpression following child-parent orders without sorting. It is more reliable than the sorting approach. I will open another PR for that.",
        "createdAt" : "2021-06-22T18:21:41Z",
        "updatedAt" : "2021-06-22T23:12:31Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "014bc8b69854efd98d1458a01996a9cbf2741721",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +82,86 @@ *                 subexpressions first. This is used if we want to selectively evaluate\n *                 particular subexpressions, instead of all at once. In the case, we need\n *                 to make sure we evaluate all children subexpressions too.\n */\ncase class SubExprEliminationState("
  },
  {
    "id" : "2567e992-7193-4923-87f6-1f3487519e78",
    "prId" : 32980,
    "prUrl" : "https://github.com/apache/spark/pull/32980#pullrequestreview-693500198",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5bef9d59-82ba-43df-b0c8-760927a79ef6",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "nit: `Iterable` -> `Seq`?",
        "createdAt" : "2021-06-28T00:29:37Z",
        "updatedAt" : "2021-06-28T00:44:30Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "a176cca2-116a-432f-89d3-526e36bdcf71",
        "parentId" : "5bef9d59-82ba-43df-b0c8-760927a79ef6",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "All its caller side use `Iterable`. If changing to `Seq` here, all callers need to add `.toSeq`.",
        "createdAt" : "2021-06-28T02:35:05Z",
        "updatedAt" : "2021-06-28T02:35:05Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "014bc8b69854efd98d1458a01996a9cbf2741721",
    "line" : 59,
    "diffHunk" : "@@ -1,1 +1049,1053 @@   * evaluation.\n   */\n  def evaluateSubExprEliminationState(subExprStates: Iterable[SubExprEliminationState]): String = {\n    val code = new StringBuilder()\n"
  },
  {
    "id" : "197f3ef6-01b0-426f-a900-dabbb2e4ac10",
    "prId" : 32980,
    "prUrl" : "https://github.com/apache/spark/pull/32980#pullrequestreview-694337450",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "aa6f1e59-5c4d-43e8-8ea7-f8ea0934d3a3",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Q: Is it difficult to add some tests for this new behaviour?",
        "createdAt" : "2021-06-28T00:43:58Z",
        "updatedAt" : "2021-06-28T00:44:30Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "9896cdbc-686e-4324-a26f-e51118757479",
        "parentId" : "aa6f1e59-5c4d-43e8-8ea7-f8ea0934d3a3",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Let me add a few tests.",
        "createdAt" : "2021-06-28T02:47:57Z",
        "updatedAt" : "2021-06-28T02:47:57Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "515217b5-862e-4f08-8bf3-50303ca41e86",
        "parentId" : "aa6f1e59-5c4d-43e8-8ea7-f8ea0934d3a3",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Added new test.",
        "createdAt" : "2021-06-28T19:52:21Z",
        "updatedAt" : "2021-06-28T19:52:21Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "014bc8b69854efd98d1458a01996a9cbf2741721",
    "line" : 124,
    "diffHunk" : "@@ -1,1 +1117,1121 @@          exprs.head.foreach {\n            case e if subExprEliminationExprs.contains(e) =>\n              childrenSubExprs += subExprEliminationExprs(e)\n            case _ =>\n          }"
  },
  {
    "id" : "4e4a496b-757a-4dc8-a389-587ba0fa0426",
    "prId" : 32980,
    "prUrl" : "https://github.com/apache/spark/pull/32980#pullrequestreview-695353867",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ccdd27dd-ffd8-4b42-b956-b7fbfabdceeb",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "We need to add some comments to explain the assumption: this code works because `EquivalentExpressions` returns child expressions first.",
        "createdAt" : "2021-06-29T14:41:10Z",
        "updatedAt" : "2021-06-29T14:41:10Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "7d3d6fc3-8ec8-4acf-87ff-3a1f0a0bdaaa",
        "parentId" : "ccdd27dd-ffd8-4b42-b956-b7fbfabdceeb",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "BTW collecting child expressions here looks really inefficient, but I don't have a better idea for now ...",
        "createdAt" : "2021-06-29T14:42:49Z",
        "updatedAt" : "2021-06-29T14:42:49Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "3bb987a6-e5e9-43b1-9c9e-ea96d684a38e",
        "parentId" : "ccdd27dd-ffd8-4b42-b956-b7fbfabdceeb",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "I see. This is not general expression but special (subexpr) ones, so we don't do collecting child expressions in general but in limited range. Except that if you have many subexpr and they are highly nested.",
        "createdAt" : "2021-06-29T15:44:43Z",
        "updatedAt" : "2021-06-29T15:44:43Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "6648232a-1fab-45bd-b167-0d31977e755a",
        "parentId" : "ccdd27dd-ffd8-4b42-b956-b7fbfabdceeb",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "> We need to add some comments to explain the assumption: this code works because EquivalentExpressions returns child expressions first.\r\n\r\nAs I commented before, I plan to remove the sorting. A better idea is to add `SubExprEliminationState` first into the map (not codegen yet). Then during codegen, we can look at the map to chain children.\r\n",
        "createdAt" : "2021-06-29T18:10:49Z",
        "updatedAt" : "2021-06-29T18:10:49Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "014bc8b69854efd98d1458a01996a9cbf2741721",
    "line" : 123,
    "diffHunk" : "@@ -1,1 +1116,1120 @@          val childrenSubExprs = mutable.ArrayBuffer.empty[SubExprEliminationState]\n          exprs.head.foreach {\n            case e if subExprEliminationExprs.contains(e) =>\n              childrenSubExprs += subExprEliminationExprs(e)\n            case _ =>"
  },
  {
    "id" : "607f7ac9-a230-4c32-9e1c-26b7178e54b5",
    "prId" : 32980,
    "prUrl" : "https://github.com/apache/spark/pull/32980#pullrequestreview-695206786",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a18850e6-d3b2-4b4a-bc21-6d4a236b83d0",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Not related to this PR: so here we repeat the logic of generating `SubExprEliminationState`s with splitting the code? `nonSplitCode` is totally wasted?",
        "createdAt" : "2021-06-29T14:49:04Z",
        "updatedAt" : "2021-06-29T14:49:04Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "7c7c40dc-6d77-443b-aa2c-4507a203e756",
        "parentId" : "a18850e6-d3b2-4b4a-bc21-6d4a236b83d0",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Previously it is lazy so we can do non-split conditionally. Now we nestedly generate subExprs so it cannot be lazy now. `SubExprEliminationStates` are needed to nestedly generate code for them.",
        "createdAt" : "2021-06-29T15:42:47Z",
        "updatedAt" : "2021-06-29T15:42:47Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "014bc8b69854efd98d1458a01996a9cbf2741721",
    "line" : 147,
    "diffHunk" : "@@ -1,1 +1139,1143 @@\n    val needSplit = nonSplitCode.map(_.eval.code.length).sum > SQLConf.get.methodSplitThreshold\n    val (subExprsMap, exprCodes) = if (needSplit) {\n      if (inputVarsForAllFuncs.map(calculateParamLengthFromExprValues).forall(isValidParamLength)) {\n        val localSubExprEliminationExprs ="
  },
  {
    "id" : "fa737e17-ed33-47ec-b35e-b22d69c2f4dc",
    "prId" : 32980,
    "prUrl" : "https://github.com/apache/spark/pull/32980#pullrequestreview-704456752",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "62dced9c-151b-4ac7-a3c3-2d08fc051189",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "nit: shall we use `subexprFunctions += subExprCode` here? otherwise we are calling `addNewFunction` twice.",
        "createdAt" : "2021-07-12T18:05:18Z",
        "updatedAt" : "2021-07-12T18:05:19Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "7c122d59-3a9e-49c2-b3d7-22c977190112",
        "parentId" : "62dced9c-151b-4ac7-a3c3-2d08fc051189",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Oh yes, as the functions in class is a map, it will overwrite. But yes, we should use `subExprCode`. Let me submit a followup.",
        "createdAt" : "2021-07-12T19:10:56Z",
        "updatedAt" : "2021-07-12T19:10:56Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "3ade6d53-8edb-437c-86fd-c600760da090",
        "parentId" : "62dced9c-151b-4ac7-a3c3-2d08fc051189",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "#33305",
        "createdAt" : "2021-07-12T19:14:28Z",
        "updatedAt" : "2021-07-12T19:14:28Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "014bc8b69854efd98d1458a01996a9cbf2741721",
    "line" : 204,
    "diffHunk" : "@@ -1,1 +1251,1255 @@\n      val subExprCode = s\"${addNewFunction(fnName, fn)}($INPUT_ROW);\"\n      subexprFunctions += s\"${addNewFunction(fnName, fn)}($INPUT_ROW);\"\n      val state = SubExprEliminationState(\n        ExprCode(code\"$subExprCode\","
  },
  {
    "id" : "da505aca-f799-4e6f-b902-96442a40f206",
    "prId" : 32699,
    "prUrl" : "https://github.com/apache/spark/pull/32699#pullrequestreview-672471375",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4f4ba443-055d-4fcb-b348-93df6c259ee0",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "what does this recursive call of `withSubExprEliminationExprs` give us?",
        "createdAt" : "2021-05-31T07:03:21Z",
        "updatedAt" : "2021-05-31T07:03:21Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "a5873dfb-6c6b-48e6-ad28-a2de661f0dd5",
        "parentId" : "4f4ba443-055d-4fcb-b348-93df6c259ee0",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "For each set of common expressions, `withSubExprEliminationExprs` only called once so I think it is not actually a recursive call?\r\n\r\n`withSubExprEliminationExprs` takes the given map used for subexpression elimination to replace common expression during expression codegen in the closure. It returns evaluated expression code (value/isNull/code).\r\n\r\nFor the two subexpressions as example:\r\n\r\n1. `simpleUDF($\"id\")`\r\n2. `functions.length(simpleUDF($\"id\"))`\r\n\r\n1st round `withSubExprEliminationExprs`:\r\n\r\nThe map is empty.\r\nGen code for `simpleUDF($\"id\")`.\r\nPut it into the map => (`simpleUDF($\"id\")` -> gen-ed code)\r\n\r\n2nd round `withSubExprEliminationExprs`:\r\n\r\nGen code for `functions.length(simpleUDF($\"id\"))`.\r\nLooking at the map and replace common expression `simpleUDF($\"id\")` as gen-ed code.\r\nPut it into the map => (`simpleUDF($\"id\")` -> gen-ed code, `functions.length(simpleUDF($\"id\"))` -> gen-ed code)\r\n\r\nThe map will be used later for subexpression elimination.\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
        "createdAt" : "2021-05-31T17:43:29Z",
        "updatedAt" : "2021-05-31T17:43:29Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "f1f64f7ba0f6246a21515ffddc2d99efbe2409db",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +1052,1056 @@    val nonSplitExprCode = {\n      commonExprs.map { exprs =>\n        val eval = withSubExprEliminationExprs(localSubExprEliminationExprsForNonSplit.toMap) {\n          val eval = exprs.head.genCode(this)\n          // Generate the code for this expression tree."
  },
  {
    "id" : "d93e5288-da75-4fc9-aab2-c61f602f0bdf",
    "prId" : 32699,
    "prUrl" : "https://github.com/apache/spark/pull/32699#pullrequestreview-672084069",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5623ae01-1855-4a54-ab89-32da1e733cc2",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "why does this have to be a mutable state now?",
        "createdAt" : "2021-05-31T07:04:52Z",
        "updatedAt" : "2021-05-31T07:04:52Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "3903e318-45c1-4336-b1e3-2809a993f837",
        "parentId" : "5623ae01-1855-4a54-ab89-32da1e733cc2",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Use the example in the description to explain. For the two subexpressions:\r\n\r\n1. `simpleUDF($\"id\")`\r\n2. `functions.length(simpleUDF($\"id\"))`\r\n\r\n\r\nPreviously we evaluate them independently, i.e.,\r\n\r\n```\r\nString subExpr1 = simpleUDF($\"id\");\r\nInt subExpr2 = functions.length(simpleUDF($\"id\"));\r\n```\r\n\r\nNow we remove redundant evaluation of nested subexpressions:\r\n```\r\nString subExpr1 = simpleUDF($\"id\");\r\nInt subExpr2 = functions.length(subExpr1);\r\n```\r\n\r\nIf we need to split the functions, when we evaluate `functions.length`, it needs access of `subExpr1`. We have two choices. One is to add `subExpr1` to the function parameter list of the split function for `functions.length`. Another one is to use mutable state.\r\n\r\nTo add it to parameter list will complicate the way we compute parameter length. That's said we need to link nested subexpression relations and get the correct parameters. Seems to me it is not worth doing that.\r\n\r\nCurrently I choose the simpler approach that is to use mutable state.\r\n\r\n\r\n",
        "createdAt" : "2021-05-31T08:33:41Z",
        "updatedAt" : "2021-05-31T08:33:41Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "f1f64f7ba0f6246a21515ffddc2d99efbe2409db",
    "line" : 52,
    "diffHunk" : "@@ -1,1 +1085,1089 @@          }.head\n\n          val value = addMutableState(javaType(expr.dataType), \"subExprValue\")\n\n          val isNullLiteral = eval.isNull match {"
  },
  {
    "id" : "1936d853-2d9d-4fff-984c-f17768724aca",
    "prId" : 32536,
    "prUrl" : "https://github.com/apache/spark/pull/32536#pullrequestreview-660548651",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "83bab319-48dd-4a46-a287-c13cf68b55e8",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "It seems fine, but have you checked if this stat value does not change before/after this PR?",
        "createdAt" : "2021-05-13T23:29:54Z",
        "updatedAt" : "2021-05-13T23:29:54Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "4dec124d-8358-4475-bc8e-bff6e10b2f87",
        "parentId" : "83bab319-48dd-4a46-a287-c13cf68b55e8",
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "Yes, I did some manual tests to check this. \r\nFor example, add a `afterEach()` method to `CodeGenerationSuite` to record the `CodegenMetrics.METRIC_GENERATED_CLASS_BYTECODE_SIZE.getSnapshot.getValues` after each case and the stat value not change before/after this PR.\r\n\r\n",
        "createdAt" : "2021-05-14T03:00:03Z",
        "updatedAt" : "2021-05-14T03:00:03Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      },
      {
        "id" : "785aca12-9bd5-4abb-8fb0-503d74592a8f",
        "parentId" : "83bab319-48dd-4a46-a287-c13cf68b55e8",
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "In the same way, the stat values of `CodegenMetrics.METRIC_GENERATED_METHOD_BYTECODE_SIZE` has not changed before/after this PR.",
        "createdAt" : "2021-05-14T03:07:56Z",
        "updatedAt" : "2021-05-14T03:07:56Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      },
      {
        "id" : "9891cc10-8cdc-4bcc-b463-62112078d0fb",
        "parentId" : "83bab319-48dd-4a46-a287-c13cf68b55e8",
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "@maropu If we want to do some code checking, maybe we can enhanced the case `metrics are recorded on compile` in `CodeGenerationSuite` as follows:\r\n```\r\ntest(\"metrics are recorded on compile\") {\r\n    ...\r\n    val metricGeneratedClassByteCodeSizeSnapshot =\r\n      CodegenMetrics.METRIC_GENERATED_CLASS_BYTECODE_SIZE.getSnapshot.getValues\r\n    val metricGeneratedMethodByteCodeSizeSnapshot =\r\n      CodegenMetrics.METRIC_GENERATED_METHOD_BYTECODE_SIZE.getSnapshot.getValues\r\n    GenerateOrdering.generate(Add(Literal(123), Literal(1)).asc :: Nil)\r\n    ...\r\n    // Make sure the stat content doesn't change before/after SPARK-35398\r\n    assert(CodegenMetrics.METRIC_GENERATED_CLASS_BYTECODE_SIZE.getSnapshot.getValues\r\n      .diff(metricGeneratedClassByteCodeSizeSnapshot)\r\n      .sameElements(Array(740, 1293)))\r\n    assert(CodegenMetrics.METRIC_GENERATED_METHOD_BYTECODE_SIZE.getSnapshot.getValues\r\n      .diff(metricGeneratedMethodByteCodeSizeSnapshot)\r\n      .sameElements(Array(5, 5, 6, 7, 10, 15, 46)))\r\n  }\r\n```\r\n\r\nThe new assertion can be passed before and after this pr, however, if we update the version of janino or change the codegen of `Add`, we may need to update the content of the assertion because the size of the generated code may change.\r\nFor example `CodegenMetrics.METRIC_GENERATED_CLASS_BYTECODE_SIZE` with janino 3.1.4 are `Array(740, 1293)`, but with  janino 3.0.16 are `Array(687, 1036)`, so I'm not sure if we need to add these assertions in this pr.",
        "createdAt" : "2021-05-14T03:55:07Z",
        "updatedAt" : "2021-05-14T03:57:51Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      },
      {
        "id" : "8660750d-6734-483d-aaec-54a5d2d38c5a",
        "parentId" : "83bab319-48dd-4a46-a287-c13cf68b55e8",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "> @maropu If we want to do some code checking, maybe we can enhanced the case metrics are recorded on compile in CodeGenerationSuite as follows:\r\n\r\nAh, I see. Thank for the explanation, @LuciferYang. Could you add a new test unit for the assert with the prefix `SPARK-35398: `?",
        "createdAt" : "2021-05-17T04:10:49Z",
        "updatedAt" : "2021-05-17T04:13:13Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "ce62d844-5d8a-49da-873f-7a33f4b387bb",
        "parentId" : "83bab319-48dd-4a46-a287-c13cf68b55e8",
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "ok",
        "createdAt" : "2021-05-17T04:48:25Z",
        "updatedAt" : "2021-05-17T04:48:25Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      }
    ],
    "commit" : "8db3551ea9ed012369cb67be1398f2c4dac81e8f",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +1433,1437 @@  private def updateAndGetCompilationStats(evaluator: ClassBodyEvaluator): ByteCodeStats = {\n    // First retrieve the generated classes.\n    val classes = evaluator.getBytecodes.asScala\n\n    // Then walk the classes to get at the method bytecode."
  },
  {
    "id" : "8a7e6d3a-d5b8-4d06-bf49-d776dcfb9cbb",
    "prId" : 32455,
    "prUrl" : "https://github.com/apache/spark/pull/32455#pullrequestreview-656240419",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "780ee225-2436-446d-9f30-0b980a21efa7",
        "parentId" : null,
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "@maropu  Can we directly use `evaluator.getBytecodes.asScala` instead of line 1438 ~ line 1445?",
        "createdAt" : "2021-05-10T02:30:54Z",
        "updatedAt" : "2021-05-10T02:30:55Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      },
      {
        "id" : "acaafc64-a043-417c-bb4f-3c06698e0605",
        "parentId" : "780ee225-2436-446d-9f30-0b980a21efa7",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Is the data the totally same with `ByteArrayClassLoader.classes`? The suggestion is a trivial update though, IMO this PR just focuses on the janino upgrade. Could you make a follow-up PR for it after this merged?",
        "createdAt" : "2021-05-10T23:31:04Z",
        "updatedAt" : "2021-05-10T23:31:04Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "11bfa092-69f4-4988-87cc-87478b159149",
        "parentId" : "780ee225-2436-446d-9f30-0b980a21efa7",
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "@maropu ok, I can try to do this followup :)\r\n\r\n",
        "createdAt" : "2021-05-11T02:53:50Z",
        "updatedAt" : "2021-05-11T02:53:50Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      }
    ],
    "commit" : "8a13cfbcd57b7e93e0009c6b93d784184a880761",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +1436,1440 @@    // First retrieve the generated classes.\n    val classes = {\n      val scField = classOf[ClassBodyEvaluator].getDeclaredField(\"sc\")\n      scField.setAccessible(true)\n      val compiler = scField.get(evaluator).asInstanceOf[SimpleCompiler]"
  },
  {
    "id" : "632722a7-d3f7-434b-9391-7227ccf8be0f",
    "prId" : 31814,
    "prUrl" : "https://github.com/apache/spark/pull/31814#pullrequestreview-611002324",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ddcdb8db-0fc4-436a-9ca7-7bfcc2311c24",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Oh, is this for only 3.0/3.1/3.2?",
        "createdAt" : "2021-03-12T05:35:45Z",
        "updatedAt" : "2021-03-12T08:55:57Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "092cedf0-4b94-4ef1-8d92-48fcc00560f5",
        "parentId" : "ddcdb8db-0fc4-436a-9ca7-7bfcc2311c24",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Yea, in 2.4 we have not split it as function yet.",
        "createdAt" : "2021-03-12T07:11:09Z",
        "updatedAt" : "2021-03-12T08:55:57Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "64d0b8c8-b826-4798-ad17-e4c2863d722e",
        "parentId" : "ddcdb8db-0fc4-436a-9ca7-7bfcc2311c24",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ah, nice catch! Users can see this compilation error? If yes, it would be nice to add end-2-end tests, too, I think.",
        "createdAt" : "2021-03-12T13:44:55Z",
        "updatedAt" : "2021-03-12T13:44:55Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "b074957a-4cc7-47d7-8657-f6c47349e4d2",
        "parentId" : "ddcdb8db-0fc4-436a-9ca7-7bfcc2311c24",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Yea, there will be a error log. This is hard to come out a e2e test, honestly. Although we add subexpr elimination to Project recently, so it is relatively easy to add a e2e test from a Project, but in branch-3.0 or branch-3.1, only hash aggregation uses subexpr elimination.\r\n\r\nThis unit test is pretty close to e2e test case. It actually writes the java code and compile it.",
        "createdAt" : "2021-03-12T17:20:38Z",
        "updatedAt" : "2021-03-12T17:20:38Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "3c739fb4-210a-4737-8b3a-9d89fe836a58",
        "parentId" : "ddcdb8db-0fc4-436a-9ca7-7bfcc2311c24",
        "authorId" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "body" : "Good catch",
        "createdAt" : "2021-03-12T17:23:24Z",
        "updatedAt" : "2021-03-12T17:23:24Z",
        "lastEditedBy" : "99e31844-a5b3-48a2-af71-412edb607a13",
        "tags" : [
        ]
      }
    ],
    "commit" : "4bff3c06bc8e3fd9b54957bc8fee16b16c871d4b",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +1091,1095 @@          val inputVars = inputVarsForAllFuncs(i)\n          val argList =\n            inputVars.map(v => s\"${CodeGenerator.typeName(v.javaType)} ${v.variableName}\")\n          val returnType = javaType(expr.dataType)\n          val fn ="
  },
  {
    "id" : "fa701aa8-4c96-4e06-a723-2029c67fb26e",
    "prId" : 30372,
    "prUrl" : "https://github.com/apache/spark/pull/30372#pullrequestreview-532090144",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5b2d6dee-a730-44da-8daf-88e36f87f2bf",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Does this issue only happens when using `spark-bigquery-with-dependencies`? In the current spark codebase, it seems dataType cannot be an user-defined type in this method.",
        "createdAt" : "2020-11-17T07:46:58Z",
        "updatedAt" : "2020-11-17T07:46:58Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "3adbaa51500d5812661348236e17708f845d83c1",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +1736,1740 @@  def getValueFromVector(vector: String, dataType: DataType, rowId: String): String = {\n    dataType match {\n      case udt: UserDefinedType[_] => getValueFromVector(vector, udt.sqlType, rowId)\n      case _ => if (dataType.isInstanceOf[StructType]) {\n        // `ColumnVector.getStruct` is different from `InternalRow.getStruct`, it only takes an"
  },
  {
    "id" : "1d55bee4-dd9d-4418-89c4-c4f279bb9a12",
    "prId" : 29975,
    "prUrl" : "https://github.com/apache/spark/pull/29975#pullrequestreview-505816500",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "eebbc683-33b9-4237-867d-dc88c7335ebb",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Is this change needed to support subexpr elimination in `ProjectExec`? What I'm interested in is that why we didn't need this change when supporting it in `HashAggregateExec`.",
        "createdAt" : "2020-10-09T13:00:36Z",
        "updatedAt" : "2020-10-12T01:42:10Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "40705efa-3f4b-43be-85c9-d6e57156a920",
        "parentId" : "eebbc683-33b9-4237-867d-dc88c7335ebb",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Yes, this is needed. `ProjectExec` doesn't require all its child's outputs to be evaluated in advance. Instead it only early evaluates the outputs used more than twice (deferring evaluation). So we need to extract these variables used by subexpressions and evaluate them before subexpressions. In `HashAggregateExec` we don't need to consider that. The simplest way is to evaluate all child's outputs, of course.",
        "createdAt" : "2020-10-09T16:16:18Z",
        "updatedAt" : "2020-10-12T01:42:10Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "2414bb041f47c00de28428014372ab6c55435e56",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +97,101 @@  codes: Seq[String],\n  states: Map[Expression, SubExprEliminationState],\n  exprCodesNeedEvaluate: Seq[ExprCode])\n\n/**"
  },
  {
    "id" : "1c151bfc-de5e-416e-88d2-0f5e51023d8d",
    "prId" : 29975,
    "prUrl" : "https://github.com/apache/spark/pull/29975#pullrequestreview-506246032",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "74db5bf8-b218-45a0-ba5f-23e21f921e9f",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "> ProjectExec doesn't require all its child's outputs to be evaluated in advance. Instead it only early evaluates the outputs used more than twice (deferring evaluation). So we need to extract these variables used by subexpressions and evaluate them before subexpressions\r\n\r\nCould you leave some comments here?",
        "createdAt" : "2020-10-11T23:38:54Z",
        "updatedAt" : "2020-10-12T01:42:10Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "1813c522-1aa3-4491-9318-f46992f954c2",
        "parentId" : "74db5bf8-b218-45a0-ba5f-23e21f921e9f",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Ok.",
        "createdAt" : "2020-10-12T01:39:19Z",
        "updatedAt" : "2020-10-12T01:42:10Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "2414bb041f47c00de28428014372ab6c55435e56",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +1065,1069 @@    // evaluate the outputs used more than twice. So we need to extract these variables used by\n    // subexpressions and evaluate them before subexpressions.\n    val (inputVarsForAllFuncs, exprCodesNeedEvaluate) = commonExprs.map { expr =>\n      val (inputVars, exprCodes) = getLocalInputVariableValues(this, expr.head)\n      (inputVars.toSeq, exprCodes.toSeq)"
  },
  {
    "id" : "e7475b00-d031-4a0c-9045-9f558c281008",
    "prId" : 29975,
    "prUrl" : "https://github.com/apache/spark/pull/29975#pullrequestreview-506245952",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2b34e31d-a4b9-4407-bfd0-804fe5dffcbc",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Could you describe what's the second value of the returned value in the code comment above?",
        "createdAt" : "2020-10-11T23:58:08Z",
        "updatedAt" : "2020-10-12T01:42:10Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "8a3c9864-5bee-43a8-a883-65d63893c691",
        "parentId" : "2b34e31d-a4b9-4407-bfd0-804fe5dffcbc",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Sure.",
        "createdAt" : "2020-10-12T01:38:56Z",
        "updatedAt" : "2020-10-12T01:42:10Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "2414bb041f47c00de28428014372ab6c55435e56",
    "line" : 71,
    "diffHunk" : "@@ -1,1 +1754,1758 @@   * evaluating subexpressions.\n   */\n  def getLocalInputVariableValues(\n      ctx: CodegenContext,\n      expr: Expression,"
  },
  {
    "id" : "82d4de1a-2244-4922-920d-9421312c9ced",
    "prId" : 29975,
    "prUrl" : "https://github.com/apache/spark/pull/29975#pullrequestreview-506251568",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "60c524dd-23f6-4b51-9ea3-3678b738838c",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "`Set` instead of `Seq` here?",
        "createdAt" : "2020-10-12T00:15:03Z",
        "updatedAt" : "2020-10-12T01:42:10Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "010f26e0-bc93-45ba-b262-c4a43c57b99c",
        "parentId" : "60c524dd-23f6-4b51-9ea3-3678b738838c",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "They are already `Set`. You mean using `Seq`?",
        "createdAt" : "2020-10-12T01:23:38Z",
        "updatedAt" : "2020-10-12T01:42:10Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "0167fde7-aa0d-46f1-8c52-3a7bc19a59c0",
        "parentId" : "60c524dd-23f6-4b51-9ea3-3678b738838c",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Yea, my bad. Yes.",
        "createdAt" : "2020-10-12T02:05:48Z",
        "updatedAt" : "2020-10-12T02:05:49Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "2414bb041f47c00de28428014372ab6c55435e56",
    "line" : 105,
    "diffHunk" : "@@ -1,1 +1796,1800 @@    }\n\n    (argSet.toSet, exprCodesNeedEvaluate.toSet)\n  }\n"
  },
  {
    "id" : "87ed5cb1-f50e-49e5-848d-28a677956dae",
    "prId" : 29975,
    "prUrl" : "https://github.com/apache/spark/pull/29975#pullrequestreview-506245936",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f00dd2d3-69b7-4d2a-8b6a-1d78e82241d1",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "just a suggestion: `exprCodesNeedEvaluate` -> `exprCodesForEarlyEvals`? ",
        "createdAt" : "2020-10-12T00:16:08Z",
        "updatedAt" : "2020-10-12T01:42:10Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "19c774e9-fe5c-4c75-89a8-98dc37e2df6a",
        "parentId" : "f00dd2d3-69b7-4d2a-8b6a-1d78e82241d1",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "`exprCodesForEarlyEvals` sounds confusing. They are not for early evaluating something but needed for evaluating subexpressions.",
        "createdAt" : "2020-10-12T01:38:50Z",
        "updatedAt" : "2020-10-12T01:42:10Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "2414bb041f47c00de28428014372ab6c55435e56",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +97,101 @@  codes: Seq[String],\n  states: Map[Expression, SubExprEliminationState],\n  exprCodesNeedEvaluate: Seq[ExprCode])\n\n/**"
  },
  {
    "id" : "b60fda92-83df-4a2d-bcf4-3eb3015605fb",
    "prId" : 29975,
    "prUrl" : "https://github.com/apache/spark/pull/29975#pullrequestreview-506307941",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "db100498-7ef0-44ac-a38a-35413cb7f6e2",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "We need this copy? A unnecessary copy can happen if `exprCodesNeedEvaluate` already has the same entry?",
        "createdAt" : "2020-10-12T00:24:40Z",
        "updatedAt" : "2020-10-12T01:42:10Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "aead602f-ef8f-4543-99f8-0fd57c4cb344",
        "parentId" : "db100498-7ef0-44ac-a38a-35413cb7f6e2",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Copying `exprCode` because we need the unevaluated `code` in `exprCode`, but we also need to empty `code` of `exprCode`. We need copied code so we can evaluate them before evaluating subexpressions. We need to empty `code` of `exprCode` so we don't re-evaluate the code.",
        "createdAt" : "2020-10-12T01:26:14Z",
        "updatedAt" : "2020-10-12T01:42:10Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "bc6244fe-33d0-478b-930d-afb833df3582",
        "parentId" : "db100498-7ef0-44ac-a38a-35413cb7f6e2",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "> We need to empty code of exprCode so we don't re-evaluate the code.\r\n\r\nAFAIK when we empty the code, we also do a copy, right?",
        "createdAt" : "2020-10-12T05:45:53Z",
        "updatedAt" : "2020-10-12T05:45:53Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "4d6bcf18-746f-4384-834a-36f9630a458c",
        "parentId" : "db100498-7ef0-44ac-a38a-35413cb7f6e2",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "`exprCode.code = EmptyBlock`, do you mean this?",
        "createdAt" : "2020-10-12T05:48:11Z",
        "updatedAt" : "2020-10-12T05:48:11Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "28ba5872-f037-4104-9ba4-038f64af8851",
        "parentId" : "db100498-7ef0-44ac-a38a-35413cb7f6e2",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Sorry I was wrong, the copy here is necessary.",
        "createdAt" : "2020-10-12T05:49:33Z",
        "updatedAt" : "2020-10-12T05:49:33Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "2414bb041f47c00de28428014372ab6c55435e56",
    "line" : 93,
    "diffHunk" : "@@ -1,1 +1785,1789 @@          // If the referred variable is not evaluated yet.\n          if (exprCode.code != EmptyBlock) {\n            exprCodesNeedEvaluate += exprCode.copy()\n            exprCode.code = EmptyBlock\n          }"
  },
  {
    "id" : "d9547f77-4143-4cfd-8371-0da92c3c7918",
    "prId" : 28112,
    "prUrl" : "https://github.com/apache/spark/pull/28112#pullrequestreview-388205047",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ad85a042-c86a-48a9-bad6-7c5db65cdc42",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "So it's generated on the driver and compiled on the executor, you're sure? seems OK",
        "createdAt" : "2020-04-03T16:04:19Z",
        "updatedAt" : "2020-04-03T16:04:19Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "784be8fd-6e7f-4d90-aad0-240a17195b8a",
        "parentId" : "ad85a042-c86a-48a9-bad6-7c5db65cdc42",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "Yes. Although compilation occurs on the driver too, it's just used to check.",
        "createdAt" : "2020-04-04T00:56:25Z",
        "updatedAt" : "2020-04-04T00:56:26Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      },
      {
        "id" : "a12d1cc7-34b6-45f1-b8d2-8d3582a40099",
        "parentId" : "ad85a042-c86a-48a9-bad6-7c5db65cdc42",
        "authorId" : "3a12ce0f-9e73-4cfb-a4b4-b19368cddc2f",
        "body" : "LGTM, thank you very much!",
        "createdAt" : "2020-04-06T07:34:41Z",
        "updatedAt" : "2020-04-06T07:34:50Z",
        "lastEditedBy" : "3a12ce0f-9e73-4cfb-a4b4-b19368cddc2f",
        "tags" : [
        ]
      },
      {
        "id" : "ce58a2a1-4f96-476c-9be2-25315337aaf0",
        "parentId" : "ad85a042-c86a-48a9-bad6-7c5db65cdc42",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "Thanks for you remind too.",
        "createdAt" : "2020-04-06T12:35:42Z",
        "updatedAt" : "2020-04-06T12:35:43Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "4f755b02e851f228643f9e72e44bc595746405ec",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +1310,1314 @@  final val MUTABLESTATEARRAY_SIZE_LIMIT = 32768\n\n  // The Java source code generated by whole-stage codegen on the Driver side is sent to each\n  // Executor for compilation and data processing. This is very effective in processing large\n  // amounts of data in a distributed environment. However, in the test environment,"
  },
  {
    "id" : "c20decc9-7a28-4b03-b1b3-c16d21b89f09",
    "prId" : 28081,
    "prUrl" : "https://github.com/apache/spark/pull/28081#pullrequestreview-385356930",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bb0af22c-ff8b-4fe0-b741-b2473b570075",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "`CodegenMetrics.METRIC_COMPILATION_TIME` is a `Histogram` that is a metric which calculates the distribution of a value. We can't reuse it.",
        "createdAt" : "2020-04-01T08:13:38Z",
        "updatedAt" : "2020-04-02T08:43:09Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "eb27c3acfcfe3b5e4ac86c6720bc02a287c4f584",
    "line" : 41,
    "diffHunk" : "@@ -1,1 +1487,1491 @@          val timeMs: Double = duration.toDouble / NANOS_PER_MILLIS\n          CodegenMetrics.METRIC_SOURCE_CODE_SIZE.update(code.body.length)\n          CodegenMetrics.METRIC_COMPILATION_TIME.update(timeMs.toLong)\n          logInfo(s\"Code generated in $timeMs ms\")\n          _compileTime.add(duration)"
  },
  {
    "id" : "490ff4c3-d82d-4553-af59-35d3c702bff6",
    "prId" : 28081,
    "prUrl" : "https://github.com/apache/spark/pull/28081#pullrequestreview-385392636",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d73abcb4-d1b8-4070-912f-0a8a185ece20",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I think `timeMs` is good enough to be recorded.",
        "createdAt" : "2020-04-01T08:43:56Z",
        "updatedAt" : "2020-04-02T08:43:09Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "49705846-30c9-46f9-9a4c-40576e91a89e",
        "parentId" : "d73abcb4-d1b8-4070-912f-0a8a185ece20",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "`timeMs` lost a lot of precision. Because `SQLQueryTestSuite` contains 231 test cases contain a lot of SQL, tens of thousands of SQL are executed. The loss of accuracy will increase.",
        "createdAt" : "2020-04-01T09:01:17Z",
        "updatedAt" : "2020-04-02T08:43:09Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "eb27c3acfcfe3b5e4ac86c6720bc02a287c4f584",
    "line" : 43,
    "diffHunk" : "@@ -1,1 +1489,1493 @@          CodegenMetrics.METRIC_COMPILATION_TIME.update(timeMs.toLong)\n          logInfo(s\"Code generated in $timeMs ms\")\n          _compileTime.add(duration)\n          result\n        }"
  },
  {
    "id" : "006efaaf-c6fb-4448-939b-b5d142c67120",
    "prId" : 28081,
    "prUrl" : "https://github.com/apache/spark/pull/28081#pullrequestreview-386050691",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f4140467-fdbd-465c-b07c-89b1159d5d97",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can we add a simple test to run queries with whole-stage-codegen on/off and see if this metrics increase? whole-stage-codegen compiles code at driver side.",
        "createdAt" : "2020-04-01T08:47:17Z",
        "updatedAt" : "2020-04-02T08:43:09Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "bf501529-688c-4b21-ba63-d167990b1f07",
        "parentId" : "f4140467-fdbd-465c-b07c-89b1159d5d97",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "OK. I added the test data onto the description of this PR.",
        "createdAt" : "2020-04-02T01:15:12Z",
        "updatedAt" : "2020-04-02T08:43:09Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "eb27c3acfcfe3b5e4ac86c6720bc02a287c4f584",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +1317,1321 @@  // running test cases, we summarize the total compilation time and output it to the execution\n  // log for easy analysis and view.\n  private val _compileTime = new LongAccumulator\n\n  // Returns the total compile time of Java source code in nanoseconds."
  },
  {
    "id" : "036f015d-c8a8-41c0-a351-799e4a4b5e13",
    "prId" : 28081,
    "prUrl" : "https://github.com/apache/spark/pull/28081#pullrequestreview-386052100",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "656bd834-5de2-44b8-9d5a-4c72050003e3",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Shall we add `// Visible for testing`?",
        "createdAt" : "2020-04-01T21:15:31Z",
        "updatedAt" : "2020-04-02T08:43:09Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "507769e1-942f-4376-9c35-07dc79c5c8b0",
        "parentId" : "656bd834-5de2-44b8-9d5a-4c72050003e3",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "OK.",
        "createdAt" : "2020-04-02T01:20:29Z",
        "updatedAt" : "2020-04-02T08:43:09Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "eb27c3acfcfe3b5e4ac86c6720bc02a287c4f584",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +1321,1325 @@  // Returns the total compile time of Java source code in nanoseconds.\n  // Visible for testing\n  def compileTime: Long = _compileTime.sum\n\n  // Reset compile time."
  },
  {
    "id" : "2eea15f1-005c-489f-a99e-892aee7b5633",
    "prId" : 28081,
    "prUrl" : "https://github.com/apache/spark/pull/28081#pullrequestreview-386052131",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "26056519-57c4-455f-956f-8938527f8c7f",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "ditto.",
        "createdAt" : "2020-04-01T21:15:38Z",
        "updatedAt" : "2020-04-02T08:43:09Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "9b78d710-b758-4155-9c77-edde94168cee",
        "parentId" : "26056519-57c4-455f-956f-8938527f8c7f",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "OK",
        "createdAt" : "2020-04-02T01:20:35Z",
        "updatedAt" : "2020-04-02T08:43:09Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "eb27c3acfcfe3b5e4ac86c6720bc02a287c4f584",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +1325,1329 @@  // Reset compile time.\n  // Visible for testing\n  def resetCompileTime: Unit = _compileTime.reset()\n\n  /**"
  },
  {
    "id" : "b4a28cc1-3c16-4cf5-9b14-80910a64ea08",
    "prId" : 28081,
    "prUrl" : "https://github.com/apache/spark/pull/28081#pullrequestreview-386220847",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0809ab9b-ada1-45b1-b04f-f870522428ae",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "We should mention that it's time in nanoseconds",
        "createdAt" : "2020-04-02T06:42:43Z",
        "updatedAt" : "2020-04-02T08:43:09Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "03727a87-0a7d-43a7-bf36-e104dba3bea9",
        "parentId" : "0809ab9b-ada1-45b1-b04f-f870522428ae",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "OK. I will add it.",
        "createdAt" : "2020-04-02T08:44:25Z",
        "updatedAt" : "2020-04-02T08:44:25Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "eb27c3acfcfe3b5e4ac86c6720bc02a287c4f584",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +1321,1325 @@  // Returns the total compile time of Java source code in nanoseconds.\n  // Visible for testing\n  def compileTime: Long = _compileTime.sum\n\n  // Reset compile time."
  },
  {
    "id" : "55986261-a818-4da2-aca7-40c5e738d5cf",
    "prId" : 28081,
    "prUrl" : "https://github.com/apache/spark/pull/28081#pullrequestreview-388309024",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7d1a139b-10b8-4932-b5e9-66aea3b66f46",
        "parentId" : null,
        "authorId" : "3a12ce0f-9e73-4cfb-a4b4-b19368cddc2f",
        "body" : "Hi @beliefer ,\r\n\r\nI'm really sorry to post edit suggestions after the PR is merged. I noticed this PR just now...\r\n\r\nIf we have a chance to make follow-up changes, could you please update `java code` to `Java code`, and `whole codegen` to `whole-stage codegen`?\r\n\r\nThanks!",
        "createdAt" : "2020-04-03T09:24:09Z",
        "updatedAt" : "2020-04-03T09:24:09Z",
        "lastEditedBy" : "3a12ce0f-9e73-4cfb-a4b4-b19368cddc2f",
        "tags" : [
        ]
      },
      {
        "id" : "efa81c6a-6f46-4a22-9491-e83f3234d3c6",
        "parentId" : "7d1a139b-10b8-4932-b5e9-66aea3b66f46",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "OK. Thanks for your remind.",
        "createdAt" : "2020-04-03T09:26:56Z",
        "updatedAt" : "2020-04-03T09:26:57Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      },
      {
        "id" : "5bb99406-2751-495b-8787-774d28d62659",
        "parentId" : "7d1a139b-10b8-4932-b5e9-66aea3b66f46",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "@beliefer can you send a followup PR to address it?",
        "createdAt" : "2020-04-06T06:02:57Z",
        "updatedAt" : "2020-04-06T06:02:57Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "0ff462c5-018d-4e34-bf08-e70918b7078e",
        "parentId" : "7d1a139b-10b8-4932-b5e9-66aea3b66f46",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "@cloud-fan @rednaxelafx I make a followup PR https://github.com/apache/spark/pull/28112.",
        "createdAt" : "2020-04-06T07:21:47Z",
        "updatedAt" : "2020-04-06T07:21:47Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      },
      {
        "id" : "20e8b13d-5747-4fd3-9ec4-ada9952099cf",
        "parentId" : "7d1a139b-10b8-4932-b5e9-66aea3b66f46",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "This one? https://github.com/apache/spark/pull/28112",
        "createdAt" : "2020-04-06T07:22:02Z",
        "updatedAt" : "2020-04-06T07:22:02Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "b50ac765-7502-4d65-ab93-463bcb5a1aa0",
        "parentId" : "7d1a139b-10b8-4932-b5e9-66aea3b66f46",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "Yes",
        "createdAt" : "2020-04-06T14:31:40Z",
        "updatedAt" : "2020-04-06T14:31:40Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "eb27c3acfcfe3b5e4ac86c6720bc02a287c4f584",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +1310,1314 @@  final val MUTABLESTATEARRAY_SIZE_LIMIT = 32768\n\n  // The java source code generated by whole codegen is compiled on the Driver side and sent to\n  // each Executor as the execution code to process data. This is very effective in processing\n  // large amounts of data in a distributed environment. However, in the test environment,"
  },
  {
    "id" : "dbef43a7-d36b-439e-ac72-24fa7642c581",
    "prId" : 28081,
    "prUrl" : "https://github.com/apache/spark/pull/28081#pullrequestreview-400965755",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4e025f1e-d4e8-47c0-a0e0-cb21de0bbd27",
        "parentId" : null,
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "Methods should be declared with parentheses, unless they are accessors that have no side-effect. See: https://github.com/databricks/scala-style-guide#parentheses\r\n\r\nFixed in https://github.com/apache/spark/pull/28252",
        "createdAt" : "2020-04-18T06:18:47Z",
        "updatedAt" : "2020-04-18T06:18:47Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      },
      {
        "id" : "758f5432-1d62-49f2-9bc4-20f7b7689169",
        "parentId" : "4e025f1e-d4e8-47c0-a0e0-cb21de0bbd27",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "@gatorsmile Thanks. I got it now.",
        "createdAt" : "2020-04-27T13:44:55Z",
        "updatedAt" : "2020-04-27T13:44:56Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "eb27c3acfcfe3b5e4ac86c6720bc02a287c4f584",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +1325,1329 @@  // Reset compile time.\n  // Visible for testing\n  def resetCompileTime: Unit = _compileTime.reset()\n\n  /**"
  },
  {
    "id" : "750acdf7-1a14-41e3-b8fc-79864c9e6ac0",
    "prId" : 27860,
    "prUrl" : "https://github.com/apache/spark/pull/27860#pullrequestreview-377747658",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c569e256-3d49-443d-9c40-370087bd8f1b",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "For the future reference:  I checked https://github.com/janino-compiler/janino/commit/9e0c16c69c166f83541d63df70b42c9fbc278536",
        "createdAt" : "2020-03-19T14:02:11Z",
        "updatedAt" : "2020-05-29T11:15:23Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "138603189738c6b105ac37fbb39dc0b0c1375e4a",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +1424,1428 @@      scField.setAccessible(true)\n      val compiler = scField.get(evaluator).asInstanceOf[SimpleCompiler]\n      val loader = compiler.getClassLoader.asInstanceOf[ByteArrayClassLoader]\n      val classesField = loader.getClass.getDeclaredField(\"classes\")\n      classesField.setAccessible(true)"
  },
  {
    "id" : "8f3afaed-22c6-45dc-86f7-c66944074fdb",
    "prId" : 26267,
    "prUrl" : "https://github.com/apache/spark/pull/26267#pullrequestreview-307552571",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f1643663-adae-40ca-8351-f44619c37c73",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "@viirya @cloud-fan sorry, but I found my mistake made in SPARK-29008... Could you check?",
        "createdAt" : "2019-10-26T12:13:58Z",
        "updatedAt" : "2019-10-26T12:13:58Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "b68ceb59-b6d4-4461-9875-71d0e1804720",
        "parentId" : "f1643663-adae-40ca-8351-f44619c37c73",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "yea, good catch! We should check param length for input parameters to common expressions.",
        "createdAt" : "2019-10-27T03:23:22Z",
        "updatedAt" : "2019-10-27T03:23:22Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "6b81cef9db94d93379c233f43e82f0aeb12048b5",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +1054,1058 @@        getLocalInputVariableValues(this, expr.head).toSeq\n      }\n      if (inputVarsForAllFuncs.map(calculateParamLengthFromExprValues).forall(isValidParamLength)) {\n        commonExprs.zipWithIndex.map { case (exprs, i) =>\n          val expr = exprs.head"
  }
]