[
  {
    "id" : "67ff9743-018c-446d-bd63-fd72823a8e99",
    "prId" : 33775,
    "prUrl" : "https://github.com/apache/spark/pull/33775#pullrequestreview-732493139",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "14288cdd-1ae4-4928-852c-9ebf6ef96de7",
        "parentId" : null,
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "Add comment for why choosing `DecimalType(16, 6))`",
        "createdAt" : "2021-08-18T06:30:44Z",
        "updatedAt" : "2021-08-18T06:30:44Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "434c4f41-6abc-46cb-ba49-f9522eb54fe0",
        "parentId" : "14288cdd-1ae4-4928-852c-9ebf6ef96de7",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "OK",
        "createdAt" : "2021-08-18T06:52:08Z",
        "updatedAt" : "2021-08-18T06:52:08Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "147429f919dc0824d64de976fcd8f52652050d13",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +2561,2565 @@  // casted into decimal safely, we use DecimalType(16, 6) which is wider than DecimalType(10, 0).\n  override def inputTypes: Seq[AbstractDataType] =\n    Seq(IntegerType, IntegerType, IntegerType, IntegerType, IntegerType, DecimalType(16, 6)) ++\n      timezone.map(_ => StringType)\n  override def nullable: Boolean = if (failOnError) children.exists(_.nullable) else true"
  },
  {
    "id" : "125d7949-8940-4cd1-bc4e-2fc57029ce80",
    "prId" : 33290,
    "prUrl" : "https://github.com/apache/spark/pull/33290#pullrequestreview-703581578",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9c1d1c39-2fdd-4a02-8082-ea96a94dec64",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Please, use TIMESTAMP_TYPE.key. Using the SQL config has some benefits like:\r\n- Easer to search in IDE by config name\r\n- Refactoring. Maybe, we will rename it in the future. So, you will not need to modify this place.",
        "createdAt" : "2021-07-11T10:23:23Z",
        "updatedAt" : "2021-07-11T10:32:40Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "d0f1fdde-7d6b-4c3e-b5ad-ff3ccf96de57",
        "parentId" : "9c1d1c39-2fdd-4a02-8082-ea96a94dec64",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "There will be errors:\r\n```\r\nannotation argument needs to be a constant; found: \"_FUNC_(year, month, day, hour, min, sec[, timezone]) - Create timestamp from year, month, day, hour, min, sec and timezone fields. \".+(scala.StringContext.apply(\"The result data type is consistent ...\r\n```",
        "createdAt" : "2021-07-11T12:14:40Z",
        "updatedAt" : "2021-07-11T12:14:40Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "abce601cba887bc66040dfb4b658cc051ccd289c",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +2288,2292 @@@ExpressionDescription(\n  usage = \"_FUNC_(year, month, day, hour, min, sec[, timezone]) - Create timestamp from year, month, day, hour, min, sec and timezone fields. \" +\n    \"The result data type is consistent with the value of configuration `spark.sql.timestampType`\",\n  arguments = \"\"\"\n    Arguments:"
  },
  {
    "id" : "f7e0fe81-3467-4e5c-ace6-2fb8d97aa7d9",
    "prId" : 33280,
    "prUrl" : "https://github.com/apache/spark/pull/33280#pullrequestreview-703581608",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bd8e0dc0-9513-468a-a499-309375b6f363",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Use TIMESTAMP_TYPE.key",
        "createdAt" : "2021-07-11T08:35:05Z",
        "updatedAt" : "2021-07-11T08:35:41Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "e11a7943-b80b-44f3-aba7-eee33b430123",
        "parentId" : "bd8e0dc0-9513-468a-a499-309375b6f363",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "There will be errors:\r\n```\r\nannotation argument needs to be a constant\r\n```",
        "createdAt" : "2021-07-11T12:15:00Z",
        "updatedAt" : "2021-07-11T12:15:00Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "4c11b7f373e5d108634888745c7fa3bcb8c1abf4",
    "line" : 48,
    "diffHunk" : "@@ -1,1 +1911,1915 @@      to a timestamp. Returns null with invalid input. By default, it follows casting rules to\n      a timestamp if the `fmt` is omitted. The result data type is consistent with the value of\n      configuration `spark.sql.timestampType`.\n  \"\"\",\n  arguments = \"\"\""
  },
  {
    "id" : "de985542-fbda-4d5b-997a-7afba7c0897f",
    "prId" : 33258,
    "prUrl" : "https://github.com/apache/spark/pull/33258#pullrequestreview-701909940",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "964d12d7-9a37-4e17-ad6d-2b165afbf4d1",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "\r\n```suggestion\r\n  since = \"3.3.0\")\r\n```\r\n",
        "createdAt" : "2021-07-08T10:42:29Z",
        "updatedAt" : "2021-07-08T10:42:30Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "998089cd0f1c2368e5a2b2773651836561a0a209",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +218,222 @@  \"\"\",\n  group = \"datetime_funcs\",\n  since = \"3.2.0\")\ncase class LocalTimestamp(timeZoneId: Option[String] = None) extends LeafExpression\n  with TimeZoneAwareExpression with CodegenFallback {"
  },
  {
    "id" : "f24b8ec0-187b-438e-944c-c817614197de",
    "prId" : 33258,
    "prUrl" : "https://github.com/apache/spark/pull/33258#pullrequestreview-704714981",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2a713bc1-7a17-4186-b5a9-072270f23be8",
        "parentId" : null,
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "Shall we add a new test case for the code change here?",
        "createdAt" : "2021-07-12T11:02:13Z",
        "updatedAt" : "2021-07-12T11:02:13Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "f474dea8-7299-40bf-bbed-8e6e8542787f",
        "parentId" : "2a713bc1-7a17-4186-b5a9-072270f23be8",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "I wonder how it is related to new function? If it is not related, I would exclude this from the PR, and open new PR with a test.",
        "createdAt" : "2021-07-12T14:21:12Z",
        "updatedAt" : "2021-07-12T14:21:12Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "a1768190-a03a-4228-9bd2-0f06ade07f37",
        "parentId" : "2a713bc1-7a17-4186-b5a9-072270f23be8",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "it's related: https://github.com/apache/spark/pull/33258/files#diff-cf2dc65d70aa7bc490d237f1c50f5fdf51e244fabed782977a94d2934c208551R565",
        "createdAt" : "2021-07-12T18:42:03Z",
        "updatedAt" : "2021-07-12T18:42:04Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "0f03b7ce-1c45-4895-a529-9e8994a9c470",
        "parentId" : "2a713bc1-7a17-4186-b5a9-072270f23be8",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "I will add new test case in this PR.",
        "createdAt" : "2021-07-13T03:36:12Z",
        "updatedAt" : "2021-07-13T07:24:19Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "998089cd0f1c2368e5a2b2773651836561a0a209",
    "line" : 59,
    "diffHunk" : "@@ -1,1 +276,280 @@      case _: TimestampType => Literal(timestampUs, TimestampType)\n      case _: TimestampNTZType =>\n        Literal(convertTz(timestampUs, ZoneOffset.UTC, zoneId), TimestampNTZType)\n      case _: DateType => Literal(microsToDays(timestampUs, zoneId), DateType)\n    }"
  },
  {
    "id" : "c8a80053-0c1d-41c6-a11a-0c4457109194",
    "prId" : 33258,
    "prUrl" : "https://github.com/apache/spark/pull/33258#pullrequestreview-704475565",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e5684cd7-9043-4f1e-8244-89102cdd281a",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "do we really need a timezone to get current local time?",
        "createdAt" : "2021-07-12T18:41:11Z",
        "updatedAt" : "2021-07-12T18:41:11Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "04e8ef42-7989-46f3-9c49-3e209a26b2d8",
        "parentId" : "e5684cd7-9043-4f1e-8244-89102cdd281a",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "@cloud-fan Yes,I think so. If you don't specify tz, the `LocalDateTime.now()` will take the default JVM time zone, see https://github.com/apache/spark/pull/33258#discussion_r667378378",
        "createdAt" : "2021-07-12T19:39:02Z",
        "updatedAt" : "2021-07-12T19:48:30Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "998089cd0f1c2368e5a2b2773651836561a0a209",
    "line" : 46,
    "diffHunk" : "@@ -1,1 +234,238 @@    copy(timeZoneId = Option(timeZoneId))\n\n  override def eval(input: InternalRow): Any = localDateTimeToMicros(LocalDateTime.now(zoneId))\n\n  override def prettyName: String = \"localtimestamp\""
  }
]