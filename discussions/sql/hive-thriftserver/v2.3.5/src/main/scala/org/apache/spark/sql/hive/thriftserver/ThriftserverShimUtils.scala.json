[
  {
    "id" : "bd3bd0d1-54e6-4ef2-96ba-55e7a693f55f",
    "prId" : 25694,
    "prUrl" : "https://github.com/apache/spark/pull/25694#pullrequestreview-285143124",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3731af2b-1a33-4963-905c-7da0d2b4e7d1",
        "parentId" : null,
        "authorId" : "e5beb795-ac0e-4bd6-ad66-708215b8ae58",
        "body" : "nit: empty line between functions.",
        "createdAt" : "2019-09-06T21:34:40Z",
        "updatedAt" : "2019-09-10T09:49:47Z",
        "lastEditedBy" : "e5beb795-ac0e-4bd6-ad66-708215b8ae58",
        "tags" : [
        ]
      },
      {
        "id" : "7ad3e390-71e1-422e-aab4-16f3c401efa1",
        "parentId" : "3731af2b-1a33-4963-905c-7da0d2b4e7d1",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "Add it .",
        "createdAt" : "2019-09-07T00:04:03Z",
        "updatedAt" : "2019-09-10T09:49:47Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "3c488fcfc5a6e97db25f417d0dd8bdb339c99525",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +66,70 @@  }\n\n  private[thriftserver] def addToClassPath(\n      loader: ClassLoader,\n      auxJars: Array[String]): ClassLoader = {"
  },
  {
    "id" : "563e32d1-68a2-4041-a589-82a4a64084eb",
    "prId" : 25694,
    "prUrl" : "https://github.com/apache/spark/pull/25694#pullrequestreview-286032437",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1d64e277-ce78-42c7-8c40-1bb2553157a7",
        "parentId" : null,
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "Why do we skip `ARRAY_TYPE`, `MAP_TYPE`, `STRUCT_TYPE` and `USER_DEFINED_TYPE`?",
        "createdAt" : "2019-09-07T15:15:32Z",
        "updatedAt" : "2019-09-10T09:49:47Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      },
      {
        "id" : "425c590b-0cbe-4b6e-93e6-ae6edc6a800c",
        "parentId" : "1d64e277-ce78-42c7-8c40-1bb2553157a7",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> Why do we skip `ARRAY_TYPE`, `MAP_TYPE`, `STRUCT_TYPE` and `USER_DEFINED_TYPE`?\r\n\r\nSupport this type just convert to string to show.  Should add . ",
        "createdAt" : "2019-09-08T01:09:50Z",
        "updatedAt" : "2019-09-10T09:49:47Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "77c99acb-e819-47f9-932d-b11ac200dbd5",
        "parentId" : "1d64e277-ce78-42c7-8c40-1bb2553157a7",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "I think we should add these types. Hive-3.1.2 also converted these types to strings.\r\n@juliuszsompolski What do you think?",
        "createdAt" : "2019-09-08T13:23:52Z",
        "updatedAt" : "2019-09-10T09:49:47Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      },
      {
        "id" : "dbd30c4a-82cf-4023-8370-b97deee7522a",
        "parentId" : "1d64e277-ce78-42c7-8c40-1bb2553157a7",
        "authorId" : "e5beb795-ac0e-4bd6-ad66-708215b8ae58",
        "body" : "How does the client handle it?\r\nIf you do\r\n```\r\nval stmt = conn.prepareStatement(\"SELECT array, map, struct, interval FROM table\")\r\nval rs = stmt.executeQuery()\r\nval md = rs.getMetaData()\r\n```\r\nThen what does `md.getColumnType(i)` return for each of these columns?\r\nWhat type of `rs.getXXX` call should the user use for each of these columns? For the array column, should it be `rs.getArray(i)` or `rs.getString(i)`?\r\nWhat is the mapping of types returned by md.getColumnType(i), with the getters that should be used for them in rs.getXXX(i)?\r\n",
        "createdAt" : "2019-09-09T13:57:05Z",
        "updatedAt" : "2019-09-10T09:49:47Z",
        "lastEditedBy" : "e5beb795-ac0e-4bd6-ad66-708215b8ae58",
        "tags" : [
        ]
      },
      {
        "id" : "9d418a12-192f-4616-8cbb-f66efdc68d9a",
        "parentId" : "1d64e277-ce78-42c7-8c40-1bb2553157a7",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "For getMetadataResult, it truly return ARRAY, MAP, STRUCT.\r\nReturn content is organized by HiveResult.toHiveString() method as each's DataType.\r\n\r\n",
        "createdAt" : "2019-09-09T14:13:58Z",
        "updatedAt" : "2019-09-10T09:49:47Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "33f585c6-2f3c-415e-a9ba-6918eab890cb",
        "parentId" : "1d64e277-ce78-42c7-8c40-1bb2553157a7",
        "authorId" : "e5beb795-ac0e-4bd6-ad66-708215b8ae58",
        "body" : "So if I run this:\r\n```\r\nClass.forName(\"org.apache.hive.jdbc.HiveDriver\")\r\nval jdbc_url = \"jdbc:hive2://localhost:10000/default;httpPath=cliservice\"\r\nval conn = DriverManager.getConnection(jdbc_url)\r\nval stmt = conn.prepareStatement(\"select collect_list(id) as arr from range(10)\")\r\nval rs = stmt.executeQuery()\r\nval md = rs.getMetaData()\r\n```\r\nand then:\r\n```\r\nscala> md.getColumnType(1)\r\nres2: Int = 2003\r\n\r\nscala> java.sql.Types.ARRAY\r\nres3: Int = 2003\r\n\r\nscala> rs.next()\r\nres4: Boolean = true\r\n\r\nscala> rs.getArray(1)\r\njava.sql.SQLException: Method not supported\r\n  at org.apache.hive.jdbc.HiveBaseResultSet.getArray(HiveBaseResultSet.java:113)\r\n  ... 33 elided\r\n\r\nscala> rs.getString(1)\r\nres6: String = [0,1,2,3,4,5,6,7,8,9]\r\n```\r\nAssuming that it's a generic JDBC application, not specific to Hive quirks, how is that application supposed to know that after getting a `getColumnType` of `Types.Array`, it needs to retrieve it with `getString`, and not with `getArray`?",
        "createdAt" : "2019-09-09T14:16:40Z",
        "updatedAt" : "2019-09-10T09:49:47Z",
        "lastEditedBy" : "e5beb795-ac0e-4bd6-ad66-708215b8ae58",
        "tags" : [
        ]
      },
      {
        "id" : "375af1e9-64f6-41a9-b863-ea0f11a6c803",
        "parentId" : "1d64e277-ce78-42c7-8c40-1bb2553157a7",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "@juliuszsompolski \r\nIn hive jdbc method. It will final treat ARRAY, MAP, STRUCT ..etc as String Type:\r\n\r\n```\r\nstatic String columnClassName(Type hiveType, JdbcColumnAttributes columnAttributes)\r\n      throws SQLException {\r\n    int columnType = hiveTypeToSqlType(hiveType);\r\n    switch(columnType) {\r\n      case Types.NULL:\r\n        return \"null\";\r\n      case Types.BOOLEAN:\r\n        return Boolean.class.getName();\r\n      case Types.CHAR:\r\n      case Types.VARCHAR:\r\n        return String.class.getName();\r\n      case Types.TINYINT:\r\n        return Byte.class.getName();\r\n      case Types.SMALLINT:\r\n        return Short.class.getName();\r\n      case Types.INTEGER:\r\n        return Integer.class.getName();\r\n      case Types.BIGINT:\r\n        return Long.class.getName();\r\n      case Types.DATE:\r\n        return Date.class.getName();\r\n      case Types.FLOAT:\r\n        return Float.class.getName();\r\n      case Types.DOUBLE:\r\n        return Double.class.getName();\r\n      case  Types.TIMESTAMP:\r\n        return Timestamp.class.getName();\r\n      case Types.DECIMAL:\r\n        return BigInteger.class.getName();\r\n      case Types.BINARY:\r\n        return byte[].class.getName();\r\n      case Types.OTHER:\r\n      case Types.JAVA_OBJECT: {\r\n        switch (hiveType) {\r\n          case INTERVAL_YEAR_MONTH_TYPE:\r\n            return HiveIntervalYearMonth.class.getName();\r\n          case INTERVAL_DAY_TIME_TYPE:\r\n            return HiveIntervalDayTime.class.getName();\r\n          default:\r\n            return String.class.getName();\r\n        }\r\n      }\r\n      case Types.ARRAY:\r\n      case Types.STRUCT:\r\n        return String.class.getName();\r\n      default:\r\n        throw new SQLException(\"Invalid column type: \" + columnType);\r\n    }\r\n  }\r\n```",
        "createdAt" : "2019-09-09T14:33:12Z",
        "updatedAt" : "2019-09-10T09:49:47Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "67a922ed-06e5-4a76-b662-dd9a1a20e693",
        "parentId" : "1d64e277-ce78-42c7-8c40-1bb2553157a7",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "OK. We can not fully support these type. Please remove them @AngersZhuuuu \r\nThanks @juliuszsompolski for you example.",
        "createdAt" : "2019-09-09T16:17:46Z",
        "updatedAt" : "2019-09-10T09:49:47Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      },
      {
        "id" : "a3a47fdc-8c8c-479a-a253-72c92d54df1b",
        "parentId" : "1d64e277-ce78-42c7-8c40-1bb2553157a7",
        "authorId" : "e5beb795-ac0e-4bd6-ad66-708215b8ae58",
        "body" : "Actually, thanks for explaining it @AngersZhuuuu, and you convinced me that ARRAY, MAP and STRUCT must be included.\r\n```\r\nscala> md.getColumnType(1)\r\nres11: Int = 2003 (== java.sql.Types.ARRAY)\r\n```\r\nbut then\r\n```\r\nscala> md.getColumnClassName(1)\r\nres10: String = java.lang.String\r\n```\r\nso that tells to the client that it is actually returned as String, and I should retrieve it as such, either with `rs.getObject(1).asInstance[String]` or as convenient shorthand with `rs.getString(1)`.\r\nIt would actually be incorrect to not include Array, Map, Struct, because we do return them in ResultSet schema (through `SparkExecuteStatement.getTableSchema`), so the client can get these type returned, and for any type that can be returned to the client there should be an entry in GetTypeInfo.\r\nWe therefore should not include INTERVAL (because we explicitly turn it to String return type after #25277), and not include UNIONTYPE or USER_DEFINED because they don't have any Spark equivalent, but ARRAY, MAP and STRUCT should be there.\r\nThank you for the explanation :+1: ",
        "createdAt" : "2019-09-09T19:00:59Z",
        "updatedAt" : "2019-09-10T09:49:47Z",
        "lastEditedBy" : "e5beb795-ac0e-4bd6-ad66-708215b8ae58",
        "tags" : [
        ]
      },
      {
        "id" : "4c6883e8-f804-46d6-afc7-86cb08c0e847",
        "parentId" : "1d64e277-ce78-42c7-8c40-1bb2553157a7",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "@juliuszsompolski \r\n```\r\ncase Types.OTHER:\r\n      case Types.JAVA_OBJECT: {\r\n        switch (hiveType) {\r\n          case INTERVAL_YEAR_MONTH_TYPE:\r\n            return HiveIntervalYearMonth.class.getName();\r\n          case INTERVAL_DAY_TIME_TYPE:\r\n            return HiveIntervalDayTime.class.getName();\r\n          default:\r\n            return String.class.getName();\r\n        }\r\n      }\r\n\r\n``` \r\nUSER_DEFINED  in java.sql.Types is OTHERS, in the convert progress, it's also converted to String , same as ARRAY, MAP, STRUCT. \r\nMaybe we should add USER_DEFINED.",
        "createdAt" : "2019-09-09T23:03:25Z",
        "updatedAt" : "2019-09-10T09:49:47Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "7172dac4-332e-4ebd-b8ac-1db3c14519af",
        "parentId" : "1d64e277-ce78-42c7-8c40-1bb2553157a7",
        "authorId" : "e5beb795-ac0e-4bd6-ad66-708215b8ae58",
        "body" : "But Spark will never return a USER_DEFINED type.\r\nThe current implementation of org.apache.spark.sql.types.UserDefinedType will return the underlying sqlType.simpleString as it's catalogString, so Thriftserver queries will return the underlying type in the schema.\r\nHence for USER_DEFINED (and UNIONTYPE) the argument is not that they wouldn't potentially work, but that Spark does not use them.",
        "createdAt" : "2019-09-10T09:34:19Z",
        "updatedAt" : "2019-09-10T09:49:47Z",
        "lastEditedBy" : "e5beb795-ac0e-4bd6-ad66-708215b8ae58",
        "tags" : [
        ]
      },
      {
        "id" : "7ddd3e54-5212-440b-917f-90c1c44c76ec",
        "parentId" : "1d64e277-ce78-42c7-8c40-1bb2553157a7",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> But Spark will never return a USER_DEFINED type.\r\n> The current implementation of org.apache.spark.sql.types.UserDefinedType will return the underlying sqlType.simpleString as it's catalogString, so Thriftserver queries will return the underlying type in the schema.\r\n> Hence for USER_DEFINED (and UNIONTYPE) the argument is not that they wouldn't potentially work, but that Spark does not use them.\r\n\r\nRemove it and resolve conflicts.",
        "createdAt" : "2019-09-10T09:50:54Z",
        "updatedAt" : "2019-09-10T09:50:55Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "3c488fcfc5a6e97db25f417d0dd8bdb339c99525",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +64,68 @@      DATE_TYPE, TIMESTAMP_TYPE,\n      ARRAY_TYPE, MAP_TYPE, STRUCT_TYPE)\n  }\n\n  private[thriftserver] def addToClassPath("
  },
  {
    "id" : "695ad4af-7a02-40e4-98bd-f5006087fac1",
    "prId" : 25443,
    "prUrl" : "https://github.com/apache/spark/pull/25443#pullrequestreview-279272979",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7dc0ee40-5d2f-4732-ab8c-46438265ada5",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "During JDK11 testing and review, we has been skipped renaming in order to focus JDK11 related stuff by minimizing PR diff. We may need to rename this src file directory `v2.3.5` to `v2.3.6` again for consistency later. If the test pass, I'd like to merge this AS-IS PR first.\r\n\r\ncc @gatorsmile , @srowen ",
        "createdAt" : "2019-08-24T03:16:00Z",
        "updatedAt" : "2019-08-24T03:16:23Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "ff4783c4c77f79d95fa805588f3283970a133780",
    "line" : 2,
    "diffHunk" : "@@ -1,1 +16,20 @@ */\n\npackage org.apache.spark.sql.hive.thriftserver\n\nimport java.security.AccessController"
  }
]