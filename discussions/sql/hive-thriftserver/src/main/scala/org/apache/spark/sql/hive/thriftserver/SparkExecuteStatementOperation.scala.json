[
  {
    "id" : "66f1836f-c3d1-431d-99e7-fbc0c54487a4",
    "prId" : 32995,
    "prUrl" : "https://github.com/apache/spark/pull/32995#pullrequestreview-688658903",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6e681a88-5e05-4930-8413-6bac726cb435",
        "parentId" : null,
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "It seems that there is not better choice from: https://github.com/apache/hive/blob/master/serde/src/java/org/apache/hadoop/hive/serde2/thrift/Type.java#L230",
        "createdAt" : "2021-06-21T12:55:31Z",
        "updatedAt" : "2021-06-21T12:55:31Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "2c8e4c50-954d-474a-b56d-25569a02a8ab",
        "parentId" : "6e681a88-5e05-4930-8413-6bac726cb435",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "We should probably map the existing timestamp to `TIMESTAMPLOCALTZ`, we can discuss this in an individual PR.",
        "createdAt" : "2021-06-21T16:41:17Z",
        "updatedAt" : "2021-06-21T16:41:38Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "88c59477-7252-4566-828c-6428a894adc7",
        "parentId" : "6e681a88-5e05-4930-8413-6bac726cb435",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "+1",
        "createdAt" : "2021-06-21T16:45:24Z",
        "updatedAt" : "2021-06-21T16:45:24Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "d5afd6abdb6eb56e91b2d95b0fecad6468d2a64b",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +380,384 @@        case _: YearMonthIntervalType => \"interval_year_month\"\n        case _: DayTimeIntervalType => \"interval_day_time\"\n        case _: TimestampWithoutTZType => \"timestamp\"\n        case other => other.catalogString\n      }"
  },
  {
    "id" : "c335a386-8a8a-4c75-8a2c-971830276d72",
    "prId" : 29933,
    "prUrl" : "https://github.com/apache/spark/pull/29933#pullrequestreview-507948419",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b33772a6-1964-44fd-bdf4-886f5bf27be0",
        "parentId" : null,
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "Maybe we need to call shutdown for this executor ?\r\n\r\nhttps://github.com/apache/hive/blob/940ee46d3a7a9300a47e5beae7c3ca6eb32fd759/service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java#L170-L184",
        "createdAt" : "2020-10-14T02:20:39Z",
        "updatedAt" : "2020-10-14T23:22:41Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "5e3c44060567d2234dd79d222f77bc58983bb805",
    "line" : 55,
    "diffHunk" : "@@ -1,1 +230,234 @@      }, timeout, TimeUnit.SECONDS)\n    }\n\n    if (!runInBackground) {\n      execute()"
  },
  {
    "id" : "4fb9aee1-be56-42c7-8c1c-9bea485d0fa8",
    "prId" : 29204,
    "prUrl" : "https://github.com/apache/spark/pull/29204#pullrequestreview-454606113",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dffaa272-cd36-48cb-a365-a04d26cb6aec",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "is `log.info` and `logInfo` the same?",
        "createdAt" : "2020-07-23T14:15:01Z",
        "updatedAt" : "2020-07-27T08:47:59Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "7c599fc7-d0f1-4d14-9b61-82f5d686b56f",
        "parentId" : "dffaa272-cd36-48cb-a365-a04d26cb6aec",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "`logInfo` will check `log.isInfoEnabled`",
        "createdAt" : "2020-07-24T02:31:19Z",
        "updatedAt" : "2020-07-27T08:47:59Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "50113145de4d9c7247d2a8af6e1e4f1087d19548",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +179,183 @@      }\n      previousFetchEndOffset = resultOffset\n      logInfo(s\"Returning result set with ${curRow} rows from offsets \" +\n        s\"[$previousFetchStartOffset, $previousFetchEndOffset) with $statementId\")\n      resultRowSet"
  },
  {
    "id" : "9713bcee-728d-416e-b039-128492689c4d",
    "prId" : 28991,
    "prUrl" : "https://github.com/apache/spark/pull/28991#pullrequestreview-442605674",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "11b598c4-8787-40e2-9bc9-b0e067cfcc16",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "nit: `logInfo` is located just before `HiveThriftServer2.eventManager.onXXX`?\r\n```\r\n        cleanup()\r\n        setState(OperationState.TIMEDOUT)\r\n        logInfo(s\"Timeout and Cancel query with $statementId \")\r\n        HiveThriftServer2.eventManager.onStatementCanceled(statementId)\r\n```\r\nhttps://github.com/apache/spark/blob/42f01e314b4874236544cc8b94bef766269385ee/sql/hive-thriftserver/src/main/scala/org/apache/spark/sql/hive/thriftserver/SparkOperation.scala#L51-L52",
        "createdAt" : "2020-07-03T08:22:15Z",
        "updatedAt" : "2020-08-11T02:48:03Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "bfd7ec1a-d1e0-4eef-94e1-5b705abb3992",
        "parentId" : "11b598c4-8787-40e2-9bc9-b0e067cfcc16",
        "authorId" : "7f1185d9-3900-4812-b576-80ba5f410d6b",
        "body" : "thanks, fixed",
        "createdAt" : "2020-07-03T09:17:18Z",
        "updatedAt" : "2020-08-11T02:48:03Z",
        "lastEditedBy" : "7f1185d9-3900-4812-b576-80ba5f410d6b",
        "tags" : [
        ]
      },
      {
        "id" : "75ac05d6-81ba-46c8-95fd-98eb937780f9",
        "parentId" : "11b598c4-8787-40e2-9bc9-b0e067cfcc16",
        "authorId" : "e5beb795-ac0e-4bd6-ad66-708215b8ae58",
        "body" : "Please setState before cleanup. It's an open bug, see https://github.com/apache/spark/pull/28912",
        "createdAt" : "2020-07-03T13:57:32Z",
        "updatedAt" : "2020-08-11T02:48:03Z",
        "lastEditedBy" : "e5beb795-ac0e-4bd6-ad66-708215b8ae58",
        "tags" : [
        ]
      },
      {
        "id" : "4facb138-f6a8-4db2-847a-5f7eebb6b578",
        "parentId" : "11b598c4-8787-40e2-9bc9-b0e067cfcc16",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "> Please setState before cleanup. It's an open bug, see #28912\r\n\r\nYea, nice suggestion! Might be better to add tests for that case, too.",
        "createdAt" : "2020-07-03T22:18:30Z",
        "updatedAt" : "2020-08-11T02:48:03Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "5038ec04-6819-4f2e-b2d0-42afb1ab69b3",
        "parentId" : "11b598c4-8787-40e2-9bc9-b0e067cfcc16",
        "authorId" : "7f1185d9-3900-4812-b576-80ba5f410d6b",
        "body" : "> Please setState before cleanup. It's an open bug, see #28912\r\n\r\nFixed, thanks for your review",
        "createdAt" : "2020-07-04T11:54:02Z",
        "updatedAt" : "2020-08-11T02:48:03Z",
        "lastEditedBy" : "7f1185d9-3900-4812-b576-80ba5f410d6b",
        "tags" : [
        ]
      }
    ],
    "commit" : "da76e1a7ba25ca96495cbb2ce56377983ee9f74f",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +314,318 @@    synchronized {\n      if (!getStatus.getState.isTerminal) {\n        setState(OperationState.TIMEDOUT)\n        cleanup()\n        logInfo(s\"Timeout and Cancel query with $statementId \")"
  },
  {
    "id" : "a8b12201-6129-4660-9ef8-db0a5f10919e",
    "prId" : 27552,
    "prUrl" : "https://github.com/apache/spark/pull/27552#pullrequestreview-359489834",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "244743e4-2b19-4b24-9aac-df9bb8b104fc",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "I have to convert Java 8 classes to `java.sql.Timestamp`/`Date` for correct formatting. I cannot use `TimestampFormatter` here because the conversions to strings can be performed in `ColumnBuffer` in `hive-serde`.",
        "createdAt" : "2020-02-13T09:24:33Z",
        "updatedAt" : "2020-02-17T12:50:08Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "652f19c7-eebb-4eef-ac15-311391506674",
        "parentId" : "244743e4-2b19-4b24-9aac-df9bb8b104fc",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can you add a code comment? Say that the results are passed to Hive and Hive only accepts  `Timestamp`/`Date`",
        "createdAt" : "2020-02-17T05:01:51Z",
        "updatedAt" : "2020-02-17T12:50:08Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "880b1dec95595b58688a3d5f7a2e0637a090cb47",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +182,186 @@        // Convert date-time instances to types that are acceptable by Hive libs\n        // used in conversions to strings.\n        val resultRow = row.map {\n          case i: Instant => Timestamp.from(i)\n          case ld: LocalDate => Date.valueOf(ld)"
  },
  {
    "id" : "65d166a7-90ef-4c44-bb24-afc84c274f44",
    "prId" : 27552,
    "prUrl" : "https://github.com/apache/spark/pull/27552#pullrequestreview-366155848",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1fa070e4-9e62-43c7-8f81-3a89cd1b5581",
        "parentId" : null,
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "There seems no java8 datetime values to be add to the `row` buffer here by `SparkExecuteStatementOperation#addNonNullColumnValue `\r\n\r\nhttps://github.com/apache/spark/pull/27552/files#diff-72dcd8f81a51c8a815159fdf0332acdcR84-R116",
        "createdAt" : "2020-02-28T03:38:18Z",
        "updatedAt" : "2020-02-28T03:38:33Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "24979ec9-e45a-44d0-827b-adcd46bd53a4",
        "parentId" : "1fa070e4-9e62-43c7-8f81-3a89cd1b5581",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can you help fix it? I think we should output java8 datetime values if the config is enabled.",
        "createdAt" : "2020-02-28T03:53:02Z",
        "updatedAt" : "2020-02-28T03:53:03Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "55c361bf-3e71-405a-baa6-f460d0447781",
        "parentId" : "1fa070e4-9e62-43c7-8f81-3a89cd1b5581",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "We are limited by `hive-jdbc` module, see https://github.com/apache/hive/blob/a7e704c679a00db68db9b9f921d133d79a32cfcc/jdbc/src/java/org/apache/hive/jdbc/HiveBaseResultSet.java#L427-L457, we might need our own jdbc driver implementation to achieve this",
        "createdAt" : "2020-02-28T04:32:13Z",
        "updatedAt" : "2020-02-28T04:32:14Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "880b1dec95595b58688a3d5f7a2e0637a090cb47",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +183,187 @@        // used in conversions to strings.\n        val resultRow = row.map {\n          case i: Instant => Timestamp.from(i)\n          case ld: LocalDate => Date.valueOf(ld)\n          case other => other"
  },
  {
    "id" : "2f5cc61d-cb19-4f94-99f0-ce7a78720c6b",
    "prId" : 26357,
    "prUrl" : "https://github.com/apache/spark/pull/26357#pullrequestreview-310892043",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "be43733a-5a47-46cd-8833-75d5bd48d96c",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "this configuration seems only affecting thriftserver. it should have an effect in regular Spark session as well. But more importantly, why don't you just restart or start another one for debugging purpose? I don't think this configuration is worth much.",
        "createdAt" : "2019-11-04T05:59:07Z",
        "updatedAt" : "2019-11-04T05:59:08Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "47bf8bc6-790a-4676-adff-f606071db54e",
        "parentId" : "be43733a-5a47-46cd-8833-75d5bd48d96c",
        "authorId" : "cb93ab63-5789-483a-864c-9467d1506bf5",
        "body" : "We just want to change the log level of thriftserver when our application has already deployed. If it doesn't support dynamic log level, we should change the log4j file and restart the thrift server every time. It is not convenient.",
        "createdAt" : "2019-11-04T06:28:05Z",
        "updatedAt" : "2019-11-04T06:28:05Z",
        "lastEditedBy" : "cb93ab63-5789-483a-864c-9467d1506bf5",
        "tags" : [
        ]
      }
    ],
    "commit" : "a26dd2b38a4ca3a6c27732efa591a9e06fc4dc34",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +377,381 @@\n  private def prepareLogLevel(): Unit = {\n    val debugClasses = sqlContext.conf.debugClasses()\n    if (debugClasses == null || debugClasses == \"\") {\n      SparkUtils.restoreLogLevel()"
  },
  {
    "id" : "7af1bbbf-eb83-45be-aecb-5ecda8b5d63f",
    "prId" : 26141,
    "prUrl" : "https://github.com/apache/spark/pull/26141#pullrequestreview-397295255",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4994f32f-aadc-4ad2-8a64-914c93ac3a4e",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "do we need to set it back?",
        "createdAt" : "2020-01-06T05:29:38Z",
        "updatedAt" : "2020-04-29T05:08:09Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "6e74000e-bbfa-45f4-bf90-6507c7a634dc",
        "parentId" : "4994f32f-aadc-4ad2-8a64-914c93ac3a4e",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> do we need to set it back?\r\n\r\nNo need, in our env, just changed like this works fine. if we set it back after `execute()`, \r\nmay have problem when re-compute.\r\n\r\nThis class loader is not used in thrift server side code. \r\nin `hive` about module, use `executionHiveClassLoader ` is also reasonable.",
        "createdAt" : "2020-01-06T06:14:25Z",
        "updatedAt" : "2020-04-29T05:08:09Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "bd92a7f2-eb05-42ab-83f5-fecdb1f53b71",
        "parentId" : "4994f32f-aadc-4ad2-8a64-914c93ac3a4e",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "\"about module\"?",
        "createdAt" : "2020-04-21T11:30:30Z",
        "updatedAt" : "2020-04-29T05:08:09Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "93e26e7e-ef46-4aad-9c3a-0aaf1725ec68",
        "parentId" : "4994f32f-aadc-4ad2-8a64-914c93ac3a4e",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> \"about module\"?\r\n\r\nemmmm, module about hive..",
        "createdAt" : "2020-04-21T12:49:06Z",
        "updatedAt" : "2020-04-29T05:08:09Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "baa9f0602e0d5fed526cef59eb7936b676d869a6",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +277,281 @@      // Always set the session state classloader to `executionHiveClassLoader` even for sync mode\n      if (!runInBackground) {\n        parentSession.getSessionState.getConf.setClassLoader(executionHiveClassLoader)\n      }\n"
  },
  {
    "id" : "70ff59a7-b728-4b13-8664-a35eb528e49b",
    "prId" : 26141,
    "prUrl" : "https://github.com/apache/spark/pull/26141#pullrequestreview-397296849",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "04eda80d-7599-45c7-ac7e-d642906ce96e",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Even in sync mode, we don't use the classloader of the current thread?",
        "createdAt" : "2020-04-21T11:27:58Z",
        "updatedAt" : "2020-04-29T05:08:09Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "6e7b3cfe-98cd-4103-8cbd-19f4ff9665f7",
        "parentId" : "04eda80d-7599-45c7-ac7e-d642906ce96e",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> Even in sync mode, we don't use the classloader of the current thread?\r\n\r\nIn code I mentioned in description, it will use SessionState's HiveConf's ClassLoader.\r\nThat's the problem, when it execute in background thread, it will use HiveClientImpl 's SessionState, and the corresponding classLoader is `executionHiveClassLoader`",
        "createdAt" : "2020-04-21T12:51:06Z",
        "updatedAt" : "2020-04-29T05:08:09Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "baa9f0602e0d5fed526cef59eb7936b676d869a6",
    "line" : 2,
    "diffHunk" : "@@ -1,1 +273,277 @@      // Always use the latest class loader provided by executionHive's state.\n      val executionHiveClassLoader = sqlContext.sharedState.jarClassLoader\n      Thread.currentThread().setContextClassLoader(executionHiveClassLoader)\n\n      // Always set the session state classloader to `executionHiveClassLoader` even for sync mode"
  },
  {
    "id" : "bd89106c-31cd-40c6-b04e-a0081ef666ce",
    "prId" : 26141,
    "prUrl" : "https://github.com/apache/spark/pull/26141#pullrequestreview-399674043",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bb303f51-68f5-4678-bf10-61419f1a6df7",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Can we add a comment?\r\n```\r\n// Always set the session state classloader to `executionHiveClassLoader` even for sync mode\r\n```",
        "createdAt" : "2020-04-24T06:34:04Z",
        "updatedAt" : "2020-04-29T05:08:09Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "baa9f0602e0d5fed526cef59eb7936b676d869a6",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +276,280 @@\n      // Always set the session state classloader to `executionHiveClassLoader` even for sync mode\n      if (!runInBackground) {\n        parentSession.getSessionState.getConf.setClassLoader(executionHiveClassLoader)\n      }"
  },
  {
    "id" : "d60eecac-24e8-4fc3-8f39-d4d379861b28",
    "prId" : 25743,
    "prUrl" : "https://github.com/apache/spark/pull/25743#pullrequestreview-287428703",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "31ab346a-eaeb-474e-9408-0a89acff9629",
        "parentId" : null,
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "Could we add a comment explaining why we need this change?",
        "createdAt" : "2019-09-12T13:29:41Z",
        "updatedAt" : "2019-09-16T09:17:10Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      }
    ],
    "commit" : "232ef816de0dba7690ff9959800ba94ec8f24a5e",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +272,276 @@        // task interrupted, it may have start some spark job, so we need to cancel again to\n        // make sure job was cancelled when background thread was interrupted\n        if (statementId != null) {\n          sqlContext.sparkContext.cancelJobGroup(statementId)\n        }"
  }
]