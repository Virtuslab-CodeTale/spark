[
  {
    "id" : "64c206c1-9587-4a81-96da-259958c6ab63",
    "prId" : 30536,
    "prUrl" : "https://github.com/apache/spark/pull/30536#pullrequestreview-540558598",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e361c148-850c-4ef7-af0b-f203c7da44ca",
        "parentId" : null,
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "The logic is the same: https://github.com/apache/spark/blob/008a2ad1f836ff04fafd51a9c94c355ef35f1692/sql/hive-thriftserver/src/main/java/org/apache/hive/service/cli/session/SessionManager.java#L273-L282",
        "createdAt" : "2020-11-30T02:06:08Z",
        "updatedAt" : "2020-11-30T02:07:17Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      }
    ],
    "commit" : "090dad4e57b73b7c56cd746b48a1bf930ab6a4fb",
    "line" : 61,
    "diffHunk" : "@@ -1,1 +81,85 @@            logWarning(\"Error closing session\", t)\n        }\n        throw new HiveSQLException(\"Failed to open new session: \" + e, e)\n    }\n  }"
  },
  {
    "id" : "b8b160c8-978d-48fd-84ed-b5a3afd4a020",
    "prId" : 30536,
    "prUrl" : "https://github.com/apache/spark/pull/30536#pullrequestreview-550699166",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c5e8fa12-ea0d-416f-9976-071d45a95723",
        "parentId" : null,
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "NonFatal ?",
        "createdAt" : "2020-12-12T07:36:53Z",
        "updatedAt" : "2020-12-12T07:36:53Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      }
    ],
    "commit" : "090dad4e57b73b7c56cd746b48a1bf930ab6a4fb",
    "line" : 58,
    "diffHunk" : "@@ -1,1 +78,82 @@          closeSession(sessionHandle)\n        } catch {\n          case t: Throwable =>\n            logWarning(\"Error closing session\", t)\n        }"
  },
  {
    "id" : "33659a59-6601-4521-8f20-1ba7c452180b",
    "prId" : 30536,
    "prUrl" : "https://github.com/apache/spark/pull/30536#pullrequestreview-550700821",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fe523cc3-a3d8-4917-bcfc-8f9ad9bcfc51",
        "parentId" : null,
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "NonFatal ?",
        "createdAt" : "2020-12-12T07:38:16Z",
        "updatedAt" : "2020-12-12T07:38:16Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      },
      {
        "id" : "51efc6a8-772c-4cb3-a2ab-48b23c6550e2",
        "parentId" : "fe523cc3-a3d8-4917-bcfc-8f9ad9bcfc51",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "https://github.com/apache/spark/pull/30744",
        "createdAt" : "2020-12-12T08:09:24Z",
        "updatedAt" : "2020-12-12T08:09:25Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      }
    ],
    "commit" : "090dad4e57b73b7c56cd746b48a1bf930ab6a4fb",
    "line" : 54,
    "diffHunk" : "@@ -1,1 +74,78 @@      sessionHandle\n    } catch {\n      case e: Exception =>\n        try {\n          closeSession(sessionHandle)"
  },
  {
    "id" : "6ad0c5cf-2938-4b78-ab44-9e4f19c4ae5d",
    "prId" : 29656,
    "prUrl" : "https://github.com/apache/spark/pull/29656#pullrequestreview-484196840",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ed147027-633e-4521-a690-04a295a658bd",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "just to be clear, is this just a small refactoring?",
        "createdAt" : "2020-09-07T06:16:21Z",
        "updatedAt" : "2020-09-07T06:16:22Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "02a11b84-c985-477e-8f81-566245692c5d",
        "parentId" : "ed147027-633e-4521-a690-04a295a658bd",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> just to be clear, is this just a small refactoring?\r\n\r\nIn this way we can avoid a lot of process part, but seems I have miss a important problem that user may write a db name wrong such as `aa.cc`",
        "createdAt" : "2020-09-07T06:33:34Z",
        "updatedAt" : "2020-09-07T06:33:34Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "d85ed65d-4141-4020-86f1-70d125e66a9a",
        "parentId" : "ed147027-633e-4521-a690-04a295a658bd",
        "authorId" : "2821208d-43c5-4475-94ad-36cbf84c14d8",
        "body" : "Can we add extra tests to verify the behaviour in case of failures? Is it the same error thrown? Are we skipping some checks along the way by calling the catalog functions?  ",
        "createdAt" : "2020-09-08T14:27:29Z",
        "updatedAt" : "2020-09-08T14:27:29Z",
        "lastEditedBy" : "2821208d-43c5-4475-94ad-36cbf84c14d8",
        "tags" : [
        ]
      }
    ],
    "commit" : "1f2fa6cfc6dd841bda5c82fa8f428a54e1dfa8a5",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +70,74 @@    setConfMap(ctx, hiveSessionState.getHiveVariables)\n    if (sessionConf != null && sessionConf.containsKey(\"use:database\")) {\n      ctx.sessionState.catalog.setCurrentDatabase(sessionConf.get(\"use:database\"))\n    }\n    sparkSqlOperationManager.sessionToContexts.put(sessionHandle, ctx)"
  }
]