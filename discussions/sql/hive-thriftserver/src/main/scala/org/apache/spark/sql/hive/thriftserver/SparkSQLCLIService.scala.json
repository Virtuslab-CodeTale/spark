[
  {
    "id" : "a8af297f-d29e-46e3-8878-1b63299c6dbe",
    "prId" : 30478,
    "prUrl" : "https://github.com/apache/spark/pull/30478#pullrequestreview-537053624",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0370e672-b76a-4e02-8d50-22ca0e7c66eb",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Just a question. Is this needed to connect?",
        "createdAt" : "2020-11-24T03:30:24Z",
        "updatedAt" : "2020-11-24T03:30:25Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "bc9d1d2d-b80a-4a36-9ba1-9b4ad3b10517",
        "parentId" : "0370e672-b76a-4e02-8d50-22ca0e7c66eb",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "Yes. otherwise it will throw exception:\r\n```\r\n20/11/23 20:03:09 WARN ThriftCLIService: Error getting info:\r\norg.apache.hive.service.cli.HiveSQLException: Unrecognized GetInfoType value: CLI_ODBC_KEYWORDS\r\n\tat org.apache.hive.service.cli.session.HiveSessionImpl.getInfo(HiveSessionImpl.java:444)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:564)\r\n\tat org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:78)\r\n\tat org.apache.hive.service.cli.session.HiveSessionProxy.access$000(HiveSessionProxy.java:36)\r\n\tat org.apache.hive.service.cli.session.HiveSessionProxy$1.run(HiveSessionProxy.java:63)\r\n\tat java.base/java.security.AccessController.doPrivileged(AccessController.java:691)\r\n\tat java.base/javax.security.auth.Subject.doAs(Subject.java:425)\r\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\r\n\tat org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:59)\r\n\tat com.sun.proxy.$Proxy23.getInfo(Unknown Source)\r\n\tat org.apache.hive.service.cli.CLIService.getInfo(CLIService.java:250)\r\n\tat org.apache.spark.sql.hive.thriftserver.SparkSQLCLIService.getInfo(SparkSQLCLIService.scala:107)\r\n\tat org.apache.hive.service.cli.thrift.ThriftCLIService.GetInfo(ThriftCLIService.java:440)\r\n\tat org.apache.hive.service.rpc.thrift.TCLIService$Processor$GetInfo.getResult(TCLIService.java:1537)\r\n\tat org.apache.hive.service.rpc.thrift.TCLIService$Processor$GetInfo.getResult(TCLIService.java:1522)\r\n\tat org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)\r\n\tat org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)\r\n\tat org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:53)\r\n\tat org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:310)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1130)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:630)\r\n\tat java.base/java.lang.Thread.run(Thread.java:832)\r\n```",
        "createdAt" : "2020-11-24T03:36:35Z",
        "updatedAt" : "2020-11-24T03:36:36Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      }
    ],
    "commit" : "43d90cafaf0aa4c8c4a355070d5c71008f6f3ea9",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +105,109 @@      case GetInfoType.CLI_DBMS_NAME => new GetInfoValue(\"Spark SQL\")\n      case GetInfoType.CLI_DBMS_VER => new GetInfoValue(sqlContext.sparkContext.version)\n      case GetInfoType.CLI_ODBC_KEYWORDS => new GetInfoValue(\"Unimplemented\")\n      case _ => super.getInfo(sessionHandle, getInfoType)\n    }"
  },
  {
    "id" : "cb577e6a-324e-40ba-872f-f2608843ee69",
    "prId" : 28835,
    "prUrl" : "https://github.com/apache/spark/pull/28835#pullrequestreview-431361753",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d13558b1-8ca5-4825-8132-ec94acc1befb",
        "parentId" : null,
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "CLIService will create a metastore connection during start, which is useless for our dummy execution hive conf and will cause class cast issue though different classloader",
        "createdAt" : "2020-06-16T10:17:24Z",
        "updatedAt" : "2020-06-18T14:30:38Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "22862417-ac95-4531-b2eb-5582d907eb19",
        "parentId" : "d13558b1-8ca5-4825-8132-ec94acc1befb",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "Here we bypass it and start the registered services as  CompositeService does",
        "createdAt" : "2020-06-16T10:18:22Z",
        "updatedAt" : "2020-06-18T14:30:38Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "e409f9ac1dd899e1d81f1e45000e4799ce3e3a2c",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +100,104 @@   * the ancestor [[CompositeService#start]] directly.\n   */\n  override def start(): Unit = startCompositeService()\n\n  override def getInfo(sessionHandle: SessionHandle, getInfoType: GetInfoType): GetInfoValue = {"
  }
]