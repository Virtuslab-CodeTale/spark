[
  {
    "id" : "b1c1c755-ec9f-4176-8d13-c667281afffd",
    "prId" : 32959,
    "prUrl" : "https://github.com/apache/spark/pull/32959#pullrequestreview-697903239",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "947bb207-ddf0-4e5b-b770-d0dd23db70be",
        "parentId" : null,
        "authorId" : "29c89154-22f7-40ee-b295-115a55734d6c",
        "body" : "same reason to \"date.sql\" that thriftserver couldn't handle negative year",
        "createdAt" : "2021-07-02T07:31:13Z",
        "updatedAt" : "2021-07-02T07:31:14Z",
        "lastEditedBy" : "29c89154-22f7-40ee-b295-115a55734d6c",
        "tags" : [
        ]
      }
    ],
    "commit" : "538463a405c2eac1ddfccba8d82ca846f81e5a22",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +86,90 @@    \"datetime.sql\",\n    \"datetime-legacy.sql\",\n    \"ansi/datetime.sql\",\n    // SPARK-28620\n    \"postgreSQL/float4.sql\","
  },
  {
    "id" : "3a7bbcf6-f5ec-4ef8-a8a5-2a0b81ff8c85",
    "prId" : 32648,
    "prUrl" : "https://github.com/apache/spark/pull/32648#pullrequestreview-666454378",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e1ed1b21-3f10-4432-9ee6-e3350e5b7b95",
        "parentId" : null,
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "```\r\n/spark/sql/hive-thriftserver/src/test/scala/org/apache/spark/sql/hive/thriftserver/ThriftServerQueryTestSuite.scala:110:15\r\nThe outer reference in this type test cannot be checked at run time.\r\n        case _: PgSQLTest =>\r\n```",
        "createdAt" : "2021-05-24T07:07:00Z",
        "updatedAt" : "2021-05-24T07:07:00Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      }
    ],
    "commit" : "2a867a6277c1c6c4f1a6497973588304f907bede",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +108,112 @@\n      testCase match {\n        case _: SQLQueryTestSuite#PgSQLTest =>\n          statement.execute(s\"SET ${SQLConf.ANSI_ENABLED.key} = true\")\n          statement.execute(s\"SET ${SQLConf.LEGACY_INTERVAL_ENABLED.key} = true\")"
  },
  {
    "id" : "6ac50485-8a37-44f3-917a-c9d7c6889f9e",
    "prId" : 32648,
    "prUrl" : "https://github.com/apache/spark/pull/32648#pullrequestreview-666454787",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "62e345fa-3a5f-47e1-a409-3caaa3d15612",
        "parentId" : null,
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "```\r\n/spark/sql/hive-thriftserver/src/test/scala/org/apache/spark/sql/hive/thriftserver/ThriftServerQueryTestSuite.scala:113:15\r\nThe outer reference in this type test cannot be checked at run time.\r\n        case _: AnsiTest =>\r\n```",
        "createdAt" : "2021-05-24T07:07:41Z",
        "updatedAt" : "2021-05-24T07:07:41Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      }
    ],
    "commit" : "2a867a6277c1c6c4f1a6497973588304f907bede",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +111,115 @@          statement.execute(s\"SET ${SQLConf.ANSI_ENABLED.key} = true\")\n          statement.execute(s\"SET ${SQLConf.LEGACY_INTERVAL_ENABLED.key} = true\")\n        case _: SQLQueryTestSuite#AnsiTest =>\n          statement.execute(s\"SET ${SQLConf.ANSI_ENABLED.key} = true\")\n        case _ =>"
  },
  {
    "id" : "099a7e37-048d-4fd3-b730-e40383673cfb",
    "prId" : 32442,
    "prUrl" : "https://github.com/apache/spark/pull/32442#pullrequestreview-654946228",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "020336a5-a96e-4504-900c-269318b9b4b1",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "why it doesn't work in thriftserver?",
        "createdAt" : "2021-05-07T08:39:58Z",
        "updatedAt" : "2021-05-10T08:41:36Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "383adefd-5c3e-42ef-8bd2-f636d4f63c06",
        "parentId" : "020336a5-a96e-4504-900c-269318b9b4b1",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "Because the output schema of hive is different from spark",
        "createdAt" : "2021-05-07T08:50:57Z",
        "updatedAt" : "2021-05-10T08:41:36Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      },
      {
        "id" : "cdc0f736-f85e-456e-96d2-9c4ac88c8518",
        "parentId" : "020336a5-a96e-4504-900c-269318b9b4b1",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "because Hive doesn't support this syntax?",
        "createdAt" : "2021-05-07T13:08:06Z",
        "updatedAt" : "2021-05-10T08:41:36Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "3c94b925-e04f-4c51-986f-3d8954198312",
        "parentId" : "020336a5-a96e-4504-900c-269318b9b4b1",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "how about adding a comment here to explain?",
        "createdAt" : "2021-05-07T17:55:41Z",
        "updatedAt" : "2021-05-10T08:41:36Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "e55982e9-cb48-4fc8-be5b-2644fca8eeb0",
        "parentId" : "020336a5-a96e-4504-900c-269318b9b4b1",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "> how about adding a comment here to explain?\r\n\r\nOK",
        "createdAt" : "2021-05-08T02:25:25Z",
        "updatedAt" : "2021-05-10T08:41:36Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      },
      {
        "id" : "2a320bfe-4843-42bd-b1b8-ffb976ff0bb6",
        "parentId" : "020336a5-a96e-4504-900c-269318b9b4b1",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "Because the output schema of some `DDL` in `Hive` is differing from `Spark SQL,` we exclude it.\r\nFor example, the output schema of `SHOW TABLES` is `(namespace, tableName, isTemporary)` in `Hive`, but `(tableName)` in Spark SQL.",
        "createdAt" : "2021-05-08T02:25:48Z",
        "updatedAt" : "2021-05-10T08:41:36Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "3312ac00fad514d9fa68e9b6999f7037cccf15b6",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +89,93 @@    // For example, the output schema of SHOW TABLES is (namespace, tableName, isTemporary) in Hive,\n    // but (tableName) in Spark SQL.\n    \"cte-ddl.sql\",\n    // SPARK-28636\n    \"decimalArithmeticOperations.sql\","
  },
  {
    "id" : "a90a7283-8aba-4872-87af-c1493439c23b",
    "prId" : 32141,
    "prUrl" : "https://github.com/apache/spark/pull/32141#pullrequestreview-634188306",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c1385d69-c758-43a5-b557-53a8a25cff4e",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Should we specify hive: `-Phive` or `-Phive-2.3`? I usually do.",
        "createdAt" : "2021-04-13T05:09:21Z",
        "updatedAt" : "2021-04-13T06:33:35Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "68954235-10e3-43a7-926a-4ef7b0bf7deb",
        "parentId" : "c1385d69-c758-43a5-b557-53a8a25cff4e",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "`-Phive-thriftserver` is enough. Let's make it simple here.",
        "createdAt" : "2021-04-13T05:36:50Z",
        "updatedAt" : "2021-04-13T06:33:35Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "590632cc8486dd2610302aa11584a73981bf0342",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +43,47 @@ * To run the entire test suite:\n * {{{\n *   build/sbt -Phive-thriftserver \"hive-thriftserver/testOnly *ThriftServerQueryTestSuite\"\n * }}}\n *"
  },
  {
    "id" : "73c78514-825a-4faf-9079-b6bbe0cf21ef",
    "prId" : 32141,
    "prUrl" : "https://github.com/apache/spark/pull/32141#pullrequestreview-634189511",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3fa23520-302c-43b7-b95a-30aaa1cb5d6f",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "**\"a single test\"** - Such command can run multiple tests, for example:\r\n```\r\nSPARK_GENERATE_GOLDEN_FILES=1 build/sbt \"sql/testOnly *SQLQueryTestSuite -- -z datetime.sql\"\r\n```\r\nupdates:\r\n```\r\n./sql/core/src/test/resources/sql-tests/inputs/ansi/datetime.sql\r\n./sql/core/src/test/resources/sql-tests/inputs/datetime.sql\r\n```",
        "createdAt" : "2021-04-13T05:27:23Z",
        "updatedAt" : "2021-04-13T06:33:35Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "1cfbc3ac-1847-4408-b99a-cdb0e5e817de",
        "parentId" : "3fa23520-302c-43b7-b95a-30aaa1cb5d6f",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "Yeah I know. This is copied from `SQLQueryTestSuite`.\r\nIf the developer really wants to update the single test only, he/she has to use the exact test case name. Otherwise, \"-z e.sql\" can update multiple test outputs too.",
        "createdAt" : "2021-04-13T05:39:49Z",
        "updatedAt" : "2021-04-13T06:33:35Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "590632cc8486dd2610302aa11584a73981bf0342",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +56,60 @@ * }}}\n *\n * To re-generate golden file for a single test, run:\n * {{{\n *   SPARK_GENERATE_GOLDEN_FILES=1 build/sbt \"sql/testOnly *SQLQueryTestSuite -- -z describe.sql\""
  }
]