[
  {
    "id" : "855b7f21-d540-4e8a-bfc1-abf9f4828a37",
    "prId" : 32949,
    "prUrl" : "https://github.com/apache/spark/pull/32949#pullrequestreview-704267163",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e494a552-cde1-4123-b123-2eb7c08b44fd",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "We should update this test to check the new interval types. @yaooqinn can you help with this later in a followup PR?",
        "createdAt" : "2021-07-12T15:40:03Z",
        "updatedAt" : "2021-07-12T15:40:03Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "b9d29165-3c1a-45e3-aa36-9362ae38ad87",
        "parentId" : "e494a552-cde1-4123-b123-2eb7c08b44fd",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "OK",
        "createdAt" : "2021-07-12T15:42:24Z",
        "updatedAt" : "2021-07-12T15:42:24Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "48f080fc5b3bb2a2d704a0cc6bddb8d6be56f328",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +357,361 @@\n    withJdbcStatement(viewName) { statement =>\n      statement.execute(s\"SET ${SQLConf.LEGACY_INTERVAL_ENABLED.key}=true\")\n      statement.execute(ddl)\n      val data = statement.getConnection.getMetaData"
  },
  {
    "id" : "9d2aea02-dd28-41b6-bd4b-2f2cbe6d3194",
    "prId" : 32176,
    "prUrl" : "https://github.com/apache/spark/pull/32176#pullrequestreview-636374676",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d944da7a-f31b-4538-aa66-f8b561b71757",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Opened SPARK-35085 to have the same tests for ANSI intervals",
        "createdAt" : "2021-04-15T07:53:14Z",
        "updatedAt" : "2021-04-16T11:24:15Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "7668405ebd902cea698b76c373d0c06b1e759426",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +358,362 @@    withJdbcStatement(viewName) { statement =>\n      val legacyIntervalEnabled = SQLConf.get.legacyIntervalEnabled\n      statement.execute(s\"SET ${SQLConf.LEGACY_INTERVAL_ENABLED.key}=true\")\n      statement.execute(ddl)\n      val data = statement.getConnection.getMetaData"
  },
  {
    "id" : "24c737dc-987d-4dd3-a844-d04f5c9de109",
    "prId" : 30101,
    "prUrl" : "https://github.com/apache/spark/pull/30101#pullrequestreview-513363314",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8bcd893c-7833-4006-b042-22719c8d1a61",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "This comment looks a bit confusing. btw, could we fix this in followup activities? If we can, could you file it in jira?",
        "createdAt" : "2020-10-21T00:21:01Z",
        "updatedAt" : "2020-10-22T07:43:16Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "f08cfa29-2ee1-4f36-9cc9-970c21ca05aa",
        "parentId" : "8bcd893c-7833-4006-b042-22719c8d1a61",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "we can't, it belongs to the upstream hive module where defines the hive behavior.  Here we just highlight the difference and make it perspective in future changes",
        "createdAt" : "2020-10-21T02:35:31Z",
        "updatedAt" : "2020-10-22T07:43:16Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "43f034c5-ea51-4051-bd80-0806682b04d7",
        "parentId" : "8bcd893c-7833-4006-b042-22719c8d1a61",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ah, I see...",
        "createdAt" : "2020-10-21T06:54:09Z",
        "updatedAt" : "2020-10-22T07:43:16Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "2b77e61f-a653-4447-9980-d2434b34ffc3",
        "parentId" : "8bcd893c-7833-4006-b042-22719c8d1a61",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "If so, could you write it in the comment like that?",
        "createdAt" : "2020-10-21T06:55:37Z",
        "updatedAt" : "2020-10-22T07:43:16Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "8e2bd998-c9c4-4f06-9191-f50a76e8b3ec",
        "parentId" : "8bcd893c-7833-4006-b042-22719c8d1a61",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "yea~",
        "createdAt" : "2020-10-21T07:04:34Z",
        "updatedAt" : "2020-10-22T07:43:16Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "7b1fa5049b6f3579a1f72a52a09c0d8fd38c72be",
    "line" : 73,
    "diffHunk" : "@@ -1,1 +452,456 @@        () => metaData.supportsSubqueriesInIns,\n        () => metaData.supportsSubqueriesInQuantifieds,\n        // Spark support this, see https://issues.apache.org/jira/browse/SPARK-18455\n        () => metaData.supportsCorrelatedSubqueries,\n        () => metaData.supportsOpenCursorsAcrossCommit,"
  },
  {
    "id" : "19c08a0c-20ea-486a-8c54-1079a36f7662",
    "prId" : 29834,
    "prUrl" : "https://github.com/apache/spark/pull/29834#pullrequestreview-493341517",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "89862f53-233b-46ca-ba90-c8ca1a13253c",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Does this operation work for permanent views?",
        "createdAt" : "2020-09-22T10:51:50Z",
        "updatedAt" : "2020-09-22T10:51:50Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "1c785fbc-c978-4401-8624-db162b331b2c",
        "parentId" : "89862f53-233b-46ca-ba90-c8ca1a13253c",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "this is DB layer API, we need to fix other type of operations too",
        "createdAt" : "2020-09-22T10:55:23Z",
        "updatedAt" : "2020-09-22T10:55:33Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "e79c1a57db504bb1804b616db37231088e68c1ba",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +29,33 @@  override def mode: ServerMode.Value = ServerMode.binary\n\n  test(\"Spark's own GetSchemasOperation(SparkGetSchemasOperation)\") {\n    def checkResult(rs: ResultSet, dbNames: Seq[String]): Unit = {\n      val expected = dbNames.iterator"
  }
]