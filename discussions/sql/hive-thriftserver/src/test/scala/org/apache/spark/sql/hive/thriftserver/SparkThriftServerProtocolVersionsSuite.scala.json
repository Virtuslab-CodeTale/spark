[
  {
    "id" : "a9ef2399-8fcd-485f-ac43-976476aa4773",
    "prId" : 32176,
    "prUrl" : "https://github.com/apache/spark/pull/32176#pullrequestreview-636373757",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b3747574-4998-4524-8625-8d956739e1f5",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "I wasn't able to set the config in the test. So, have to use the Cast expression to get the legacy interval column.",
        "createdAt" : "2021-04-15T07:52:13Z",
        "updatedAt" : "2021-04-16T11:24:15Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "7668405ebd902cea698b76c373d0c06b1e759426",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +365,369 @@      testExecuteStatementWithProtocolVersion(\n        version,\n        \"SELECT CAST('1 year 2 day' AS INTERVAL) AS icol\") { rs =>\n        assert(rs.next())\n        assert(rs.getString(1) === \"1 years 2 days\")"
  },
  {
    "id" : "69e6513d-7673-400d-9bdc-c668e6b190d5",
    "prId" : 32121,
    "prUrl" : "https://github.com/apache/spark/pull/32121#pullrequestreview-639179126",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ce42ec88-29ed-4da4-8162-1f8b3042b671",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "I tested only day-time interval because constructing of year-month interval in SQL is not possible at the moment. I created the JIRA for that: SPARK-35018",
        "createdAt" : "2021-04-10T10:00:12Z",
        "updatedAt" : "2021-04-11T15:47:32Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "8cf3dbe1-2c71-443d-a0f9-ea2131d7b37f",
        "parentId" : "ce42ec88-29ed-4da4-8162-1f8b3042b671",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "The PR https://github.com/apache/spark/pull/32240 adds a test for year-month intervals.",
        "createdAt" : "2021-04-19T18:31:34Z",
        "updatedAt" : "2021-04-19T18:31:34Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "feeeea5a2d2672c274ba626ddf1c31f6d082efc4",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +461,465 @@    }\n\n    test(s\"SPARK-35017: $version get day-time interval type\") {\n      testExecuteStatementWithProtocolVersion(\n        version, \"SELECT date'2021-01-01' - date'2020-12-31' AS dt\") { rs =>"
  },
  {
    "id" : "8bee6167-e07e-41b8-8737-82c24b1d019e",
    "prId" : 29746,
    "prUrl" : "https://github.com/apache/spark/pull/29746#pullrequestreview-487506001",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4ed09d7d-b35c-4cc4-9ad0-1220f576d4c3",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "We don't need to check `getColumnTypeName`?",
        "createdAt" : "2020-09-14T07:35:43Z",
        "updatedAt" : "2020-09-14T07:57:24Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "4151110e-fb6f-4dc0-bde9-f93e3e3514b7",
        "parentId" : "4ed09d7d-b35c-4cc4-9ad0-1220f576d4c3",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "thanks for the suggestions~",
        "createdAt" : "2020-09-14T07:57:31Z",
        "updatedAt" : "2020-09-14T07:57:31Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "9ebfe2cd72465b2dfb2d797edf819c5a060fc226",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +152,156 @@        assert(metaData.getColumnName(1) === \"CAST(1 AS TINYINT)\")\n        assert(metaData.getColumnTypeName(1) === \"tinyint\")\n        assert(metaData.getColumnType(1) === java.sql.Types.TINYINT)\n        assert(metaData.getPrecision(1) === 3)\n        assert(metaData.getScale(1) === 0)"
  },
  {
    "id" : "38ef0a8c-ccf9-4527-bc48-c48d984692f3",
    "prId" : 29746,
    "prUrl" : "https://github.com/apache/spark/pull/29746#pullrequestreview-487496555",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cf2972a0-d3bc-4b61-a0df-5c4b5273c0a2",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Why did you modify the existing statement?",
        "createdAt" : "2020-09-14T07:36:17Z",
        "updatedAt" : "2020-09-14T07:57:24Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "447aecd3-6928-47e0-9acf-6a1f1f2dc9e5",
        "parentId" : "cf2972a0-d3bc-4b61-a0df-5c4b5273c0a2",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "for easily building the following  check loop",
        "createdAt" : "2020-09-14T07:44:29Z",
        "updatedAt" : "2020-09-14T07:57:24Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "9ebfe2cd72465b2dfb2d797edf819c5a060fc226",
    "line" : 81,
    "diffHunk" : "@@ -1,1 +225,229 @@    test(s\"$version get decimal type\") {\n      testExecuteStatementWithProtocolVersion(version,\n        \"SELECT cast(1 as decimal(9, 1)) as col0, 1234.56BD as col1, 0.123 as col2\") { rs =>\n        assert(rs.next())\n        assert(rs.getBigDecimal(1) === new java.math.BigDecimal(\"1.0\"))"
  },
  {
    "id" : "28c37413-7716-4f61-8e40-8fe459e93947",
    "prId" : 29746,
    "prUrl" : "https://github.com/apache/spark/pull/29746#pullrequestreview-487495633",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5d533956-a99b-46b6-ae6b-7f291e4ee732",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "We don't need to test `rs.getBigDecimal(2)`?",
        "createdAt" : "2020-09-14T07:36:43Z",
        "updatedAt" : "2020-09-14T07:57:24Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "239ed5dd-9123-4aba-a5ca-ddd9ab1e6734",
        "parentId" : "5d533956-a99b-46b6-ae6b-7f291e4ee732",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "It's as same as L224",
        "createdAt" : "2020-09-14T07:43:09Z",
        "updatedAt" : "2020-09-14T07:57:24Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "9ebfe2cd72465b2dfb2d797edf819c5a060fc226",
    "line" : 84,
    "diffHunk" : "@@ -1,1 +227,231 @@        \"SELECT cast(1 as decimal(9, 1)) as col0, 1234.56BD as col1, 0.123 as col2\") { rs =>\n        assert(rs.next())\n        assert(rs.getBigDecimal(1) === new java.math.BigDecimal(\"1.0\"))\n        assert(rs.getBigDecimal(\"col1\") === new java.math.BigDecimal(\"1234.56\"))\n        assert(rs.getBigDecimal(\"col2\") === new java.math.BigDecimal(\"0.123\"))"
  },
  {
    "id" : "7314fe38-e67c-4a24-8276-3ec453ebc5ab",
    "prId" : 25480,
    "prUrl" : "https://github.com/apache/spark/pull/25480#pullrequestreview-278174803",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f87b2eca-26f5-4722-a3fe-024d5cf6376c",
        "parentId" : null,
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "@dongjoon-hyun @HyukjinKwon Maybe we should uses CharArray.",
        "createdAt" : "2019-08-17T04:12:04Z",
        "updatedAt" : "2019-08-17T04:12:04Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      },
      {
        "id" : "bfad6e2a-fdff-4b39-a2a3-5232e8bbb494",
        "parentId" : "f87b2eca-26f5-4722-a3fe-024d5cf6376c",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "What is the difference? Could you tell us the root cause you think?",
        "createdAt" : "2019-08-17T06:47:45Z",
        "updatedAt" : "2019-08-17T06:47:46Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "a5d1fcfe-1168-4b92-8b0e-c7fc971ec857",
        "parentId" : "f87b2eca-26f5-4722-a3fe-024d5cf6376c",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "I'm not sure. May be related to environment:\r\nhttps://amplab.cs.berkeley.edu/jenkins/job/NewSparkPullRequestBuilder/4832/\r\nhttps://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/109194/testReport/\r\n\r\nThese two PullRequestBuilders are built on the same machine(amp-jenkins-worker-03). The first one failed, but the last one successful. The environment differences:\r\n![image](https://user-images.githubusercontent.com/5399861/63208095-c7effd00-c102-11e9-8542-53cfad79716c.png)\r\n",
        "createdAt" : "2019-08-17T07:25:09Z",
        "updatedAt" : "2019-08-17T07:25:09Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      },
      {
        "id" : "3597c5a0-c0f3-4d4f-b560-aefb5b5010ba",
        "parentId" : "f87b2eca-26f5-4722-a3fe-024d5cf6376c",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "I will verify it later.",
        "createdAt" : "2019-08-17T07:25:27Z",
        "updatedAt" : "2019-08-17T07:25:28Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      },
      {
        "id" : "0020e7ab-849f-44de-9cbc-4aa4f9ef9667",
        "parentId" : "f87b2eca-26f5-4722-a3fe-024d5cf6376c",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Maybe, something like `LANG=en_US.UTF_8`?",
        "createdAt" : "2019-08-17T07:38:06Z",
        "updatedAt" : "2019-08-17T07:38:06Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "cf669bdb-4c63-4523-a7b6-66fc081396ba",
        "parentId" : "f87b2eca-26f5-4722-a3fe-024d5cf6376c",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "Yes. I can reproduce it by `unset LANG`:\r\n```\r\n[info] - HIVE_CLI_SERVICE_PROTOCOL_V1 get binary type *** FAILED *** (458 milliseconds)\r\n[info]   \"[?](\" did not equal \"[?](\" (SparkThriftServerProtocolVersionsSuite.scala:227)\r\n```",
        "createdAt" : "2019-08-17T14:43:13Z",
        "updatedAt" : "2019-08-17T14:43:13Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      },
      {
        "id" : "c528aebe-a8a0-4db1-aa78-5dde160d9d6b",
        "parentId" : "f87b2eca-26f5-4722-a3fe-024d5cf6376c",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "@shaneknapp I think we need to standardize `LANG` across the workers? or should I try giving it shot?\r\nThat seems reasonable though I am distantly concerned that something in the code relies on this setting. That said, I think it's probably correct to set `LANG` in a prod environment and correct to set it to this value anyway.",
        "createdAt" : "2019-08-17T20:45:12Z",
        "updatedAt" : "2019-08-17T20:45:12Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "5bbff76f-1c2b-4872-a4e7-8b7997472588",
        "parentId" : "f87b2eca-26f5-4722-a3fe-024d5cf6376c",
        "authorId" : "2d01e4aa-3f50-4136-a9ae-7e75e96e9979",
        "body" : "> I'm not sure. May be related to environment:\r\n> https://amplab.cs.berkeley.edu/jenkins/job/NewSparkPullRequestBuilder/4832/\r\n> https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/109194/testReport/\r\n> \r\n> These two PullRequestBuilders are built on the same machine(amp-jenkins-worker-03). The first one failed, but the last one successful. The environment differences:\r\n> ![image](https://user-images.githubusercontent.com/5399861/63208095-c7effd00-c102-11e9-8542-53cfad79716c.png)\r\n\r\nok, the SparkPullRequestBuilder is triggered by the amplab jenkins bot, and the NewSparkPullRequestBuilder is triggered by databricks' test site (http://spark-prs.appspot.com).\r\n\r\ni can easily add the LANG variable in the latter build.  another option is to add it to the default environment vars for all workers.",
        "createdAt" : "2019-08-21T17:51:54Z",
        "updatedAt" : "2019-08-21T17:52:31Z",
        "lastEditedBy" : "2d01e4aa-3f50-4136-a9ae-7e75e96e9979",
        "tags" : [
        ]
      },
      {
        "id" : "9442b248-a19e-4b34-9539-93492d03261a",
        "parentId" : "f87b2eca-26f5-4722-a3fe-024d5cf6376c",
        "authorId" : "2d01e4aa-3f50-4136-a9ae-7e75e96e9979",
        "body" : "(fyi, i just added LANG=en_US.UTF-8 to the NewSparkPullRequestBuilder job)",
        "createdAt" : "2019-08-21T17:55:13Z",
        "updatedAt" : "2019-08-21T17:55:13Z",
        "lastEditedBy" : "2d01e4aa-3f50-4136-a9ae-7e75e96e9979",
        "tags" : [
        ]
      },
      {
        "id" : "5d33f27f-8c1b-443b-9761-7300d00a480c",
        "parentId" : "f87b2eca-26f5-4722-a3fe-024d5cf6376c",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "@shaneknapp I'd set it everywhere, personally, if it's easy.",
        "createdAt" : "2019-08-21T17:55:14Z",
        "updatedAt" : "2019-08-21T17:55:14Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "7d42c624-ac52-49fb-b1a3-70d5dd76e93f",
        "parentId" : "f87b2eca-26f5-4722-a3fe-024d5cf6376c",
        "authorId" : "2d01e4aa-3f50-4136-a9ae-7e75e96e9979",
        "body" : "it's easy, but requires each worker to be disconnected/reconnected...  i'll get that set up now but it won't go in to effect until i have the opportunity to restart things.",
        "createdAt" : "2019-08-21T18:05:57Z",
        "updatedAt" : "2019-08-21T18:05:57Z",
        "lastEditedBy" : "2d01e4aa-3f50-4136-a9ae-7e75e96e9979",
        "tags" : [
        ]
      },
      {
        "id" : "2d040b65-08b0-47c7-87a0-e2ed57565835",
        "parentId" : "f87b2eca-26f5-4722-a3fe-024d5cf6376c",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "Thank you @shaneknapp",
        "createdAt" : "2019-08-22T03:04:20Z",
        "updatedAt" : "2019-08-22T03:04:21Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      },
      {
        "id" : "04e15482-97c6-40fd-a2e7-151d81ff2b2b",
        "parentId" : "f87b2eca-26f5-4722-a3fe-024d5cf6376c",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "Could we close this PR?",
        "createdAt" : "2019-08-22T03:04:54Z",
        "updatedAt" : "2019-08-22T03:04:54Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      },
      {
        "id" : "0a61a53c-2eac-4c2b-89bc-b8d2bba77095",
        "parentId" : "f87b2eca-26f5-4722-a3fe-024d5cf6376c",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Thank you for investigating this so far, @wangyum . Yes. It looks like that. \r\nYou can close this and the JIRA together. If the failure is reported again, we can reopen this.",
        "createdAt" : "2019-08-22T03:30:17Z",
        "updatedAt" : "2019-08-22T03:30:17Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "da84f92f7eb011184641eefb81f669bcdf74d080",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +227,231 @@        assertResult(Array(0, 0, 65533, 40).map(_.toChar)) {\n          rs.getString(1).toCharArray\n        }\n      }\n      testExecuteStatementWithProtocolVersion(version, \"SELECT cast(null as binary)\") { rs =>"
  },
  {
    "id" : "7f6716ac-76ed-4443-b5f1-8a4226d5d663",
    "prId" : 25379,
    "prUrl" : "https://github.com/apache/spark/pull/25379#pullrequestreview-272387527",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "28d7d5cb-2085-4f70-bbaf-981741e9d8bb",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "last nit. Can we add another test that returns an arbitrary binary (not UTF-8 encoded)? For instance,:\r\n\r\n```scala\r\nscala> sql(\"select cast(49960 as binary)\").show()\r\n+---------------------+\r\n|CAST(49960 AS BINARY)|\r\n+---------------------+\r\n|        [00 00 C3 28]|\r\n+---------------------+\r\n```\r\n\r\n`C3 28` is an invalid UTF-8:\r\n\r\n```python\r\n>>> bytes.fromhex(\"c328\").decode(\"utf-8\")\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0xc3 in position 0: invalid continuation byte\r\n```",
        "createdAt" : "2019-08-08T06:40:09Z",
        "updatedAt" : "2019-08-08T07:30:28Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "ac682ee2-49d6-453c-a0ec-a5b30051c3a0",
        "parentId" : "28d7d5cb-2085-4f70-bbaf-981741e9d8bb",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "Done",
        "createdAt" : "2019-08-08T07:31:14Z",
        "updatedAt" : "2019-08-08T07:31:14Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      }
    ],
    "commit" : "7b506e8cf33ad055adcb4daeda9bd8e18d233fbe",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +228,232 @@        assert(rs.getString(1) === UTF8String.fromBytes(NumberConverter.toBinary(49960)).toString)\n      }\n      testExecuteStatementWithProtocolVersion(version, \"SELECT cast(null as binary)\") { rs =>\n        assert(rs.next())\n        assert(rs.getString(1) === null)"
  },
  {
    "id" : "e49fa83a-5125-454e-b3a8-9a7e8fee5310",
    "prId" : 25228,
    "prUrl" : "https://github.com/apache/spark/pull/25228#pullrequestreview-267476392",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "eb218ecd-418a-4f2e-bfc5-902b36f2b6c9",
        "parentId" : null,
        "authorId" : "e5beb795-ac0e-4bd6-ad66-708215b8ae58",
        "body" : "nit: should we still assert what the returned value is equal to here?",
        "createdAt" : "2019-07-27T09:47:50Z",
        "updatedAt" : "2019-08-06T05:29:31Z",
        "lastEditedBy" : "e5beb795-ac0e-4bd6-ad66-708215b8ae58",
        "tags" : [
        ]
      },
      {
        "id" : "2380e014-af16-482b-8549-8da934f11935",
        "parentId" : "eb218ecd-418a-4f2e-bfc5-902b36f2b6c9",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "it will throw exception.\r\nClient log:\r\n```sql\r\n0: jdbc:hive2://localhost:10000/default> SELECT interval '1' year '2' day;\r\nError: java.lang.IllegalArgumentException: Unrecognized type name: interval (state=,code=0)\r\n```\r\nServer log:\r\n```java\r\njava.lang.RuntimeException: java.lang.IllegalArgumentException: Unrecognized type name: interval\r\n\tat org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:83)\r\n\tat org.apache.hive.service.cli.session.HiveSessionProxy.access$000(HiveSessionProxy.java:36)\r\n\tat org.apache.hive.service.cli.session.HiveSessionProxy$1.run(HiveSessionProxy.java:63)\r\n\tat java.security.AccessController.doPrivileged(AccessController.java:770)\r\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\r\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1746)\r\n\tat org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:59)\r\n\tat com.sun.proxy.$Proxy26.getResultSetMetadata(Unknown Source)\r\n\tat org.apache.hive.service.cli.CLIService.getResultSetMetadata(CLIService.java:436)\r\n\tat org.apache.hive.service.cli.thrift.ThriftCLIService.GetResultSetMetadata(ThriftCLIService.java:607)\r\n\tat org.apache.hive.service.cli.thrift.TCLIService$Processor$GetResultSetMetadata.getResult(TCLIService.java:1533)\r\n\tat org.apache.hive.service.cli.thrift.TCLIService$Processor$GetResultSetMetadata.getResult(TCLIService.java:1518)\r\n\tat org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38)\r\n\tat org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)\r\n\tat org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:53)\r\n\tat org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:310)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:819)\r\nCaused by: java.lang.IllegalArgumentException: Unrecognized type name: interval\r\n\tat org.apache.hive.service.cli.Type.getType(Type.java:169)\r\n\tat org.apache.hive.service.cli.TypeDescriptor.<init>(TypeDescriptor.java:53)\r\n\tat org.apache.hive.service.cli.ColumnDescriptor.<init>(ColumnDescriptor.java:53)\r\n\tat org.apache.hive.service.cli.TableSchema.<init>(TableSchema.java:52)\r\n\tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$.getTableSchema(SparkExecuteStatementOperation.scala:314)\r\n\tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.resultSchema$lzycompute(SparkExecuteStatementOperation.scala:69)\r\n\tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.resultSchema(SparkExecuteStatementOperation.scala:64)\r\n\tat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.getResultSetSchema(SparkExecuteStatementOperation.scala:158)\r\n\tat org.apache.hive.service.cli.operation.OperationManager.getOperationResultSetSchema(OperationManager.java:209)\r\n\tat org.apache.hive.service.cli.session.HiveSessionImpl.getResultSetMetadata(HiveSessionImpl.java:773)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:78)\r\n\t... 18 more\r\n```",
        "createdAt" : "2019-07-27T13:18:51Z",
        "updatedAt" : "2019-08-06T05:29:31Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      },
      {
        "id" : "54661294-dfa1-4a03-a1dd-ab6af5811210",
        "parentId" : "eb218ecd-418a-4f2e-bfc5-902b36f2b6c9",
        "authorId" : "e5beb795-ac0e-4bd6-ad66-708215b8ae58",
        "body" : "Would it fix it if it was converted to string like other unsupported types (Arrays, Maps etc.) in https://github.com/apache/spark/blob/master/sql/hive-thriftserver/src/main/scala/org/apache/spark/sql/hive/thriftserver/SparkExecuteStatementOperation.scala#L107 ?",
        "createdAt" : "2019-07-27T17:39:27Z",
        "updatedAt" : "2019-08-06T05:29:31Z",
        "lastEditedBy" : "e5beb795-ac0e-4bd6-ad66-708215b8ae58",
        "tags" : [
        ]
      }
    ],
    "commit" : "1c9afae88de80a69c872488d520574f37ff95ec3",
    "line" : 259,
    "diffHunk" : "@@ -1,1 +257,261 @@    ignore(s\"$version get interval type\") {\n      testExecuteStatementWithProtocolVersion(version, \"SELECT interval '1' year '2' day\") { rs =>\n        assert(rs.next())\n      }\n    }"
  }
]