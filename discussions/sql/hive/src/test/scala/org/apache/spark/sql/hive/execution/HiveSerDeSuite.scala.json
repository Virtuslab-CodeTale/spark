[
  {
    "id" : "be9cae9e-198d-40cd-ac06-2373b9598dca",
    "prId" : 26736,
    "prUrl" : "https://github.com/apache/spark/pull/26736#pullrequestreview-328046736",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e417dadd-2be2-4a7c-b13d-c3fab79de146",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "shall we just add `using hive`?",
        "createdAt" : "2019-12-06T07:04:58Z",
        "updatedAt" : "2019-12-06T07:45:19Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "ae3ef0ea-7348-459b-b55b-013d2a17086b",
        "parentId" : "e417dadd-2be2-4a7c-b13d-c3fab79de146",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "This is intended to test hive storage, `using hive` could break this.",
        "createdAt" : "2019-12-06T08:08:19Z",
        "updatedAt" : "2019-12-06T08:08:20Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "a2013079277494504af75ac5257652cd24f71e57",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +87,91 @@      SQLConf.LEGACY_CREATE_HIVE_TABLE_BY_DEFAULT_ENABLED.key -> \"true\") {\n      val (desc, exists) = extractTableDesc(\n        \"CREATE TABLE IF NOT EXISTS fileformat_test (id int)\")\n      assert(exists)\n      assert(desc.storage.inputFormat == Some(\"org.apache.hadoop.hive.ql.io.orc.OrcInputFormat\"))"
  },
  {
    "id" : "509bc1bb-d277-4575-8d20-b2ab3e2e5e9e",
    "prId" : 26736,
    "prUrl" : "https://github.com/apache/spark/pull/26736#pullrequestreview-328026653",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e5461e14-8606-4bb8-9389-cdf138221f1c",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ditto",
        "createdAt" : "2019-12-06T07:05:09Z",
        "updatedAt" : "2019-12-06T07:45:19Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "a2013079277494504af75ac5257652cd24f71e57",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +95,99 @@\n    withSQLConf(\"hive.default.fileformat\" -> \"parquet\",\n      SQLConf.LEGACY_CREATE_HIVE_TABLE_BY_DEFAULT_ENABLED.key -> \"true\") {\n      val (desc, exists) = extractTableDesc(\"CREATE TABLE IF NOT EXISTS fileformat_test (id int)\")\n      assert(exists)"
  },
  {
    "id" : "0d987d96-24ec-4b23-95af-882a90e1b23b",
    "prId" : 24489,
    "prUrl" : "https://github.com/apache/spark/pull/24489#pullrequestreview-233709918",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2f80d1d6-683d-491d-8de6-2d4d18eb0df4",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "nit: we could make this line up.",
        "createdAt" : "2019-05-04T00:02:08Z",
        "updatedAt" : "2019-05-04T00:02:08Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "21a750c294e9119f33132d0d89131b84d6bfa302",
    "line" : 35,
    "diffHunk" : "@@ -1,1 +227,231 @@      assert(storageFormat.serde.contains(\"org.apache.hadoop.hive.ql.io.orc.OrcSerde\"))\n    }\n    finally {\n      testSession.sparkContext.hadoopConfiguration.unset(\"hive.default.fileformat\")\n    }"
  }
]