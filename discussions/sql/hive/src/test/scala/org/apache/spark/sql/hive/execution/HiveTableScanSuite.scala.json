[
  {
    "id" : "86922cfd-5659-439f-8bd6-2b2b0ee99a9b",
    "prId" : 29739,
    "prUrl" : "https://github.com/apache/spark/pull/29739#pullrequestreview-489427414",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a116ef70-e86e-4ab6-879e-ebec441490dd",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This seems duplicated to `Scan hive default.df`",
        "createdAt" : "2020-09-16T08:47:45Z",
        "updatedAt" : "2020-09-17T10:25:55Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "fed7fd41-dd54-4576-8458-227074e3fc17",
        "parentId" : "a116ef70-e86e-4ab6-879e-ebec441490dd",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> This seems duplicated to `Scan hive default.df`\r\n\r\nYea, in origin plan, also have this problem. we can't drop this in `HiveTableRelation`  since we need to show table in Optimized plan and  analyzed plan. \r\n\r\nHow about  implement HiveTableScanExec's `simpleString` to filter  HiveTableRelation's table info?",
        "createdAt" : "2020-09-16T08:52:16Z",
        "updatedAt" : "2020-09-17T10:25:55Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "428b0f3c-3002-4180-a8d4-e8c2a4f41a84",
        "parentId" : "a116ef70-e86e-4ab6-879e-ebec441490dd",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "let's leave it, as it's a trivial problem.",
        "createdAt" : "2020-09-16T09:03:47Z",
        "updatedAt" : "2020-09-17T10:25:55Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "cb5aa460-0199-4678-8f96-75090125827c",
        "parentId" : "a116ef70-e86e-4ab6-879e-ebec441490dd",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> let's leave it, as it's a trivial problem.\r\n\r\nOk.",
        "createdAt" : "2020-09-16T09:10:05Z",
        "updatedAt" : "2020-09-17T10:25:55Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "2a8fd35899afc4ae6f43ad7afe192fc57e519966",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +205,209 @@          \"Scan hive default.df [id, k],\" +\n            \" HiveTableRelation [\" +\n            \"`default`.`df`,\" +\n            \" org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe,\" +\n            \" Data Cols: [id],\" +"
  },
  {
    "id" : "8fa7180a-ea9d-41ab-b6f5-89b354f362db",
    "prId" : 26461,
    "prUrl" : "https://github.com/apache/spark/pull/26461#pullrequestreview-315103627",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "97cbcfc3-8dcb-4359-b5e4-2077fe4ccc2d",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "`should not increase data parallelism` -> `should respect HIVE_TABLE_SCAN_MAX_PARALLELISM`?",
        "createdAt" : "2019-11-11T19:20:31Z",
        "updatedAt" : "2019-11-11T19:20:31Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "2b7615c79ad83b4078c01d0864cdb9989e411624",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +189,193 @@  }\n\n  test(\"HiveTableScanExec should not increase data parallelism\") {\n    withSQLConf(HiveUtils.HIVE_TABLE_SCAN_MAX_PARALLELISM.key -> \"1\") {\n      val view = \"src\""
  }
]