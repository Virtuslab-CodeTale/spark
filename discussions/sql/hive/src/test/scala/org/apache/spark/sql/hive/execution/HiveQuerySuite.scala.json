[
  {
    "id" : "204fc163-da79-4a5d-a4cb-394544a849b9",
    "prId" : 32074,
    "prUrl" : "https://github.com/apache/spark/pull/32074#pullrequestreview-630416773",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b5738473-20df-432d-9a27-4e8eadadaa66",
        "parentId" : null,
        "authorId" : "3a227965-84e0-47cf-9974-11293764f028",
        "body" : "Unlike `ADD FILE \"path\"` and `ADD ARCHIVE \"path\"`, we cannot execute `ADD JAR \"path\"` when the path contains whitespaces.\r\nI think it's a bug and #32052 will fix this issue.",
        "createdAt" : "2021-04-07T05:43:24Z",
        "updatedAt" : "2021-04-12T09:26:21Z",
        "lastEditedBy" : "3a227965-84e0-47cf-9974-11293764f028",
        "tags" : [
        ]
      },
      {
        "id" : "6a29e4c8-b20b-44af-a0c3-573b32a3e5ad",
        "parentId" : "b5738473-20df-432d-9a27-4e8eadadaa66",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Got it. @sarutak .",
        "createdAt" : "2021-04-07T18:40:25Z",
        "updatedAt" : "2021-04-12T09:26:21Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "3f78c4387f6acc3c781a39876214376ba86b0e2b",
    "line" : 65,
    "diffHunk" : "@@ -1,1 +1026,1030 @@\n      sql(s\"ADD JAR ${jarFile4.getAbsolutePath}\")\n      sql(s\"ADD JAR ${jarFile5.getAbsolutePath}\")\n      sql(s\"ADD JAR ${jarFile6.getAbsolutePath}\")\n      val listJars = sql(s\"LIST JARS '${jarFile4.getAbsolutePath}' \" +"
  },
  {
    "id" : "606e461b-b9d2-4d13-ba83-d35f56a710d8",
    "prId" : 31721,
    "prUrl" : "https://github.com/apache/spark/pull/31721#pullrequestreview-606659023",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ec58463c-013b-47c9-b743-93fb0c93c80d",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Could you add a test for `ADD ARCHIVES`, too?",
        "createdAt" : "2021-03-08T12:14:36Z",
        "updatedAt" : "2021-03-09T06:39:03Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "4bf4de06-451b-4ff7-a010-c0fa4b556b35",
        "parentId" : "ec58463c-013b-47c9-b743-93fb0c93c80d",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "What if the given file does not exist? Also, what if the given file has a unsupported format?",
        "createdAt" : "2021-03-08T12:17:09Z",
        "updatedAt" : "2021-03-09T06:39:03Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "84070bfc-89af-43cc-b480-7bbe6d621230",
        "parentId" : "ec58463c-013b-47c9-b743-93fb0c93c80d",
        "authorId" : "3a227965-84e0-47cf-9974-11293764f028",
        "body" : "> Could you add a test for ADD ARCHIVES, too?\r\n\r\nIt's not supported.\r\n\r\n> What if the given file does not exist? Also, what if the given file has a unsupported format?\r\n\r\nCovered such cases.",
        "createdAt" : "2021-03-08T20:02:13Z",
        "updatedAt" : "2021-03-09T06:39:03Z",
        "lastEditedBy" : "3a227965-84e0-47cf-9974-11293764f028",
        "tags" : [
        ]
      }
    ],
    "commit" : "ff708fa75c8a16943d0187d7854cd57480e22478",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +872,876 @@      TestUtils.createJar(Seq(file2), jarFile)\n\n      sql(s\"ADD ARCHIVE ${zipFile.getAbsolutePath}#foo\")\n      sql(s\"ADD ARCHIVE ${jarFile.getAbsolutePath}#bar\")\n"
  },
  {
    "id" : "ce5d472b-4696-4a02-a8a2-234c64a67aeb",
    "prId" : 31721,
    "prUrl" : "https://github.com/apache/spark/pull/31721#pullrequestreview-606497104",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a1917d59-1fab-4592-aade-dba34dac30d0",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "nit: please use the upper case where possible, `LIST ARCHIVES`.",
        "createdAt" : "2021-03-08T12:15:54Z",
        "updatedAt" : "2021-03-09T06:39:03Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "53ae6190-d69d-4836-8888-f8fdc5bb1c1c",
        "parentId" : "a1917d59-1fab-4592-aade-dba34dac30d0",
        "authorId" : "3a227965-84e0-47cf-9974-11293764f028",
        "body" : "There are `list file`, `list files`, `list jar` and `list jars` in this file.\r\nI don't think it matters but If you think it's really necessary them to be upper case, I'll fix including them.",
        "createdAt" : "2021-03-08T16:52:38Z",
        "updatedAt" : "2021-03-09T06:39:03Z",
        "lastEditedBy" : "3a227965-84e0-47cf-9974-11293764f028",
        "tags" : [
        ]
      }
    ],
    "commit" : "ff708fa75c8a16943d0187d7854cd57480e22478",
    "line" : 51,
    "diffHunk" : "@@ -1,1 +898,902 @@      assert(checkAddArchive(3) === (\"bar\", true, None))\n      assert(checkAddArchive(4) === (s\"bar/${file2.getName}\", true, Some(\"file2\")))\n      assert(sql(\"list archives\").\n        filter(_.getString(0).contains(s\"${zipFile.getAbsolutePath}\")).count() > 0)\n      assert(sql(\"list archive\")."
  },
  {
    "id" : "9d5aeb1a-7d67-43fa-a410-16b347bccdf8",
    "prId" : 31721,
    "prUrl" : "https://github.com/apache/spark/pull/31721#pullrequestreview-606608910",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4ccb5c5e-dd7c-44d9-98d9-dfe25473f065",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "ditto",
        "createdAt" : "2021-03-08T12:16:22Z",
        "updatedAt" : "2021-03-09T06:39:03Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "450a960c-da67-4cfb-b97f-2dea9e678612",
        "parentId" : "4ccb5c5e-dd7c-44d9-98d9-dfe25473f065",
        "authorId" : "3a227965-84e0-47cf-9974-11293764f028",
        "body" : "[same reply](https://github.com/apache/spark/pull/31721#discussion_r589581473).",
        "createdAt" : "2021-03-08T18:57:36Z",
        "updatedAt" : "2021-03-09T06:39:03Z",
        "lastEditedBy" : "3a227965-84e0-47cf-9974-11293764f028",
        "tags" : [
        ]
      }
    ],
    "commit" : "ff708fa75c8a16943d0187d7854cd57480e22478",
    "line" : 53,
    "diffHunk" : "@@ -1,1 +900,904 @@      assert(sql(\"list archives\").\n        filter(_.getString(0).contains(s\"${zipFile.getAbsolutePath}\")).count() > 0)\n      assert(sql(\"list archive\").\n        filter(_.getString(0).contains(s\"${jarFile.getAbsolutePath}\")).count() > 0)\n      assert(sql(s\"list archive ${zipFile.getAbsolutePath}\").count() === 1)"
  },
  {
    "id" : "07d4f097-3aa5-4e7a-a83a-92aaf84b4ab4",
    "prId" : 25417,
    "prUrl" : "https://github.com/apache/spark/pull/25417#pullrequestreview-273572631",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1c91eb4e-e591-4f3a-b999-2e2de473800c",
        "parentId" : null,
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "Hive output result:\r\nhttps://github.com/apache/hive/blob/release-2.3.5-rc0/ql/src/test/results/clientpositive/udf_radians.q.out#L87-L91",
        "createdAt" : "2019-08-12T08:57:36Z",
        "updatedAt" : "2019-08-12T08:57:36Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      }
    ],
    "commit" : "ba9d634e478909aabbf2dd7f70355d9ed419479b",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +1218,1222 @@      } else {\n        assertResult(Array(Row(1.000000357564167))) (result)\n      }\n\n      assertResult(Array(Row(2.4999991485811655))) {"
  },
  {
    "id" : "7647b701-6d25-4920-be3f-fe8e3c4f055a",
    "prId" : 24886,
    "prUrl" : "https://github.com/apache/spark/pull/24886#pullrequestreview-254364455",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4c849322-9ab3-46e3-9656-dc6ccb1cb034",
        "parentId" : null,
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "Should we set it back?\r\n\r\nUse withSQLConf ?\r\n\r\nAlso do we need to set the case sensitivity conf?",
        "createdAt" : "2019-06-26T02:25:29Z",
        "updatedAt" : "2019-06-26T02:25:29Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      },
      {
        "id" : "d5b24508-7d46-4c4a-ac48-dbcda46052a8",
        "parentId" : "4c849322-9ab3-46e3-9656-dc6ccb1cb034",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "This set follows other tests in same suite. Using withSQLConf is good, yes.\r\n\r\nThe case sensitivity conf has no effect on this, I think it is fine.",
        "createdAt" : "2019-06-26T03:23:25Z",
        "updatedAt" : "2019-06-26T03:30:10Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "1aec7f83292269757bb4c5e863e1d439cd26dd02",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +1192,1196 @@  test(\"SPARK-28054: Unable to insert partitioned table when partition name is upper case\") {\n    withTable(\"spark_28054_test\") {\n      sql(\"set hive.exec.dynamic.partition.mode=nonstrict\")\n      sql(\"CREATE TABLE spark_28054_test (KEY STRING, VALUE STRING) PARTITIONED BY (DS STRING)\")\n"
  },
  {
    "id" : "5bcc0d61-7c17-48e2-98ee-610b8b33286d",
    "prId" : 24806,
    "prUrl" : "https://github.com/apache/spark/pull/24806#pullrequestreview-248960037",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d5e5bde7-3dee-48ba-81d7-b80b3e7e5e53",
        "parentId" : null,
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "Why does this use the optimized plan now? So that `checkAnalysis` will run?",
        "createdAt" : "2019-06-05T17:54:09Z",
        "updatedAt" : "2019-06-12T07:04:18Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "b02c0a2b-16d6-45dd-93cd-234644e2cf75",
        "parentId" : "d5e5bde7-3dee-48ba-81d7-b80b3e7e5e53",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "The `Cast` operator will be eliminated by optimization rule `ConstantFolding`.",
        "createdAt" : "2019-06-06T06:46:11Z",
        "updatedAt" : "2019-06-12T07:04:18Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "e528326e-213e-4152-84df-7bd4bef8fd25",
        "parentId" : "d5e5bde7-3dee-48ba-81d7-b80b3e7e5e53",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "Why not update the test case with the Cast operator?",
        "createdAt" : "2019-06-12T19:04:40Z",
        "updatedAt" : "2019-06-12T19:04:40Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      }
    ],
    "commit" : "3e2949131a8a7579149a7dd4153650461f5b5da2",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +376,380 @@\n      // The `Cast` operator will be eliminated by optimization rule `ConstantFolding`.\n      val optimizedPlan = sql(\n        \"\"\"\n        |INSERT OVERWRITE table test_partition PARTITION (b=1, c)"
  }
]