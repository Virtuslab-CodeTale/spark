[
  {
    "id" : "01ab72d8-af30-4de6-b717-9fa7d17f7b42",
    "prId" : 30665,
    "prUrl" : "https://github.com/apache/spark/pull/30665#pullrequestreview-548187606",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "70cb0253-f2e0-4223-9451-dd8f633f1941",
        "parentId" : null,
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "How about?\r\n```scala\r\ncheckAnswer(\r\n  sql(\"SELECT udtf_stack2(2, 'A', 10, date '2015-01-01', 'B', 20, date '2016-01-01')\"),\r\n  Seq(Row(\"A\", 10, java.sql.Date.valueOf(\"2015-01-01\")),\r\n    Row(\"B\", 20, java.sql.Date.valueOf(\"2016-01-01\"))))\r\n```",
        "createdAt" : "2020-12-09T13:35:30Z",
        "updatedAt" : "2020-12-09T13:35:31Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      },
      {
        "id" : "539219d7-8656-44c3-9c51-ce77bdd270b4",
        "parentId" : "70cb0253-f2e0-4223-9451-dd8f633f1941",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "Could you update test name?",
        "createdAt" : "2020-12-09T13:36:19Z",
        "updatedAt" : "2020-12-09T13:36:19Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      }
    ],
    "commit" : "0e3dca1ea3228747a43d573075bc6162cc76d475",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +2135,2139 @@      val num =\n        sql(\"SELECT udtf_stack2(2, 'A', 10, date '2015-01-01', 'B', 20, date '2016-01-01')\").count()\n      assert(num === 2)\n    }\n  }"
  },
  {
    "id" : "18eece97-a7cd-44bb-8cb5-9d5a73479caa",
    "prId" : 29761,
    "prUrl" : "https://github.com/apache/spark/pull/29761#pullrequestreview-490241510",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1ca557df-aad8-4b7e-bb9e-02059469e848",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Oh, I missed that you meant to change this.",
        "createdAt" : "2020-09-17T04:52:53Z",
        "updatedAt" : "2020-09-17T06:34:53Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "7d63fd96462fda9b820873a679464fe2662e6869",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +2207,2211 @@  }\n\n  test(\"SPARK-21912 Parquet table should not create invalid column names\") {\n    Seq(\" \", \",\", \";\", \"{\", \"}\", \"(\", \")\", \"\\n\", \"\\t\", \"=\").foreach { name =>\n      val source = \"PARQUET\""
  },
  {
    "id" : "7b8b4fc6-4b54-4f1a-a204-beeece52ac42",
    "prId" : 29672,
    "prUrl" : "https://github.com/apache/spark/pull/29672#pullrequestreview-485668578",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7d609a8b-59bb-4da6-ad8e-75d8ad8e9533",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Does this test fail w/o this patch? Looks it can pass even in master.",
        "createdAt" : "2020-09-10T05:20:27Z",
        "updatedAt" : "2020-09-10T05:26:05Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "f8613cfd-818b-460e-a821-75d48dea85dc",
        "parentId" : "7d609a8b-59bb-4da6-ad8e-75d8ad8e9533",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> Does this test fail w/o this patch? Looks it can pass even in master.\r\n\r\nI miss the point that SQLConf.get is related to current thread's SparkSession.",
        "createdAt" : "2020-09-10T07:50:12Z",
        "updatedAt" : "2020-09-10T07:50:12Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "fc221f5f5c9a73b4627ba24517c925393acf21ba",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +2562,2566 @@  }\n\n  test(\"SPARK-32818: make metastore convert session level configurable\") {\n    withSQLConf(HiveUtils.CONVERT_METASTORE_ORC.key -> \"true\") {\n      withTable(\"t\") {"
  },
  {
    "id" : "28464d48-b11e-4b7e-bcf9-8ccc679ddddc",
    "prId" : 29672,
    "prUrl" : "https://github.com/apache/spark/pull/29672#pullrequestreview-485589576",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a1f0ee65-f2c4-4019-b997-80c290b8eb2b",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "nit: `SparkPlan` not used.",
        "createdAt" : "2020-09-10T05:20:38Z",
        "updatedAt" : "2020-09-10T05:26:05Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "fc221f5f5c9a73b4627ba24517c925393acf21ba",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +34,38 @@import org.apache.spark.sql.catalyst.parser.ParseException\nimport org.apache.spark.sql.catalyst.plans.logical.{LogicalPlan, SubqueryAlias}\nimport org.apache.spark.sql.execution.{FileSourceScanExec, SparkPlan, TestUncaughtExceptionHandler}\nimport org.apache.spark.sql.execution.adaptive.{DisableAdaptiveExecutionSuite, EnableAdaptiveExecutionSuite}\nimport org.apache.spark.sql.execution.command.{FunctionsCommand, LoadDataCommand}"
  },
  {
    "id" : "fc3a844f-c122-4af4-9d74-198507973e62",
    "prId" : 29672,
    "prUrl" : "https://github.com/apache/spark/pull/29672#pullrequestreview-485589576",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c6430fe8-1d91-49bb-a76e-d0dc6016bece",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "I think we don't need the partition definition for this test and how about writing it like this;\r\n```\r\nsql(\"CREATE TABLE t (i INT) USING hive\")\r\nsql(\"SELECT * FROM t\")\r\n```",
        "createdAt" : "2020-09-10T05:22:02Z",
        "updatedAt" : "2020-09-10T05:26:05Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "fc221f5f5c9a73b4627ba24517c925393acf21ba",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +2566,2570 @@      withTable(\"t\") {\n        sql(\"CREATE TABLE t (i INT) PARTITIONED BY (p STRING) STORED AS ORC\")\n        sql(\"INSERT INTO t PARTITION(p='20200901') SELECT 1\")\n\n        val query ="
  },
  {
    "id" : "bf37afe7-ea9d-498c-bef4-a169ebe1bde7",
    "prId" : 29156,
    "prUrl" : "https://github.com/apache/spark/pull/29156#pullrequestreview-451173158",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5b8e32fb-e26c-4a61-b404-c9004a26ba65",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Just in case, could you check that the hist is correctly applied?",
        "createdAt" : "2020-07-19T22:58:34Z",
        "updatedAt" : "2020-07-19T22:58:34Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "75b7ac61-f4c9-4e12-9e87-4bcac82e11be",
        "parentId" : "5b8e32fb-e26c-4a61-b404-c9004a26ba65",
        "authorId" : "919368dc-8bac-4d8f-9fa6-be962263fc1e",
        "body" : "Thank you, I need to check the hist, seems something wrong with the patch.",
        "createdAt" : "2020-07-19T23:33:01Z",
        "updatedAt" : "2020-07-19T23:33:01Z",
        "lastEditedBy" : "919368dc-8bac-4d8f-9fa6-be962263fc1e",
        "tags" : [
        ]
      }
    ],
    "commit" : "be0711aa5582ea27d3d1f6b89a712ba7edcea057",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +2563,2567 @@    withTempView(\"t\") {\n      sql(\"create temporary view t as select 1 as id\")\n      sql(\"with cte as (select /*+ BROADCAST(id) */ id from t) select id from cte\")\n      sql(\"with cte as (select /*+ COALESCE(3) */ id from t) select id from cte\")\n    }"
  }
]