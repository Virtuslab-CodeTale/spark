[
  {
    "id" : "3d23da99-5789-44bb-b9ef-9e3c3a3052e3",
    "prId" : 30785,
    "prUrl" : "https://github.com/apache/spark/pull/30785#pullrequestreview-559035374",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4e6adafd-4e36-403a-9d17-3d2a2d28eaf5",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "How does the ORC table wotk with the delimiter?",
        "createdAt" : "2020-12-16T02:14:17Z",
        "updatedAt" : "2020-12-16T08:59:38Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "227a4538-180b-4294-b875-493812044f18",
        "parentId" : "4e6adafd-4e36-403a-9d17-3d2a2d28eaf5",
        "authorId" : "62055540-2831-4746-af2d-e126c5d7477e",
        "body" : "Although this is unnecessary for ORC table, we can support an option that user can choose to ignore it or not. Maybe it is better to throw warning than error.",
        "createdAt" : "2020-12-16T03:27:44Z",
        "updatedAt" : "2020-12-16T08:59:38Z",
        "lastEditedBy" : "62055540-2831-4746-af2d-e126c5d7477e",
        "tags" : [
        ]
      },
      {
        "id" : "60463860-aabb-4982-9872-e0606daac740",
        "parentId" : "4e6adafd-4e36-403a-9d17-3d2a2d28eaf5",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "It's better to be explicit for what Spark supports. It's a bit odd that we add no-op syntax.",
        "createdAt" : "2020-12-16T04:07:48Z",
        "updatedAt" : "2020-12-16T08:59:38Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "1842441e-876e-4b8e-b8c7-bd38c5d1e3f5",
        "parentId" : "4e6adafd-4e36-403a-9d17-3d2a2d28eaf5",
        "authorId" : "62055540-2831-4746-af2d-e126c5d7477e",
        "body" : "We have many tasks which are running on hive and slowly, so we want to migrate it from hive to spark. I think other companies want to this too. If we support ignore this exception by set spark.sql.orc.skipRowFormatDelimitedError=true , we can migrate hive task and user do not need to modify his sql script. ",
        "createdAt" : "2020-12-16T08:56:46Z",
        "updatedAt" : "2020-12-16T08:59:38Z",
        "lastEditedBy" : "62055540-2831-4746-af2d-e126c5d7477e",
        "tags" : [
        ]
      },
      {
        "id" : "6bade4c0-0c56-4f8a-84b0-99adb6d88ceb",
        "parentId" : "4e6adafd-4e36-403a-9d17-3d2a2d28eaf5",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Does Hive work with this delimiter specified with ORC?",
        "createdAt" : "2020-12-17T02:17:32Z",
        "updatedAt" : "2020-12-17T02:17:32Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "5db1b8a1-ae8b-4516-8ff5-8b1c5ae12ead",
        "parentId" : "4e6adafd-4e36-403a-9d17-3d2a2d28eaf5",
        "authorId" : "62055540-2831-4746-af2d-e126c5d7477e",
        "body" : "Hive doesn't work with it, but hive doesn't throw exception too.",
        "createdAt" : "2020-12-17T02:36:21Z",
        "updatedAt" : "2020-12-17T02:36:21Z",
        "lastEditedBy" : "62055540-2831-4746-af2d-e126c5d7477e",
        "tags" : [
        ]
      },
      {
        "id" : "19d70096-0f9f-4850-bf37-27f243bf2b83",
        "parentId" : "4e6adafd-4e36-403a-9d17-3d2a2d28eaf5",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Let's don't fix it then. It's odd that Spark works with a syntax that's no-op, and that does not also work in Hive.",
        "createdAt" : "2020-12-28T01:19:36Z",
        "updatedAt" : "2020-12-28T01:19:36Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "00d3b52d-93a2-4e6a-aafe-2b75596f8deb",
        "parentId" : "4e6adafd-4e36-403a-9d17-3d2a2d28eaf5",
        "authorId" : "62055540-2831-4746-af2d-e126c5d7477e",
        "body" : "thx very much, i'll close it.",
        "createdAt" : "2020-12-28T08:04:36Z",
        "updatedAt" : "2020-12-28T08:04:36Z",
        "lastEditedBy" : "62055540-2831-4746-af2d-e126c5d7477e",
        "tags" : [
        ]
      }
    ],
    "commit" : "05fcc631413a98bf0e623b68ea5ddb3ce1ce05d7",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +162,166 @@           |  stringField STRING\n           |)\n           |ROW FORMAT DELIMITED FIELDS TERMINATED BY '002'\n           |STORED AS ORC\n           |LOCATION '${orcTableAsDir.toURI}'"
  },
  {
    "id" : "dc8000a6-672f-49de-ad53-6d0e2d26cc5a",
    "prId" : 30734,
    "prUrl" : "https://github.com/apache/spark/pull/30734#pullrequestreview-552560377",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6ba3069e-9a4a-40dd-b24a-ede150e23e11",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "How does the ORC table wotk with the delimiter?",
        "createdAt" : "2020-12-15T10:18:27Z",
        "updatedAt" : "2020-12-15T10:18:27Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "482a6ee5-4cf1-4545-aef5-df2c81d3a69e",
        "parentId" : "6ba3069e-9a4a-40dd-b24a-ede150e23e11",
        "authorId" : "62055540-2831-4746-af2d-e126c5d7477e",
        "body" : "Sorry for my late reply. I found this problem when migrating task from hive to spark. Hive is supported (It's not good, but it's not a problem, we can ignore it). So I fixed it in version Spark 2.4. Although Orc doesn't need this delimiter, but I don't think we need to be so strict in syntax. It is more convenient to migrate tasks from hive to spark. \r\nI will close this PR and re submit a new PR based on Spark 2.4 https://github.com/apache/spark/pull/30785",
        "createdAt" : "2020-12-15T15:11:33Z",
        "updatedAt" : "2020-12-15T16:20:01Z",
        "lastEditedBy" : "62055540-2831-4746-af2d-e126c5d7477e",
        "tags" : [
        ]
      }
    ],
    "commit" : "bff97e24e3fb63d64e3dff5b05ab481908c882b2",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +336,340 @@           |  stringField STRING\n           |)\n           |ROW FORMAT DELIMITED FIELDS TERMINATED BY '002'\n           |STORED AS ORC\n           |LOCATION '${orcTableAsDir.toURI}'"
  }
]