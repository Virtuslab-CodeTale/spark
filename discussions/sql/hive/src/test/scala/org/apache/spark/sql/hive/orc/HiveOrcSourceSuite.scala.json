[
  {
    "id" : "3d23da99-5789-44bb-b9ef-9e3c3a3052e3",
    "prId" : 30785,
    "prUrl" : "https://github.com/apache/spark/pull/30785#pullrequestreview-559035374",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4e6adafd-4e36-403a-9d17-3d2a2d28eaf5",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "How does the ORC table wotk with the delimiter?",
        "createdAt" : "2020-12-16T02:14:17Z",
        "updatedAt" : "2020-12-16T08:59:38Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "227a4538-180b-4294-b875-493812044f18",
        "parentId" : "4e6adafd-4e36-403a-9d17-3d2a2d28eaf5",
        "authorId" : "62055540-2831-4746-af2d-e126c5d7477e",
        "body" : "Although this is unnecessary for ORC table, we can support an option that user can choose to ignore it or not. Maybe it is better to throw warning than error.",
        "createdAt" : "2020-12-16T03:27:44Z",
        "updatedAt" : "2020-12-16T08:59:38Z",
        "lastEditedBy" : "62055540-2831-4746-af2d-e126c5d7477e",
        "tags" : [
        ]
      },
      {
        "id" : "60463860-aabb-4982-9872-e0606daac740",
        "parentId" : "4e6adafd-4e36-403a-9d17-3d2a2d28eaf5",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "It's better to be explicit for what Spark supports. It's a bit odd that we add no-op syntax.",
        "createdAt" : "2020-12-16T04:07:48Z",
        "updatedAt" : "2020-12-16T08:59:38Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "1842441e-876e-4b8e-b8c7-bd38c5d1e3f5",
        "parentId" : "4e6adafd-4e36-403a-9d17-3d2a2d28eaf5",
        "authorId" : "62055540-2831-4746-af2d-e126c5d7477e",
        "body" : "We have many tasks which are running on hive and slowly, so we want to migrate it from hive to spark. I think other companies want to this too. If we support ignore this exception by set spark.sql.orc.skipRowFormatDelimitedError=true , we can migrate hive task and user do not need to modify his sql script. ",
        "createdAt" : "2020-12-16T08:56:46Z",
        "updatedAt" : "2020-12-16T08:59:38Z",
        "lastEditedBy" : "62055540-2831-4746-af2d-e126c5d7477e",
        "tags" : [
        ]
      },
      {
        "id" : "6bade4c0-0c56-4f8a-84b0-99adb6d88ceb",
        "parentId" : "4e6adafd-4e36-403a-9d17-3d2a2d28eaf5",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Does Hive work with this delimiter specified with ORC?",
        "createdAt" : "2020-12-17T02:17:32Z",
        "updatedAt" : "2020-12-17T02:17:32Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "5db1b8a1-ae8b-4516-8ff5-8b1c5ae12ead",
        "parentId" : "4e6adafd-4e36-403a-9d17-3d2a2d28eaf5",
        "authorId" : "62055540-2831-4746-af2d-e126c5d7477e",
        "body" : "Hive doesn't work with it, but hive doesn't throw exception too.",
        "createdAt" : "2020-12-17T02:36:21Z",
        "updatedAt" : "2020-12-17T02:36:21Z",
        "lastEditedBy" : "62055540-2831-4746-af2d-e126c5d7477e",
        "tags" : [
        ]
      },
      {
        "id" : "19d70096-0f9f-4850-bf37-27f243bf2b83",
        "parentId" : "4e6adafd-4e36-403a-9d17-3d2a2d28eaf5",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Let's don't fix it then. It's odd that Spark works with a syntax that's no-op, and that does not also work in Hive.",
        "createdAt" : "2020-12-28T01:19:36Z",
        "updatedAt" : "2020-12-28T01:19:36Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "00d3b52d-93a2-4e6a-aafe-2b75596f8deb",
        "parentId" : "4e6adafd-4e36-403a-9d17-3d2a2d28eaf5",
        "authorId" : "62055540-2831-4746-af2d-e126c5d7477e",
        "body" : "thx very much, i'll close it.",
        "createdAt" : "2020-12-28T08:04:36Z",
        "updatedAt" : "2020-12-28T08:04:36Z",
        "lastEditedBy" : "62055540-2831-4746-af2d-e126c5d7477e",
        "tags" : [
        ]
      }
    ],
    "commit" : "05fcc631413a98bf0e623b68ea5ddb3ce1ce05d7",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +162,166 @@           |  stringField STRING\n           |)\n           |ROW FORMAT DELIMITED FIELDS TERMINATED BY '002'\n           |STORED AS ORC\n           |LOCATION '${orcTableAsDir.toURI}'"
  },
  {
    "id" : "dc8000a6-672f-49de-ad53-6d0e2d26cc5a",
    "prId" : 30734,
    "prUrl" : "https://github.com/apache/spark/pull/30734#pullrequestreview-552560377",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6ba3069e-9a4a-40dd-b24a-ede150e23e11",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "How does the ORC table wotk with the delimiter?",
        "createdAt" : "2020-12-15T10:18:27Z",
        "updatedAt" : "2020-12-15T10:18:27Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "482a6ee5-4cf1-4545-aef5-df2c81d3a69e",
        "parentId" : "6ba3069e-9a4a-40dd-b24a-ede150e23e11",
        "authorId" : "62055540-2831-4746-af2d-e126c5d7477e",
        "body" : "Sorry for my late reply. I found this problem when migrating task from hive to spark. Hive is supported (It's not good, but it's not a problem, we can ignore it). So I fixed it in version Spark 2.4. Although Orc doesn't need this delimiter, but I don't think we need to be so strict in syntax. It is more convenient to migrate tasks from hive to spark. \r\nI will close this PR and re submit a new PR based on Spark 2.4 https://github.com/apache/spark/pull/30785",
        "createdAt" : "2020-12-15T15:11:33Z",
        "updatedAt" : "2020-12-15T16:20:01Z",
        "lastEditedBy" : "62055540-2831-4746-af2d-e126c5d7477e",
        "tags" : [
        ]
      }
    ],
    "commit" : "bff97e24e3fb63d64e3dff5b05ab481908c882b2",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +336,340 @@           |  stringField STRING\n           |)\n           |ROW FORMAT DELIMITED FIELDS TERMINATED BY '002'\n           |STORED AS ORC\n           |LOCATION '${orcTableAsDir.toURI}'"
  },
  {
    "id" : "1ae3c928-5c19-446e-87a3-651d4936468d",
    "prId" : 28373,
    "prUrl" : "https://github.com/apache/spark/pull/28373#pullrequestreview-401406467",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "af5a3ffd-dba7-41c0-9ac4-415eca57152d",
        "parentId" : null,
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "I haven't seen this before, that's a cool feature :)\r\nThat being said I'm not sure about the version number check here, looking at the related JIRAs https://issues.apache.org/jira/browse/HIVE-22480 & https://issues.apache.org/jira/browse/ORC-569 it seems like it should be fixed earlier? Or is that JIRA wrong?",
        "createdAt" : "2020-04-27T23:22:10Z",
        "updatedAt" : "2020-04-27T23:24:49Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      },
      {
        "id" : "696ac4bd-96a2-4ec7-8a27-ce357770af1a",
        "parentId" : "af5a3ffd-dba7-41c0-9ac4-415eca57152d",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "The Hive JIRA is correct, but all fixed versions in HIVE-22480 are not released officially.\r\n> 1.3.0, 1.2.3, 2.1.2, 2.2.1\r\n\r\n- https://archive.apache.org/dist/hive/\r\n\r\nFrom Hive 2.3.x, Hive starts to use Apache ORC. During the transition, Hive side fix seems to be not migrated to Apache ORC correctly.",
        "createdAt" : "2020-04-27T23:31:10Z",
        "updatedAt" : "2020-04-27T23:34:12Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "becd006b-7547-40a7-bc0e-31adf064051f",
        "parentId" : "af5a3ffd-dba7-41c0-9ac4-415eca57152d",
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "Thanks for the additional context :) Sounds reasonable.",
        "createdAt" : "2020-04-27T23:54:48Z",
        "updatedAt" : "2020-04-27T23:54:48Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      }
    ],
    "commit" : "4e346c7958332e3526332b583386250a4caf4498",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +323,327 @@\n  test(\"SPARK-31580: Read a file written before ORC-569\") {\n    assume(HiveUtils.isHive23) // Hive 1.2 doesn't use Apache ORC\n    // Test ORC file came from ORC-621\n    val df = readResourceOrcFile(\"test-data/TestStringDictionary.testRowIndex.orc\")"
  }
]