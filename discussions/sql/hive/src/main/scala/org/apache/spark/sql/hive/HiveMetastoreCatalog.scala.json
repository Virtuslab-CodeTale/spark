[
  {
    "id" : "da6ab290-2e49-4b26-bced-2905a94419f4",
    "prId" : 26499,
    "prUrl" : "https://github.com/apache/spark/pull/26499#pullrequestreview-316105305",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "eb51e24b-dfa5-4939-aa7a-8e05874dcff6",
        "parentId" : null,
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "Thank you @LantaoJin Could we add a test case?",
        "createdAt" : "2019-11-13T08:58:44Z",
        "updatedAt" : "2019-11-19T03:11:44Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      },
      {
        "id" : "233a406e-c660-47df-a103-5b66581e1f66",
        "parentId" : "eb51e24b-dfa5-4939-aa7a-8e05874dcff6",
        "authorId" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "body" : "`spark.sql.sources.*` can not add in SQL of `CREATE TABLE` in current Spark version. Any other way to go to this invalid code path?",
        "createdAt" : "2019-11-13T09:28:14Z",
        "updatedAt" : "2019-11-19T03:11:44Z",
        "lastEditedBy" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "tags" : [
        ]
      },
      {
        "id" : "9840eb86-f6cc-4b31-924f-dd5acbb5a67f",
        "parentId" : "eb51e24b-dfa5-4939-aa7a-8e05874dcff6",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "`sparkSession.metadataHive.runSqlHive`?\r\nhttps://github.com/apache/spark/blob/96179732aad28418d486de1a365cd5d68c3db910/sql/hive/src/test/scala/org/apache/spark/sql/hive/HiveMetastoreCatalogSuite.scala#L314-L320",
        "createdAt" : "2019-11-13T09:35:01Z",
        "updatedAt" : "2019-11-19T03:11:44Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      }
    ],
    "commit" : "3288ffddf66d0db058dcf7190992f4a0bf49445f",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +271,275 @@          s\"Set ${HiveUtils.CONVERT_METASTORE_PARQUET.key} to false, \" +\n          s\"or recreate table ${relation.tableMeta.identifier} to workaround.\")\n    }\n    val newOutput = result.output.zip(relation.output).map {\n      case (a1, a2) => a1.withExprId(a2.exprId)"
  }
]