[
  {
    "id" : "a6db54d2-24b3-4611-8dba-6fda82d55db5",
    "prId" : 33382,
    "prUrl" : "https://github.com/apache/spark/pull/33382#pullrequestreview-718364227",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "239b7855-b58b-462d-9a64-e297b8bd5818",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This fallback can lead to a huge performance slowdown, or even hang the application (e.g. listing millions of partitions)\r\n\r\nI think we should be very conservative about fallback. Maybe a config to control this is better, instead of looking at the `directSQL` flag.",
        "createdAt" : "2021-07-26T10:39:25Z",
        "updatedAt" : "2021-07-26T10:39:25Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "67654481-014a-4ed9-b3f1-c98a0366a615",
        "parentId" : "239b7855-b58b-462d-9a64-e297b8bd5818",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "@cloud-fan thanks for your input. What do you think of the proposal [here](https://github.com/apache/spark/pull/33382#issuecomment-883134666)? We can introduce a flag `SQLConf.get.metastorePartitionPruningFallbackOnException` which default to false. As result, the code will no longer depend on the directSQL flag (currently when the flag is turned off on the remote HMS, Spark will always fallback to list all partitions).",
        "createdAt" : "2021-07-26T17:14:55Z",
        "updatedAt" : "2021-07-26T17:14:55Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "a53d8b63-00b5-45eb-8c2a-6a16c470b96f",
        "parentId" : "239b7855-b58b-462d-9a64-e297b8bd5818",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "SGTM",
        "createdAt" : "2021-07-27T11:04:04Z",
        "updatedAt" : "2021-07-27T11:04:04Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "394263b5-284d-48dc-95de-aa4ae1374f90",
        "parentId" : "239b7855-b58b-462d-9a64-e297b8bd5818",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "@cloud-fan updated the PR with this approach. Let me know what you think.",
        "createdAt" : "2021-07-29T17:36:50Z",
        "updatedAt" : "2021-07-29T17:36:50Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      }
    ],
    "commit" : "32fc0054a6f71565f9e44d3a542310392ab3bd77",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +894,898 @@              shouldFallback =>\n            logWarning(\"Caught Hive MetaException attempting to get partition metadata by \" +\n              \"filter from Hive. Falling back to fetching all partition metadata, which will \" +\n              \"degrade performance. Modifying your Hive metastore configuration to set \" +\n              s\"${tryDirectSqlConfVar.varname} to true (if it is not true already) may resolve \" +"
  },
  {
    "id" : "eba82253-f147-43fc-8b1d-c136cd259ec9",
    "prId" : 32446,
    "prUrl" : "https://github.com/apache/spark/pull/32446#pullrequestreview-654151027",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "13ca7e80-f7df-455e-9442-07cc567b4601",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "should we make it final? If higher version overrides it accidentally, seems we don't have test to prevent it.",
        "createdAt" : "2021-05-07T06:10:31Z",
        "updatedAt" : "2021-05-07T06:10:31Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "e4f228fe-88ea-4f91-8aa3-a3ee8a01c8f7",
        "parentId" : "13ca7e80-f7df-455e-9442-07cc567b4601",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "Hmm I don't see why ppl would intentionally override this while ignoring the rationale here. On the other hand we might need to override it again in case Hive changes in an incompatible way (say, `Hive.getWithFastCheck` starts to call another newly introduced HMS thrift API).",
        "createdAt" : "2021-05-07T06:56:58Z",
        "updatedAt" : "2021-05-07T06:56:58Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "33dce00a-3e3f-4d68-8f3f-d186492ee774",
        "parentId" : "13ca7e80-f7df-455e-9442-07cc567b4601",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Oh, I thought it may be easily to ignore we have different `getHive` here, when overriding `getHive` on other Shim. If we want to override it again, we at least notice it by compiler error.\r\n\r\nNot strong option, anyway. Okay for me as it is.",
        "createdAt" : "2021-05-07T07:13:40Z",
        "updatedAt" : "2021-05-07T07:13:40Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "88697a43ba63963a1951f8d99a697fab4ca5692f",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +1327,1331 @@  // To mitigate here we use `Hive.getWithFastCheck` instead which skips loading the permanent\n  // functions and therefore avoids calling `get_all_functions`.\n  override def getHive(hiveConf: HiveConf): Hive = Hive.getWithFastCheck(hiveConf, false)\n}\n"
  },
  {
    "id" : "99c33a6e-3a6e-49ce-ab14-bfa136f70d19",
    "prId" : 31646,
    "prUrl" : "https://github.com/apache/spark/pull/31646#pullrequestreview-598610124",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0d67a3bb-e2ce-45f1-8cc9-9b050d6448ec",
        "parentId" : null,
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "More than 10,000 values will cause the Hive Metastore stack overflow.",
        "createdAt" : "2021-02-25T13:14:00Z",
        "updatedAt" : "2021-03-11T09:21:56Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      },
      {
        "id" : "84a364e4-f3a6-4411-9432-d3713673b4d2",
        "parentId" : "0d67a3bb-e2ce-45f1-8cc9-9b050d6448ec",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "How about stoping push it If it's values size exceeds the threshold ? In this case it can not be covert like `>= and <=`.",
        "createdAt" : "2021-02-25T14:17:40Z",
        "updatedAt" : "2021-03-11T09:21:56Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "17aea47f717827f42a12fccc7e5901403f69b323",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +750,754 @@\n    def convertNotInToAnd(name: String, values: Seq[String]): String = {\n      values.map(value => s\"$name != $value\").mkString(\"(\", \" and \", \")\")\n    }\n"
  },
  {
    "id" : "2f0750ce-3704-4409-bfae-1b3a2f5e5af0",
    "prId" : 31646,
    "prUrl" : "https://github.com/apache/spark/pull/31646#pullrequestreview-608251491",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "45f2a0b6-a94b-49c8-8a35-81b63d36cdbe",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "`Not(a IN (null, 2))`: if a = 1, the final result is null.\r\n`a != 2`: if a = 1, the final result is true\r\n\r\nI think this rewrite is incorrect. We need to make sure the values of IN are all not null.\r\n\r\n",
        "createdAt" : "2021-03-09T14:57:32Z",
        "updatedAt" : "2021-03-11T09:21:56Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "acaefbe2-b68e-416d-977a-ea2f732fe272",
        "parentId" : "45f2a0b6-a94b-49c8-8a35-81b63d36cdbe",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "My bad, missed this. For `Not(InSet)` case, null value can not be skip safely, it should convert to `and(xx != null)`.",
        "createdAt" : "2021-03-10T01:19:08Z",
        "updatedAt" : "2021-03-11T12:36:23Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "17aea47f717827f42a12fccc7e5901403f69b323",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +783,787 @@        Some(convertInToOr(name, values))\n\n      case Not(In(ExtractAttribute(SupportedAttribute(name)), ExtractableLiterals(values)))\n        if useAdvanced =>\n        Some(convertNotInToAnd(name, values))"
  },
  {
    "id" : "69da6e49-7516-4dc0-8fd1-55d6a48cf501",
    "prId" : 31632,
    "prUrl" : "https://github.com/apache/spark/pull/31632#pullrequestreview-597138868",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "270cd48f-26ba-4f57-be5d-8d7285db44d4",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Will this change the result of `InSet` which contains null?",
        "createdAt" : "2021-02-24T07:07:40Z",
        "updatedAt" : "2021-02-24T07:17:21Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "adaee6e6-adc2-48b7-ab1c-e4d3848dddb9",
        "parentId" : "270cd48f-26ba-4f57-be5d-8d7285db44d4",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "same question here. The null sematic of IN is pretty tricky.",
        "createdAt" : "2021-02-24T07:12:27Z",
        "updatedAt" : "2021-02-24T07:17:21Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "8d525c4e-0f5f-4b77-b318-75ac8cb5ea5d",
        "parentId" : "270cd48f-26ba-4f57-be5d-8d7285db44d4",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "It's safe, since `In` has already do this.\r\nhttps://github.com/apache/spark/blob/714ff73d4aec317fddf32720d5a7a1c283921983/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveShim.scala#L666-L684",
        "createdAt" : "2021-02-24T07:14:48Z",
        "updatedAt" : "2021-02-24T07:17:21Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "38f798c13414de9b0270caebfaf9c8781698246a",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +772,776 @@        // Skip null here is safe, more details could see at ExtractableLiterals.\n        val sortedValues = values.filter(_ != null).toSeq\n          .sorted(TypeUtils.getInterpretedOrdering(dataType))\n        convert(And(GreaterThanOrEqual(child, Literal(sortedValues.head, dataType)),\n          LessThanOrEqual(child, Literal(sortedValues.last, dataType))))"
  },
  {
    "id" : "621aaac2-6871-4f12-808c-1ece9e7fbea0",
    "prId" : 31632,
    "prUrl" : "https://github.com/apache/spark/pull/31632#pullrequestreview-597139133",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0209550a-3e97-4d2d-a29c-be8b93e82ab8",
        "parentId" : null,
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "Shall we add a similar comment for why this is safe, similar to `IN` - https://github.com/apache/spark/pull/21832 ?",
        "createdAt" : "2021-02-24T07:14:31Z",
        "updatedAt" : "2021-02-24T07:17:21Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      },
      {
        "id" : "a138f041-cbdf-4622-a45a-7982e5f617b4",
        "parentId" : "0209550a-3e97-4d2d-a29c-be8b93e82ab8",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "looks better",
        "createdAt" : "2021-02-24T07:15:17Z",
        "updatedAt" : "2021-02-24T07:17:21Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "38f798c13414de9b0270caebfaf9c8781698246a",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +771,775 @@        val dataType = child.dataType\n        // Skip null here is safe, more details could see at ExtractableLiterals.\n        val sortedValues = values.filter(_ != null).toSeq\n          .sorted(TypeUtils.getInterpretedOrdering(dataType))\n        convert(And(GreaterThanOrEqual(child, Literal(sortedValues.head, dataType)),"
  },
  {
    "id" : "dddcb5b0-767c-4749-b2f9-10525549622e",
    "prId" : 30708,
    "prUrl" : "https://github.com/apache/spark/pull/30708#pullrequestreview-549773270",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ca280bd8-24c3-4e4b-8b9a-aa4ecc706f1b",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Nah .. I don't think this is a right direction in Spark. It's a very big overhead to maintain the list of case Hive function matches, and we should check each behaviour between Spark and Hive.",
        "createdAt" : "2020-12-11T03:16:13Z",
        "updatedAt" : "2020-12-11T03:16:13Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "92eff049ea3882e59c18dd0155d54fddde8c9baf",
    "line" : 137,
    "diffHunk" : "@@ -1,1 +941,945 @@\n      // Prune partition of ConcatWs\n      case op@BinaryComparison(a: ConcatWs, Literal(v, _: StringType)) =>\n        convertUDFExpToPartitions(hive, table, op, a, v.toString)\n      case op@BinaryComparison(Literal(v, _: StringType), a: ConcatWs) =>"
  },
  {
    "id" : "c8fe98a2-9ad5-4cbe-a928-58b51a0d5ba2",
    "prId" : 30535,
    "prUrl" : "https://github.com/apache/spark/pull/30535#pullrequestreview-540658609",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8ec07a98-7deb-4fb3-8e32-54f3f2eea921",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "What if an input str is a special value (e.g., now, today, ...)?",
        "createdAt" : "2020-11-29T09:53:30Z",
        "updatedAt" : "2020-11-30T07:46:06Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "0c7a68cb-85b2-4587-a78f-4802edcd1c1d",
        "parentId" : "8ec07a98-7deb-4fb3-8e32-54f3f2eea921",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "These special values handle by:\r\n\r\nhttps://github.com/apache/spark/blob/6d625ccd5b5a76a149e2070df31984610629a295/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/finishAnalysis.scala#L82-L87\r\n\r\nhttps://github.com/apache/spark/blob/a5e13acd19871831a93a5bdcbc99a9eb9f1aba07/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveShim.scala#L660-L661\r\n",
        "createdAt" : "2020-11-30T07:45:15Z",
        "updatedAt" : "2020-11-30T07:46:06Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      }
    ],
    "commit" : "1e715205ef785e5b362ef003f191371603343016",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +758,762 @@          case Cast(child @ IntegralType(), dt: IntegralType, _)\n              if Cast.canUpCast(child.dataType.asInstanceOf[AtomicType], dt) => unapply(child)\n          case Cast(child @ StringType(), DateType, _) => unapply(child)\n          case _ => None\n        }"
  },
  {
    "id" : "69af5a8c-cc2a-4191-8604-df240a5668e7",
    "prId" : 30408,
    "prUrl" : "https://github.com/apache/spark/pull/30408#pullrequestreview-533451121",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "06a9ab54-dddc-4e41-88a4-439f6b6c95ef",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "why not update `ExtractableValues` to support dateï¼Ÿ",
        "createdAt" : "2020-11-18T12:55:42Z",
        "updatedAt" : "2020-11-25T05:17:09Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "b638d3d2-fd66-403e-8226-678c8bfb1883",
        "parentId" : "06a9ab54-dddc-4e41-88a4-439f6b6c95ef",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "This is because for `InSet` predicate, the `hset`'s value is the int type, we need to use `dateFormatter` to format it, this is the test:\r\nhttps://github.com/apache/spark/blob/ba2f5531601ff169ff0f9fab9bb60627f65082bf/sql/hive/src/test/scala/org/apache/spark/sql/hive/client/HivePartitionFilteringSuite.scala#L339-L342",
        "createdAt" : "2020-11-18T13:36:27Z",
        "updatedAt" : "2020-11-25T05:17:09Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      }
    ],
    "commit" : "29c489ad5f753aaa3551489655073c9f6fc7b0c6",
    "line" : 59,
    "diffHunk" : "@@ -1,1 +710,714 @@    }\n\n    object ExtractableDateValues {\n      private lazy val valueToLiteralString: PartialFunction[Any, String] = {\n        case value: Int => dateFormatter.format(value)"
  },
  {
    "id" : "ea196576-ea0e-4b78-a9e7-45bc61e0f982",
    "prId" : 30408,
    "prUrl" : "https://github.com/apache/spark/pull/30408#pullrequestreview-537093318",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a76a3d42-af15-4a4d-b549-c61c87a7156f",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Why do we need `forall` here? `InSet` can have mixed values: int and other types?",
        "createdAt" : "2020-11-24T02:13:24Z",
        "updatedAt" : "2020-11-25T05:17:09Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "a71eac4b-eacc-4d92-9765-d9b888f4f754",
        "parentId" : "a76a3d42-af15-4a4d-b549-c61c87a7156f",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "Otherwise this test will fail:\r\n```scala\r\n  filterTest(\"string filter with InSet predicate\",\r\n    (InSet(a(\"stringcol\", StringType),\r\n      Range(1, 3).map(d => UTF8String.fromString(d.toString)).toSet)) :: Nil,\r\n    \"(stringcol = \\\"1\\\" or stringcol = \\\"2\\\")\")\r\n```\r\n\r\n```\r\nNone.get\r\njava.util.NoSuchElementException: None.get\r\n\tat scala.None$.get(Option.scala:529)\r\n\tat scala.None$.get(Option.scala:527)\r\n\tat org.apache.spark.sql.hive.client.Shim_v0_13$ExtractableDateValues$1$.$anonfun$unapply$7(HiveShim.scala:720)\r\n\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\r\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\r\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\r\n```",
        "createdAt" : "2020-11-24T05:38:50Z",
        "updatedAt" : "2020-11-25T05:17:09Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      },
      {
        "id" : "0c47ac8c-aea4-43c4-aa2d-4295515be0ca",
        "parentId" : "a76a3d42-af15-4a4d-b549-c61c87a7156f",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ah, ok. Thanks.",
        "createdAt" : "2020-11-24T05:43:44Z",
        "updatedAt" : "2020-11-25T05:17:09Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "29c489ad5f753aaa3551489655073c9f6fc7b0c6",
    "line" : 66,
    "diffHunk" : "@@ -1,1 +717,721 @@      def unapply(values: Set[Any]): Option[Seq[String]] = {\n        val extractables = values.toSeq.map(valueToLiteralString.lift)\n        if (extractables.nonEmpty && extractables.forall(_.isDefined)) {\n          Some(extractables.map(_.get))\n        } else {"
  },
  {
    "id" : "36b0304c-2d88-4f13-b0bb-3d2b50c1b023",
    "prId" : 30383,
    "prUrl" : "https://github.com/apache/spark/pull/30383#pullrequestreview-533081209",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "71ecfc42-6b19-4588-9b9a-8b327a98ac94",
        "parentId" : null,
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "@wangyum Can we add test cases to ensure all the Hive metastore versions support them?",
        "createdAt" : "2020-11-18T03:33:42Z",
        "updatedAt" : "2020-11-18T03:33:42Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      },
      {
        "id" : "1f996fc6-5511-401f-a7a8-8a64f5999bac",
        "parentId" : "71ecfc42-6b19-4588-9b9a-8b327a98ac94",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "It should have been tested from Hive 0.13 to Hive 3.1: https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/131123/testReport/org.apache.spark.sql.hive.client/HivePartitionFilteringSuite/",
        "createdAt" : "2020-11-18T03:38:51Z",
        "updatedAt" : "2020-11-18T03:38:51Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      }
    ],
    "commit" : "9c40971afc3f4872232e518bd528900f5effd858",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +760,764 @@        Some(s\"$name like \" + (value.dropRight(1) + \".*\\\"\"))\n\n      case EndsWith(ExtractAttribute(SupportedAttribute(name)), ExtractableLiteral(value)) =>\n        Some(s\"$name like \" + (\"\\\".*\" + value.drop(1)))\n"
  },
  {
    "id" : "feb706bd-7d22-4545-971f-75e05bd84c60",
    "prId" : 30207,
    "prUrl" : "https://github.com/apache/spark/pull/30207#pullrequestreview-521758087",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8afa9146-08b7-496a-abb2-25cf8b5e0836",
        "parentId" : null,
        "authorId" : "934976a5-cca7-44a7-8578-4c05ccf3cb53",
        "body" : "I don't have an equivalent \"attempt to correct\" for In and Inset, just for binary comparisons. In the case of In and Inset, if the datatypes are not compatible, I just drop the filter (which is what would have happened before SPARK-22384)",
        "createdAt" : "2020-11-02T15:54:05Z",
        "updatedAt" : "2020-11-02T15:54:05Z",
        "lastEditedBy" : "934976a5-cca7-44a7-8578-4c05ccf3cb53",
        "tags" : [
        ]
      }
    ],
    "commit" : "a186127197321f4dd3c52ac69784f44e938c5823",
    "line" : 124,
    "diffHunk" : "@@ -1,1 +786,790 @@        fixValue(rawValue, dt1).map { value =>\n          s\"$name ${op.symbol} $value\"\n        }\n\n      case op @ SpecialBinaryComparison("
  },
  {
    "id" : "0e58e411-4169-4705-a097-688e3fc1d6cc",
    "prId" : 30207,
    "prUrl" : "https://github.com/apache/spark/pull/30207#pullrequestreview-522141722",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "84d72083-0a4b-41d3-ab9f-8d84fad95385",
        "parentId" : null,
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "hmm, will this change semantics? suppose we have `cast(b as string) < '012'` where `b` is 11. Before the conversion this will evaluate to false but after it will evaluate to true.",
        "createdAt" : "2020-11-03T00:58:10Z",
        "updatedAt" : "2020-11-03T01:05:17Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "d966badf-c20e-4e6f-a1c8-0af8591a1f5a",
        "parentId" : "84d72083-0a4b-41d3-ab9f-8d84fad95385",
        "authorId" : "934976a5-cca7-44a7-8578-4c05ccf3cb53",
        "body" : "Yes, it should probably ignore any literal strings with leading zeros.",
        "createdAt" : "2020-11-03T01:18:18Z",
        "updatedAt" : "2020-11-03T01:18:19Z",
        "lastEditedBy" : "934976a5-cca7-44a7-8578-4c05ccf3cb53",
        "tags" : [
        ]
      },
      {
        "id" : "ceadff34-6a81-4c08-962e-c2d1688ec909",
        "parentId" : "84d72083-0a4b-41d3-ab9f-8d84fad95385",
        "authorId" : "934976a5-cca7-44a7-8578-4c05ccf3cb53",
        "body" : ">perhaps we should do it in UnwrapCastInBinaryComparison so that it can not only be used by Hive but also other data sources.\r\n\r\nWhatever makes sense. There is some (long-time) ongoing work with TypeCoercion (#22038) that fixes a few of these cases. But if if that goes through and we can close the gap with the others, that would be fine. I am probably not in a position to provide much help in the optimizer code (at this point).",
        "createdAt" : "2020-11-03T01:26:43Z",
        "updatedAt" : "2020-11-03T01:26:43Z",
        "lastEditedBy" : "934976a5-cca7-44a7-8578-4c05ccf3cb53",
        "tags" : [
        ]
      }
    ],
    "commit" : "a186127197321f4dd3c52ac69784f44e938c5823",
    "line" : 122,
    "diffHunk" : "@@ -1,1 +784,788 @@          ExtractAttribute(SupportedAttribute(name), dt1), ExtractableLiteral(rawValue, dt2))\n          if dt1.isInstanceOf[IntegralType] && dt2.isInstanceOf[StringType] =>\n        fixValue(rawValue, dt1).map { value =>\n          s\"$name ${op.symbol} $value\"\n        }"
  }
]