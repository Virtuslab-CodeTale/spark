[
  {
    "id" : "a6db54d2-24b3-4611-8dba-6fda82d55db5",
    "prId" : 33382,
    "prUrl" : "https://github.com/apache/spark/pull/33382#pullrequestreview-718364227",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "239b7855-b58b-462d-9a64-e297b8bd5818",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This fallback can lead to a huge performance slowdown, or even hang the application (e.g. listing millions of partitions)\r\n\r\nI think we should be very conservative about fallback. Maybe a config to control this is better, instead of looking at the `directSQL` flag.",
        "createdAt" : "2021-07-26T10:39:25Z",
        "updatedAt" : "2021-07-26T10:39:25Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "67654481-014a-4ed9-b3f1-c98a0366a615",
        "parentId" : "239b7855-b58b-462d-9a64-e297b8bd5818",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "@cloud-fan thanks for your input. What do you think of the proposal [here](https://github.com/apache/spark/pull/33382#issuecomment-883134666)? We can introduce a flag `SQLConf.get.metastorePartitionPruningFallbackOnException` which default to false. As result, the code will no longer depend on the directSQL flag (currently when the flag is turned off on the remote HMS, Spark will always fallback to list all partitions).",
        "createdAt" : "2021-07-26T17:14:55Z",
        "updatedAt" : "2021-07-26T17:14:55Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "a53d8b63-00b5-45eb-8c2a-6a16c470b96f",
        "parentId" : "239b7855-b58b-462d-9a64-e297b8bd5818",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "SGTM",
        "createdAt" : "2021-07-27T11:04:04Z",
        "updatedAt" : "2021-07-27T11:04:04Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "394263b5-284d-48dc-95de-aa4ae1374f90",
        "parentId" : "239b7855-b58b-462d-9a64-e297b8bd5818",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "@cloud-fan updated the PR with this approach. Let me know what you think.",
        "createdAt" : "2021-07-29T17:36:50Z",
        "updatedAt" : "2021-07-29T17:36:50Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      }
    ],
    "commit" : "32fc0054a6f71565f9e44d3a542310392ab3bd77",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +894,898 @@              shouldFallback =>\n            logWarning(\"Caught Hive MetaException attempting to get partition metadata by \" +\n              \"filter from Hive. Falling back to fetching all partition metadata, which will \" +\n              \"degrade performance. Modifying your Hive metastore configuration to set \" +\n              s\"${tryDirectSqlConfVar.varname} to true (if it is not true already) may resolve \" +"
  },
  {
    "id" : "eba82253-f147-43fc-8b1d-c136cd259ec9",
    "prId" : 32446,
    "prUrl" : "https://github.com/apache/spark/pull/32446#pullrequestreview-654151027",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "13ca7e80-f7df-455e-9442-07cc567b4601",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "should we make it final? If higher version overrides it accidentally, seems we don't have test to prevent it.",
        "createdAt" : "2021-05-07T06:10:31Z",
        "updatedAt" : "2021-05-07T06:10:31Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "e4f228fe-88ea-4f91-8aa3-a3ee8a01c8f7",
        "parentId" : "13ca7e80-f7df-455e-9442-07cc567b4601",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "Hmm I don't see why ppl would intentionally override this while ignoring the rationale here. On the other hand we might need to override it again in case Hive changes in an incompatible way (say, `Hive.getWithFastCheck` starts to call another newly introduced HMS thrift API).",
        "createdAt" : "2021-05-07T06:56:58Z",
        "updatedAt" : "2021-05-07T06:56:58Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "33dce00a-3e3f-4d68-8f3f-d186492ee774",
        "parentId" : "13ca7e80-f7df-455e-9442-07cc567b4601",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Oh, I thought it may be easily to ignore we have different `getHive` here, when overriding `getHive` on other Shim. If we want to override it again, we at least notice it by compiler error.\r\n\r\nNot strong option, anyway. Okay for me as it is.",
        "createdAt" : "2021-05-07T07:13:40Z",
        "updatedAt" : "2021-05-07T07:13:40Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "88697a43ba63963a1951f8d99a697fab4ca5692f",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +1327,1331 @@  // To mitigate here we use `Hive.getWithFastCheck` instead which skips loading the permanent\n  // functions and therefore avoids calling `get_all_functions`.\n  override def getHive(hiveConf: HiveConf): Hive = Hive.getWithFastCheck(hiveConf, false)\n}\n"
  },
  {
    "id" : "99c33a6e-3a6e-49ce-ab14-bfa136f70d19",
    "prId" : 31646,
    "prUrl" : "https://github.com/apache/spark/pull/31646#pullrequestreview-598610124",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0d67a3bb-e2ce-45f1-8cc9-9b050d6448ec",
        "parentId" : null,
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "More than 10,000 values will cause the Hive Metastore stack overflow.",
        "createdAt" : "2021-02-25T13:14:00Z",
        "updatedAt" : "2021-03-11T09:21:56Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      },
      {
        "id" : "84a364e4-f3a6-4411-9432-d3713673b4d2",
        "parentId" : "0d67a3bb-e2ce-45f1-8cc9-9b050d6448ec",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "How about stoping push it If it's values size exceeds the threshold ? In this case it can not be covert like `>= and <=`.",
        "createdAt" : "2021-02-25T14:17:40Z",
        "updatedAt" : "2021-03-11T09:21:56Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "17aea47f717827f42a12fccc7e5901403f69b323",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +750,754 @@\n    def convertNotInToAnd(name: String, values: Seq[String]): String = {\n      values.map(value => s\"$name != $value\").mkString(\"(\", \" and \", \")\")\n    }\n"
  },
  {
    "id" : "2f0750ce-3704-4409-bfae-1b3a2f5e5af0",
    "prId" : 31646,
    "prUrl" : "https://github.com/apache/spark/pull/31646#pullrequestreview-608251491",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "45f2a0b6-a94b-49c8-8a35-81b63d36cdbe",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "`Not(a IN (null, 2))`: if a = 1, the final result is null.\r\n`a != 2`: if a = 1, the final result is true\r\n\r\nI think this rewrite is incorrect. We need to make sure the values of IN are all not null.\r\n\r\n",
        "createdAt" : "2021-03-09T14:57:32Z",
        "updatedAt" : "2021-03-11T09:21:56Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "acaefbe2-b68e-416d-977a-ea2f732fe272",
        "parentId" : "45f2a0b6-a94b-49c8-8a35-81b63d36cdbe",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "My bad, missed this. For `Not(InSet)` case, null value can not be skip safely, it should convert to `and(xx != null)`.",
        "createdAt" : "2021-03-10T01:19:08Z",
        "updatedAt" : "2021-03-11T12:36:23Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "17aea47f717827f42a12fccc7e5901403f69b323",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +783,787 @@        Some(convertInToOr(name, values))\n\n      case Not(In(ExtractAttribute(SupportedAttribute(name)), ExtractableLiterals(values)))\n        if useAdvanced =>\n        Some(convertNotInToAnd(name, values))"
  },
  {
    "id" : "69da6e49-7516-4dc0-8fd1-55d6a48cf501",
    "prId" : 31632,
    "prUrl" : "https://github.com/apache/spark/pull/31632#pullrequestreview-597138868",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "270cd48f-26ba-4f57-be5d-8d7285db44d4",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Will this change the result of `InSet` which contains null?",
        "createdAt" : "2021-02-24T07:07:40Z",
        "updatedAt" : "2021-02-24T07:17:21Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "adaee6e6-adc2-48b7-ab1c-e4d3848dddb9",
        "parentId" : "270cd48f-26ba-4f57-be5d-8d7285db44d4",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "same question here. The null sematic of IN is pretty tricky.",
        "createdAt" : "2021-02-24T07:12:27Z",
        "updatedAt" : "2021-02-24T07:17:21Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "8d525c4e-0f5f-4b77-b318-75ac8cb5ea5d",
        "parentId" : "270cd48f-26ba-4f57-be5d-8d7285db44d4",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "It's safe, since `In` has already do this.\r\nhttps://github.com/apache/spark/blob/714ff73d4aec317fddf32720d5a7a1c283921983/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveShim.scala#L666-L684",
        "createdAt" : "2021-02-24T07:14:48Z",
        "updatedAt" : "2021-02-24T07:17:21Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "38f798c13414de9b0270caebfaf9c8781698246a",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +772,776 @@        // Skip null here is safe, more details could see at ExtractableLiterals.\n        val sortedValues = values.filter(_ != null).toSeq\n          .sorted(TypeUtils.getInterpretedOrdering(dataType))\n        convert(And(GreaterThanOrEqual(child, Literal(sortedValues.head, dataType)),\n          LessThanOrEqual(child, Literal(sortedValues.last, dataType))))"
  },
  {
    "id" : "621aaac2-6871-4f12-808c-1ece9e7fbea0",
    "prId" : 31632,
    "prUrl" : "https://github.com/apache/spark/pull/31632#pullrequestreview-597139133",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0209550a-3e97-4d2d-a29c-be8b93e82ab8",
        "parentId" : null,
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "Shall we add a similar comment for why this is safe, similar to `IN` - https://github.com/apache/spark/pull/21832 ?",
        "createdAt" : "2021-02-24T07:14:31Z",
        "updatedAt" : "2021-02-24T07:17:21Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      },
      {
        "id" : "a138f041-cbdf-4622-a45a-7982e5f617b4",
        "parentId" : "0209550a-3e97-4d2d-a29c-be8b93e82ab8",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "looks better",
        "createdAt" : "2021-02-24T07:15:17Z",
        "updatedAt" : "2021-02-24T07:17:21Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "38f798c13414de9b0270caebfaf9c8781698246a",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +771,775 @@        val dataType = child.dataType\n        // Skip null here is safe, more details could see at ExtractableLiterals.\n        val sortedValues = values.filter(_ != null).toSeq\n          .sorted(TypeUtils.getInterpretedOrdering(dataType))\n        convert(And(GreaterThanOrEqual(child, Literal(sortedValues.head, dataType)),"
  },
  {
    "id" : "dddcb5b0-767c-4749-b2f9-10525549622e",
    "prId" : 30708,
    "prUrl" : "https://github.com/apache/spark/pull/30708#pullrequestreview-549773270",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ca280bd8-24c3-4e4b-8b9a-aa4ecc706f1b",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Nah .. I don't think this is a right direction in Spark. It's a very big overhead to maintain the list of case Hive function matches, and we should check each behaviour between Spark and Hive.",
        "createdAt" : "2020-12-11T03:16:13Z",
        "updatedAt" : "2020-12-11T03:16:13Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "92eff049ea3882e59c18dd0155d54fddde8c9baf",
    "line" : 137,
    "diffHunk" : "@@ -1,1 +941,945 @@\n      // Prune partition of ConcatWs\n      case op@BinaryComparison(a: ConcatWs, Literal(v, _: StringType)) =>\n        convertUDFExpToPartitions(hive, table, op, a, v.toString)\n      case op@BinaryComparison(Literal(v, _: StringType), a: ConcatWs) =>"
  },
  {
    "id" : "c8fe98a2-9ad5-4cbe-a928-58b51a0d5ba2",
    "prId" : 30535,
    "prUrl" : "https://github.com/apache/spark/pull/30535#pullrequestreview-540658609",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8ec07a98-7deb-4fb3-8e32-54f3f2eea921",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "What if an input str is a special value (e.g., now, today, ...)?",
        "createdAt" : "2020-11-29T09:53:30Z",
        "updatedAt" : "2020-11-30T07:46:06Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "0c7a68cb-85b2-4587-a78f-4802edcd1c1d",
        "parentId" : "8ec07a98-7deb-4fb3-8e32-54f3f2eea921",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "These special values handle by:\r\n\r\nhttps://github.com/apache/spark/blob/6d625ccd5b5a76a149e2070df31984610629a295/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/finishAnalysis.scala#L82-L87\r\n\r\nhttps://github.com/apache/spark/blob/a5e13acd19871831a93a5bdcbc99a9eb9f1aba07/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveShim.scala#L660-L661\r\n",
        "createdAt" : "2020-11-30T07:45:15Z",
        "updatedAt" : "2020-11-30T07:46:06Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      }
    ],
    "commit" : "1e715205ef785e5b362ef003f191371603343016",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +758,762 @@          case Cast(child @ IntegralType(), dt: IntegralType, _)\n              if Cast.canUpCast(child.dataType.asInstanceOf[AtomicType], dt) => unapply(child)\n          case Cast(child @ StringType(), DateType, _) => unapply(child)\n          case _ => None\n        }"
  },
  {
    "id" : "69af5a8c-cc2a-4191-8604-df240a5668e7",
    "prId" : 30408,
    "prUrl" : "https://github.com/apache/spark/pull/30408#pullrequestreview-533451121",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "06a9ab54-dddc-4e41-88a4-439f6b6c95ef",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "why not update `ExtractableValues` to support dateï¼Ÿ",
        "createdAt" : "2020-11-18T12:55:42Z",
        "updatedAt" : "2020-11-25T05:17:09Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "b638d3d2-fd66-403e-8226-678c8bfb1883",
        "parentId" : "06a9ab54-dddc-4e41-88a4-439f6b6c95ef",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "This is because for `InSet` predicate, the `hset`'s value is the int type, we need to use `dateFormatter` to format it, this is the test:\r\nhttps://github.com/apache/spark/blob/ba2f5531601ff169ff0f9fab9bb60627f65082bf/sql/hive/src/test/scala/org/apache/spark/sql/hive/client/HivePartitionFilteringSuite.scala#L339-L342",
        "createdAt" : "2020-11-18T13:36:27Z",
        "updatedAt" : "2020-11-25T05:17:09Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      }
    ],
    "commit" : "29c489ad5f753aaa3551489655073c9f6fc7b0c6",
    "line" : 59,
    "diffHunk" : "@@ -1,1 +710,714 @@    }\n\n    object ExtractableDateValues {\n      private lazy val valueToLiteralString: PartialFunction[Any, String] = {\n        case value: Int => dateFormatter.format(value)"
  },
  {
    "id" : "ea196576-ea0e-4b78-a9e7-45bc61e0f982",
    "prId" : 30408,
    "prUrl" : "https://github.com/apache/spark/pull/30408#pullrequestreview-537093318",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a76a3d42-af15-4a4d-b549-c61c87a7156f",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Why do we need `forall` here? `InSet` can have mixed values: int and other types?",
        "createdAt" : "2020-11-24T02:13:24Z",
        "updatedAt" : "2020-11-25T05:17:09Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "a71eac4b-eacc-4d92-9765-d9b888f4f754",
        "parentId" : "a76a3d42-af15-4a4d-b549-c61c87a7156f",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "Otherwise this test will fail:\r\n```scala\r\n  filterTest(\"string filter with InSet predicate\",\r\n    (InSet(a(\"stringcol\", StringType),\r\n      Range(1, 3).map(d => UTF8String.fromString(d.toString)).toSet)) :: Nil,\r\n    \"(stringcol = \\\"1\\\" or stringcol = \\\"2\\\")\")\r\n```\r\n\r\n```\r\nNone.get\r\njava.util.NoSuchElementException: None.get\r\n\tat scala.None$.get(Option.scala:529)\r\n\tat scala.None$.get(Option.scala:527)\r\n\tat org.apache.spark.sql.hive.client.Shim_v0_13$ExtractableDateValues$1$.$anonfun$unapply$7(HiveShim.scala:720)\r\n\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238)\r\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\r\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\r\n```",
        "createdAt" : "2020-11-24T05:38:50Z",
        "updatedAt" : "2020-11-25T05:17:09Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      },
      {
        "id" : "0c47ac8c-aea4-43c4-aa2d-4295515be0ca",
        "parentId" : "a76a3d42-af15-4a4d-b549-c61c87a7156f",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ah, ok. Thanks.",
        "createdAt" : "2020-11-24T05:43:44Z",
        "updatedAt" : "2020-11-25T05:17:09Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "29c489ad5f753aaa3551489655073c9f6fc7b0c6",
    "line" : 66,
    "diffHunk" : "@@ -1,1 +717,721 @@      def unapply(values: Set[Any]): Option[Seq[String]] = {\n        val extractables = values.toSeq.map(valueToLiteralString.lift)\n        if (extractables.nonEmpty && extractables.forall(_.isDefined)) {\n          Some(extractables.map(_.get))\n        } else {"
  },
  {
    "id" : "36b0304c-2d88-4f13-b0bb-3d2b50c1b023",
    "prId" : 30383,
    "prUrl" : "https://github.com/apache/spark/pull/30383#pullrequestreview-533081209",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "71ecfc42-6b19-4588-9b9a-8b327a98ac94",
        "parentId" : null,
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "@wangyum Can we add test cases to ensure all the Hive metastore versions support them?",
        "createdAt" : "2020-11-18T03:33:42Z",
        "updatedAt" : "2020-11-18T03:33:42Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      },
      {
        "id" : "1f996fc6-5511-401f-a7a8-8a64f5999bac",
        "parentId" : "71ecfc42-6b19-4588-9b9a-8b327a98ac94",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "It should have been tested from Hive 0.13 to Hive 3.1: https://amplab.cs.berkeley.edu/jenkins/job/SparkPullRequestBuilder/131123/testReport/org.apache.spark.sql.hive.client/HivePartitionFilteringSuite/",
        "createdAt" : "2020-11-18T03:38:51Z",
        "updatedAt" : "2020-11-18T03:38:51Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      }
    ],
    "commit" : "9c40971afc3f4872232e518bd528900f5effd858",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +760,764 @@        Some(s\"$name like \" + (value.dropRight(1) + \".*\\\"\"))\n\n      case EndsWith(ExtractAttribute(SupportedAttribute(name)), ExtractableLiteral(value)) =>\n        Some(s\"$name like \" + (\"\\\".*\" + value.drop(1)))\n"
  },
  {
    "id" : "feb706bd-7d22-4545-971f-75e05bd84c60",
    "prId" : 30207,
    "prUrl" : "https://github.com/apache/spark/pull/30207#pullrequestreview-521758087",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8afa9146-08b7-496a-abb2-25cf8b5e0836",
        "parentId" : null,
        "authorId" : "934976a5-cca7-44a7-8578-4c05ccf3cb53",
        "body" : "I don't have an equivalent \"attempt to correct\" for In and Inset, just for binary comparisons. In the case of In and Inset, if the datatypes are not compatible, I just drop the filter (which is what would have happened before SPARK-22384)",
        "createdAt" : "2020-11-02T15:54:05Z",
        "updatedAt" : "2020-11-02T15:54:05Z",
        "lastEditedBy" : "934976a5-cca7-44a7-8578-4c05ccf3cb53",
        "tags" : [
        ]
      }
    ],
    "commit" : "a186127197321f4dd3c52ac69784f44e938c5823",
    "line" : 124,
    "diffHunk" : "@@ -1,1 +786,790 @@        fixValue(rawValue, dt1).map { value =>\n          s\"$name ${op.symbol} $value\"\n        }\n\n      case op @ SpecialBinaryComparison("
  },
  {
    "id" : "0e58e411-4169-4705-a097-688e3fc1d6cc",
    "prId" : 30207,
    "prUrl" : "https://github.com/apache/spark/pull/30207#pullrequestreview-522141722",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "84d72083-0a4b-41d3-ab9f-8d84fad95385",
        "parentId" : null,
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "hmm, will this change semantics? suppose we have `cast(b as string) < '012'` where `b` is 11. Before the conversion this will evaluate to false but after it will evaluate to true.",
        "createdAt" : "2020-11-03T00:58:10Z",
        "updatedAt" : "2020-11-03T01:05:17Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "d966badf-c20e-4e6f-a1c8-0af8591a1f5a",
        "parentId" : "84d72083-0a4b-41d3-ab9f-8d84fad95385",
        "authorId" : "934976a5-cca7-44a7-8578-4c05ccf3cb53",
        "body" : "Yes, it should probably ignore any literal strings with leading zeros.",
        "createdAt" : "2020-11-03T01:18:18Z",
        "updatedAt" : "2020-11-03T01:18:19Z",
        "lastEditedBy" : "934976a5-cca7-44a7-8578-4c05ccf3cb53",
        "tags" : [
        ]
      },
      {
        "id" : "ceadff34-6a81-4c08-962e-c2d1688ec909",
        "parentId" : "84d72083-0a4b-41d3-ab9f-8d84fad95385",
        "authorId" : "934976a5-cca7-44a7-8578-4c05ccf3cb53",
        "body" : ">perhaps we should do it in UnwrapCastInBinaryComparison so that it can not only be used by Hive but also other data sources.\r\n\r\nWhatever makes sense. There is some (long-time) ongoing work with TypeCoercion (#22038) that fixes a few of these cases. But if if that goes through and we can close the gap with the others, that would be fine. I am probably not in a position to provide much help in the optimizer code (at this point).",
        "createdAt" : "2020-11-03T01:26:43Z",
        "updatedAt" : "2020-11-03T01:26:43Z",
        "lastEditedBy" : "934976a5-cca7-44a7-8578-4c05ccf3cb53",
        "tags" : [
        ]
      }
    ],
    "commit" : "a186127197321f4dd3c52ac69784f44e938c5823",
    "line" : 122,
    "diffHunk" : "@@ -1,1 +784,788 @@          ExtractAttribute(SupportedAttribute(name), dt1), ExtractableLiteral(rawValue, dt2))\n          if dt1.isInstanceOf[IntegralType] && dt2.isInstanceOf[StringType] =>\n        fixValue(rawValue, dt1).map { value =>\n          s\"$name ${op.symbol} $value\"\n        }"
  },
  {
    "id" : "fe55e4d9-490a-43fb-ad0b-08586ac1d171",
    "prId" : 29649,
    "prUrl" : "https://github.com/apache/spark/pull/29649#pullrequestreview-483109769",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "656c8706-1b77-4a7b-b1f6-3a99cf7c321a",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "What if a different database has the same name of table?",
        "createdAt" : "2020-09-06T00:43:20Z",
        "updatedAt" : "2020-09-06T00:43:20Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "d5b64025-092a-4212-9fef-065efe27eb0d",
        "parentId" : "656c8706-1b77-4a7b-b1f6-3a99cf7c321a",
        "authorId" : "f2e3e1f3-82a3-4b68-a0c2-2f7fdf58cf35",
        "body" : "This should not be a problem, reason as per below\r\n\r\nSpark prefixes the database name to the table name, so hive can resolve the database from tablename\r\n\r\n**Spark Code** https://github.com/apache/spark/blob/master/sql/hive/src/main/scala/org/apache/spark/sql/hive/client/HiveClientImpl.scala#L855-L873\r\n\r\n![image](https://user-images.githubusercontent.com/35216143/92318002-31032500-f024-11ea-80eb-ad38db0f9a05.png)\r\n\r\n**Hive Code**\r\n\r\n![image](https://user-images.githubusercontent.com/35216143/92318067-b1c22100-f024-11ea-84b9-636f08176d15.png)\r\n\r\nhttps://github.com/apache/hive/blob/rel/release-3.1.0/ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java#L2145-L2169\r\n\r\n![image](https://user-images.githubusercontent.com/35216143/92318098-0ebdd700-f025-11ea-89f7-da8d45893d7c.png)\r\n\r\n\r\nP.S : Above mentioned logic is already working with Hive-2.1 support",
        "createdAt" : "2020-09-06T04:12:33Z",
        "updatedAt" : "2020-09-06T04:12:34Z",
        "lastEditedBy" : "f2e3e1f3-82a3-4b68-a0c2-2f7fdf58cf35",
        "tags" : [
        ]
      }
    ],
    "commit" : "8d45542e915bea1b321f42988b407091065a2539",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +1330,1334 @@    val session = SparkSession.getActiveSession\n    assert(session.nonEmpty)\n    val table = hive.getTable(tableName)\n    val loadFileType = if (replace) {\n      clazzLoadFileType.getEnumConstants.find(_.toString.equalsIgnoreCase(\"REPLACE_ALL\"))"
  },
  {
    "id" : "9b465b8a-9cc9-46fe-8242-07d246c5c4ab",
    "prId" : 29649,
    "prUrl" : "https://github.com/apache/spark/pull/29649#pullrequestreview-483249799",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "95f29c98-e41a-4649-8792-a402ea7f1779",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "just for curiosity, why can't we use `hive.getTable(dbName, tblName)` here? It looks weird that the `loadPartition` method in `HiveShim` takes a single `tableName` parameter which is a qualified name.",
        "createdAt" : "2020-09-07T04:59:04Z",
        "updatedAt" : "2020-09-07T04:59:05Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "88cdf728-7f91-4986-87fa-ce10794f19b7",
        "parentId" : "95f29c98-e41a-4649-8792-a402ea7f1779",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "We can use. The problem is when we get the `database` here from `session.get.sessionState.catalog.getCurrentDatabase `.",
        "createdAt" : "2020-09-07T05:01:21Z",
        "updatedAt" : "2020-09-07T05:01:22Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "613a748b-b360-4285-86ce-b6d7ffa622d3",
        "parentId" : "95f29c98-e41a-4649-8792-a402ea7f1779",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "If the question is why `Shim.loadPartition` doesn't take database as an argument, yes I think we can change to take. But looks like it's to match with `Hive.loadPartition`'s signature.",
        "createdAt" : "2020-09-07T05:13:36Z",
        "updatedAt" : "2020-09-07T05:13:36Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "4f21183a-289e-48e7-b0d6-9f42cacd87a2",
        "parentId" : "95f29c98-e41a-4649-8792-a402ea7f1779",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "The `Hive.loadPartition` API we are using here takes a `Table` instance as a parameter, not a single table name.",
        "createdAt" : "2020-09-07T05:16:32Z",
        "updatedAt" : "2020-09-07T05:16:32Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "c3616745-b385-4e4e-81b0-580634d8a31c",
        "parentId" : "95f29c98-e41a-4649-8792-a402ea7f1779",
        "authorId" : "f2e3e1f3-82a3-4b68-a0c2-2f7fdf58cf35",
        "body" : "`Hive.loadPartition` for Hive-3.1.x it takes `Table`, but other Hive version such as 2.1.x takes `tablename` as `string`\r\n\r\nHive-3.1.0\r\n```\r\n  public Partition loadPartition(Path loadPath, Table tbl, Map<String, String> partSpec,\r\n      LoadFileType loadFileType, boolean inheritTableSpecs, boolean isSkewedStoreAsSubdir,\r\n      boolean isSrcLocal, boolean isAcidIUDoperation, boolean hasFollowingStatsTask, Long writeId,\r\n      int stmtId, boolean isInsertOverwrite)\r\n```\r\n\r\nHive-2.1.0\r\n\r\n```\r\n  public void loadPartition(Path loadPath, String tableName,\r\n      Map<String, String> partSpec, boolean replace,\r\n      boolean inheritTableSpecs, boolean isSkewedStoreAsSubdir,\r\n      boolean isSrcLocal, boolean isAcid, boolean hasFollowingStatsTask)\r\n```",
        "createdAt" : "2020-09-07T05:22:06Z",
        "updatedAt" : "2020-09-07T05:22:06Z",
        "lastEditedBy" : "f2e3e1f3-82a3-4b68-a0c2-2f7fdf58cf35",
        "tags" : [
        ]
      },
      {
        "id" : "dde4d59e-66f5-4ab0-9c6a-9e1ed0598a5e",
        "parentId" : "95f29c98-e41a-4649-8792-a402ea7f1779",
        "authorId" : "f2e3e1f3-82a3-4b68-a0c2-2f7fdf58cf35",
        "body" : "> If the question is why `Shim.loadPartition` doesn't take database as an argument, yes I think we can change to take. But looks like it's to match with `Hive.loadPartition`'s signature.\r\n\r\n+1 for this ,  I will update the API signature to take the database name",
        "createdAt" : "2020-09-07T05:27:10Z",
        "updatedAt" : "2020-09-07T05:27:11Z",
        "lastEditedBy" : "f2e3e1f3-82a3-4b68-a0c2-2f7fdf58cf35",
        "tags" : [
        ]
      },
      {
        "id" : "b075d1ff-35e8-4af0-a936-64cb6d19c32d",
        "parentId" : "95f29c98-e41a-4649-8792-a402ea7f1779",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "I think it's okay to don't change at least in this PR since this PR will likely be ported back. Minimised change here looks good.",
        "createdAt" : "2020-09-07T05:28:46Z",
        "updatedAt" : "2020-09-07T05:28:47Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "8d45542e915bea1b321f42988b407091065a2539",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +1330,1334 @@    val session = SparkSession.getActiveSession\n    assert(session.nonEmpty)\n    val table = hive.getTable(tableName)\n    val loadFileType = if (replace) {\n      clazzLoadFileType.getEnumConstants.find(_.toString.equalsIgnoreCase(\"REPLACE_ALL\"))"
  },
  {
    "id" : "1060eca6-bfeb-4645-899d-b0893fc92d67",
    "prId" : 29649,
    "prUrl" : "https://github.com/apache/spark/pull/29649#pullrequestreview-487206335",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "122dc639-894a-4076-baf1-c0e65562b549",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "In this case, it seems that we can remove the above two lines together, doesn't it?",
        "createdAt" : "2020-09-11T15:59:18Z",
        "updatedAt" : "2020-09-11T15:59:19Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "1df6f0ee-ed0b-4d59-b8e4-fdcbae71cabb",
        "parentId" : "122dc639-894a-4076-baf1-c0e65562b549",
        "authorId" : "f2e3e1f3-82a3-4b68-a0c2-2f7fdf58cf35",
        "body" : "Ah!! sorry, I missed that will raise follow-up",
        "createdAt" : "2020-09-12T05:38:05Z",
        "updatedAt" : "2020-09-12T05:38:05Z",
        "lastEditedBy" : "f2e3e1f3-82a3-4b68-a0c2-2f7fdf58cf35",
        "tags" : [
        ]
      },
      {
        "id" : "61967174-dafd-4f2c-9bbe-e7736914cde0",
        "parentId" : "122dc639-894a-4076-baf1-c0e65562b549",
        "authorId" : "f2e3e1f3-82a3-4b68-a0c2-2f7fdf58cf35",
        "body" : "I raised the follow-up PR  [29736](https://github.com/apache/spark/pull/29736). Sorry for the trouble",
        "createdAt" : "2020-09-12T05:47:33Z",
        "updatedAt" : "2020-09-12T05:47:33Z",
        "lastEditedBy" : "f2e3e1f3-82a3-4b68-a0c2-2f7fdf58cf35",
        "tags" : [
        ]
      }
    ],
    "commit" : "8d45542e915bea1b321f42988b407091065a2539",
    "line" : 3,
    "diffHunk" : "@@ -1,1 +1329,1333 @@      isSrcLocal: Boolean): Unit = {\n    val session = SparkSession.getActiveSession\n    assert(session.nonEmpty)\n    val table = hive.getTable(tableName)\n    val loadFileType = if (replace) {"
  },
  {
    "id" : "4bce5c8b-46c7-465e-8cf3-37af4e8ac83b",
    "prId" : 27952,
    "prUrl" : "https://github.com/apache/spark/pull/27952#pullrequestreview-378247182",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ca0768df-7946-41b4-95b5-151bfb4b1b07",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "@Eric5553, do you mean we'll support `SHOW VIEWS` only with Hive 2.3 in Spark side?",
        "createdAt" : "2020-03-19T03:03:55Z",
        "updatedAt" : "2020-03-20T17:28:22Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "48ac9399-0ba3-4308-a3cd-6122c3c76543",
        "parentId" : "ca0768df-7946-41b4-95b5-151bfb4b1b07",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Okay, so it's still possible to look up via `listTables`. Can you fix the PR description? seems not it's a precondition but just for better performance",
        "createdAt" : "2020-03-19T03:08:24Z",
        "updatedAt" : "2020-03-20T17:28:22Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "397499fe-d11f-44ee-b736-dea9ed16a365",
        "parentId" : "ca0768df-7946-41b4-95b5-151bfb4b1b07",
        "authorId" : "c48b13f0-9ce5-4910-a8eb-aee1ac73ffcb",
        "body" : "As @cloud-fan suggested in https://github.com/apache/spark/pull/27897#discussion_r394391663, for versions before Hive 2.3, I'll implement the fallback solution using `listTables` and filter the result in PR https://github.com/apache/spark/pull/27897.\r\nThanks for the review! @HyukjinKwon ",
        "createdAt" : "2020-03-19T03:08:29Z",
        "updatedAt" : "2020-03-20T17:28:22Z",
        "lastEditedBy" : "c48b13f0-9ce5-4910-a8eb-aee1ac73ffcb",
        "tags" : [
        ]
      },
      {
        "id" : "028b5564-4800-4b14-ad5e-f5d3b7be66f1",
        "parentId" : "ca0768df-7946-41b4-95b5-151bfb4b1b07",
        "authorId" : "c48b13f0-9ce5-4910-a8eb-aee1ac73ffcb",
        "body" : "Sure, that's a mismatch. Updated the description, thanks :-)",
        "createdAt" : "2020-03-19T03:15:41Z",
        "updatedAt" : "2020-03-20T17:28:22Z",
        "lastEditedBy" : "c48b13f0-9ce5-4910-a8eb-aee1ac73ffcb",
        "tags" : [
        ]
      },
      {
        "id" : "517ac580-d4bd-428d-aeb4-bd008f9ad50f",
        "parentId" : "ca0768df-7946-41b4-95b5-151bfb4b1b07",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Can't we do the fallback here? It's better to make the low-level API completed, e.g. `getTablesByType` always sucess, but may be optimized with Hive 2.3+ ",
        "createdAt" : "2020-03-19T06:16:11Z",
        "updatedAt" : "2020-03-20T17:28:22Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "55b762a8-3836-47f9-8bdc-e157add36876",
        "parentId" : "ca0768df-7946-41b4-95b5-151bfb4b1b07",
        "authorId" : "c48b13f0-9ce5-4910-a8eb-aee1ac73ffcb",
        "body" : "Previously I thought `HiveShim` is a thin layer close to Hive API. Yea, it should be better if we handle it in low-level API. I'll make the change here.",
        "createdAt" : "2020-03-19T06:32:56Z",
        "updatedAt" : "2020-03-20T17:28:22Z",
        "lastEditedBy" : "c48b13f0-9ce5-4910-a8eb-aee1ac73ffcb",
        "tags" : [
        ]
      },
      {
        "id" : "590c86f3-4c9c-4d0e-b235-ab1ef5e10f6c",
        "parentId" : "ca0768df-7946-41b4-95b5-151bfb4b1b07",
        "authorId" : "c48b13f0-9ce5-4910-a8eb-aee1ac73ffcb",
        "body" : "The fallback logic needs to call `HiveClient.getTablesByName`, which got a lot of logic in `HiveClient`. Thus I think it needs to handle the fallback logic in `HiveClient` instead of `HiveShim`. 0a550b17ff24e43144d841ac449b510ef1c297cf WDYT @maropu @cloud-fan @HyukjinKwon , thanks!\r\n\r\nAlso I renamed the `HiveClient.listViews` API to `HiveClient.listTablesByType` to provide a more common interface.",
        "createdAt" : "2020-03-19T14:14:19Z",
        "updatedAt" : "2020-03-20T17:28:22Z",
        "lastEditedBy" : "c48b13f0-9ce5-4910-a8eb-aee1ac73ffcb",
        "tags" : [
        ]
      },
      {
        "id" : "887a6e12-0ce2-41f9-ae63-5d822e2cc69f",
        "parentId" : "ca0768df-7946-41b4-95b5-151bfb4b1b07",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "We had better keep this `HiveShim` layer simple. +1 for @Eric5553 's suggestion to implement the fallback in `HiveClientImpl` layer.\r\n\r\ncc @gatorsmile ",
        "createdAt" : "2020-03-20T06:02:30Z",
        "updatedAt" : "2020-03-20T17:28:22Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "ff3777faf81079fb7a5f66c84037b3121f8a846a",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +377,381 @@      tableType: TableType): Seq[String] = {\n    throw new UnsupportedOperationException(\"Hive 2.2 and lower versions don't support \" +\n      \"getTablesByType. Please use Hive 2.3 or higher version.\")\n  }\n"
  }
]