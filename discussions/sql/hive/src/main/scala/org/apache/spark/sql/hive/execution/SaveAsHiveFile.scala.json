[
  {
    "id" : "ecd5568a-43d3-41a4-a5c5-88fd933e6065",
    "prId" : 28129,
    "prUrl" : "https://github.com/apache/spark/pull/28129#pullrequestreview-387909969",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c3d099b4-bfde-4321-beb2-6567ad52bd86",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "If the description is true, we should check if `spark.speculation` is true or false here?",
        "createdAt" : "2020-04-06T01:49:31Z",
        "updatedAt" : "2020-04-06T01:49:31Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "5ecf5519-b769-45ec-96d8-2adc97af0eac",
        "parentId" : "c3d099b4-bfde-4321-beb2-6567ad52bd86",
        "authorId" : "0f4ef4e8-09be-436f-b743-bf8fbc343490",
        "body" : "@maropu Thanks for reply. In my scenario it was indeed caused by `spark.speculation`, but I donâ€™t know if there are any other scenarios also happened in this.\r\nIf it only happened with `spark.speculation`, then we can just check `spark.speculation` instead of adding new configuration.",
        "createdAt" : "2020-04-06T02:52:30Z",
        "updatedAt" : "2020-04-06T02:52:31Z",
        "lastEditedBy" : "0f4ef4e8-09be-436f-b743-bf8fbc343490",
        "tags" : [
        ]
      },
      {
        "id" : "31823c2b-93ad-4c88-b167-c308f1de7da1",
        "parentId" : "c3d099b4-bfde-4321-beb2-6567ad52bd86",
        "authorId" : "0f4ef4e8-09be-436f-b743-bf8fbc343490",
        "body" : "It is happened when running tasks is killed after Job committed, maybe the better way to solve this is checking the job's tasks status. However it seems it is impossible to check status here, thus I add new configuration to this.",
        "createdAt" : "2020-04-06T03:05:59Z",
        "updatedAt" : "2020-04-06T03:05:59Z",
        "lastEditedBy" : "0f4ef4e8-09be-436f-b743-bf8fbc343490",
        "tags" : [
        ]
      }
    ],
    "commit" : "2f9dc05e7dbf5f1c6724407741137fcc6153e7d0",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +144,148 @@        // Sometimes (e.g., when speculative task is enabled), temporary directories may be\n        // left uncleaned, confirmTempDirDeleted can confirm deleteOnExit.\n        if (fs.delete(path, true) && !SQLConf.get.confirmTempDirDeleted) {\n          // If we successfully delete the staging directory, remove it from FileSystem's cache.\n          fs.cancelDeleteOnExit(path)"
  },
  {
    "id" : "cb46f502-d347-46a1-98f4-5d7357e31547",
    "prId" : 28129,
    "prUrl" : "https://github.com/apache/spark/pull/28129#pullrequestreview-388807802",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2cd3aed2-80f0-41ff-a362-a70f8d248f7e",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Do you mean even if we delete the temp dir here, some tasks may re-create it later?",
        "createdAt" : "2020-04-07T05:46:45Z",
        "updatedAt" : "2020-04-07T05:46:45Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "5b251510-78f4-4867-8d66-fd66997a948b",
        "parentId" : "2cd3aed2-80f0-41ff-a362-a70f8d248f7e",
        "authorId" : "0f4ef4e8-09be-436f-b743-bf8fbc343490",
        "body" : "Yeap, the speculative tasks are maybe still running after Job committed.",
        "createdAt" : "2020-04-07T06:07:26Z",
        "updatedAt" : "2020-04-07T06:07:26Z",
        "lastEditedBy" : "0f4ef4e8-09be-436f-b743-bf8fbc343490",
        "tags" : [
        ]
      }
    ],
    "commit" : "2f9dc05e7dbf5f1c6724407741137fcc6153e7d0",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +143,147 @@        val fs = path.getFileSystem(hadoopConf)\n        // Sometimes (e.g., when speculative task is enabled), temporary directories may be\n        // left uncleaned, confirmTempDirDeleted can confirm deleteOnExit.\n        if (fs.delete(path, true) && !SQLConf.get.confirmTempDirDeleted) {\n          // If we successfully delete the staging directory, remove it from FileSystem's cache."
  }
]