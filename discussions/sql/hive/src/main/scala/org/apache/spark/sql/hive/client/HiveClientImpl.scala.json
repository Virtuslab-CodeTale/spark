[
  {
    "id" : "4ace1b81-f4b7-4940-8b87-77476a05ccee",
    "prId" : 32446,
    "prUrl" : "https://github.com/apache/spark/pull/32446#pullrequestreview-654087281",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "802f825b-74cd-406b-8ae5-57e9d6418ff6",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Here, line 303 claims that we need `the side-effect of Hive.get(conf)`.\r\nCould you confirm that `shim.getHive(conf)` doesn't break the side-effect assumption?",
        "createdAt" : "2021-05-07T05:14:03Z",
        "updatedAt" : "2021-05-07T05:14:03Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "83f1ef44-b4c8-4187-bd1c-33dd93652c59",
        "parentId" : "802f825b-74cd-406b-8ae5-57e9d6418ff6",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "yeah it shouldn't - both function are doing the same in this case by updating the `Hive` object's config with provided `conf`.",
        "createdAt" : "2021-05-07T05:16:22Z",
        "updatedAt" : "2021-05-07T05:16:23Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      }
    ],
    "commit" : "88697a43ba63963a1951f8d99a697fab4ca5692f",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +304,308 @@    // See discussion in https://github.com/apache/spark/pull/16826/files#r104606859\n    // for more details.\n    shim.getHive(conf)\n    // setCurrentSessionState will use the classLoader associated\n    // with the HiveConf in `state` to override the context class loader of the current"
  },
  {
    "id" : "23d4bb52-1a1b-475a-89d3-162a7145e886",
    "prId" : 32410,
    "prUrl" : "https://github.com/apache/spark/pull/32410#pullrequestreview-679603176",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0c147e18-0a17-4b84-9ed9-b276612db912",
        "parentId" : null,
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "@HyukjinKwon @sunchao I changed it to `shim.setCurrentSessionState(state)` to make it simpler.",
        "createdAt" : "2021-05-14T06:05:24Z",
        "updatedAt" : "2021-05-14T06:05:24Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      },
      {
        "id" : "39068d0f-fa49-4f5b-b965-6fb1eb586a21",
        "parentId" : "0c147e18-0a17-4b84-9ed9-b276612db912",
        "authorId" : "2821208d-43c5-4475-94ad-36cbf84c14d8",
        "body" : "@wangyum I wonder if this is a safe change. And why do you think this is making it simpler? ",
        "createdAt" : "2021-06-07T19:58:50Z",
        "updatedAt" : "2021-06-07T19:58:51Z",
        "lastEditedBy" : "2821208d-43c5-4475-94ad-36cbf84c14d8",
        "tags" : [
        ]
      },
      {
        "id" : "ab32acde-9137-41ed-8227-bb7a892ec651",
        "parentId" : "0c147e18-0a17-4b84-9ed9-b276612db912",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "Sorry for late replay. It is two questions.\r\n\r\n> if this is a safe change\r\n\r\nYes. The difference is `sessionState.start` creating too many directories and Spark SQL do not need it.\r\n\r\n> why do you think this is making it simpler?\r\n\r\n`shim.setCurrentSessionState(state)` is simpler than `if (version != hive.v12) SessionState.setCurrentSessionState(state) else   SessionState.start(state) `.",
        "createdAt" : "2021-06-09T12:45:42Z",
        "updatedAt" : "2021-06-09T12:45:42Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      }
    ],
    "commit" : "4bca8ecaec066ef19d04a12e134ba830320a2e0f",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +191,195 @@    // got changed. We reset it to clientLoader.ClassLoader here.\n    state.getConf.setClassLoader(clientLoader.classLoader)\n    shim.setCurrentSessionState(state)\n    state.out = new PrintStream(outputBuffer, true, UTF_8.name())\n    state.err = new PrintStream(outputBuffer, true, UTF_8.name())"
  },
  {
    "id" : "74bb2218-3400-4d14-b8fe-a369175442bc",
    "prId" : 32410,
    "prUrl" : "https://github.com/apache/spark/pull/32410#pullrequestreview-682750212",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4c0257a7-d08d-48d5-8a5d-251174890531",
        "parentId" : null,
        "authorId" : "2821208d-43c5-4475-94ad-36cbf84c14d8",
        "body" : "@HyukjinKwon @wangyum should this also be replaced with `shim.setCurrentSessionState(state)`?",
        "createdAt" : "2021-06-14T09:22:38Z",
        "updatedAt" : "2021-06-14T09:22:38Z",
        "lastEditedBy" : "2821208d-43c5-4475-94ad-36cbf84c14d8",
        "tags" : [
        ]
      },
      {
        "id" : "996662bd-ed01-4b44-a731-04df2158eb27",
        "parentId" : "4c0257a7-d08d-48d5-8a5d-251174890531",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "I think it's because it executes some Hive queries e.g.) `sparkSession.metadataHive.runSqlHive(\"SELECT * FROM t\")` at `sql/hive/src/test/scala/org/apache/spark/sql/hive/HiveMetastoreCatalogSuite.scala`",
        "createdAt" : "2021-06-14T09:37:20Z",
        "updatedAt" : "2021-06-14T09:37:20Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "f754a457-6405-4327-8df7-ed47d1b62765",
        "parentId" : "4c0257a7-d08d-48d5-8a5d-251174890531",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "Yes. Hive query needs to start `SessionState`.",
        "createdAt" : "2021-06-14T10:26:12Z",
        "updatedAt" : "2021-06-14T10:26:12Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      }
    ],
    "commit" : "4bca8ecaec066ef19d04a12e134ba830320a2e0f",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +830,834 @@\n    // Hive query needs to start SessionState.\n    SessionState.start(state)\n    logDebug(s\"Running hiveql '$cmd'\")\n    if (cmd.toLowerCase(Locale.ROOT).startsWith(\"set\")) { logDebug(s\"Changing config: $cmd\") }"
  },
  {
    "id" : "b4f9dcc5-3775-4b08-8bf9-da9acff611c6",
    "prId" : 31850,
    "prUrl" : "https://github.com/apache/spark/pull/31850#pullrequestreview-613129858",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c5d220f8-a5c9-47e1-84fa-969b82c2a28f",
        "parentId" : null,
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "this bypasses the hook canceling here\r\n\r\n```java\r\n// org.apache.hadoop.hive.common.FileUtils#deleteTmpFile\r\n\r\n  /**\r\n   * delete a temporary file and remove it from delete-on-exit hook.\r\n   */\r\n  public static boolean deleteTmpFile(File tempFile) {\r\n    if (tempFile != null) {\r\n      tempFile.delete();\r\n      ShutdownHookManager.cancelDeleteOnExit(tempFile);\r\n      return true;\r\n    }\r\n    return false;\r\n  }\r\n```\r\nfor `org.apache.hadoop.hive.ql.session.SessionState#deleteTmpOutputFile` and `deleteTmpErrOutputFile`",
        "createdAt" : "2021-03-16T11:28:01Z",
        "updatedAt" : "2021-03-16T13:10:34Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "b454fef8442d3c57d08622bc6323256485e0d9a8",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +164,168 @@    if (state.getTmpOutputFile != null) {\n      state.getTmpOutputFile.delete()\n      state.setTmpOutputFile(null)\n    }\n    if (state.getTmpErrOutputFile != null) {"
  },
  {
    "id" : "c95e79f4-4cd1-4527-957d-cdd91ed9b6fd",
    "prId" : 31271,
    "prUrl" : "https://github.com/apache/spark/pull/31271#pullrequestreview-574729794",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1fd3c087-a80c-4eb4-b6e3-6d5523677412",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "hmmm, I thought `org.apache.spark.sql.hive` is already a private package, no? cc @viirya @dongjoon-hyun ",
        "createdAt" : "2021-01-21T06:01:53Z",
        "updatedAt" : "2021-01-25T02:32:33Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "5dce089d-0d46-4081-809d-ab7a9b04e7fa",
        "parentId" : "1fd3c087-a80c-4eb4-b6e3-6d5523677412",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "I think so.",
        "createdAt" : "2021-01-21T06:03:26Z",
        "updatedAt" : "2021-01-25T02:32:33Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "7a33cdc0-bf80-4403-add4-1a93d9075266",
        "parentId" : "1fd3c087-a80c-4eb4-b6e3-6d5523677412",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Nah, it's exposed. https://spark.apache.org/docs/3.0.1/api/java/org/apache/spark/sql/hive/package-summary.html. We should better explicitly make it private",
        "createdAt" : "2021-01-21T09:07:46Z",
        "updatedAt" : "2021-01-25T02:32:33Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "2af98f7b-897e-493d-b93f-76da9fba69e3",
        "parentId" : "1fd3c087-a80c-4eb4-b6e3-6d5523677412",
        "authorId" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "body" : "Got it, will fix it in the next commit.",
        "createdAt" : "2021-01-22T08:55:28Z",
        "updatedAt" : "2021-01-25T02:32:33Z",
        "lastEditedBy" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "tags" : [
        ]
      },
      {
        "id" : "e8d5545c-1a51-4563-b47d-e77a85c45163",
        "parentId" : "1fd3c087-a80c-4eb4-b6e3-6d5523677412",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Thank you for pinging me. +1 for making it private.",
        "createdAt" : "2021-01-23T03:07:34Z",
        "updatedAt" : "2021-01-25T02:32:33Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "1b89ea39a6393d478225bd05142fca655f16f4a5",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1269,1273 @@}\n\nprivate[hive] case object HiveVoidType extends DataType {\n  override def defaultSize: Int = 1\n  override def asNullable: DataType = HiveVoidType"
  },
  {
    "id" : "45cb58a2-0144-40c6-a58a-4b2578a121c8",
    "prId" : 30866,
    "prUrl" : "https://github.com/apache/spark/pull/30866#pullrequestreview-556304036",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9bf1334c-5ba0-4f62-95bb-091087bff406",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "@MaxGekk, are there more places like to fix in this file? I think we can fix in one go instead of fixing one by one.",
        "createdAt" : "2020-12-21T10:52:32Z",
        "updatedAt" : "2020-12-21T10:52:32Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "6c1bdea6-9d46-4d2f-8c37-7bf7044a7f8b",
        "parentId" : "9bf1334c-5ba0-4f62-95bb-091087bff406",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Maybe, there are more places here but I am not fixing them somehow randomly. I find those issues while unifying tests for DSv2, DSv1 In-Memory and Hive Table (SPARK-33381). More tests we will unify, more behavior differences we will find, I guess.",
        "createdAt" : "2020-12-21T11:09:50Z",
        "updatedAt" : "2020-12-21T11:09:50Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "bcc0f1a5-d34b-4c54-8f90-75462fd52237",
        "parentId" : "9bf1334c-5ba0-4f62-95bb-091087bff406",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "In particular, this fix is needed for https://github.com/apache/spark/pull/30863#discussion_r546630850",
        "createdAt" : "2020-12-21T11:10:54Z",
        "updatedAt" : "2020-12-21T11:10:55Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "ab696330-fb88-4a99-b2d4-fafd91d8cb09",
        "parentId" : "9bf1334c-5ba0-4f62-95bb-091087bff406",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "ðŸ‘Œ ",
        "createdAt" : "2020-12-21T11:12:33Z",
        "updatedAt" : "2020-12-21T11:12:34Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "1c478e888c5bd2d3f63f5ff9a92fb2d6318ad491",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +666,670 @@    val hiveTable = toHiveTable(catalogTable, Some(userName))\n    specs.zip(newSpecs).foreach { case (oldSpec, newSpec) =>\n      if (client.getPartition(hiveTable, newSpec.asJava, false) != null) {\n        throw new PartitionAlreadyExistsException(db, table, newSpec)\n      }"
  },
  {
    "id" : "557decfb-2a56-4908-9518-aef74eef73cd",
    "prId" : 29936,
    "prUrl" : "https://github.com/apache/spark/pull/29936#pullrequestreview-501703891",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "31a4ec39-8d89-4f23-9d6f-7c097931bfc5",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "@dongjoon-hyun should we remove `HiveUtils.isHive23` and related changes? I see it was added when we add Hive 2.3 support at https://github.com/apache/spark/commit/33f3c48cac087e079b9c7e342c2e58b16eaaa681#diff-842e3447fc453de26c706db1cac8f2c4R59. cc @wangyum FYI",
        "createdAt" : "2020-10-05T02:25:35Z",
        "updatedAt" : "2020-10-05T22:12:19Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "ca774720-fa3e-494a-aebd-1ab5b19bc865",
        "parentId" : "31a4ec39-8d89-4f23-9d6f-7c097931bfc5",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "@AngersZhuuuu should we remove https://github.com/apache/spark/blob/55ce49ed28a58e0047a9680fa63f4dff54c11be4/sql/hive/src/test/scala/org/apache/spark/sql/hive/execution/HiveScriptTransformationSuite.scala#L41 too?",
        "createdAt" : "2020-10-05T02:26:06Z",
        "updatedAt" : "2020-10-05T22:12:19Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "963e0260-732a-4b9f-9394-ce83cd4af290",
        "parentId" : "31a4ec39-8d89-4f23-9d6f-7c097931bfc5",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "+1, we can remove `HiveUtils.isHive23` and related changes.",
        "createdAt" : "2020-10-05T03:28:23Z",
        "updatedAt" : "2020-10-05T22:12:19Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      }
    ],
    "commit" : "c855260761af80b287caaea0ab071dbd15319265",
    "line" : 2,
    "diffHunk" : "@@ -1,1 +295,299 @@    } catch {\n      case e: NoClassDefFoundError\n        if HiveUtils.isHive23 && e.getMessage.contains(\"org/apache/hadoop/hive/serde2/SerDe\") =>\n        throw new ClassNotFoundException(\"The SerDe interface removed since Hive 2.3(HIVE-15167).\" +\n          \" Please migrate your custom SerDes to Hive 2.3. See HIVE-15167 for more details.\", e)"
  },
  {
    "id" : "baf2c54f-3efa-41fa-b6f9-472e74a0b61e",
    "prId" : 29363,
    "prUrl" : "https://github.com/apache/spark/pull/29363#pullrequestreview-461853455",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "11631d95-64ae-45c3-baf4-1a604a20b881",
        "parentId" : null,
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "+1",
        "createdAt" : "2020-08-05T16:58:28Z",
        "updatedAt" : "2020-08-05T16:58:29Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      }
    ],
    "commit" : "9236cc6db5b2a381baa16f4e464a9338baa349b4",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +760,764 @@      pattern: String,\n      tableType: CatalogTableType): Seq[String] = withHiveState {\n    val hiveTableType = toHiveTableType(tableType)\n    try {\n      // Try with Hive API getTablesByType first, it's supported from Hive 2.3+."
  },
  {
    "id" : "790e8032-cced-43c7-aad5-39a12dac5a65",
    "prId" : 28647,
    "prUrl" : "https://github.com/apache/spark/pull/28647#pullrequestreview-440530813",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "30764732-26e3-455c-9e1a-5eb0075e4d37",
        "parentId" : null,
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "It also affect `createTable`, but seems fine.",
        "createdAt" : "2020-07-01T04:02:41Z",
        "updatedAt" : "2020-11-24T09:28:18Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "c45489ad5b8ddd53d5e81fbba4cd08c0b4fd9850",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +1066,1070 @@    // Hive only retain the useful properties through serde class annotation.\n    // For better compatible with Hive, we remove the metastore properties.\n    val hiveProperties = table.properties -- HIVE_METASTORE_GENERATED_PROPERTIES\n    hiveProperties.foreach { case (k, v) => hiveTable.setProperty(k, v) }\n    table.comment.foreach { c => hiveTable.setProperty(\"comment\", c) }"
  },
  {
    "id" : "52d4ca66-4fdb-4103-8c16-7d8a090a16a1",
    "prId" : 28647,
    "prUrl" : "https://github.com/apache/spark/pull/28647#pullrequestreview-446046675",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "80b3b7bd-4897-4cce-9d5e-f48c8ad1af53",
        "parentId" : null,
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "After check Hive1.2 and Hive2.3 again, I think we can just remove 3 properties so that we can reduce the scope of influence.",
        "createdAt" : "2020-07-08T01:15:47Z",
        "updatedAt" : "2020-11-24T09:28:18Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      },
      {
        "id" : "63297559-718e-48ef-84c3-18655df9eb25",
        "parentId" : "80b3b7bd-4897-4cce-9d5e-f48c8ad1af53",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Does this include all the properties in https://github.com/apache/spark/pull/28647/files#diff-b7094baa12601424a5d19cb930e3402fL1534 ?",
        "createdAt" : "2020-07-09T15:24:18Z",
        "updatedAt" : "2020-11-24T09:28:18Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "78050762-56c9-4d21-86f6-c85b48d8e296",
        "parentId" : "80b3b7bd-4897-4cce-9d5e-f48c8ad1af53",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "Yes, I checked all the properties and make sure hive just modify the three properties.",
        "createdAt" : "2020-07-10T00:12:30Z",
        "updatedAt" : "2020-11-24T09:28:18Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "c45489ad5b8ddd53d5e81fbba4cd08c0b4fd9850",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +1227,1231 @@\n  // Visible for testing.\n  private[hive] val HIVE_METASTORE_GENERATED_PROPERTIES: Set[String] = Set(\n    hive_metastoreConstants.DDL_TIME,\n    // at org.apache.hadoop.hive.ql.exec.DDLTask.updateModifiedParameters()"
  },
  {
    "id" : "89e6926d-97ba-44f7-bae2-e812894d159f",
    "prId" : 27041,
    "prUrl" : "https://github.com/apache/spark/pull/27041#pullrequestreview-342803015",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c1596c24-b503-4795-824a-192f054546c6",
        "parentId" : null,
        "authorId" : "56b136f7-d485-4c54-b8df-91c9cec8c43d",
        "body" : "Seems we should update https://github.com/apache/spark/pull/27041/files#diff-6fd847124f8eae45ba2de1cf7d6296feR170-R179 and also explain why extraConfig is at the end.",
        "createdAt" : "2020-01-14T19:26:03Z",
        "updatedAt" : "2020-02-18T15:07:02Z",
        "lastEditedBy" : "56b136f7-d485-4c54-b8df-91c9cec8c43d",
        "tags" : [
        ]
      },
      {
        "id" : "9570fd2b-0a3d-4622-96f3-8f8583604c5b",
        "parentId" : "c1596c24-b503-4795-824a-192f054546c6",
        "authorId" : "2c1bd8aa-c665-4159-a689-57743063347c",
        "body" : "@yhuai Sure, I have updated the PR with reasonable pointers for the order. Does it suffice it now.?",
        "createdAt" : "2020-01-14T19:38:39Z",
        "updatedAt" : "2020-02-18T15:07:02Z",
        "lastEditedBy" : "2c1bd8aa-c665-4159-a689-57743063347c",
        "tags" : [
        ]
      },
      {
        "id" : "cb16b834-b329-4c57-9c6e-c7e204b69f3c",
        "parentId" : "c1596c24-b503-4795-824a-192f054546c6",
        "authorId" : "56b136f7-d485-4c54-b8df-91c9cec8c43d",
        "body" : "Thank you. As getConfSystemProperties will get all of hive confs that are in the system properties, it is possible that we will pull in a config that is not set by `--hiveconf`. Seems we are introducing a behavior change? Can you explain the impact of this change and why this change is fine?",
        "createdAt" : "2020-01-14T19:55:37Z",
        "updatedAt" : "2020-02-18T15:07:02Z",
        "lastEditedBy" : "56b136f7-d485-4c54-b8df-91c9cec8c43d",
        "tags" : [
        ]
      },
      {
        "id" : "5d7045b5-5e4d-4e7c-a37e-5556e9874b38",
        "parentId" : "c1596c24-b503-4795-824a-192f054546c6",
        "authorId" : "2c1bd8aa-c665-4159-a689-57743063347c",
        "body" : "Sure, even without my changes in this PR, the `HiveConf` always considers the hive confs in system properties which were not set via `--hiveconf` as part of `HiveConf` constructor i.e Refer https://github.com/apache/hive/blob/rel/release-2.3.5/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java#L4079 (same behaviour for hive 1.2.1 as well) hence, this do not change any flow",
        "createdAt" : "2020-01-14T20:01:55Z",
        "updatedAt" : "2020-02-18T15:07:02Z",
        "lastEditedBy" : "2c1bd8aa-c665-4159-a689-57743063347c",
        "tags" : [
        ]
      }
    ],
    "commit" : "3718df989c02641f864432b246313a158a11b9e6",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +191,195 @@    val overriddenHiveProps = HiveConf.getConfSystemProperties.asScala\n    val confMap = (hadoopConf.iterator().asScala.map(kv => kv.getKey -> kv.getValue) ++\n      sparkConf.getAll.toMap ++ overriddenHiveProps ++ extraConfig).toMap\n    confMap.foreach { case (k, v) => hiveConf.set(k, v) }\n    SQLConf.get.redactOptions(confMap).foreach { case (k, v) =>"
  },
  {
    "id" : "30a2d6b3-df28-49e6-9404-475363254566",
    "prId" : 27041,
    "prUrl" : "https://github.com/apache/spark/pull/27041#pullrequestreview-360415248",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f073b573-fbf1-491d-b136-a4917f43ec0e",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "so we totally ignore the --hive-conf previously?",
        "createdAt" : "2020-02-18T05:26:29Z",
        "updatedAt" : "2020-02-18T15:07:02Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "2d1f08bb-2dfc-4811-8b9d-3b0d11416dd2",
        "parentId" : "f073b573-fbf1-491d-b136-a4917f43ec0e",
        "authorId" : "2c1bd8aa-c665-4159-a689-57743063347c",
        "body" : "it was handled as --hiveconf as part of HiveConf constructor i.e Refer https://github.com/apache/hive/blob/rel/release-2.3.5/common/src/java/org/apache/hadoop/hive/conf/HiveConf.java#L4079 , \r\ni.e first it loads hive-site and then it adds --hiveconf  properties on top. \r\n\r\nBut in spark we again add hadoopConf on top of it hence overwriting HiveConf order",
        "createdAt" : "2020-02-18T05:31:20Z",
        "updatedAt" : "2020-02-18T15:07:02Z",
        "lastEditedBy" : "2c1bd8aa-c665-4159-a689-57743063347c",
        "tags" : [
        ]
      },
      {
        "id" : "9a63eca8-0050-4f45-b0f3-db9fd920007d",
        "parentId" : "f073b573-fbf1-491d-b136-a4917f43ec0e",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Can you add more code comment to convince people that `HiveConf.getConfSystemProperties` contains only the --hiveconf?",
        "createdAt" : "2020-02-18T05:46:05Z",
        "updatedAt" : "2020-02-18T15:07:02Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "34ce4b74-01bc-4bfd-bdfe-4a7f6312c9e3",
        "parentId" : "f073b573-fbf1-491d-b136-a4917f43ec0e",
        "authorId" : "2c1bd8aa-c665-4159-a689-57743063347c",
        "body" : "@cloud-fan updated. is the comment adequate now?",
        "createdAt" : "2020-02-18T15:08:27Z",
        "updatedAt" : "2020-02-18T15:08:40Z",
        "lastEditedBy" : "2c1bd8aa-c665-4159-a689-57743063347c",
        "tags" : [
        ]
      }
    ],
    "commit" : "3718df989c02641f864432b246313a158a11b9e6",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +189,193 @@    // which were considered on creation of HiveConf constructor\n    // Refer: org.apache.hadoop.hive.conf.HiveConf#applySystemProperties\n    val overriddenHiveProps = HiveConf.getConfSystemProperties.asScala\n    val confMap = (hadoopConf.iterator().asScala.map(kv => kv.getKey -> kv.getValue) ++\n      sparkConf.getAll.toMap ++ overriddenHiveProps ++ extraConfig).toMap"
  }
]