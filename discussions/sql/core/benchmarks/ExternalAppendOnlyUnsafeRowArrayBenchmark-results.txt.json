[
  {
    "id" : "a62f45c0-edc2-48ec-a2de-a192f6aed254",
    "prId" : 27246,
    "prUrl" : "https://github.com/apache/spark/pull/27246#pullrequestreview-437165114",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "75f84488-3d01-466f-840d-ef5afa5dfd45",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "You mean the other numbers didn't change at all?",
        "createdAt" : "2020-06-23T23:54:13Z",
        "updatedAt" : "2020-08-01T17:33:48Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "f7fd17dd-0c6a-4f08-8e41-c159a8614b25",
        "parentId" : "75f84488-3d01-466f-840d-ef5afa5dfd45",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Also, could you update the jdk11 one, too: https://github.com/apache/spark/blob/master/sql/core/benchmarks/ExternalAppendOnlyUnsafeRowArrayBenchmark-jdk11-results.txt",
        "createdAt" : "2020-06-23T23:56:04Z",
        "updatedAt" : "2020-08-01T17:33:48Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "9f8b5d5f-b45b-42ef-a9a7-cbce6a2e1376",
        "parentId" : "75f84488-3d01-466f-840d-ef5afa5dfd45",
        "authorId" : "39b78cdc-063e-4571-aeca-1b5a0e92b697",
        "body" : "> You mean the other numbers didn't change at all?\r\n\r\nMy understanding was to add new benchmark results to the file. I didn't change other results in the files. Do you want me to update all results? ",
        "createdAt" : "2020-06-24T01:03:13Z",
        "updatedAt" : "2020-08-01T17:33:48Z",
        "lastEditedBy" : "39b78cdc-063e-4571-aeca-1b5a0e92b697",
        "tags" : [
        ]
      },
      {
        "id" : "9f4ed8bd-3b82-4440-bb61-22265fe49327",
        "parentId" : "75f84488-3d01-466f-840d-ef5afa5dfd45",
        "authorId" : "39b78cdc-063e-4571-aeca-1b5a0e92b697",
        "body" : "One more thing, we will not see performance improvements for the existing benchmarks if the benchmark iterates  over the spilled data. Then comparison will be related to the machine on which benchmark was running and disk speed.",
        "createdAt" : "2020-06-24T01:17:10Z",
        "updatedAt" : "2020-08-01T17:33:48Z",
        "lastEditedBy" : "39b78cdc-063e-4571-aeca-1b5a0e92b697",
        "tags" : [
        ]
      },
      {
        "id" : "10fc96ee-d543-4611-8606-df3b1757c62a",
        "parentId" : "75f84488-3d01-466f-840d-ef5afa5dfd45",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "> My understanding was to add new benchmark results to the file. I didn't change other results in the files. Do you want me to update all results?\r\n\r\nWe need to check no perf regression on jdk8/jdk11 (Sometimes, we hit perf regression unexpectedly). But, yea. we might not need the update if you've already checked locally.",
        "createdAt" : "2020-06-25T01:16:59Z",
        "updatedAt" : "2020-08-01T17:33:48Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "e8a3f5e6-c558-4ff2-bca0-8ebd9788385b",
        "parentId" : "75f84488-3d01-466f-840d-ef5afa5dfd45",
        "authorId" : "39b78cdc-063e-4571-aeca-1b5a0e92b697",
        "body" : "Yes, I did comparison of the existing micro-benchmark results when patch is applied and when there is no patch.\r\nI do not see regression in the performance for the existing micro-benchmarks. I will push micro-benchmark results for jdk11 soon.\r\nThank you for help ðŸ˜Š\r\n",
        "createdAt" : "2020-06-25T04:48:59Z",
        "updatedAt" : "2020-08-01T17:33:48Z",
        "lastEditedBy" : "39b78cdc-063e-4571-aeca-1b5a0e92b697",
        "tags" : [
        ]
      }
    ],
    "commit" : "9d5bd99e317d5d0f73b645f8e29276c5d99ed39a",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +43,47 @@ExternalAppendOnlyUnsafeRowArray                      9             10           1         17.1          58.5       1.2X\n\nOpenJDK 64-Bit Server VM 1.8.0_252-8u252-b09-1~16.04-b09 on Linux 4.4.0-178-generic\nIntel(R) Xeon(R) CPU E5-2687W v3 @ 3.10GHz\nSpilling  SpillReader with 16000 rows:    Best Time(ms)   Avg Time(ms)   Stdev(ms)    Rate(M/s)   Per Row(ns)   Relative"
  },
  {
    "id" : "c9fa43d4-9e5b-4f2e-9336-411114516069",
    "prId" : 27246,
    "prUrl" : "https://github.com/apache/spark/pull/27246#pullrequestreview-437183982",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cb1ec5cb-c225-415d-99af-d507d11240d4",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "What's a number without this PR?",
        "createdAt" : "2020-06-25T01:20:27Z",
        "updatedAt" : "2020-08-01T17:33:48Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "1e5a36bc-a902-4618-9056-9c369d9a8f7b",
        "parentId" : "cb1ec5cb-c225-415d-99af-d507d11240d4",
        "authorId" : "39b78cdc-063e-4571-aeca-1b5a0e92b697",
        "body" : "Here it is:\r\nOpenJDK 64-Bit Server VM 1.8.0_252-8u252-b09-1~16.04-b09 on Linux 4.4.0-178-generic\r\nIntel(R) Xeon(R) CPU E5-2687W v3 @ 3.10GHz\r\nSpilling  SpillReader with 16000 rows:    Best Time(ms)   Avg Time(ms)   Stdev(ms)    Rate(M/s)   Per Row(ns)   Relative\r\n//------------------------------------------------------------------------------------------------------------------------\r\nUnsafeSorterSpillReader                          932683         943898         NaN          0.0     3643292.4       1.0X",
        "createdAt" : "2020-06-25T04:54:54Z",
        "updatedAt" : "2020-08-01T17:33:48Z",
        "lastEditedBy" : "39b78cdc-063e-4571-aeca-1b5a0e92b697",
        "tags" : [
        ]
      },
      {
        "id" : "44b69f4e-f7b1-465e-8561-9759f3db141d",
        "parentId" : "cb1ec5cb-c225-415d-99af-d507d11240d4",
        "authorId" : "39b78cdc-063e-4571-aeca-1b5a0e92b697",
        "body" : "There are three spill files. It will result in three I/Os for each created iterator, because it has to read number of rows from each spilled file. So, we see more than 2000 X performance difference.",
        "createdAt" : "2020-06-25T04:59:10Z",
        "updatedAt" : "2020-08-01T17:33:48Z",
        "lastEditedBy" : "39b78cdc-063e-4571-aeca-1b5a0e92b697",
        "tags" : [
        ]
      },
      {
        "id" : "101a57e4-822b-4c0a-b06f-e0a8582c5d49",
        "parentId" : "cb1ec5cb-c225-415d-99af-d507d11240d4",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "oh, looks nice.",
        "createdAt" : "2020-06-25T05:46:05Z",
        "updatedAt" : "2020-08-01T17:33:48Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "9d5bd99e317d5d0f73b645f8e29276c5d99ed39a",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +47,51 @@Spilling  SpillReader with 16000 rows:    Best Time(ms)   Avg Time(ms)   Stdev(ms)    Rate(M/s)   Per Row(ns)   Relative\n------------------------------------------------------------------------------------------------------------------------\nUnsafeSorterSpillReader_bufferSize1024              411            426          13          0.6        1607.2       1.0X"
  }
]