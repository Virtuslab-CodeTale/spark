[
  {
    "id" : "f0123998-c7e0-438b-810b-6149ca014670",
    "prId" : 29427,
    "prUrl" : "https://github.com/apache/spark/pull/29427#pullrequestreview-467714120",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8900f8dc-88d9-42f8-b724-2a2794695fa5",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "@HyukjinKwon @dongjoon-hyun I think this is a bug. I found this when I added test for #29412.",
        "createdAt" : "2020-08-13T19:42:11Z",
        "updatedAt" : "2020-08-16T05:15:00Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "9a8d2f5f-5bc6-492f-ac58-95fe53d75fac",
        "parentId" : "8900f8dc-88d9-42f8-b724-2a2794695fa5",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "This was already in Spark ORC datasource before SPARK-25557. Thus it's not a regression caused by nested predicate pushdown. So I will address this in a new ticket and PR.",
        "createdAt" : "2020-08-13T19:47:08Z",
        "updatedAt" : "2020-08-16T05:15:00Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "0e8b025f-863d-486b-8f5c-e697f11164ef",
        "parentId" : "8900f8dc-88d9-42f8-b724-2a2794695fa5",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Can we have this non-nested test case on `branch-3.0`, too?",
        "createdAt" : "2020-08-14T03:57:52Z",
        "updatedAt" : "2020-08-16T05:15:00Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "3ef6017a-25df-40c2-a522-d817cb6e36c6",
        "parentId" : "8900f8dc-88d9-42f8-b724-2a2794695fa5",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Yes, this should be fixed in branch-3.0 too.",
        "createdAt" : "2020-08-14T04:05:13Z",
        "updatedAt" : "2020-08-16T05:15:00Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "4eb114b4-2b40-4dd0-95c1-4c22d54f8ee5",
        "parentId" : "8900f8dc-88d9-42f8-b724-2a2794695fa5",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "I use original SPARK-25557 as PR title now. If we want to backport this test to branch-3.0, should I create a new JIRA ticket for this?",
        "createdAt" : "2020-08-14T04:09:18Z",
        "updatedAt" : "2020-08-16T05:15:00Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "fbdd78cb-d9f1-4886-be3f-edd28fe0ea73",
        "parentId" : "8900f8dc-88d9-42f8-b724-2a2794695fa5",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Yes, please~",
        "createdAt" : "2020-08-14T16:33:53Z",
        "updatedAt" : "2020-08-16T05:15:00Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "edcdb8795ed9b1333f568be4f42ad1e8bfd04a45",
    "line" : 89,
    "diffHunk" : "@@ -1,1 +588,592 @@          val actual = stripSparkFilter(sql(s\"select a from $tableName where a < 0\"))\n          // TODO: ORC predicate pushdown should work under case-insensitive analysis.\n          // assert(actual.count() == 1)\n        }\n      }"
  }
]