[
  {
    "id" : "ee3fb466-e139-45a9-a8a1-57a521189daa",
    "prId" : 33671,
    "prUrl" : "https://github.com/apache/spark/pull/33671#pullrequestreview-727913807",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5ac4d4cb-4c77-4dc1-885a-5a4483c43784",
        "parentId" : null,
        "authorId" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "body" : "RoundRobin sorts data before shuffling right? That will slow things a lot.",
        "createdAt" : "2021-08-11T19:03:31Z",
        "updatedAt" : "2021-08-11T19:03:31Z",
        "lastEditedBy" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "tags" : [
        ]
      },
      {
        "id" : "2b240d47-de90-4d62-b8b4-8311642c5313",
        "parentId" : "5ac4d4cb-4c77-4dc1-885a-5a4483c43784",
        "authorId" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "body" : "Yes, that's why we put a TODO there.",
        "createdAt" : "2021-08-11T20:12:33Z",
        "updatedAt" : "2021-08-11T20:12:45Z",
        "lastEditedBy" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "tags" : [
        ]
      }
    ],
    "commit" : "4cc52f74ab8a12599b74ae163e8f4065a99e359d",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +686,690 @@        // TODO create a new identity partitioning instead of using RoundRobinPartitioning.\n        exchange.ShuffleExchangeExec(\n          RoundRobinPartitioning(conf.numShufflePartitions),\n          planLater(newPlan),\n          REPARTITION_BY_COL) :: Nil"
  },
  {
    "id" : "6972f06c-fe91-4ada-bc98-1179cedff43c",
    "prId" : 33093,
    "prUrl" : "https://github.com/apache/spark/pull/33093#pullrequestreview-697558169",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "98e4426c-2368-4954-b787-a11cbd233a30",
        "parentId" : null,
        "authorId" : "2d6b46ba-4100-4c4d-9341-fff5e39647ec",
        "body" : "`planLater(initialState)` Is it still correct when `initialState` has a batch `FlatMapGroupsWithState`? Could you add a test for this case?",
        "createdAt" : "2021-06-30T21:37:11Z",
        "updatedAt" : "2021-06-30T21:52:57Z",
        "lastEditedBy" : "2d6b46ba-4100-4c4d-9341-fff5e39647ec",
        "tags" : [
        ]
      },
      {
        "id" : "00e368ad-1633-4c6c-ae91-6c071dffb37d",
        "parentId" : "98e4426c-2368-4954-b787-a11cbd233a30",
        "authorId" : "0e7383af-ae8f-4891-9ab6-e80efa3990c0",
        "body" : "do we still need to worry about it now since we are passing a keyValueGroupedDataset",
        "createdAt" : "2021-07-01T12:14:16Z",
        "updatedAt" : "2021-07-01T12:14:16Z",
        "lastEditedBy" : "0e7383af-ae8f-4891-9ab6-e80efa3990c0",
        "tags" : [
        ]
      },
      {
        "id" : "63963c8e-7a38-4cef-8323-45162202b2af",
        "parentId" : "98e4426c-2368-4954-b787-a11cbd233a30",
        "authorId" : "2d6b46ba-4100-4c4d-9341-fff5e39647ec",
        "body" : "> do we still need to worry about it now since we are passing a keyValueGroupedDataset\r\n\r\nWe do. You can still get it from `ds.flatMapGroups(...).groupBy(key)...`. I feel this rule is missing `isStreaming` check, but haven't checked it.",
        "createdAt" : "2021-07-01T18:47:54Z",
        "updatedAt" : "2021-07-01T18:47:54Z",
        "lastEditedBy" : "2d6b46ba-4100-4c4d-9341-fff5e39647ec",
        "tags" : [
        ]
      }
    ],
    "commit" : "eb83b684fdc7d62846b3860f90d26ec119c136c5",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +567,571 @@          func, keyDeser, valueDeser, sDeser, groupAttr, stateGroupAttr, dataAttr, sda, outputAttr,\n          None, stateEnc, stateVersion, outputMode, timeout, batchTimestampMs = None,\n          eventTimeWatermark = None, planLater(initialState), hasInitialState, planLater(child)\n        )\n        execPlan :: Nil"
  },
  {
    "id" : "4ea782e8-0509-4782-9cb7-06408d0d95d7",
    "prId" : 33081,
    "prUrl" : "https://github.com/apache/spark/pull/33081#pullrequestreview-706976281",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4730ad6c-7af7-4c80-8c1b-2f3869b3a719",
        "parentId" : null,
        "authorId" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "body" : "nit: we get the aggregation state format version twice https://github.com/apache/spark/pull/33081/files#diff-21f071d73070b8257ad76e6e16ec5ed38a13d1278fe94bd42546c258a69f4410R327",
        "createdAt" : "2021-07-15T04:24:07Z",
        "updatedAt" : "2021-07-15T04:51:30Z",
        "lastEditedBy" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "tags" : [
        ]
      },
      {
        "id" : "560e0595-1906-42d2-8802-9d47e8631f42",
        "parentId" : "4730ad6c-7af7-4c80-8c1b-2f3869b3a719",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "I'll remove above one. Nice finding!",
        "createdAt" : "2021-07-15T06:36:46Z",
        "updatedAt" : "2021-07-15T06:36:46Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      }
    ],
    "commit" : "bbade3501f16e9437ba9af4feca3e2029785d273",
    "line" : 35,
    "diffHunk" : "@@ -1,1 +352,356 @@\n          case None =>\n            val stateVersion = conf.getConf(SQLConf.STREAMING_AGGREGATION_STATE_FORMAT_VERSION)\n\n            AggUtils.planStreamingAggregation("
  },
  {
    "id" : "90e7c893-633d-4fb0-9487-917cbac796d2",
    "prId" : 32355,
    "prUrl" : "https://github.com/apache/spark/pull/32355#pullrequestreview-656210701",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "46c515d7-f5dd-4bcf-bf85-fc4571d82398",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can we check this in `ResolveJoinStrategyHints`?",
        "createdAt" : "2021-04-27T06:16:45Z",
        "updatedAt" : "2021-04-27T06:16:45Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "f6de0eb1-961d-483d-9732-b0a90538d2b9",
        "parentId" : "46c515d7-f5dd-4bcf-bf85-fc4571d82398",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "I thought about it but seems we need to do this check in physical side.\r\n\r\nWe don't konw the join strategy at analysis or optimizer (`EliminateResolvedHint`). For example, if user specify `boradcast`, we need to check if it's a equijoin first then check the build side, since this join could be bhj or bnlj.",
        "createdAt" : "2021-04-27T06:51:59Z",
        "updatedAt" : "2021-04-27T06:51:59Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      },
      {
        "id" : "6c3cf8b3-fdb3-4f19-8265-c0ea65eaaf56",
        "parentId" : "46c515d7-f5dd-4bcf-bf85-fc4571d82398",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "maybe we can move `ExtractEquiJoinKeys` to catalyst?",
        "createdAt" : "2021-04-27T06:58:42Z",
        "updatedAt" : "2021-04-27T06:58:42Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "b3d39983-345e-46df-8d48-4b37e237c6d0",
        "parentId" : "46c515d7-f5dd-4bcf-bf85-fc4571d82398",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "It's a point. How about make a new rule at Optimizer `Finish Analysis` batch to check if join is illegal. Move to Optimizer is to avoid effect like `EliminateOuterJoin`.",
        "createdAt" : "2021-04-27T07:35:00Z",
        "updatedAt" : "2021-04-27T07:35:00Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      },
      {
        "id" : "1a0c57f8-6e4c-491b-9796-93feb1464cd5",
        "parentId" : "46c515d7-f5dd-4bcf-bf85-fc4571d82398",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "`EliminateOuterJoin` is a good point, so we can only know if the hint is valid or not at the planner.\r\n\r\nIt's a bit unfortunate to see the hint code being widespread, @maryannxue do you have any thoughts?",
        "createdAt" : "2021-04-27T08:10:15Z",
        "updatedAt" : "2021-04-27T08:10:15Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "6ec8330d-53bc-45c3-9340-0e4dd75028b2",
        "parentId" : "46c515d7-f5dd-4bcf-bf85-fc4571d82398",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "How about move `EliminateResolvedHint` from optimizer to physical side ? then we can add the check in one rule.",
        "createdAt" : "2021-05-11T01:30:29Z",
        "updatedAt" : "2021-05-11T01:30:29Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "f1e7ba082bfb557c67adad8f6c5c4ec7af622167",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +142,146 @@    with PredicateHelper\n    with JoinSelectionHelper {\n    private val hintErrorHandler = conf.hintErrorHandler\n\n    private def checkHintBuildSide("
  },
  {
    "id" : "600c991a-e429-413b-adeb-09a0f3d3212d",
    "prId" : 32355,
    "prUrl" : "https://github.com/apache/spark/pull/32355#pullrequestreview-720407628",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "39a5bd40-8bfc-4e66-a161-4df7c5aa967b",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can we make it more general? I think we can also give a warning if SMJ/SHJ hint is specified but the join has no join keys.",
        "createdAt" : "2021-08-02T16:50:46Z",
        "updatedAt" : "2021-08-02T16:50:46Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "f1e7ba082bfb557c67adad8f6c5c4ec7af622167",
    "line" : 62,
    "diffHunk" : "@@ -1,1 +199,203 @@      case j @ ExtractEquiJoinKeys(joinType, leftKeys, rightKeys, nonEquiCond, left, right, hint) =>\n        def createBroadcastHashJoin(onlyLookingAtHint: Boolean) = {\n          val buildSide = getBroadcastBuildSide(\n            left, right, joinType, hint, onlyLookingAtHint, conf)\n          checkHintBuildSide(onlyLookingAtHint, buildSide, joinType, hint, true)"
  },
  {
    "id" : "6b11bf21-13ca-4586-816c-34c6b20da460",
    "prId" : 29455,
    "prUrl" : "https://github.com/apache/spark/pull/29455#pullrequestreview-470103334",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8c26c529-ad8d-473c-af82-4670b58e0ad9",
        "parentId" : null,
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "Just a high level question - if we are worried about broadcast join OOM on driver side here, shouldn't we be also worried about shuffled hash join OOM on task side as well?",
        "createdAt" : "2020-08-18T21:26:16Z",
        "updatedAt" : "2020-09-04T08:12:16Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      },
      {
        "id" : "09eb52b8-46f2-416b-8639-e26ea1fbf264",
        "parentId" : "8c26c529-ad8d-473c-af82-4670b58e0ad9",
        "authorId" : "cce1c782-0596-44b6-8b99-6b77d2cca53c",
        "body" : "the HashedRelation built in ShuffledHashedJoinExec which was partitioned, it should be less data, so the driver OOM issue should be a major concern.",
        "createdAt" : "2020-08-19T01:24:13Z",
        "updatedAt" : "2020-09-04T08:12:16Z",
        "lastEditedBy" : "cce1c782-0596-44b6-8b99-6b77d2cca53c",
        "tags" : [
        ]
      },
      {
        "id" : "d5e769ab-b6b5-4dc0-ab08-2b69d02bb1df",
        "parentId" : "8c26c529-ad8d-473c-af82-4670b58e0ad9",
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "Sorry I don't get why we don't worry about shuffled hash join OOM if sub-query is way too big/skewed in certain keys. In general, shuffled hash join OOM is a normal issue if people choose shuffled hash join blindly. Could we add a check to make sure build size is not too big to be shuffled hash join?\r\n\r\ne.g.\r\n\r\n```\r\nif (!canBroadcastBySize(j.right, conf) && canBuildLocalHashMapBySize(j.right, conf) && conf.adaptiveExecutionEnabled) {\r\n  ...\r\n}\r\n```",
        "createdAt" : "2020-08-19T01:31:00Z",
        "updatedAt" : "2020-09-04T08:12:16Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      },
      {
        "id" : "48361e6f-e180-40c3-89ae-e61de58f9b9a",
        "parentId" : "8c26c529-ad8d-473c-af82-4670b58e0ad9",
        "authorId" : "cce1c782-0596-44b6-8b99-6b77d2cca53c",
        "body" : "> Sorry I don't get why we don't worry about shuffled hash join OOM if sub-query is way too big/skewed in certain keys. In general, shuffled hash join OOM is a normal issue if people choose shuffled hash join blindly. Could we add a check to make sure build size is not too big to be shuffled hash join?\r\n> \r\n> e.g.\r\n> \r\n> ```\r\n> if (!canBroadcastBySize(j.right, conf) && canBuildLocalHashMapBySize(j.right, conf) && conf.adaptiveExecutionEnabled) {\r\n>   ...\r\n> }\r\n> ```\r\n\r\nDo you have any contact that I can offline communicate with you maybe, maybe you can reach me with my WeChat \"18518298234\"",
        "createdAt" : "2020-08-19T03:42:33Z",
        "updatedAt" : "2020-09-04T08:12:16Z",
        "lastEditedBy" : "cce1c782-0596-44b6-8b99-6b77d2cca53c",
        "tags" : [
        ]
      }
    ],
    "commit" : "51cec86843bc8088498df24601a1e4cc2fca86c1",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +236,240 @@\n      case j @ ExtractSingleColumnNullAwareAntiJoin(leftKeys, rightKeys) =>\n        if (!canBroadcastBySize(j.right, conf) && conf.adaptiveExecutionEnabled) {\n          Seq(joins.ShuffledHashJoinExec(leftKeys, rightKeys, LeftAnti, BuildRight,\n            None, planLater(j.left), planLater(j.right), isNullAwareAntiJoin = true))"
  },
  {
    "id" : "ace92705-38f8-4ed4-8427-bdb5b37784bd",
    "prId" : 29455,
    "prUrl" : "https://github.com/apache/spark/pull/29455#pullrequestreview-471082594",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4a519089-b271-4f21-9a31-c17e3e59e675",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "We should also update the doc of `spark.sql.optimizeNullAwareAntiJoin`. It is not only `BroadcastHashJoinExec` now.",
        "createdAt" : "2020-08-19T19:51:13Z",
        "updatedAt" : "2020-09-04T08:12:16Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "41dd1e1f-e128-453a-9e47-f2c7c774edce",
        "parentId" : "4a519089-b271-4f21-9a31-c17e3e59e675",
        "authorId" : "cce1c782-0596-44b6-8b99-6b77d2cca53c",
        "body" : "OK.",
        "createdAt" : "2020-08-20T02:20:37Z",
        "updatedAt" : "2020-09-04T08:12:16Z",
        "lastEditedBy" : "cce1c782-0596-44b6-8b99-6b77d2cca53c",
        "tags" : [
        ]
      }
    ],
    "commit" : "51cec86843bc8088498df24601a1e4cc2fca86c1",
    "line" : 3,
    "diffHunk" : "@@ -1,1 +235,239 @@          .getOrElse(createJoinWithoutHint())\n\n      case j @ ExtractSingleColumnNullAwareAntiJoin(leftKeys, rightKeys) =>\n        if (!canBroadcastBySize(j.right, conf) && conf.adaptiveExecutionEnabled) {\n          Seq(joins.ShuffledHashJoinExec(leftKeys, rightKeys, LeftAnti, BuildRight,"
  },
  {
    "id" : "f8204a5a-d3b2-4325-ac72-7e5e869ae30a",
    "prId" : 29342,
    "prUrl" : "https://github.com/apache/spark/pull/29342#pullrequestreview-467005565",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3a9b53c7-4d05-4580-ac3b-3a0931b05455",
        "parentId" : null,
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "Should we add some commentary about what is meant by \"hash map\" here ? Is it the hash map you are using for storing the matched-bits or is it the build hash table ? (something true of all hash joins ?) ",
        "createdAt" : "2020-08-13T17:06:23Z",
        "updatedAt" : "2020-08-16T18:24:08Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      },
      {
        "id" : "c2fb58e3-cce3-4e36-a683-baa661f02557",
        "parentId" : "3a9b53c7-4d05-4580-ac3b-3a0931b05455",
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "@agrawaldevesh - I am referring to same \"hash map\" as stated in other place in this file e.g. [other comment](https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/SparkStrategies.scala#L156).",
        "createdAt" : "2020-08-13T18:44:50Z",
        "updatedAt" : "2020-08-16T18:24:08Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      }
    ],
    "commit" : "526709b73b87687f48f68486b9c8c7be0866291f",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +118,122 @@   *     Only supported for equi-joins, while the join keys do not need to be sortable.\n   *     Supported for all join types.\n   *     Building hash map from table is a memory-intensive operation and it could cause OOM\n   *     when the build side is big.\n   *"
  },
  {
    "id" : "c6cb7c90-f090-4e19-8192-58689bff6267",
    "prId" : 29035,
    "prUrl" : "https://github.com/apache/spark/pull/29035#pullrequestreview-446171563",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3202ede2-b9d6-47f8-bade-0dcdd9f52856",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "good catch!",
        "createdAt" : "2020-07-10T07:12:54Z",
        "updatedAt" : "2020-07-10T07:12:55Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "d9b4dcd5664d27ef50606ae30abdeeac7356e25e",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +200,204 @@        def createCartesianProduct() = {\n          if (joinType.isInstanceOf[InnerLike]) {\n            Some(Seq(joins.CartesianProductExec(planLater(left), planLater(right), p.condition)))\n          } else {\n            None"
  },
  {
    "id" : "431a9f64-0f56-4eec-983e-f87f65fde8b8",
    "prId" : 29035,
    "prUrl" : "https://github.com/apache/spark/pull/29035#pullrequestreview-447022864",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8d263851-b155-4ac8-9429-e6663bfe1a3e",
        "parentId" : null,
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "We need to write a comment above this line and explain what it is doing. \r\n// instead of using the condition extracted by ExtractEquiJoinKeys, we should use the original join condition, i.e., \"p.condition\". ",
        "createdAt" : "2020-07-13T07:05:50Z",
        "updatedAt" : "2020-07-13T07:05:50Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      },
      {
        "id" : "035b4a37-4045-4295-a9bf-ec6eb7934c9b",
        "parentId" : "8d263851-b155-4ac8-9429-e6663bfe1a3e",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> We need to write a comment above this line and explain what it is doing.\r\n> // instead of using the condition extracted by ExtractEquiJoinKeys, we should use the original join condition, i.e., \"p.condition\".\r\n\r\nRaise a PR  https://github.com/apache/spark/pull/29084",
        "createdAt" : "2020-07-13T08:13:41Z",
        "updatedAt" : "2020-07-13T08:13:42Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "d9b4dcd5664d27ef50606ae30abdeeac7356e25e",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +200,204 @@        def createCartesianProduct() = {\n          if (joinType.isInstanceOf[InnerLike]) {\n            Some(Seq(joins.CartesianProductExec(planLater(left), planLater(right), p.condition)))\n          } else {\n            None"
  },
  {
    "id" : "53b251f2-bd64-4ed0-af97-47041951d3ee",
    "prId" : 29035,
    "prUrl" : "https://github.com/apache/spark/pull/29035#pullrequestreview-447020629",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a7dca8d0-158d-4608-9fbb-7e2c7472f446",
        "parentId" : null,
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "To avoid making the similar mistakes, we need to rename `condition` to a self-descriptive name. \"otherConditions\"? It is a little bit hard to name it TBH\r\n",
        "createdAt" : "2020-07-13T07:11:26Z",
        "updatedAt" : "2020-07-13T07:11:26Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      }
    ],
    "commit" : "d9b4dcd5664d27ef50606ae30abdeeac7356e25e",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +160,164 @@      //   5. Pick broadcast nested loop join as the final solution. It may OOM but we don't have\n      //      other choice.\n      case p @ ExtractEquiJoinKeys(joinType, leftKeys, rightKeys, condition, left, right, hint) =>\n        def createBroadcastHashJoin(onlyLookingAtHint: Boolean) = {\n          getBroadcastBuildSide(left, right, joinType, hint, onlyLookingAtHint, conf).map {"
  },
  {
    "id" : "927552d0-7e4f-4565-a3d0-dbb6502af684",
    "prId" : 28919,
    "prUrl" : "https://github.com/apache/spark/pull/28919#pullrequestreview-436851358",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6146e107-b841-4575-a3cc-c8e70bed0889",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "So, this references the original `e` (before `NormalizeFloatingNumbers`)?",
        "createdAt" : "2020-06-24T17:13:09Z",
        "updatedAt" : "2020-06-29T04:45:45Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "f3afc467-9c32-4287-94e0-e88b4b92065f",
        "parentId" : "6146e107-b841-4575-a3cc-c8e70bed0889",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Yes",
        "createdAt" : "2020-06-24T17:18:30Z",
        "updatedAt" : "2020-06-29T04:45:45Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "b6a96ea975f795981ca4a25e32eccf8c1df9a6b2",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +464,468 @@                case other =>\n                  // Keep the name of the original expression.\n                  val name = e match {\n                    case ne: NamedExpression => ne.name\n                    case _ => e.toString"
  }
]