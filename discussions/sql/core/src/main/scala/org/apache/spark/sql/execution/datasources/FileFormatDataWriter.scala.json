[
  {
    "id" : "9bf8f12c-7a4b-4bf5-8cf6-39efa0fff7b8",
    "prId" : 33239,
    "prUrl" : "https://github.com/apache/spark/pull/33239#pullrequestreview-710162665",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9e13e67b-f5df-4ede-b614-9f628295a4b3",
        "parentId" : null,
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "Shall we add tests for the changes in this File? ",
        "createdAt" : "2021-07-19T13:15:27Z",
        "updatedAt" : "2021-07-19T13:15:27Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "4d8092d2-d6d8-4798-b5ab-11ccf0230224",
        "parentId" : "9e13e67b-f5df-4ede-b614-9f628295a4b3",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Let me try to add one.",
        "createdAt" : "2021-07-19T21:58:57Z",
        "updatedAt" : "2021-07-19T21:58:57Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "3a63701e-6526-4f15-8fb2-79a330b2fd7b",
        "parentId" : "9e13e67b-f5df-4ede-b614-9f628295a4b3",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "I added custom metric for writing to InMemory table for test purpose. The tests are in `FileFormatDataWriterMetricSuite`.",
        "createdAt" : "2021-07-20T04:16:57Z",
        "updatedAt" : "2021-07-20T04:16:57Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "25cc5463d1cb45f81125d45d54100bd0e3dfbffe",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +44,48 @@    taskAttemptContext: TaskAttemptContext,\n    committer: FileCommitProtocol,\n    customMetrics: Map[String, SQLMetric]) extends DataWriter[InternalRow] {\n  /**\n   * Max number of files a single task writes out due to file size. In most cases the number of"
  },
  {
    "id" : "2db4c8eb-eada-4c97-be15-6613868e5a13",
    "prId" : 33239,
    "prUrl" : "https://github.com/apache/spark/pull/33239#pullrequestreview-710223209",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5c1c0f49-489a-4cce-942b-e41ab0141c85",
        "parentId" : null,
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "could we have something like:\r\n```scala\r\ndef writeWithMetrics(record: InternalRow): Unit = {\r\n  if (count % CustomMetrics.NUM_ROWS_PER_UPDATE == 0) {\r\n    CustomMetrics.updateMetrics(currentMetricsValues, customMetrics)\r\n  }\r\n  count += 1\r\n  write(record)\r\n}\r\n```\r\nand then update all the places to use this? instead of replicating the code in several places?\r\n",
        "createdAt" : "2021-07-20T06:16:16Z",
        "updatedAt" : "2021-07-20T06:27:04Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "3d280b3f-2eba-4d2c-b694-cff15979cef8",
        "parentId" : "5c1c0f49-489a-4cce-942b-e41ab0141c85",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "sounds good. let me update.",
        "createdAt" : "2021-07-20T06:38:55Z",
        "updatedAt" : "2021-07-20T06:38:56Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "25cc5463d1cb45f81125d45d54100bd0e3dfbffe",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +88,92 @@  /** Write an iterator of records. */\n  def writeWithIterator(iterator: Iterator[InternalRow]): Unit = {\n    var count = 0L\n    while (iterator.hasNext) {\n      writeWithMetrics(iterator.next(), count)"
  }
]