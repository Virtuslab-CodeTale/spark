[
  {
    "id" : "fb9bf9e6-94a3-4efc-9309-f33c8b24f463",
    "prId" : 25600,
    "prUrl" : "https://github.com/apache/spark/pull/25600#pullrequestreview-296626770",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7e12741f-05d0-4a55-8062-5769388aa14a",
        "parentId" : null,
        "authorId" : "a269db99-bf49-44c7-9b33-056e49f21bc5",
        "body" : "we shouldn't create a top level package for non-user facing stuff. Either put this into catalyst or execution.\r\n",
        "createdAt" : "2019-10-02T20:56:30Z",
        "updatedAt" : "2019-10-02T20:56:31Z",
        "lastEditedBy" : "a269db99-bf49-44c7-9b33-056e49f21bc5",
        "tags" : [
        ]
      },
      {
        "id" : "6396443f-08a3-4987-8a1f-a4db19d7a2cd",
        "parentId" : "7e12741f-05d0-4a55-8062-5769388aa14a",
        "authorId" : "a269db99-bf49-44c7-9b33-056e49f21bc5",
        "body" : "maybe put it in execution.adaptive",
        "createdAt" : "2019-10-02T20:57:11Z",
        "updatedAt" : "2019-10-02T20:57:11Z",
        "lastEditedBy" : "a269db99-bf49-44c7-9b33-056e49f21bc5",
        "tags" : [
        ]
      },
      {
        "id" : "c59baabc-527c-4ad0-87cd-f77162d6fc69",
        "parentId" : "7e12741f-05d0-4a55-8062-5769388aa14a",
        "authorId" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "body" : "This isn't about PlanDynamicPruningFilter, which could have been put in sql.execution. It's more about `PartitionPruning`, which has to match logical scan nodes, and they are in spark-sql (which I don't like but can't do anything about). Then I was left to struggle where to put this logical rule in spark-sql. Package `execution` seems more for physical stuff, and definitely I wouldn't want to mix DPP classes in the `adaptive` package.",
        "createdAt" : "2019-10-02T21:09:11Z",
        "updatedAt" : "2019-10-02T21:09:11Z",
        "lastEditedBy" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "tags" : [
        ]
      },
      {
        "id" : "ad07aef8-5c04-4d54-8ad2-cb6e0759a5f2",
        "parentId" : "7e12741f-05d0-4a55-8062-5769388aa14a",
        "authorId" : "a269db99-bf49-44c7-9b33-056e49f21bc5",
        "body" : "OK in either case I wouldn't put it as a new top level package.\r\n",
        "createdAt" : "2019-10-02T21:14:08Z",
        "updatedAt" : "2019-10-02T21:14:09Z",
        "lastEditedBy" : "a269db99-bf49-44c7-9b33-056e49f21bc5",
        "tags" : [
        ]
      },
      {
        "id" : "9debd6a7-df8a-4b32-9821-6b8acde43c7e",
        "parentId" : "7e12741f-05d0-4a55-8062-5769388aa14a",
        "authorId" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "body" : "I'll submit a follow-up to move the package.",
        "createdAt" : "2019-10-03T03:29:06Z",
        "updatedAt" : "2019-10-03T03:29:07Z",
        "lastEditedBy" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "tags" : [
        ]
      }
    ],
    "commit" : "b00225078c6471b5b01f8a920ab28a2361b8e48b",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +16,20 @@ */\n\npackage org.apache.spark.sql.dynamicpruning\n\nimport org.apache.spark.sql.SparkSession"
  }
]