[
  {
    "id" : "7dff44de-f01b-4e47-942f-341ee0927e2c",
    "prId" : 24981,
    "prUrl" : "https://github.com/apache/spark/pull/24981#pullrequestreview-291522288",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3900449e-48b3-4de9-812c-c227b7cae065",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Why did we do such refactoring in this PR? it should better be separate; otherwise, it's hard to follow the changes.",
        "createdAt" : "2019-09-22T12:45:16Z",
        "updatedAt" : "2019-09-22T12:45:16Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "b5877770-8dc3-42c9-807b-b5e59d1b4184",
        "parentId" : "3900449e-48b3-4de9-812c-c227b7cae065",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "One thing we should consider is, R vectorized code path is matched with Python side. We should think about that before generalizing it - my goal was that deduplicating both code paths.",
        "createdAt" : "2019-09-22T12:45:55Z",
        "updatedAt" : "2019-09-22T12:45:56Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "158ddb7e-0a5b-48d3-aba6-4ed9aa19c32c",
        "parentId" : "3900449e-48b3-4de9-812c-c227b7cae065",
        "authorId" : "0c293c45-22a6-4358-8a40-adbf7c470575",
        "body" : "I think the changes were pretty straightforward to support the feature, mainly to be able to read back results the same way as group map udfs. I didn't consider this to be major refactoring, so making a complete copy of the python runner seemed a little excessive. Otherwise I would agree to keep things separate.\r\n\r\n>We should think about that before generalizing it - my goal was that deduplicating both code paths.\r\n\r\nThis sounds like a good idea, it shouldn't really matter if writing to Python or R, and would be good to deduplicate.",
        "createdAt" : "2019-09-22T19:00:44Z",
        "updatedAt" : "2019-09-22T19:00:44Z",
        "lastEditedBy" : "0c293c45-22a6-4358-8a40-adbf7c470575",
        "tags" : [
        ]
      }
    ],
    "commit" : "1b966fda46c5334cf7963bae0bece159c9568622",
    "line" : 37,
    "diffHunk" : "@@ -1,1 +35,39 @@ * Common functionality for a udf runner that exchanges data with Python worker via Arrow stream.\n */\nabstract class BaseArrowPythonRunner[T](\n    funcs: Seq[ChainedPythonFunctions],\n    evalType: Int,"
  },
  {
    "id" : "32522eaf-ec1b-441c-b225-42ff7cb22710",
    "prId" : 24965,
    "prUrl" : "https://github.com/apache/spark/pull/24965#pullrequestreview-253903259",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "09ade300-c20c-42da-a290-5185b64f7e3c",
        "parentId" : null,
        "authorId" : "627d34e9-eba3-4504-aa67-ffc2f967c413",
        "body" : "\r\n\r\nThis is just some common stuff that I needed for both the new Data passing mechanism and the existing (Arrow Streaming mechanism). I've broken it out her mainly because made it easier for me to track what new functionality I'd actually added. I don't think a proper solution would really have this class hierarchy.\r\n",
        "createdAt" : "2019-06-25T10:09:57Z",
        "updatedAt" : "2019-07-02T08:59:40Z",
        "lastEditedBy" : "627d34e9-eba3-4504-aa67-ffc2f967c413",
        "tags" : [
        ]
      }
    ],
    "commit" : "d15dabbf71ad3007ea0c37e71c997e6fa1799e51",
    "line" : 35,
    "diffHunk" : "@@ -1,1 +33,37 @@\n\nabstract class BaseArrowPythonRunner[T](\n                         funcs: Seq[ChainedPythonFunctions],\n                         evalType: Int,"
  }
]