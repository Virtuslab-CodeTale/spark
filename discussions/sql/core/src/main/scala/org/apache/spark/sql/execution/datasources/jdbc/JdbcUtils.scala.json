[
  {
    "id" : "136d0bbb-31ee-4ff4-b97e-692e8fcbfc08",
    "prId" : 31491,
    "prUrl" : "https://github.com/apache/spark/pull/31491#pullrequestreview-585132612",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "daa4aae5-8492-4081-867b-63882cc41961",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "@sarutak should we maybe update migration guide?",
        "createdAt" : "2021-02-07T02:41:03Z",
        "updatedAt" : "2021-02-17T01:59:57Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "79b3cc06-bd52-467a-8175-5e1d9c0e77c4",
        "parentId" : "daa4aae5-8492-4081-867b-63882cc41961",
        "authorId" : "3a227965-84e0-47cf-9974-11293764f028",
        "body" : "Thanks. I've updated.",
        "createdAt" : "2021-02-08T03:02:00Z",
        "updatedAt" : "2021-02-17T01:59:57Z",
        "lastEditedBy" : "3a227965-84e0-47cf-9974-11293764f028",
        "tags" : [
        ]
      }
    ],
    "commit" : "73f53d91e609a7450819ee3bb14b81eee34d42f9",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +227,231 @@      case java.sql.Types.REF           => StringType\n      case java.sql.Types.REF_CURSOR    => null\n      case java.sql.Types.ROWID         => StringType\n      case java.sql.Types.SMALLINT      => IntegerType\n      case java.sql.Types.SQLXML        => StringType"
  },
  {
    "id" : "8e9ffbc7-f277-43d6-96b8-6cf28b7e481f",
    "prId" : 31491,
    "prUrl" : "https://github.com/apache/spark/pull/31491#pullrequestreview-588764025",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3ec69a0b-9577-4293-adce-5e9fd4b8f9eb",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "So basically we can't assume the row ID is <= 8 bytes? if that's true then I agree.",
        "createdAt" : "2021-02-11T16:28:23Z",
        "updatedAt" : "2021-02-17T01:59:57Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "779553ad-6874-4eed-9ca2-4ad1410de486",
        "parentId" : "3ec69a0b-9577-4293-adce-5e9fd4b8f9eb",
        "authorId" : "3a227965-84e0-47cf-9974-11293764f028",
        "body" : "Not only we can't assume the length of the ROWID but also it's not required to be represented as integer.\r\nJDBC RowId declares `getBytes` and `toString` to represent ROWID so I think we can safely map ROWID to StringType.\r\nhttps://docs.oracle.com/javase/8/docs/api/java/sql/RowId.html",
        "createdAt" : "2021-02-11T16:44:04Z",
        "updatedAt" : "2021-02-17T01:59:57Z",
        "lastEditedBy" : "3a227965-84e0-47cf-9974-11293764f028",
        "tags" : [
        ]
      }
    ],
    "commit" : "73f53d91e609a7450819ee3bb14b81eee34d42f9",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +227,231 @@      case java.sql.Types.REF           => StringType\n      case java.sql.Types.REF_CURSOR    => null\n      case java.sql.Types.ROWID         => StringType\n      case java.sql.Types.SMALLINT      => IntegerType\n      case java.sql.Types.SQLXML        => StringType"
  },
  {
    "id" : "8cc7af0e-c190-4ab1-8a2e-8ad148b08a4c",
    "prId" : 31264,
    "prUrl" : "https://github.com/apache/spark/pull/31264#pullrequestreview-576461282",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f3b22654-9ccd-49fc-9625-79b2423ac105",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "@MaxGekk, is this correct way `toJavaTimestamp(instantToMicros(row.getAs[Instant](pos)))`?",
        "createdAt" : "2021-01-26T14:17:27Z",
        "updatedAt" : "2021-01-29T06:35:41Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "019c5a4d-b721-41d5-a57e-eddfd78d80ee",
        "parentId" : "f3b22654-9ccd-49fc-9625-79b2423ac105",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "yes",
        "createdAt" : "2021-01-26T15:24:37Z",
        "updatedAt" : "2021-01-29T06:35:41Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "6a5a4b7de4bcd85a32d7544c7887f3d12378e42e",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +589,593 @@      if (SQLConf.get.datetimeJava8ApiEnabled) {\n        (stmt: PreparedStatement, row: Row, pos: Int) =>\n          stmt.setTimestamp(pos + 1, toJavaTimestamp(instantToMicros(row.getAs[Instant](pos))))\n      } else {\n        (stmt: PreparedStatement, row: Row, pos: Int) =>"
  },
  {
    "id" : "22172ade-d07a-4d4e-92f7-3eba18f88cd3",
    "prId" : 31252,
    "prUrl" : "https://github.com/apache/spark/pull/31252#pullrequestreview-571933765",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5b0a1ed0-e1a2-47b7-97fd-d8273c9b306d",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "If this issue is only for postgresql, could you add this fix in `PostgresDialect`?",
        "createdAt" : "2021-01-20T00:20:52Z",
        "updatedAt" : "2021-01-20T00:20:52Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "4e299472-8501-41b1-8de6-9d5b8308a9e6",
        "parentId" : "5b0a1ed0-e1a2-47b7-97fd-d8273c9b306d",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "+1 for @maropu 's advice.",
        "createdAt" : "2021-01-20T03:36:44Z",
        "updatedAt" : "2021-01-20T03:36:45Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "0b9371ef-4ef6-4d46-a982-bb06073ee535",
        "parentId" : "5b0a1ed0-e1a2-47b7-97fd-d8273c9b306d",
        "authorId" : "137b17b4-9571-4fa2-a8d5-4b3d15930469",
        "body" : "The only way `fieldScale` can make it into the dialect is by the field metadata.\r\nIt was always added prior to the previous commit (which I agree with on a fundamental level)\r\nhttps://github.com/skestle/spark/commit/0b647fe69cf201b4dcbc0f4dfc0eb504a523571d#diff-c3859e97335ead4b131263565c987d877bea0af3adbd6c5bf2d3716768d2e083",
        "createdAt" : "2021-01-20T06:15:40Z",
        "updatedAt" : "2021-01-20T06:15:40Z",
        "lastEditedBy" : "137b17b4-9571-4fa2-a8d5-4b3d15930469",
        "tags" : [
        ]
      },
      {
        "id" : "8e0c3341-5455-4057-8226-8b20a99be9d5",
        "parentId" : "5b0a1ed0-e1a2-47b7-97fd-d8273c9b306d",
        "authorId" : "4a21ee68-297a-45ce-ad3f-eebc5801c797",
        "body" : "I've explained a few more rationale regarding this change proposed by @skestle in the comment below https://github.com/apache/spark/pull/31252#discussion_r560730953",
        "createdAt" : "2021-01-20T07:31:48Z",
        "updatedAt" : "2021-01-20T07:31:48Z",
        "lastEditedBy" : "4a21ee68-297a-45ce-ad3f-eebc5801c797",
        "tags" : [
        ]
      }
    ],
    "commit" : "9fe9769809b177a9967b195ecf78a3717e1cfd8f",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +314,318 @@        case java.sql.Types.NUMERIC => metadata.putLong(\"scale\", fieldScale)\n        case java.sql.Types.DECIMAL => metadata.putLong(\"scale\", fieldScale)\n        case java.sql.Types.ARRAY   => metadata.putLong(\"scale\", fieldScale) // PostgresDialect.scala wants this information\n        case java.sql.Types.TIME    => metadata.putBoolean(\"logical_time_type\", true)\n        case _                      =>"
  },
  {
    "id" : "37b00370-8502-4730-9dc0-4b7d7d03df91",
    "prId" : 31252,
    "prUrl" : "https://github.com/apache/spark/pull/31252#pullrequestreview-572009023",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "94e0b84a-aa72-421c-817f-3330e89d2e09",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can we always include the scale metadata if it's present? cc @saikocat",
        "createdAt" : "2021-01-20T05:37:50Z",
        "updatedAt" : "2021-01-20T05:37:50Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "6967d7b4-b28d-4d4e-8e87-04049823044e",
        "parentId" : "94e0b84a-aa72-421c-817f-3330e89d2e09",
        "authorId" : "4a21ee68-297a-45ce-ad3f-eebc5801c797",
        "body" : "We can do that for simplification. But we need to fix the tests for the rest of the dialects. Cos it adds `{\"scale\": 0}` to all metadata, then existing tests failed (previously metadata didn't get build in getSchema(), so the JSON meta didn't generated)\r\n\r\nThat's why I choose to set it to only decimal and numeric. The problem also eluded me cos the test for array in Postgresql dialects call the toCalaystType directly instead of going through the code path of using metadata. Sorry on phone so it's hard for me to link the line.",
        "createdAt" : "2021-01-20T05:57:20Z",
        "updatedAt" : "2021-01-20T05:57:21Z",
        "lastEditedBy" : "4a21ee68-297a-45ce-ad3f-eebc5801c797",
        "tags" : [
        ]
      },
      {
        "id" : "76521966-5fd5-4822-abf1-327b19efcf5f",
        "parentId" : "94e0b84a-aa72-421c-817f-3330e89d2e09",
        "authorId" : "4a21ee68-297a-45ce-ad3f-eebc5801c797",
        "body" : "Alright, let me elaborate more so you two (cc: @skestle) can decide on which approach to go for. Though I'm kind of favor the current approach of adding data type matching for adding scale metadata cos fixing the failing tests will be more difficult and it makes the JDBCSuite test `\"jdbc data source shouldn't have unnecessary metadata in its schema\"` test slightly lose its meaning. \r\n\r\nSo in order to push \"logical_time_type\" to metadata, I have to force metadata to be built in the field type as of here:\r\nhttps://github.com/skestle/spark/commit/0b647fe69cf201b4dcbc0f4dfc0eb504a523571d#diff-c3859e97335ead4b131263565c987d877bea0af3adbd6c5bf2d3716768d2e083R323 whereas previously, metadata can be built  by the dialect or completely ignored (as default)\r\n\r\nThis will cause 3 tests in `JDBCSuite` to fail cause of schema mismatch (extra `{\"scale\": 0}` in the metadata always present) [1. `\"jdbc API support custom schema\"`, 2. `\"jdbc API custom schema DDL-like strings.\"`, 3. `\"jdbc data source shouldn't have unnecessary metadata in its schema\"`]. ",
        "createdAt" : "2021-01-20T07:29:37Z",
        "updatedAt" : "2021-01-20T07:29:37Z",
        "lastEditedBy" : "4a21ee68-297a-45ce-ad3f-eebc5801c797",
        "tags" : [
        ]
      },
      {
        "id" : "aff02065-b2a1-4d93-9480-7daaa1d9f4c0",
        "parentId" : "94e0b84a-aa72-421c-817f-3330e89d2e09",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "> whereas previously, metadata can be built by the dialect or completely ignored (as default)\r\n\r\nIf it was dialect's responsibility to put things into metadata before, I think this PR should put the fix in `PostgresDialect`.",
        "createdAt" : "2021-01-20T09:00:40Z",
        "updatedAt" : "2021-01-20T09:00:40Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "9b92c4e3-ce6d-4052-9554-c217ac491bae",
        "parentId" : "94e0b84a-aa72-421c-817f-3330e89d2e09",
        "authorId" : "4a21ee68-297a-45ce-ad3f-eebc5801c797",
        "body" : "But the only way `fieldScale` can make it into the dialect is by the field metadata. So it is a very chicken and egg problem. \r\n\r\nEDIT: Postgresql utilize the metadatabuilder to get the scale for array[][] of type numeric for example - cos dataType is `ARRAY ` but the typeName is `_numeric` - note the underscore specific for Postgresql. Whereas MySQL dialect is putting more info into the metadata (like put(\"binarylong\")). The use cases differ.\r\n\r\nMight have to change the interface somehow to let the ResultSetMetadata to be passed or init-ed to the dialect. ",
        "createdAt" : "2021-01-20T09:08:38Z",
        "updatedAt" : "2021-01-20T09:16:18Z",
        "lastEditedBy" : "4a21ee68-297a-45ce-ad3f-eebc5801c797",
        "tags" : [
        ]
      }
    ],
    "commit" : "9fe9769809b177a9967b195ecf78a3717e1cfd8f",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +307,311 @@      val metadata = new MetadataBuilder()\n      // SPARK-33888\n      // - include scale in metadata for only DECIMAL & NUMERIC as well as ARRAY (for Postgres)\n      // - include TIME type metadata\n      // - always build the metadata"
  }
]