[
  {
    "id" : "f042a9de-3561-4321-b78a-fb9b53e130f6",
    "prId" : 25771,
    "prUrl" : "https://github.com/apache/spark/pull/25771#pullrequestreview-291472743",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e7b362fd-b865-4490-a096-e7dda03485d2",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "why not use `CurrentCatalogAndNamespace`?",
        "createdAt" : "2019-09-19T03:02:04Z",
        "updatedAt" : "2019-10-02T08:17:09Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "e226f493-86d2-4470-b220-4d0eb4bca3d7",
        "parentId" : "e7b362fd-b865-4490-a096-e7dda03485d2",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "Yes `CurrentCatalogAndNamespace` can be now used as session catalog supports namespaces.",
        "createdAt" : "2019-09-21T16:58:21Z",
        "updatedAt" : "2019-10-02T08:17:10Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "84856190f5bf7f7865ce3428986cca61471c9845",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +179,183 @@\n    case ShowNamespacesStatement(Some(namespace), pattern) =>\n      val DefaultCatalogAndNamespace(maybeCatalog, ns) = namespace\n      maybeCatalog match {\n        case Some(catalog) =>"
  },
  {
    "id" : "125e006a-e2bf-4678-9183-afb285b0202d",
    "prId" : 25771,
    "prUrl" : "https://github.com/apache/spark/pull/25771#pullrequestreview-291473389",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "19bcfb49-e4a7-4e48-8956-a688555a8304",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ditto",
        "createdAt" : "2019-09-19T03:02:12Z",
        "updatedAt" : "2019-10-02T08:17:09Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "70f7d760-7bad-4f01-9060-15f140deb4a9",
        "parentId" : "19bcfb49-e4a7-4e48-8956-a688555a8304",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "OK. I updated to use `CurrentCatalogAndNamespace`. This will not fall back to `ShowTablesCommand` and there will be no `isTemporary` column any longer. This should be OK, right?",
        "createdAt" : "2019-09-21T17:17:56Z",
        "updatedAt" : "2019-10-02T08:17:10Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "84856190f5bf7f7865ce3428986cca61471c9845",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +203,207 @@\n    case ShowTablesStatement(Some(namespace), pattern) =>\n      val DefaultCatalogAndNamespace(maybeCatalog, ns) = namespace\n      maybeCatalog match {\n        case Some(catalog) =>"
  },
  {
    "id" : "2fe02e61-8068-48d9-b960-e574d4c0179d",
    "prId" : 25601,
    "prUrl" : "https://github.com/apache/spark/pull/25601#pullrequestreview-285885998",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "15049550-8d7d-44f6-b42e-0e778f56d50f",
        "parentId" : null,
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "I think this needs to distinguish between the case where the catalog is None and the catalog does not support namespaces. For the second case, this should report that the catalog doesn't support namespaces. You can also add a conversion method, `asNamespaceCatalog` to `CatalogV2Utils` like `asTableCatalog`.",
        "createdAt" : "2019-09-04T21:57:05Z",
        "updatedAt" : "2019-09-09T23:58:04Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "36bf4884-d941-4040-8aae-5597c31b783f",
        "parentId" : "15049550-8d7d-44f6-b42e-0e778f56d50f",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "Using `asNamespaceCatalog` simplifies the matching. Thanks.",
        "createdAt" : "2019-09-04T23:59:00Z",
        "updatedAt" : "2019-09-09T23:58:04Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      },
      {
        "id" : "7f25d28b-a64c-47d6-8daa-f714c0675a8b",
        "parentId" : "15049550-8d7d-44f6-b42e-0e778f56d50f",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "Why not use the current catalog instead of failing?",
        "createdAt" : "2019-09-06T21:38:49Z",
        "updatedAt" : "2019-09-09T23:58:04Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "4282111a-f240-4ea9-8665-852634d1a281",
        "parentId" : "15049550-8d7d-44f6-b42e-0e778f56d50f",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "If the catalog name is specified, but catalog doesn't support namespace, I think we should fail instead of falling back to the current catalog.\r\n\r\nIt's similar to: if the catalog name is specified, but doesn't contain the table we need, we should fail instead of falling back to the current catalog.",
        "createdAt" : "2019-09-10T03:14:38Z",
        "updatedAt" : "2019-09-10T03:14:38Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "9a55a03acf84fe67595817c8fef409a9e4912a51",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +184,188 @@          ShowNamespaces(catalog.asNamespaceCatalog, Some(ns), pattern)\n        case None =>\n          throw new AnalysisException(\n            s\"No v2 catalog is available for ${namespace.quoted}\")\n      }"
  },
  {
    "id" : "a6096db7-ee44-4ad1-8ba6-d1a4b0931f32",
    "prId" : 25601,
    "prUrl" : "https://github.com/apache/spark/pull/25601#pullrequestreview-286530033",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "46d73852-3896-495e-abef-1aa3101afba3",
        "parentId" : null,
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "I think this should be `currentCatalog` instead. @cloud-fan, do you agree?",
        "createdAt" : "2019-09-06T21:38:12Z",
        "updatedAt" : "2019-09-09T23:58:04Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "577c5c2d-6590-4b09-9181-6d3d9589cbd5",
        "parentId" : "46d73852-3896-495e-abef-1aa3101afba3",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "yea",
        "createdAt" : "2019-09-10T03:10:08Z",
        "updatedAt" : "2019-09-10T03:10:08Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "59f3542e-ee1c-4ff7-8727-66ef387b7f3c",
        "parentId" : "46d73852-3896-495e-abef-1aa3101afba3",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Let's implement switching the current catalog first, otherwise we are not able to test it.",
        "createdAt" : "2019-09-10T13:19:47Z",
        "updatedAt" : "2019-09-10T13:19:47Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "dc97ec07-3dc7-4cdc-a661-efaad81bf816",
        "parentId" : "46d73852-3896-495e-abef-1aa3101afba3",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "@imback82 are you working on it?",
        "createdAt" : "2019-09-10T13:25:01Z",
        "updatedAt" : "2019-09-10T13:25:02Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "87387512-98d1-45c1-b0f1-bc634ea6fe4a",
        "parentId" : "46d73852-3896-495e-abef-1aa3101afba3",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "yes, I am working on `USE NAMESPACE`",
        "createdAt" : "2019-09-10T23:13:52Z",
        "updatedAt" : "2019-09-10T23:13:53Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      },
      {
        "id" : "8ea3bd77-2b49-4490-aae0-73338b0349db",
        "parentId" : "46d73852-3896-495e-abef-1aa3101afba3",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "I should be able to send out the PR sometime tomorrow.",
        "createdAt" : "2019-09-11T02:46:22Z",
        "updatedAt" : "2019-09-11T02:46:22Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "9a55a03acf84fe67595817c8fef409a9e4912a51",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +171,175 @@\n    case ShowNamespacesStatement(None, pattern) =>\n      defaultCatalog match {\n        case Some(catalog) =>\n          ShowNamespaces(catalog.asNamespaceCatalog, None, pattern)"
  },
  {
    "id" : "3f30775d-db2e-4ff6-966e-2c14145a4d4e",
    "prId" : 25465,
    "prUrl" : "https://github.com/apache/spark/pull/25465#pullrequestreview-278159880",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2f61a46f-947e-4639-bedd-646c63544b0e",
        "parentId" : null,
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "If this logic were in `lookupDataSourceV2`, I don't think this case would be required.",
        "createdAt" : "2019-08-21T21:26:08Z",
        "updatedAt" : "2019-08-27T05:48:29Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "7b7c3a08-cb01-44c1-8b38-dca4932c4408",
        "parentId" : "2f61a46f-947e-4639-bedd-646c63544b0e",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "see https://github.com/apache/spark/pull/25465/files#r316472026",
        "createdAt" : "2019-08-22T02:14:42Z",
        "updatedAt" : "2019-08-27T05:48:29Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "d9f664438417ee8f4bb952d41f53c8c0b0e8d500",
    "line" : 76,
    "diffHunk" : "@@ -1,1 +208,212 @@      DataSource.lookupDataSourceV2(provider, conf) match {\n        // TODO(SPARK-28396): Currently file source v2 can't work with tables.\n        case Some(_: FileDataSourceV2) => Some(provider)\n        case Some(_) => None\n        case _ => Some(provider)"
  },
  {
    "id" : "0b37c536-04dd-40d5-a5a4-63e74a241561",
    "prId" : 25247,
    "prUrl" : "https://github.com/apache/spark/pull/25247#pullrequestreview-273436306",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5c47f620-d414-4996-99e4-b6c95cb60f75",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "we can only fallback to the v1 show tables if `namespace.length == 1`. Otherwise we should fail and ask users to specify a valid database name.\r\n\r\n`SHOW TABLES a.b` fails in Spark 2.x, and it should still fail in Spark 3.0 if users do not set the default catalog.",
        "createdAt" : "2019-08-08T06:10:43Z",
        "updatedAt" : "2019-08-23T00:03:45Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "570724b5-aba7-4b9b-ac9d-fe52ed5af66f",
        "parentId" : "5c47f620-d414-4996-99e4-b6c95cb60f75",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "Added the check. Thanks for pointing it out.",
        "createdAt" : "2019-08-10T19:05:24Z",
        "updatedAt" : "2019-08-23T00:03:45Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "6f2fa4e7b8572a6b9dd243f1253e4962af27d40a",
    "line" : 39,
    "diffHunk" : "@@ -1,1 +202,206 @@              s\"The database name is not valid: ${namespace.quoted}\")\n          }\n          ShowTablesCommand(Some(namespace.quoted), pattern)\n      }\n  }"
  },
  {
    "id" : "4767ef0f-7dc3-408b-9eb7-f35b97020baa",
    "prId" : 25115,
    "prUrl" : "https://github.com/apache/spark/pull/25115#pullrequestreview-274653227",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "09c7a42e-2779-4976-be26-8881306726a3",
        "parentId" : null,
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "Since this always throws `AnalysisException`, I think this case should be removed. Instead, the next case should match and the `V2SessionCatalog` should be used. If the table loaded by the v2 session catalog doesn't support delete, then conversion to physical plan will fail when `asDeletable` is called.\r\n\r\nThen users can still call v2 deletes for formats like `parquet` that have a v2 implementation that will work.\r\n\r\nFYI @brkyvz.",
        "createdAt" : "2019-08-12T18:25:58Z",
        "updatedAt" : "2019-08-14T01:57:20Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "ac7176d6-d058-41de-83c4-5e6a496c11d9",
        "parentId" : "09c7a42e-2779-4976-be26-8881306726a3",
        "authorId" : "8afcf008-6988-44a5-92fa-2bef54bb4058",
        "body" : "Thank you @rdblue . Removed this case and fallback to `sessionCatalog` when `resolveTables` for `DeleteFromTable`.",
        "createdAt" : "2019-08-13T06:56:09Z",
        "updatedAt" : "2019-08-14T01:57:20Z",
        "lastEditedBy" : "8afcf008-6988-44a5-92fa-2bef54bb4058",
        "tags" : [
        ]
      },
      {
        "id" : "0974e767-e725-4d5d-acb3-c205fb89cc2b",
        "parentId" : "09c7a42e-2779-4976-be26-8881306726a3",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I think it's worse to move this case from here to https://github.com/apache/spark/pull/25115/files#diff-57b3d87be744b7d79a9beacf8e5e5eb2R657 .\r\n\r\nIf we can't merge these 2 cases into one here, let's keep it as it was.",
        "createdAt" : "2019-08-13T12:37:23Z",
        "updatedAt" : "2019-08-14T01:57:20Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "d69aeec2-e6c2-4547-b096-60e6a1bf34ca",
        "parentId" : "09c7a42e-2779-4976-be26-8881306726a3",
        "authorId" : "8afcf008-6988-44a5-92fa-2bef54bb4058",
        "body" : "If I understand correctly, one purpose of removing the first case is we can execute delete on `parquet` format via this API (if we implement it later) as @rdblue mentioned. The key point here is we resolve the table use `V2SessionCatalog` **as the fallback catalog**.  The original `resolveTable` doesn't give any fallback-to-sessionCatalog mechanism (if no catalog found, it will fallback to `resolveRelation`). So maybe we can modify `resolveTable` and let it treat `V2SessionCatalog` as a try option:\r\n```\r\ncase u @ UnresolvedRelation(CatalogObjectIdentifier(maybeCatalog, ident)) =>\r\n        maybeCatalog.orElse(sessionCatalog) match {\r\n          case Some(catalogPlugin) =>\r\n            loadTable(catalogPlugin, ident).map(DataSourceV2Relation.create).getOrElse(u)\r\n          case None =>\r\n            u\r\n        }\r\n```\r\n",
        "createdAt" : "2019-08-13T14:49:08Z",
        "updatedAt" : "2019-08-14T01:57:20Z",
        "lastEditedBy" : "8afcf008-6988-44a5-92fa-2bef54bb4058",
        "tags" : [
        ]
      },
      {
        "id" : "d51ac4aa-b0f1-464b-80de-00b350daa076",
        "parentId" : "09c7a42e-2779-4976-be26-8881306726a3",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "I don't think we need to update `ResolveTables`, though I do see that it would be nice to use `ResolveTables` as the only rule that resolves `UnresolvedRelation` for v2 tables.\r\n\r\nThere is already another rule that loads tables from a catalog, [`ResolveInsertInto`](https://github.com/apache/spark/blob/master/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/Analyzer.scala#L772).\r\n\r\nI considered updating that rule and moving the table resolution part into `ResolveTables` as well, but I think it is a little cleaner to resolve the table when converting the statement (in `DataSourceResolution`), as @cloud-fan is suggesting.\r\n\r\nOne of the reasons to do this for the insert plans is that those plans don't include the target relation as a child. Instead, those plans have the data to insert as a child node, which means that the unresolved relation won't be visible to the `ResolveTables` rule.\r\n\r\nTaking the same approach in this PR would also make this a little cleaner. If `DeleteFrom` didn't expose the relation as a child, it could be a `UnaryNode` and you wouldn't need to update some of the other rules to explicitly include `DeleteFrom`.",
        "createdAt" : "2019-08-13T17:10:38Z",
        "updatedAt" : "2019-08-14T01:57:20Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "6ab69cd6-27f9-4374-9879-3a4f1e251114",
        "parentId" : "09c7a42e-2779-4976-be26-8881306726a3",
        "authorId" : "8afcf008-6988-44a5-92fa-2bef54bb4058",
        "body" : "Okay, I rolled back the resolve rules for `DeleteFromTable` as it was as @cloud-fan suggested. For cases that like deleting from formats or `V2SessionCatalog` support, let's open another pr. And another pr for resolve rules is also need because I found other issues related with that. Does this sounds reasonable?",
        "createdAt" : "2019-08-14T02:05:37Z",
        "updatedAt" : "2019-08-14T02:05:37Z",
        "lastEditedBy" : "8afcf008-6988-44a5-92fa-2bef54bb4058",
        "tags" : [
        ]
      },
      {
        "id" : "ff34688e-cc6b-4602-b621-6399a01fbef4",
        "parentId" : "09c7a42e-2779-4976-be26-8881306726a3",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "We can remove this case after https://github.com/apache/spark/pull/25402, which updates `ResolveTable` to fallback to v2 session catalog.",
        "createdAt" : "2019-08-14T03:04:06Z",
        "updatedAt" : "2019-08-14T03:04:06Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "a3b6c1a1-112b-4821-a70b-507563e006c4",
        "parentId" : "09c7a42e-2779-4976-be26-8881306726a3",
        "authorId" : "8afcf008-6988-44a5-92fa-2bef54bb4058",
        "body" : "Saw the code in #25402 . I think it's the best choice.",
        "createdAt" : "2019-08-14T03:29:34Z",
        "updatedAt" : "2019-08-14T03:29:34Z",
        "lastEditedBy" : "8afcf008-6988-44a5-92fa-2bef54bb4058",
        "tags" : [
        ]
      }
    ],
    "commit" : "bbf515666495cbf5f12731b3cdab4a23960f3d77",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +175,179 @@\n    case DeleteFromStatement(AsTableIdentifier(table), tableAlias, condition) =>\n      throw new AnalysisException(\n        s\"Delete from tables is not supported using the legacy / v1 Spark external catalog\" +\n            s\" API. Identifier: $table.\")"
  },
  {
    "id" : "cd0c09c6-8eb4-4cff-85b2-a26cf6fc89fc",
    "prId" : 25040,
    "prUrl" : "https://github.com/apache/spark/pull/25040#pullrequestreview-259172212",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a93a211f-6df1-4908-bc00-42be9dc64d96",
        "parentId" : null,
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "Should this be supported eventually, or is it redundant if DESCRIBE TABLE is available?",
        "createdAt" : "2019-07-06T19:31:06Z",
        "updatedAt" : "2019-08-06T18:59:07Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "274f3a25-2c5c-4ca3-a161-e330b58b0208",
        "parentId" : "a93a211f-6df1-4908-bc00-42be9dc64d96",
        "authorId" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "body" : "Think we need to support it eventually if only to keep parity with V1 tables.",
        "createdAt" : "2019-07-08T21:42:13Z",
        "updatedAt" : "2019-08-06T18:59:07Z",
        "lastEditedBy" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "tags" : [
        ]
      }
    ],
    "commit" : "cff78a16e691917e812b4cd63bf7544a54af4742",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +101,105 @@    case DescribeColumnStatement(\n        CatalogObjectIdentifier(Some(catalog), ident), colName, isExtended) =>\n      throw new AnalysisException(\"Describing columns is not supported for v2 tables.\")\n\n    case DescribeTableStatement("
  },
  {
    "id" : "c15917f8-a603-43cc-b0a5-e5390616b1e9",
    "prId" : 24768,
    "prUrl" : "https://github.com/apache/spark/pull/24768#pullrequestreview-252915069",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3a7d7f8b-708f-42ff-a6eb-fa22cb593f9d",
        "parentId" : null,
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "Should it be default catalog instead of session catalog here? Or do you mean it should be V1 table here. It would be good to have some comments.",
        "createdAt" : "2019-06-13T16:01:52Z",
        "updatedAt" : "2019-07-09T17:36:34Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "6ccf3501-3472-4d66-acbc-235d4ff9911b",
        "parentId" : "3a7d7f8b-708f-42ff-a6eb-fa22cb593f9d",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "I've updated this:\r\n\r\n```\r\n  // the identifier had no catalog and no default catalog is set, but the source is\r\n  // use the v2 session catalog, which delegates to the global v1 session catalog\r\n```",
        "createdAt" : "2019-06-21T16:21:18Z",
        "updatedAt" : "2019-07-09T17:36:34Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      }
    ],
    "commit" : "4169a8760d6e358914071460c91f381d4ae89b0b",
    "line" : 59,
    "diffHunk" : "@@ -1,1 +69,73 @@          // the identifier had no catalog and no default catalog is set, but the source is v2.\n          // use the v2 session catalog, which delegates to the global v1 session catalog\n          convertCreateTable(v2SessionCatalog.asTableCatalog, identifier, create)\n      }\n"
  },
  {
    "id" : "2a02b9b5-c7f9-4018-bea6-6786c2d42d1e",
    "prId" : 24768,
    "prUrl" : "https://github.com/apache/spark/pull/24768#pullrequestreview-257201769",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7472d2a0-6541-4474-b834-ee9e21fcce02",
        "parentId" : null,
        "authorId" : "1f3c66ec-cc36-4a64-807a-476c6615e68c",
        "body" : "I don't know if there's anything to do about it in this PR, and maybe I'm misunderstanding, but I'm very concerned if we're inferring which catalogs do or don't exist based only on the shape of the query plan. Ideally we should be able to interpret query plans without needing to think about which catalogs exist, and directly check in the rare situations where it does matter.",
        "createdAt" : "2019-07-02T20:37:13Z",
        "updatedAt" : "2019-07-09T17:36:34Z",
        "lastEditedBy" : "1f3c66ec-cc36-4a64-807a-476c6615e68c",
        "tags" : [
        ]
      },
      {
        "id" : "feda90b1-5802-415f-9883-4feabf99546d",
        "parentId" : "7472d2a0-6541-4474-b834-ee9e21fcce02",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "Catalog existence is independent. A catalog exists if it is defined in Spark's configuration properties, `spark.sql.catalog.name=<implementation-class>`.\r\n\r\nAs far as the ability to interpret plans without knowing which catalogs exist, that would require being able to know which part of an identifier refers to a catalog up front. That means either always requiring a catalog, or always requiring a certain number of identifier parts. Because the need was to support external catalogs with an unknown number of namespaces and to provide backward compatibility with existing tables (e.g. the identifier `db.table` without a catalog), we need to look up the first identifier to check whether it is a catalog.\r\n\r\nI can give you more context if you'd like, but this decision was carefully considered and not really something we should revisit at this point.",
        "createdAt" : "2019-07-02T21:12:40Z",
        "updatedAt" : "2019-07-09T17:36:34Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "7dede293-9f18-45e8-88c2-e91cd05c2563",
        "parentId" : "7472d2a0-6541-4474-b834-ee9e21fcce02",
        "authorId" : "1f3c66ec-cc36-4a64-807a-476c6615e68c",
        "body" : "I agree with the design goals you're describing, and agree that we shouldn't revisit that decision here. (Even if I had a better solution in mind, which I don't.)\r\n\r\nI'm still confused about the \"there is no default v2 catalog\" part, though. How do we know that a CreateTableStatement matching this case can't exist when there's a default v2 catalog?",
        "createdAt" : "2019-07-02T22:59:59Z",
        "updatedAt" : "2019-07-09T17:36:34Z",
        "lastEditedBy" : "1f3c66ec-cc36-4a64-807a-476c6615e68c",
        "tags" : [
        ]
      },
      {
        "id" : "f5ebdf67-296b-4ebd-bcb0-fa668b708b52",
        "parentId" : "7472d2a0-6541-4474-b834-ee9e21fcce02",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "After this PR, the rules to determine the catalog responsible for an identifier are:\r\n\r\n1. If the identifier starts with a known catalog, use it\r\n2. If there is a configured default v2 catalog, use that catalog\r\n3. Otherwise, the session catalog is responsible for the identifier\r\n\r\nRules 1 and 2 are implemented in the `AsTableIdentifier` and `CatalogObjectIdentifier` extractors. So `AsTableIdentifier` is not going to match and convert to a v1 identifier if a v2 catalog is responsible for the table. In those cases, `CatalogObjectIdentifier` will always return a catalog and an `Identifier`.\r\n\r\nIf the session catalog is responsible for the identifier, then Spark needs to determine whether it should use the session catalog directly, or if it needs to use a v2 plan that uses the `V2SessionCatalog` because the source is v2. That's what the `V1WriteProvider` matcher determines.\r\n\r\nSo putting all of that together, we get that this rule will match when the source is v1 (use the session catalog directly), the identifier has no catalog (rule 1 is not the case), and there is no default v2 catalog (rule 2 is not the case).\r\n",
        "createdAt" : "2019-07-02T23:47:00Z",
        "updatedAt" : "2019-07-09T17:36:34Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      }
    ],
    "commit" : "4169a8760d6e358914071460c91f381d4ae89b0b",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +52,56 @@        AsTableIdentifier(table), schema, partitionCols, bucketSpec, properties,\n        V1WriteProvider(provider), options, location, comment, ifNotExists) =>\n      // the source is v1, the identifier has no catalog, and there is no default v2 catalog\n      val tableDesc = buildCatalogTable(table, schema, partitionCols, bucketSpec, properties,\n        provider, options, location, comment, ifNotExists)"
  },
  {
    "id" : "4addc74f-c60a-4ce7-ab4d-645e0194f0a9",
    "prId" : 24723,
    "prUrl" : "https://github.com/apache/spark/pull/24723#pullrequestreview-245562355",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1bc31d4a-ce12-4171-b2af-5f70f5a19a6f",
        "parentId" : null,
        "authorId" : "43998e22-6c2f-401d-9914-8cecf6fad929",
        "body" : "`AlterTableAlterColumnStatement` is missing?",
        "createdAt" : "2019-06-04T11:30:49Z",
        "updatedAt" : "2019-06-04T19:04:01Z",
        "lastEditedBy" : "43998e22-6c2f-401d-9914-8cecf6fad929",
        "tags" : [
        ]
      },
      {
        "id" : "bae59c3c-ea10-4c8e-82c0-89c50ed76e8a",
        "parentId" : "1bc31d4a-ce12-4171-b2af-5f70f5a19a6f",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "Nothing implements `AlterTableAlterColumnStatement`. This PR preserves existing behavior and updates the parser, it does not add new behavior.",
        "createdAt" : "2019-06-04T16:29:38Z",
        "updatedAt" : "2019-06-04T19:04:01Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      }
    ],
    "commit" : "bd7d8c8f7c6a2c378deba5927c96a8eb4dc6ef54",
    "line" : 39,
    "diffHunk" : "@@ -1,1 +118,122 @@        if newColumns.forall(_.name.size == 1) =>\n      // only top-level adds are supported using AlterTableAddColumnsCommand\n      AlterTableAddColumnsCommand(table, newColumns.map(convertToStructField))\n  }\n"
  },
  {
    "id" : "92fd76e2-9286-4251-afd4-e25a8a53a606",
    "prId" : 24686,
    "prUrl" : "https://github.com/apache/spark/pull/24686#pullrequestreview-243590432",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1c10a85e-55a5-4378-9fa7-65151b48e553",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Please handle `DropViewStatement(CatalogObjectIdentifier(...))` case here to show a user-friendly `AnalysisException` message.",
        "createdAt" : "2019-05-29T20:13:12Z",
        "updatedAt" : "2019-05-30T03:06:36Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "b0e07a5b-b8f0-4baf-bfb7-6b4455a514a9",
        "parentId" : "1c10a85e-55a5-4378-9fa7-65151b48e553",
        "authorId" : "f5b3f57a-75a6-496c-af94-c32580ada13a",
        "body" : "Good idea!",
        "createdAt" : "2019-05-30T01:33:38Z",
        "updatedAt" : "2019-05-30T03:06:36Z",
        "lastEditedBy" : "f5b3f57a-75a6-496c-af94-c32580ada13a",
        "tags" : [
        ]
      }
    ],
    "commit" : "d5b0d4ad5f276a9f9fd52154c782418b8fa80a28",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +96,100 @@        s\"Can not specify catalog `${catalog.name}` for view $ident \" +\n          s\"because view support in catalog has not been implemented yet\")\n\n    case DropViewStatement(AsTableIdentifier(tableName), ifExists) =>\n      DropTableCommand(tableName, ifExists, isView = true, purge = false)"
  },
  {
    "id" : "56ecbbb1-5eaa-483a-93b6-e37e2a9d01dd",
    "prId" : 24617,
    "prUrl" : "https://github.com/apache/spark/pull/24617#pullrequestreview-241277484",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "55eacbc3-25fd-4590-b26e-6a79447dfc0f",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "shall we use default catalog here?",
        "createdAt" : "2019-05-23T12:49:35Z",
        "updatedAt" : "2019-05-23T15:32:37Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "c29a8f1b-0acf-4568-8b11-cafe1c1aed8d",
        "parentId" : "55eacbc3-25fd-4590-b26e-6a79447dfc0f",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "Yes. I'll update this.",
        "createdAt" : "2019-05-23T15:21:56Z",
        "updatedAt" : "2019-05-23T15:32:37Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      }
    ],
    "commit" : "9664638d65d496f560286261a3f90cfe1c53ab87",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +61,65 @@      val CatalogObjectIdentifier(maybeCatalog, identifier) = create.tableName\n      val catalog = maybeCatalog.orElse(defaultCatalog)\n          .getOrElse(throw new AnalysisException(\n            s\"No catalog specified for table ${identifier.quoted} and no default catalog is set\"))\n          .asTableCatalog"
  }
]