[
  {
    "id" : "f042a9de-3561-4321-b78a-fb9b53e130f6",
    "prId" : 25771,
    "prUrl" : "https://github.com/apache/spark/pull/25771#pullrequestreview-291472743",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e7b362fd-b865-4490-a096-e7dda03485d2",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "why not use `CurrentCatalogAndNamespace`?",
        "createdAt" : "2019-09-19T03:02:04Z",
        "updatedAt" : "2019-10-02T08:17:09Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "e226f493-86d2-4470-b220-4d0eb4bca3d7",
        "parentId" : "e7b362fd-b865-4490-a096-e7dda03485d2",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "Yes `CurrentCatalogAndNamespace` can be now used as session catalog supports namespaces.",
        "createdAt" : "2019-09-21T16:58:21Z",
        "updatedAt" : "2019-10-02T08:17:10Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "84856190f5bf7f7865ce3428986cca61471c9845",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +179,183 @@\n    case ShowNamespacesStatement(Some(namespace), pattern) =>\n      val DefaultCatalogAndNamespace(maybeCatalog, ns) = namespace\n      maybeCatalog match {\n        case Some(catalog) =>"
  },
  {
    "id" : "125e006a-e2bf-4678-9183-afb285b0202d",
    "prId" : 25771,
    "prUrl" : "https://github.com/apache/spark/pull/25771#pullrequestreview-291473389",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "19bcfb49-e4a7-4e48-8956-a688555a8304",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ditto",
        "createdAt" : "2019-09-19T03:02:12Z",
        "updatedAt" : "2019-10-02T08:17:09Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "70f7d760-7bad-4f01-9060-15f140deb4a9",
        "parentId" : "19bcfb49-e4a7-4e48-8956-a688555a8304",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "OK. I updated to use `CurrentCatalogAndNamespace`. This will not fall back to `ShowTablesCommand` and there will be no `isTemporary` column any longer. This should be OK, right?",
        "createdAt" : "2019-09-21T17:17:56Z",
        "updatedAt" : "2019-10-02T08:17:10Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "84856190f5bf7f7865ce3428986cca61471c9845",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +203,207 @@\n    case ShowTablesStatement(Some(namespace), pattern) =>\n      val DefaultCatalogAndNamespace(maybeCatalog, ns) = namespace\n      maybeCatalog match {\n        case Some(catalog) =>"
  },
  {
    "id" : "2fe02e61-8068-48d9-b960-e574d4c0179d",
    "prId" : 25601,
    "prUrl" : "https://github.com/apache/spark/pull/25601#pullrequestreview-285885998",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "15049550-8d7d-44f6-b42e-0e778f56d50f",
        "parentId" : null,
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "I think this needs to distinguish between the case where the catalog is None and the catalog does not support namespaces. For the second case, this should report that the catalog doesn't support namespaces. You can also add a conversion method, `asNamespaceCatalog` to `CatalogV2Utils` like `asTableCatalog`.",
        "createdAt" : "2019-09-04T21:57:05Z",
        "updatedAt" : "2019-09-09T23:58:04Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "36bf4884-d941-4040-8aae-5597c31b783f",
        "parentId" : "15049550-8d7d-44f6-b42e-0e778f56d50f",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "Using `asNamespaceCatalog` simplifies the matching. Thanks.",
        "createdAt" : "2019-09-04T23:59:00Z",
        "updatedAt" : "2019-09-09T23:58:04Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      },
      {
        "id" : "7f25d28b-a64c-47d6-8daa-f714c0675a8b",
        "parentId" : "15049550-8d7d-44f6-b42e-0e778f56d50f",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "Why not use the current catalog instead of failing?",
        "createdAt" : "2019-09-06T21:38:49Z",
        "updatedAt" : "2019-09-09T23:58:04Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "4282111a-f240-4ea9-8665-852634d1a281",
        "parentId" : "15049550-8d7d-44f6-b42e-0e778f56d50f",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "If the catalog name is specified, but catalog doesn't support namespace, I think we should fail instead of falling back to the current catalog.\r\n\r\nIt's similar to: if the catalog name is specified, but doesn't contain the table we need, we should fail instead of falling back to the current catalog.",
        "createdAt" : "2019-09-10T03:14:38Z",
        "updatedAt" : "2019-09-10T03:14:38Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "9a55a03acf84fe67595817c8fef409a9e4912a51",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +184,188 @@          ShowNamespaces(catalog.asNamespaceCatalog, Some(ns), pattern)\n        case None =>\n          throw new AnalysisException(\n            s\"No v2 catalog is available for ${namespace.quoted}\")\n      }"
  },
  {
    "id" : "a6096db7-ee44-4ad1-8ba6-d1a4b0931f32",
    "prId" : 25601,
    "prUrl" : "https://github.com/apache/spark/pull/25601#pullrequestreview-286530033",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "46d73852-3896-495e-abef-1aa3101afba3",
        "parentId" : null,
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "I think this should be `currentCatalog` instead. @cloud-fan, do you agree?",
        "createdAt" : "2019-09-06T21:38:12Z",
        "updatedAt" : "2019-09-09T23:58:04Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "577c5c2d-6590-4b09-9181-6d3d9589cbd5",
        "parentId" : "46d73852-3896-495e-abef-1aa3101afba3",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "yea",
        "createdAt" : "2019-09-10T03:10:08Z",
        "updatedAt" : "2019-09-10T03:10:08Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "59f3542e-ee1c-4ff7-8727-66ef387b7f3c",
        "parentId" : "46d73852-3896-495e-abef-1aa3101afba3",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Let's implement switching the current catalog first, otherwise we are not able to test it.",
        "createdAt" : "2019-09-10T13:19:47Z",
        "updatedAt" : "2019-09-10T13:19:47Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "dc97ec07-3dc7-4cdc-a661-efaad81bf816",
        "parentId" : "46d73852-3896-495e-abef-1aa3101afba3",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "@imback82 are you working on it?",
        "createdAt" : "2019-09-10T13:25:01Z",
        "updatedAt" : "2019-09-10T13:25:02Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "87387512-98d1-45c1-b0f1-bc634ea6fe4a",
        "parentId" : "46d73852-3896-495e-abef-1aa3101afba3",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "yes, I am working on `USE NAMESPACE`",
        "createdAt" : "2019-09-10T23:13:52Z",
        "updatedAt" : "2019-09-10T23:13:53Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      },
      {
        "id" : "8ea3bd77-2b49-4490-aae0-73338b0349db",
        "parentId" : "46d73852-3896-495e-abef-1aa3101afba3",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "I should be able to send out the PR sometime tomorrow.",
        "createdAt" : "2019-09-11T02:46:22Z",
        "updatedAt" : "2019-09-11T02:46:22Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "9a55a03acf84fe67595817c8fef409a9e4912a51",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +171,175 @@\n    case ShowNamespacesStatement(None, pattern) =>\n      defaultCatalog match {\n        case Some(catalog) =>\n          ShowNamespaces(catalog.asNamespaceCatalog, None, pattern)"
  },
  {
    "id" : "3f30775d-db2e-4ff6-966e-2c14145a4d4e",
    "prId" : 25465,
    "prUrl" : "https://github.com/apache/spark/pull/25465#pullrequestreview-278159880",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2f61a46f-947e-4639-bedd-646c63544b0e",
        "parentId" : null,
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "If this logic were in `lookupDataSourceV2`, I don't think this case would be required.",
        "createdAt" : "2019-08-21T21:26:08Z",
        "updatedAt" : "2019-08-27T05:48:29Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "7b7c3a08-cb01-44c1-8b38-dca4932c4408",
        "parentId" : "2f61a46f-947e-4639-bedd-646c63544b0e",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "see https://github.com/apache/spark/pull/25465/files#r316472026",
        "createdAt" : "2019-08-22T02:14:42Z",
        "updatedAt" : "2019-08-27T05:48:29Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "d9f664438417ee8f4bb952d41f53c8c0b0e8d500",
    "line" : 76,
    "diffHunk" : "@@ -1,1 +208,212 @@      DataSource.lookupDataSourceV2(provider, conf) match {\n        // TODO(SPARK-28396): Currently file source v2 can't work with tables.\n        case Some(_: FileDataSourceV2) => Some(provider)\n        case Some(_) => None\n        case _ => Some(provider)"
  },
  {
    "id" : "0b37c536-04dd-40d5-a5a4-63e74a241561",
    "prId" : 25247,
    "prUrl" : "https://github.com/apache/spark/pull/25247#pullrequestreview-273436306",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5c47f620-d414-4996-99e4-b6c95cb60f75",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "we can only fallback to the v1 show tables if `namespace.length == 1`. Otherwise we should fail and ask users to specify a valid database name.\r\n\r\n`SHOW TABLES a.b` fails in Spark 2.x, and it should still fail in Spark 3.0 if users do not set the default catalog.",
        "createdAt" : "2019-08-08T06:10:43Z",
        "updatedAt" : "2019-08-23T00:03:45Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "570724b5-aba7-4b9b-ac9d-fe52ed5af66f",
        "parentId" : "5c47f620-d414-4996-99e4-b6c95cb60f75",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "Added the check. Thanks for pointing it out.",
        "createdAt" : "2019-08-10T19:05:24Z",
        "updatedAt" : "2019-08-23T00:03:45Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "6f2fa4e7b8572a6b9dd243f1253e4962af27d40a",
    "line" : 39,
    "diffHunk" : "@@ -1,1 +202,206 @@              s\"The database name is not valid: ${namespace.quoted}\")\n          }\n          ShowTablesCommand(Some(namespace.quoted), pattern)\n      }\n  }"
  },
  {
    "id" : "4767ef0f-7dc3-408b-9eb7-f35b97020baa",
    "prId" : 25115,
    "prUrl" : "https://github.com/apache/spark/pull/25115#pullrequestreview-274653227",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "09c7a42e-2779-4976-be26-8881306726a3",
        "parentId" : null,
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "Since this always throws `AnalysisException`, I think this case should be removed. Instead, the next case should match and the `V2SessionCatalog` should be used. If the table loaded by the v2 session catalog doesn't support delete, then conversion to physical plan will fail when `asDeletable` is called.\r\n\r\nThen users can still call v2 deletes for formats like `parquet` that have a v2 implementation that will work.\r\n\r\nFYI @brkyvz.",
        "createdAt" : "2019-08-12T18:25:58Z",
        "updatedAt" : "2019-08-14T01:57:20Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "ac7176d6-d058-41de-83c4-5e6a496c11d9",
        "parentId" : "09c7a42e-2779-4976-be26-8881306726a3",
        "authorId" : "8afcf008-6988-44a5-92fa-2bef54bb4058",
        "body" : "Thank you @rdblue . Removed this case and fallback to `sessionCatalog` when `resolveTables` for `DeleteFromTable`.",
        "createdAt" : "2019-08-13T06:56:09Z",
        "updatedAt" : "2019-08-14T01:57:20Z",
        "lastEditedBy" : "8afcf008-6988-44a5-92fa-2bef54bb4058",
        "tags" : [
        ]
      },
      {
        "id" : "0974e767-e725-4d5d-acb3-c205fb89cc2b",
        "parentId" : "09c7a42e-2779-4976-be26-8881306726a3",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I think it's worse to move this case from here to https://github.com/apache/spark/pull/25115/files#diff-57b3d87be744b7d79a9beacf8e5e5eb2R657 .\r\n\r\nIf we can't merge these 2 cases into one here, let's keep it as it was.",
        "createdAt" : "2019-08-13T12:37:23Z",
        "updatedAt" : "2019-08-14T01:57:20Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "d69aeec2-e6c2-4547-b096-60e6a1bf34ca",
        "parentId" : "09c7a42e-2779-4976-be26-8881306726a3",
        "authorId" : "8afcf008-6988-44a5-92fa-2bef54bb4058",
        "body" : "If I understand correctly, one purpose of removing the first case is we can execute delete on `parquet` format via this API (if we implement it later) as @rdblue mentioned. The key point here is we resolve the table use `V2SessionCatalog` **as the fallback catalog**.  The original `resolveTable` doesn't give any fallback-to-sessionCatalog mechanism (if no catalog found, it will fallback to `resolveRelation`). So maybe we can modify `resolveTable` and let it treat `V2SessionCatalog` as a try option:\r\n```\r\ncase u @ UnresolvedRelation(CatalogObjectIdentifier(maybeCatalog, ident)) =>\r\n        maybeCatalog.orElse(sessionCatalog) match {\r\n          case Some(catalogPlugin) =>\r\n            loadTable(catalogPlugin, ident).map(DataSourceV2Relation.create).getOrElse(u)\r\n          case None =>\r\n            u\r\n        }\r\n```\r\n",
        "createdAt" : "2019-08-13T14:49:08Z",
        "updatedAt" : "2019-08-14T01:57:20Z",
        "lastEditedBy" : "8afcf008-6988-44a5-92fa-2bef54bb4058",
        "tags" : [
        ]
      },
      {
        "id" : "d51ac4aa-b0f1-464b-80de-00b350daa076",
        "parentId" : "09c7a42e-2779-4976-be26-8881306726a3",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "I don't think we need to update `ResolveTables`, though I do see that it would be nice to use `ResolveTables` as the only rule that resolves `UnresolvedRelation` for v2 tables.\r\n\r\nThere is already another rule that loads tables from a catalog, [`ResolveInsertInto`](https://github.com/apache/spark/blob/master/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/Analyzer.scala#L772).\r\n\r\nI considered updating that rule and moving the table resolution part into `ResolveTables` as well, but I think it is a little cleaner to resolve the table when converting the statement (in `DataSourceResolution`), as @cloud-fan is suggesting.\r\n\r\nOne of the reasons to do this for the insert plans is that those plans don't include the target relation as a child. Instead, those plans have the data to insert as a child node, which means that the unresolved relation won't be visible to the `ResolveTables` rule.\r\n\r\nTaking the same approach in this PR would also make this a little cleaner. If `DeleteFrom` didn't expose the relation as a child, it could be a `UnaryNode` and you wouldn't need to update some of the other rules to explicitly include `DeleteFrom`.",
        "createdAt" : "2019-08-13T17:10:38Z",
        "updatedAt" : "2019-08-14T01:57:20Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "6ab69cd6-27f9-4374-9879-3a4f1e251114",
        "parentId" : "09c7a42e-2779-4976-be26-8881306726a3",
        "authorId" : "8afcf008-6988-44a5-92fa-2bef54bb4058",
        "body" : "Okay, I rolled back the resolve rules for `DeleteFromTable` as it was as @cloud-fan suggested. For cases that like deleting from formats or `V2SessionCatalog` support, let's open another pr. And another pr for resolve rules is also need because I found other issues related with that. Does this sounds reasonable?",
        "createdAt" : "2019-08-14T02:05:37Z",
        "updatedAt" : "2019-08-14T02:05:37Z",
        "lastEditedBy" : "8afcf008-6988-44a5-92fa-2bef54bb4058",
        "tags" : [
        ]
      },
      {
        "id" : "ff34688e-cc6b-4602-b621-6399a01fbef4",
        "parentId" : "09c7a42e-2779-4976-be26-8881306726a3",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "We can remove this case after https://github.com/apache/spark/pull/25402, which updates `ResolveTable` to fallback to v2 session catalog.",
        "createdAt" : "2019-08-14T03:04:06Z",
        "updatedAt" : "2019-08-14T03:04:06Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "a3b6c1a1-112b-4821-a70b-507563e006c4",
        "parentId" : "09c7a42e-2779-4976-be26-8881306726a3",
        "authorId" : "8afcf008-6988-44a5-92fa-2bef54bb4058",
        "body" : "Saw the code in #25402 . I think it's the best choice.",
        "createdAt" : "2019-08-14T03:29:34Z",
        "updatedAt" : "2019-08-14T03:29:34Z",
        "lastEditedBy" : "8afcf008-6988-44a5-92fa-2bef54bb4058",
        "tags" : [
        ]
      }
    ],
    "commit" : "bbf515666495cbf5f12731b3cdab4a23960f3d77",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +175,179 @@\n    case DeleteFromStatement(AsTableIdentifier(table), tableAlias, condition) =>\n      throw new AnalysisException(\n        s\"Delete from tables is not supported using the legacy / v1 Spark external catalog\" +\n            s\" API. Identifier: $table.\")"
  },
  {
    "id" : "cd0c09c6-8eb4-4cff-85b2-a26cf6fc89fc",
    "prId" : 25040,
    "prUrl" : "https://github.com/apache/spark/pull/25040#pullrequestreview-259172212",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a93a211f-6df1-4908-bc00-42be9dc64d96",
        "parentId" : null,
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "Should this be supported eventually, or is it redundant if DESCRIBE TABLE is available?",
        "createdAt" : "2019-07-06T19:31:06Z",
        "updatedAt" : "2019-08-06T18:59:07Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "274f3a25-2c5c-4ca3-a161-e330b58b0208",
        "parentId" : "a93a211f-6df1-4908-bc00-42be9dc64d96",
        "authorId" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "body" : "Think we need to support it eventually if only to keep parity with V1 tables.",
        "createdAt" : "2019-07-08T21:42:13Z",
        "updatedAt" : "2019-08-06T18:59:07Z",
        "lastEditedBy" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "tags" : [
        ]
      }
    ],
    "commit" : "cff78a16e691917e812b4cd63bf7544a54af4742",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +101,105 @@    case DescribeColumnStatement(\n        CatalogObjectIdentifier(Some(catalog), ident), colName, isExtended) =>\n      throw new AnalysisException(\"Describing columns is not supported for v2 tables.\")\n\n    case DescribeTableStatement("
  }
]