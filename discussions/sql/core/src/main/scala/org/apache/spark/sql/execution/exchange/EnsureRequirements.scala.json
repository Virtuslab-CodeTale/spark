[
  {
    "id" : "13162e36-2430-46b0-8709-e1311a5a2d98",
    "prId" : 33541,
    "prUrl" : "https://github.com/apache/spark/pull/33541#pullrequestreview-718762829",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "554420a9-7140-49a1-97e1-bccaedfa86a2",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "The logic here is simplified as well. Now it's pretty simple to keep the old logic and try our best to optimize out user-specified repartition.\r\n\r\nhttps://github.com/apache/spark/commit/7fe4c4a9ad92cedd398a13a1781649dff57ca4d9 can be reverted to avoid perf regreession.",
        "createdAt" : "2021-07-29T07:12:27Z",
        "updatedAt" : "2021-07-29T07:15:40Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "5fa8ded9-00d1-456c-9f12-c94bbfa7232d",
        "parentId" : "554420a9-7140-49a1-97e1-bccaedfa86a2",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "The previous check is to avoid AQE change output partitioning during execution (not the final stage). So I suggested do not remove all shuffle origin before.",
        "createdAt" : "2021-07-29T11:42:01Z",
        "updatedAt" : "2021-07-29T11:42:30Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      },
      {
        "id" : "fe2998cf-0651-44f2-a740-3f2560ce8388",
        "parentId" : "554420a9-7140-49a1-97e1-bccaedfa86a2",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "why do we care about user-specified repartition if it's not in the final stage?",
        "createdAt" : "2021-07-30T04:34:29Z",
        "updatedAt" : "2021-07-30T04:34:30Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "ef427ee2-dc89-4f24-a9b4-5477f23632f8",
        "parentId" : "554420a9-7140-49a1-97e1-bccaedfa86a2",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "User may want to have a custom shuffle partition number with `/*+ repartition(10000, col) */`. If this shuffle is removed, I think it will break user expectaion.",
        "createdAt" : "2021-07-30T05:27:06Z",
        "updatedAt" : "2021-07-30T05:27:06Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      },
      {
        "id" : "a393ec20-516b-405b-8e9e-3b564ee6f56e",
        "parentId" : "554420a9-7140-49a1-97e1-bccaedfa86a2",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This may be good or not, but my change here is to revert back to the behavior in 3.1, to make sure we don't have perf regression in 3.2",
        "createdAt" : "2021-07-30T06:34:23Z",
        "updatedAt" : "2021-07-30T06:34:23Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "c99463d3-02af-4c08-aa3c-161bb7346c94",
        "parentId" : "554420a9-7140-49a1-97e1-bccaedfa86a2",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "ok I'm fine with this",
        "createdAt" : "2021-07-30T06:36:45Z",
        "updatedAt" : "2021-07-30T06:36:45Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "61cc6751e4baad96f0a8b251296c6e58ffbbf3a3",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +258,262 @@    case operator @ ShuffleExchangeExec(upper: HashPartitioning, child, shuffleOrigin)\n        if optimizeOutRepartition &&\n          (shuffleOrigin == REPARTITION_BY_COL || shuffleOrigin == REPARTITION_BY_NUM) =>\n      def hasSemanticEqualPartitioning(partitioning: Partitioning): Boolean = {\n        partitioning match {"
  },
  {
    "id" : "fc02e3dd-dea6-4777-aabb-b075c0489de4",
    "prId" : 33188,
    "prUrl" : "https://github.com/apache/spark/pull/33188#pullrequestreview-714988801",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fceab74f-02f1-467b-bd70-b01c4439e3b8",
        "parentId" : null,
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "Sorry for going back to here. After some more thought, it would be better to skip removing shuffle with all shuffle origin in AQE which include the `REPARTITION_BY_COL`. Then the condition can be changed to `if !conf.adaptiveExecutionEnabled`. Given this we can remove the final stage rules in `AdaptiveSparkPlanExec` safely which seems a little hack.\r\n\r\nFor `REPARTITION_BY_COL`, I want to explain it's also unsafe to remove. We may apply `OptimizeLocalShuffleReader` to change the output partitioning which does not follow the semantics of `RepartitionByExpression`.\r\n\r\nWhat do you think ? @HyukjinKwon @cloud-fan ",
        "createdAt" : "2021-07-15T01:50:59Z",
        "updatedAt" : "2021-07-15T01:50:59Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      },
      {
        "id" : "8aad5093-9c9d-4332-820b-5286d751ae8d",
        "parentId" : "fceab74f-02f1-467b-bd70-b01c4439e3b8",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This may introduce perf regression (or improve perf if AQE can optimize skew join) but can simplify AQE code a lot. What do you think? @maryannxue @JkSelf ",
        "createdAt" : "2021-07-15T02:22:38Z",
        "updatedAt" : "2021-07-15T02:23:00Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "b5c0f2f0-ca8e-400a-b353-a2fdb3b1bd3e",
        "parentId" : "fceab74f-02f1-467b-bd70-b01c4439e3b8",
        "authorId" : "1b84a7ff-6bf9-4417-bf9f-e46e997e5974",
        "body" : "The `CoalesceShufflePartitions` rule may change the partition number when the `shuffleOrigin` is `REPARTITION_BY_COL`. I think it maybe a potential bug if removing the shuffle and not the perf issue.",
        "createdAt" : "2021-07-20T01:51:29Z",
        "updatedAt" : "2021-07-20T01:51:29Z",
        "lastEditedBy" : "1b84a7ff-6bf9-4417-bf9f-e46e997e5974",
        "tags" : [
        ]
      },
      {
        "id" : "68d61e10-3b3e-4a0a-b4d1-cf531f76f120",
        "parentId" : "fceab74f-02f1-467b-bd70-b01c4439e3b8",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "yeah, as we have only skipped applying `CoalesceShufflePartitions` or other custom shuffle reader at final stage. But for the stages which are in the process, we do nothing. That's why I think a little bit hack.\r\n\r\nOne other hack idea is we can remark the shuffle which is before the removed shuffle and change the `ENSURE_REQUIREMENTS` to `REPARTITION_BY_COL`. Then in AQE, we can do optimization safely.\r\n\r\nIMO, I prefer the idea of `skip removing shuffle with all shuffle origin in AQE`, it's simple and it can be seen as a behavior change due to AQE is enabled by default. If user really hit this issue, they can just disable AQE.",
        "createdAt" : "2021-07-20T03:26:31Z",
        "updatedAt" : "2021-07-20T03:26:31Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      },
      {
        "id" : "d4404007-2068-466c-92dd-0bc962e6a3f5",
        "parentId" : "fceab74f-02f1-467b-bd70-b01c4439e3b8",
        "authorId" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "body" : "Changing sth. that would introduce regressions to the existing logic just to get the potential benefit of sth. we have not implemented yet is NOT acceptable.\r\n\r\nA better solution here is to have a \"root distribution (and potentially ordering) requirement\", which will be passed to EnsureRequirement and ValidateRequirement, so that each custom-shuffle-reader rule (e.g., local-shuffle-reader, skew-join) can decide whether to apply just by calling `ValidateRequirement` or add back necessary shuffle by calling `EnsureRequirement`. There would be no need for final-stage hacks.",
        "createdAt" : "2021-07-20T15:25:19Z",
        "updatedAt" : "2021-07-20T15:25:19Z",
        "lastEditedBy" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "tags" : [
        ]
      },
      {
        "id" : "5f968e77-da5a-4f7e-a0e0-08cdcd091769",
        "parentId" : "fceab74f-02f1-467b-bd70-b01c4439e3b8",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "given this, is it better to add a new physical plan for repartition ? which can aslo hold the `\"root distribution (and potentially ordering) requirement\"`. I remember some PR discussed about it before, and it should have other benefits, e.g. `AliasAwareOutputPartitioning`.\r\n",
        "createdAt" : "2021-07-22T04:56:05Z",
        "updatedAt" : "2021-07-22T04:56:05Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      },
      {
        "id" : "02e53335-b3fd-4b7f-a3cd-2eea9476f71a",
        "parentId" : "fceab74f-02f1-467b-bd70-b01c4439e3b8",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This doesn't solve the real problem: shall we eliminate the new physical plan for user-specified shuffles and skip some AQE rules? Or do not eliminate and always run all the AQE rules?",
        "createdAt" : "2021-07-26T15:29:24Z",
        "updatedAt" : "2021-07-26T15:29:24Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "7b668bbd9cef4ca2f0cfa84d2e16870464db4f1b",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +256,260 @@    // So, here we only remove REPARTITION_BY_COL in AQE.\n    case operator @ ShuffleExchangeExec(upper: HashPartitioning, child, shuffleOrigin)\n        if shuffleOrigin == REPARTITION_BY_COL || !conf.adaptiveExecutionEnabled =>\n      def hasSemanticEqualPartitioning(partitioning: Partitioning): Boolean = {\n        partitioning match {"
  },
  {
    "id" : "18e8ec7b-6ed4-4f78-9885-f337c80a85ce",
    "prId" : 29725,
    "prUrl" : "https://github.com/apache/spark/pull/29725#pullrequestreview-533142797",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7dd23be4-519a-4696-a065-197a043ba1c4",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "nit: `isEmpty` -> `nonEmpty`",
        "createdAt" : "2020-11-18T06:24:18Z",
        "updatedAt" : "2020-11-18T06:24:18Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "d91c5507-85e3-4c1e-8bdb-584177bebbb5",
        "parentId" : "7dd23be4-519a-4696-a065-197a043ba1c4",
        "authorId" : "c9c61219-802f-49bf-82c3-2e4d14bf5f35",
        "body" : "Thanks, will fix it.",
        "createdAt" : "2020-11-18T06:45:20Z",
        "updatedAt" : "2020-11-18T07:23:16Z",
        "lastEditedBy" : "c9c61219-802f-49bf-82c3-2e4d14bf5f35",
        "tags" : [
        ]
      }
    ],
    "commit" : "32a6714bd31fb86e3a2d057943c13ba812b6e28e",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +128,132 @@        operator match {\n          case WindowExec(_, partitionSpec, orderSpec, _)\n            if (!partitionSpec.isEmpty && !orderSpec.isEmpty) =>\n            WindowSortExec(\n              partitionSpec,"
  },
  {
    "id" : "084d3036-bfcd-4203-abf4-35944c55ebe0",
    "prId" : 29074,
    "prUrl" : "https://github.com/apache/spark/pull/29074#pullrequestreview-446842786",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "10a340c0-b6a4-410c-bfec-22100f5b5298",
        "parentId" : null,
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "This can be also implemented by looking at left partitioning first then move to the right partitionoing:\r\n```scala\r\n    (leftPartitioning, rightPartitioning) match {\r\n      case (HashPartitioning(leftExpressions, _), _) =>\r\n        reorder(leftKeys.toIndexedSeq, rightKeys.toIndexedSeq, leftExpressions, leftKeys)\r\n          .orElse(reorderJoinKeysRecursively(\r\n            leftKeys, rightKeys, UnknownPartitioning(0), rightPartitioning))\r\n      case (PartitioningCollection(partitionings), _) =>\r\n        partitionings.foreach { p =>\r\n          reorderJoinKeysRecursively(leftKeys, rightKeys, p, rightPartitioning).map { k =>\r\n            return Some(k)\r\n          }\r\n        }\r\n        reorderJoinKeysRecursively(leftKeys, rightKeys, UnknownPartitioning(0), rightPartitioning)\r\n      case (_, HashPartitioning(rightExpressions, _)) =>\r\n        reorder(leftKeys.toIndexedSeq, rightKeys.toIndexedSeq, rightExpressions, rightKeys)\r\n      case (_, PartitioningCollection(partitionings)) =>\r\n        partitionings.foreach { p =>\r\n          reorderJoinKeysRecursively(leftKeys, rightKeys, leftPartitioning, p).map { k =>\r\n            return Some(k)\r\n          }\r\n        }\r\n        None\r\n      case _ =>\r\n        None\r\n    }\r\n```\r\nHowever, I chose this way so that the behavior remains the same. If you have `leftPartitioning = PartitioningCollection` and `rightPartitioning = HashPartitioning`, it will match the `rightPartitioning` first, which is the existing behavior. ",
        "createdAt" : "2020-07-12T03:22:02Z",
        "updatedAt" : "2020-10-07T16:28:37Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "3cd6df91b74fc98487ffb1f9920bada5b4040e96",
    "line" : 69,
    "diffHunk" : "@@ -1,1 +209,213 @@      case (_, Some(HashPartitioning(rightExpressions, _))) =>\n        reorder(leftKeys.toIndexedSeq, rightKeys.toIndexedSeq, rightExpressions, rightKeys)\n          .orElse(reorderJoinKeysRecursively(\n            leftKeys, rightKeys, leftPartitioning, None))\n      case (Some(PartitioningCollection(partitionings)), _) =>"
  }
]