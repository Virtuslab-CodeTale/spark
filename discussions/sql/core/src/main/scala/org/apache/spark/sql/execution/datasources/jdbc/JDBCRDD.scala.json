[
  {
    "id" : "158904ac-88fa-404e-8bcd-8c4c4be7efa2",
    "prId" : 33352,
    "prUrl" : "https://github.com/apache/spark/pull/33352#pullrequestreview-709643243",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dfd65c20-1279-4e58-89ff-d5339765e2fc",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Sorry I don't get it. Why not just `aggregates.map`? Why do we need an ArrayBuilder?",
        "createdAt" : "2021-07-19T14:49:58Z",
        "updatedAt" : "2021-07-19T14:49:58Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "fae570a68cde1cc25ae60e7ba74651e7972578e3",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +140,144 @@    def quote(colName: String): String = dialect.quoteIdentifier(colName)\n\n    aggregates.map {\n      case min: Min =>\n        assert(min.column.fieldNames.length == 1)"
  },
  {
    "id" : "2e2e631e-667e-4015-a235-a53fd9da74d0",
    "prId" : 33352,
    "prUrl" : "https://github.com/apache/spark/pull/33352#pullrequestreview-712266129",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "73dd6a77-48d1-4db7-bdf9-b88215baf679",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "shall we pass `Array[FieldReference]` and use empty array to represent no grouping?",
        "createdAt" : "2021-07-21T13:35:18Z",
        "updatedAt" : "2021-07-21T13:35:18Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "00672445-121a-4762-a3e9-766670473b35",
        "parentId" : "73dd6a77-48d1-4db7-bdf9-b88215baf679",
        "authorId" : "99765afe-8dbe-4d5f-9ad3-d5bc40f0462b",
        "body" : "I guess no. I am using this `groupByColumns` to tell if aggregate is pushed down. Having this as an Option, I can do this:\r\n```\r\nif (groupByColumns.isEmpty) {  // no pushed down aggregate\r\n  quote columns\r\n} else {\r\n  // columns already quoated\r\n  if (groupByColumns.get.isEmpty) { // no group by columns\r\n    getGroupByClause = \"\"\r\n  }  else {\r\n    getGroupByClause = ...\r\n  }\r\n}\r\n\r\n```",
        "createdAt" : "2021-07-21T23:23:54Z",
        "updatedAt" : "2021-07-21T23:23:54Z",
        "lastEditedBy" : "99765afe-8dbe-4d5f-9ad3-d5bc40f0462b",
        "tags" : [
        ]
      }
    ],
    "commit" : "fae570a68cde1cc25ae60e7ba74651e7972578e3",
    "line" : 59,
    "diffHunk" : "@@ -1,1 +186,190 @@      options: JDBCOptions,\n      outputSchema: Option[StructType] = None,\n      groupByColumns: Option[Array[FieldReference]] = None): RDD[InternalRow] = {\n    val url = options.url\n    val dialect = JdbcDialects.get(url)"
  },
  {
    "id" : "5994cfac-181a-495e-89f1-ba78e7fee274",
    "prId" : 33352,
    "prUrl" : "https://github.com/apache/spark/pull/33352#pullrequestreview-711661951",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e4640e6a-013b-4048-82c7-03ab96a48914",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ditto",
        "createdAt" : "2021-07-21T13:35:25Z",
        "updatedAt" : "2021-07-21T13:35:25Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "fae570a68cde1cc25ae60e7ba74651e7972578e3",
    "line" : 90,
    "diffHunk" : "@@ -1,1 +222,226 @@    url: String,\n    options: JDBCOptions,\n    groupByColumns: Option[Array[FieldReference]])\n  extends RDD[InternalRow](sc, Nil) {\n"
  },
  {
    "id" : "ef9290e7-0689-4e61-8b34-c9c0f6d1ebfe",
    "prId" : 33352,
    "prUrl" : "https://github.com/apache/spark/pull/33352#pullrequestreview-711662579",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e0d085f4-52bf-407a-b439-d367f4e94fe3",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "nit: `assert(groupByColumns.forall(_.fieldNames.length == 1))`",
        "createdAt" : "2021-07-21T13:35:58Z",
        "updatedAt" : "2021-07-21T13:35:58Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "fae570a68cde1cc25ae60e7ba74651e7972578e3",
    "line" : 105,
    "diffHunk" : "@@ -1,1 +269,273 @@      assert(groupByColumns.get.forall(_.fieldNames.length == 1))\n      val dialect = JdbcDialects.get(url)\n      val quotedColumns = groupByColumns.get.map(c => dialect.quoteIdentifier(c.fieldNames.head))\n      s\"GROUP BY ${quotedColumns.mkString(\", \")}\"\n    } else {"
  },
  {
    "id" : "d331272f-3b43-401f-9a71-86c7e40e9765",
    "prId" : 33352,
    "prUrl" : "https://github.com/apache/spark/pull/33352#pullrequestreview-714572564",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1a6c89c4-b3a6-42ad-8621-cd6355876397",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Is the param doc correct? I don't see `aggregation` parameter but `outputSchema` and `groupByColumns`.",
        "createdAt" : "2021-07-26T08:24:05Z",
        "updatedAt" : "2021-07-26T08:24:06Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "fae570a68cde1cc25ae60e7ba74651e7972578e3",
    "line" : 48,
    "diffHunk" : "@@ -1,1 +174,178 @@   * @param options - JDBC options that contains url, table and other information.\n   * @param requiredSchema - The schema of the columns to SELECT.\n   * @param aggregation - The pushed down aggregation\n   *\n   * @return An RDD representing \"SELECT requiredColumns FROM fqTable\"."
  }
]