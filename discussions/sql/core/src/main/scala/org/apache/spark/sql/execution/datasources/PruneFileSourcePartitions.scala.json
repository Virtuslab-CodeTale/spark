[
  {
    "id" : "4dfcbdc6-7e81-4c83-a255-b51dd34d9dca",
    "prId" : 33584,
    "prUrl" : "https://github.com/apache/spark/pull/33584#pullrequestreview-719634360",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "db3fbd08-f79a-46d3-b55f-45d273a6ba08",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Conceptually, it is a bit weird to have two rules handling pruning partition.",
        "createdAt" : "2021-08-01T07:49:48Z",
        "updatedAt" : "2021-08-01T08:07:03Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "bbc85db716de1db24bdb67f2ca9075dcaa648ded",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +30,34 @@ * Prune the partitions of file source based table using partition filters. Currently, this rule\n * is applied to [[HadoopFsRelation]] with [[CatalogFileIndex]]. [[DataSourceV2ScanRelation]]\n * with [[FileScan]] is pruned in [[PushDownUtils]].\n *\n * For [[HadoopFsRelation]], the location will be replaced by pruned file index, and corresponding"
  }
]