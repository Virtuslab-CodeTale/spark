[
  {
    "id" : "4dd11a41-7480-4e8a-8579-e9558bfdd564",
    "prId" : 30473,
    "prUrl" : "https://github.com/apache/spark/pull/30473#pullrequestreview-536746651",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7d8f37d0-ab3b-4dd3-9b27-fd18c55c6c0b",
        "parentId" : null,
        "authorId" : "99765afe-8dbe-4d5f-9ad3-d5bc40f0462b",
        "body" : "Seems to me the only property we can support for name space is schema comment. I don't have a good way to retrieve schema comment, so I will return an empty map for now.",
        "createdAt" : "2020-11-23T18:37:30Z",
        "updatedAt" : "2020-12-03T16:05:02Z",
        "lastEditedBy" : "99765afe-8dbe-4d5f-9ad3-d5bc40f0462b",
        "tags" : [
        ]
      }
    ],
    "commit" : "68838c979de47d35d1df3324b3a92ab80615d053",
    "line" : 88,
    "diffHunk" : "@@ -1,1 +214,218 @@      case Array(db) =>\n        if (!namespaceExists(namespace)) throw new NoSuchNamespaceException(db)\n        mutable.HashMap[String, String]().asJava\n\n      case _ =>"
  },
  {
    "id" : "0b58ffa2-dcec-425a-88e7-8165c9b3cbe6",
    "prId" : 30473,
    "prUrl" : "https://github.com/apache/spark/pull/30473#pullrequestreview-540699064",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ed0679c9-4689-4500-b0a0-733570f3c864",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "shall we fail and say \"action xxx not supported\"?",
        "createdAt" : "2020-11-30T08:48:59Z",
        "updatedAt" : "2020-12-03T16:05:02Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "68838c979de47d35d1df3324b3a92ab80615d053",
    "line" : 151,
    "diffHunk" : "@@ -1,1 +277,281 @@            }\n\n          case _ =>\n            throw new AnalysisException(s\"Unsupported NamespaceChange $changes in JDBC catalog.\")\n        }"
  },
  {
    "id" : "440e1f69-15ca-4999-b7df-6ec274701ce5",
    "prId" : 30473,
    "prUrl" : "https://github.com/apache/spark/pull/30473#pullrequestreview-543288050",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f9d6c938-c572-454a-8efe-f74c7dca156a",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "does it return schemas only from the current catalog?",
        "createdAt" : "2020-12-02T05:40:04Z",
        "updatedAt" : "2020-12-03T16:05:02Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "575de141-bd0c-48c9-8baa-e162c931a075",
        "parentId" : "f9d6c938-c572-454a-8efe-f74c7dca156a",
        "authorId" : "99765afe-8dbe-4d5f-9ad3-d5bc40f0462b",
        "body" : "DB2 jdbc driver implements this to return schemas from the current catalog (the current database jdbc driver connects to). Not sure how other jdbc drivers implement this. I tested with postgres jdbc driver, it also returns schemas from the current catalog. In listTables (https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/v2/jdbc/JDBCTableCatalog.scala#L62), we also assume ```getTables``` with `null` as catalog value returns tables from the current catalog. ",
        "createdAt" : "2020-12-02T22:24:22Z",
        "updatedAt" : "2020-12-03T16:05:02Z",
        "lastEditedBy" : "99765afe-8dbe-4d5f-9ad3-d5bc40f0462b",
        "tags" : [
        ]
      }
    ],
    "commit" : "68838c979de47d35d1df3324b3a92ab80615d053",
    "line" : 53,
    "diffHunk" : "@@ -1,1 +179,183 @@    case Array(db) =>\n      withConnection { conn =>\n        val rs = conn.getMetaData.getSchemas(null, db)\n        while (rs.next()) {\n          if (rs.getString(1) == db) return true;"
  },
  {
    "id" : "c5e67643-99c2-43cb-a8d5-3b775791085e",
    "prId" : 30473,
    "prUrl" : "https://github.com/apache/spark/pull/30473#pullrequestreview-543288111",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "76f7ca37-2b17-48eb-a278-fb4709c4a40e",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "shall we return the input `namespace` here?",
        "createdAt" : "2020-12-02T05:41:28Z",
        "updatedAt" : "2020-12-03T16:05:02Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "77398012-8c8c-4426-979f-d042ed98a100",
        "parentId" : "76f7ca37-2b17-48eb-a278-fb4709c4a40e",
        "authorId" : "99765afe-8dbe-4d5f-9ad3-d5bc40f0462b",
        "body" : "I am following the implementation in `V2SessionCatalog` (https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/v2/V2SessionCatalog.scala#L211). According to the method definition `List namespaces in a namespace`, the method returns namespaces inside the input `namespace`, which is empty.",
        "createdAt" : "2020-12-02T22:24:28Z",
        "updatedAt" : "2020-12-03T16:05:02Z",
        "lastEditedBy" : "99765afe-8dbe-4d5f-9ad3-d5bc40f0462b",
        "tags" : [
        ]
      }
    ],
    "commit" : "68838c979de47d35d1df3324b3a92ab80615d053",
    "line" : 78,
    "diffHunk" : "@@ -1,1 +204,208 @@        listNamespaces()\n      case Array(_) if namespaceExists(namespace) =>\n        Array()\n      case _ =>\n        throw new NoSuchNamespaceException(namespace)"
  }
]