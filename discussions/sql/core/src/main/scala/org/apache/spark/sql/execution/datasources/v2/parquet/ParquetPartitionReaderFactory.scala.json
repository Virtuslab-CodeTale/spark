[
  {
    "id" : "f69f7db8-b0de-4008-8000-a1b0a32b657d",
    "prId" : 32049,
    "prUrl" : "https://github.com/apache/spark/pull/32049#pullrequestreview-628374589",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a1d84906-cbee-453d-a541-855050d47d15",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "So if we use aggregate pushdown for Parquet, we cannot use vectorized Parquet reader, right? Can you describe it too in the config doc?",
        "createdAt" : "2021-04-04T17:43:41Z",
        "updatedAt" : "2021-04-28T06:21:16Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "33c97c5d-def4-476c-b127-e3c481493b0c",
        "parentId" : "a1d84906-cbee-453d-a541-855050d47d15",
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "It seems that it's supported to read aggregation result into a `ColumnarBatch` below in `buildColumnarReader`. So we can still do aggregation push down with vectorized reader enabled right?",
        "createdAt" : "2021-04-05T07:43:07Z",
        "updatedAt" : "2021-04-28T06:21:16Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      },
      {
        "id" : "a022c08e-7efc-47ec-98f9-e3f005d3e31d",
        "parentId" : "a1d84906-cbee-453d-a541-855050d47d15",
        "authorId" : "99765afe-8dbe-4d5f-9ad3-d5bc40f0462b",
        "body" : "I think it doesn't matter if the vectorized reader is enabled or not.  Since we are reading the statistics information from the parquet footer, we don't really create a VectorizedReader. But if columnar reader is enabled, we return a `ColumnarBatch` instead of a `InternalRow`.",
        "createdAt" : "2021-04-06T01:17:33Z",
        "updatedAt" : "2021-04-28T06:21:16Z",
        "lastEditedBy" : "99765afe-8dbe-4d5f-9ad3-d5bc40f0462b",
        "tags" : [
        ]
      }
    ],
    "commit" : "5c2b630a61d8ea9263116c37e154884a5cabd2ca",
    "line" : 87,
    "diffHunk" : "@@ -1,1 +126,130 @@\n      val reader = if (enableVectorizedReader) {\n        createVectorizedReader(file)\n      } else {\n        createRowBaseReader(file)"
  }
]