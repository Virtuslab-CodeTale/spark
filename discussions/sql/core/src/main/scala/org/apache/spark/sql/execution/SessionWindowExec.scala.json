[
  {
    "id" : "57c05a42-333c-4d0e-8f39-19c24da1cd65",
    "prId" : 31570,
    "prUrl" : "https://github.com/apache/spark/pull/31570#pullrequestreview-616746364",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5d87afb9-5932-41d5-af7e-e03f8802a017",
        "parentId" : null,
        "authorId" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "body" : "This is another difference with the @HeartSaVioR's. We use the pattern of SQL window function, while Jungtaek's one is a sub-class for aggregation iterator.\r\nPros:\r\nLess code change. Don't mess up with aggregation logic.\r\nCons:\r\nWe keep the original row for a while. Might involve more memory cost.",
        "createdAt" : "2021-03-18T01:54:31Z",
        "updatedAt" : "2021-03-18T02:54:50Z",
        "lastEditedBy" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "tags" : [
        ]
      },
      {
        "id" : "13f3bf2c-0145-4234-a32f-adfd06434c91",
        "parentId" : "5d87afb9-5932-41d5-af7e-e03f8802a017",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "That may not just bring additional memory cost. That may bring spill, which is something we'd like to avoid at all cost. There's a trade-off, complexity vs optimization.\r\n\r\nI'm OK to move forward to make it work, and evaluate the value of the trade-off. Except state format we could change everything afterwards, so OK with that.",
        "createdAt" : "2021-03-18T03:53:17Z",
        "updatedAt" : "2021-03-18T04:14:30Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      },
      {
        "id" : "09e987b5-bb12-4e64-b813-f4cb0a317582",
        "parentId" : "5d87afb9-5932-41d5-af7e-e03f8802a017",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "And if I understand correctly, this needs to copy all input rows because of the buffering. Now I could reload the context of my patch a bit; MergingSessionsIterator only copies the rows which are the first row of session, as it only needs to retain the last session to compare with current input row. That was the reason I chose such complexity. Performance wise, and also there was concerns on JIRA issue about memory usage on the flight.",
        "createdAt" : "2021-03-18T08:09:22Z",
        "updatedAt" : "2021-03-18T08:11:09Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      },
      {
        "id" : "0a745789-0c84-4853-b6d1-cd8da91a2ddb",
        "parentId" : "5d87afb9-5932-41d5-af7e-e03f8802a017",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "I think it's valid to compare this with UpdatingSessionIterator, which is used to support aggregation with one distinct and technically does the same with this. The major difference between twos looks to be that UpdatingSessionIterator doesn't try to memorize entire parts of row - it only memorizes the value part of row, as key part should be just all same with current session, and when session is closed, it restores the memorized rows with key & value parts.\r\n\r\nI guess there're pros and cons against twos but not that outstanding (memory usage may be better for UpdatingSessionIterator, but we have to pay cost for restoring), and at least this is simpler, I'm OK to pick this up for the replacement of UpdatingSessionIterator. I'm feeling that MergingSessionsIterator is something we should revisit, but as I said, if we feel that's a blocker on moving forward, I'll take it up after this lands to the codebase.",
        "createdAt" : "2021-03-18T08:26:22Z",
        "updatedAt" : "2021-03-18T08:27:57Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      },
      {
        "id" : "ccbadf8f-e19f-4d66-b78a-a57914c38e7c",
        "parentId" : "5d87afb9-5932-41d5-af7e-e03f8802a017",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "That's right. It is a trade-off. For session window use case, I image that most cases the buffer should not hold too many rows. It's hardly to think about that a session window has rows causing serious problem. Sounds like a rare case to me.\r\n\r\nI think I understand the design thinking here. The approach `MergingSessionsIterator` takes increases complexity by mixing aggregating and session window operations. If don't mix with aggregation, currently I don't have idea how to avoid buffering. I may not worry much too early about this before we have real customer complaints on this issue.\r\n",
        "createdAt" : "2021-03-19T18:14:18Z",
        "updatedAt" : "2021-03-19T18:14:18Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "75278c19-2c9d-4e5d-b952-7e8e01311d74",
        "parentId" : "5d87afb9-5932-41d5-af7e-e03f8802a017",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "That is a one of concerns. Another concern is, to buffer row you'll need to \"copy\" the row, which makes entire input rows going through buffer being copied. (Doesn't matter how many rows are buffered at specific time.) I see there're multiple physical ops to buffer rows, which makes me wondering about the performance and resource usage.\r\n\r\nI'll need to check the performance is really on par with mine - I think the major complexity of mine was introduced on linked-list of state format. Migrating state format to the one in agreement here would reduce the complexity significantly, so after applying the change on mine, we could reevaluate both properly.",
        "createdAt" : "2021-03-19T19:51:47Z",
        "updatedAt" : "2021-03-20T01:42:55Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      }
    ],
    "commit" : "04ca039bdf74c3b71be5fe53574906f426f25256",
    "line" : 68,
    "diffHunk" : "@@ -1,1 +66,70 @@   * Overridden by concrete implementations of SparkPlan.\n   */\n  override protected def doExecute(): RDD[InternalRow] = {\n    val inMemoryThreshold = sqlContext.conf.windowExecBufferInMemoryThreshold\n    val spillThreshold = sqlContext.conf.windowExecBufferSpillThreshold"
  },
  {
    "id" : "532919fa-32f8-459e-bd58-24aec0856178",
    "prId" : 31570,
    "prUrl" : "https://github.com/apache/spark/pull/31570#pullrequestreview-614932111",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0fc38e5c-2252-4c77-af3c-912b720943d8",
        "parentId" : null,
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "This made me stop to think, and looks like this is guaranteed per micro-batch. Probably ideal to leave a brief explanation how it is guaranteed.",
        "createdAt" : "2021-03-18T03:26:18Z",
        "updatedAt" : "2021-03-18T03:37:02Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      }
    ],
    "commit" : "04ca039bdf74c3b71be5fe53574906f426f25256",
    "line" : 61,
    "diffHunk" : "@@ -1,1 +59,63 @@  override def outputPartitioning: Partitioning = child.outputPartitioning\n\n  override def outputOrdering: Seq[SortOrder] = child.outputOrdering\n\n  /**"
  },
  {
    "id" : "1e242b0b-990c-45ed-b16b-8511c5394e14",
    "prId" : 31570,
    "prUrl" : "https://github.com/apache/spark/pull/31570#pullrequestreview-614932111",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "44fe3163-532f-462d-a4a4-25f185c52afb",
        "parentId" : null,
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "The comment doesn't seem to be needed.",
        "createdAt" : "2021-03-18T03:27:49Z",
        "updatedAt" : "2021-03-18T03:37:02Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      }
    ],
    "commit" : "04ca039bdf74c3b71be5fe53574906f426f25256",
    "line" : 63,
    "diffHunk" : "@@ -1,1 +61,65 @@  override def outputOrdering: Seq[SortOrder] = child.outputOrdering\n\n  /**\n   * Produces the result of the query as an `RDD[InternalRow]`\n   *"
  }
]