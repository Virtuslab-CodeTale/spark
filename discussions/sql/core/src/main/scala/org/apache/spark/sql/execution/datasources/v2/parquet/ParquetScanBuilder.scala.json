[
  {
    "id" : "c4c3a525-c5f6-426c-96f3-a128faaf398a",
    "prId" : 33347,
    "prUrl" : "https://github.com/apache/spark/pull/33347#pullrequestreview-707586165",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "18ecd9f2-53af-4980-824b-ede03f5aaeb5",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "We create `ParquetFilters` here only to check which filters are convertible, and rebase mode doesn't matter.\r\n\r\nShall we use pass `datetimeRebaseMode` as `CORRECTED` here?  ",
        "createdAt" : "2021-07-15T16:16:09Z",
        "updatedAt" : "2021-07-15T16:16:09Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "2baef0f1-1723-4b39-8c15-11a9fdea3b40",
        "parentId" : "18ecd9f2-53af-4980-824b-ede03f5aaeb5",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Yep. Let me pass `CORRECTED` here.",
        "createdAt" : "2021-07-15T16:25:38Z",
        "updatedAt" : "2021-07-15T16:25:38Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "37d7ffadd511520e8a052561e41411460e2d532f",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +64,68 @@      // whether they is convertible.\n      LegacyBehaviorPolicy.CORRECTED)\n    parquetFilters.convertibleFilters(this.filters).toArray\n  }\n"
  },
  {
    "id" : "2561737c-8087-4ed3-936d-0def229dbc84",
    "prId" : 30670,
    "prUrl" : "https://github.com/apache/spark/pull/30670#pullrequestreview-547785030",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1e8a7c67-cc61-4182-b5e2-0d8c36f78e8f",
        "parentId" : null,
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "Maybe we should use `readDataSchema()` instead of dataSchema",
        "createdAt" : "2020-12-09T02:17:33Z",
        "updatedAt" : "2020-12-09T02:17:33Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      }
    ],
    "commit" : "5b6d7204bb12d5b8905e639406ea479de6b12054",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +51,55 @@    val isCaseSensitive = sqlConf.caseSensitiveAnalysis\n    val parquetSchema =\n      new SparkToParquetSchemaConverter(sparkSession.sessionState.conf).convert(dataSchema)\n    val parquetFilters = new ParquetFilters(parquetSchema, pushDownDate, pushDownTimestamp,\n      pushDownDecimal, pushDownStringStartWith, pushDownInFilterThreshold, isCaseSensitive)"
  },
  {
    "id" : "4a8ca8aa-7c4e-411e-9e7b-74e007d2267f",
    "prId" : 24327,
    "prUrl" : "https://github.com/apache/spark/pull/24327#pullrequestreview-249998010",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3745fd3c-d6f8-4ef8-a62e-d271f15c4bf9",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Sorry if I missed some context. What's diff between `ParquetFilters.convertibleFilters` and `ParquetFilters.createFilters`? Seems like logic is duplicated.",
        "createdAt" : "2019-06-14T07:55:08Z",
        "updatedAt" : "2019-06-14T16:45:37Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "985d0b32-299f-4e55-8d72-883da9452062",
        "parentId" : "3745fd3c-d6f8-4ef8-a62e-d271f15c4bf9",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "`ParquetFilters.convertibleFilters` returns `Seq[org.apache.spark.sql.sources.Filter] `\r\n`ParquetFilters.createFilters` returns `org.apache.parquet.filter2.predicate.FilterPredicate`\r\n\r\nThe overlap of the two methods is only on the `And`/`Or`/`Not` operator.",
        "createdAt" : "2019-06-14T16:21:32Z",
        "updatedAt" : "2019-06-14T16:45:37Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "f658e9265ba741922fc96eec76038addcb6491a1",
    "line" : 56,
    "diffHunk" : "@@ -1,1 +54,58 @@    val parquetFilters = new ParquetFilters(parquetSchema, pushDownDate, pushDownTimestamp,\n      pushDownDecimal, pushDownStringStartWith, pushDownInFilterThreshold, isCaseSensitive)\n    parquetFilters.convertibleFilters(this.filters).toArray\n  }\n"
  }
]