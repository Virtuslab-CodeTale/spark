[
  {
    "id" : "8fbba9cd-f71b-4dcb-9df3-182c06e29ed6",
    "prId" : 32144,
    "prUrl" : "https://github.com/apache/spark/pull/32144#pullrequestreview-634518290",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3cb04dd2-0a69-4d7d-960d-38c1d02ed8e3",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Can we make the PR title clearer? It seems the SET command can already set/get hadoop configs in the SQLConf. The only problem is we don't display the default value correctly, which is from `sparkSession.sharedState.hadoopConf`.\r\n\r\nBTW do we have a valid use case? e.g. a hadoop conf is not in `SQLConf` but in `sparkSession.sharedState.hadoopConf`.",
        "createdAt" : "2021-04-13T11:50:03Z",
        "updatedAt" : "2021-04-14T14:43:40Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "365907a0-7a14-4243-9691-f2f1eebcfdda",
        "parentId" : "3cb04dd2-0a69-4d7d-960d-38c1d02ed8e3",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "> Can we make the PR title clearer?\r\n\r\nOK\r\n\r\n> BTW do we have a valid use case? e.g. a hadoop conf is not in `SQLConf` but in `sparkSession.sharedState.hadoopConf`.\r\n\r\nThe pre-loaded ones from `core-site.xml, hive-site.xml` etc., will only stay in `sparkSession.sharedState.hadoopConf` or `sc. _hadoopConfiguation` not `SQLConf`. Some of them that related the Hive Metastore connection(never change it spark runtime), e.g. `hive.metastore.uris`, are clearly global static and unchangeable but displayable I guess. Some of the ones that might be related to, for example, the output codec/compression, preset in Hadoop/hive config files like `core-site.xml` shall bestill changeable from case to case, table to table, file to file, etc. So, it's meaningful to show the defaults for users to change based on that.\r\n",
        "createdAt" : "2021-04-13T12:19:58Z",
        "updatedAt" : "2021-04-14T14:43:40Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "b6d26b7d87917e7e230ca38f2817c6110b461370",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +161,165 @@          // take affect from table to table, file to file, so they are not static and users are\n          // very likely to change them based the default value they see.\n          sparkSession.sharedState.hadoopConf.get(key, \"<undefined>\")\n        }\n        Seq(Row(key, value))"
  },
  {
    "id" : "296a409d-71e2-43de-b5d8-fc4afe1ded46",
    "prId" : 32144,
    "prUrl" : "https://github.com/apache/spark/pull/32144#pullrequestreview-634614203",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bea2b254-dc77-404a-b2dc-3cd697ed2b2e",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "let's add a few comments here.",
        "createdAt" : "2021-04-13T13:49:41Z",
        "updatedAt" : "2021-04-14T14:43:40Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "b6d26b7d87917e7e230ca38f2817c6110b461370",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +161,165 @@          // take affect from table to table, file to file, so they are not static and users are\n          // very likely to change them based the default value they see.\n          sparkSession.sharedState.hadoopConf.get(key, \"<undefined>\")\n        }\n        Seq(Row(key, value))"
  },
  {
    "id" : "4e093722-b261-4333-93ae-16c225f2bf2e",
    "prId" : 30045,
    "prUrl" : "https://github.com/apache/spark/pull/30045#pullrequestreview-510403412",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d648cbc1-28c7-4dbf-b91d-fb057f81c4f9",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ah so this only adds the warehouse dir config compared to the `sparkContext.conf`?",
        "createdAt" : "2020-10-16T11:04:53Z",
        "updatedAt" : "2020-10-22T15:38:55Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "ed09aa46-bbc4-49ee-bd9a-15a82dc5e43d",
        "parentId" : "d648cbc1-28c7-4dbf-b91d-fb057f81c4f9",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "No. The `sharedState.conf` is a cloned `sparkContext.conf` with other initial options including the warehouse dir and other static/dynamic configs set by the 1st SparkSession instance which creates the one and only `sharedState`. \r\nIf there is existing sc when we create the 1st SparkSession (e.g. see the PR description), the initial configs will go to the `sharedState.conf`, and we use this version of conf as defaults. Also, later created SparkSession with other options will not affect the `sharedState.conf`",
        "createdAt" : "2020-10-16T12:00:45Z",
        "updatedAt" : "2020-10-22T15:38:55Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "d1947961a366cd76086b9996c4d9687b7c63f3f7",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +173,177 @@\n  override def run(sparkSession: SparkSession): Seq[Row] = {\n    val defaults = sparkSession.sharedState.conf\n    config match {\n      case Some(key) =>"
  }
]