[
  {
    "id" : "f70099d6-5406-4ad8-b774-b777dc74b0fe",
    "prId" : 28394,
    "prUrl" : "https://github.com/apache/spark/pull/28394#pullrequestreview-401877822",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7762beaa-ddf2-4471-9587-daae95659aa9",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Could you leave some comments here like `// Force to build Hive configuration`?",
        "createdAt" : "2020-04-28T14:02:54Z",
        "updatedAt" : "2020-04-28T14:07:05Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "a888838c-4f30-437f-8814-e94703cdcdb0",
        "parentId" : "7762beaa-ddf2-4471-9587-daae95659aa9",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "`// Force to build SQL configurations from Hive module` may be better since they are not hive configs\r\n",
        "createdAt" : "2020-04-28T14:06:21Z",
        "updatedAt" : "2020-04-28T14:07:05Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "911f8c14-5a42-45a8-8c4d-61cd364652ac",
        "parentId" : "7762beaa-ddf2-4471-9587-daae95659aa9",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "yea, ok.",
        "createdAt" : "2020-04-28T14:13:29Z",
        "updatedAt" : "2020-04-28T14:13:29Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "b7d14be909655e320d2e93a8a48249f56e3286ce",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +51,55 @@    // Force to build SQL configurations from Hive module\n    try {\n      val symbol = ScalaReflection.mirror.staticModule(\"org.apache.spark.sql.hive.HiveUtils\")\n      ScalaReflection.mirror.reflectModule(symbol).instance\n    } catch {"
  },
  {
    "id" : "65a9effb-64b0-4045-9b11-b60d49f81410",
    "prId" : 27459,
    "prUrl" : "https://github.com/apache/spark/pull/27459#pullrequestreview-353400917",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "faf19c0e-eaf6-43f6-9a7f-d6cb8827d466",
        "parentId" : null,
        "authorId" : "fd6ebc48-7da4-490b-8d41-2e8530d92720",
        "body" : "The original `Seq` wouldn't translate over into Python, so I had to convert this to an `Array`. I wonder if there's a cleaner way to do this.",
        "createdAt" : "2020-02-04T21:41:38Z",
        "updatedAt" : "2020-02-07T23:13:31Z",
        "lastEditedBy" : "fd6ebc48-7da4-490b-8d41-2e8530d92720",
        "tags" : [
        ]
      },
      {
        "id" : "55f4880f-936e-472b-bf11-166fb435ce24",
        "parentId" : "faf19c0e-eaf6-43f6-9a7f-d6cb8827d466",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "This is fine but I would leave a comment though.",
        "createdAt" : "2020-02-05T00:39:56Z",
        "updatedAt" : "2020-02-07T23:13:31Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "b08bac43a844376bc870cb99c776d50157c39a01",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +44,48 @@    val conf = new SQLConf()\n    // Py4J doesn't seem to translate Seq well, so we convert to an Array.\n    conf.getAllDefinedConfs.toArray\n  }\n"
  }
]