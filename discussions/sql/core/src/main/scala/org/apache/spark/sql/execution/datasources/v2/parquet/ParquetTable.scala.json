[
  {
    "id" : "2048df7b-aa71-4cf1-b549-a3c511702e83",
    "prId" : 24327,
    "prUrl" : "https://github.com/apache/spark/pull/24327#pullrequestreview-246777838",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b7e8270e-faff-44da-95dc-178f0d0c12e5",
        "parentId" : null,
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "Looks like this will also hit SPARK-27960. I think this is okay for now. No need to block Parquet to fix it.\r\n\r\nHowever, it would be good to follow up with a suite of SQL tests for each v2 implementation that validates overall behavior, like reporting the metastore schema after a table is created.",
        "createdAt" : "2019-06-06T19:45:11Z",
        "updatedAt" : "2019-06-14T16:45:37Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      }
    ],
    "commit" : "f658e9265ba741922fc96eec76038addcb6491a1",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +36,40 @@    userSpecifiedSchema: Option[StructType],\n    fallbackFileFormat: Class[_ <: FileFormat])\n  extends FileTable(sparkSession, options, paths, userSpecifiedSchema) {\n\n  override def newScanBuilder(options: CaseInsensitiveStringMap): ParquetScanBuilder ="
  }
]