[
  {
    "id" : "f1ad772d-ba9c-43ba-9b02-5fbbc40af91f",
    "prId" : 24937,
    "prUrl" : "https://github.com/apache/spark/pull/24937#pullrequestreview-260546803",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "88e86ade-e475-4f0f-95c2-d40230c6d269",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "not related to this PR but just a thought: for API that's implemented by users and called by Spark, it seems not a good idea to use var-length argument list, as Spark always call this API with all the parameters at hand.",
        "createdAt" : "2019-07-11T08:37:00Z",
        "updatedAt" : "2019-07-11T17:21:21Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "5b10bd0164132bf296a07bcb794c3f7af262a72e",
    "line" : 39,
    "diffHunk" : "@@ -1,1 +37,41 @@  override protected def doExecute(): RDD[InternalRow] = {\n    try {\n      catalog.alterTable(ident, changes: _*)\n    } catch {\n      case e: IllegalArgumentException =>"
  }
]