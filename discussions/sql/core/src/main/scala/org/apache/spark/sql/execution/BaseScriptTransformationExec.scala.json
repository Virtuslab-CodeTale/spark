[
  {
    "id" : "ae10e953-97ca-4bfb-b588-e11cd7fe2e79",
    "prId" : 33751,
    "prUrl" : "https://github.com/apache/spark/pull/33751#pullrequestreview-730731405",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c03644fd-b3ec-4784-a5c6-00f1b9e9316a",
        "parentId" : null,
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "This is following string to date logic in BaseScriptTransformationExec",
        "createdAt" : "2021-08-16T13:43:55Z",
        "updatedAt" : "2021-08-16T13:43:55Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "7a03c24491af59c76744d791d76e06d68fe37b3f",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +226,230 @@      case YearMonthIntervalType(start, end) => wrapperConvertException(\n        data => IntervalUtils.castStringToYMInterval(UTF8String.fromString(data), start, end)\n          .map(IntervalUtils.monthsToPeriod).orNull, converter)\n      case DayTimeIntervalType(start, end) => wrapperConvertException(\n        data => IntervalUtils.microsToDuration("
  },
  {
    "id" : "9d9fa779-61bf-42a3-8dee-3a6518b27cf4",
    "prId" : 33363,
    "prUrl" : "https://github.com/apache/spark/pull/33363#pullrequestreview-709103168",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "85c6fd75-2269-4df4-9125-e2d8d223c3d6",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "nit:\r\n```\r\n        if (data == ioschema.outputRowFormatMap(\"TOK_TABLEROWFORMATNULL\")) {\r\n          null\r\n        } else {\r\n          try {\r\n            f(data)\r\n          } catch {\r\n            case NonFatal(_) => null\r\n          }\r\n        }\r\n```\r\n?",
        "createdAt" : "2021-07-16T02:00:21Z",
        "updatedAt" : "2021-07-16T02:03:48Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "5d9a4b1e-433e-48ca-be67-4d1a6bdc62cd",
        "parentId" : "85c6fd75-2269-4df4-9125-e2d8d223c3d6",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "Done",
        "createdAt" : "2021-07-19T02:14:09Z",
        "updatedAt" : "2021-07-19T02:14:09Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "4f44917dd2b2c789ea46ca365a1b60cd5fa4ee24",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +247,251 @@          } catch {\n            case NonFatal(_) => null\n          }\n        }\n      }"
  },
  {
    "id" : "2df3776d-6899-4a7c-afcb-4e3d5fbac5a1",
    "prId" : 33363,
    "prUrl" : "https://github.com/apache/spark/pull/33363#pullrequestreview-712332671",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4cd124e1-be35-46f3-a424-991c2f59e4bf",
        "parentId" : null,
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "FYI @cloud-fan @maropu For this change, I need to explain is that. \r\nIf we not add parameter -1, \r\n```\r\n\"2@false@Spark SQL@\".split('@') will have three elems\r\n\"2\"\r\n\"false\"\r\n\"Spark SQL\"\r\n```\r\nSince we are strict handle data, we need to add -1 the result should be \r\n```\r\n\"2@false@Spark SQL@\".split('@', -1) will have four elems\r\n\"2\"\r\n\"false\"\r\n\"Spark SQL\"\r\n\"\"\r\n```",
        "createdAt" : "2021-07-22T03:09:14Z",
        "updatedAt" : "2021-07-22T03:09:29Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "4f44917dd2b2c789ea46ca365a1b60cd5fa4ee24",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +119,123 @@        prevLine: String =>\n          new GenericInternalRow(\n            prevLine.split(outputRowFormat, -1).padTo(outputFieldWriters.size, null)\n              .zip(outputFieldWriters)\n              .map { case (data, writer) => writer(data) })"
  }
]