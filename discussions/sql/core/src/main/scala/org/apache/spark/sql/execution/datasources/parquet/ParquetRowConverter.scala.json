[
  {
    "id" : "8f708fce-327a-47fc-9aa1-b9fc9e479293",
    "prId" : 31357,
    "prUrl" : "https://github.com/apache/spark/pull/31357#pullrequestreview-577587706",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "609a446e-8bc4-4604-befc-1d695fa79f4c",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Got it.",
        "createdAt" : "2021-01-27T17:31:34Z",
        "updatedAt" : "2021-01-27T17:31:35Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "0fee33bf7fef207bfef061747a0d89fd93522087",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +275,279 @@          // INT32 value.\n          new ParquetIntDictionaryAwareDecimalConverter(\n            DecimalType.IntDecimal.precision, 0, updater)\n        } else {\n          new ParquetIntDictionaryAwareDecimalConverter("
  },
  {
    "id" : "f33f7b49-b38b-430d-9402-362e1696e77e",
    "prId" : 31319,
    "prUrl" : "https://github.com/apache/spark/pull/31319#pullrequestreview-576052194",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "31caa554-cbdb-4bdf-b206-43b19bb7c869",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "same question as the avro PR: how do we handle the precision/scale inconsistency between the decimal value and the catalyst decimal type?",
        "createdAt" : "2021-01-26T05:38:08Z",
        "updatedAt" : "2021-01-26T20:11:19Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "138b8259-599b-442d-b261-bd0aec9cd181",
        "parentId" : "31caa554-cbdb-4bdf-b206-43b19bb7c869",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "1. For object handling, after creating decimal object, the upper layer uses the object's precision and scale to handle the object's value. Do you have some usual-suspect code?\r\n2. For the user-facing side, this doesn't change the user-provided schema. So, there is no change from user's perspective.",
        "createdAt" : "2021-01-26T06:19:08Z",
        "updatedAt" : "2021-01-26T20:11:19Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "7932069e5c70fe6ccb99aa7b8a8725a48b402c7e",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +284,288 @@      case t: DecimalType if parquetType.asPrimitiveType().getPrimitiveTypeName == INT32 =>\n        val (precision, scale) = getPrecisionAndScale(parquetType, t)\n        new ParquetIntDictionaryAwareDecimalConverter(precision, scale, updater)\n\n      // For INT64 backed decimals"
  },
  {
    "id" : "d176b274-f91f-4e1b-9e97-4ae0af20bf8f",
    "prId" : 31319,
    "prUrl" : "https://github.com/apache/spark/pull/31319#pullrequestreview-576722424",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "05dd5dfd-9a8d-45b7-81e0-0a50931d6890",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "This is the new logic, @cloud-fan .",
        "createdAt" : "2021-01-26T20:12:28Z",
        "updatedAt" : "2021-01-26T20:12:28Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "7932069e5c70fe6ccb99aa7b8a8725a48b402c7e",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +247,251 @@   * 1. If there is a decimal metadata, we read decimal values with the given precision and scale.\n   * 2. If there is no metadata, we read decimal values with scale `0` because it's plain integers\n   *    when it is written into INT32/INT64/BINARY/FIXED_LEN_BYTE_ARRAY types.\n   */\n  private def getPrecisionAndScale(parquetType: Type, t: DecimalType): (Int, Int) = {"
  },
  {
    "id" : "fdcfdfaa-7e13-48ff-a43a-3e2ca9445adb",
    "prId" : 27888,
    "prUrl" : "https://github.com/apache/spark/pull/27888#pullrequestreview-373989249",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b5498e30-a399-4145-9c85-eb065a199d57",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "@kimtkyeom, can we add an if-else on `spark.sql.optimizer.nestedSchemaPruning.enabled`, and keep the very original codes https://github.com/apache/spark/pull/24307/files#diff-d07d3850a0ad8635a0c5562ed1e8bf26L185-L188?",
        "createdAt" : "2020-03-13T01:03:13Z",
        "updatedAt" : "2020-03-16T12:45:40Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "a0d9a19b2995e766d5b8a8d751d0426aea367c47",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +187,191 @@      CaseInsensitiveMap(catalystType.fieldNames.zipWithIndex.toMap)\n    }\n    parquetType.getFields.asScala.map { parquetField =>\n      val fieldIndex = catalystFieldNameToIndex(parquetField.getName)\n      val catalystField = catalystType(fieldIndex)"
  },
  {
    "id" : "c31b3c1f-095e-4fec-a5fa-70f220ae7e4a",
    "prId" : 27888,
    "prUrl" : "https://github.com/apache/spark/pull/27888#pullrequestreview-375431573",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "97262863-3bd6-4d5d-a60d-4edddf073da6",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "@kimtkyeom . @viirya means the following in line 182.\r\n```scala\r\n- val catalystFieldNameToIndex = if (caseSensitive) {\r\n+ val catalystFieldNameToIndex = if (SQLConf.get.caseSensitiveAnalysis) {\r\n```",
        "createdAt" : "2020-03-16T08:17:23Z",
        "updatedAt" : "2020-03-16T12:45:40Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "14a83010-6aa3-427a-b3b6-d6cf1226d188",
        "parentId" : "97262863-3bd6-4d5d-a60d-4edddf073da6",
        "authorId" : "4ad0d346-13a3-48ad-a114-c9a75205e416",
        "body" : "Aha, I will change it. Thank you for comment.",
        "createdAt" : "2020-03-16T08:23:21Z",
        "updatedAt" : "2020-03-16T12:45:40Z",
        "lastEditedBy" : "4ad0d346-13a3-48ad-a114-c9a75205e416",
        "tags" : [
        ]
      },
      {
        "id" : "c3a14c55-0c22-4706-ab12-10ada283a0bb",
        "parentId" : "97262863-3bd6-4d5d-a60d-4edddf073da6",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Oh, wait a minute for this.",
        "createdAt" : "2020-03-16T08:27:24Z",
        "updatedAt" : "2020-03-16T12:45:40Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "03979a5b-0511-4e43-a1f3-b84f7b494047",
        "parentId" : "97262863-3bd6-4d5d-a60d-4edddf073da6",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "@viirya . Is the above what you mean?",
        "createdAt" : "2020-03-16T08:30:40Z",
        "updatedAt" : "2020-03-16T12:45:40Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "3279e2cb-f58b-4c72-b86a-1b488f99edbd",
        "parentId" : "97262863-3bd6-4d5d-a60d-4edddf073da6",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Yea, thanks @dongjoon-hyun.",
        "createdAt" : "2020-03-16T17:24:56Z",
        "updatedAt" : "2020-03-16T17:24:57Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "a0d9a19b2995e766d5b8a8d751d0426aea367c47",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +179,183 @@\n  // Converters for each field.\n  private[this] val fieldConverters: Array[Converter with HasParentContainerUpdater] = {\n    // (SPARK-31116) Use case insensitive map if spark.sql.caseSensitive is false\n    // to prevent throwing IllegalArgumentException when searching catalyst type's field index"
  },
  {
    "id" : "2588ac77-beb3-4f19-bb56-ade6b8add97e",
    "prId" : 26993,
    "prUrl" : "https://github.com/apache/spark/pull/26993#pullrequestreview-337294153",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3ee089fd-93bf-45fe-85b0-bc5e5628e586",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "@JoshRosen, no big deal at all but how about we put the JIRA ID somewhere in the comment?",
        "createdAt" : "2019-12-31T03:50:01Z",
        "updatedAt" : "2020-01-06T22:21:36Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "7036e2b8-51d7-418f-a8f1-04873963fe6f",
        "parentId" : "3ee089fd-93bf-45fe-85b0-bc5e5628e586",
        "authorId" : "a11722a8-ecfa-4827-88e3-4d708f023846",
        "body" : "Good idea: I added a JIRA reference in https://github.com/apache/spark/pull/26993/commits/e6945e88a24d51551cba105b5e7e3825bc5e0a69",
        "createdAt" : "2019-12-31T04:17:54Z",
        "updatedAt" : "2020-01-06T22:21:36Z",
        "lastEditedBy" : "a11722a8-ecfa-4827-88e3-4d708f023846",
        "tags" : [
        ]
      }
    ],
    "commit" : "0f1af94c6cfc72651c3209bc0d31ae1bef140988",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +319,323 @@\n      case t: StructType =>\n        val wrappedUpdater = {\n          // SPARK-30338: avoid unnecessary InternalRow copying for nested structs:\n          // There are two cases to handle here:"
  }
]