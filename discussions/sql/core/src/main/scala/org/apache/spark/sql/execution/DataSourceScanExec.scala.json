[
  {
    "id" : "e8bd9030-fefd-4674-a16a-b72ed5296e49",
    "prId" : 31413,
    "prUrl" : "https://github.com/apache/spark/pull/31413#pullrequestreview-623210655",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dcd4d40a-b28d-4478-8234-4840bfd7d293",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "It's a bit odd that we call method name as `createNonBucketedReadRDD` but do something with buckets. I guess we could name `createNonBucketedReadRDD` like just `createReadRDD` or `createStandardReadRDD`",
        "createdAt" : "2021-03-29T13:11:32Z",
        "updatedAt" : "2021-03-29T13:11:32Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "03120af6b31af89dbc9fb9aad05045e98d52c699",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +591,595 @@      s\"open cost is considered as scanning $openCostInBytes bytes.\")\n\n    // Filter files with bucket pruning if possible\n    val bucketingEnabled = fsRelation.sparkSession.sessionState.conf.bucketingEnabled\n    val shouldProcess: Path => Boolean = optionalBucketSet match {"
  },
  {
    "id" : "de9777a3-fec5-4ba1-9725-1ffa6b61c36e",
    "prId" : 31413,
    "prUrl" : "https://github.com/apache/spark/pull/31413#pullrequestreview-623231689",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5f7b281e-4183-4bd2-b5a4-0d910d265067",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Hm, it could be one liner:\r\n\r\n```scala\r\n        filePath => BucketingUtils.getBucketId(filePath.getName).forall(bucketSet.get)\r\n```\r\n\r\nIf it looks less readable we could:\r\n\r\n```scala\r\n        filePath => BucketingUtils.getBucketId(filePath.getName).map(bucketSet.get).getOrElse\r\n```\r\n\r\nIf we worry about perf penalty from pattern matching, etc. we could do:\r\n\r\n```scala\r\n        filePath => {\r\n          val bucketId = BucketingUtils.getBucketId(filePath.getName)\r\n          if (bucketId.isEmpty) true else bucketSet.get(bucketId.get)\r\n        }\r\n``` \r\n",
        "createdAt" : "2021-03-29T13:31:51Z",
        "updatedAt" : "2021-03-29T13:31:51Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "03120af6b31af89dbc9fb9aad05045e98d52c699",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +600,604 @@            case None =>\n              // Do not prune the file if bucket file name is invalid\n              true\n          }\n        }"
  },
  {
    "id" : "7650c8c8-93c7-42ba-9490-b234881558ca",
    "prId" : 29804,
    "prUrl" : "https://github.com/apache/spark/pull/29804#pullrequestreview-498644161",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b68d92d5-e145-48b9-98b0-8fc1e7a2bf4e",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "`map` -> `foreach`",
        "createdAt" : "2020-09-22T23:59:12Z",
        "updatedAt" : "2020-10-01T01:11:06Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "8e1e42bc-614a-4db5-b72f-edfe076ee538",
        "parentId" : "b68d92d5-e145-48b9-98b0-8fc1e7a2bf4e",
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "@maropu - just for my own education, why does it matter? Updated anyway.",
        "createdAt" : "2020-09-23T06:14:15Z",
        "updatedAt" : "2020-10-01T01:11:06Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      },
      {
        "id" : "3b67c24e-9698-44a3-9090-d70048894e24",
        "parentId" : "b68d92d5-e145-48b9-98b0-8fc1e7a2bf4e",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Yea, I remember the previous discussion: https://issues.apache.org/jira/browse/SPARK-16694",
        "createdAt" : "2020-09-23T09:53:07Z",
        "updatedAt" : "2020-10-01T01:11:06Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "f174cba5-ad3f-43b4-a96e-2f0170dfcec4",
        "parentId" : "b68d92d5-e145-48b9-98b0-8fc1e7a2bf4e",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Yea, please only use `map` when you care about the return value. `foreach` is better if you just want to do some calculation if `Option` is `Some`",
        "createdAt" : "2020-09-29T11:13:46Z",
        "updatedAt" : "2020-10-01T01:11:06Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "c2607647-7599-412d-b0c8-471b3b3c4bd3",
        "parentId" : "b68d92d5-e145-48b9-98b0-8fc1e7a2bf4e",
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "@cloud-fan , @maropu - I changed the code during iterations. The current change is just adding a `if (bucketedScan) { ... } else { ... }` on top of original code, where we still need to use `map` as it's returning value.",
        "createdAt" : "2020-09-29T15:57:47Z",
        "updatedAt" : "2020-10-01T01:11:06Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      }
    ],
    "commit" : "b29f688fc4a06bc35effa6d24632d2a64501c9fd",
    "line" : 40,
    "diffHunk" : "@@ -1,1 +355,359 @@    // TODO(SPARK-32986): Add bucketed scan info in explain output of FileSourceScanExec\n    if (bucketedScan) {\n      relation.bucketSpec.map { spec =>\n        val numSelectedBuckets = optionalBucketSet.map { b =>\n          b.cardinality()"
  },
  {
    "id" : "39455706-a2ed-4142-bbcc-96c643a6123e",
    "prId" : 29637,
    "prUrl" : "https://github.com/apache/spark/pull/29637#pullrequestreview-481710317",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "13fc6e89-4351-4652-9cf1-e0f84b20ad6e",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This change is not needed, but I keep it here for: 1. avoid duplicated code. 2. make it super safe that we only update the `numPartitions` if table is partitioned.",
        "createdAt" : "2020-09-03T10:35:10Z",
        "updatedAt" : "2020-09-03T12:16:53Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "3e4a6a5d9a8f4151735b67c9dc585201e8543ab5",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +436,440 @@      driverMetrics(\"staticFilesSize\") = filesSize\n    }\n    if (relation.partitionSchemaOption.isDefined) {\n      driverMetrics(\"numPartitions\") = partitions.length\n    }"
  }
]