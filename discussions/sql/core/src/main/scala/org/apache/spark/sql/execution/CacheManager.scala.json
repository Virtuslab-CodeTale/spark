[
  {
    "id" : "9e615724-9ea2-4eb4-bc6e-d19cabfd884c",
    "prId" : 32482,
    "prUrl" : "https://github.com/apache/spark/pull/32482#pullrequestreview-659419079",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "56711fd9-a92f-4fc0-a8d3-6a1013c7b251",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "\"If CAN_CHANGE_CACHED_PLAN_OUTPUT_PARTITIONING is disabled\" -> do we mean enabled?",
        "createdAt" : "2021-05-13T17:33:10Z",
        "updatedAt" : "2021-05-13T17:33:11Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "393cafae-3894-4809-982d-24d3361c7f33",
        "parentId" : "56711fd9-a92f-4fc0-a8d3-6a1013c7b251",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "good catch!",
        "createdAt" : "2021-05-13T17:48:41Z",
        "updatedAt" : "2021-05-13T17:48:41Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "9c424dbe-d077-457f-975a-aac62724ef38",
        "parentId" : "56711fd9-a92f-4fc0-a8d3-6a1013c7b251",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "Sorry, forgot to fix the comment, create followup [#32543](https://github.com/apache/spark/pull/32543).",
        "createdAt" : "2021-05-14T01:22:50Z",
        "updatedAt" : "2021-05-14T01:22:50Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "2e8492baf2c9b6dba3bd635f2b3a25d288e7f3ab",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +329,333 @@\n  /**\n   * If CAN_CHANGE_CACHED_PLAN_OUTPUT_PARTITIONING is disabled, just return original session.\n   */\n  private def getOrCloneSessionWithConfigsOff(session: SparkSession): SparkSession = {"
  },
  {
    "id" : "eb318452-0bb7-4c9e-9bc3-c35e4e83060f",
    "prId" : 30815,
    "prUrl" : "https://github.com/apache/spark/pull/30815#pullrequestreview-554934649",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "18475ecb-d8e0-4847-9e01-c1e5cdd52bd1",
        "parentId" : null,
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "+1 on this!  I think we may replace one more usage in `DataSourceV2Strategy.invalidateCache` as well.\r\n\r\n",
        "createdAt" : "2020-12-17T18:12:29Z",
        "updatedAt" : "2020-12-17T19:48:44Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "8354317a-1f01-44a1-a9d4-1cde7e613050",
        "parentId" : "18475ecb-d8e0-4847-9e01-c1e5cdd52bd1",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "thanks, updated.",
        "createdAt" : "2020-12-17T19:48:34Z",
        "updatedAt" : "2020-12-17T19:48:44Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "bc80b6d30307b7876a1b4e4e8d383bd387d89b0a",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +97,101 @@   * recomputing the in-memory columnar representation of the underlying table is expensive.\n   */\n  def cacheQuery(\n      spark: SparkSession,\n      planToCache: LogicalPlan,"
  },
  {
    "id" : "212a2224-ccc5-4d4c-83e6-576554b15c64",
    "prId" : 30815,
    "prUrl" : "https://github.com/apache/spark/pull/30815#pullrequestreview-554868098",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4baaa0ef-4b3a-4361-8edf-e3474cace9b9",
        "parentId" : null,
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "perhaps we can just keep a single method with default value of `tableName` being `None` and `storageLevel` being `MEMORY_AND_DISK`?",
        "createdAt" : "2020-12-17T18:15:30Z",
        "updatedAt" : "2020-12-17T19:48:44Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "c96731b4-6af5-4e35-b111-0589b9a3297b",
        "parentId" : "4baaa0ef-4b3a-4361-8edf-e3474cace9b9",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "The scala compiler will complain if we do that. See https://github.com/apache/spark/pull/30815#discussion_r544815956",
        "createdAt" : "2020-12-17T18:17:26Z",
        "updatedAt" : "2020-12-17T19:48:44Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "f5929010-9dd9-42b4-bcb6-5d1ea9bda828",
        "parentId" : "4baaa0ef-4b3a-4361-8edf-e3474cace9b9",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "Ah got it. Thanks.",
        "createdAt" : "2020-12-17T18:18:54Z",
        "updatedAt" : "2020-12-17T19:48:44Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      }
    ],
    "commit" : "bc80b6d30307b7876a1b4e4e8d383bd387d89b0a",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +111,115 @@      planToCache: LogicalPlan,\n      tableName: Option[String],\n      storageLevel: StorageLevel): Unit = {\n    if (lookupCachedData(planToCache).nonEmpty) {\n      logWarning(\"Asked to cache already cached data.\")"
  },
  {
    "id" : "2f0dc745-0671-4dba-b9e0-394c8906d945",
    "prId" : 28948,
    "prUrl" : "https://github.com/apache/spark/pull/28948#pullrequestreview-439689407",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ccd40c3f-f69d-47a7-abec-a4d8d83444fb",
        "parentId" : null,
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "how about we change the method as\r\n```\r\ndef recacheByPath(spark: SparkSession, resourcePath: String, options: Map[String, String]=Map.empty)\r\n```\r\nso that we can avoid the new method below?",
        "createdAt" : "2020-06-29T21:45:36Z",
        "updatedAt" : "2020-06-30T06:46:13Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "c46fb11c-4ef0-4ee7-bc11-52247e020962",
        "parentId" : "ccd40c3f-f69d-47a7-abec-a4d8d83444fb",
        "authorId" : "eec69026-4066-480b-afca-bd70f71d6813",
        "body" : "That also works, but it feels a little bit weird to couple the data source options concept with the cache manager...",
        "createdAt" : "2020-06-30T05:54:05Z",
        "updatedAt" : "2020-06-30T06:46:13Z",
        "lastEditedBy" : "eec69026-4066-480b-afca-bd70f71d6813",
        "tags" : [
        ]
      }
    ],
    "commit" : "2d7975ec67d12025f6c09d688d6cdb033ef5072f",
    "line" : 3,
    "diffHunk" : "@@ -1,1 +248,252 @@   * `HadoopFsRelation` node(s) as part of its logical plan.\n   */\n  def recacheByPath(spark: SparkSession, resourcePath: String): Unit = {\n    val path = new Path(resourcePath)\n    val fs = path.getFileSystem(spark.sessionState.newHadoopConf())"
  },
  {
    "id" : "0fc0f90b-1709-4717-be85-30acc1696b43",
    "prId" : 26813,
    "prUrl" : "https://github.com/apache/spark/pull/26813#pullrequestreview-337281629",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "763cc1f2-5296-456c-8a14-9fb02d857085",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "nit: `val qe = try ...` can reduce the code diff",
        "createdAt" : "2019-12-30T15:28:27Z",
        "updatedAt" : "2020-01-13T07:45:09Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "ec3ace4b-9251-49d1-bb88-d104ce9ca679",
        "parentId" : "763cc1f2-5296-456c-8a14-9fb02d857085",
        "authorId" : "1b84a7ff-6bf9-4417-bf9f-e46e997e5974",
        "body" : "Here we need put `inMemoryRelation `in `try `not  `qe`. Because only when executing `qe.executedPlan`, it will be inserted `AdaptiveSparkPlanExec`. And I will remove the `qe `before `try` later.",
        "createdAt" : "2019-12-31T01:49:43Z",
        "updatedAt" : "2020-01-13T07:45:09Z",
        "lastEditedBy" : "1b84a7ff-6bf9-4417-bf9f-e46e997e5974",
        "tags" : [
        ]
      }
    ],
    "commit" : "8b5e7442c63fe326db7c7f46f7a194fbae8f0d46",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +83,87 @@      val qe = sparkSession.sessionState.executePlan(planToCache)\n      val originalValue = sparkSession.sessionState.conf.getConf(SQLConf.ADAPTIVE_EXECUTION_ENABLED)\n      val inMemoryRelation = try {\n        // Avoiding changing the output partitioning, here disable AQE.\n        sparkSession.sessionState.conf.setConf(SQLConf.ADAPTIVE_EXECUTION_ENABLED, false)"
  },
  {
    "id" : "f93232fb-da87-4124-b00a-a43f0fabdd21",
    "prId" : 26813,
    "prUrl" : "https://github.com/apache/spark/pull/26813#pullrequestreview-339041481",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7d79f436-aedd-42c6-9ff5-d1eb56a19bb4",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can we add a comment to explain why disable it? e.g. to avoid changing the output partitioning",
        "createdAt" : "2020-01-07T05:51:15Z",
        "updatedAt" : "2020-01-13T07:45:09Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "8b5e7442c63fe326db7c7f46f7a194fbae8f0d46",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +85,89 @@      val inMemoryRelation = try {\n        // Avoiding changing the output partitioning, here disable AQE.\n        sparkSession.sessionState.conf.setConf(SQLConf.ADAPTIVE_EXECUTION_ENABLED, false)\n        InMemoryRelation(\n          sparkSession.sessionState.conf.useCompression,"
  },
  {
    "id" : "a4cc67f6-adda-4b7f-b75d-109b51c9f8e5",
    "prId" : 24580,
    "prUrl" : "https://github.com/apache/spark/pull/24580#pullrequestreview-236795121",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "63674526-be4b-4df5-a2fb-701e170cddf6",
        "parentId" : null,
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "If the original cached plan has a hint, should we keep/respect them? We need to define a clear behavior in our cache manager.",
        "createdAt" : "2019-05-13T05:14:48Z",
        "updatedAt" : "2019-05-14T13:37:33Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      },
      {
        "id" : "14795069-8e2b-4026-8c81-d4f32e45108a",
        "parentId" : "63674526-be4b-4df5-a2fb-701e170cddf6",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "It doesn't matter, because\r\n1. as a cache key, the lookup relies on `semanticEquals`, so having the hint node in the plan has no effect.\r\n2. the cache lookup returns `InMemoryRelation`, which has no hint.\r\n\r\nI think the behavior is pretty clear: for any query, the hint behavior should be the same no matter some sub-plans are cached or not.",
        "createdAt" : "2019-05-13T06:00:17Z",
        "updatedAt" : "2019-05-14T13:37:33Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "a1a8f642-3e86-4fef-a14b-57bd7157bd49",
        "parentId" : "63674526-be4b-4df5-a2fb-701e170cddf6",
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "Basically, we ignore the hints that are specified in the original cached plans. If users want to use hints, they should specify them in the queries. ",
        "createdAt" : "2019-05-13T16:46:57Z",
        "updatedAt" : "2019-05-14T13:37:33Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      }
    ],
    "commit" : "48e55fa8037bfb47cc6d0b56337faf79c2924730",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +217,221 @@      case currentFragment =>\n        lookupCachedData(currentFragment).map { cached =>\n          // After cache lookup, we should still keep the hints from the input plan.\n          val hints = EliminateResolvedHint.extractHintsFromPlan(currentFragment)._2\n          val cachedPlan = cached.cachedRepresentation.withOutput(currentFragment.output)"
  },
  {
    "id" : "4c8553cb-d755-4489-a7a4-8f29818e608c",
    "prId" : 24580,
    "prUrl" : "https://github.com/apache/spark/pull/24580#pullrequestreview-237029849",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "32ed3c16-5915-4b0e-9076-a0e5a3ad9f32",
        "parentId" : null,
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "`extractHintsFromPlan(currentFragment)._2` was originally a private function. Asking the caller to call reverse is weird. We can add a new function in EliminateResolvedHint or even add a new object for Hint processing. ",
        "createdAt" : "2019-05-13T17:08:18Z",
        "updatedAt" : "2019-05-14T13:37:33Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      },
      {
        "id" : "0eaa21bd-caaf-484f-b11e-91b37721479f",
        "parentId" : "32ed3c16-5915-4b0e-9076-a0e5a3ad9f32",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "It's natural to return the hints in a top-down fashion. And the caller side is free to process the returned hints, including reverse it. ",
        "createdAt" : "2019-05-14T05:15:58Z",
        "updatedAt" : "2019-05-14T13:37:33Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "48e55fa8037bfb47cc6d0b56337faf79c2924730",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +218,222 @@        lookupCachedData(currentFragment).map { cached =>\n          // After cache lookup, we should still keep the hints from the input plan.\n          val hints = EliminateResolvedHint.extractHintsFromPlan(currentFragment)._2\n          val cachedPlan = cached.cachedRepresentation.withOutput(currentFragment.output)\n          // The returned hint list is in top-down order, we should create the hint nodes from"
  },
  {
    "id" : "2ba0b807-656c-400c-85c6-b7eb6a28af04",
    "prId" : 24580,
    "prUrl" : "https://github.com/apache/spark/pull/24580#pullrequestreview-237595446",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0fb0a554-0f7d-40eb-92cd-d381d8386088",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Is this the same (semantically) as original cached plan?\r\n\r\nWe can take one example in added test: `broadcast(spark.range(1000)).filter($\"id\" > 100)`. Originally, the plan broadcasted is `spark.range(1000)`. After using cached data, seems cached `spark.range(1000).filter($\"id\" > 100)` is broadcasted by the hint, actually. It is slightly difference, but maybe in significant effect it might cause?",
        "createdAt" : "2019-05-14T15:51:40Z",
        "updatedAt" : "2019-05-14T15:51:40Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "8724f513-69c3-4d9e-bb3a-7cc4cb56e4f8",
        "parentId" : "0fb0a554-0f7d-40eb-92cd-d381d8386088",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "The semantic of a hint node is special. By design only join node has hints, so `Hint(Filter(Relation))` is the same as `Filter(Hint(Relation))`, as they both indicate that the left/right sub-tree of a join node has a hint.",
        "createdAt" : "2019-05-15T03:09:03Z",
        "updatedAt" : "2019-05-15T03:09:04Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "ad1b3d0f-bbab-4bb4-8ba8-e74b3274b5c7",
        "parentId" : "0fb0a554-0f7d-40eb-92cd-d381d8386088",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Ok, I see. Makes sense and it's fine.",
        "createdAt" : "2019-05-15T03:34:52Z",
        "updatedAt" : "2019-05-15T03:34:52Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "48e55fa8037bfb47cc6d0b56337faf79c2924730",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +223,227 @@          // right to left.\n          hints.foldRight[LogicalPlan](cachedPlan) { case (hint, p) =>\n            ResolvedHint(p, hint)\n          }\n        }.getOrElse(currentFragment)"
  }
]