[
  {
    "id" : "53126310-310c-43bc-b994-b365e36bb79f",
    "prId" : 31804,
    "prUrl" : "https://github.com/apache/spark/pull/31804#pullrequestreview-609398956",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2e68d73b-fcdb-4ab0-aa5d-1278732f50e2",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Do we still have a test coverage for this line?",
        "createdAt" : "2021-03-11T04:55:18Z",
        "updatedAt" : "2021-03-30T07:59:14Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "f028eb37-c14a-4574-9425-007adbd14fea",
        "parentId" : "2e68d73b-fcdb-4ab0-aa5d-1278732f50e2",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "yes, the new `show-tables-legacy.sql` will import the corresponding tests to cover.  I can add some cases in `v1.ShowTablesSuite` if `show-tables-legacy.sql` is unintuitive",
        "createdAt" : "2021-03-11T05:09:47Z",
        "updatedAt" : "2021-03-30T07:59:14Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "3ef5b5f414b68ea149877eaa26618e9787252004",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +857,861 @@            Row(database, tableName, isTemp, tableType)\n          } else {\n            Row(database, tableName, isTemp)\n          }\n"
  },
  {
    "id" : "29bd4783-6950-478c-b3df-0dd042aba42c",
    "prId" : 31378,
    "prUrl" : "https://github.com/apache/spark/pull/31378#pullrequestreview-580376725",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c4636c85-f30e-44f2-894b-bc0da10023f0",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "do we need the `override val`?",
        "createdAt" : "2021-02-01T13:53:23Z",
        "updatedAt" : "2021-02-08T15:01:25Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "1b3376ae-0d9b-4266-a6d4-cd5c4608d35b",
        "parentId" : "c4636c85-f30e-44f2-894b-bc0da10023f0",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "Same change as last PR https://github.com/apache/spark/pull/31341/files\r\n![image](https://user-images.githubusercontent.com/46485123/106468154-87439980-64d8-11eb-89cb-c04c8316d323.png)\r\n",
        "createdAt" : "2021-02-01T13:57:57Z",
        "updatedAt" : "2021-02-08T15:01:25Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "cc9d8ac1105a336997384eab475fc82458d92b01",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +900,904 @@    table: TableIdentifier,\n    propertyKey: Option[String],\n    override val output: Seq[Attribute]) extends RunnableCommand {\n\n  override def run(sparkSession: SparkSession): Seq[Row] = {"
  },
  {
    "id" : "bce2af5f-c25c-4e72-b281-aeffb02141aa",
    "prId" : 31377,
    "prUrl" : "https://github.com/apache/spark/pull/31377#pullrequestreview-580380244",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c4fd725f-4b49-4ee2-a708-980ba676520d",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "do we need `override val`?",
        "createdAt" : "2021-02-01T13:56:15Z",
        "updatedAt" : "2021-02-01T13:56:15Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "b09ee167-febe-482f-861c-a4dab0d9fe2a",
        "parentId" : "c4fd725f-4b49-4ee2-a708-980ba676520d",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> do we need `override val`?\r\n\r\nSame change as last PR https://github.com/apache/spark/pull/31341/files\r\n![image](https://user-images.githubusercontent.com/46485123/106468154-87439980-64d8-11eb-89cb-c04c8316d323.png)\r\n",
        "createdAt" : "2021-02-01T14:01:47Z",
        "updatedAt" : "2021-02-01T14:01:47Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "81d5a38ac0209edce01e60e7d6e24aaa66ffa81e",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +937,941 @@    databaseName: Option[String],\n    tableName: TableIdentifier,\n    override val output: Seq[Attribute]) extends RunnableCommand {\n\n  override def run(sparkSession: SparkSession): Seq[Row] = {"
  },
  {
    "id" : "130ff021-c230-41f1-8a6d-1375cca79270",
    "prId" : 31368,
    "prUrl" : "https://github.com/apache/spark/pull/31368#pullrequestreview-577669100",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e9956f79-e6fb-457d-839a-11e278c8e191",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "the view plan can be unresolved (with cast and alias added), we should use the recorded view schema.",
        "createdAt" : "2021-01-27T19:07:26Z",
        "updatedAt" : "2021-01-29T04:46:02Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "2aebf0516f146456e4567612db8823fc3407641b",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +626,630 @@          s\"DESC PARTITION is not allowed on a temporary view: ${table.identifier}\")\n      }\n      val schema = catalog.getTempViewOrPermanentTableMetadata(table).schema\n      describeSchema(schema, result, header = false)\n    } else {"
  },
  {
    "id" : "0227b4f0-6965-4476-8f5b-373d2757e33c",
    "prId" : 31308,
    "prUrl" : "https://github.com/apache/spark/pull/31308#pullrequestreview-576208545",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "20392d5c-51ad-4ba7-8779-8ccc925d1415",
        "parentId" : null,
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "Hmm... Not sure if we should catch any non-fatal exception like the previous one, since otherwise we'd skip updating stats?",
        "createdAt" : "2021-01-24T20:37:34Z",
        "updatedAt" : "2021-01-24T20:37:37Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "3ad37773-d940-4ddf-b925-57d063941707",
        "parentId" : "20392d5c-51ad-4ba7-8779-8ccc925d1415",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "1. We don't catch any exceptions in other commands\r\n2. What kind of exceptions should we hide (catch) from users here?",
        "createdAt" : "2021-01-24T20:51:24Z",
        "updatedAt" : "2021-01-24T21:01:50Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "064a1ebd-bc69-40b0-a702-daebc34ee82e",
        "parentId" : "20392d5c-51ad-4ba7-8779-8ccc925d1415",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Not clear which exceptions are caught here. `uncacheQuery()` doesn't throw anything, `spark.table(table.identifier).logicalPlan` could fail but in that case it is not clear how we reached this point.",
        "createdAt" : "2021-01-24T21:10:01Z",
        "updatedAt" : "2021-01-24T21:10:01Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "08c311cb-ce3c-465b-ba37-0358b416738c",
        "parentId" : "20392d5c-51ad-4ba7-8779-8ccc925d1415",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "I think someone could drop a table or permanent view in a different session, or drop a Hive table through beeline or HMS API. This may cause some cache which depend on them AND this truncated table to become invalid, and potentially analysis exception when recaching them. I haven't got a chance to verify this though.\r\n\r\nI feel overall it will be a good practice to recover from unknown errors here and continue. `DropTableCommand` does this as well.",
        "createdAt" : "2021-01-25T03:47:49Z",
        "updatedAt" : "2021-01-25T03:48:03Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "a0738496-f356-40d4-8091-fdf990892861",
        "parentId" : "20392d5c-51ad-4ba7-8779-8ccc925d1415",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "The case which you described here is applicable to any other commands like add/drop/rename/recover partitions. I do believe we either should \"fix\" all commands with tests for the case, or apply the approach w/o catching exceptions here as we do in other commands so far (otherwise the implementation looks inconsistent).",
        "createdAt" : "2021-01-25T06:20:29Z",
        "updatedAt" : "2021-01-25T06:20:29Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "4c522392-5da2-4a78-9777-9eb00f67e5f4",
        "parentId" : "20392d5c-51ad-4ba7-8779-8ccc925d1415",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "Personally I'd keep just the try-catch logic here because I think the above do happens and we shouldn't skip updating stats in the case. But I don't really have strong opinion on this.",
        "createdAt" : "2021-01-25T08:25:02Z",
        "updatedAt" : "2021-01-25T08:25:03Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "14f7a989-4fbc-4fd6-936f-d9ebe08986f2",
        "parentId" : "20392d5c-51ad-4ba7-8779-8ccc925d1415",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can we fix the inconsistency first? i.e. reach an agreement about whether we should add `try-cache` or not for all other commands.",
        "createdAt" : "2021-01-25T08:53:09Z",
        "updatedAt" : "2021-01-25T08:53:09Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "89790a28-0f87-43af-b8dd-0a3b3fe1bfd9",
        "parentId" : "20392d5c-51ad-4ba7-8779-8ccc925d1415",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "> ... someone could drop a table or permanent view in a different session, or drop a Hive table through beeline or HMS API.\r\n\r\nIf somebody dropped the table in parallel, updating statistics wouldn't matter any more. We should show the error to user as soon as possible.\r\n\r\n> can we fix the inconsistency first?\r\n\r\n@sunchao Can you write a test which reproduces the issue?",
        "createdAt" : "2021-01-25T09:16:16Z",
        "updatedAt" : "2021-01-25T09:16:17Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "1cbb21c2-0504-4559-ae29-92a7233d8d08",
        "parentId" : "20392d5c-51ad-4ba7-8779-8ccc925d1415",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "We might utilize `HiveThriftServer2Suites` for this - I can check when I got time.",
        "createdAt" : "2021-01-25T23:53:55Z",
        "updatedAt" : "2021-01-25T23:53:55Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "446ac16c-ee77-404e-bb6c-24a882cd3f16",
        "parentId" : "20392d5c-51ad-4ba7-8779-8ccc925d1415",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "So I wasn't able to reproduce it with the above example, sorry for the false alarm. Turned out the analysis exception will be thrown later when the cache is actually queried (rather than in `recacheByPlan` itself). Therefore, I think it should be fine in this case.\r\n\r\nI do agree we should keep it consistent (whether try-catch or not). IMO it can be done separately tho.",
        "createdAt" : "2021-01-26T10:20:42Z",
        "updatedAt" : "2021-01-26T10:20:42Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      }
    ],
    "commit" : "25b8583d65246372f8b6ac35071ead118b1c97f2",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +564,568 @@    // After deleting the data, refresh the table to make sure we don't keep around a stale\n    // file relation in the metastore cache and cached table data in the cache manager.\n    spark.catalog.refreshTable(tableIdentWithDB)\n\n    if (table.stats.nonEmpty) {"
  },
  {
    "id" : "70b596dd-1de9-4143-8b2b-a8d4c2b17290",
    "prId" : 31245,
    "prUrl" : "https://github.com/apache/spark/pull/31245#pullrequestreview-576937862",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d3418237-c1b8-4221-a5ef-a555389b607a",
        "parentId" : null,
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "We can remove this line since https://github.com/apache/spark/pull/31342 merged",
        "createdAt" : "2021-01-27T02:06:21Z",
        "updatedAt" : "2021-02-08T08:25:31Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "920c23f1-e327-43fa-bbd8-cbd1b68914a0",
        "parentId" : "d3418237-c1b8-4221-a5ef-a555389b607a",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "Yeah!",
        "createdAt" : "2021-01-27T02:47:41Z",
        "updatedAt" : "2021-02-08T08:25:31Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "815d36b35c294d110cf0770d2f0850d9ae1da151",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +829,833 @@    isExtended: Boolean = false,\n    partitionSpec: Option[TablePartitionSpec] = None) extends RunnableCommand {\n\n  override def run(sparkSession: SparkSession): Seq[Row] = {\n    // Since we need to return a Seq of rows, we will call getTables directly"
  },
  {
    "id" : "786c5bf1-dc6f-4783-a707-b0547d1e783e",
    "prId" : 30774,
    "prUrl" : "https://github.com/apache/spark/pull/30774#pullrequestreview-553152156",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "133b23ad-9e44-48b9-9f6f-ea76fc64d68b",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Does this miss the `tableName` if there is in the original cache?",
        "createdAt" : "2020-12-15T06:57:13Z",
        "updatedAt" : "2020-12-15T07:49:21Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "f17f2fdc-4681-482d-8abe-4bc2702bcb8c",
        "parentId" : "133b23ad-9e44-48b9-9f6f-ea76fc64d68b",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "Sorry, I didn't get this question. This is creating a new cache with a new table name.",
        "createdAt" : "2020-12-15T07:33:11Z",
        "updatedAt" : "2020-12-15T07:49:21Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      },
      {
        "id" : "be46b523-dd5c-4147-a53d-7457e8f219ef",
        "parentId" : "133b23ad-9e44-48b9-9f6f-ea76fc64d68b",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Hm, you can check the change like #30769. Especially how it recaches the table. There is a `cacheName` parameter. If the table was cached with a cache name, when recaching it, I think we should keep it.\r\n\r\n```scala\r\n    val cache = session.sharedState.cacheManager.lookupCachedData(v2Relation)\r\n    session.sharedState.cacheManager.uncacheQuery(session, v2Relation, cascade = true)\r\n    session.sharedState.cacheManager.uncacheQuery(session, v2Relation, cascade = true)\r\n    if (recacheTable && cache.isDefined) {\r\n      // save the cache name and cache level for recreation\r\n      val cacheName = cache.get.cachedRepresentation.cacheBuilder.tableName\r\n      val cacheLevel = cache.get.cachedRepresentation.cacheBuilder.storageLevel\r\n\r\n      // recache with the same name and cache level.\r\n      val ds = Dataset.ofRows(session, v2Relation)\r\n      session.sharedState.cacheManager.cacheQuery(ds, cacheName, cacheLevel)\r\n    }\r\n```",
        "createdAt" : "2020-12-15T08:53:57Z",
        "updatedAt" : "2020-12-15T08:53:58Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "fedffb95-8557-431e-920b-2b778f89df15",
        "parentId" : "133b23ad-9e44-48b9-9f6f-ea76fc64d68b",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "The previous code seems also recache with the new name?",
        "createdAt" : "2020-12-15T09:04:35Z",
        "updatedAt" : "2020-12-15T09:04:35Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "288ad92e-52b7-406c-acd5-74e2a3d2bce3",
        "parentId" : "133b23ad-9e44-48b9-9f6f-ea76fc64d68b",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "No, the refresh table command for v2 doesn't recache the table before #30769.",
        "createdAt" : "2020-12-15T09:09:06Z",
        "updatedAt" : "2020-12-15T09:09:06Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "c75e7042-05bb-465b-9140-c920ca9ed6c6",
        "parentId" : "133b23ad-9e44-48b9-9f6f-ea76fc64d68b",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I mean the previous code in `AlterTableRenameCommand`. We shouldn't change its behavior regarding cache name in this bug fix PR.",
        "createdAt" : "2020-12-15T14:06:07Z",
        "updatedAt" : "2020-12-15T14:06:07Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "bd71cbd6-78b8-493e-87bd-7f496e013158",
        "parentId" : "133b23ad-9e44-48b9-9f6f-ea76fc64d68b",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Hmm okay, actually it also sounds like a bug if alter table command changes the cache name. I'm fine to leave it unchanged here.",
        "createdAt" : "2020-12-15T17:40:02Z",
        "updatedAt" : "2020-12-15T17:40:02Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "0bbe6409-8dcf-41f9-b802-aea8dd9b86cd",
        "parentId" : "133b23ad-9e44-48b9-9f6f-ea76fc64d68b",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "I believe cache name is used for debug purpose only (for `RDD` name and `InMemoryTableScanExec`). So if the cache name - which is tied to the table name - doesn't change when the table is changed, wouldn't it cause a confusion since it will still refer to the old table name? I can do a follow up PR if this seems like a bug.",
        "createdAt" : "2020-12-16T00:13:48Z",
        "updatedAt" : "2020-12-16T00:13:48Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "11603d54d4a6b222edc2c5dbd4755e3a1e9072a2",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +205,209 @@      catalog.renameTable(oldName, newName)\n      optStorageLevel.foreach { storageLevel =>\n        sparkSession.catalog.cacheTable(newName.unquotedString, storageLevel)\n      }\n    }"
  },
  {
    "id" : "d54482ec-54e0-47ac-b85e-e2dc09c655d2",
    "prId" : 29866,
    "prUrl" : "https://github.com/apache/spark/pull/29866#pullrequestreview-495977526",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "04add2b5-29ed-4635-a706-643452047303",
        "parentId" : null,
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "This is moved from `ddl.scala` and `RefreshTable` is renamed to `RefreshTableCommand`. Note that there is a TODO in this file that all the commands in `ddl.scala` need to move here, so I will handle it separately.",
        "createdAt" : "2020-09-24T21:54:16Z",
        "updatedAt" : "2020-09-25T03:53:55Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "d1051c6fad37993a299ed79617f574d6ce51c890",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +1400,1404 @@    Seq.empty[Row]\n  }\n}"
  },
  {
    "id" : "f8d3a780-02d4-4afc-97d2-92c6d8a8bc60",
    "prId" : 29387,
    "prUrl" : "https://github.com/apache/spark/pull/29387#pullrequestreview-472920172",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "711a4e06-2a2e-4437-bde5-1664e7b5672e",
        "parentId" : null,
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "do we need to have test cases to cover when the flag is on or off?",
        "createdAt" : "2020-08-21T21:03:49Z",
        "updatedAt" : "2020-08-24T22:01:57Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "6c530de2-84ff-4922-a756-8e90d70d623c",
        "parentId" : "711a4e06-2a2e-4437-bde5-1664e7b5672e",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "+1 for adding a test coverage for the new feature (if possible).",
        "createdAt" : "2020-08-22T00:22:40Z",
        "updatedAt" : "2020-08-24T22:01:57Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "5740af91-85e5-4d7a-a730-085aae13be17",
        "parentId" : "711a4e06-2a2e-4437-bde5-1664e7b5672e",
        "authorId" : "a88f50e2-6440-4a6c-8883-3130888d05bc",
        "body" : "added tests please review",
        "createdAt" : "2020-08-22T11:29:59Z",
        "updatedAt" : "2020-08-24T22:01:57Z",
        "lastEditedBy" : "a88f50e2-6440-4a6c-8883-3130888d05bc",
        "tags" : [
        ]
      }
    ],
    "commit" : "a2df53b48db372ed8f9a303cd8c0c499e33f3adf",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +516,520 @@          }\n\n          Utils.moveToTrashIfEnabled(fs, path, isTrashEnabled, hadoopConf)\n\n          // We should keep original permission/acl of the path."
  },
  {
    "id" : "61e7f5ce-9c76-4996-b6dc-aeb1274d4017",
    "prId" : 29127,
    "prUrl" : "https://github.com/apache/spark/pull/29127#pullrequestreview-449577938",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ef998968-e607-4a91-ba1c-cfaa33d5d9e1",
        "parentId" : null,
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "This will not be hit if you go thru `SHOW TBLPROPERTIES` command.",
        "createdAt" : "2020-07-16T07:29:20Z",
        "updatedAt" : "2020-07-24T00:35:29Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "933dc28ed5a54e06d8125e51ae3c86e95760f21e",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +921,925 @@    val catalog = sparkSession.sessionState.catalog\n    if (catalog.isTemporaryTable(table)) {\n      throw new AnalysisException(s\"SHOW TBLPROPERTIES is not allowed on a temporary view: $table\")\n    } else {\n      val catalogTable = catalog.getTableMetadata(table)"
  }
]