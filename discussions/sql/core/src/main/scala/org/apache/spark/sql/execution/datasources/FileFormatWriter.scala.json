[
  {
    "id" : "790523b2-ea13-4352-8792-8411f717b1bb",
    "prId" : 33279,
    "prUrl" : "https://github.com/apache/spark/pull/33279#pullrequestreview-705961435",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bbccf4ae-6135-47cb-9683-5a346e041ac1",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "After some more thought, I think it's better to use SQL metrics for it. It's very hard to know max/min/avg by reading the logs.\r\n\r\n@AngersZhuuuu I think you tried it before. Can you restore the work? ",
        "createdAt" : "2021-07-14T07:15:29Z",
        "updatedAt" : "2021-07-14T07:15:29Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "4dba9c78-afe5-4e75-ac2c-29c4a8f4e79c",
        "parentId" : "bbccf4ae-6135-47cb-9683-5a346e041ac1",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> After some more thought, I think it's better to use SQL metrics for it. It's very hard to know max/min/avg by reading the logs.\r\n> \r\n> @AngersZhuuuu I think you tried it before. Can you restore the work?\r\n\r\nYea, working on this",
        "createdAt" : "2021-07-14T07:51:47Z",
        "updatedAt" : "2021-07-14T07:51:47Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "fb3af2a23f6c4d9ca0bbc45451f73307341e78c6",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +308,312 @@          dataWriter.commit()\n        }\n        logInfo(s\"$taskAttemptID finished to write and commit. Elapsed time: $timeCost ms.\")\n        res\n      })(catchBlock = {"
  },
  {
    "id" : "622d39fe-4fd0-44d2-a7ea-e20404c4800c",
    "prId" : 32881,
    "prUrl" : "https://github.com/apache/spark/pull/32881#pullrequestreview-688077390",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4e780141-7141-43d0-ba61-6ab4b666d9aa",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "why not pass 2 parameter?",
        "createdAt" : "2021-06-21T05:23:18Z",
        "updatedAt" : "2021-06-21T05:23:18Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "87b1cb77-44ad-4a7d-a6a0-1107edfceccc",
        "parentId" : "4e780141-7141-43d0-ba61-6ab4b666d9aa",
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "From my side, whenever I add the 11th parameter of a scala method, intellij will mark it as a lint error. Do we have # of parameter rule in Spark?",
        "createdAt" : "2021-06-21T06:45:42Z",
        "updatedAt" : "2021-06-21T06:45:47Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      }
    ],
    "commit" : "0f3df0f45dc12768c7b9843e84e28a50b279443e",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +97,101 @@      plan: SparkPlan,\n      fileFormat: FileFormat,\n      protocols: (FileCommitProtocol, FileNamingProtocol),\n      outputSpec: OutputSpec,\n      hadoopConf: Configuration,"
  },
  {
    "id" : "ab739ef3-8381-4466-bcc5-bd0440f4e6e0",
    "prId" : 31522,
    "prUrl" : "https://github.com/apache/spark/pull/31522#pullrequestreview-604085959",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c7117aaa-9e9f-4fc6-8cbd-ee0692ceb52b",
        "parentId" : null,
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "Sorry but why do we need the show the duration of the function call of `commitJob` here.\r\nAs per the doc:\r\n```\r\n  /**\r\n   * Commits a job after the writes succeed. Must be called on the driver.\r\n   */\r\n  def commitJob(jobContext: JobContext, taskCommits: Seq[TaskCommitMessage]): Unit\r\n```\r\nThe commitJob API mostly is for moving the temporary output files to the target final path.",
        "createdAt" : "2021-02-24T12:34:17Z",
        "updatedAt" : "2021-03-04T13:14:32Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "a370119c-f962-4837-b4d6-a5d9255ca0d2",
        "parentId" : "c7117aaa-9e9f-4fc6-8cbd-ee0692ceb52b",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "Some times  after task all completed, we wait a long time then job finished, it's always cost on job commit and  metadata handling such as `externalCatalog.loadDynamicPartition()` etc.\r\n \r\nThese duration information is important when it's slow  when we want to compare job's performance. Since when hdfs is unstable, file operation will cost  more time. \r\n\r\nAlso I want to add metrics about metadata handling time after job committed.",
        "createdAt" : "2021-02-24T15:21:27Z",
        "updatedAt" : "2021-03-04T13:14:32Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "e533e0ad-469e-4380-8b25-01b71e301b52",
        "parentId" : "c7117aaa-9e9f-4fc6-8cbd-ee0692ceb52b",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "Normally, this should be fast. I don't think it is a good idea to put this in the SQL graph. For debug purpose, the log message should be enough.\r\nBesides, the name \"duration of committing the job\" can be confusing to end-users.\r\nI have to leave -1 for this one.",
        "createdAt" : "2021-02-24T15:41:28Z",
        "updatedAt" : "2021-03-04T13:14:32Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "ed628982-14e7-4b3c-b18b-86c6c5f0437f",
        "parentId" : "c7117aaa-9e9f-4fc6-8cbd-ee0692ceb52b",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "`externalCatalog.loadDynamicPartition()` is this really counted as the commit duration in this PR?",
        "createdAt" : "2021-02-24T15:54:19Z",
        "updatedAt" : "2021-03-04T13:14:32Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "e743ed57-0e42-4997-b68f-79e17101683a",
        "parentId" : "c7117aaa-9e9f-4fc6-8cbd-ee0692ceb52b",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> `externalCatalog.loadDynamicPartition()` is this really counted as the commit duration in this PR?\r\n\r\nNot yet,  we need to collect this duration after job committed. not counted in job commit duration.",
        "createdAt" : "2021-02-25T02:15:22Z",
        "updatedAt" : "2021-03-04T13:14:32Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "8a3fe6ba-9194-4b86-910d-0f54e126b24d",
        "parentId" : "c7117aaa-9e9f-4fc6-8cbd-ee0692ceb52b",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "Just now, my friend ask me why job finished then cost 80s to job committed.\r\n```\r\n21/02/25 15:42:12 INFO DAGScheduler: ResultStage 1 (run at AccessController.java:0) finished in 82.189 s\r\n21/02/25 15:42:12 INFO DAGScheduler: Job 1 finished: run at AccessController.java:0, took 84.330846 s\r\n21/02/25 15:43:38 INFO FileFormatWriter: Job null committed.\r\n21/02/25 15:43:38 WARN DFSClient: Slow ReadProcessor read fields took 41202ms (threshold=30000ms); ack: seqno: 140 status: SUCCESS downstreamAckTimeNanos: 33201980 4: \"\\000\", targets: [172.16.1.71:9866, 172.16.1.104:9866, 172.16.1.18:9866, 172.16.1.33:9866]\r\n```\r\n\r\nHis SQL task run 80s, job commit cost 80s and hive metadata load data cost 100s.",
        "createdAt" : "2021-02-25T07:49:40Z",
        "updatedAt" : "2021-03-04T13:14:32Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "55718a5b-9b6c-4f27-8ad2-8c10460cc755",
        "parentId" : "c7117aaa-9e9f-4fc6-8cbd-ee0692ceb52b",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "if we show job commit duration in the UI, shall we also show hive load table duration?",
        "createdAt" : "2021-02-25T13:13:40Z",
        "updatedAt" : "2021-03-04T13:14:32Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "d6932436-7a06-4a5a-b514-ce7f91d06acf",
        "parentId" : "c7117aaa-9e9f-4fc6-8cbd-ee0692ceb52b",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> if we show job commit duration in the UI, shall we also show hive load table duration?\r\n\r\nI originally planned to show hive load table duration after this PR. Shall I also update about hive load table duration in this PR?",
        "createdAt" : "2021-02-25T13:29:04Z",
        "updatedAt" : "2021-03-04T13:14:32Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "4169ffe6-2dd4-4801-afaa-1c0bee23ae74",
        "parentId" : "c7117aaa-9e9f-4fc6-8cbd-ee0692ceb52b",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "https://github.com/apache/spark/pull/31679 this is a related PR before add hive load table duration in SQLMetrics, since `CreateTableAsSelect` also need show hive load data duration.\r\n\r\nI hope to add hive load data duration after this pr and https://github.com/apache/spark/pull/31679.",
        "createdAt" : "2021-02-28T07:56:56Z",
        "updatedAt" : "2021-03-04T13:14:32Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "b419fe4d-fa60-4e8a-8264-a5c3cbe78a99",
        "parentId" : "c7117aaa-9e9f-4fc6-8cbd-ee0692ceb52b",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "Gentle ping @cloud-fan What should I do next for this pr?",
        "createdAt" : "2021-03-04T13:15:00Z",
        "updatedAt" : "2021-03-04T13:15:00Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "b5c9d6338c53c52724c0a21d61a093194745b98f",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +241,245 @@      logInfo(s\"Write Job ${description.uuid} committed. Elapsed time: $duration ms.\")\n\n      processStats(description.statsTrackers, ret.map(_.summary.stats), duration)\n      logInfo(s\"Finished processing stats for write job ${description.uuid}.\")\n"
  },
  {
    "id" : "05b2dda2-64fb-477b-85da-f98fa34bda14",
    "prId" : 30681,
    "prUrl" : "https://github.com/apache/spark/pull/30681#pullrequestreview-587202941",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d2b48ecf-6f81-4582-a67c-f3dfe7aa3f32",
        "parentId" : null,
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "`map {`",
        "createdAt" : "2021-02-10T02:30:41Z",
        "updatedAt" : "2021-02-10T02:30:51Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      }
    ],
    "commit" : "0824bfc6597c98c5057aeef16ea6c57637a0f654",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +229,233 @@            val header = s\"File stats [ \"\n            val metrics = s.asInstanceOf[BasicWriteJobStatsTracker].metrics\n            val inner = metrics.map{\n              p => p._1 + \"=\" + p._2.value\n            }.mkString(\"; \")"
  },
  {
    "id" : "d4cf0d3d-fd06-4888-aaff-27b6a31ac369",
    "prId" : 30681,
    "prUrl" : "https://github.com/apache/spark/pull/30681#pullrequestreview-587203322",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "56ac6508-c187-44b5-8760-eccf4c0a02eb",
        "parentId" : null,
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "method + in class Int is deprecated since 2.13.0,  we should use the string interpolation `s\"$num$str\"` to avoid some new compilation warnings",
        "createdAt" : "2021-02-10T02:31:41Z",
        "updatedAt" : "2021-02-10T02:41:20Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      }
    ],
    "commit" : "0824bfc6597c98c5057aeef16ea6c57637a0f654",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +230,234 @@            val metrics = s.asInstanceOf[BasicWriteJobStatsTracker].metrics\n            val inner = metrics.map{\n              p => p._1 + \"=\" + p._2.value\n            }.mkString(\"; \")\n            header + inner + \" ]\\n\""
  },
  {
    "id" : "40249298-87be-4ae4-b8a3-91a86c3e2545",
    "prId" : 30681,
    "prUrl" : "https://github.com/apache/spark/pull/30681#pullrequestreview-587203857",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "98281049-54b5-4b8d-8500-1728de90e110",
        "parentId" : null,
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "`map {`",
        "createdAt" : "2021-02-10T02:33:21Z",
        "updatedAt" : "2021-02-10T02:33:22Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      }
    ],
    "commit" : "0824bfc6597c98c5057aeef16ea6c57637a0f654",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +225,229 @@\n      val insertStats : String = try {\n        description.statsTrackers.map{\n          s =>\n            val header = s\"File stats [ \""
  },
  {
    "id" : "3d4dfefe-7f55-4380-9f6a-bf3b5ce7175e",
    "prId" : 30681,
    "prUrl" : "https://github.com/apache/spark/pull/30681#pullrequestreview-587205102",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "643a21ff-e101-4a15-883b-afbdd7a9ebd4",
        "parentId" : null,
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "Why `print` instead of `log`?",
        "createdAt" : "2021-02-10T02:37:01Z",
        "updatedAt" : "2021-02-10T02:37:02Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      }
    ],
    "commit" : "0824bfc6597c98c5057aeef16ea6c57637a0f654",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +240,244 @@\n      if (!sparkSession.sparkContext.getConf.get(config.FILE_INSERT_STATUS_LOG_FLAG)) {\n        print(insertStats)\n      } else {\n        System.err.print(insertStats)"
  },
  {
    "id" : "773b9e1f-188a-4efa-aae1-e3848b9d972a",
    "prId" : 30681,
    "prUrl" : "https://github.com/apache/spark/pull/30681#pullrequestreview-587205690",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "371c27a7-30e7-47d4-a374-1b61ba93d036",
        "parentId" : null,
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "Why print to syserr？",
        "createdAt" : "2021-02-10T02:38:40Z",
        "updatedAt" : "2021-02-10T02:38:40Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      }
    ],
    "commit" : "0824bfc6597c98c5057aeef16ea6c57637a0f654",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +242,246 @@        print(insertStats)\n      } else {\n        System.err.print(insertStats)\n      }\n"
  },
  {
    "id" : "842a8580-72f1-4aa2-b6b8-3938aaba9382",
    "prId" : 30681,
    "prUrl" : "https://github.com/apache/spark/pull/30681#pullrequestreview-587206364",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "90fe46f3-5059-4b01-932c-d392929bb990",
        "parentId" : null,
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "What kind of `Exception` is it?",
        "createdAt" : "2021-02-10T02:40:30Z",
        "updatedAt" : "2021-02-10T02:40:31Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      }
    ],
    "commit" : "0824bfc6597c98c5057aeef16ea6c57637a0f654",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +235,239 @@        }.mkString(\"\\n\")\n      } catch {\n        case e: Exception => logWarning(\"Exception write logs error\", e)\n          \"\"\n      }"
  },
  {
    "id" : "839628b9-7fa9-4670-8b01-53caff38d006",
    "prId" : 30681,
    "prUrl" : "https://github.com/apache/spark/pull/30681#pullrequestreview-587207490",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d3f05cfc-a8cc-40fa-865f-6f8e9a1062fa",
        "parentId" : null,
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "`config` should come before `Logging` and can you fix the scalastyle problem first ？",
        "createdAt" : "2021-02-10T02:43:51Z",
        "updatedAt" : "2021-02-10T02:43:52Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      }
    ],
    "commit" : "0824bfc6597c98c5057aeef16ea6c57637a0f654",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +27,31 @@\nimport org.apache.spark._\nimport org.apache.spark.internal.{Logging, config}\nimport org.apache.spark.internal.io.{FileCommitProtocol, SparkHadoopWriterUtils}\nimport org.apache.spark.shuffle.FetchFailedException"
  },
  {
    "id" : "8b19d106-5c61-45f9-a814-abaf3bf6a49b",
    "prId" : 30141,
    "prUrl" : "https://github.com/apache/spark/pull/30141#pullrequestreview-516770111",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "653af3f6-58b7-4359-af92-c479d903abe9",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Do you mean Apache Hadoop S3A committer use this?  If not, `spark.sql.sources.writeJobUUID` is not used inside Spark 3.x/2.x code base.\r\n\r\nAs you wrote, in Spark 1.6, it was a part of file name explicitly.\r\n```scala\r\nval uniqueWriteJobId = conf.get(\"spark.sql.sources.writeJobUUID\")\r\n...\r\nval filename = f\"part-r-$partition%05d-$uniqueWriteJobId.orc\"\r\n```",
        "createdAt" : "2020-10-23T16:00:44Z",
        "updatedAt" : "2020-10-23T16:05:06Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "5fff6c03-ae7f-491c-ac84-f842a3d416e4",
        "parentId" : "653af3f6-58b7-4359-af92-c479d903abe9",
        "authorId" : "224991ce-ad69-410b-8143-bf394b6b5c59",
        "body" : "It picked it up if set, so yes, it was being used. We've hit a problem where if >1 job kicks off in the same second for that user, the generated app ID is the same for both, so the staging committers end up using the same dir in HDFS. The committers already use the writeJobUUID property if set: restoring the original config option will mean that the shipping artifacts will work",
        "createdAt" : "2020-10-26T13:23:46Z",
        "updatedAt" : "2020-10-26T13:23:47Z",
        "lastEditedBy" : "224991ce-ad69-410b-8143-bf394b6b5c59",
        "tags" : [
        ]
      }
    ],
    "commit" : "cfbb49d7155f50bcbe82e436d7db8447aa53d920",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +167,171 @@    // propagate the decription UUID into the jobs, so that committers\n    // get an ID guaranteed to be unique.\n    job.getConfiguration.set(\"spark.sql.sources.writeJobUUID\", description.uuid)\n\n    // This call shouldn't be put into the `try` block below because it only initializes and"
  },
  {
    "id" : "63acb6f7-1ed9-46d2-adc6-4f37ecb406fb",
    "prId" : 26312,
    "prUrl" : "https://github.com/apache/spark/pull/26312#pullrequestreview-510540028",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dbd903be-7618-45df-b4fd-a720798a5f5e",
        "parentId" : null,
        "authorId" : "2d6b46ba-4100-4c4d-9341-fff5e39647ec",
        "body" : "Looks like this makes a very strong assumption. It assumes `FileAlreadyExistsException` is thrown from the commit protocol. But `FileAlreadyExistsException` is a very common exception which can be thrown from anywhere. `FileAlreadyExistsException` may be from user codes and the user may want to retry.",
        "createdAt" : "2020-10-16T00:15:41Z",
        "updatedAt" : "2020-10-16T00:30:26Z",
        "lastEditedBy" : "2d6b46ba-4100-4c4d-9341-fff5e39647ec",
        "tags" : [
        ]
      },
      {
        "id" : "476435fd-a9e2-460c-b41a-efadb0863ded",
        "parentId" : "dbd903be-7618-45df-b4fd-a720798a5f5e",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "If users really want to retry, I believe it is to catch `FileAlreadyExistsException` and do retry in user code with changing filename, instead of relying on Spark to retry it.\r\n\r\nTo rely on Spark's task attempt for file writing retry? It is unreliable and task failure can have many reasons not just file already existing.\r\n",
        "createdAt" : "2020-10-16T00:53:29Z",
        "updatedAt" : "2020-10-16T00:53:29Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "9f3726da-4d74-48df-ae50-720fca9740b3",
        "parentId" : "dbd903be-7618-45df-b4fd-a720798a5f5e",
        "authorId" : "2d6b46ba-4100-4c4d-9341-fff5e39647ec",
        "body" : "> If users really want to retry, I believe it is to catch `FileAlreadyExistsException` and do retry in user code with changing filename, instead of relying on Spark to retry it.\r\n\r\nThis applies to any other exceptions as well. Of cause, users can retry. But since Spark provides task retry, users may have a rare race that can cause `FileAlreadyExistsException` and decide to reply on Spark task retry to handle it. In addition, some users may just call a library or a service that they cannot make changes.\r\n\r\nMoreover, this is a behavior change and it may break user applications relying on task retry for `FileAlreadyExistsException`. But it's documented.\r\n\r\nIIUC, this PR seems just trying to fail fast when hitting `FileAlreadyExistsException` in some rare case ( SPARK-27194 ). Please correct me if I'm wrong. If so, it's not worth to make a behavior change in my opinion.\r\n",
        "createdAt" : "2020-10-16T01:49:35Z",
        "updatedAt" : "2020-10-16T01:49:35Z",
        "lastEditedBy" : "2d6b46ba-4100-4c4d-9341-fff5e39647ec",
        "tags" : [
        ]
      },
      {
        "id" : "20560ef5-66c6-46d3-9676-fcd018848bc2",
        "parentId" : "dbd903be-7618-45df-b4fd-a720798a5f5e",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "It is not a rare case actually. We had customer encountered this issue in production jobs occasionally. There are also other people reporting this issue. It is remarkable because this `FileAlreadyExistsException` cannot be handled by user code. It is happened internally in Spark, and users have no way to deal with it. Image your production jobs fail after 10+ hours because of `FileAlreadyExistsException`. I believe it is worth failing fast the production jobs.\r\n\r\nIt sounds really unreliable to rely on retry to handle a rare race that causes `FileAlreadyExistsException`. What if later attempts cannot success too? Seems to me a production job won't rely on that and needs address this issue seriously. In most of cases this can be handled by catching `FileAlreadyExistsException` and retrying. In rare case if any, there is rare race that can cause `FileAlreadyExistsException`  and it cannot make change? It sounds pretty rare to me, and even if it is really happens we can retry the call of the library/service to solve it, so I'm not sure if we should sacrifice the cases seen in production for a rare case.\r\n\r\n\r\n\r\n",
        "createdAt" : "2020-10-16T03:18:53Z",
        "updatedAt" : "2020-10-16T03:18:53Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "403d2de8-2766-496d-8373-86184d35d0ff",
        "parentId" : "dbd903be-7618-45df-b4fd-a720798a5f5e",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Makes sense to me. @viirya can we throw a spark specific exception for commit protocol errors and catch it here?",
        "createdAt" : "2020-10-16T03:28:36Z",
        "updatedAt" : "2020-10-16T03:28:36Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "3145269e-fa0c-4c1f-827b-01a986226bdf",
        "parentId" : "dbd903be-7618-45df-b4fd-a720798a5f5e",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "@cloud-fan Sure. Will submit a PR.",
        "createdAt" : "2020-10-16T03:30:45Z",
        "updatedAt" : "2020-10-16T03:30:45Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "f26b707c-1af5-4bc6-8ac0-c38381df153a",
        "parentId" : "dbd903be-7618-45df-b4fd-a720798a5f5e",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Created SPARK-33167 and will submit a PR in next days. Thanks.",
        "createdAt" : "2020-10-16T03:36:41Z",
        "updatedAt" : "2020-10-16T03:36:42Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "77eb8be9-b4e4-4445-9e71-ab3a9a43fa1d",
        "parentId" : "dbd903be-7618-45df-b4fd-a720798a5f5e",
        "authorId" : "2d6b46ba-4100-4c4d-9341-fff5e39647ec",
        "body" : "If SPARK-27194 is not rare, it sounds a serious bug. Can we focus on fixing SPARK-27194 instead? Maybe speed up the review for #29000? If SPARK-27194 is resolved, we won't need this hack. Right? In addition, it's weird that FileFormatWriter needs to understand the behavior of `SQLHadoopMapReduceCommitProtocol`. It would be great if we can avoid leaking the implementation details of a commit protocol to `FileFormatWriter`.\r\n\r\nRegarding user cases, I have seen multiple customers hitting recoverable `FileAlreadyExistsException` caused by https://issues.apache.org/jira/browse/HADOOP-17015 . But they could not upgrade the their Hadoop version. It's much harder to upgrade Hadoop than Spark. This change makes their jobs fail occasionally after upgrading to Spark 3.0 because Spark doesn't retry `FileAlreadyExistsException`. And like what you said, the user cannot change Spark's behavior to retry `FileAlreadyExistsException`. Their jobs should have been finished but because Spark didn't retry, they wasted hours of work.\r\n\r\nThrowing spark specific exception for commit protocol errors cannot resolve this because the issue is in the underlying FileSystem implementation called by Spark directly.\r\n\r\nIMO, we need to make the tradeoff between:\r\n\r\n- Make a job successful if we retry `FileAlreadyExistsException`, but a failed job may take more time to fail.\r\n- Make a job fail when it should have been successful if we retried `FileAlreadyExistsException`, but make a failed job fail fast.\r\n\r\nI prefer the first one as we can make more jobs successful and the behavior is the same as before.",
        "createdAt" : "2020-10-16T04:56:50Z",
        "updatedAt" : "2020-10-16T04:58:40Z",
        "lastEditedBy" : "2d6b46ba-4100-4c4d-9341-fff5e39647ec",
        "tags" : [
        ]
      },
      {
        "id" : "796a342b-8aed-422e-869f-02348f446184",
        "parentId" : "dbd903be-7618-45df-b4fd-a720798a5f5e",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "I see. Thanks for the details. We have different standpoints. For your cases the first one option looks a better choice. The customers we had are using HDFS and `FileAlreadyExistsException` isn't recoverable. So the pain point comes from more time spent on a failed job.\r\n\r\nI believe even SPARK-27194 is resolved, fast-fail of a failed job caused by `FileAlreadyExistsException` or maybe other errors if we know they are un-recoverable in advance, is still useful.\r\n\r\nSeems to me there are options, one is to revert this completely, second is to add a config for the fast-fail behavior and set it false by default. I prefer the second one because the reason above, we can relieve the pain of wasting time on failed job if users want.\r\n\r\nWDYT?\r\n\r\n",
        "createdAt" : "2020-10-16T06:34:22Z",
        "updatedAt" : "2020-10-16T06:34:22Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "60feed99-25f8-43d3-8635-dcb546fe8780",
        "parentId" : "dbd903be-7618-45df-b4fd-a720798a5f5e",
        "authorId" : "2d6b46ba-4100-4c4d-9341-fff5e39647ec",
        "body" : "> second is to add a config for the fast-fail behavior and set it false by default. I prefer the second one because the reason above, we can relieve the pain of wasting time on failed job if users want.\r\n\r\n+1 for this. Thanks a lot for the discussion.\r\n\r\n",
        "createdAt" : "2020-10-16T14:45:29Z",
        "updatedAt" : "2020-10-16T14:45:44Z",
        "lastEditedBy" : "2d6b46ba-4100-4c4d-9341-fff5e39647ec",
        "tags" : [
        ]
      }
    ],
    "commit" : "d799c2748590e49cfcbcfa950b281358d6f05e56",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +282,286 @@      case e: FetchFailedException =>\n        throw e\n      case f: FileAlreadyExistsException =>\n        // If any output file to write already exists, it does not make sense to re-run this task.\n        // We throw the exception and let Executor throw ExceptionFailure to abort the job."
  }
]