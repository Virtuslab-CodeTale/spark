[
  {
    "id" : "6581e852-30ad-479a-807e-d227f443941b",
    "prId" : 31635,
    "prUrl" : "https://github.com/apache/spark/pull/31635#pullrequestreview-598236293",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a1904bfc-9a80-4878-b38e-868df3f5d89f",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I'm a bit reluctant to rename v1 commands, as they are legacy and have been there for many years. ",
        "createdAt" : "2021-02-24T17:31:18Z",
        "updatedAt" : "2021-02-24T17:31:18Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "1c23693e-a002-4fc7-8448-da8ff2549d08",
        "parentId" : "a1904bfc-9a80-4878-b38e-868df3f5d89f",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Sure, but this is non-public API. We have already extended `AlterTableRecoverPartitionsCommand` in https://github.com/apache/spark/pull/31499. After that, it became incompatible by sources and binary with the previous version.",
        "createdAt" : "2021-02-24T17:52:43Z",
        "updatedAt" : "2021-02-24T17:53:15Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "befc5955-9215-4170-8877-1d6c47b5694b",
        "parentId" : "a1904bfc-9a80-4878-b38e-868df3f5d89f",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "And how about the logical nodes that were massively replaced in https://issues.apache.org/jira/browse/SPARK-29900. They are legacy and have been there for many years too, aren't they?",
        "createdAt" : "2021-02-24T17:57:03Z",
        "updatedAt" : "2021-02-24T17:57:03Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "4689b7ad-dd7b-4f00-9925-f975ed082d0b",
        "parentId" : "a1904bfc-9a80-4878-b38e-868df3f5d89f",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "I think the point is that we might better focus on checking V2 instead of V1 commands because eventually V2 commands should replace V1 commands in the future. If this is likely only the one, I think it's fine. If there are a lot of such instances, I wouldn't change for now.",
        "createdAt" : "2021-02-25T00:35:56Z",
        "updatedAt" : "2021-02-25T00:35:56Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "da40a887-2a22-4b66-ac89-e1efb6d3a1b5",
        "parentId" : "a1904bfc-9a80-4878-b38e-868df3f5d89f",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "> If this is likely only the one, I think it's fine.\r\n\r\nYep, only this for now.",
        "createdAt" : "2021-02-25T06:37:51Z",
        "updatedAt" : "2021-02-25T06:37:52Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "13362936b7fa8336a13f23f75367aaa4a6624c40",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +601,605 @@ * }}}\n */\ncase class RepairTableCommand(\n    tableName: TableIdentifier,\n    enableAddPartitions: Boolean,"
  },
  {
    "id" : "3cee3646-e1b2-4f06-8316-419389b948fd",
    "prId" : 31499,
    "prUrl" : "https://github.com/apache/spark/pull/31499#pullrequestreview-597256032",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "51f58e19-82ef-43ab-a89b-d0d2172cdfc3",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "@cloud-fan @dongjoon-hyun Should we rename this to `RepairTableCommand` (or `MsckRepairTableCommad`) since `ALTER TABLE .. RECOVER PARTITIONS` is just a specific case of `MSCK REPAIR TABLE table [{ADD|DROP|SYNC} PARTITIONS]`, and it doesn't support `{DROP|SYNC} PARTITIONS`?",
        "createdAt" : "2021-02-18T21:56:54Z",
        "updatedAt" : "2021-02-23T10:22:53Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "7fd39255-6a62-4740-81c8-073e794f4529",
        "parentId" : "51f58e19-82ef-43ab-a89b-d0d2172cdfc3",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Well, it means many additional changes including the doc changes at line 594, `Recover Partitions in ALTER TABLE`. Why don't we do that renaming in another PR separately if you want? For example, like #31584 ?",
        "createdAt" : "2021-02-18T22:30:11Z",
        "updatedAt" : "2021-02-23T10:22:53Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "c60c58b6-3489-4e8a-81bd-aa7e1ca689c1",
        "parentId" : "51f58e19-82ef-43ab-a89b-d0d2172cdfc3",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Here is the PR https://github.com/apache/spark/pull/31635 for renaming.",
        "createdAt" : "2021-02-24T09:14:52Z",
        "updatedAt" : "2021-02-24T09:14:52Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "fefea57d097e64b5b506dea45aac24c537f27abd",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +601,605 @@ * }}}\n */\ncase class AlterTableRecoverPartitionsCommand(\n    tableName: TableIdentifier,\n    enableAddPartitions: Boolean,"
  },
  {
    "id" : "c3e20fc7-2923-474a-a4b2-64218b46e10f",
    "prId" : 31499,
    "prUrl" : "https://github.com/apache/spark/pull/31499#pullrequestreview-596167737",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "76460ede-67f4-4a49-84dd-4d77dc65d991",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Could you add a comment about the reason why we use `retainData=true`? I guess the reason is that `fs.exists(..)` is already `false` and we don't want addition file system calls. Did I understand correctly?",
        "createdAt" : "2021-02-23T04:42:16Z",
        "updatedAt" : "2021-02-23T10:22:53Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "8461c589-25c4-49df-aeff-90de939743be",
        "parentId" : "76460ede-67f4-4a49-84dd-4d77dc65d991",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "> ... we don't want addition file system calls. Did I understand correctly?\r\n\r\nYep, if we set `retainData` to `true`, the `deleteData` flag will `false` at https://github.com/apache/hive/blob/release-3.1.3-rc0/standalone-metastore/src/main/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java#L4360-L4378 . So, Hive MeteStore will not try to delete the partition folders.",
        "createdAt" : "2021-02-23T10:00:57Z",
        "updatedAt" : "2021-02-23T10:22:53Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "352b8049-71d6-4fe3-83a8-ced22380702e",
        "parentId" : "76460ede-67f4-4a49-84dd-4d77dc65d991",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "The same for the `In-Memory` catalog: https://github.com/apache/spark/blob/bfc023501379d28ae2db8708928f4e658ccaa07f/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/catalog/InMemoryCatalog.scala#L464-L473\r\n",
        "createdAt" : "2021-02-23T10:04:59Z",
        "updatedAt" : "2021-02-23T10:22:53Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "fefea57d097e64b5b506dea45aac24c537f27abd",
    "line" : 99,
    "diffHunk" : "@@ -1,1 +818,822 @@      // Since we have already checked that partition directories do not exist, we can avoid\n      // additional calls to the file system at the catalog side by setting this flag.\n      retainData = true)\n    dropPartSpecs.length\n  }"
  },
  {
    "id" : "1d585c29-69f0-4fdb-9457-899f9a194b4c",
    "prId" : 31107,
    "prUrl" : "https://github.com/apache/spark/pull/31107#pullrequestreview-570939164",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "28d4c125-3bf7-417d-821f-ef06f2dcf2f8",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "how about the v2 drop table command?",
        "createdAt" : "2021-01-18T07:39:08Z",
        "updatedAt" : "2021-01-19T19:56:05Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "c9e5c290-4535-4fe5-9075-cf6789eb34b3",
        "parentId" : "28d4c125-3bf7-417d-821f-ef06f2dcf2f8",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "Hmm, I think all dropping temp views are handled by v1 `DropTableCommand` and v2 only handles tables, is that correct?",
        "createdAt" : "2021-01-19T06:31:09Z",
        "updatedAt" : "2021-01-19T19:56:05Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "31323272-d122-4338-a81a-b4e55c05c99b",
        "parentId" : "28d4c125-3bf7-417d-821f-ef06f2dcf2f8",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ah you are right.",
        "createdAt" : "2021-01-19T06:33:51Z",
        "updatedAt" : "2021-01-19T19:56:05Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "40ef4b12ae328493c4a5ae5fd8274a7f839050de",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +241,245 @@          catalog.getTempViewOrPermanentTableMetadata(tableName).viewText.isDefined\n        sparkSession.sharedState.cacheManager.uncacheQuery(\n          sparkSession.table(tableName), cascade = !isTempView || hasViewText)\n      } catch {\n        case NonFatal(e) => log.warn(e.toString, e)"
  },
  {
    "id" : "ded7f21a-c7e8-4226-9401-07918699c519",
    "prId" : 31107,
    "prUrl" : "https://github.com/apache/spark/pull/31107#pullrequestreview-571527799",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "59b8dcb2-a565-41bd-aff1-4ca7fff82a91",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Is the PR title and description up-to-dated? Looks like the change in the PR is basically changing the uncaching behavior of view with view text.\r\n\r\nLooks like we already did cascade uncache when dropping a source table here, so I'm wondering why the title is \"A cached view should become invalid after the source table is dropped\"?",
        "createdAt" : "2021-01-19T18:10:32Z",
        "updatedAt" : "2021-01-19T19:56:05Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "60d9ed74-bf02-435b-8ab5-9373899ce8f7",
        "parentId" : "59b8dcb2-a565-41bd-aff1-4ca7fff82a91",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "Yes the PR title is not very good - I just updated it. I think the description is more aligned to what the PR does but I'll try to add more details there.",
        "createdAt" : "2021-01-19T18:24:05Z",
        "updatedAt" : "2021-01-19T19:56:05Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      }
    ],
    "commit" : "40ef4b12ae328493c4a5ae5fd8274a7f839050de",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +241,245 @@          catalog.getTempViewOrPermanentTableMetadata(tableName).viewText.isDefined\n        sparkSession.sharedState.cacheManager.uncacheQuery(\n          sparkSession.table(tableName), cascade = !isTempView || hasViewText)\n      } catch {\n        case NonFatal(e) => log.warn(e.toString, e)"
  },
  {
    "id" : "4537af40-4772-4dae-a96d-3a868836b058",
    "prId" : 31101,
    "prUrl" : "https://github.com/apache/spark/pull/31101#pullrequestreview-565354875",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5d8cb716-6468-4af4-b839-f955a950a059",
        "parentId" : null,
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "just curious, does it matter whether we refresh cache before or after the stats are updated?",
        "createdAt" : "2021-01-09T18:11:00Z",
        "updatedAt" : "2021-01-10T05:03:07Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "b641a88a-e248-4d1d-b775-8b2920ce0470",
        "parentId" : "5d8cb716-6468-4af4-b839-f955a950a059",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "In this particular case, it doesn't matter because table size is re-calculated by getting file statuses directly from the filesystem. So, the cached data is not used in updating table stats.\r\n\r\nI think we should review other places.\r\n\r\nJust in case, I will update the test and check that table size is updated after adding of the partition.",
        "createdAt" : "2021-01-09T20:06:34Z",
        "updatedAt" : "2021-01-10T05:03:07Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "f95447d4-60f0-461c-9f02-4a043babf2a5",
        "parentId" : "5d8cb716-6468-4af4-b839-f955a950a059",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "> Just in case, I will update the test and check that table size is updated after adding of the partition.\r\n\r\nLet me add such checking later independently from this PR. I think I have found one more issue relating to looking for `HiveTableRelation` in the cache of Cache Manager.\r\n\r\nIt seems cleaning the table stats made in https://github.com/apache/spark/pull/30995 is not enough.",
        "createdAt" : "2021-01-09T21:31:51Z",
        "updatedAt" : "2021-01-10T05:03:07Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "f850f901-c51b-49c2-b5a9-d8a79b6c37b0",
        "parentId" : "5d8cb716-6468-4af4-b839-f955a950a059",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "+1 for @MaxGekk 's decision.",
        "createdAt" : "2021-01-09T23:30:04Z",
        "updatedAt" : "2021-01-10T05:03:07Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "2d9c958d-5d63-4d7c-872b-31c16896aa57",
        "parentId" : "5d8cb716-6468-4af4-b839-f955a950a059",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "Yup, SGTM :)",
        "createdAt" : "2021-01-09T23:34:58Z",
        "updatedAt" : "2021-01-10T05:03:07Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "aff89448-37d0-42a4-bdf2-f4f915641b0b",
        "parentId" : "5d8cb716-6468-4af4-b839-f955a950a059",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Here is the bug fix: https://github.com/apache/spark/pull/31112 . Updating of table stats triggers the bug.",
        "createdAt" : "2021-01-10T10:37:38Z",
        "updatedAt" : "2021-01-10T10:37:38Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "159bbe71-9edc-4b21-88bf-74ac22532b67",
        "parentId" : "5d8cb716-6468-4af4-b839-f955a950a059",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "> Let me add such checking later independently from this PR.\r\n\r\nI added the check for partition adding as well. Please, review this PR: https://github.com/apache/spark/pull/31131",
        "createdAt" : "2021-01-11T13:32:17Z",
        "updatedAt" : "2021-01-11T13:32:17Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "8aa432c8797e2d73c8065376d63474321cecf81a",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +486,490 @@    }\n\n    sparkSession.catalog.refreshTable(table.identifier.quotedString)\n    if (table.stats.nonEmpty) {\n      if (sparkSession.sessionState.conf.autoSizeUpdateEnabled) {"
  },
  {
    "id" : "f1b2cb75-731f-4b93-be74-7ee19d7a24ef",
    "prId" : 31066,
    "prUrl" : "https://github.com/apache/spark/pull/31066#pullrequestreview-563224341",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "78303d7d-1efa-40d9-9ceb-76125271c2a5",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Here, we invoke https://github.com/apache/spark/blob/3fdbc48373cdf12b8ba05632bc65ad49b7af1afb/sql/core/src/main/scala/org/apache/spark/sql/internal/CatalogImpl.scala#L514 instead of https://github.com/apache/spark/blob/cc1d9d25fb4c2e4af912d6f9802de8f351c32deb/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/catalog/SessionCatalog.scala#L990 . The last one doesn't refresh the cache.",
        "createdAt" : "2021-01-06T12:23:26Z",
        "updatedAt" : "2021-01-18T05:44:04Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "4c44b2c6-d4b7-4d54-a60c-61926207d8a4",
        "parentId" : "78303d7d-1efa-40d9-9ceb-76125271c2a5",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "@cloud-fan I don't know why we have 2 implementations of `refreshTable()`. I would merge them and call one from another.",
        "createdAt" : "2021-01-06T12:33:22Z",
        "updatedAt" : "2021-01-18T05:44:04Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "7e1aaf80-1315-4a44-a4a0-cd36a0833e97",
        "parentId" : "78303d7d-1efa-40d9-9ceb-76125271c2a5",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "yea we should unify these two refreshTable",
        "createdAt" : "2021-01-06T14:45:05Z",
        "updatedAt" : "2021-01-18T05:44:04Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "a730d63d-1dc5-49b1-a012-96cdc422cf19",
        "parentId" : "78303d7d-1efa-40d9-9ceb-76125271c2a5",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "+1 for the unification.",
        "createdAt" : "2021-01-06T17:24:38Z",
        "updatedAt" : "2021-01-18T05:44:04Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "0cd47433-a97b-4ae1-a5a8-9559677c2e4b",
        "parentId" : "78303d7d-1efa-40d9-9ceb-76125271c2a5",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "I think the former calls the latter which only refreshes metadata cache and is used in multiple other places. ",
        "createdAt" : "2021-01-06T17:35:32Z",
        "updatedAt" : "2021-01-18T05:44:04Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "762711cd-8f99-40e4-9134-f495046fc2c0",
        "parentId" : "78303d7d-1efa-40d9-9ceb-76125271c2a5",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "I wonder what are the use cases when we need to update only meta-data but not cached table data. Looking at the places where `SessionCatalog.refreshTable` is used:\r\n1. https://github.com/apache/spark/blob/c62b84a0432e51fd10e628088ee311dc3be73d2f/sql/hive/src/main/scala/org/apache/spark/sql/hive/execution/InsertIntoHiveTable.scala#L113\r\n2. https://github.com/apache/spark/blob/271c4f6e00b7bc7c47d84a8e59018e84a19c9822/sql/core/src/main/scala/org/apache/spark/sql/DataFrameWriter.scala#L729\r\n3. https://github.com/apache/spark/blob/2ab77d634f2e87b080786f4f39cb17e0994bc550/sql/core/src/main/scala/org/apache/spark/sql/execution/command/ddl.scala#L245\r\n4. https://github.com/apache/spark/blob/ddc0d5148ac6decde160cca847b5db5d6de1be58/sql/core/src/main/scala/org/apache/spark/sql/execution/command/tables.scala#L233\r\n5. https://github.com/apache/spark/blob/ddc0d5148ac6decde160cca847b5db5d6de1be58/sql/core/src/main/scala/org/apache/spark/sql/execution/command/tables.scala#L394\r\n\r\nIn all those ^^ places, updating of cached table data makes sense, IMHO.",
        "createdAt" : "2021-01-06T18:48:47Z",
        "updatedAt" : "2021-01-18T05:44:04Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "32901b11-a760-402f-95d9-15ad53d7a7b7",
        "parentId" : "78303d7d-1efa-40d9-9ceb-76125271c2a5",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "I think there are cases like `alterTableStats` (may be the only one?) which only trigger metadata change. In the above, some already uncache the table data, although via different paths such as `CommandUtils.uncacheTableOrView` or `cacheManager.uncacheQuery`. Also, the other `refreshTable` recaches the target table but sometimes seems we just want to remove the cache but still refreshes the metadata.\r\n\r\nOf course, it will be very helpful if we can simplify the code a bit. It also seems there are still quite a few cases where cache is not properly handled, both in v1 and v2.",
        "createdAt" : "2021-01-07T05:45:58Z",
        "updatedAt" : "2021-01-18T05:44:04Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      }
    ],
    "commit" : "0938cc278ee5327ce4b7b8f598daa34dc17d4db4",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +677,681 @@    // before Spark 2.1 unless they are converted via `msck repair table`.\n    spark.sessionState.catalog.alterTable(table.copy(tracksPartitionsInCatalog = true))\n    spark.catalog.refreshTable(tableIdentWithDB)\n    logInfo(s\"Recovered all partitions ($total).\")\n    Seq.empty[Row]"
  },
  {
    "id" : "89824a9c-c260-4576-8b00-bb6f132a693b",
    "prId" : 30983,
    "prUrl" : "https://github.com/apache/spark/pull/30983#pullrequestreview-560577973",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d439986c-e2f6-426a-8ce0-5f16f7d09986",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "What's the difference to #30983 (corrected: #30979)?",
        "createdAt" : "2020-12-31T23:30:38Z",
        "updatedAt" : "2021-01-03T08:33:21Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "0c14c521-ca90-463d-b770-e9ba995b99c8",
        "parentId" : "d439986c-e2f6-426a-8ce0-5f16f7d09986",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "This PR solves **only** the caching issue, please, see the JIRA tickets that have code examples.",
        "createdAt" : "2020-12-31T23:35:05Z",
        "updatedAt" : "2021-01-03T08:33:21Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "a39c488b-3b51-4588-82c4-790b499f8cc4",
        "parentId" : "d439986c-e2f6-426a-8ce0-5f16f7d09986",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "#30983 tries to solve slightly another issue - outdated cache + file index after partition dropping. Scope of this PR is SQL only but #30983 has wider scope - interference of Spark SQL and other APIs (Scala API, for instance).",
        "createdAt" : "2020-12-31T23:41:54Z",
        "updatedAt" : "2021-01-03T08:33:21Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "434a2669-b201-48be-8ef8-24b31d4c1d24",
        "parentId" : "d439986c-e2f6-426a-8ce0-5f16f7d09986",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Do I miss the difference? I read the two JIRA tickets, looks like they are the same?\r\n\r\n1. Create partitioned table\r\n2. Cache the table\r\n3. Drop a partition\r\n4. The query of the table doesn't change because the cache is not refreshed\r\n\r\n",
        "createdAt" : "2021-01-01T04:11:45Z",
        "updatedAt" : "2021-01-03T08:33:21Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "0425412f-ba80-4684-bbdd-a3e47374d649",
        "parentId" : "d439986c-e2f6-426a-8ce0-5f16f7d09986",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "We can see the problem when we comment the caching:\r\n```scala\r\n  test(\"SPARK-33941: refresh cache after partition dropping\") {\r\n    withNamespaceAndTable(\"ns\", \"tbl\") { t =>\r\n      sql(s\"CREATE TABLE $t (id int, part int) $defaultUsing PARTITIONED BY (part)\")\r\n      sql(s\"INSERT INTO $t PARTITION (part=0) SELECT 0\")\r\n      sql(s\"INSERT INTO $t PARTITION (part=1) SELECT 1\")\r\n      val df = spark.table(t)\r\n      // df.cache()\r\n      df.collect()\r\n      sql(s\"ALTER TABLE $t DROP PARTITION (part=0)\")\r\n      df.collect()\r\n    }\r\n  }\r\n```\r\nthe test fails on the second `df.collect()`:\r\n```\r\njava.io.FileNotFoundException: File file:.../ns.db/tbl/part=0/part-00000-44671e51-2b9a-4049-b449-4ea454abbe77.c000.snappy.parquet does not exist\r\n```\r\n\r\nThe reason of that is in:\r\n1. `val df = spark.table(t)` creates `FileSourceScanExec` in which `inputRDD` has not been materialized yet: https://github.com/apache/spark/blob/a093d6feefb0e086d19c86ae53bf92df12ccf2fa/sql/core/src/main/scala/org/apache/spark/sql/execution/DataSourceScanExec.scala#L398\r\n2. The first `df.collect()` materiazes `inputRDD` -> `createNonBucketedReadRDD()` where `dynamicallySelectedPartitions` are:\r\n    \r\n\r\n- PartitionDirectory([0],WrappedArray(LocatedFileStatus{path=file:../ns.db/tbl/part=0 ...\r\n- PartitionDirectory([1],WrappedArray(LocatedFileStatus{path=file:.../ns.db/tbl/part=1 ...\r\n\r\nIn this ways, `inputRDD` becomes `FileScanRDD` with 2 partitions that pointed out to 2 folders `part=0` and `part=1`\r\n3. `sql(s\"ALTER TABLE $t DROP PARTITION (part=0)\")` deletes the `part=0` folder (and invalidates the cache for partition data after the fix).\r\n4. Since `df` contains the same `FileSourceScanExec` with already materialized `inputRDD`, the second action `df.collect()` tries to read the deleted folder `part=0`. As a consequence of that, we observe the exception: `java.io.FileNotFoundException: File file:.../ns.db/tbl/part=0/... does not exist`\r\n\r\nAs you can see, the problem of SPARK-33941 is not only in caching.",
        "createdAt" : "2021-01-01T09:03:05Z",
        "updatedAt" : "2021-01-03T08:33:21Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "021c4ac89b4bfde874bdbaf814e3d7791cb88bc9",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +582,586 @@      retainData = retainData)\n\n    sparkSession.catalog.refreshTable(table.identifier.quotedString)\n    CommandUtils.updateTableStats(sparkSession, table)\n"
  },
  {
    "id" : "715f5d6e-a829-4557-80fd-2d245edc1e41",
    "prId" : 30869,
    "prUrl" : "https://github.com/apache/spark/pull/30869#pullrequestreview-706343493",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4ac9f715-4cf1-4786-b1d3-37b0aeefe4d8",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "how about inner field names? do we need to check?",
        "createdAt" : "2021-07-14T14:26:20Z",
        "updatedAt" : "2021-07-14T14:26:20Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "706938c3c970225dfbfcd673d1e58faca4c344d0",
    "line" : 42,
    "diffHunk" : "@@ -1,1 +935,939 @@          val serde = table.storage.serde\n          if (serde == HiveSerDe.sourceToSerDe(\"orc\").get.serde) {\n            checkDataColNames(\"orc\", colNames)\n          } else if (serde == HiveSerDe.sourceToSerDe(\"parquet\").get.serde ||\n            serde == Some(\"parquet.hive.serde.ParquetHiveSerDe\") ||"
  },
  {
    "id" : "5bf74997-c95a-4734-9909-d4377176e6c8",
    "prId" : 30869,
    "prUrl" : "https://github.com/apache/spark/pull/30869#pullrequestreview-706346136",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b65a0011-2634-4cab-bab4-475fc19a562d",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "why do we limit to only these 3 file sources?",
        "createdAt" : "2021-07-14T14:28:29Z",
        "updatedAt" : "2021-07-14T14:28:29Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "706938c3c970225dfbfcd673d1e58faca4c344d0",
    "line" : 53,
    "diffHunk" : "@@ -1,1 +943,947 @@            checkDataColNames(\"avro\", colNames)\n          }\n        case provider if Seq(\"parquet\", \"orc\", \"avro\").contains(provider) =>\n          checkDataColNames(provider, colNames)\n        case _ =>"
  },
  {
    "id" : "34b41e6e-4236-41ce-a8c8-860af59ca73b",
    "prId" : 30869,
    "prUrl" : "https://github.com/apache/spark/pull/30869#pullrequestreview-706354669",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9c24c4b2-b7be-4a10-93aa-778495a89bff",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "file source v2 have a better place to put this check: https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/v2/FileTable.scala#L84",
        "createdAt" : "2021-07-14T14:35:23Z",
        "updatedAt" : "2021-07-14T14:35:23Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "706938c3c970225dfbfcd673d1e58faca4c344d0",
    "line" : 64,
    "diffHunk" : "@@ -1,1 +954,958 @@      DataSource.lookupDataSource(provider, SQLConf.get).getConstructor().newInstance() match {\n        case f: FileFormat => f.checkFieldNames(colNames)\n        case f: FileDataSourceV2 => f.checkFieldNames(colNames)\n        case _ =>\n      }"
  },
  {
    "id" : "571d7b0e-87f1-435e-8ac9-c1f6bccee612",
    "prId" : 30869,
    "prUrl" : "https://github.com/apache/spark/pull/30869#pullrequestreview-706417000",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "38d49cd3-9630-424c-92ca-6a16826cde74",
        "parentId" : null,
        "authorId" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "body" : "We should catch a more specific exception here. At least limited to `NonFatal`, but really it should probably be just the should probably just be `ReflectiveOperationException` and `SecurityException`. I also don't see why we catch-and-rethrow `AnalysisException` and `SchemaParseException`?",
        "createdAt" : "2021-07-14T15:26:37Z",
        "updatedAt" : "2021-07-14T15:29:37Z",
        "lastEditedBy" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "tags" : [
        ]
      }
    ],
    "commit" : "706938c3c970225dfbfcd673d1e58faca4c344d0",
    "line" : 71,
    "diffHunk" : "@@ -1,1 +961,965 @@      case e: SchemaParseException => throw e\n      case e: Throwable =>\n        logError(s\"Failed to find data source: $provider when check data column names.\", e)\n    }\n  }"
  },
  {
    "id" : "8a34a385-3a67-4304-92e5-1cac4d0c6331",
    "prId" : 28662,
    "prUrl" : "https://github.com/apache/spark/pull/28662#pullrequestreview-424135560",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9fb801db-e216-4f5f-9acf-338fbbed2720",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "I can see `readHiveTable` is used by writing path (`InsertIntoStatement`) too. If we just get cached plan, will it be dangerous if the cached plan is out-of-date and Spark writes with incorrect metadata?",
        "createdAt" : "2020-06-03T22:48:25Z",
        "updatedAt" : "2020-06-05T05:24:23Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "7ec22bf1-cf37-4d31-ab42-cd70816734b3",
        "parentId" : "9fb801db-e216-4f5f-9acf-338fbbed2720",
        "authorId" : "f3166ab8-4dba-4d22-b10b-31a984dfa2ad",
        "body" : "I tried to reuse the cache of Datasource tables for Hive tables\r\nInsertIntoStatement for Datasource tables, also fetches from the same cache. The cache invalidation have been taken care. \r\nFrom my reading, I didnt find any cases. Let me know if you find any cases that needs special handling. I will also check the code from this perspective again.",
        "createdAt" : "2020-06-04T06:27:50Z",
        "updatedAt" : "2020-06-05T05:24:23Z",
        "lastEditedBy" : "f3166ab8-4dba-4d22-b10b-31a984dfa2ad",
        "tags" : [
        ]
      }
    ],
    "commit" : "59d45fc1f6a9c3aaa581bd367d18e956776ff46f",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +852,856 @@  }\n\n  def readHiveTable(catalog: SessionCatalog, table: CatalogTable): HiveTableRelation = {\n    val qualifiedTableName = QualifiedTableName(table.database, table.identifier.table)\n    val tbl = catalog.getCachedPlan(qualifiedTableName, () => {"
  },
  {
    "id" : "61aa2e76-7b5a-45e2-bdbe-738def053013",
    "prId" : 28056,
    "prUrl" : "https://github.com/apache/spark/pull/28056#pullrequestreview-383627486",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "428589c0-ed86-4aba-971f-bfb3947d1ab4",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Hm, @wangyum, when `isTempView` is `true`, `catalog.tableExists(tableName)` won't be called by short-circuiting. So, this isn't a clean improvement but it has trade-off. Can you clarify this trade-off as well?",
        "createdAt" : "2020-03-30T08:21:46Z",
        "updatedAt" : "2020-03-31T02:57:57Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "c0f1305ed8abf571e226d211a74d6dbd98b55e33",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +236,240 @@    }\n\n    if (isTempView || isTableExist) {\n      try {\n        sparkSession.sharedState.cacheManager.uncacheQuery("
  }
]