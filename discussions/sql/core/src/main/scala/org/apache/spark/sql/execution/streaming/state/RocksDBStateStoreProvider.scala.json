[
  {
    "id" : "35252deb-8d1a-4547-96a5-2c51f28bedea",
    "prId" : 33455,
    "prUrl" : "https://github.com/apache/spark/pull/33455#pullrequestreview-717095098",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fdb7e5ee-8460-44b0-a5a1-fe4aaee6bcff",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Is it `nativeOpsHistograms` here?",
        "createdAt" : "2021-07-21T08:27:43Z",
        "updatedAt" : "2021-07-21T08:27:43Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "805bd478-dbdc-4da8-bddd-eb7f2f48fbcb",
        "parentId" : "fdb7e5ee-8460-44b0-a5a1-fe4aaee6bcff",
        "authorId" : "56016911-ce1a-4799-a941-6dac717edd44",
        "body" : "its actually `nativeOpsMetrics` (the ticker based metrics)",
        "createdAt" : "2021-07-21T14:33:01Z",
        "updatedAt" : "2021-07-21T14:45:16Z",
        "lastEditedBy" : "56016911-ce1a-4799-a941-6dac717edd44",
        "tags" : [
        ]
      },
      {
        "id" : "e3e46537-85eb-4d47-8087-b246987d0f75",
        "parentId" : "fdb7e5ee-8460-44b0-a5a1-fe4aaee6bcff",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Hm, `nativeOpsMetrics` looks like counting metrics, why this is `nativeOpsLatencyMillis` which is a timing metrics?",
        "createdAt" : "2021-07-28T08:24:36Z",
        "updatedAt" : "2021-07-28T08:24:37Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "d086e8d4-0295-4176-ab34-3f6f256bc076",
        "parentId" : "fdb7e5ee-8460-44b0-a5a1-fe4aaee6bcff",
        "authorId" : "56016911-ce1a-4799-a941-6dac717edd44",
        "body" : "The ticker based metrics are not just `counts` of some operations, they also capture the time. Example one is [here](https://javadoc.io/static/org.rocksdb/rocksdbjni/6.4.6/org/rocksdb/TickerType.html#STALL_MICROS). This is just a utility method to extract the time out of these ticker based metrics.",
        "createdAt" : "2021-07-28T14:41:32Z",
        "updatedAt" : "2021-07-28T14:43:21Z",
        "lastEditedBy" : "56016911-ce1a-4799-a941-6dac717edd44",
        "tags" : [
        ]
      }
    ],
    "commit" : "3a6c42b5ca95afc8e573c2e06b03282a420d23c5",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +108,112 @@      def commitLatencyMs(typ: String): Long = rocksDBMetrics.lastCommitLatencyMs.getOrElse(typ, 0L)\n      def nativeOpsLatencyMillis(typ: String): Long = {\n        rocksDBMetrics.nativeOpsMetrics.get(typ).map(_ * 1000).getOrElse(0)\n      }\n      def sumNativeOpsLatencyMillis(typ: String): Long = {"
  },
  {
    "id" : "d7d801a0-f2a6-4d28-a982-012c925d9628",
    "prId" : 33455,
    "prUrl" : "https://github.com/apache/spark/pull/33455#pullrequestreview-711398356",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fd3c4d01-5ff3-4870-a894-516fe19cea44",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Good catch.",
        "createdAt" : "2021-07-21T08:34:54Z",
        "updatedAt" : "2021-07-21T08:34:55Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "3a6c42b5ca95afc8e573c2e06b03282a420d23c5",
    "line" : 85,
    "diffHunk" : "@@ -1,1 +260,264 @@  val CUSTOM_METRIC_FILESYNC_TIME = StateStoreCustomTimingMetric(\n    \"rocksdbCommitFileSyncLatencyMs\", \"RocksDB: commit - file sync to external storage time\")\n  val CUSTOM_METRIC_FILES_COPIED = StateStoreCustomSumMetric(\n    \"rocksdbFilesCopied\", \"RocksDB: file manager - files copied\")\n  val CUSTOM_METRIC_BYTES_COPIED = StateStoreCustomSizeMetric("
  },
  {
    "id" : "07828635-4a8f-4b03-ace8-65e3f193bba3",
    "prId" : 33455,
    "prUrl" : "https://github.com/apache/spark/pull/33455#pullrequestreview-717222083",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "168893a7-b703-49bd-84da-68b3c96fe2e2",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "`nativeOpsCount` looks like more for `nativeOpsMetrics`?",
        "createdAt" : "2021-07-28T08:25:41Z",
        "updatedAt" : "2021-07-28T08:25:41Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "093ec27d-0633-47d8-95e4-0c2df48453b3",
        "parentId" : "168893a7-b703-49bd-84da-68b3c96fe2e2",
        "authorId" : "56016911-ce1a-4799-a941-6dac717edd44",
        "body" : "`nativeOpsCount` is extracting the `count` from histogram based metrics. `nativeOpsMetrics` is extracting the value from ticker based metrics.",
        "createdAt" : "2021-07-28T14:43:04Z",
        "updatedAt" : "2021-07-28T14:43:21Z",
        "lastEditedBy" : "56016911-ce1a-4799-a941-6dac717edd44",
        "tags" : [
        ]
      },
      {
        "id" : "6e23a244-1355-4ea3-9458-9ee45e1adab3",
        "parentId" : "168893a7-b703-49bd-84da-68b3c96fe2e2",
        "authorId" : "56016911-ce1a-4799-a941-6dac717edd44",
        "body" : "`nativeOpsCount` is extracting the `count` from histogram based metrics. `nativeOpsMetrics` is extracting the value from ticker based metrics.",
        "createdAt" : "2021-07-28T14:43:15Z",
        "updatedAt" : "2021-07-28T14:43:21Z",
        "lastEditedBy" : "56016911-ce1a-4799-a941-6dac717edd44",
        "tags" : [
        ]
      },
      {
        "id" : "010b8ef2-1dc0-4955-97c9-575db11e8132",
        "parentId" : "168893a7-b703-49bd-84da-68b3c96fe2e2",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Oh, I see. Thanks for clarifying it.",
        "createdAt" : "2021-07-28T16:28:01Z",
        "updatedAt" : "2021-07-28T16:28:01Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "3a6c42b5ca95afc8e573c2e06b03282a420d23c5",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +115,119 @@      def nativeOpsCount(typ: String): Long = {\n        rocksDBMetrics.nativeOpsHistograms.get(typ).map(_.count).getOrElse(0)\n      }\n      def nativeOpsMetrics(typ: String): Long = {\n        rocksDBMetrics.nativeOpsMetrics.get(typ).getOrElse(0)"
  },
  {
    "id" : "3e61a147-7374-43e0-ad85-f3b3b32bc81d",
    "prId" : 33187,
    "prUrl" : "https://github.com/apache/spark/pull/33187#pullrequestreview-699571252",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d07effdd-d24f-4cf1-a8b8-19a1cf394abb",
        "parentId" : null,
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "I thought the characters (`=,()`) being used in `storeIdStr` are odd, but this works in MacOS and I think it would also work in Linux file systems, so OK.",
        "createdAt" : "2021-07-05T02:45:57Z",
        "updatedAt" : "2021-07-05T03:06:56Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      },
      {
        "id" : "6fd9a9c0-353c-4824-83c0-7f4bac7b75b8",
        "parentId" : "d07effdd-d24f-4cf1-a8b8-19a1cf394abb",
        "authorId" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "body" : "Yes, the dir contains `=()` works in the Linux file system.",
        "createdAt" : "2021-07-06T06:19:13Z",
        "updatedAt" : "2021-07-06T06:19:13Z",
        "lastEditedBy" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "tags" : [
        ]
      }
    ],
    "commit" : "b6a9d0ac78e85c1c411d67ae48417de02de85093",
    "line" : 194,
    "diffHunk" : "@@ -1,1 +192,196 @@      s\"partId=${stateStoreId.partitionId},name=${stateStoreId.storeName})\"\n    val sparkConf = Option(SparkEnv.get).map(_.conf).getOrElse(new SparkConf)\n    val localRootDir = Utils.createTempDir(Utils.getLocalDir(sparkConf), storeIdStr)\n    new RocksDB(dfsRootDir, RocksDBConf(storeConf), localRootDir, hadoopConf, storeIdStr)\n  }"
  },
  {
    "id" : "c26ffab5-9732-4da1-be9f-db9d868bdbdb",
    "prId" : 33187,
    "prUrl" : "https://github.com/apache/spark/pull/33187#pullrequestreview-699572053",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5f3ed88c-f491-4ae0-9248-f4e9da8af790",
        "parentId" : null,
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "This simply works as there's only one version (version 0) - we'll need to check the version when we add a new state encoding version.",
        "createdAt" : "2021-07-05T02:52:01Z",
        "updatedAt" : "2021-07-05T03:06:56Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      },
      {
        "id" : "39a7db51-a43f-4d0d-9fbb-19d938f33026",
        "parentId" : "5f3ed88c-f491-4ae0-9248-f4e9da8af790",
        "authorId" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "body" : "Yea, agree. For the new encoding version, we should have branches here for different versions.",
        "createdAt" : "2021-07-06T06:20:37Z",
        "updatedAt" : "2021-07-06T06:20:37Z",
        "lastEditedBy" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "tags" : [
        ]
      }
    ],
    "commit" : "b6a9d0ac78e85c1c411d67ae48417de02de85093",
    "line" : 245,
    "diffHunk" : "@@ -1,1 +243,247 @@    def decodeKey(keyBytes: Array[Byte]): UnsafeRow = {\n      if (keyBytes != null) {\n        // Platform.BYTE_ARRAY_OFFSET is the recommended way refer to the 1st offset. See Platform.\n        keyRow.pointTo(\n          keyBytes,"
  },
  {
    "id" : "53845dbb-3e82-44e3-962d-97f2e8c47933",
    "prId" : 33187,
    "prUrl" : "https://github.com/apache/spark/pull/33187#pullrequestreview-699572339",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "151bfd02-a45a-4ad0-9a09-22478da782d4",
        "parentId" : null,
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "We can deduplicate here; I can deal with it in prefix scan for RocksDB state store as I'll bring broader change for state encoding.",
        "createdAt" : "2021-07-05T02:53:49Z",
        "updatedAt" : "2021-07-05T03:06:56Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      },
      {
        "id" : "a2117ee4-65a5-4f55-a2d0-9f5fbe4f56e0",
        "parentId" : "151bfd02-a45a-4ad0-9a09-22478da782d4",
        "authorId" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "body" : "Copy that.",
        "createdAt" : "2021-07-06T06:21:05Z",
        "updatedAt" : "2021-07-06T06:21:05Z",
        "lastEditedBy" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "tags" : [
        ]
      }
    ],
    "commit" : "b6a9d0ac78e85c1c411d67ae48417de02de85093",
    "line" : 265,
    "diffHunk" : "@@ -1,1 +263,267 @@      if (valueBytes != null) {\n        // Platform.BYTE_ARRAY_OFFSET is the recommended way refer to the 1st offset. See Platform.\n        valueRow.pointTo(\n          valueBytes,\n          Platform.BYTE_ARRAY_OFFSET + STATE_ENCODING_NUM_VERSION_BYTES,"
  },
  {
    "id" : "e0bbb636-665e-4cd1-8e97-d39781336630",
    "prId" : 33187,
    "prUrl" : "https://github.com/apache/spark/pull/33187#pullrequestreview-699572436",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b7e6a99c-2336-485e-af75-ba98568a183e",
        "parentId" : null,
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "nit: remove one of two empty lines",
        "createdAt" : "2021-07-05T02:56:31Z",
        "updatedAt" : "2021-07-05T03:06:56Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      },
      {
        "id" : "78e5545d-fbbd-438b-a8a7-dd2da48695ed",
        "parentId" : "b7e6a99c-2336-485e-af75-ba98568a183e",
        "authorId" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "body" : "Thanks, done in 9ddbf58",
        "createdAt" : "2021-07-06T06:21:16Z",
        "updatedAt" : "2021-07-06T06:21:16Z",
        "lastEditedBy" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "tags" : [
        ]
      }
    ],
    "commit" : "b6a9d0ac78e85c1c411d67ae48417de02de85093",
    "line" : 322,
    "diffHunk" : "@@ -1,1 +320,324 @@  val CUSTOM_METRIC_SST_FILE_SIZE = StateStoreCustomSizeMetric(\n    \"rocksdbSstFileSize\", \"RocksDB: size of all SST files\")\n\n  val ALL_CUSTOM_METRICS = Seq(\n    CUSTOM_METRIC_SST_FILE_SIZE, CUSTOM_METRIC_GET_TIME, CUSTOM_METRIC_PUT_TIME,"
  },
  {
    "id" : "496c8e5f-7f14-486c-9ccd-c8093c808aaf",
    "prId" : 33187,
    "prUrl" : "https://github.com/apache/spark/pull/33187#pullrequestreview-701834144",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ebc1c873-4599-46dd-a3b0-36d08649a0d2",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "I recommend to be consistent with `HDFSBackedStateStore` where it uses `version` and `newVersion`.",
        "createdAt" : "2021-07-08T07:38:55Z",
        "updatedAt" : "2021-07-08T07:38:55Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "622b73eb-0380-4355-83cc-81fca1d0eb8f",
        "parentId" : "ebc1c873-4599-46dd-a3b0-36d08649a0d2",
        "authorId" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "body" : "Actually for RocksDB, we keep the name `newVersion`. The major difference here is we have a `loadedVersion` concept, so that's why for the provider side, we have a `latestVersion`.",
        "createdAt" : "2021-07-08T09:20:30Z",
        "updatedAt" : "2021-07-08T09:20:30Z",
        "lastEditedBy" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "tags" : [
        ]
      }
    ],
    "commit" : "b6a9d0ac78e85c1c411d67ae48417de02de85093",
    "line" : 47,
    "diffHunk" : "@@ -1,1 +45,49 @@    override def id: StateStoreId = RocksDBStateStoreProvider.this.stateStoreId\n\n    override def version: Long = lastVersion\n\n    override def get(key: UnsafeRow): UnsafeRow = {"
  },
  {
    "id" : "d5487145-acec-4fdf-b041-88de6d3a2f17",
    "prId" : 24922,
    "prUrl" : "https://github.com/apache/spark/pull/24922#pullrequestreview-254476242",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0bf39d9f-4d17-412f-bd12-c1f31c8ab575",
        "parentId" : null,
        "authorId" : "63281e91-e961-4e6e-b0bb-6855587910d1",
        "body" : "Can we make `rocksDbPath` configurable as in [here](https://github.com/apache/flink/blob/d8aac6ffb833d1d0348be0f6d280b465213d5df5/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBStateBackend.java#L327)?\r\n",
        "createdAt" : "2019-06-20T10:56:04Z",
        "updatedAt" : "2019-09-26T06:35:25Z",
        "lastEditedBy" : "63281e91-e961-4e6e-b0bb-6855587910d1",
        "tags" : [
        ]
      },
      {
        "id" : "ecfd57fa-e375-42ba-885f-a9189af8de74",
        "parentId" : "0bf39d9f-4d17-412f-bd12-c1f31c8ab575",
        "authorId" : "be7041e0-9315-4dbe-8cde-5135813054ec",
        "body" : "Sure. Will make the changes.",
        "createdAt" : "2019-06-21T04:25:25Z",
        "updatedAt" : "2019-09-26T06:35:25Z",
        "lastEditedBy" : "be7041e0-9315-4dbe-8cde-5135813054ec",
        "tags" : [
        ]
      },
      {
        "id" : "11573d33-29d6-472a-8aef-e3439abb7a4c",
        "parentId" : "0bf39d9f-4d17-412f-bd12-c1f31c8ab575",
        "authorId" : "be7041e0-9315-4dbe-8cde-5135813054ec",
        "body" : "Done",
        "createdAt" : "2019-06-26T09:07:46Z",
        "updatedAt" : "2019-09-26T06:35:25Z",
        "lastEditedBy" : "be7041e0-9315-4dbe-8cde-5135813054ec",
        "tags" : [
        ]
      }
    ],
    "commit" : "45e0d054a38958ac9e1b7c6a9429a3a3df9b8ff1",
    "line" : 435,
    "diffHunk" : "@@ -1,1 +433,437 @@              s\" No SST files found\")\n        }\n        FileUtils.moveDirectory(tmpLocDir, new File(rocksDbPath))\n        true\n      } else {"
  },
  {
    "id" : "79b8cb26-cef4-41df-aa22-5adc21690672",
    "prId" : 24922,
    "prUrl" : "https://github.com/apache/spark/pull/24922#pullrequestreview-258747195",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a5041a79-0c64-46ef-9eb9-d4492d147baf",
        "parentId" : null,
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "According to RocksDB FAQ, better to comment here it's an \"estimated\" value due to the nature of RocksDB.\r\nhttps://github.com/facebook/rocksdb/wiki/RocksDB-FAQ\r\n",
        "createdAt" : "2019-07-05T06:18:09Z",
        "updatedAt" : "2019-09-26T06:35:25Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      },
      {
        "id" : "ba0421d4-0949-4dd7-ba96-37d1a5024e9b",
        "parentId" : "a5041a79-0c64-46ef-9eb9-d4492d147baf",
        "authorId" : "be7041e0-9315-4dbe-8cde-5135813054ec",
        "body" : "added",
        "createdAt" : "2019-07-08T08:17:18Z",
        "updatedAt" : "2019-09-26T06:35:25Z",
        "lastEditedBy" : "be7041e0-9315-4dbe-8cde-5135813054ec",
        "tags" : [
        ]
      }
    ],
    "commit" : "45e0d054a38958ac9e1b7c6a9429a3a3df9b8ff1",
    "line" : 111,
    "diffHunk" : "@@ -1,1 +109,113 @@     * see https://github.com/facebook/rocksdb/wiki/RocksDB-FAQ for more details\n     */\n    var numEntriesInDb: Long = 0L\n    var bytesUsedByDb: Long = 0L\n"
  },
  {
    "id" : "04201e9c-00c5-4c97-a741-dd9c3e76a062",
    "prId" : 24922,
    "prUrl" : "https://github.com/apache/spark/pull/24922#pullrequestreview-256162930",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "46392cdd-e763-42d0-a6f8-2ceac67f43d9",
        "parentId" : null,
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "According to the FAQ, `numEntriesInDb` here is an estimated value, as well as some of entries are tombstone, so this value is also become \"estimated\" and even very roughly. Better to comment here as well.",
        "createdAt" : "2019-07-05T06:24:26Z",
        "updatedAt" : "2019-09-26T06:35:25Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      }
    ],
    "commit" : "45e0d054a38958ac9e1b7c6a9429a3a3df9b8ff1",
    "line" : 112,
    "diffHunk" : "@@ -1,1 +110,114 @@     */\n    var numEntriesInDb: Long = 0L\n    var bytesUsedByDb: Long = 0L\n\n    private def initTransaction(): Unit = {"
  },
  {
    "id" : "1e20f5e8-81d1-4a45-a8d9-ebeba2b4701f",
    "prId" : 24922,
    "prUrl" : "https://github.com/apache/spark/pull/24922#pullrequestreview-258792264",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c77555aa-4451-438b-982c-8b00d632842f",
        "parentId" : null,
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "Does the provider guarantee `dbPath` always contains the content of the version? HDFS state store provider always \"loads\" the version first and then snapshot it, so it guarantees snapshot is properly created.",
        "createdAt" : "2019-07-05T08:18:09Z",
        "updatedAt" : "2019-09-26T06:35:25Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      },
      {
        "id" : "dc2447cb-5e89-4290-a8df-ca94ae105a1f",
        "parentId" : "c77555aa-4451-438b-982c-8b00d632842f",
        "authorId" : "be7041e0-9315-4dbe-8cde-5135813054ec",
        "body" : "if `dbPath` exists, as per the code semantics, it will have backed up version. Every time we commit/close a version, a backed up version is created at a different folder location.\r\n\r\nI will make changes to check if `dbPath` exists before creating TarFile\r\n\r\nCreating backup helped in physical isolation between current active DB and prev versions but it comes with a cost. (Every micro-batch takes some extra time to complete). I will try to find any other alternative to save this cost.",
        "createdAt" : "2019-07-08T10:06:28Z",
        "updatedAt" : "2019-09-26T06:35:25Z",
        "lastEditedBy" : "be7041e0-9315-4dbe-8cde-5135813054ec",
        "tags" : [
        ]
      }
    ],
    "commit" : "45e0d054a38958ac9e1b7c6a9429a3a3df9b8ff1",
    "line" : 513,
    "diffHunk" : "@@ -1,1 +511,515 @@        try {\n          val (_, t1) = Utils.timeTakenMs {\n            FileUtility.createTarFile(dbPath, snapShotFileName)\n            val targetFile = snapshotFile(baseDir, lastVersion)\n            uploadFile(fm, new Path(snapShotFileName), targetFile, sparkConf)"
  }
]