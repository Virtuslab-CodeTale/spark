[
  {
    "id" : "cac7bcf6-4d02-425f-920d-0bb21de7bdd5",
    "prId" : 30097,
    "prUrl" : "https://github.com/apache/spark/pull/30097#pullrequestreview-528862463",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8eb835ed-0c41-470d-9bcf-8a5efa82398c",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ditto",
        "createdAt" : "2020-11-12T08:44:40Z",
        "updatedAt" : "2020-11-12T08:44:40Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "7612695c78456155a95ad4f7d54ef70e53f88921",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +74,78 @@ * Preprocess [[CreateTable]], to do some normalization and checking.\n */\nobject PreprocessTableCreation extends Rule[LogicalPlan] {\n  // catalog is a def and not a val/lazy val as the latter would introduce a circular reference\n  private def catalog = SparkSession.active.sessionState.catalog"
  },
  {
    "id" : "1818aa26-9e34-4735-bd6b-7b3669f993cf",
    "prId" : 28833,
    "prUrl" : "https://github.com/apache/spark/pull/28833#pullrequestreview-440721670",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "107f2be0-cf6e-4a61-a254-e855122a49a7",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Is this needed? I think the changes in `ResolveCatalogs` and `ResolveSessionCatalog` should cover all the commands.",
        "createdAt" : "2020-07-01T04:40:56Z",
        "updatedAt" : "2020-07-08T00:27:04Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "58d28d99-4846-4adc-a253-8854cd43ecea",
        "parentId" : "107f2be0-cf6e-4a61-a254-e855122a49a7",
        "authorId" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "body" : "Without this, \"CREATE TABLE t1 USING PARQUET AS SELECT null as null_col\" in Spark will throw `Parquet data source does not support null data type.` instead of `Cannot create tables with VOID type`\r\n\r\nComparing the error message from Hive `SemanticException [Error 10305]: CREATE-TABLE-AS-SELECT creates a VOID type, please use CAST to specify the type, near field: col`, it's confused. So better to keep it.",
        "createdAt" : "2020-07-01T06:46:25Z",
        "updatedAt" : "2020-07-08T00:27:04Z",
        "lastEditedBy" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "tags" : [
        ]
      },
      {
        "id" : "b40e40bc-5a03-4542-a14a-1fe747eac63f",
        "parentId" : "107f2be0-cf6e-4a61-a254-e855122a49a7",
        "authorId" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "body" : "@cloud-fan \r\n> Without this, \"CREATE TABLE t1 USING PARQUET AS SELECT null as null_col\" in Spark will throw `Parquet data source does not support null data type.` instead of `Cannot create tables with VOID type`\r\n\r\nSorry, above description is incorrect. Without this, CTAS for Hive table `CREATE TABLE t2 AS SELECT null as null_col` will pass. No exception throws.\r\n\r\nSeems Hive table (non-parquet/orc format) doesn't go through `ResolveSessionCatalog`",
        "createdAt" : "2020-07-01T09:54:56Z",
        "updatedAt" : "2020-07-08T00:27:04Z",
        "lastEditedBy" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "tags" : [
        ]
      }
    ],
    "commit" : "9ad57d17bac47ea0f801004ec0aba9197e631bc7",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +294,298 @@      sparkSession.sessionState.conf.caseSensitiveAnalysis)\n\n    assertNoNullTypeInSchema(schema)\n\n    val normalizedPartCols = normalizePartitionColumns(schema, table)"
  },
  {
    "id" : "3f2d73e6-eddf-4304-aaaf-3b493e929e66",
    "prId" : 25305,
    "prUrl" : "https://github.com/apache/spark/pull/25305#pullrequestreview-272684133",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2b2a5310-f1eb-4478-9795-7374f7a355f5",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "shall we add an assert that the plan must be `CreateTableAsSelect` if schema is empty?",
        "createdAt" : "2019-08-07T08:01:29Z",
        "updatedAt" : "2019-08-08T16:17:23Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "3c1b4599-9cee-4827-bf2f-6d952eb88727",
        "parentId" : "2b2a5310-f1eb-4478-9795-7374f7a355f5",
        "authorId" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "body" : "no. Existing data may exist for a table, and all that you may want is to create a pointer to that table (Think of creating a pointer to a JDBC table in the MetaStore)",
        "createdAt" : "2019-08-08T16:14:04Z",
        "updatedAt" : "2019-08-08T16:17:23Z",
        "lastEditedBy" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "tags" : [
        ]
      }
    ],
    "commit" : "b7a5ac549c26153a3aa8bf3e73bd415929a78a1f",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +255,259 @@        partitioning, \"in the partitioning\", isCaseSensitive)\n\n      if (schema.isEmpty) {\n        if (partitioning.nonEmpty) {\n          throw new AnalysisException(\"It is not allowed to specify partitioning when the \" +"
  },
  {
    "id" : "1f80b83c-d0ee-49c2-8d31-6a4b192bda68",
    "prId" : 25198,
    "prUrl" : "https://github.com/apache/spark/pull/25198#pullrequestreview-272460229",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "479bafee-c91f-42ff-8216-b89c220020f0",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I think the rationale here is that, we don't want to create tables with null type field. It should be same for both `CREATE TABLE` and `CTAS`.",
        "createdAt" : "2019-08-08T07:16:51Z",
        "updatedAt" : "2019-09-30T09:56:42Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "1554695a-c2b1-4072-a50a-9740460c3c5d",
        "parentId" : "479bafee-c91f-42ff-8216-b89c220020f0",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "OK, and also add `AlterTable`.",
        "createdAt" : "2019-08-08T09:48:42Z",
        "updatedAt" : "2019-09-30T09:56:42Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "358e2a225d6744274599774ca9ea9878c712a1e5",
    "line" : 54,
    "diffHunk" : "@@ -1,1 +479,483 @@        checkSchema(tableDesc.schema)\n\n      case CreateV2Table(_, _, tableSchema, _, _, _) =>\n        checkSchema(tableSchema)\n"
  }
]