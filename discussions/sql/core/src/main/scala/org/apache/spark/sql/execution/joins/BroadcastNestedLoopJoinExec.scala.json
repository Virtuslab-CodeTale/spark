[
  {
    "id" : "1c17df39-57b4-4175-ae5d-f5497120ea73",
    "prId" : 31874,
    "prUrl" : "https://github.com/apache/spark/pull/31874#pullrequestreview-616074405",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "86c68e31-87e0-4fb5-ae35-8c62041c77f0",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "For this case, we don't need to add a mutable state for `buildRowArrayTerm `?",
        "createdAt" : "2021-03-19T01:28:47Z",
        "updatedAt" : "2021-03-21T06:09:04Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "14a0d375-063d-418c-8f35-e0fa017a8baa",
        "parentId" : "86c68e31-87e0-4fb5-ae35-8c62041c77f0",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "It's already added inside `prepareBroadcast`",
        "createdAt" : "2021-03-19T03:55:00Z",
        "updatedAt" : "2021-03-21T06:09:04Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "0e408d23-2c2b-4732-ba93-fa326d70851f",
        "parentId" : "86c68e31-87e0-4fb5-ae35-8c62041c77f0",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "~Ah, my qestion is wrong. I meant, is `buildRowArrayTerm` referenced in this case?~ Ah, nvm, it looks fine.",
        "createdAt" : "2021-03-19T05:36:50Z",
        "updatedAt" : "2021-03-21T06:09:04Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "f2e846d873f1e062429a58ceb56cb1bf2aaab14d",
    "line" : 81,
    "diffHunk" : "@@ -1,1 +482,486 @@        // 2. build side is non-empty for LeftAnti join.\n        \"\"\n      }\n    } else {\n      val (buildRow, checkCondition, _) = getJoinCondition(ctx, input, streamed, broadcast)"
  },
  {
    "id" : "6262fcb3-8770-42f4-87bd-ff8f55ea5393",
    "prId" : 31821,
    "prUrl" : "https://github.com/apache/spark/pull/31821#pullrequestreview-611353302",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "08be6f5b-1ec3-46a2-9fad-de4296f0dfd7",
        "parentId" : null,
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "`BuildRight` related logic here is not changed.",
        "createdAt" : "2021-03-13T01:41:42Z",
        "updatedAt" : "2021-03-13T06:21:03Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      }
    ],
    "commit" : "f0ba910eb308af926992afe08b5ac8f504b2624f",
    "line" : 43,
    "diffHunk" : "@@ -1,1 +200,204 @@      exists: Boolean): RDD[InternalRow] = {\n    buildSide match {\n      case BuildRight =>\n        streamed.execute().mapPartitionsInternal { streamedIter =>\n          val buildRows = relation.value"
  },
  {
    "id" : "d9a4b053-17a5-41d0-9982-ca0212b6e2b6",
    "prId" : 31821,
    "prUrl" : "https://github.com/apache/spark/pull/31821#pullrequestreview-611354356",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5d702a47-b9b9-469e-959b-672e7da922ac",
        "parentId" : null,
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "`BuildLeft` with `condition.isEmpty` is the added new change in this PR.",
        "createdAt" : "2021-03-13T01:42:21Z",
        "updatedAt" : "2021-03-13T06:21:03Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      }
    ],
    "commit" : "f0ba910eb308af926992afe08b5ac8f504b2624f",
    "line" : 62,
    "diffHunk" : "@@ -1,1 +215,219 @@          }\n        }\n      case BuildLeft if condition.isEmpty =>\n        // If condition is empty, do not need to read rows from streamed side at all.\n        // Only need to know whether streamed side is empty or not."
  },
  {
    "id" : "bf145092-2e73-42e6-baef-3e858d2cad7e",
    "prId" : 31821,
    "prUrl" : "https://github.com/apache/spark/pull/31821#pullrequestreview-611356813",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0ad47521-de3b-4d5d-ae93-58735c42c184",
        "parentId" : null,
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "`BuildRight` related logic here is not changed.",
        "createdAt" : "2021-03-13T01:43:59Z",
        "updatedAt" : "2021-03-13T06:21:03Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      }
    ],
    "commit" : "f0ba910eb308af926992afe08b5ac8f504b2624f",
    "line" : 131,
    "diffHunk" : "@@ -1,1 +244,248 @@  private def existenceJoin(relation: Broadcast[Array[InternalRow]]): RDD[InternalRow] = {\n    buildSide match {\n      case BuildRight =>\n        streamed.execute().mapPartitionsInternal { streamedIter =>\n          val buildRows = relation.value"
  },
  {
    "id" : "972f8a7e-9eb7-4cb6-9aa6-ed7d39135558",
    "prId" : 31821,
    "prUrl" : "https://github.com/apache/spark/pull/31821#pullrequestreview-611570996",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "49d58d1b-e4b8-43a3-b503-e4f66298189b",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "`defaultJoin` now has outer joins only, so we cannot merge it with `outerJoin`?",
        "createdAt" : "2021-03-13T05:08:56Z",
        "updatedAt" : "2021-03-13T06:21:03Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "627f24d2-a016-4254-a7ce-14d70dedb339",
        "parentId" : "49d58d1b-e4b8-43a3-b503-e4f66298189b",
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "@maropu - we can, but I feel the code is too complicated as one method when combining these two.",
        "createdAt" : "2021-03-13T06:01:54Z",
        "updatedAt" : "2021-03-13T06:21:30Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      }
    ],
    "commit" : "f0ba910eb308af926992afe08b5ac8f504b2624f",
    "line" : 190,
    "diffHunk" : "@@ -1,1 +284,288 @@   *   FullOuter\n   */\n  private def defaultJoin(relation: Broadcast[Array[InternalRow]]): RDD[InternalRow] = {\n    val streamRdd = streamed.execute()\n    val matchedBroadcastRows = getMatchedBroadcastRowsBitSet(streamRdd, relation)"
  },
  {
    "id" : "437ab8f7-f504-4b59-b156-ee38cccf99fd",
    "prId" : 31821,
    "prUrl" : "https://github.com/apache/spark/pull/31821#pullrequestreview-611570996",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "21d3781a-3f45-4d0c-8b62-6e465f93cd4b",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "we need this variable `streamRdd ` here? How about referencing `streamed` directly?",
        "createdAt" : "2021-03-13T05:15:03Z",
        "updatedAt" : "2021-03-13T06:21:03Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "2959c2d4-bf6a-4aa7-9257-49b5eff882b8",
        "parentId" : "21d3781a-3f45-4d0c-8b62-6e465f93cd4b",
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "@maropu - then we need to call `streamed.execute()`twice in `defaultJoin()`. I feel it's bit weird and not sure if it can lead to any bug in the future. Normally during execution, we only call `child.execute()` once.",
        "createdAt" : "2021-03-13T06:06:41Z",
        "updatedAt" : "2021-03-13T06:21:30Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      }
    ],
    "commit" : "f0ba910eb308af926992afe08b5ac8f504b2624f",
    "line" : 206,
    "diffHunk" : "@@ -1,1 +340,344 @@   */\n  private def getMatchedBroadcastRowsBitSet(\n      streamRdd: RDD[InternalRow],\n      relation: Broadcast[Array[InternalRow]]): BitSet = {\n    val matchedBuildRows = streamRdd.mapPartitionsInternal { streamedIter =>"
  },
  {
    "id" : "8d5cdfc9-1963-4944-a806-6f49152b821d",
    "prId" : 31821,
    "prUrl" : "https://github.com/apache/spark/pull/31821#pullrequestreview-611865192",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "362fd518-7f7b-4efb-abbc-e39c9d471774",
        "parentId" : null,
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "@dongjoon-hyun - for original left anti join, here's one of code paths to handle it (`condition` is empty and `exists` is false).",
        "createdAt" : "2021-03-15T06:44:42Z",
        "updatedAt" : "2021-03-15T06:44:42Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      }
    ],
    "commit" : "f0ba910eb308af926992afe08b5ac8f504b2624f",
    "line" : 66,
    "diffHunk" : "@@ -1,1 +219,223 @@        // Only need to know whether streamed side is empty or not.\n        val streamExists = !streamed.execute().isEmpty()\n        if (streamExists == exists) {\n          sparkContext.makeRDD(relation.value)\n        } else {"
  },
  {
    "id" : "7aa438e0-ebdd-4633-9253-658c4927e1bc",
    "prId" : 31821,
    "prUrl" : "https://github.com/apache/spark/pull/31821#pullrequestreview-611865561",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4e6bfbf8-f8b6-4612-8d5e-e093ba75c893",
        "parentId" : null,
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "@dongjoon-hyun - for original left anti join, here's the other code path to handle it (`condition` is non-empty and `exists` is false). This is same as original code in `defaultJoin()`. But this PR adds the optimization for empty `condition` case.",
        "createdAt" : "2021-03-15T06:45:36Z",
        "updatedAt" : "2021-03-15T06:45:36Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      }
    ],
    "commit" : "f0ba910eb308af926992afe08b5ac8f504b2624f",
    "line" : 102,
    "diffHunk" : "@@ -1,1 +230,234 @@        val buildRows = relation.value\n        while (i < buildRows.length) {\n          if (matchedBroadcastRows.get(i) == exists) {\n            buf += buildRows(i).copy()\n          }"
  },
  {
    "id" : "a06e0248-4f07-458a-aa10-181b13f46021",
    "prId" : 31821,
    "prUrl" : "https://github.com/apache/spark/pull/31821#pullrequestreview-612648580",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3b6f7a46-b5e7-4ea3-9bca-cfe399bf89e8",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "shall we follow `Dataset.isEmpty` and call `streamed.executeTake(1).isEmpty`?",
        "createdAt" : "2021-03-15T07:48:32Z",
        "updatedAt" : "2021-03-15T07:48:32Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "3c747de8-669a-44ec-be6f-0a62d3502413",
        "parentId" : "3b6f7a46-b5e7-4ea3-9bca-cfe399bf89e8",
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "@cloud-fan - sounds reasonable to me. Created https://github.com/apache/spark/pull/31845 .",
        "createdAt" : "2021-03-15T21:13:21Z",
        "updatedAt" : "2021-03-15T21:13:21Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      }
    ],
    "commit" : "f0ba910eb308af926992afe08b5ac8f504b2624f",
    "line" : 65,
    "diffHunk" : "@@ -1,1 +218,222 @@        // If condition is empty, do not need to read rows from streamed side at all.\n        // Only need to know whether streamed side is empty or not.\n        val streamExists = !streamed.execute().isEmpty()\n        if (streamExists == exists) {\n          sparkContext.makeRDD(relation.value)"
  }
]