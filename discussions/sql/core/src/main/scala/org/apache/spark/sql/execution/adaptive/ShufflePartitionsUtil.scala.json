[
  {
    "id" : "459db4eb-f306-4e12-8649-bed2a80ee472",
    "prId" : 33655,
    "prUrl" : "https://github.com/apache/spark/pull/33655#pullrequestreview-723532662",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4eb25cc3-e751-4e46-b80a-dc288dc33e46",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "a small cleanup",
        "createdAt" : "2021-08-05T15:57:02Z",
        "updatedAt" : "2021-08-05T15:57:02Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "eeeff3ae6bb62eedeb09011cc99514d240a8b7d0",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +58,62 @@    val totalPostShuffleInputSize = mapOutputStatistics.flatMap(_.map(_.bytesByPartitionId.sum)).sum\n    val maxTargetSize = math.ceil(totalPostShuffleInputSize / minNumPartitions.toDouble).toLong\n    // It's meaningless to make target size smaller than minPartitionSize.\n    val targetSize = maxTargetSize.min(advisoryTargetSize).max(minPartitionSize)\n"
  }
]