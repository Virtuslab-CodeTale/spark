[
  {
    "id" : "e6366611-8dd1-461f-8171-e767b09caec5",
    "prId" : 28904,
    "prUrl" : "https://github.com/apache/spark/pull/28904#pullrequestreview-435545836",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "86f4edb9-e895-48d7-b230-37e53827890a",
        "parentId" : null,
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "This would help when we introduce a new condition on exclusion of entries.",
        "createdAt" : "2020-06-23T08:26:04Z",
        "updatedAt" : "2020-08-18T04:54:59Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      }
    ],
    "commit" : "e16ebe4e530d3c44bb0ba39981c4ec2287c3589e",
    "line" : 152,
    "diffHunk" : "@@ -1,1 +259,263 @@          val logs =\n            getAllValidBatches(latestId, compactInterval).flatMap { id =>\n              filterInBatch(id)(shouldRetain).getOrElse {\n                throw new IllegalStateException(\n                  s\"${batchIdToPath(id)} doesn't exist \" +"
  },
  {
    "id" : "ce15a7c6-0dc9-40c2-8bcb-01a236339161",
    "prId" : 28904,
    "prUrl" : "https://github.com/apache/spark/pull/28904#pullrequestreview-435545836",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dd30d34f-f2c4-48da-ab53-9b8b75c7532a",
        "parentId" : null,
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "This new approach is to avoid reading the next compact file log, which materializes all entries into the file. It should be extreme case, so it's also OK to keep this as it is if someone strongly think the previous one is better.",
        "createdAt" : "2020-06-23T08:26:58Z",
        "updatedAt" : "2020-08-18T04:54:59Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      }
    ],
    "commit" : "e16ebe4e530d3c44bb0ba39981c4ec2287c3589e",
    "line" : 168,
    "diffHunk" : "@@ -1,1 +272,276 @@            // deleting old files. If so, let's try the next compaction batch and we should find it.\n            // Otherwise, this is a real IO issue and we should throw it.\n            val expectedMinLatestId = nextCompactionBatchId(latestId, compactInterval)\n            latestId = super.getLatestBatchId().getOrElse(-1)\n            if (latestId < expectedMinLatestId) {"
  },
  {
    "id" : "92585d44-49a7-413f-b77b-68180d48e2f8",
    "prId" : 28904,
    "prUrl" : "https://github.com/apache/spark/pull/28904#pullrequestreview-468955930",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fe5b8938-b71b-4712-89af-7ef4474223d4",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Shall we mention `IllegalStateException` explicitly because the caller should know what kind of exception it is? Or, you may want to mention `IllegalStateException` at line 182 in a similar way to `FileNotFoundException`.",
        "createdAt" : "2020-08-10T23:51:03Z",
        "updatedAt" : "2020-08-18T04:54:59Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "d4c06ae0-9451-4bf7-8d79-6fefaea40a94",
        "parentId" : "fe5b8938-b71b-4712-89af-7ef4474223d4",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "`IllegalStateException` is not the only exception this method can throw. It can also throw `IOException` as it deals with file, and also depends on `deserializeEntry`.\r\n\r\nI think the type of exception won't affect what caller should do. Caller may want to deal with FNFE specifically, but still do the same for others, and even for FNFE it's safer to follow the guide on NOTE.",
        "createdAt" : "2020-08-18T02:51:50Z",
        "updatedAt" : "2020-08-18T04:54:59Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      }
    ],
    "commit" : "e16ebe4e530d3c44bb0ba39981c4ec2287c3589e",
    "line" : 70,
    "diffHunk" : "@@ -1,1 +187,191 @@   * FileNotFoundException if the metadata log file doesn't exist.\n   *\n   * NOTE: This doesn't fail early on corruption. The caller should handle the exception\n   * properly and make sure the logic is not affected by failing in the middle.\n   */"
  },
  {
    "id" : "1abdd6fe-b71c-408f-9d23-d9e504f11522",
    "prId" : 28904,
    "prUrl" : "https://github.com/apache/spark/pull/28904#pullrequestreview-468959219",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "333bf581-dd14-4846-ab3e-1e474c02484c",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "ditto. Shall we mention `IllegalStateException`?",
        "createdAt" : "2020-08-10T23:52:48Z",
        "updatedAt" : "2020-08-18T04:54:59Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "8d6101e3-7711-40de-8617-f20c09d8613d",
        "parentId" : "333bf581-dd14-4846-ab3e-1e474c02484c",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "ditto. Would we want to mention all possible exceptions per method? `IllegalStateException` is the explicit one, but there're also many possible exceptions, starting from `IOException`.",
        "createdAt" : "2020-08-18T03:02:45Z",
        "updatedAt" : "2020-08-18T04:54:59Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      }
    ],
    "commit" : "e16ebe4e530d3c44bb0ba39981c4ec2287c3589e",
    "line" : 76,
    "diffHunk" : "@@ -1,1 +193,197 @@\n  /**\n   * Apply filter on all entries in the specific batch.\n   */\n  def filterInBatch(batchId: Long)(predicate: T => Boolean): Option[Array[T]] = {"
  },
  {
    "id" : "a4a14f53-f444-4f17-9bdb-c08d95a008b2",
    "prId" : 28904,
    "prUrl" : "https://github.com/apache/spark/pull/28904#pullrequestreview-468958465",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e7d3dd40-5619-4d10-a835-be9aa2d7fcf4",
        "parentId" : null,
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "If the caller does not handle the exception properly, what is the consequence? Do we have a test case to cover it?",
        "createdAt" : "2020-08-11T03:20:27Z",
        "updatedAt" : "2020-08-18T04:54:59Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      },
      {
        "id" : "45895b70-2a6c-4e99-a6d9-d45c3b7c4e07",
        "parentId" : "e7d3dd40-5619-4d10-a835-be9aa2d7fcf4",
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "How to ensure all the callers handle it properly? Do we need to introduce a test to cover it?",
        "createdAt" : "2020-08-11T03:28:30Z",
        "updatedAt" : "2020-08-18T04:54:59Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      },
      {
        "id" : "6cfcd700-409d-43d9-aac1-7c39da66d24a",
        "parentId" : "e7d3dd40-5619-4d10-a835-be9aa2d7fcf4",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "I'm not sure how this class ensures callers are following the guide. Did you mean we'd like to test this behavior with derived classes (file stream source/sink) log? Or we'd like to test this behavior with test-purpose implementation of CompactibleFileStreamLog?",
        "createdAt" : "2020-08-18T03:00:11Z",
        "updatedAt" : "2020-08-18T04:54:59Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      }
    ],
    "commit" : "e16ebe4e530d3c44bb0ba39981c4ec2287c3589e",
    "line" : 71,
    "diffHunk" : "@@ -1,1 +188,192 @@   *\n   * NOTE: This doesn't fail early on corruption. The caller should handle the exception\n   * properly and make sure the logic is not affected by failing in the middle.\n   */\n  def foreachInBatch(batchId: Long)(fn: T => Unit): Unit = applyFnInBatch(batchId)(_.foreach(fn))"
  },
  {
    "id" : "7a7e888e-2a2e-4af5-962b-8593fff23645",
    "prId" : 27557,
    "prUrl" : "https://github.com/apache/spark/pull/27557#pullrequestreview-398243851",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d8df83c4-ac61-461f-9fd9-7ad94a218d92",
        "parentId" : null,
        "authorId" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "body" : "nit: seems these two logs could combine into one? ",
        "createdAt" : "2020-02-21T12:40:00Z",
        "updatedAt" : "2020-04-23T03:16:17Z",
        "lastEditedBy" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "tags" : [
        ]
      },
      {
        "id" : "4691954b-8ce9-4075-aedd-66f8b3a8de28",
        "parentId" : "d8df83c4-ac61-461f-9fd9-7ad94a218d92",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "It was actually one line and I split it because I felt it's a bit long to have it one-liner, as well as message of second line is only for WARN level.\r\nBut if it helps to correlate I would do. Let's have more voices on this.",
        "createdAt" : "2020-02-21T13:42:44Z",
        "updatedAt" : "2020-04-23T03:16:17Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      },
      {
        "id" : "0ad61ab3-b0e2-4d9b-bee2-faa94a550399",
        "parentId" : "d8df83c4-ac61-461f-9fd9-7ad94a218d92",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "two logs are fine I guess.",
        "createdAt" : "2020-04-22T14:22:50Z",
        "updatedAt" : "2020-04-23T03:16:17Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "648f0dc2b5b2b53e2c62641ea0da0e04a5ffec0b",
    "line" : 40,
    "diffHunk" : "@@ -1,1 +198,202 @@    val elapsedMs = loadElapsedMs + writeElapsedMs\n    if (elapsedMs >= COMPACT_LATENCY_WARN_THRESHOLD_MS) {\n      logWarning(s\"Compacting took $elapsedMs ms (load: $loadElapsedMs ms,\" +\n        s\" write: $writeElapsedMs ms) for compact batch $batchId\")\n      logWarning(s\"Loaded ${allLogs.size} entries (estimated ${SizeEstimator.estimate(allLogs)} \" +"
  },
  {
    "id" : "bf5a005f-fdf2-4b98-9461-878b6bce9c78",
    "prId" : 27557,
    "prUrl" : "https://github.com/apache/spark/pull/27557#pullrequestreview-398722570",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "62c6ab4e-d91c-4b03-a888-4d08866d8fb9",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Was this value from the practice? I guess it's fine.",
        "createdAt" : "2020-04-22T14:23:42Z",
        "updatedAt" : "2020-04-23T03:16:17Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "d4030538-bd72-4cc4-812e-c9ca6169a81a",
        "parentId" : "62c6ab4e-d91c-4b03-a888-4d08866d8fb9",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "Yeah it's a heuristic - I think a batch spending more than 2 seconds only for compacting metadata should be noticed to the end users, as the latency here is opaque to end user if we don't log it and they will be questioning.",
        "createdAt" : "2020-04-23T02:48:21Z",
        "updatedAt" : "2020-04-23T03:16:17Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      }
    ],
    "commit" : "648f0dc2b5b2b53e2c62641ea0da0e04a5ffec0b",
    "line" : 57,
    "diffHunk" : "@@ -1,1 +289,293 @@object CompactibleFileStreamLog {\n  val COMPACT_FILE_SUFFIX = \".compact\"\n  val COMPACT_LATENCY_WARN_THRESHOLD_MS = 2000\n\n  def getBatchIdFromFileName(fileName: String): Long = {"
  }
]