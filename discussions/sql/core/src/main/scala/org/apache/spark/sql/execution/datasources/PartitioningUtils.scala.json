[
  {
    "id" : "34b5a095-684b-4958-8eb9-5c2b7ad6d6d8",
    "prId" : 33291,
    "prUrl" : "https://github.com/apache/spark/pull/33291#pullrequestreview-704703036",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "70c8ee9b-573b-4579-9e5c-d68eaa3b7e62",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Can we use the same code path with the one when it's non-empty?",
        "createdAt" : "2021-07-12T05:48:22Z",
        "updatedAt" : "2021-07-12T05:48:22Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "585fad21-828d-49c5-bb56-68d2b8a26040",
        "parentId" : "70c8ee9b-573b-4579-9e5c-d68eaa3b7e62",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "cc @MaxGekk FYI",
        "createdAt" : "2021-07-12T05:48:29Z",
        "updatedAt" : "2021-07-12T05:48:29Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "04cccf02-a460-4795-a0bc-4b6ff8703d07",
        "parentId" : "70c8ee9b-573b-4579-9e5c-d68eaa3b7e62",
        "authorId" : "87a71d79-d4d2-4f2c-8e9a-be56cf39b035",
        "body" : "> Can we use the same code path with the one when it's non-empty?\r\n\r\nI think no. The below code separate code path for update partition metadata of updated partition (non-empty) and empty\r\n\r\nhttps://github.com/apache/spark/blob/badb0393d46d7aef90710e51e233fb5077977423/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/InsertIntoHadoopFsRelationCommand.scala#L189-L198",
        "createdAt" : "2021-07-12T07:28:20Z",
        "updatedAt" : "2021-07-12T07:28:20Z",
        "lastEditedBy" : "87a71d79-d4d2-4f2c-8e9a-be56cf39b035",
        "tags" : [
        ]
      },
      {
        "id" : "3f0447c3-41b2-40ef-bbab-7b66e1e29520",
        "parentId" : "70c8ee9b-573b-4579-9e5c-d68eaa3b7e62",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Can you factor out PartitioningUtils.parsePartitions and share the same casting logic?",
        "createdAt" : "2021-07-12T09:45:30Z",
        "updatedAt" : "2021-07-12T09:45:30Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "34feb2f0-13a8-4f0b-8d57-5219d4c2e174",
        "parentId" : "70c8ee9b-573b-4579-9e5c-d68eaa3b7e62",
        "authorId" : "87a71d79-d4d2-4f2c-8e9a-be56cf39b035",
        "body" : "PartitioningUtils.parsePartitions use castPartValueToDesiredType to cast multiple type of partition. I think in this issue, we only need cast number type (or remove leading zeros), the other types will be handled by org.apache.spark.sql.catalyst.expressions.CastBase",
        "createdAt" : "2021-07-13T03:02:16Z",
        "updatedAt" : "2021-07-13T03:02:17Z",
        "lastEditedBy" : "87a71d79-d4d2-4f2c-8e9a-be56cf39b035",
        "tags" : [
        ]
      }
    ],
    "commit" : "620917d11554929d85c0060a940b38877441106a",
    "line" : 2,
    "diffHunk" : "@@ -1,1 +350,354 @@   * This is the inverse of parsePathFragment().\n   */\n  def getPathFragment(spec: TablePartitionSpec, partitionSchema: StructType): String = {\n    partitionSchema.map { field =>\n      escapePathName(field.name) + \"=\" +"
  },
  {
    "id" : "7ee3e452-452f-4184-b9cf-68c17d9bbbb0",
    "prId" : 31549,
    "prUrl" : "https://github.com/apache/spark/pull/31549#pullrequestreview-593509736",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "95512077-1f22-4aa3-9269-ef8e6d411579",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "maybe not related to this PR. When shall we call `unescapePathName`?",
        "createdAt" : "2021-02-18T13:07:51Z",
        "updatedAt" : "2021-02-19T05:40:08Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "eb6f09e5-8f96-4380-9bc4-dae873afe757",
        "parentId" : "95512077-1f22-4aa3-9269-ef8e6d411579",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Every time when we get a value from the file system as a part of file name. Since you added the method in https://github.com/apache/spark/pull/15797/files#diff-74a21c0670bb349140a57b99a473d036060a6bcd20d22674346cc77213cebac1R76, you should know better ;-)",
        "createdAt" : "2021-02-18T18:11:13Z",
        "updatedAt" : "2021-02-19T05:40:08Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "14cb5ab4429918a806c3c4dfcaa74b3d0bed5eaa",
    "line" : 229,
    "diffHunk" : "@@ -1,1 +524,528 @@    case TimestampType =>\n      Try {\n        Cast(Literal(unescapePathName(value)), TimestampType, Some(zoneId.getId)).eval()\n      }.getOrElse {\n        Cast(Cast(Literal(value), DateType, Some(zoneId.getId)), TimestampType).eval()"
  }
]