[
  {
    "id" : "b949d201-2116-4c93-b1c8-707a3df72404",
    "prId" : 31356,
    "prUrl" : "https://github.com/apache/spark/pull/31356#pullrequestreview-580939464",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b2ff1bf4-c6cd-4b89-b146-505512e4fa0a",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Is there any better way to get the last element in this case than iterate over all of them? maybe not given the unusual nature of the dat backing ExternalAppendOnlyUnsafeRowArray",
        "createdAt" : "2021-02-01T14:38:03Z",
        "updatedAt" : "2021-02-01T14:38:03Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "9a0381a8-596e-4723-a103-3c83b15a3603",
        "parentId" : "b2ff1bf4-c6cd-4b89-b146-505512e4fa0a",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "`ExternalAppendOnlyUnsafeRowArray` cannot get the last element directly.",
        "createdAt" : "2021-02-02T02:38:28Z",
        "updatedAt" : "2021-02-02T02:38:28Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "a10115c30472b3ec9ecd2e1499afb1fe0be7fe26",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +505,509 @@        var lastRow = EmptyRow\n        while (iterator.hasNext) {\n          lastRow = iterator.next()\n        }\n        if (lastRow != EmptyRow) {"
  },
  {
    "id" : "4f3736dd-ceaa-440c-a953-35ce551570c8",
    "prId" : 31325,
    "prUrl" : "https://github.com/apache/spark/pull/31325#pullrequestreview-576052546",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6f8506c1-4cd9-492b-a898-6e0d7feeb924",
        "parentId" : null,
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "nit: maybe just call `resetStates` at the begging and use `input.length` to make the intention clear that `prepare` always reset the states first?",
        "createdAt" : "2021-01-25T21:09:54Z",
        "updatedAt" : "2021-01-25T22:08:17Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      },
      {
        "id" : "d6fbb8f2-13b9-41d1-a5b4-f95de129d9e5",
        "parentId" : "6f8506c1-4cd9-492b-a898-6e0d7feeb924",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "+1 for @imback82 's suggestion.",
        "createdAt" : "2021-01-26T01:53:16Z",
        "updatedAt" : "2021-01-26T01:53:16Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "48e7e092-4b47-4efd-939c-49d8c1bf66a6",
        "parentId" : "6f8506c1-4cd9-492b-a898-6e0d7feeb924",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I was trying to avoid calling `input.generateIterator()`, as it was not called before when `offset > rows.length`, and it may cause perf regression as the name `generateIterator` sounds expensive.",
        "createdAt" : "2021-01-26T05:55:47Z",
        "updatedAt" : "2021-01-26T05:55:47Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "163b95d1-e3e5-430a-8262-36a020ad51b3",
        "parentId" : "6f8506c1-4cd9-492b-a898-6e0d7feeb924",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "ah ok, thanks for the explanation.",
        "createdAt" : "2021-01-26T06:20:13Z",
        "updatedAt" : "2021-01-26T06:20:13Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "a3fb8373299a81aa34a9f1493332f1cbcb0e1a9f",
    "line" : 48,
    "diffHunk" : "@@ -1,1 +310,314 @@\n  override def prepare(rows: ExternalAppendOnlyUnsafeRowArray): Unit = {\n    if (offset > rows.length) {\n      fillDefaultValue(EmptyRow)\n    } else {"
  },
  {
    "id" : "d4e715b7-8b8a-490f-8b68-94d9d7e45718",
    "prId" : 31325,
    "prUrl" : "https://github.com/apache/spark/pull/31325#pullrequestreview-576288600",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b89938c0-3a74-408a-96b4-c19f50379646",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "Yeah!",
        "createdAt" : "2021-01-26T12:11:52Z",
        "updatedAt" : "2021-01-26T12:11:53Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "a3fb8373299a81aa34a9f1493332f1cbcb0e1a9f",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +148,152 @@    skippedNonNullCount = 0\n    nextSelectedRow = EmptyRow\n  }\n\n  /** Create the projection to determine whether input is null. */"
  },
  {
    "id" : "45cda97f-fe80-46c7-801e-80d68110a60c",
    "prId" : 31178,
    "prUrl" : "https://github.com/apache/spark/pull/31178#pullrequestreview-572374497",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2a62567e-e4f2-46d1-a9ee-cef0dc0a9b8f",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "In this class, `write` is empty, so `selectedRow` can be a local variable\r\n```\r\nvar selectedRow: UnsafeRow = null\r\nwhile (inputIndex < offset) {\r\n  selectedRow = WindowFunctionFrame.getNextOrNull(inputIterator)\r\n  inputIndex += 1\r\n}\r\nprojection(selectedRow)\r\n```",
        "createdAt" : "2021-01-20T15:26:03Z",
        "updatedAt" : "2021-01-20T15:58:23Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "93dabcdf-75a9-4efd-9fa4-129e99c77cf4",
        "parentId" : "2a62567e-e4f2-46d1-a9ee-cef0dc0a9b8f",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "OK",
        "createdAt" : "2021-01-20T15:59:32Z",
        "updatedAt" : "2021-01-20T15:59:32Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "bf17bae5e8d3f7c0eb1c17d90b75618d60553d4d",
    "line" : 92,
    "diffHunk" : "@@ -1,1 +318,322 @@        var selectedRow: UnsafeRow = null\n        while (inputIndex < offset) {\n          selectedRow = WindowFunctionFrame.getNextOrNull(inputIterator)\n          inputIndex += 1\n        }"
  },
  {
    "id" : "441c4fcf-4c6c-47dd-bb81-51e6c3111abe",
    "prId" : 30387,
    "prUrl" : "https://github.com/apache/spark/pull/30387#pullrequestreview-554251293",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "399304fa-1974-4905-9390-4bc543689bcb",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "what's the behavior if `offset == 0`?",
        "createdAt" : "2020-12-15T15:58:16Z",
        "updatedAt" : "2020-12-24T06:06:51Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "9d247508-964c-4136-8b83-f91324587943",
        "parentId" : "399304fa-1974-4905-9390-4bc543689bcb",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "Return current row itself. ",
        "createdAt" : "2020-12-17T03:18:48Z",
        "updatedAt" : "2020-12-24T06:06:51Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "4f183190df6a324364b5f895acaacbfebc16b7ca",
    "line" : 146,
    "diffHunk" : "@@ -1,1 +261,265 @@        skippedNonNullCount += 1\n      }\n  } else {\n    (current: InternalRow) =>\n      if (inputIndex >= 0 && inputIndex < input.length) {"
  },
  {
    "id" : "50d09a9c-79a5-4221-90c3-7dd0f043ac48",
    "prId" : 29800,
    "prUrl" : "https://github.com/apache/spark/pull/29800#pullrequestreview-505336974",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7ba6c135-30c2-41bf-a19d-45bef6319090",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "why can't it support ignoreNulls?",
        "createdAt" : "2020-10-07T07:27:09Z",
        "updatedAt" : "2020-10-28T02:15:58Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "b0abf1e0-d662-490d-8f8c-aadd8070243e",
        "parentId" : "7ba6c135-30c2-41bf-a19d-45bef6319090",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "Because the current `WindowFunctionFrame` is for data row by row.",
        "createdAt" : "2020-10-09T03:33:44Z",
        "updatedAt" : "2020-10-28T02:15:58Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "1c0e82ba0ab95af7871b4b16f8be1e0662d49c78",
    "line" : 136,
    "diffHunk" : "@@ -1,1 +228,232 @@ * (starting from 1) equal to or greater than offset in the window partition.\n */\nclass UnboundedPrecedingOffsetWindowFunctionFrame(\n    target: InternalRow,\n    ordinal: Int,"
  },
  {
    "id" : "6f923e24-2a68-43a5-b306-dc3aa8a088e9",
    "prId" : 29800,
    "prUrl" : "https://github.com/apache/spark/pull/29800#pullrequestreview-517430277",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "06afbcf1-bac2-4553-a972-07dff22bfdd7",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "The logic here is a bit weird. Why do we iterate the first `offset - 1` records in `super.prepare` method, and then accesee the `offset`th record here? Can we combine them?",
        "createdAt" : "2020-10-26T12:22:53Z",
        "updatedAt" : "2020-10-28T02:15:58Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "126f136b-0291-43af-aab9-d787e9cde4b0",
        "parentId" : "06afbcf1-bac2-4553-a972-07dff22bfdd7",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "OK",
        "createdAt" : "2020-10-27T08:02:48Z",
        "updatedAt" : "2020-10-28T02:15:58Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "1c0e82ba0ab95af7871b4b16f8be1e0662d49c78",
    "line" : 115,
    "diffHunk" : "@@ -1,1 +207,211 @@        inputIndex += 1\n      }\n      val r = WindowFunctionFrame.getNextOrNull(inputIterator)\n      projection(r)\n    }"
  },
  {
    "id" : "770b013e-c06f-4767-8c72-b127f8b2ab0f",
    "prId" : 29800,
    "prUrl" : "https://github.com/apache/spark/pull/29800#pullrequestreview-517314504",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a84e2ceb-79e5-4906-890e-c5f36a019d2c",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "here we reset the `inputIndex`. Does it make sense for nth_value?",
        "createdAt" : "2020-10-26T12:28:50Z",
        "updatedAt" : "2020-10-28T02:15:58Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "2d9a32b5-a12f-480c-bc1d-a10e56d24fc0",
        "parentId" : "a84e2ceb-79e5-4906-890e-c5f36a019d2c",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "`nth_value` not use `FrameLessOffsetWindowFunctionFrame`.",
        "createdAt" : "2020-10-27T03:00:18Z",
        "updatedAt" : "2020-10-28T02:15:58Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "1c0e82ba0ab95af7871b4b16f8be1e0662d49c78",
    "line" : 78,
    "diffHunk" : "@@ -1,1 +172,176 @@      fillDefaultValue(current)\n    }\n    inputIndex += 1\n  }\n}"
  }
]