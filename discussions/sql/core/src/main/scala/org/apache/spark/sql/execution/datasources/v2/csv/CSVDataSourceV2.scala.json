[
  {
    "id" : "6b3bc76a-e690-46b1-87b7-528b4ae18ee8",
    "prId" : 25651,
    "prUrl" : "https://github.com/apache/spark/pull/25651#pullrequestreview-301908238",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c0427d8c-99e3-44a6-8ae4-495f6f4a4321",
        "parentId" : null,
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "`partitions` is ignored in all of these implementations. That looks like a bug to me.\r\n\r\nI can understand not wanting to support partitioning that is passed in right away. In that case, this should get the partitioning of the `CSVTable` and check it against the incoming partitioning here and throw an exception if it doesn't match.",
        "createdAt" : "2019-09-25T20:56:54Z",
        "updatedAt" : "2019-10-21T16:55:34Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "108220e8-939f-41f7-b7b1-7e0dc77116fa",
        "parentId" : "c0427d8c-99e3-44a6-8ae4-495f6f4a4321",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "We shouldn't make this PR bigger and supports partitioning in file source. For now let's explicitly say that file source doesn't support user-specified partitioning: https://github.com/apache/spark/pull/25651/files#diff-3d5fde6e98a2856ba1b00ce6f172c4a8R72",
        "createdAt" : "2019-10-15T13:31:01Z",
        "updatedAt" : "2019-10-21T16:55:34Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "cfbe0a75f80e88d4a5831785d05fb9b708c5ada3",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +41,45 @@    val paths = getPaths(properties)\n    val tableName = getTableName(paths)\n    CSVTable(tableName, sparkSession, properties, paths, Some(schema), fallbackFileFormat)\n  }\n}"
  }
]