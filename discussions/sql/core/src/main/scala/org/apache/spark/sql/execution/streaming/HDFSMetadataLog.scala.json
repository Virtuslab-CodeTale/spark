[
  {
    "id" : "73812a0a-b081-4450-bcbb-2ae0db40e309",
    "prId" : 31495,
    "prUrl" : "https://github.com/apache/spark/pull/31495#pullrequestreview-584935673",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "35b251b2-f3aa-42c9-98e6-75e6a2901e0b",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Usually, `possibleTargetBatchIds.length` should be 1?",
        "createdAt" : "2021-02-06T13:19:16Z",
        "updatedAt" : "2021-02-09T00:33:26Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "e25e66aa-f508-4a67-a140-0cf19c6527b8",
        "parentId" : "35b251b2-f3aa-42c9-98e6-75e6a2901e0b",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "Yes usually the value will be 1, once purge is executed once via listing. I just don't set it to 1 because I don't want to make the logic be tight to MicroBatchExecution/ContinuousExecution. (Someone outside of Spark may leverage this as well.)\r\n\r\nThat's a magic number based on heuristic so I don't mind too much about the value (just should be greater than 1), but considering the cost of list vs exist, the ideal threshold wouldn't be just 1.",
        "createdAt" : "2021-02-07T02:54:52Z",
        "updatedAt" : "2021-02-09T00:33:26Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      }
    ],
    "commit" : "03801f726a1443736dd7e404ba6a6ac1f8740c10",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +247,251 @@  override def purge(thresholdBatchId: Long): Unit = {\n    val possibleTargetBatchIds = (lastPurgedBatchId + 1 until thresholdBatchId)\n    if (possibleTargetBatchIds.length <= 3) {\n      // avoid using list if we only need to purge at most 3 elements\n      possibleTargetBatchIds.foreach { batchId =>"
  },
  {
    "id" : "94c55e95-b253-4aa1-9b7c-e8261c453ef1",
    "prId" : 28904,
    "prUrl" : "https://github.com/apache/spark/pull/28904#pullrequestreview-440007750",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f2da08c6-3764-4d34-81a0-d85b65de9417",
        "parentId" : null,
        "authorId" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "body" : "nit: duplicated code with `get`.",
        "createdAt" : "2020-06-30T15:00:24Z",
        "updatedAt" : "2020-08-18T04:54:59Z",
        "lastEditedBy" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "tags" : [
        ]
      }
    ],
    "commit" : "e16ebe4e530d3c44bb0ba39981c4ec2287c3589e",
    "line" : 50,
    "diffHunk" : "@@ -1,1 +138,142 @@   * properly and make sure the logic is not affected by failing in the middle.\n   */\n  def applyFnToBatchByStream[RET](batchId: Long)(fn: InputStream => RET): RET = {\n    val batchMetadataFile = batchIdToPath(batchId)\n    if (fileManager.exists(batchMetadataFile)) {"
  },
  {
    "id" : "99d79a11-14a3-4f1b-99e6-fe4701e92a50",
    "prId" : 28904,
    "prUrl" : "https://github.com/apache/spark/pull/28904#pullrequestreview-440007750",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "aefef996-3bcf-4942-b500-2d613fa1b610",
        "parentId" : null,
        "authorId" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "body" : "ditto, duplicate code with writeBatchToFile",
        "createdAt" : "2020-06-30T15:01:40Z",
        "updatedAt" : "2020-08-18T04:54:59Z",
        "lastEditedBy" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "tags" : [
        ]
      }
    ],
    "commit" : "e16ebe4e530d3c44bb0ba39981c4ec2287c3589e",
    "line" : 83,
    "diffHunk" : "@@ -1,1 +170,174 @@   * valid behavior, we still need to prevent it from destroying the files.\n   */\n  def addNewBatchByStream(batchId: Long)(fn: OutputStream => Unit): Boolean = {\n    get(batchId).map(_ => false).getOrElse {\n      // Only write metadata when the batch has not yet been written"
  },
  {
    "id" : "119f1917-f7d5-4cd4-823a-ced8ee9963f5",
    "prId" : 27664,
    "prUrl" : "https://github.com/apache/spark/pull/27664#pullrequestreview-416167107",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "477e7835-b5db-46cd-b087-e6c8d4789975",
        "parentId" : null,
        "authorId" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "body" : "nit but maybe not to involve a new behavior change here?",
        "createdAt" : "2020-05-13T06:08:38Z",
        "updatedAt" : "2020-05-22T15:48:53Z",
        "lastEditedBy" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "tags" : [
        ]
      },
      {
        "id" : "0f5f84d2-0996-402b-8f48-64b0fb4320a2",
        "parentId" : "477e7835-b5db-46cd-b087-e6c8d4789975",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "This is a part of the change in #25965 which should be dealt with. It shouldn't give the content with batch ID which is less than the latest batch ID - it should rather fail.",
        "createdAt" : "2020-05-13T06:17:21Z",
        "updatedAt" : "2020-05-22T15:48:53Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      },
      {
        "id" : "4c416e6e-e6b0-459e-bb92-6b40e4ef2d04",
        "parentId" : "477e7835-b5db-46cd-b087-e6c8d4789975",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "That said, you might have interesting proposals on my old PRs, https://github.com/apache/spark/pulls/HeartSaVioR",
        "createdAt" : "2020-05-13T06:35:51Z",
        "updatedAt" : "2020-05-22T15:48:53Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      },
      {
        "id" : "ac6bac82-3844-488f-962f-c896458d9474",
        "parentId" : "477e7835-b5db-46cd-b087-e6c8d4789975",
        "authorId" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "body" : "Thanks for the reference, will take a look later.",
        "createdAt" : "2020-05-14T11:25:47Z",
        "updatedAt" : "2020-05-22T15:48:53Z",
        "lastEditedBy" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "tags" : [
        ]
      },
      {
        "id" : "85ee202d-2a64-427e-b01d-eded5cffcb74",
        "parentId" : "477e7835-b5db-46cd-b087-e6c8d4789975",
        "authorId" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "body" : "Thanks for reference #25965, LGTM to this change.\r\nI personally think the comment in https://github.com/apache/spark/pull/25965/files#diff-aaeb546880508bb771df502318c40a99R183 is clearer. Either way is fine though.",
        "createdAt" : "2020-05-21T13:47:54Z",
        "updatedAt" : "2020-05-22T15:48:53Z",
        "lastEditedBy" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "tags" : [
        ]
      },
      {
        "id" : "eaa59775-624b-4749-8f22-4ceddfb0fa2e",
        "parentId" : "477e7835-b5db-46cd-b087-e6c8d4789975",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "Just pulled the comment here. Either this or #25965 will have to resolve merge conflict but wanted to be sure the code comment is clear in any way.",
        "createdAt" : "2020-05-21T13:57:57Z",
        "updatedAt" : "2020-05-22T15:48:53Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      }
    ],
    "commit" : "4a5679e800a10a74a78236c5be9814e1a61c6ec7",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +199,203 @@        // If we find the last batch file, we must read that file, other than failing back to\n        // old batches.\n        throw new IllegalStateException(s\"failed to read log file for batch $batchId\")\n      }\n      (batchId, content)"
  }
]