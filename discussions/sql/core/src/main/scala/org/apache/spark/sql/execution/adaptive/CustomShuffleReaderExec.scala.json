[
  {
    "id" : "eaec278f-9c9d-4557-b55b-24d018272b55",
    "prId" : 33431,
    "prUrl" : "https://github.com/apache/spark/pull/33431#pullrequestreview-710552127",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "86db32a5-6e77-4d01-bafb-4f40c3e7dc5c",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "nit but let's use getClass or something next time",
        "createdAt" : "2021-07-20T13:04:07Z",
        "updatedAt" : "2021-07-20T13:04:08Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "26bb39aea4d606fbe52d09ce51cc6b62fa775e6f",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +41,45 @@    child: SparkPlan,\n    partitionSpecs: Seq[ShufflePartitionSpec]) extends UnaryExecNode {\n  assert(partitionSpecs.nonEmpty, \"CustomShuffleReaderExec requires at least one partition\")\n\n  // If this reader is to read shuffle files locally, then all partition specs should be"
  },
  {
    "id" : "f650c3fe-a93a-4501-b615-d37a2154819b",
    "prId" : 33342,
    "prUrl" : "https://github.com/apache/spark/pull/33342#pullrequestreview-706037557",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "55b3f49e-b5eb-406d-ab3d-19100796932b",
        "parentId" : null,
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "it should be more clearer than `s.startReducerIndex + 1 != s.endReducerIndex`",
        "createdAt" : "2021-07-14T09:10:58Z",
        "updatedAt" : "2021-07-14T09:10:58Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "464b3d34ef6fc29807d7cbd31e6368be1a100f96",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +94,98 @@    partitionSpecs.exists {\n      // shuffle from empty RDD\n      case CoalescedPartitionSpec(0, 0, _) => true\n      case s: CoalescedPartitionSpec => s.endReducerIndex - s.startReducerIndex > 1\n      case _ => false"
  },
  {
    "id" : "e8a6ad16-7465-46f0-b613-5d85a4f86d4e",
    "prId" : 32872,
    "prUrl" : "https://github.com/apache/spark/pull/32872#pullrequestreview-706035870",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fe625ed9-109a-473e-bb2b-55211fe04af2",
        "parentId" : null,
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "I prefer use `s.startReducerIndex + 1 != s.endReducerIndex` since we have a special case `CoalescedPartitionSpec (0, 0, 0)`",
        "createdAt" : "2021-07-13T01:14:03Z",
        "updatedAt" : "2021-07-13T01:14:03Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      },
      {
        "id" : "93757cb1-f200-4ac4-8af0-4d7cfd38aa2a",
        "parentId" : "fe625ed9-109a-473e-bb2b-55211fe04af2",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "how can this happen?",
        "createdAt" : "2021-07-13T12:37:32Z",
        "updatedAt" : "2021-07-13T12:37:32Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "e26167ea-2519-4195-869d-cafd935b0ceb",
        "parentId" : "fe625ed9-109a-473e-bb2b-55211fe04af2",
        "authorId" : "9acf210d-4935-4e03-8384-d944eb558b45",
        "body" : "The intent of this PR is to have`hasCoalesedPartitions` only return true if some partitions were combined - to avoid reporting \"coalesced\" when partition spec looks something like `CoalescePartitionSpec(0, 1), CoalescePartitionSpec(1, 2)`\r\nEven if `CoalescePartitionSpec(0, 0, 0)` is possible, it's not combining anything.",
        "createdAt" : "2021-07-13T18:20:41Z",
        "updatedAt" : "2021-07-13T18:21:23Z",
        "lastEditedBy" : "9acf210d-4935-4e03-8384-d944eb558b45",
        "tags" : [
        ]
      },
      {
        "id" : "e52e455a-1d27-460b-bc80-3616d135782c",
        "parentId" : "fe625ed9-109a-473e-bb2b-55211fe04af2",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "We coalesce all partitions to an empty partition if the input RDD is empty\r\n```\r\n// If all input RDDs have 0 partition, we create an empty partition for every shuffle reader.\r\nif (validMetrics.isEmpty) {\r\n  return Seq.fill(numShuffles)(Seq(CoalescedPartitionSpec(0, 0, 0)))\r\n}\r\n```",
        "createdAt" : "2021-07-14T01:27:39Z",
        "updatedAt" : "2021-07-14T01:27:40Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      },
      {
        "id" : "855ea8c3-1a89-4646-9497-2f1823edbf94",
        "parentId" : "fe625ed9-109a-473e-bb2b-55211fe04af2",
        "authorId" : "9acf210d-4935-4e03-8384-d944eb558b45",
        "body" : "If you  started with no partitions, you are not coalescing, i.e. you are not combining any partitions.\r\n",
        "createdAt" : "2021-07-14T02:25:58Z",
        "updatedAt" : "2021-07-14T02:25:58Z",
        "lastEditedBy" : "9acf210d-4935-4e03-8384-d944eb558b45",
        "tags" : [
        ]
      },
      {
        "id" : "d2759006-ca6e-4812-aec6-95913ea5f209",
        "parentId" : "fe625ed9-109a-473e-bb2b-55211fe04af2",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "Start with empty RDD does not mean the partition after shuffle is empty, instead the shuffle partitions is `spark.sql.shuffle.partitions` without AQE. After `CoalesceShufflePartitions`, the shuffle partitions are coalesced from `spark.sql.shuffle.partitions` to one empty partition. So it shouble be coalesced.",
        "createdAt" : "2021-07-14T02:38:44Z",
        "updatedAt" : "2021-07-14T02:38:45Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      },
      {
        "id" : "a625a5cd-69d5-45c7-82d0-824c77435ee6",
        "parentId" : "fe625ed9-109a-473e-bb2b-55211fe04af2",
        "authorId" : "9acf210d-4935-4e03-8384-d944eb558b45",
        "body" : "Interesting.  I didn't realize Spark could produce `spark.sql.shuffle.partitions` empty partitions.\r\n",
        "createdAt" : "2021-07-14T03:59:57Z",
        "updatedAt" : "2021-07-14T03:59:57Z",
        "lastEditedBy" : "9acf210d-4935-4e03-8384-d944eb558b45",
        "tags" : [
        ]
      },
      {
        "id" : "4c946280-2041-4aa4-ab89-f96e9b051c33",
        "parentId" : "fe625ed9-109a-473e-bb2b-55211fe04af2",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "```\r\n// If all input RDDs have 0 partition, we create an empty partition for every shuffle reader.\r\nif (validMetrics.isEmpty) {\r\n  return Seq.fill(numShuffles)(Seq(CoalescedPartitionSpec(0, 0, 0)))\r\n}\r\n```\r\n\r\nShall we use `CoalescedPartitionSpec(0, numReducers, 0)`?",
        "createdAt" : "2021-07-14T04:41:25Z",
        "updatedAt" : "2021-07-14T04:41:25Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "b2fe306f-fe0c-4234-b897-02b602319db2",
        "parentId" : "fe625ed9-109a-473e-bb2b-55211fe04af2",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "Although `CoalescedPartitionSpec(0, 0, 0)` looks a little hack but it's safe and effective.\r\n\r\nWe don't know the numReducers if the shuffle comes from `EmptyRDD`, then we can only assume the number is same with `spark.sql.shuffle.partitions`. But sometimes the assuming is not correct, e.g. if serveral `EmptyRDD`s have different pre-shuffle partition numbers.",
        "createdAt" : "2021-07-14T06:39:31Z",
        "updatedAt" : "2021-07-14T06:40:31Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      },
      {
        "id" : "e4b499dc-2454-48b5-80b4-de87c6938db2",
        "parentId" : "fe625ed9-109a-473e-bb2b-55211fe04af2",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I see, then I agree `s.startReducerIndex + 1 != s.endReducerIndex` is better.",
        "createdAt" : "2021-07-14T07:45:13Z",
        "updatedAt" : "2021-07-14T07:45:13Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "382b06cf-503e-4738-93a7-11630a18c730",
        "parentId" : "fe625ed9-109a-473e-bb2b-55211fe04af2",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "@ulysses-you can you open a followup PR? This is really a corner case and I'd like to merge this PR first.",
        "createdAt" : "2021-07-14T07:47:23Z",
        "updatedAt" : "2021-07-14T07:47:23Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "7bd13435-b2f4-495a-9f51-88f249ab1a45",
        "parentId" : "fe625ed9-109a-473e-bb2b-55211fe04af2",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "@cloud-fan created https://github.com/apache/spark/pull/33342",
        "createdAt" : "2021-07-14T09:09:09Z",
        "updatedAt" : "2021-07-14T09:09:09Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "4bed38168439d9afb83be89f16bcc20f817eaa45",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +93,97 @@  def hasCoalescedPartition: Boolean = {\n    partitionSpecs.exists {\n      case s: CoalescedPartitionSpec => s.endReducerIndex - s.startReducerIndex > 1\n      case _ => false\n    }"
  },
  {
    "id" : "1f5d4df5-cd80-413c-89bd-00b18574af5e",
    "prId" : 31653,
    "prUrl" : "https://github.com/apache/spark/pull/31653#pullrequestreview-623428847",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "853d6797-cb46-4d21-99a0-a71461250892",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Good point. We can fix it separatedly.",
        "createdAt" : "2021-03-29T16:40:49Z",
        "updatedAt" : "2021-03-29T17:14:45Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "7cfda59a1e9a8e0f86e2e6424c21639c1b5b14e3",
    "line" : 47,
    "diffHunk" : "@@ -1,1 +111,115 @@    // shouldn't this check that at least some index ranges are > 1?\n    // otherwise it's just reading original shuffle results\n    // that is how OptimizeSkewedJoin.optimizeSkewJoin defines it\n    partitionSpecs.exists(_.isInstanceOf[CoalescedPartitionSpec])\n  }"
  },
  {
    "id" : "660df77c-2bfe-4dcc-92d0-e1ade09d766e",
    "prId" : 28240,
    "prUrl" : "https://github.com/apache/spark/pull/28240#pullrequestreview-395354336",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e90abae0-e20d-4050-b300-0e6461b3e272",
        "parentId" : null,
        "authorId" : "1b84a7ff-6bf9-4417-bf9f-e46e997e5974",
        "body" : "why use the `dataSizes's sum` not `partitionDataSizes's sum` ?",
        "createdAt" : "2020-04-17T09:57:43Z",
        "updatedAt" : "2020-04-17T09:57:43Z",
        "lastEditedBy" : "1b84a7ff-6bf9-4417-bf9f-e46e997e5974",
        "tags" : [
        ]
      },
      {
        "id" : "0fd81d80-b0d9-4d5c-945c-1644c7ae118a",
        "parentId" : "e90abae0-e20d-4050-b300-0e6461b3e272",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "`partitionDataSizes.foreach { dataSizes =>` so `dateSizes = partitionDataSizes.get`",
        "createdAt" : "2020-04-17T10:51:29Z",
        "updatedAt" : "2020-04-17T10:51:29Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "3092cd8818af6c6512ae7c27da33c060ed65324b",
    "line" : 67,
    "diffHunk" : "@@ -1,1 +133,137 @@      driverAccumUpdates ++= dataSizes.map(partitionDataSizeMetrics.id -> _)\n      // Set sum value to \"partitionDataSize\" metric.\n      partitionDataSizeMetrics.set(dataSizes.sum)\n    }\n"
  },
  {
    "id" : "c8cdfd7e-14b9-4c7d-954e-a1ad65e8aa46",
    "prId" : 28175,
    "prUrl" : "https://github.com/apache/spark/pull/28175#pullrequestreview-394262341",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fa501d34-f4f4-4b08-8779-6199b3a03fbf",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This is unreacheable as the if condition has `shuffleStage.get.mapStats.isDefined`. But we do need to set size as 0 if `mapStats.isEmpty` as it means no partitions.",
        "createdAt" : "2020-04-16T02:44:34Z",
        "updatedAt" : "2020-04-16T04:52:02Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "2e2dfb8ce273c5e793eb4d6252c67d94d307abb1",
    "line" : 47,
    "diffHunk" : "@@ -1,1 +120,124 @@      val mapStats = shuffleStage.get.mapStats\n\n      if (mapStats.isEmpty) {\n        partitionMetrics.set(0)\n        driverAccumUpdates = driverAccumUpdates :+ (partitionMetrics.id, 0L)"
  }
]