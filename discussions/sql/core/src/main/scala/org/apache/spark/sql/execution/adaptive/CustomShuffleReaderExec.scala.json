[
  {
    "id" : "eaec278f-9c9d-4557-b55b-24d018272b55",
    "prId" : 33431,
    "prUrl" : "https://github.com/apache/spark/pull/33431#pullrequestreview-710552127",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "86db32a5-6e77-4d01-bafb-4f40c3e7dc5c",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "nit but let's use getClass or something next time",
        "createdAt" : "2021-07-20T13:04:07Z",
        "updatedAt" : "2021-07-20T13:04:08Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "26bb39aea4d606fbe52d09ce51cc6b62fa775e6f",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +41,45 @@    child: SparkPlan,\n    partitionSpecs: Seq[ShufflePartitionSpec]) extends UnaryExecNode {\n  assert(partitionSpecs.nonEmpty, \"CustomShuffleReaderExec requires at least one partition\")\n\n  // If this reader is to read shuffle files locally, then all partition specs should be"
  },
  {
    "id" : "f650c3fe-a93a-4501-b615-d37a2154819b",
    "prId" : 33342,
    "prUrl" : "https://github.com/apache/spark/pull/33342#pullrequestreview-706037557",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "55b3f49e-b5eb-406d-ab3d-19100796932b",
        "parentId" : null,
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "it should be more clearer than `s.startReducerIndex + 1 != s.endReducerIndex`",
        "createdAt" : "2021-07-14T09:10:58Z",
        "updatedAt" : "2021-07-14T09:10:58Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "464b3d34ef6fc29807d7cbd31e6368be1a100f96",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +94,98 @@    partitionSpecs.exists {\n      // shuffle from empty RDD\n      case CoalescedPartitionSpec(0, 0, _) => true\n      case s: CoalescedPartitionSpec => s.endReducerIndex - s.startReducerIndex > 1\n      case _ => false"
  }
]