[
  {
    "id" : "8dc45ef0-0955-4665-b898-ed1f3d98464a",
    "prId" : 29831,
    "prUrl" : "https://github.com/apache/spark/pull/29831#pullrequestreview-505623841",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7ee84585-ba90-4b80-bfe8-5101e6fa7a97",
        "parentId" : null,
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "Nit: It would be better to add a comment saying that the `partitionKeyFilters`  here is the same as the filters used in the partition pruning rule `PruneFileSourcePartitions`. ",
        "createdAt" : "2020-10-09T12:26:29Z",
        "updatedAt" : "2020-10-19T04:41:28Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "8ac7e5aba2f0e75cb7717eeb561903c9acda9830",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +158,162 @@      // this partitionKeyFilters should be the same with the ones being executed in\n      // PruneFileSourcePartitions\n      val partitionKeyFilters = DataSourceStrategy.getPushedDownFilters(partitionColumns,\n        normalizedFilters)\n"
  },
  {
    "id" : "03b8d2a1-14d1-4772-86ee-ff6441ca0aa1",
    "prId" : 29526,
    "prUrl" : "https://github.com/apache/spark/pull/29526#pullrequestreview-473084488",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a1e2fbdf-5ebc-4ec7-9804-cc688bda42ad",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : ">  It will possibly push down a predicate with partition column to datasource.\r\n\r\nI see, but, why does the test only fail when enabling `hive-1.2`? Also, could you leave some comments about \"data columns ` dataColumns`can have partition columns... \" above?",
        "createdAt" : "2020-08-23T23:54:21Z",
        "updatedAt" : "2020-08-24T00:13:44Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "0e92e8d1-bcc5-482e-af75-0eef9293d17e",
        "parentId" : "a1e2fbdf-5ebc-4ec7-9804-cc688bda42ad",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Sure. Added.\r\n\r\nIt only happens in hive-1.2 profile, because for hive-2.3 we go for a different path to create pushed down filters. In that path, we have checked if an attribute is in the field map.",
        "createdAt" : "2020-08-24T00:15:31Z",
        "updatedAt" : "2020-08-24T00:15:31Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "b251006e-c746-4bcc-ae4d-09b2dd7584ac",
        "parentId" : "a1e2fbdf-5ebc-4ec7-9804-cc688bda42ad",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ah, ok. If so, the fix looks fine.",
        "createdAt" : "2020-08-24T00:26:19Z",
        "updatedAt" : "2020-08-24T00:26:20Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "e2bfadca-b012-43bc-bfc9-618f3d8b5eb5",
        "parentId" : "a1e2fbdf-5ebc-4ec7-9804-cc688bda42ad",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> Sure. Added.\r\n> \r\n> It only happens in hive-1.2 profile, because for hive-2.3 we go for a different path to create pushed down filters. In that path, we have checked if an attribute is in the field map.\r\n\r\nLGTMï¼Œwhen  I doing that pr  https://github.com/apache/spark/pull/29406, I have thought that : from the code, seems dataColumns won't have partition col. \r\n\r\nThanks for these fix.",
        "createdAt" : "2020-08-24T02:28:12Z",
        "updatedAt" : "2020-08-24T02:28:12Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "b37f6949f1f7c4c6d2264559402a963eb077990d",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +178,182 @@      // Partition keys are not available in the statistics of the files.\n      // `dataColumns` might have partition columns, we need to filter them out.\n      val dataColumnsWithoutPartitionCols = dataColumns.filterNot(partitionColumns.contains)\n      val dataFilters = normalizedFiltersWithoutSubqueries.flatMap { f =>\n        if (f.references.intersect(partitionSet).nonEmpty) {"
  }
]