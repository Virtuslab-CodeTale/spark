[
  {
    "id" : "8dc45ef0-0955-4665-b898-ed1f3d98464a",
    "prId" : 29831,
    "prUrl" : "https://github.com/apache/spark/pull/29831#pullrequestreview-505623841",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7ee84585-ba90-4b80-bfe8-5101e6fa7a97",
        "parentId" : null,
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "Nit: It would be better to add a comment saying that the `partitionKeyFilters`  here is the same as the filters used in the partition pruning rule `PruneFileSourcePartitions`. ",
        "createdAt" : "2020-10-09T12:26:29Z",
        "updatedAt" : "2020-10-19T04:41:28Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "8ac7e5aba2f0e75cb7717eeb561903c9acda9830",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +158,162 @@      // this partitionKeyFilters should be the same with the ones being executed in\n      // PruneFileSourcePartitions\n      val partitionKeyFilters = DataSourceStrategy.getPushedDownFilters(partitionColumns,\n        normalizedFilters)\n"
  },
  {
    "id" : "03b8d2a1-14d1-4772-86ee-ff6441ca0aa1",
    "prId" : 29526,
    "prUrl" : "https://github.com/apache/spark/pull/29526#pullrequestreview-473084488",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a1e2fbdf-5ebc-4ec7-9804-cc688bda42ad",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : ">  It will possibly push down a predicate with partition column to datasource.\r\n\r\nI see, but, why does the test only fail when enabling `hive-1.2`? Also, could you leave some comments about \"data columns ` dataColumns`can have partition columns... \" above?",
        "createdAt" : "2020-08-23T23:54:21Z",
        "updatedAt" : "2020-08-24T00:13:44Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "0e92e8d1-bcc5-482e-af75-0eef9293d17e",
        "parentId" : "a1e2fbdf-5ebc-4ec7-9804-cc688bda42ad",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Sure. Added.\r\n\r\nIt only happens in hive-1.2 profile, because for hive-2.3 we go for a different path to create pushed down filters. In that path, we have checked if an attribute is in the field map.",
        "createdAt" : "2020-08-24T00:15:31Z",
        "updatedAt" : "2020-08-24T00:15:31Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "b251006e-c746-4bcc-ae4d-09b2dd7584ac",
        "parentId" : "a1e2fbdf-5ebc-4ec7-9804-cc688bda42ad",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ah, ok. If so, the fix looks fine.",
        "createdAt" : "2020-08-24T00:26:19Z",
        "updatedAt" : "2020-08-24T00:26:20Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "e2bfadca-b012-43bc-bfc9-618f3d8b5eb5",
        "parentId" : "a1e2fbdf-5ebc-4ec7-9804-cc688bda42ad",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> Sure. Added.\r\n> \r\n> It only happens in hive-1.2 profile, because for hive-2.3 we go for a different path to create pushed down filters. In that path, we have checked if an attribute is in the field map.\r\n\r\nLGTMï¼Œwhen  I doing that pr  https://github.com/apache/spark/pull/29406, I have thought that : from the code, seems dataColumns won't have partition col. \r\n\r\nThanks for these fix.",
        "createdAt" : "2020-08-24T02:28:12Z",
        "updatedAt" : "2020-08-24T02:28:12Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "b37f6949f1f7c4c6d2264559402a963eb077990d",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +178,182 @@      // Partition keys are not available in the statistics of the files.\n      // `dataColumns` might have partition columns, we need to filter them out.\n      val dataColumnsWithoutPartitionCols = dataColumns.filterNot(partitionColumns.contains)\n      val dataFilters = normalizedFiltersWithoutSubqueries.flatMap { f =>\n        if (f.references.intersect(partitionSet).nonEmpty) {"
  },
  {
    "id" : "61fe7a72-343c-4d0f-aff4-df74d86b15f4",
    "prId" : 28366,
    "prUrl" : "https://github.com/apache/spark/pull/28366#pullrequestreview-405408651",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a8513a54-85fe-4cb3-a694-45d38ad247b3",
        "parentId" : null,
        "authorId" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "body" : "Is it possible to have it propagated back so when an user does `explain(true)`, the filters that are pushed down can be shown?",
        "createdAt" : "2020-05-04T22:36:49Z",
        "updatedAt" : "2020-05-05T06:13:39Z",
        "lastEditedBy" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "tags" : [
        ]
      },
      {
        "id" : "83fbbe7f-0664-4fc7-85e1-e7242a5e676b",
        "parentId" : "a8513a54-85fe-4cb3-a694-45d38ad247b3",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "In `FileSourceScanExec`, this pushed down filters are shown there.",
        "createdAt" : "2020-05-04T23:10:40Z",
        "updatedAt" : "2020-05-05T06:13:39Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "00b9d47702ae76fca3c7246155175cb42f75136f",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +183,187 @@      val pushedFilters = dataFilters\n        .flatMap(DataSourceStrategy.translateFilter(_, supportNestedPredicatePushdown))\n      logInfo(s\"Pushed Filters: ${pushedFilters.mkString(\",\")}\")\n\n      // Predicates with both partition keys and attributes need to be evaluated after the scan."
  },
  {
    "id" : "fd21afde-3520-41f6-a759-6dbb12a647a4",
    "prId" : 26565,
    "prUrl" : "https://github.com/apache/spark/pull/26565#pullrequestreview-318092196",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b868ca75-4771-4a46-9d04-dfa112d3e9b7",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "We will run more than once translateFilter.",
        "createdAt" : "2019-11-18T01:39:15Z",
        "updatedAt" : "2019-11-18T01:39:27Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "7a270856-4e32-4c53-8b44-e85e67565c68",
        "parentId" : "b868ca75-4771-4a46-9d04-dfa112d3e9b7",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "Yes, but if we want to print the pushed filter once, I can not find a better way with min changed.",
        "createdAt" : "2019-11-18T01:48:27Z",
        "updatedAt" : "2019-11-18T01:49:12Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      },
      {
        "id" : "c3eb8501-b655-42d7-96a9-e899e207c2df",
        "parentId" : "b868ca75-4771-4a46-9d04-dfa112d3e9b7",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "I think run translateFilter twice is worse than logging twice.",
        "createdAt" : "2019-11-18T01:58:01Z",
        "updatedAt" : "2019-11-18T01:58:02Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "16f8b1e8-8c17-40df-9ae9-a8e4987afc00",
        "parentId" : "b868ca75-4771-4a46-9d04-dfa112d3e9b7",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "Before this pr, translateFilter is also run twice. This just reduce one logging.\r\nHow about pass pushedDownFilters in `case class FileSourceScanExec()` ?",
        "createdAt" : "2019-11-18T04:13:49Z",
        "updatedAt" : "2019-11-18T04:13:49Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "0aa4a48b45aaa6220481f196fc4c8c7983a7031f",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +179,183 @@        normalizedFiltersWithoutSubqueries.filter(_.references.intersect(partitionSet).isEmpty)\n      logInfo(s\"Pushed Filters: \" +\n        s\"${dataFilters.flatMap(DataSourceStrategy.translateFilter).mkString(\",\")}\")\n\n      // Predicates with both partition keys and attributes need to be evaluated after the scan."
  }
]