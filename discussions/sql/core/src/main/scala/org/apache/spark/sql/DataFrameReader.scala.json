[
  {
    "id" : "deb0eafa-c525-4f90-8dc9-fa391631287c",
    "prId" : 33436,
    "prUrl" : "https://github.com/apache/spark/pull/33436#pullrequestreview-711231249",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "21c1f084-0c65-4a7a-b1e0-72beab989157",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Actually would you mind updating migration guide (https://github.com/apache/spark/blob/master/docs/sql-migration-guide.md)? You can describe, for example, non-nullable schema was not supported properly in previous Spark version so the output schema of `DataFrameReader.json(jsonDataset: Dataset[String])` and `DataFrameReader.csv(csvDataset: Dataset[String])` became nullable which also matches with `DataFrameReader.json(path: String)` and `DataFrameReader.csv(path: String)`.\r\n",
        "createdAt" : "2021-07-21T01:16:48Z",
        "updatedAt" : "2021-07-21T01:16:48Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "6131ffc2-df3c-4d1a-9229-8df71b35b583",
        "parentId" : "21c1f084-0c65-4a7a-b1e0-72beab989157",
        "authorId" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "body" : "Done. BTW, shall we backport this PR into the previous version?",
        "createdAt" : "2021-07-21T02:21:58Z",
        "updatedAt" : "2021-07-21T02:21:58Z",
        "lastEditedBy" : "c12eb4aa-c39d-4fa9-8470-ed071c0be24a",
        "tags" : [
        ]
      },
      {
        "id" : "4008e261-9869-46a3-a326-6b1b4eb6e7b9",
        "parentId" : "21c1f084-0c65-4a7a-b1e0-72beab989157",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Let's don't port it back. it will be merged into 3.3 only for now.",
        "createdAt" : "2021-07-21T03:40:15Z",
        "updatedAt" : "2021-07-21T03:40:15Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "56ceec462588aec85ec869fe15c66447ee93ccf1",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +522,526 @@      }\n\n    val schema = userSpecifiedSchema.map(_.asNullable).getOrElse {\n      TextInputCSVDataSource.inferFromDataset(\n        sparkSession,"
  },
  {
    "id" : "5754f193-af12-4a00-bde4-efec796310a9",
    "prId" : 32546,
    "prUrl" : "https://github.com/apache/spark/pull/32546#pullrequestreview-663979905",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a8fcee7b-62a1-4d4d-8db2-352891f3ed9a",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "ditto. it says ORC-specific options but also mentions about Generic Files Source Options later",
        "createdAt" : "2021-05-20T06:19:25Z",
        "updatedAt" : "2021-05-20T06:19:25Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "043d3087c838c2f6439d798bdc8e889d6a728ff7",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +875,879 @@   * Loads ORC files and returns the result as a `DataFrame`.\n   *\n   * ORC-specific option(s) for reading ORC files can be found in\n   * <a href=\n   *   \"https://spark.apache.org/docs/latest/sql-data-sources-orc.html#data-source-option\">"
  },
  {
    "id" : "589fd460-f3aa-4404-8693-604af5a26904",
    "prId" : 32546,
    "prUrl" : "https://github.com/apache/spark/pull/32546#pullrequestreview-665066612",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "658c2718-2774-4df0-998b-3eef4e8274c0",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Ditto.",
        "createdAt" : "2021-05-21T03:48:06Z",
        "updatedAt" : "2021-05-21T03:48:06Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "043d3087c838c2f6439d798bdc8e889d6a728ff7",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +877,881 @@   * ORC-specific option(s) for reading ORC files can be found in\n   * <a href=\n   *   \"https://spark.apache.org/docs/latest/sql-data-sources-orc.html#data-source-option\">\n   *   Data Source Option</a> in the version you use.\n   *"
  },
  {
    "id" : "5fb9397a-2738-4718-a8f2-4215bee2b97a",
    "prId" : 32204,
    "prUrl" : "https://github.com/apache/spark/pull/32204#pullrequestreview-663975403",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c88dd33c-2af6-4e5c-b0ad-4424e027102e",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "ditto. It says JSON specific options but it mentions \"Generic Files Source Options\"",
        "createdAt" : "2021-05-20T06:11:25Z",
        "updatedAt" : "2021-05-20T06:11:26Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "a10586c3d2887463de16984adb72d205f85f3796",
    "line" : 151,
    "diffHunk" : "@@ -1,1 +391,395 @@   * schema in advance, use the version that specifies the schema to avoid the extra scan.\n   *\n   * You can find the JSON-specific options for reading JSON files in\n   * <a href=\"https://spark.apache.org/docs/latest/sql-data-sources-json.html#data-source-option\">\n   *   Data Source Option</a> in the version you use."
  }
]