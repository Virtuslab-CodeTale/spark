[
  {
    "id" : "5a415096-6f32-4ad2-8e03-531f4e32ef62",
    "prId" : 33310,
    "prUrl" : "https://github.com/apache/spark/pull/33310#pullrequestreview-705991230",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "da783f6b-eefc-4ea0-bc27-e246b7b60e30",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I'm wondering that if we should have a more meticulous algorithm.\r\n\r\nLet's say that there are 3 mappers and 2 reducers, so 6 shuffle blocks in total: `(M0, R0), (M0, R1), (M1, R0), (M1, R1), (M2, R0), (M2, R1)`. If the expected parallelism is 2, I think each task should read 3 blocks:\r\ntask 0: `(M0, R0), (M0, R1), (M1, R0)`\r\ntask1: `(M1, R1), (M2, R0), (M2, R1)`\r\n\r\nSo one task can read some entire mappers and some partial mapper.",
        "createdAt" : "2021-07-14T08:23:54Z",
        "updatedAt" : "2021-07-14T08:24:09Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "b4b6b15b8841bc6e9e2452861db74440e5dcbcd2",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +87,91 @@      (0 until 1).flatMap { _ =>\n        (splitPoints :+ numMappers).sliding(2).map {\n          case Seq(start, end) => CoalescedMapperPartitionSpec(start, end, numReducers)\n        }\n      }"
  },
  {
    "id" : "b554f62a-d3fc-409e-a36a-5d8fcd4cf334",
    "prId" : 29307,
    "prUrl" : "https://github.com/apache/spark/pull/29307#pullrequestreview-458905988",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7efa1fb9-168d-4aba-a3ae-74fadd997255",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "This skips 0 partitions case, right?",
        "createdAt" : "2020-07-31T03:37:47Z",
        "updatedAt" : "2020-07-31T04:59:45Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "53f3bde3-8945-4ebd-b26e-9b0e4fded8e5",
        "parentId" : "7efa1fb9-168d-4aba-a3ae-74fadd997255",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "yea, otherwise we will hit\r\n```\r\nval splitPoints = if (numMappers == 0) {\r\n  Seq.empty\r\n} else ...\r\n```\r\nwhich creates a local reader with 0 partitions.",
        "createdAt" : "2020-07-31T04:15:18Z",
        "updatedAt" : "2020-07-31T04:59:45Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "f89880bb-08c2-4ad4-a770-f9de612da491",
        "parentId" : "7efa1fb9-168d-4aba-a3ae-74fadd997255",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "We should be able to turn the `if` into `assert`, but I'd like to only do it in master to be safe.",
        "createdAt" : "2020-07-31T04:16:00Z",
        "updatedAt" : "2020-07-31T04:59:45Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "2ae792bcce7ad8e806c06a79a7f20c04af253170",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +141,145 @@  def canUseLocalShuffleReader(plan: SparkPlan): Boolean = plan match {\n    case s: ShuffleQueryStageExec =>\n      s.shuffle.canChangeNumPartitions && s.mapStats.isDefined\n    case CustomShuffleReaderExec(s: ShuffleQueryStageExec, partitionSpecs) =>\n      s.shuffle.canChangeNumPartitions && s.mapStats.isDefined && partitionSpecs.nonEmpty"
  },
  {
    "id" : "45535c76-2cbd-4617-bdfb-6a6793687714",
    "prId" : 29021,
    "prUrl" : "https://github.com/apache/spark/pull/29021#pullrequestreview-450486806",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d94fa6f0-6ac4-4a75-a99d-925838111d09",
        "parentId" : null,
        "authorId" : "1b84a7ff-6bf9-4417-bf9f-e46e997e5974",
        "body" : "It means the rule of `OptimizeLocalShuffleReader` is disabled when enable the rule of `OptimizedSkwedJoin `rule ?",
        "createdAt" : "2020-07-17T07:37:42Z",
        "updatedAt" : "2020-07-21T07:50:57Z",
        "lastEditedBy" : "1b84a7ff-6bf9-4417-bf9f-e46e997e5974",
        "tags" : [
        ]
      },
      {
        "id" : "49e459da-fbc7-4ea7-81f9-964b6a5b877c",
        "parentId" : "d94fa6f0-6ac4-4a75-a99d-925838111d09",
        "authorId" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "body" : "Not exactly. In this more general skew join handling, we can match more patterns. For example, we can handle skew join like https://user-images.githubusercontent.com/1853780/87743215-01e9e780-c81b-11ea-97d9-f274b379912e.png. The number partitions of `CustomShuffleReader` in the the BCJ (changed from SMJ by AE) after `OptimizeLocalShuffleReader` is not equals to the anther side. So simply, I disable `createLocalReader`.",
        "createdAt" : "2020-07-17T08:53:10Z",
        "updatedAt" : "2020-07-21T07:50:57Z",
        "lastEditedBy" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "tags" : [
        ]
      }
    ],
    "commit" : "5bed68ceed90c89457ff04af6da62f2222c795b7",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +143,147 @@    case s: ShuffleQueryStageExec =>\n      s.shuffle.canChangeNumPartitions\n    // This CustomShuffleReaderExec used in skew side, its numPartitions increased.\n    case CustomShuffleReaderExec(_, partitionSpecs)\n        if partitionSpecs.exists(_.isInstanceOf[PartialReducerPartitionSpec]) => false"
  },
  {
    "id" : "37dfa129-58db-4bc1-81fe-60d270c47dfe",
    "prId" : 26862,
    "prUrl" : "https://github.com/apache/spark/pull/26862#pullrequestreview-331639065",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "78b2a799-5d54-4e27-abd8-0bfe2480b4ad",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Hm, but if numMappers = 0, Array.fill never evaluates anything; you get an empty array. Are you sure this is the cause?",
        "createdAt" : "2019-12-12T13:33:49Z",
        "updatedAt" : "2019-12-12T13:33:49Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "23ac283f-2d5d-4d09-8adc-e29f6379bda8",
        "parentId" : "78b2a799-5d54-4e27-abd8-0bfe2480b4ad",
        "authorId" : "1b84a7ff-6bf9-4417-bf9f-e46e997e5974",
        "body" : "yes, we may does not need this check. The error is tested with previous commit and it seems fixed in the latest commit. And I will close this PR. Thanks",
        "createdAt" : "2019-12-13T02:37:49Z",
        "updatedAt" : "2019-12-13T02:37:49Z",
        "lastEditedBy" : "1b84a7ff-6bf9-4417-bf9f-e46e997e5974",
        "tags" : [
        ]
      }
    ],
    "commit" : "9bc812345b1ae6e7a2d0ee1f40eb8ff3b0d186f6",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +89,93 @@    val numReducers = shuffleDep.partitioner.numPartitions\n    val expectedParallelism = advisoryParallelism.getOrElse(numReducers)\n    val numMappers = math.max(1, shuffleDep.rdd.getNumPartitions)\n    Array.fill(numMappers) {\n      equallyDivide(numReducers, math.max(1, expectedParallelism / numMappers)).toArray"
  },
  {
    "id" : "564523ee-1cd1-4099-aa39-fc9a136c029a",
    "prId" : 26516,
    "prUrl" : "https://github.com/apache/spark/pull/26516#pullrequestreview-318824044",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "59ce8cda-cd50-4e31-9236-58866590dee6",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "nit: we can move `BroadcastJoinWithShuffleLeft` to this object as well, then in `case class OptimizeLocalShuffleReader`, simply `import OptimizeLocalShuffleReader._`",
        "createdAt" : "2019-11-19T07:19:40Z",
        "updatedAt" : "2019-11-19T08:10:51Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "fff1115fba0e9d8f934263d6709631ed0110701f",
    "line" : 111,
    "diffHunk" : "@@ -1,1 +87,91 @@\nobject OptimizeLocalShuffleReader {\n\n  object BroadcastJoinWithShuffleLeft {\n    def unapply(plan: SparkPlan): Option[(SparkPlan, BuildSide)] = plan match {"
  },
  {
    "id" : "b593842f-ad08-46b9-8af0-033a4d8c5a37",
    "prId" : 26289,
    "prUrl" : "https://github.com/apache/spark/pull/26289#pullrequestreview-309004713",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "de9825a5-ee29-46c1-89ef-4c75f3026841",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Now this rule converts local shuffle reader for all BroadcastHashJoinExec and then reverts all local shuffle readers if any of local shuffle reader causes additional shuffle. \r\n\r\nCan we just revert the local shuffle readers that cause additional shuffle and keep these not?",
        "createdAt" : "2019-10-30T07:20:58Z",
        "updatedAt" : "2019-10-31T07:12:30Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "8511df47-f012-4a80-99f1-9f6e9f001458",
        "parentId" : "de9825a5-ee29-46c1-89ef-4c75f3026841",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This is the best, but I don't know if there is an easy way to do it.",
        "createdAt" : "2019-10-30T07:29:48Z",
        "updatedAt" : "2019-10-31T07:12:30Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "d1358c8b-b637-44ac-80e9-65925592bbb3",
        "parentId" : "de9825a5-ee29-46c1-89ef-4c75f3026841",
        "authorId" : "1b84a7ff-6bf9-4417-bf9f-e46e997e5974",
        "body" : "We can implement using revert all the local reader currently and re-optimize later when we find a better way.",
        "createdAt" : "2019-10-30T07:34:58Z",
        "updatedAt" : "2019-10-31T07:12:30Z",
        "lastEditedBy" : "1b84a7ff-6bf9-4417-bf9f-e46e997e5974",
        "tags" : [
        ]
      }
    ],
    "commit" : "573ffcd83a320d7405e4795f3fe81df0a015dc53",
    "line" : 72,
    "diffHunk" : "@@ -1,1 +77,81 @@      }.length\n    }\n    // Check whether additional shuffle introduced. If introduced, revert the local reader.\n    val numExchangeBefore = numExchanges(EnsureRequirements(conf).apply(plan))\n    val numExchangeAfter = numExchanges(EnsureRequirements(conf).apply(withProbeSideLocalReader))"
  }
]