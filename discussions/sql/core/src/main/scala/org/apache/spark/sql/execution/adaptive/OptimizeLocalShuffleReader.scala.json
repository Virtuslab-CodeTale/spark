[
  {
    "id" : "5a415096-6f32-4ad2-8e03-531f4e32ef62",
    "prId" : 33310,
    "prUrl" : "https://github.com/apache/spark/pull/33310#pullrequestreview-705991230",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "da783f6b-eefc-4ea0-bc27-e246b7b60e30",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I'm wondering that if we should have a more meticulous algorithm.\r\n\r\nLet's say that there are 3 mappers and 2 reducers, so 6 shuffle blocks in total: `(M0, R0), (M0, R1), (M1, R0), (M1, R1), (M2, R0), (M2, R1)`. If the expected parallelism is 2, I think each task should read 3 blocks:\r\ntask 0: `(M0, R0), (M0, R1), (M1, R0)`\r\ntask1: `(M1, R1), (M2, R0), (M2, R1)`\r\n\r\nSo one task can read some entire mappers and some partial mapper.",
        "createdAt" : "2021-07-14T08:23:54Z",
        "updatedAt" : "2021-07-14T08:24:09Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "b4b6b15b8841bc6e9e2452861db74440e5dcbcd2",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +87,91 @@      (0 until 1).flatMap { _ =>\n        (splitPoints :+ numMappers).sliding(2).map {\n          case Seq(start, end) => CoalescedMapperPartitionSpec(start, end, numReducers)\n        }\n      }"
  },
  {
    "id" : "b554f62a-d3fc-409e-a36a-5d8fcd4cf334",
    "prId" : 29307,
    "prUrl" : "https://github.com/apache/spark/pull/29307#pullrequestreview-458905988",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7efa1fb9-168d-4aba-a3ae-74fadd997255",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "This skips 0 partitions case, right?",
        "createdAt" : "2020-07-31T03:37:47Z",
        "updatedAt" : "2020-07-31T04:59:45Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "53f3bde3-8945-4ebd-b26e-9b0e4fded8e5",
        "parentId" : "7efa1fb9-168d-4aba-a3ae-74fadd997255",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "yea, otherwise we will hit\r\n```\r\nval splitPoints = if (numMappers == 0) {\r\n  Seq.empty\r\n} else ...\r\n```\r\nwhich creates a local reader with 0 partitions.",
        "createdAt" : "2020-07-31T04:15:18Z",
        "updatedAt" : "2020-07-31T04:59:45Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "f89880bb-08c2-4ad4-a770-f9de612da491",
        "parentId" : "7efa1fb9-168d-4aba-a3ae-74fadd997255",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "We should be able to turn the `if` into `assert`, but I'd like to only do it in master to be safe.",
        "createdAt" : "2020-07-31T04:16:00Z",
        "updatedAt" : "2020-07-31T04:59:45Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "2ae792bcce7ad8e806c06a79a7f20c04af253170",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +141,145 @@  def canUseLocalShuffleReader(plan: SparkPlan): Boolean = plan match {\n    case s: ShuffleQueryStageExec =>\n      s.shuffle.canChangeNumPartitions && s.mapStats.isDefined\n    case CustomShuffleReaderExec(s: ShuffleQueryStageExec, partitionSpecs) =>\n      s.shuffle.canChangeNumPartitions && s.mapStats.isDefined && partitionSpecs.nonEmpty"
  },
  {
    "id" : "45535c76-2cbd-4617-bdfb-6a6793687714",
    "prId" : 29021,
    "prUrl" : "https://github.com/apache/spark/pull/29021#pullrequestreview-450486806",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d94fa6f0-6ac4-4a75-a99d-925838111d09",
        "parentId" : null,
        "authorId" : "1b84a7ff-6bf9-4417-bf9f-e46e997e5974",
        "body" : "It means the rule of `OptimizeLocalShuffleReader` is disabled when enable the rule of `OptimizedSkwedJoin `rule ?",
        "createdAt" : "2020-07-17T07:37:42Z",
        "updatedAt" : "2020-07-21T07:50:57Z",
        "lastEditedBy" : "1b84a7ff-6bf9-4417-bf9f-e46e997e5974",
        "tags" : [
        ]
      },
      {
        "id" : "49e459da-fbc7-4ea7-81f9-964b6a5b877c",
        "parentId" : "d94fa6f0-6ac4-4a75-a99d-925838111d09",
        "authorId" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "body" : "Not exactly. In this more general skew join handling, we can match more patterns. For example, we can handle skew join like https://user-images.githubusercontent.com/1853780/87743215-01e9e780-c81b-11ea-97d9-f274b379912e.png. The number partitions of `CustomShuffleReader` in the the BCJ (changed from SMJ by AE) after `OptimizeLocalShuffleReader` is not equals to the anther side. So simply, I disable `createLocalReader`.",
        "createdAt" : "2020-07-17T08:53:10Z",
        "updatedAt" : "2020-07-21T07:50:57Z",
        "lastEditedBy" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "tags" : [
        ]
      }
    ],
    "commit" : "5bed68ceed90c89457ff04af6da62f2222c795b7",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +143,147 @@    case s: ShuffleQueryStageExec =>\n      s.shuffle.canChangeNumPartitions\n    // This CustomShuffleReaderExec used in skew side, its numPartitions increased.\n    case CustomShuffleReaderExec(_, partitionSpecs)\n        if partitionSpecs.exists(_.isInstanceOf[PartialReducerPartitionSpec]) => false"
  }
]