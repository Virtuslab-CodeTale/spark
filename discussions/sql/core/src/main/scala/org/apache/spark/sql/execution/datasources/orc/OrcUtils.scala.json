[
  {
    "id" : "0c33f322-d3e5-4545-b50a-4adf60ab538f",
    "prId" : 33030,
    "prUrl" : "https://github.com/apache/spark/pull/33030#pullrequestreview-689856877",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2018b4da-5a89-4a5c-9544-cfdda2a718a4",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Thank you for adding this.",
        "createdAt" : "2021-06-22T18:18:27Z",
        "updatedAt" : "2021-06-22T18:18:27Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "87124f2c7e7827a776a71c091d88ab1baa9d8d22",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +85,89 @@  }\n\n  private def toCatalystSchema(schema: TypeDescription): StructType = {\n    // The Spark query engine has not completely supported CHAR/VARCHAR type yet, and here we\n    // replace the orc CHAR/VARCHAR with STRING type."
  }
]