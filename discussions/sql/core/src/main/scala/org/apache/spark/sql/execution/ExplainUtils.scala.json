[
  {
    "id" : "2542afd2-710d-4e1f-b78d-d419d99483df",
    "prId" : 26039,
    "prUrl" : "https://github.com/apache/spark/pull/26039#pullrequestreview-301113033",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "173bcbe2-c2bf-49de-a0cf-bc1e87e1beca",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "since this method put its result in the parameter `subqueries`, I think we don't need to call `flatMap` and `collect`, just `foreach`.",
        "createdAt" : "2019-10-07T17:45:03Z",
        "updatedAt" : "2019-10-07T22:34:10Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "8d360de1-a538-4c77-9196-5d2da99ef94f",
        "parentId" : "173bcbe2-c2bf-49de-a0cf-bc1e87e1beca",
        "authorId" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "body" : "@cloud-fan We need the collect to traverse the expression tree. I have changed flatMap to foreach.",
        "createdAt" : "2019-10-07T22:35:19Z",
        "updatedAt" : "2019-10-07T22:35:19Z",
        "lastEditedBy" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "tags" : [
        ]
      },
      {
        "id" : "f0710d73-b9d0-45ee-85f2-ffd58dd14336",
        "parentId" : "173bcbe2-c2bf-49de-a0cf-bc1e87e1beca",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "> We need the collect to traverse the expression tree\r\n\r\nhmm, can we use `foreach` to traverse the expression tree? We have `TreeNode.foreach`",
        "createdAt" : "2019-10-08T07:03:30Z",
        "updatedAt" : "2019-10-08T07:03:30Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "cc5ff6dd-55b5-4fd0-898f-8b942ee14ad5",
        "parentId" : "173bcbe2-c2bf-49de-a0cf-bc1e87e1beca",
        "authorId" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "body" : "@cloud-fan We have it in this form : \r\np.expressions.foreach(_.collect {\r\n    ...\r\n    ...\r\n})\r\n\r\nYou are suggesting to do : \r\n\r\np.expressions.foreach(_.foreach {\r\n    ...\r\n    ...\r\n}\r\n\r\n?",
        "createdAt" : "2019-10-08T07:18:40Z",
        "updatedAt" : "2019-10-08T07:18:40Z",
        "lastEditedBy" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "tags" : [
        ]
      },
      {
        "id" : "7a9b7406-5137-4956-b88f-8b8623b678a4",
        "parentId" : "173bcbe2-c2bf-49de-a0cf-bc1e87e1beca",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "yup",
        "createdAt" : "2019-10-08T08:19:38Z",
        "updatedAt" : "2019-10-08T08:19:38Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "e39582ad-93ed-4211-9923-92b5d9ff87a0",
        "parentId" : "173bcbe2-c2bf-49de-a0cf-bc1e87e1beca",
        "authorId" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "body" : "@cloud-fan Got it... I will send a small follow-up. Thank you.",
        "createdAt" : "2019-10-14T05:59:26Z",
        "updatedAt" : "2019-10-14T05:59:27Z",
        "lastEditedBy" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "tags" : [
        ]
      }
    ],
    "commit" : "316e0743d3f25527a495c5349ebf12faed43ba60",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +200,204 @@                subqueries += ((p, e, s))\n                getSubqueries(s, subqueries)\n              case _ =>\n            }\n        })"
  },
  {
    "id" : "cf13a9b6-11af-4bb7-9136-9ebd34316d22",
    "prId" : 24759,
    "prUrl" : "https://github.com/apache/spark/pull/24759#pullrequestreview-277465386",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8acffc53-fea5-4894-804f-d24aa0f42736",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "do we really need this type parameter?",
        "createdAt" : "2019-08-20T10:55:34Z",
        "updatedAt" : "2019-08-26T07:56:18Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "04e571fe-2090-4a05-bb4c-5c015ba515c5",
        "parentId" : "8acffc53-fea5-4894-804f-d24aa0f42736",
        "authorId" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "body" : "@cloud-fan No.. don't need it.. i probably copied from somewhere :-)",
        "createdAt" : "2019-08-20T17:06:08Z",
        "updatedAt" : "2019-08-26T07:56:18Z",
        "lastEditedBy" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "tags" : [
        ]
      },
      {
        "id" : "f95d0a59-085f-4afd-861a-5f7d8fe30486",
        "parentId" : "8acffc53-fea5-4894-804f-d24aa0f42736",
        "authorId" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "body" : "@cloud-fan Sorry.. we need it as this calls append.. and it has the type scope..I get a compilation error if i remove it.",
        "createdAt" : "2019-08-20T22:01:46Z",
        "updatedAt" : "2019-08-26T07:56:18Z",
        "lastEditedBy" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "tags" : [
        ]
      }
    ],
    "commit" : "f401175f7bd0e94db1722653734b92c9db57a779",
    "line" : 51,
    "diffHunk" : "@@ -1,1 +49,53 @@   *\n   */\n  private def processPlanSkippingSubqueries[T <: QueryPlan[T]](\n      plan: => QueryPlan[T],\n      append: String => Unit,"
  },
  {
    "id" : "0954d8bf-085f-40e9-8536-ab1967c9f0c9",
    "prId" : 24759,
    "prUrl" : "https://github.com/apache/spark/pull/24759#pullrequestreview-277311636",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bfdcaf93-b6f5-4fa7-bae9-b80ed17ad726",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "we should add doc to explain what the return value is.",
        "createdAt" : "2019-08-20T10:56:35Z",
        "updatedAt" : "2019-08-26T07:56:18Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "ebc387e7-ec0f-4f52-a022-5731ef1ab840",
        "parentId" : "bfdcaf93-b6f5-4fa7-bae9-b80ed17ad726",
        "authorId" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "body" : "@cloud-fan OK.",
        "createdAt" : "2019-08-20T17:06:17Z",
        "updatedAt" : "2019-08-26T07:56:18Z",
        "lastEditedBy" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "tags" : [
        ]
      }
    ],
    "commit" : "f401175f7bd0e94db1722653734b92c9db57a779",
    "line" : 54,
    "diffHunk" : "@@ -1,1 +52,56 @@      plan: => QueryPlan[T],\n      append: String => Unit,\n      startOperatorID: Int): Int = {\n\n    val operationIDs = new mutable.ArrayBuffer[(Int, QueryPlan[_])]()"
  },
  {
    "id" : "dec433a3-c90c-4831-b2ab-fa45111a5988",
    "prId" : 24759,
    "prUrl" : "https://github.com/apache/spark/pull/24759#pullrequestreview-278130012",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ae7aef20-16e7-4408-b08a-3f893d480282",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "if we want to skip subqueries, why handle inner children here?",
        "createdAt" : "2019-08-21T13:20:41Z",
        "updatedAt" : "2019-08-26T07:56:18Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "c75eede2-fdb3-4fae-8769-46348d455305",
        "parentId" : "ae7aef20-16e7-4408-b08a-3f893d480282",
        "authorId" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "body" : "@cloud-fan Do you have a suggestion for me here ? My idea was to write this in a generic way so that i don't have to change the code that drives the recursion. The only thing we may change is at the top of the function which checks for `BaseSubqueryExec`. I wanted to make that check a function in the future that is called from both this function and `generateWholeStageCodegenIds`. This is basically to support for more cases where we want treat a operator same as `BaseSubqueryExec`.  By the way, i have examined the plan for other operators which has innerChildren such as `InsertIntoDataSourceCommand` and we are printing the plan ok. ",
        "createdAt" : "2019-08-21T23:50:31Z",
        "updatedAt" : "2019-08-26T07:56:18Z",
        "lastEditedBy" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "tags" : [
        ]
      }
    ],
    "commit" : "f401175f7bd0e94db1722653734b92c9db57a779",
    "line" : 153,
    "diffHunk" : "@@ -1,1 +151,155 @@          operatorIDs += ((currentOperationID, other))\n        }\n        other.innerChildren.foreach { plan =>\n          currentOperationID = generateOperatorIDs(plan,\n            currentOperationID,"
  },
  {
    "id" : "44bb3a8e-c09f-4046-a31c-59a5f7ed99ea",
    "prId" : 24759,
    "prUrl" : "https://github.com/apache/spark/pull/24759#pullrequestreview-278130073",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "794f324c-70af-4b54-933d-5bd212e1f4f6",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ditto",
        "createdAt" : "2019-08-21T13:20:54Z",
        "updatedAt" : "2019-08-26T07:56:18Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "cbc2d411-35ba-46ef-b6b4-a64fd956b210",
        "parentId" : "794f324c-70af-4b54-933d-5bd212e1f4f6",
        "authorId" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "body" : "@cloud-fan same comment as above.",
        "createdAt" : "2019-08-21T23:50:45Z",
        "updatedAt" : "2019-08-26T07:56:18Z",
        "lastEditedBy" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "tags" : [
        ]
      }
    ],
    "commit" : "f401175f7bd0e94db1722653734b92c9db57a779",
    "line" : 179,
    "diffHunk" : "@@ -1,1 +177,181 @@          other.setTagValue(QueryPlan.CODEGEN_ID_TAG, currentCodegenId)\n        }\n        other.innerChildren.foreach { plan =>\n          generateWholeStageCodegenIds(plan)\n        }"
  },
  {
    "id" : "919a996c-b318-4f38-841e-67e3c4d602c1",
    "prId" : 24759,
    "prUrl" : "https://github.com/apache/spark/pull/24759#pullrequestreview-278130738",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0c7867ce-fa4d-4dd5-b0dd-72d8c044bfc7",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "nit:\r\n```\r\nif (subqueries.nonEmpty) append(\"\\n===== Subqueries =====\\n\\n\")\r\nfor (sub <- subqueries) ...\r\n```\r\nthen we don't need the `var i = 0`",
        "createdAt" : "2019-08-21T13:23:22Z",
        "updatedAt" : "2019-08-26T07:56:18Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "36cd98ef-b77b-422a-99cd-b10cfb622cce",
        "parentId" : "0c7867ce-fa4d-4dd5-b0dd-72d8c044bfc7",
        "authorId" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "body" : "@cloud-fan actually i need that variable to print the subquery number ? I print like :\r\n```\r\nsubquery:1\r\n....\r\nsubquery:2\r\n....\r\n```",
        "createdAt" : "2019-08-21T23:53:33Z",
        "updatedAt" : "2019-08-26T07:56:18Z",
        "lastEditedBy" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "tags" : [
        ]
      }
    ],
    "commit" : "f401175f7bd0e94db1722653734b92c9db57a779",
    "line" : 99,
    "diffHunk" : "@@ -1,1 +97,101 @@          append(\"\\n===== Subqueries =====\\n\\n\")\n        }\n        i = i + 1\n        append(s\"Subquery:$i Hosting operator id = \" +\n          s\"${getOpId(sub._1)} Hosting Expression = ${sub._2}\\n\")"
  }
]