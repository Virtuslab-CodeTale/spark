[
  {
    "id" : "c6185042-864d-477d-8903-a6bc4505c5c8",
    "prId" : 32547,
    "prUrl" : "https://github.com/apache/spark/pull/32547#pullrequestreview-669647084",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1dbe8a08-0426-45b7-923c-e5e767a9bb4e",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "nit: seems `loaded` is not needed for `LeftAnti` case.",
        "createdAt" : "2021-05-26T16:43:53Z",
        "updatedAt" : "2021-05-26T16:43:53Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "7eb993ff-7a84-4d0a-bc17-4d13264be58f",
        "parentId" : "1dbe8a08-0426-45b7-923c-e5e767a9bb4e",
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "`loadStreamed` is not used by `LeftAnti`.\r\nI think you are referring to `boolean $loaded = false;` in `before` should not be needed, right?",
        "createdAt" : "2021-05-26T17:09:20Z",
        "updatedAt" : "2021-05-26T17:09:20Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      },
      {
        "id" : "06f43785-1cd7-40b1-b847-bfb56fc18d2f",
        "parentId" : "1dbe8a08-0426-45b7-923c-e5e767a9bb4e",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "yea, looks like for `LeftAnti`, it doesn't rely on `loaded` to do `streamedAfter`.",
        "createdAt" : "2021-05-26T17:47:24Z",
        "updatedAt" : "2021-05-26T17:47:24Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "601cd844-6737-4669-b85c-331a13d0e7cd",
        "parentId" : "1dbe8a08-0426-45b7-923c-e5e767a9bb4e",
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "Created https://github.com/apache/spark/pull/32681 as followup, thanks.",
        "createdAt" : "2021-05-27T00:34:40Z",
        "updatedAt" : "2021-05-27T00:34:40Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      }
    ],
    "commit" : "df70b01c6c4c26be365f714b793c7e469e6ae1af",
    "line" : 93,
    "diffHunk" : "@@ -1,1 +694,698 @@           |  $streamedAfter\n           |}\n         \"\"\".stripMargin\n\n      val loadStreamedAfterCondition = joinType match {"
  },
  {
    "id" : "119c1636-8fc8-480f-97b2-499bc18179c8",
    "prId" : 32528,
    "prUrl" : "https://github.com/apache/spark/pull/32528#pullrequestreview-658744620",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "33d4eb5d-27c1-41c7-81e0-174c11cc4079",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "shall we pass `beforeLoop.trim` so that we don't need to do it in all the 3 methods?",
        "createdAt" : "2021-05-13T07:22:59Z",
        "updatedAt" : "2021-05-13T07:23:00Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "511fdee8-5434-48d8-b4fe-546cc9e340a2",
        "parentId" : "33d4eb5d-27c1-41c7-81e0-174c11cc4079",
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "Actually after double checking, we do not need to do `beforeLoop.trim` as `beforeLoop` already has `stripMargin`, and has no trailing spaces. Also updated to avoid repeated `conditionCheck.trim`",
        "createdAt" : "2021-05-13T09:39:49Z",
        "updatedAt" : "2021-05-13T09:40:08Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      }
    ],
    "commit" : "6282a09d2b78aad102926f956a10d68272e05c8d",
    "line" : 229,
    "diffHunk" : "@@ -1,1 +722,726 @@    joinType match {\n      case _: InnerLike =>\n        codegenInner(findNextJoinRows, beforeLoop, iterator, bufferedRow, condCheck, outputRow,\n          eagerCleanup)\n      case LeftOuter | RightOuter =>"
  },
  {
    "id" : "b6884f8f-4895-4ce9-b3fd-e72ec59f6734",
    "prId" : 32528,
    "prUrl" : "https://github.com/apache/spark/pull/32528#pullrequestreview-658778708",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "04b29b37-59c3-4f62-b04e-710ff51088c3",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "do we need this flag if we are sure `matchIterator` has at most one element?",
        "createdAt" : "2021-05-13T07:24:48Z",
        "updatedAt" : "2021-05-13T07:24:49Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "eeb803c9-a1a8-4344-a2cf-2bf739c89074",
        "parentId" : "04b29b37-59c3-4f62-b04e-710ff51088c3",
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "@cloud-fan - `matchIterator` will only has at most one element if join condition is empty. So yes we don't need this if join condition is empty. But consider the extra code is just a while loop check on `hasOutputRow`, and set value of `hasOutputRow`, I don't see much value to specialize another code-gen for left semi join without join condition. WDYT?",
        "createdAt" : "2021-05-13T08:19:10Z",
        "updatedAt" : "2021-05-13T08:19:15Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      },
      {
        "id" : "5f477737-ef19-49e3-972b-0c11397f58d5",
        "parentId" : "04b29b37-59c3-4f62-b04e-710ff51088c3",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I see, let's keep it",
        "createdAt" : "2021-05-13T10:30:35Z",
        "updatedAt" : "2021-05-13T10:30:35Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "6282a09d2b78aad102926f956a10d68272e05c8d",
    "line" : 316,
    "diffHunk" : "@@ -1,1 +809,813 @@       |while ($findNextJoinRows) {\n       |  $beforeLoop\n       |  boolean $hasOutputRow = false;\n       |\n       |  while (!$hasOutputRow && $matchIterator.hasNext()) {"
  },
  {
    "id" : "68cfcebd-91ea-456a-b5db-f233c592e227",
    "prId" : 32495,
    "prUrl" : "https://github.com/apache/spark/pull/32495#pullrequestreview-659520578",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "076002f0-6a4a-4742-ad7a-e52da1088386",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "If we have multiple SMJ in one whole-stage, will we have multiple `findNextJoinRows` methods in the outer class and fail the compilation?",
        "createdAt" : "2021-05-13T13:51:56Z",
        "updatedAt" : "2021-05-13T13:51:56Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "eba09739-b74f-45ad-a439-dc691a55a41e",
        "parentId" : "076002f0-6a4a-4742-ad7a-e52da1088386",
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "This is applying to inner join before this PR as well. There won't be an issue and we will never have multiple `findNextJoinRows` in one class. The reason is with current design, [sort merge join will always do code-gen for its children separately](https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/WholeStageCodegenExec.scala#L912), so there won't be two `SortMergeJoinExec`s code-gen-ed in the same class.\r\n\r\nVerified with example query:\r\n\r\n```\r\nval df1 = spark.range(10).select($\"id\".as(\"k1\"))\r\nval df2 = spark.range(4).select($\"id\".as(\"k2\"))\r\nval df3 = spark.range(6).select($\"id\".as(\"k3\"))\r\ndf3.join(df2.hint(\"SHUFFLE_MERGE\"), $\"k3\" === $\"k2\", \"left_outer\")\r\n  .join(df1.hint(\"SHUFFLE_MERGE\"), $\"k3\" === $\"k1\", \"right_outer\")\r\n  .explain(\"codegen\")\r\n```\r\n\r\nQuery plan:\r\n\r\n```\r\n*(8) SortMergeJoin [k3#10L], [k1#2L], RightOuter\r\n:- *(5) SortMergeJoin [k3#10L], [k2#6L], LeftOuter\r\n:  :- *(2) Sort [k3#10L ASC NULLS FIRST], false, 0\r\n:  :  +- Exchange hashpartitioning(k3#10L, 5), ENSURE_REQUIREMENTS, [id=#43]\r\n:  :     +- *(1) Project [id#8L AS k3#10L]\r\n:  :        +- *(1) Range (0, 6, step=1, splits=2)\r\n:  +- *(4) Sort [k2#6L ASC NULLS FIRST], false, 0\r\n:     +- Exchange hashpartitioning(k2#6L, 5), ENSURE_REQUIREMENTS, [id=#49]\r\n:        +- *(3) Project [id#4L AS k2#6L]\r\n:           +- *(3) Range (0, 4, step=1, splits=2)\r\n+- *(7) Sort [k1#2L ASC NULLS FIRST], false, 0\r\n   +- Exchange hashpartitioning(k1#2L, 5), ENSURE_REQUIREMENTS, [id=#58]\r\n      +- *(6) Project [id#0L AS k1#2L]\r\n         +- *(6) Range (0, 10, step=1, splits=2)\r\n```\r\n\r\nAll generated code is in https://gist.github.com/c21/873775bcd08583105b289e67221f6e17.",
        "createdAt" : "2021-05-13T23:29:41Z",
        "updatedAt" : "2021-05-13T23:29:42Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      },
      {
        "id" : "1b8f9469-3502-44be-b8b6-6723a2d9d609",
        "parentId" : "076002f0-6a4a-4742-ad7a-e52da1088386",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "got it, thanks!",
        "createdAt" : "2021-05-14T03:27:04Z",
        "updatedAt" : "2021-05-14T03:27:04Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "f17482ed-35b0-484b-88fc-a515bb0dd8e7",
        "parentId" : "076002f0-6a4a-4742-ad7a-e52da1088386",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "worth to add a comment for it, in case we changed this in the future (codegen one side with SMJ together)",
        "createdAt" : "2021-05-14T03:28:12Z",
        "updatedAt" : "2021-05-14T03:28:13Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "5c777c33-f53b-4fac-a069-bb41abbcfbe5",
        "parentId" : "076002f0-6a4a-4742-ad7a-e52da1088386",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "or we just make it future proof and create a fresh function name here.",
        "createdAt" : "2021-05-14T03:28:36Z",
        "updatedAt" : "2021-05-14T03:28:36Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "22231cf6-da4a-4c85-bdc2-23f188c9e750",
        "parentId" : "076002f0-6a4a-4742-ad7a-e52da1088386",
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "@cloud-fan - thanks for calling it out. I would like to make it future proof by giving it a fresh name. Let me do it in a followup PR. Actually I was wondering the same question as you when implementing and spent some time to figuring it out.",
        "createdAt" : "2021-05-14T05:05:58Z",
        "updatedAt" : "2021-05-14T05:05:58Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      }
    ],
    "commit" : "191243698d17978e1d4ed2bb966de2564926b309",
    "line" : 158,
    "diffHunk" : "@@ -1,1 +486,490 @@         |  return false; // unreachable\n         |}\n       \"\"\".stripMargin, inlineToOuterClass = true)\n\n    (streamedRow, matches)"
  },
  {
    "id" : "63d0a7b6-180e-4c76-a5a0-8934c748d9ca",
    "prId" : 32476,
    "prUrl" : "https://github.com/apache/spark/pull/32476#pullrequestreview-656304733",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9fa1f3ee-6a60-4924-8934-6fd7fcd7437e",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "```\r\n        // Eagerly return streamed row.\r\n        s\"\"\"\r\n           |$matches.clear();\r\n           |return false;\r\n         \"\"\".stripMargin\r\n```\r\n?",
        "createdAt" : "2021-05-09T14:01:08Z",
        "updatedAt" : "2021-05-11T09:17:07Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "c515a89c-a72f-413a-a98e-ddd032ca68eb",
        "parentId" : "9fa1f3ee-6a60-4924-8934-6fd7fcd7437e",
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "Wanted to avoid `clear()` if `isEmpty()` is true. `ExternalAppendOnlyUnsafeRowArray.isEmpty()` is very cheap but `clear()` sets multiple variables.",
        "createdAt" : "2021-05-10T00:25:54Z",
        "updatedAt" : "2021-05-11T09:17:07Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      },
      {
        "id" : "1425cdbf-6125-4343-8792-82c4f1319bfc",
        "parentId" : "9fa1f3ee-6a60-4924-8934-6fd7fcd7437e",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "I see. Could you leave some comments about it there?",
        "createdAt" : "2021-05-10T00:38:48Z",
        "updatedAt" : "2021-05-11T09:17:07Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "15e81b48-0317-408b-a93d-d26d5db57095",
        "parentId" : "9fa1f3ee-6a60-4924-8934-6fd7fcd7437e",
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "@maropu - added comment.",
        "createdAt" : "2021-05-11T05:53:33Z",
        "updatedAt" : "2021-05-11T09:17:07Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      }
    ],
    "commit" : "429edcc5b6ab11f600642fc61d5205da135ce083",
    "line" : 41,
    "diffHunk" : "@@ -1,1 +449,453 @@           |  $matches.clear();\n           |}\n           |return false;\n         \"\"\".stripMargin\n      case x =>"
  },
  {
    "id" : "bf2d9519-ec5e-42f2-99a0-df39beac753b",
    "prId" : 32476,
    "prUrl" : "https://github.com/apache/spark/pull/32476#pullrequestreview-655203734",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f8270dcd-949d-4639-ad88-fd2b1a3066ca",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "In the outer case, a return value is not used?",
        "createdAt" : "2021-05-09T23:47:28Z",
        "updatedAt" : "2021-05-11T09:17:07Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "f3e21a41-dc1f-4a1c-91b2-f5ae9c46df74",
        "parentId" : "f8270dcd-949d-4639-ad88-fd2b1a3066ca",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "It looks reusing the inner-case code makes the outer-case code inefficient. For example, if there are too many matched duplicate rows in the buffered side, it seems we don't need to put all the rows in `matches`, right?",
        "createdAt" : "2021-05-10T00:18:53Z",
        "updatedAt" : "2021-05-11T09:17:07Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "26f3f31a-86ad-473e-94ec-ddb8240d4615",
        "parentId" : "f8270dcd-949d-4639-ad88-fd2b1a3066ca",
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "> In the outer case, a return value is not used?\r\n\r\nYes. Otherwise it's very hard to re-use code in `findNextJoinRows`. I can further make more change to not return anything for `findNextJoinRows` in case it's an outer join. Do we want to do that?",
        "createdAt" : "2021-05-10T00:22:52Z",
        "updatedAt" : "2021-05-11T09:17:07Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      },
      {
        "id" : "3fac5715-e161-440d-ab76-c95fda73ce7c",
        "parentId" : "f8270dcd-949d-4639-ad88-fd2b1a3066ca",
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "> For example, if there are too many matched duplicate rows in the buffered side, it seems we don't need to put all the rows in matches, right?\r\n\r\nWhy we don't need to put all the rows? We anyway need to evaluate all the rows on buffered side for join, right?",
        "createdAt" : "2021-05-10T00:26:58Z",
        "updatedAt" : "2021-05-11T09:17:07Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      },
      {
        "id" : "506cc00a-d4b5-43e8-9bb1-0a1f3f10eff6",
        "parentId" : "f8270dcd-949d-4639-ad88-fd2b1a3066ca",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "> Why we don't need to put all the rows? We anyway need to evaluate all the rows on buffered side for join, right?\r\n\r\nOh, my bad. ya, you're right. I misunderstood it.",
        "createdAt" : "2021-05-10T00:42:55Z",
        "updatedAt" : "2021-05-11T09:17:07Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "64053a71-200e-4826-85a2-0e8eaa3833f1",
        "parentId" : "f8270dcd-949d-4639-ad88-fd2b1a3066ca",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "> In the outer case, a return value is not used?\r\nYes. Otherwise it's very hard to re-use code in findNextJoinRows. I can further make more change to not return anything for findNextJoinRows in case it's an outer join. Do we want to do that?\r\n\r\nokay, the current one looks fine. Let's just wait for a @cloud-fan comment here.",
        "createdAt" : "2021-05-10T00:44:54Z",
        "updatedAt" : "2021-05-11T09:17:07Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "b1c621af-0ab4-420b-a19d-8c2d44b06cbb",
        "parentId" : "f8270dcd-949d-4639-ad88-fd2b1a3066ca",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "btw, in the current generated code, it seems `conditionCheck` is evaluated outside `findNextJoinRows`. We cannot evaluate it inside `findNextJoinRows` to avoid putting unmached rows in `matches`?",
        "createdAt" : "2021-05-10T00:54:06Z",
        "updatedAt" : "2021-05-11T09:17:07Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "bfab61a8-0157-4368-8b6d-6e5714df7f0e",
        "parentId" : "f8270dcd-949d-4639-ad88-fd2b1a3066ca",
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "@maropu - No I think we need buffer anyway. The buffered rows has same join keys with current streamed row. But there can be multiple followed streamed rows having same join keys, as the buffered rows. Even though buffered rows cannot match condition with current streamed row, they may match condition with followed streamed rows. I think this is how current sort merge join (code-gen & iterator) is designed.",
        "createdAt" : "2021-05-10T03:25:24Z",
        "updatedAt" : "2021-05-11T09:17:07Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      }
    ],
    "commit" : "429edcc5b6ab11f600642fc61d5205da135ce083",
    "line" : 91,
    "diffHunk" : "@@ -1,1 +499,503 @@    ctx.addNewFunction(\"findNextJoinRows\",\n      s\"\"\"\n         |private boolean findNextJoinRows(\n         |    scala.collection.Iterator streamedIter,\n         |    scala.collection.Iterator bufferedIter) {"
  },
  {
    "id" : "1ab018a2-3764-4516-9109-a3cde1809025",
    "prId" : 32476,
    "prUrl" : "https://github.com/apache/spark/pull/32476#pullrequestreview-656314667",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e828db20-4d90-4846-8206-b7894ee0cb2f",
        "parentId" : null,
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "sorry forgot to change this in https://github.com/apache/spark/pull/32495, fix it now here. cc @maropu.",
        "createdAt" : "2021-05-11T06:12:10Z",
        "updatedAt" : "2021-05-11T09:17:07Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      }
    ],
    "commit" : "429edcc5b6ab11f600642fc61d5205da135ce083",
    "line" : 118,
    "diffHunk" : "@@ -1,1 +567,571 @@      streamedRow: String): (Seq[ExprCode], Seq[String]) = {\n    ctx.INPUT_ROW = streamedRow\n    streamedPlan.output.zipWithIndex.map { case (a, i) =>\n      val value = ctx.freshName(\"value\")\n      val valueCode = CodeGenerator.getValue(streamedRow, a.dataType, i.toString)"
  },
  {
    "id" : "4f1636f1-29d8-4440-9e36-32ee3c9b7e6d",
    "prId" : 32476,
    "prUrl" : "https://github.com/apache/spark/pull/32476#pullrequestreview-656476508",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9fa2e2d5-3ba4-4285-9a9c-5e52989473ff",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Can we add some comments to explain `findNextJoinRows`? Its \"return value\" is not just the boolean value, it can also change some states, like `bufferedRow = null`. We should explain how the states can be changed and what does it mean.",
        "createdAt" : "2021-05-11T06:50:24Z",
        "updatedAt" : "2021-05-11T09:17:07Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "670e9606-2fad-4a9c-b167-c35166a0d437",
        "parentId" : "9fa2e2d5-3ba4-4285-9a9c-5e52989473ff",
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "@cloud-fan - sure, updated with comment.",
        "createdAt" : "2021-05-11T09:17:40Z",
        "updatedAt" : "2021-05-11T09:17:44Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      }
    ],
    "commit" : "429edcc5b6ab11f600642fc61d5205da135ce083",
    "line" : 89,
    "diffHunk" : "@@ -1,1 +497,501 @@    //            2. Left/Right Outer join: keep the row and return false (with `matches` being\n    //                                      empty).\n    ctx.addNewFunction(\"findNextJoinRows\",\n      s\"\"\"\n         |private boolean findNextJoinRows("
  },
  {
    "id" : "b12c868b-8bf1-4125-9e9f-96f360c8bdd3",
    "prId" : 32476,
    "prUrl" : "https://github.com/apache/spark/pull/32476#pullrequestreview-657264552",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "76596633-d636-401b-8b7a-e4bd5ba36358",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "why can we safely clear the previous `matches`? Are we sure they are already outputed?",
        "createdAt" : "2021-05-11T09:49:54Z",
        "updatedAt" : "2021-05-11T09:50:01Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "ad32954d-5f7d-4c54-b2d0-7692e1638e6c",
        "parentId" : "76596633-d636-401b-8b7a-e4bd5ba36358",
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "@cloud-fan - here is my theory:\r\n\r\n1.Previously some `streamedRow` (say `row_a`) has non-empty `matches`.\r\n2.Current `streamedRow` (say `row_b`) has null join keys. `row_b` does not match with `row_a` (because `row_b` has null key but `row_a` does not have), so `row_b` does not match with `matches`.\r\n\r\nIt's safe to clear `matches` now as there won't be a future `streamedRow` (say `row_c`) to match with `matches`. If there's such `row_c`, then [`row_a`, `row_b`, `row_c`] is not valid sorted on join keys (because then the correct sort ordering should be [`row_a`, `row_c`, `row_b`]). So there's no such `row_c`, and it's safe to clear now.",
        "createdAt" : "2021-05-11T09:59:19Z",
        "updatedAt" : "2021-05-11T09:59:20Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      },
      {
        "id" : "f9e4a988-d0e8-4a51-b65b-93e7b9062b54",
        "parentId" : "76596633-d636-401b-8b7a-e4bd5ba36358",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Why it's not a problem for inner join?",
        "createdAt" : "2021-05-11T12:16:38Z",
        "updatedAt" : "2021-05-11T12:16:38Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "4772ccb8-4fb6-4987-b657-e3e49d46281b",
        "parentId" : "76596633-d636-401b-8b7a-e4bd5ba36358",
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "For streamed row with null keys, inner join will skip it, but left/right outer join (and left semi/anti join in followup) needs to output it. So for inner join we don't need to clear `matches` right away as the streamed row was not outputted. It seems to me it's not very good to have a streamed row with a non-cleared `matches` (which matches previous rows but not itself). We can change code to live with it but I feel it's not very clean.",
        "createdAt" : "2021-05-11T21:55:48Z",
        "updatedAt" : "2021-05-11T21:56:35Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      }
    ],
    "commit" : "429edcc5b6ab11f600642fc61d5205da135ce083",
    "line" : 78,
    "diffHunk" : "@@ -1,1 +486,490 @@    //            1. Inner join: skip the row. `matches` will be cleared later when hitting the\n    //                           next `streamedRow` with non-null join keys.\n    //            2. Left/Right Outer join: clear the previous `matches` if needed, keep the row,\n    //                                      and return false.\n    //"
  },
  {
    "id" : "91e98654-0c38-4215-a57b-89481c8d7529",
    "prId" : 29572,
    "prUrl" : "https://github.com/apache/spark/pull/29572#pullrequestreview-486546582",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3a229f01-ad68-4f53-87bd-615af435eafb",
        "parentId" : null,
        "authorId" : "e5beb795-ac0e-4bd6-ad66-708215b8ae58",
        "body" : "Thanks @peter-toth !\r\nI think this could be also added to LeftAnti join, which is also only interested in the existence of a match and doesn't need to buffer them.",
        "createdAt" : "2020-09-10T16:49:55Z",
        "updatedAt" : "2020-09-10T16:49:56Z",
        "lastEditedBy" : "e5beb795-ac0e-4bd6-ad66-708215b8ae58",
        "tags" : [
        ]
      },
      {
        "id" : "71c99c73-5983-4026-88cc-5d0f84f0113d",
        "parentId" : "3a229f01-ad68-4f53-87bd-615af435eafb",
        "authorId" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "body" : "Thanks @juliuszsompolski, I think you are right. Shall I open a follow-up PR or a different ticket?\r\n\r\n\r\n\r\n",
        "createdAt" : "2020-09-10T19:46:14Z",
        "updatedAt" : "2020-09-10T19:46:15Z",
        "lastEditedBy" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "tags" : [
        ]
      },
      {
        "id" : "e545f7fb-0c17-4f7b-a9d9-d7a4a6712c8d",
        "parentId" : "3a229f01-ad68-4f53-87bd-615af435eafb",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I think a followup PR is fine.",
        "createdAt" : "2020-09-11T03:45:55Z",
        "updatedAt" : "2020-09-11T03:45:56Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "8478ffcf-4be3-4aaa-a0f5-fdff7ef3b2a4",
        "parentId" : "3a229f01-ad68-4f53-87bd-615af435eafb",
        "authorId" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "body" : "I've opened https://github.com/apache/spark/pull/29727",
        "createdAt" : "2020-09-11T07:41:50Z",
        "updatedAt" : "2020-09-11T07:41:51Z",
        "lastEditedBy" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "tags" : [
        ]
      }
    ],
    "commit" : "f699118df05e25193a81c9bedce5b4eb10023079",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +253,257 @@              spillThreshold,\n              cleanupResources,\n              condition.isEmpty\n            )\n            private[this] val joinRow = new JoinedRow"
  },
  {
    "id" : "a618fb91-a4f3-4a8b-a871-01daeefa9099",
    "prId" : 27509,
    "prUrl" : "https://github.com/apache/spark/pull/27509#pullrequestreview-359352903",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2021791a-7304-45c0-849a-83b2cffcae0d",
        "parentId" : null,
        "authorId" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "body" : "It might not be related to this PR, but can we do the same thing as https://github.com/apache/spark/pull/27368/files#diff-ddb517fe44ae649ddda3c733c2adcb76R70 for joins? Just for symmetry and future handiness.",
        "createdAt" : "2020-02-12T17:40:18Z",
        "updatedAt" : "2020-02-21T03:10:15Z",
        "lastEditedBy" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "tags" : [
        ]
      },
      {
        "id" : "b5ca1ea9-051e-4199-b39c-0cccf54b1812",
        "parentId" : "2021791a-7304-45c0-849a-83b2cffcae0d",
        "authorId" : "c48b13f0-9ce5-4910-a8eb-aee1ac73ffcb",
        "body" : "Make `HashJoin` extend `BinaryExecNode`, and `ShuffledHashJoinExec/BroadcastHashJoinExec` extend `HashJoin`, right? Yea, I can make it here together :-)",
        "createdAt" : "2020-02-14T17:16:37Z",
        "updatedAt" : "2020-02-21T03:10:15Z",
        "lastEditedBy" : "c48b13f0-9ce5-4910-a8eb-aee1ac73ffcb",
        "tags" : [
        ]
      },
      {
        "id" : "bafbdb76-1cb2-4ed5-9df8-c2086c6c5a1c",
        "parentId" : "2021791a-7304-45c0-849a-83b2cffcae0d",
        "authorId" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "body" : "No. I meant creating a trait for all physical joins. It'll make pattern matching easier although we don't have this requirement right now. We could do it in a follow-up.",
        "createdAt" : "2020-02-14T19:46:41Z",
        "updatedAt" : "2020-02-21T03:10:15Z",
        "lastEditedBy" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "tags" : [
        ]
      },
      {
        "id" : "3a2ad06e-430c-493d-9eb1-47fde2575ae9",
        "parentId" : "2021791a-7304-45c0-849a-83b2cffcae0d",
        "authorId" : "c48b13f0-9ce5-4910-a8eb-aee1ac73ffcb",
        "body" : "Oh, yea. I just recall the conversation, thanks for your explanation :-)\r\nI'll submit a follow-up PR for joins accordingly. ",
        "createdAt" : "2020-02-15T01:35:29Z",
        "updatedAt" : "2020-02-21T03:10:15Z",
        "lastEditedBy" : "c48b13f0-9ce5-4910-a8eb-aee1ac73ffcb",
        "tags" : [
        ]
      },
      {
        "id" : "c5091fff-3236-4895-8f91-c42913ee8756",
        "parentId" : "2021791a-7304-45c0-849a-83b2cffcae0d",
        "authorId" : "c48b13f0-9ce5-4910-a8eb-aee1ac73ffcb",
        "body" : "PR https://github.com/apache/spark/pull/27595 opened for this follow-up.",
        "createdAt" : "2020-02-15T16:15:31Z",
        "updatedAt" : "2020-02-21T03:10:15Z",
        "lastEditedBy" : "c48b13f0-9ce5-4910-a8eb-aee1ac73ffcb",
        "tags" : [
        ]
      }
    ],
    "commit" : "1290cd523d6fdead5399923ea4acac450a5c2175",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +64,68 @@    s\"\"\"\n       |(${ExplainUtils.getOpId(this)}) $nodeName ${ExplainUtils.getCodegenId(this)}\n       |${ExplainUtils.generateFieldString(\"Left keys\", leftKeys)}\n       |${ExplainUtils.generateFieldString(\"Right keys\", rightKeys)}\n       |${ExplainUtils.generateFieldString(\"Join condition\", joinCondStr)}"
  },
  {
    "id" : "3ea58499-a4d7-47c1-8a19-79ecd8c25989",
    "prId" : 27493,
    "prUrl" : "https://github.com/apache/spark/pull/27493#pullrequestreview-356013785",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1e6feaaa-b3fb-4a03-b55d-65b68f87f1b7",
        "parentId" : null,
        "authorId" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "body" : "+1. Let's make it more explicit in the explain plan",
        "createdAt" : "2020-02-10T15:45:23Z",
        "updatedAt" : "2020-02-13T12:28:23Z",
        "lastEditedBy" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "tags" : [
        ]
      }
    ],
    "commit" : "b4a0606c240476d037a912e238b4a25e33b4e6da",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +42,46 @@    left: SparkPlan,\n    right: SparkPlan,\n    isSkewJoin: Boolean = false) extends BinaryExecNode with CodegenSupport {\n\n  override lazy val metrics = Map("
  }
]