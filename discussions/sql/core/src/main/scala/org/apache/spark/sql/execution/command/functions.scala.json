[
  {
    "id" : "50352302-568e-428b-9e13-06904ca735b6",
    "prId" : 31800,
    "prUrl" : "https://github.com/apache/spark/pull/31800#pullrequestreview-609309676",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "661afb88-907d-4c93-b45c-ab46c0d8bef6",
        "parentId" : null,
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "nit: shall we update the above comment in L123 `Hard code \"<>\", \"!=\", \"between\", and \"case\" ...` as well?",
        "createdAt" : "2021-03-10T23:52:37Z",
        "updatedAt" : "2021-03-11T01:04:36Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      },
      {
        "id" : "03685309-adf1-420c-826f-e3e470b5f7f6",
        "parentId" : "661afb88-907d-4c93-b45c-ab46c0d8bef6",
        "authorId" : "3a227965-84e0-47cf-9974-11293764f028",
        "body" : "Ah, right. I'll update it..",
        "createdAt" : "2021-03-11T01:01:12Z",
        "updatedAt" : "2021-03-11T01:04:36Z",
        "lastEditedBy" : "3a227965-84e0-47cf-9974-11293764f028",
        "tags" : [
        ]
      }
    ],
    "commit" : "2c62cca97225c664d2d10a9fa488d00ce49f0120",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +142,146 @@            \"When `expr1` = `expr2`, returns `expr3`; \" +\n            \"when `expr1` = `expr4`, return `expr5`; else return `expr6`.\") :: Nil\n      case \"||\" =>\n        Row(\"Function: ||\") ::\n          Row(\"Usage: expr1 || expr2 - Returns the concatenation of `expr1` and `expr2`.\") :: Nil"
  },
  {
    "id" : "2c7bc822-03b4-4fdd-b3db-2d4ff1c84ca1",
    "prId" : 28840,
    "prUrl" : "https://github.com/apache/spark/pull/28840#pullrequestreview-436305253",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0e4c9ec3-b172-4fe5-9361-0550baca6aee",
        "parentId" : null,
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "should this condition be a no op? or do we proactively register the function?",
        "createdAt" : "2020-06-24T02:04:14Z",
        "updatedAt" : "2020-07-21T12:12:06Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      },
      {
        "id" : "bb2c29a5-88bf-4ffb-a780-7ace82d92c11",
        "parentId" : "0e4c9ec3-b172-4fe5-9361-0550baca6aee",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "register function is light. I think it's ok to cache the function right away instead lazy.",
        "createdAt" : "2020-06-24T03:49:33Z",
        "updatedAt" : "2020-07-21T12:12:06Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "b18437c5998f5df50172732015f66b33c3908d2a",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +265,269 @@      // register overwrite function.\n      val func = catalog.getFunctionMetadata(identifier)\n      catalog.registerFunction(func, true)\n    } else {\n      // clear cached function and throw exception"
  },
  {
    "id" : "a20f9532-f32a-42a6-a8d2-22fac3aa3a4a",
    "prId" : 28840,
    "prUrl" : "https://github.com/apache/spark/pull/28840#pullrequestreview-447695818",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e2a6cb22-8b38-4d23-b2cd-d515c219f249",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Does `registerFunction` overwrite existing entry? If it does then we don't need to add `unregisterFunction` API.",
        "createdAt" : "2020-07-13T13:26:44Z",
        "updatedAt" : "2020-07-21T12:12:06Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "4c97cb87-b7b5-47cc-8367-bc176853e69c",
        "parentId" : "e2a6cb22-8b38-4d23-b2cd-d515c219f249",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "Changed.",
        "createdAt" : "2020-07-14T00:06:47Z",
        "updatedAt" : "2020-07-21T12:12:06Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "b18437c5998f5df50172732015f66b33c3908d2a",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +265,269 @@      // register overwrite function.\n      val func = catalog.getFunctionMetadata(identifier)\n      catalog.registerFunction(func, true)\n    } else {\n      // clear cached function and throw exception"
  },
  {
    "id" : "5cebca94-9d18-4492-964e-3c5bfcda04da",
    "prId" : 28840,
    "prUrl" : "https://github.com/apache/spark/pull/28840#pullrequestreview-452158970",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1c47b188-d2d0-46f0-b707-3be1c5fb259f",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I spent more time thinking about it, and feel like your original proposal is better. When people refreshing a function, they should expect the function to exist and want to use it later. It looks more consistent if we always fail REFRESH TABLE when the function doesn't exist in the catalog anymore.\r\n\r\nThat said, we can make `unregisterFunction` a noop if the function is not registered, and throw `NoSuchFunctionException` at the end.\r\n\r\nSorry for the back and forth!",
        "createdAt" : "2020-07-16T14:47:27Z",
        "updatedAt" : "2020-07-21T12:12:06Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "ce2fe0ca-11e4-477b-bea3-e1865b3cf720",
        "parentId" : "1c47b188-d2d0-46f0-b707-3be1c5fb259f",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "Thanks for your deep thinking! ",
        "createdAt" : "2020-07-17T00:09:04Z",
        "updatedAt" : "2020-07-21T12:12:06Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      },
      {
        "id" : "ec32e9a7-2537-466a-9790-0f9c47dfb5ab",
        "parentId" : "1c47b188-d2d0-46f0-b707-3be1c5fb259f",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can you change it? I'd expect something like\r\n```\r\ncatalog.unregisterFunction(identifier)\r\nthrow new NoSuchFunction...\r\n```",
        "createdAt" : "2020-07-21T06:26:26Z",
        "updatedAt" : "2020-07-21T12:12:06Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "b18437c5998f5df50172732015f66b33c3908d2a",
    "line" : 35,
    "diffHunk" : "@@ -1,1 +268,272 @@    } else {\n      // clear cached function and throw exception\n      catalog.unregisterFunction(identifier)\n      throw new NoSuchFunctionException(identifier.database.get, identifier.funcName)\n    }"
  },
  {
    "id" : "0418f34d-7552-4614-8b36-65c552ba7829",
    "prId" : 28840,
    "prUrl" : "https://github.com/apache/spark/pull/28840#pullrequestreview-469007701",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fa818f79-785c-4c0f-8bb3-1fd3f6120aa9",
        "parentId" : null,
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "We still can create persistent function with the same name as the built-in function. For example, \r\n\r\n```SQL\r\nCREATE FUNCTION rand AS 'org.apache.spark.sql.catalyst.expressions.Abs'\r\nDESC function default.rand\r\n```\r\n\r\nI think we should still allow this case. ",
        "createdAt" : "2020-08-16T23:20:39Z",
        "updatedAt" : "2020-08-16T23:20:39Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      },
      {
        "id" : "88efa6b7-6eb5-4be2-bf3c-2e1545b0c979",
        "parentId" : "fa818f79-785c-4c0f-8bb3-1fd3f6120aa9",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "It seems no meaning to refresh a persistent function whose name is same as a built-in function.\r\n\r\nYes, we can create a persistent function with the same name as the built-in function, but just create in metastore. The actual function we used is the built-in function. The reason is built-in functions are pre-cached in registry and we lookup cached function first.\r\n\r\ne.g., `CREATE FUNCTION rand AS 'xxx'`, `DESC FUNCTION rand` will always return `Class: org.apache.spark.sql.catalyst.expressions.Rand`.\r\n\r\nBTW, maybe it's the reason why we create function and load it lazy that just be a Hive client, otherwise we can't create such function like `rand`,`md5` in metastore. @cloud-fan ",
        "createdAt" : "2020-08-17T05:48:49Z",
        "updatedAt" : "2020-08-17T05:48:49Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      },
      {
        "id" : "e79eb775-51a8-479e-9ff5-b95b4ee7b9a0",
        "parentId" : "fa818f79-785c-4c0f-8bb3-1fd3f6120aa9",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "how about\r\n```\r\nCREATE FUNCTION rand AS 'xxx';\r\nDESC FUNCTION default.rand;\r\n```\r\n\r\nI think this is similar to table and temp views. Spark will try to look up temp view first, so if the name conflicts, temp view is preferred. But users can still use a qualified table name to read the table explicitly.",
        "createdAt" : "2020-08-18T04:49:39Z",
        "updatedAt" : "2020-08-18T04:49:39Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "23791d70-9677-44cb-927f-1bc4234bc917",
        "parentId" : "fa818f79-785c-4c0f-8bb3-1fd3f6120aa9",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "You are right.\r\n\r\nMissed qualified name case, I will fix this in followup.",
        "createdAt" : "2020-08-18T05:48:19Z",
        "updatedAt" : "2020-08-18T05:48:20Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "b18437c5998f5df50172732015f66b33c3908d2a",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +252,256 @@  override def run(sparkSession: SparkSession): Seq[Row] = {\n    val catalog = sparkSession.sessionState.catalog\n    if (FunctionRegistry.builtin.functionExists(FunctionIdentifier(functionName))) {\n      throw new AnalysisException(s\"Cannot refresh builtin function $functionName\")\n    }"
  },
  {
    "id" : "8762eb36-55a8-45a0-9d54-3be8c8782efb",
    "prId" : 28840,
    "prUrl" : "https://github.com/apache/spark/pull/28840#pullrequestreview-468178321",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0ddb9405-96e6-4ab4-8e8e-2643523601d9",
        "parentId" : null,
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "Nit: built-in",
        "createdAt" : "2020-08-16T23:21:00Z",
        "updatedAt" : "2020-08-16T23:21:01Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      },
      {
        "id" : "321aa88e-457f-4dec-ab7b-affe48ba8453",
        "parentId" : "0ddb9405-96e6-4ab4-8e8e-2643523601d9",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "get it.",
        "createdAt" : "2020-08-17T05:49:12Z",
        "updatedAt" : "2020-08-17T05:49:12Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "b18437c5998f5df50172732015f66b33c3908d2a",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +253,257 @@    val catalog = sparkSession.sessionState.catalog\n    if (FunctionRegistry.builtin.functionExists(FunctionIdentifier(functionName))) {\n      throw new AnalysisException(s\"Cannot refresh builtin function $functionName\")\n    }\n    if (catalog.isTemporaryFunction(FunctionIdentifier(functionName, databaseName))) {"
  }
]