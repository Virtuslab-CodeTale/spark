[
  {
    "id" : "2ae35048-9e9d-4d94-b88d-d2b447ab8e39",
    "prId" : 32754,
    "prUrl" : "https://github.com/apache/spark/pull/32754#pullrequestreview-675570405",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d4d736cd-ac27-4bf6-b7b7-7ac98be8ebf4",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "I guess `10000` is fine. I wonder if it's better to reduce the number to like 128 though. ",
        "createdAt" : "2021-06-03T02:35:54Z",
        "updatedAt" : "2021-06-03T02:35:54Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "6484722d-3efd-43ea-bb51-a2a9e665abb2",
        "parentId" : "d4d736cd-ac27-4bf6-b7b7-7ac98be8ebf4",
        "authorId" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "body" : "Do you think we wouldn't need to cache more than the top 128 metric names. It does makes sense. Just to be on the safer side, I set it to 10k. I don't think this should consume a lot of memory though. I am fine either way. Let me know your thoughts.",
        "createdAt" : "2021-06-03T17:46:01Z",
        "updatedAt" : "2021-06-03T17:46:01Z",
        "lastEditedBy" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "tags" : [
        ]
      }
    ],
    "commit" : "2cb9f8a8236d5c8b04cb4f9f50f7110b76276a33",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +97,101 @@\n  private val metricsCache: LoadingCache[String, Option[String]] =\n    CacheBuilder.newBuilder().maximumSize(10000)\n    .build(new CacheLoader[String, Option[String]] {\n      override def load(name: String): Option[String] = {"
  }
]