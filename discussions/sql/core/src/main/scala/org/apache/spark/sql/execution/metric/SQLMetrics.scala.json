[
  {
    "id" : "2ae35048-9e9d-4d94-b88d-d2b447ab8e39",
    "prId" : 32754,
    "prUrl" : "https://github.com/apache/spark/pull/32754#pullrequestreview-675570405",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d4d736cd-ac27-4bf6-b7b7-7ac98be8ebf4",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "I guess `10000` is fine. I wonder if it's better to reduce the number to like 128 though. ",
        "createdAt" : "2021-06-03T02:35:54Z",
        "updatedAt" : "2021-06-03T02:35:54Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "6484722d-3efd-43ea-bb51-a2a9e665abb2",
        "parentId" : "d4d736cd-ac27-4bf6-b7b7-7ac98be8ebf4",
        "authorId" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "body" : "Do you think we wouldn't need to cache more than the top 128 metric names. It does makes sense. Just to be on the safer side, I set it to 10k. I don't think this should consume a lot of memory though. I am fine either way. Let me know your thoughts.",
        "createdAt" : "2021-06-03T17:46:01Z",
        "updatedAt" : "2021-06-03T17:46:01Z",
        "lastEditedBy" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "tags" : [
        ]
      }
    ],
    "commit" : "2cb9f8a8236d5c8b04cb4f9f50f7110b76276a33",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +97,101 @@\n  private val metricsCache: LoadingCache[String, Option[String]] =\n    CacheBuilder.newBuilder().maximumSize(10000)\n    .build(new CacheLoader[String, Option[String]] {\n      override def load(name: String): Option[String] = {"
  },
  {
    "id" : "71fac13d-c653-4362-9c17-19441bff4075",
    "prId" : 28037,
    "prUrl" : "https://github.com/apache/spark/pull/28037#pullrequestreview-382311872",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "24bf8c26-9e1e-4f8c-be54-c70abda4651e",
        "parentId" : null,
        "authorId" : "3a227965-84e0-47cf-9974-11293764f028",
        "body" : "It's not obvious that this is for the case of driver so can we leave a comment for the readability?",
        "createdAt" : "2020-03-26T18:49:01Z",
        "updatedAt" : "2020-03-27T11:40:50Z",
        "lastEditedBy" : "3a227965-84e0-47cf-9974-11293764f028",
        "tags" : [
        ]
      }
    ],
    "commit" : "5838142ad2bee105af8c2c6b43d5edb45ea288a3",
    "line" : 71,
    "diffHunk" : "@@ -1,1 +182,186 @@      // common for driver-side SQL metrics.\n      if (validValues.length <= 1) {\n        toNumberFormat(validValues.headOption.getOrElse(0))\n      } else {\n        val Seq(min, med, max) = {"
  },
  {
    "id" : "820400e8-0c1d-470d-8c31-c83d57f25503",
    "prId" : 28037,
    "prUrl" : "https://github.com/apache/spark/pull/28037#pullrequestreview-382311872",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "273de51e-3cb7-4a34-8b96-80dcae38f4d6",
        "parentId" : null,
        "authorId" : "3a227965-84e0-47cf-9974-11293764f028",
        "body" : "Same as [here](https://github.com/apache/spark/pull/28037/files#diff-803f475b01acfae1c5c96807c2ea9ddcR182).",
        "createdAt" : "2020-03-26T18:50:34Z",
        "updatedAt" : "2020-03-27T11:40:50Z",
        "lastEditedBy" : "3a227965-84e0-47cf-9974-11293764f028",
        "tags" : [
        ]
      }
    ],
    "commit" : "5838142ad2bee105af8c2c6b43d5edb45ea288a3",
    "line" : 101,
    "diffHunk" : "@@ -1,1 +208,212 @@      // common for driver-side SQL metrics.\n      if (validValues.length <= 1) {\n        strFormat(validValues.headOption.getOrElse(0))\n      } else {\n        val Seq(sum, min, med, max) = {"
  }
]