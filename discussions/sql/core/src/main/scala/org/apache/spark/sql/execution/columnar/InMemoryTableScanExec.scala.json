[
  {
    "id" : "0e828618-3701-42e9-913d-875bf07ae227",
    "prId" : 25008,
    "prUrl" : "https://github.com/apache/spark/pull/25008#pullrequestreview-259828175",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c240fcd6-9ca0-4f23-9c41-b822ad8b95ee",
        "parentId" : null,
        "authorId" : "0f2e4443-2e01-4589-9e1c-17979892188b",
        "body" : "should `numOutputRows` be `max(numRows)`?",
        "createdAt" : "2019-07-09T17:24:33Z",
        "updatedAt" : "2019-07-10T15:36:54Z",
        "lastEditedBy" : "0f2e4443-2e01-4589-9e1c-17979892188b",
        "tags" : [
        ]
      },
      {
        "id" : "141cd5ed-a366-49e8-98f4-040dd1eb97fb",
        "parentId" : "c240fcd6-9ca0-4f23-9c41-b822ad8b95ee",
        "authorId" : "b19fe247-920f-40ae-83e7-6b8ec9979f6b",
        "body" : "no because `b` is a `ColumnarBatch`, so we are iterating over possibly multiple batches.  We are not iterating over individual columns.",
        "createdAt" : "2019-07-09T22:03:04Z",
        "updatedAt" : "2019-07-10T15:36:54Z",
        "lastEditedBy" : "b19fe247-920f-40ae-83e7-6b8ec9979f6b",
        "tags" : [
        ]
      },
      {
        "id" : "1e961b90-147c-48f2-b2fb-3bd99b6dbcc3",
        "parentId" : "c240fcd6-9ca0-4f23-9c41-b822ad8b95ee",
        "authorId" : "0f2e4443-2e01-4589-9e1c-17979892188b",
        "body" : "ah right, missed that. Thanks",
        "createdAt" : "2019-07-10T01:07:42Z",
        "updatedAt" : "2019-07-10T15:36:54Z",
        "lastEditedBy" : "0f2e4443-2e01-4589-9e1c-17979892188b",
        "tags" : [
        ]
      }
    ],
    "commit" : "2cce2fa9e057cb379e628fe01ea2cef280a9b198",
    "line" : 52,
    "diffHunk" : "@@ -1,1 +117,121 @@      .map(createAndDecompressColumn(_, offHeapColumnVectorEnabled))\n      .map(b => {\n        numOutputRows += b.numRows()\n        b\n      })"
  },
  {
    "id" : "0fedb0dd-11b8-4cfe-bbf6-9c899e3f9609",
    "prId" : 24696,
    "prUrl" : "https://github.com/apache/spark/pull/24696#pullrequestreview-242020377",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "33ee76bd-3135-42ba-a61f-3563fffb25f6",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "So, does this for the case when `addTaskCompletionListener` is not called yet?",
        "createdAt" : "2019-05-25T23:03:51Z",
        "updatedAt" : "2019-05-25T23:03:51Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "1ace36fb-12f3-49d4-9732-6c3be8a07801",
        "parentId" : "33ee76bd-3135-42ba-a61f-3563fffb25f6",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Yea.",
        "createdAt" : "2019-05-26T01:51:10Z",
        "updatedAt" : "2019-05-26T01:51:10Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "676ee35920cc194e3b96b5671a67370d394f380e",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +110,114 @@    // When the task is already completed, it is not valid to access a closed batch.\n    if (taskContext.nonEmpty && taskContext.get.isCompleted) {\n      columnarBatch.close()\n      None\n    } else {"
  },
  {
    "id" : "10736f5e-dfbf-4cd5-8d2a-f135f9bbc31b",
    "prId" : 24696,
    "prUrl" : "https://github.com/apache/spark/pull/24696#pullrequestreview-243164703",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "08a2cf40-e9a6-4c60-a18a-47024dc681e7",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "It's still possible that the task completes right after this check. I think it's OK to create unnecessary column vectors, as this is a corner case.",
        "createdAt" : "2019-05-29T08:20:18Z",
        "updatedAt" : "2019-05-29T08:20:18Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "28c18cfc-7642-42b7-aae6-4364b282ac3b",
        "parentId" : "08a2cf40-e9a6-4c60-a18a-47024dc681e7",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "OK. It's right.",
        "createdAt" : "2019-05-29T10:15:58Z",
        "updatedAt" : "2019-05-29T10:15:59Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "676ee35920cc194e3b96b5671a67370d394f380e",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +100,104 @@\n    // Decompress cached batch if the task is not completed, or there is no task context.\n    if (taskContext.isEmpty || !taskContext.get.isCompleted) {\n      for (i <- attributes.indices) {\n        ColumnAccessor.decompress("
  },
  {
    "id" : "6c87cfb4-5318-444c-abf2-322f8598fe96",
    "prId" : 24696,
    "prUrl" : "https://github.com/apache/spark/pull/24696#pullrequestreview-243193302",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6fdf9ea1-b113-4a2b-bd4e-18c39c3c93f5",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "https://github.com/apache/spark/pull/24696#discussion_r288445659 can also apply here. If so, we still return a closed batch. That said, seems we can't easily prevent the reader from accessing a closed batch.",
        "createdAt" : "2019-05-29T11:12:38Z",
        "updatedAt" : "2019-05-29T11:12:38Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "2b39ee00-7479-4c26-b70f-81e32748c589",
        "parentId" : "6fdf9ea1-b113-4a2b-bd4e-18c39c3c93f5",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "As now, the possible thread is shadowed in the writer thread. It's minor. And I have no better idea to avoid the accessing issue. So I will close this first.",
        "createdAt" : "2019-05-29T11:21:26Z",
        "updatedAt" : "2019-05-29T11:21:26Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "676ee35920cc194e3b96b5671a67370d394f380e",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +109,113 @@    }\n    // When the task is already completed, it is not valid to access a closed batch.\n    if (taskContext.nonEmpty && taskContext.get.isCompleted) {\n      columnarBatch.close()\n      None"
  }
]