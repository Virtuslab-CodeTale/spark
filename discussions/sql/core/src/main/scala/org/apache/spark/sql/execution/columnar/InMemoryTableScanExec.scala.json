[
  {
    "id" : "0e828618-3701-42e9-913d-875bf07ae227",
    "prId" : 25008,
    "prUrl" : "https://github.com/apache/spark/pull/25008#pullrequestreview-259828175",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c240fcd6-9ca0-4f23-9c41-b822ad8b95ee",
        "parentId" : null,
        "authorId" : "0f2e4443-2e01-4589-9e1c-17979892188b",
        "body" : "should `numOutputRows` be `max(numRows)`?",
        "createdAt" : "2019-07-09T17:24:33Z",
        "updatedAt" : "2019-07-10T15:36:54Z",
        "lastEditedBy" : "0f2e4443-2e01-4589-9e1c-17979892188b",
        "tags" : [
        ]
      },
      {
        "id" : "141cd5ed-a366-49e8-98f4-040dd1eb97fb",
        "parentId" : "c240fcd6-9ca0-4f23-9c41-b822ad8b95ee",
        "authorId" : "b19fe247-920f-40ae-83e7-6b8ec9979f6b",
        "body" : "no because `b` is a `ColumnarBatch`, so we are iterating over possibly multiple batches.  We are not iterating over individual columns.",
        "createdAt" : "2019-07-09T22:03:04Z",
        "updatedAt" : "2019-07-10T15:36:54Z",
        "lastEditedBy" : "b19fe247-920f-40ae-83e7-6b8ec9979f6b",
        "tags" : [
        ]
      },
      {
        "id" : "1e961b90-147c-48f2-b2fb-3bd99b6dbcc3",
        "parentId" : "c240fcd6-9ca0-4f23-9c41-b822ad8b95ee",
        "authorId" : "0f2e4443-2e01-4589-9e1c-17979892188b",
        "body" : "ah right, missed that. Thanks",
        "createdAt" : "2019-07-10T01:07:42Z",
        "updatedAt" : "2019-07-10T15:36:54Z",
        "lastEditedBy" : "0f2e4443-2e01-4589-9e1c-17979892188b",
        "tags" : [
        ]
      }
    ],
    "commit" : "2cce2fa9e057cb379e628fe01ea2cef280a9b198",
    "line" : 52,
    "diffHunk" : "@@ -1,1 +117,121 @@      .map(createAndDecompressColumn(_, offHeapColumnVectorEnabled))\n      .map(b => {\n        numOutputRows += b.numRows()\n        b\n      })"
  }
]