[
  {
    "id" : "d185e88a-dccd-40e1-b619-3ab1668e3086",
    "prId" : 32361,
    "prUrl" : "https://github.com/apache/spark/pull/32361#pullrequestreview-647939127",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "57140e0b-e129-4478-9459-f6e7a582153c",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "not related to this PR: I think it's better to document clearly that whether the path parameter should be relative or qualified, in all the methods of this trait, even if this is just an internal API.",
        "createdAt" : "2021-04-29T08:16:55Z",
        "updatedAt" : "2021-04-29T18:25:11Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "c33eb151-4dea-43b4-9fe7-5a3e769b252f",
        "parentId" : "57140e0b-e129-4478-9459-f6e7a582153c",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Good point. I roughly looked at few places, seems the used parameter is absolute path, though not qualified.",
        "createdAt" : "2021-04-29T08:28:27Z",
        "updatedAt" : "2021-04-29T18:25:11Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "466d353c986c8a76f3b0c31c116f8d62c4fa0321",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +91,95 @@  def createCheckpointDirectory(): Path\n}\n\nobject CheckpointFileManager extends Logging {\n"
  },
  {
    "id" : "7448e53e-1b94-4add-a8d8-8408a816ab01",
    "prId" : 30290,
    "prUrl" : "https://github.com/apache/spark/pull/30290#pullrequestreview-525843511",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f2bd2594-cddf-42f7-8e43-ea68d33e82ca",
        "parentId" : null,
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "do we need to fix `close()` method as well since seems it also doesn't handle IO exception from `underlyingStream.close()`?",
        "createdAt" : "2020-11-08T19:43:57Z",
        "updatedAt" : "2020-11-08T20:05:04Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "8dc9eab1-a268-44cc-aeb9-198a38162cd5",
        "parentId" : "f2bd2594-cddf-42f7-8e43-ea68d33e82ca",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "<del>`cancel` is called to abandon the temporary output, so if it is just non fatal exception, we don't handle it. </del>",
        "createdAt" : "2020-11-08T19:51:34Z",
        "updatedAt" : "2020-11-08T20:06:02Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "fa489f9e-6e19-4af5-9b4d-02cfae034dbe",
        "parentId" : "f2bd2594-cddf-42f7-8e43-ea68d33e82ca",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Oh misreading your question. `close` cannot ignore the IO exception from `underlyingStream.close`. So it doesn't catch it. Such exception will fail the streaming query.",
        "createdAt" : "2020-11-08T20:02:26Z",
        "updatedAt" : "2020-11-08T20:05:04Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "ea661dc0-3ae8-4eed-b9f3-5a927464653c",
        "parentId" : "f2bd2594-cddf-42f7-8e43-ea68d33e82ca",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "Ah I see. Thanks.",
        "createdAt" : "2020-11-08T20:46:00Z",
        "updatedAt" : "2020-11-08T20:46:00Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      }
    ],
    "commit" : "334375a7d0b9f88b1186732f0c1424b1c4638e87",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +161,165 @@      try {\n        if (terminated) return\n        try {\n          underlyingStream.close()\n        } catch {"
  },
  {
    "id" : "85de65cc-e351-42b2-960f-386445553613",
    "prId" : 25488,
    "prUrl" : "https://github.com/apache/spark/pull/25488#pullrequestreview-276760606",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "16e6a50c-a5b8-47ab-990b-1ac6379c5be4",
        "parentId" : null,
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "The ideal behavior would be renaming crc file to be matched with dstPath, but in SPARK-17475 seems like we just decided to remove the crc file, so I guess this is OK.",
        "createdAt" : "2019-08-18T22:04:24Z",
        "updatedAt" : "2019-08-23T01:27:17Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      },
      {
        "id" : "9944bcd9-6fd2-4c08-bbe0-d5e587848532",
        "parentId" : "16e6a50c-a5b8-47ab-990b-1ac6379c5be4",
        "authorId" : "2d6b46ba-4100-4c4d-9341-fff5e39647ec",
        "body" : "Is it possible to detect whether checksum is enabled? If it's disabled, we can save an `exists` call.",
        "createdAt" : "2019-08-19T17:00:21Z",
        "updatedAt" : "2019-08-23T01:27:17Z",
        "lastEditedBy" : "2d6b46ba-4100-4c4d-9341-fff5e39647ec",
        "tags" : [
        ]
      },
      {
        "id" : "a1d7ecac-22d7-4b09-ba50-c2909142ba00",
        "parentId" : "16e6a50c-a5b8-47ab-990b-1ac6379c5be4",
        "authorId" : "2d6b46ba-4100-4c4d-9341-fff5e39647ec",
        "body" : "NVM. Just saw your latest comment.",
        "createdAt" : "2019-08-19T17:02:25Z",
        "updatedAt" : "2019-08-23T01:27:17Z",
        "lastEditedBy" : "2d6b46ba-4100-4c4d-9341-fff5e39647ec",
        "tags" : [
        ]
      },
      {
        "id" : "609ab014-adbf-49fb-8001-5156cfe180ab",
        "parentId" : "16e6a50c-a5b8-47ab-990b-1ac6379c5be4",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "Yeah, please feel free to let me know if we prefer alternative approach - I can make a change.",
        "createdAt" : "2019-08-19T19:16:08Z",
        "updatedAt" : "2019-08-23T01:27:17Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      }
    ],
    "commit" : "376b7eb102532c87e27e2008866f868fa87951b8",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +329,333 @@    fc.rename(srcPath, dstPath, if (overwriteIfPossible) OVERWRITE else NONE)\n    // TODO: this is a workaround of HADOOP-16255 - remove this when HADOOP-16255 is resolved\n    mayRemoveCrcFile(srcPath)\n  }\n"
  }
]