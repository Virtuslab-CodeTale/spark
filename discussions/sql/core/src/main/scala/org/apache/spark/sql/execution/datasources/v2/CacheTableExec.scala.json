[
  {
    "id" : "0234e9e5-d72c-462d-baa2-d454192a2d9b",
    "prId" : 32032,
    "prUrl" : "https://github.com/apache/spark/pull/32032#pullrequestreview-630924272",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cf4deee7-2747-46e9-97ea-69e0fd97e976",
        "parentId" : null,
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "We can just call `run` now that the `plan` is analyzed; no need to go thru `Dataset.ofRows`.",
        "createdAt" : "2021-04-08T02:17:22Z",
        "updatedAt" : "2021-04-14T03:19:24Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "111ef8be8bc03a62389aed4f0871b958714eb789",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +106,110 @@      viewType = LocalTempView,\n      isAnalyzed = true\n    ).run(sparkSession)\n\n    dataFrameForCachedPlan.logicalPlan"
  },
  {
    "id" : "48e16ed0-2fa6-4d2a-8288-ea1a3d53e8b9",
    "prId" : 31933,
    "prUrl" : "https://github.com/apache/spark/pull/31933#pullrequestreview-618860834",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e0baf934-3943-4b9a-8f8f-006bff98a2c6",
        "parentId" : null,
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "@cloud-fan If we make `query` as `child` of `CacheTableAsSelectExec`, it will be an optimized plan instead of an analyzed plan, which can be problematic when looking up the cached plan. One way to work around is to move matching `CacheTableAsSelect` back to `ResolveSessionCatalog`... Any thought?",
        "createdAt" : "2021-03-22T19:18:24Z",
        "updatedAt" : "2021-03-25T03:52:40Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      },
      {
        "id" : "b798f20d-91d0-4c0f-9735-02c2e2988e0d",
        "parentId" : "e0baf934-3943-4b9a-8f8f-006bff98a2c6",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "The current code looks fine.  I think `CacheTableAsSelectExec` is the only exception that it has a `query` which is not a simple table relation but we want to skip optimizing it. Let's document this clearly.",
        "createdAt" : "2021-03-23T04:51:30Z",
        "updatedAt" : "2021-03-25T03:52:40Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "ad4c573e-7f9b-4f1a-bc27-7004dd668195",
        "parentId" : "e0baf934-3943-4b9a-8f8f-006bff98a2c6",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "thanks, updated.",
        "createdAt" : "2021-03-23T17:20:30Z",
        "updatedAt" : "2021-03-25T03:52:40Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "507b00c34058cf52f430641078e44a0c1fc0be84",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +100,104 @@    val qe = sparkSession.sessionState.executePlan(query)\n    qe.assertAnalyzed()\n    val analyzedPlan = qe.analyzed\n\n    Dataset.ofRows(sparkSession,"
  },
  {
    "id" : "b0f3bd39-d1fd-4a06-ace0-2d40735af0f6",
    "prId" : 31933,
    "prUrl" : "https://github.com/apache/spark/pull/31933#pullrequestreview-621822414",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c11c4486-f89d-4697-8de5-2ffa5be6aa96",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Can we further clean this up by creating `CreateViewStatement` instead of `CreateViewCommand` below?",
        "createdAt" : "2021-03-26T06:43:22Z",
        "updatedAt" : "2021-03-26T06:43:22Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "507b00c34058cf52f430641078e44a0c1fc0be84",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +97,101 @@    // CacheTableAsSelectExec.query is not resolved yet (e.g., not a child of CacheTableAsSelect)\n    // in order to skip optimizing it; note that we need to pass an analyzed plan to\n    // CreateViewCommand for the cache to work correctly. Thus, the query is analyzed below.\n    val qe = sparkSession.sessionState.executePlan(query)\n    qe.assertAnalyzed()"
  }
]