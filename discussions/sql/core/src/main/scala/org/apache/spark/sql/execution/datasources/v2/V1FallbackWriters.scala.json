[
  {
    "id" : "f4675838-4498-491d-99de-7075b77f3504",
    "prId" : 30806,
    "prUrl" : "https://github.com/apache/spark/pull/30806#pullrequestreview-554299839",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fa4850e7-5cba-47aa-8642-0f5d3c210536",
        "parentId" : null,
        "authorId" : "f5b3f57a-75a6-496c-af94-c32580ada13a",
        "body" : "Nicely simplified",
        "createdAt" : "2020-12-17T05:59:38Z",
        "updatedAt" : "2020-12-21T15:35:33Z",
        "lastEditedBy" : "f5b3f57a-75a6-496c-af94-c32580ada13a",
        "tags" : [
        ]
      }
    ],
    "commit" : "882e3210004c0e27aca914b58819008dafdde92a",
    "line" : 104,
    "diffHunk" : "@@ -1,1 +81,85 @@  def plan: LogicalPlan\n\n  protected def writeWithV1(relation: InsertableRelation): Seq[InternalRow] = {\n    relation.insert(Dataset.ofRows(sqlContext.sparkSession, plan), overwrite = false)\n    Nil"
  },
  {
    "id" : "fc4ca4b7-506a-4052-93f4-2b22071ca52f",
    "prId" : 25569,
    "prUrl" : "https://github.com/apache/spark/pull/25569#pullrequestreview-286467535",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8ed126de-c999-445b-947f-896fd4401a8f",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I think `AlreadyPlanned` works well here, as a top-level node. However, there can be problems if we make the framework too general and support using `AlreadyPlanned` as a non-top-levle node.\r\n\r\nThe physical plan has no stats, so `AlreadyPlanned` has no stats as well. This may change the planning result if the original logical plan has stats, e.g. broadcast join becomes sort merge join.",
        "createdAt" : "2019-08-26T04:41:04Z",
        "updatedAt" : "2019-09-23T02:05:40Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "d49c5e61-979e-46a4-8804-318562925a5b",
        "parentId" : "8ed126de-c999-445b-947f-896fd4401a8f",
        "authorId" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "body" : "+1. It's probably not worth saving the compilation time if we end up generating a bad plan. ",
        "createdAt" : "2019-09-10T22:21:47Z",
        "updatedAt" : "2019-09-23T02:05:40Z",
        "lastEditedBy" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "tags" : [
        ]
      }
    ],
    "commit" : "2bd20c016a3b3df08d38cde4a005271a49f47f81",
    "line" : 55,
    "diffHunk" : "@@ -1,1 +113,117 @@\n  protected def writeWithV1(relation: InsertableRelation): RDD[InternalRow] = {\n    relation.insert(AlreadyPlanned.dataFrame(sqlContext.sparkSession, query), overwrite = false)\n    sparkContext.emptyRDD\n  }"
  }
]