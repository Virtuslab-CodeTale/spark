[
  {
    "id" : "f4675838-4498-491d-99de-7075b77f3504",
    "prId" : 30806,
    "prUrl" : "https://github.com/apache/spark/pull/30806#pullrequestreview-554299839",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fa4850e7-5cba-47aa-8642-0f5d3c210536",
        "parentId" : null,
        "authorId" : "f5b3f57a-75a6-496c-af94-c32580ada13a",
        "body" : "Nicely simplified",
        "createdAt" : "2020-12-17T05:59:38Z",
        "updatedAt" : "2020-12-21T15:35:33Z",
        "lastEditedBy" : "f5b3f57a-75a6-496c-af94-c32580ada13a",
        "tags" : [
        ]
      }
    ],
    "commit" : "882e3210004c0e27aca914b58819008dafdde92a",
    "line" : 104,
    "diffHunk" : "@@ -1,1 +81,85 @@  def plan: LogicalPlan\n\n  protected def writeWithV1(relation: InsertableRelation): Seq[InternalRow] = {\n    relation.insert(Dataset.ofRows(sqlContext.sparkSession, plan), overwrite = false)\n    Nil"
  }
]