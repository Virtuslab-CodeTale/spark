[
  {
    "id" : "288b644a-1981-4fd9-b338-a7c4ecfc9445",
    "prId" : 24596,
    "prUrl" : "https://github.com/apache/spark/pull/24596#pullrequestreview-239202280",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "12a38cf9-00d3-4aa9-98b2-6d1fb7e59c60",
        "parentId" : null,
        "authorId" : "88415353-b462-4a22-8116-e3955add54a7",
        "body" : "It looks like a specific requirement.Maybe it should use 'ANALYZE TABLE <tablename> COMPUTE STATISTICS'.",
        "createdAt" : "2019-05-16T09:18:44Z",
        "updatedAt" : "2019-05-16T09:18:44Z",
        "lastEditedBy" : "88415353-b462-4a22-8116-e3955add54a7",
        "tags" : [
        ]
      },
      {
        "id" : "c4fdec22-cef1-4164-b7dc-810dcb7fe53e",
        "parentId" : "12a38cf9-00d3-4aa9-98b2-6d1fb7e59c60",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "We should automatically collect it once `spark.sql.statistics.size.autoUpdate.enabled=true`. right?",
        "createdAt" : "2019-05-18T15:31:18Z",
        "updatedAt" : "2019-05-18T15:31:18Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      }
    ],
    "commit" : "914f85a9ec406f011b1806b3debca12280280757",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +194,198 @@    }\n\n    CommandUtils.updateTableStats(sparkSession, table)\n\n    Seq.empty[Row]"
  }
]