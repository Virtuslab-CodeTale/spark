[
  {
    "id" : "4b2315ac-8203-4cc4-8e42-2e3c81bc6b5b",
    "prId" : 30427,
    "prUrl" : "https://github.com/apache/spark/pull/30427#pullrequestreview-536770995",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6a25be89-ad43-4422-8bed-0e3e482f8742",
        "parentId" : null,
        "authorId" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "body" : "Fully agree with `knowing the gap between actual wall clock and watermark looks more useful than the absolute value.` and thanks for the super useful watermark info!\r\n\r\nI only have one concern same with @viirya https://github.com/apache/spark/pull/30427#issuecomment-730852396. Maybe we can address both scenarios(event time is/isn't close to clock time) by using the max event time received in this batch? I mean:\r\n```\r\n         if (watermarkValue > 0L) {\r\n           // seconds\r\n-          Some((batchTimestamp, ((batchTimestamp - watermarkValue) / 1000.0)))\r\n+          val maxEventTime = parseProgressTimestamp(p.eventTime.get(\"max\"))\r\n+          Some((batchTimestamp, (maxEventTime - watermarkValue) / 1000.0))\r\n         } else {\r\n           None\r\n         }\r\n```\r\n\r\nOf cause this proposal changes the meaning of this chart, it represents `The gap between the latest event \r\n and global watermark for the batch`. And we might need to add more explanation here since the number will be negative when all the data in the current batch is late than the current watermark(it can be reproduced by the complex demo provided). WDYT? @HeartSaVioR @viirya ",
        "createdAt" : "2020-11-23T08:53:45Z",
        "updatedAt" : "2020-11-24T22:46:17Z",
        "lastEditedBy" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "tags" : [
        ]
      },
      {
        "id" : "1a7cfabf-3de1-4087-a5a2-031982efcc9d",
        "parentId" : "6a25be89-ad43-4422-8bed-0e3e482f8742",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "I'm sorry, but when you pick the max event time, you're discarding the gap between wall clock and event time. The intention of showing watermark gap is showing the \"gap\" between \"the event time\" of events (which finally produces watermark) and \"wall clock\".\r\n\r\nWould this answer your comment?",
        "createdAt" : "2020-11-23T09:06:08Z",
        "updatedAt" : "2020-11-24T22:46:17Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      },
      {
        "id" : "30c982ee-ce87-4a3f-ad34-1e7d18323c77",
        "parentId" : "6a25be89-ad43-4422-8bed-0e3e482f8742",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "Probably we can represent various aspect of views if we plot all points (wall clock, max event time, global watermark, etc. like min event time). As I'm not a FE and don't like to jump in and hack the code around graph, I just stick with one line and decide to plot the line for the gap between wall clock and global watermark.\r\n\r\nIf someone is interested to do some experiment with the graph, plotting all lines and finding relations and deciding lines to keep would be valuable.",
        "createdAt" : "2020-11-23T09:32:08Z",
        "updatedAt" : "2020-11-24T22:46:17Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      },
      {
        "id" : "37a1d031-9b03-4be3-87e5-e98a77829bfa",
        "parentId" : "6a25be89-ad43-4422-8bed-0e3e482f8742",
        "authorId" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "body" : "Yeah, that depends on how we define `watermark gap` here.\r\nThese 2 definitions will not show a difference in result in the ideal case. My point is as the watermark is decided by event time, seems it should make more sense to use both event time to get the `gap`.",
        "createdAt" : "2020-11-23T09:32:24Z",
        "updatedAt" : "2020-11-24T22:46:17Z",
        "lastEditedBy" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "tags" : [
        ]
      },
      {
        "id" : "6a98dda7-4cfc-47f6-a1d7-b56fa28d700f",
        "parentId" : "6a25be89-ad43-4422-8bed-0e3e482f8742",
        "authorId" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "body" : "`we can represent various aspect of views if we plot all points`\r\nYeah agree, if a multi-line chart is available here might be helpful here! :)\r\n\r\nActually, this idea came when I was thinking about the `ideal line` for the historical streaming data that should be using event time to represent processing time, not current clock time.\r\n\r\nAnyway, just want to post a different explanation of the `watermark gap` here, the current changes LGTM. If others think it's worth having another event-based gap maybe we can do it at another timeline.",
        "createdAt" : "2020-11-23T09:50:30Z",
        "updatedAt" : "2020-11-24T22:46:17Z",
        "lastEditedBy" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "tags" : [
        ]
      },
      {
        "id" : "d928a833-ddcf-4947-829f-642cdee357cb",
        "parentId" : "6a25be89-ad43-4422-8bed-0e3e482f8742",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "More correctly, how we define the \"processing time\" in the graph in https://github.com/apache/spark/pull/30427#issuecomment-730844687. (y axis) \r\n\r\nThe query which pulls recent events are expected to have processing time as wall clock. That is only broken when we deal with historical data - that's not having the \"ideal\" processing time. One of approaches which can rough guess would be tracking event time, but given Spark takes max event time to calculate watermark (while other engines take min event time) the gap is more likely pretty much similar across batches.\r\n\r\nIn historical case, as well as real time case (as Spark picks max event time), tracking the gap between global watermark and min event time would be more helpful, as we can at least see whether the watermark delay is enough to cover the min event time of the next batch. This is pretty specific to Spark's case, though.\r\n\r\n(So likewise I said, there're several useful lines to plot which can be compared between and produce the meaning. I just don't take the step to go my life for frontend engineer.)",
        "createdAt" : "2020-11-23T10:02:03Z",
        "updatedAt" : "2020-11-24T22:46:17Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      },
      {
        "id" : "f672242b-9f63-44a1-99d3-200265c6fa7e",
        "parentId" : "6a25be89-ad43-4422-8bed-0e3e482f8742",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "OK I took too many efforts to write the comment and wrote too late. In short, if we can pick the second metric to compare with global watermark, it should be min instead of max. If Spark also picks min event time to construct watermark, we should pick max to see how much the output is lagging due to slow watermark advance.",
        "createdAt" : "2020-11-23T10:04:52Z",
        "updatedAt" : "2020-11-24T22:46:17Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      },
      {
        "id" : "cbdc1f11-75b4-496c-989e-5dcec9332425",
        "parentId" : "6a25be89-ad43-4422-8bed-0e3e482f8742",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Thanks @xuanyuanking for raising this discussion.\r\n\r\n> OK I took too many efforts to write the comment and wrote too late. In short, if we can pick the second metric to compare with global watermark, it should be min instead of max. If Spark also picks min event time to construct watermark, we should pick max to see how much the output is lagging due to slow watermark advance.\r\n\r\nI agree. Actually my first thought is to use min event time instead of batch time in this graph.\r\n\r\nI think a ideal approach should be able to select different base time for constructing this graph, e.g. min event time or batch time. I am not sure if current UI component supports this kind of feature. But for current change, I think it should be good enough for use cases except for event time is far from clock time. That is why I gave +1 for this PR.\r\n",
        "createdAt" : "2020-11-23T18:00:42Z",
        "updatedAt" : "2020-11-24T22:46:17Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "d04da101-82db-40f6-ad6e-f18edc7e5b11",
        "parentId" : "6a25be89-ad43-4422-8bed-0e3e482f8742",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "Yeah it should be great if someone who is familiar with the FE volunteers to revise the graphs. I actually think other existing graphs are also not that ideal. (in point of auto-scale, multiple lines plotting, better unit & value & tooltip)",
        "createdAt" : "2020-11-23T19:13:27Z",
        "updatedAt" : "2020-11-24T22:46:17Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      }
    ],
    "commit" : "a6db726c10ba999077a03d90231c8224d2a4a621",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +154,158 @@        if (watermarkValue > 0L) {\n          // seconds\n          Some((batchTimestamp, ((batchTimestamp - watermarkValue) / 1000.0)))\n        } else {\n          None"
  },
  {
    "id" : "7cba797b-d956-4c0c-a3b9-fba35b1004f2",
    "prId" : 30336,
    "prUrl" : "https://github.com/apache/spark/pull/30336#pullrequestreview-532388282",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cc0c88ac-97fa-490b-98f8-98af608f8063",
        "parentId" : null,
        "authorId" : "3a227965-84e0-47cf-9974-11293764f028",
        "body" : "Does this work if there are multiple state operators in the query plan and they have different custom metrics?",
        "createdAt" : "2020-11-16T09:33:36Z",
        "updatedAt" : "2020-11-24T18:09:50Z",
        "lastEditedBy" : "3a227965-84e0-47cf-9974-11293764f028",
        "tags" : [
        ]
      },
      {
        "id" : "b395e178-e2b1-4b83-9abb-7f0c220e84c7",
        "parentId" : "cc0c88ac-97fa-490b-98f8-98af608f8063",
        "authorId" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "body" : "This is working because all state operator must have the exact same number of custom metrics. The names are coming from `head` and the values from `query.recentProgress`.",
        "createdAt" : "2020-11-16T09:47:11Z",
        "updatedAt" : "2020-11-24T18:09:50Z",
        "lastEditedBy" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "tags" : [
        ]
      },
      {
        "id" : "0208804e-ca5f-4be0-8609-cb42988e01e4",
        "parentId" : "cc0c88ac-97fa-490b-98f8-98af608f8063",
        "authorId" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "body" : "One additional thing, please see that the timeline and histogram aggregated...",
        "createdAt" : "2020-11-16T09:56:55Z",
        "updatedAt" : "2020-11-24T18:09:50Z",
        "lastEditedBy" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "tags" : [
        ]
      },
      {
        "id" : "6161e33a-e97b-4804-8ce0-5cdb225ed79b",
        "parentId" : "cc0c88ac-97fa-490b-98f8-98af608f8063",
        "authorId" : "3a227965-84e0-47cf-9974-11293764f028",
        "body" : "> This is working because all state operator must have the exact same number of custom metrics. \r\n\r\n@HeartSaVioR you added `customMetrics` to `StateOperatorProgress` in #21469 .\r\nDid you intend that all the state operators in a query should have the same number / type of custom metrics?\r\nIn other words, each state operator should not have its own custom metrics right?",
        "createdAt" : "2020-11-16T11:32:51Z",
        "updatedAt" : "2020-11-24T18:09:50Z",
        "lastEditedBy" : "3a227965-84e0-47cf-9974-11293764f028",
        "tags" : [
        ]
      },
      {
        "id" : "d62edb03-af1a-4eb3-833b-06b20743659e",
        "parentId" : "cc0c88ac-97fa-490b-98f8-98af608f8063",
        "authorId" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "body" : "@sarutak nice catch, that's definitely not tested and the code will blow up.\r\n@HeartSaVioR If operator `O1` has custom metric `C1` and operator `O2` has custom metric `C2` then the currently implemented aggregation is not fine.\r\n",
        "createdAt" : "2020-11-16T12:15:05Z",
        "updatedAt" : "2020-11-24T18:09:50Z",
        "lastEditedBy" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "tags" : [
        ]
      },
      {
        "id" : "1f591c96-824b-4fde-808e-e875ad17bbfc",
        "parentId" : "cc0c88ac-97fa-490b-98f8-98af608f8063",
        "authorId" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "body" : "Solved all other comments but leaving this open because this can be a major issue w/ big influence on the PR.\r\nLet's wait on the answer and adjust the code/tests based on that (as said this case not tested because of maybe bad assumption).",
        "createdAt" : "2020-11-16T12:54:28Z",
        "updatedAt" : "2020-11-24T18:09:50Z",
        "lastEditedBy" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "tags" : [
        ]
      },
      {
        "id" : "8fcf436d-12b2-4bd8-a661-17556076b17d",
        "parentId" : "cc0c88ac-97fa-490b-98f8-98af608f8063",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "The custom metrics is bound to the `state store provider` instead of `operator`.\r\n\r\nGiven the provider instances are created per state store id, it's not technically impossible for provider to provide different custom metrics, but at least that's not a purpose and you'll wonder how to leverage the flexibility. These metrics are for state itself, not related to the operator.",
        "createdAt" : "2020-11-16T21:55:05Z",
        "updatedAt" : "2020-11-24T18:09:50Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      },
      {
        "id" : "e1cb6ec1-5f0c-4ffc-8c9d-4754fbd30cbb",
        "parentId" : "cc0c88ac-97fa-490b-98f8-98af608f8063",
        "authorId" : "3a227965-84e0-47cf-9974-11293764f028",
        "body" : "`StateStoreWriter#getProgress` is not marked as `final` so I wondered it's intended to have sub classes which override `getProgress` where custom metrics can be created for a operator which is implemented as a sub class of `StateStoreWriter`.\r\nBut now I understand that custom metrics are not for operators.",
        "createdAt" : "2020-11-17T02:19:44Z",
        "updatedAt" : "2020-11-24T18:09:50Z",
        "lastEditedBy" : "3a227965-84e0-47cf-9974-11293764f028",
        "tags" : [
        ]
      },
      {
        "id" : "f7a954e3-5a2e-496a-a578-b29ff1aca283",
        "parentId" : "cc0c88ac-97fa-490b-98f8-98af608f8063",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "OK you found a good point I was missing.\r\n\r\nRegarding subclassing I think it's not intended to - Spark doesn't have any actual implementation for overriding the method, as well as we don't expect user code to implement `StateStoreWriter` and kick in to physical execution node. So as you said that's technically possible, that looks to be beyond intention. (Seems to be missing guard, but not sure we have been strictly doing it.)\r\n\r\nAnd regarding the possibility of having different custom metrics among stat store provider instances like I mentioned:\r\n\r\nhttps://github.com/apache/spark/blob/5af5aa146ecbff38b809127b5eb9805441627ed2/sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/statefulOperators.scala#L127-L137\r\n\r\nHere the list of custom metrics are being picked up, and it is populated from dummy StateStoreProvider instance. That said, Spark \"expects\" the same value of `supportedCustomMetrics` across StateStoreProvider instances created from same provider class.",
        "createdAt" : "2020-11-17T02:30:11Z",
        "updatedAt" : "2020-11-24T18:09:50Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      },
      {
        "id" : "47eb93f9-3d33-4d98-9afe-4ad0b3ca018b",
        "parentId" : "cc0c88ac-97fa-490b-98f8-98af608f8063",
        "authorId" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "body" : "Thank you guys pinpointing this + giving explanation related the main intention of this feature.\r\nAs I understand the mentioned use-case is physically possible but that's not the main intention.\r\nWhat is the final call what satisfies everybody? Should we make `StateStoreWriter#getProgress` as `final` to enforce this or we're good as-is?",
        "createdAt" : "2020-11-17T09:16:03Z",
        "updatedAt" : "2020-11-24T18:09:50Z",
        "lastEditedBy" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "tags" : [
        ]
      },
      {
        "id" : "0ea3602d-875a-443c-80bf-286d105ab060",
        "parentId" : "cc0c88ac-97fa-490b-98f8-98af608f8063",
        "authorId" : "3a227965-84e0-47cf-9974-11293764f028",
        "body" : "> What is the final call what satisfies everybody? Should we make StateStoreWriter#getProgress as final to enforce this or we're good as-is?\r\n\r\nHow about leaving it as is and focusing on UI part for now?",
        "createdAt" : "2020-11-17T12:54:38Z",
        "updatedAt" : "2020-11-24T18:09:50Z",
        "lastEditedBy" : "3a227965-84e0-47cf-9974-11293764f028",
        "tags" : [
        ]
      },
      {
        "id" : "7acefd7e-7c37-4564-997d-4e60ff62de51",
        "parentId" : "cc0c88ac-97fa-490b-98f8-98af608f8063",
        "authorId" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "body" : "I agree w/ this! Thanks @sarutak ",
        "createdAt" : "2020-11-17T13:59:49Z",
        "updatedAt" : "2020-11-24T18:09:50Z",
        "lastEditedBy" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "tags" : [
        ]
      }
    ],
    "commit" : "e2f15947ef6e97fbcee5f9f328e6e8315a2eea66",
    "line" : 134,
    "diffHunk" : "@@ -1,1 +272,276 @@    // This is made sure on caller side but put it here to be defensive\n    require(query.lastProgress.stateOperators.nonEmpty)\n    query.lastProgress.stateOperators.head.customMetrics.keySet().asScala\n      .filter(m => enabledCustomMetrics.contains(m.toLowerCase(Locale.ROOT))).map { metricName =>\n        val data = query.recentProgress.map(p => (parseProgressTimestamp(p.timestamp),"
  },
  {
    "id" : "6e4dd479-b9ca-47fb-bb28-b4b66763d8df",
    "prId" : 30336,
    "prUrl" : "https://github.com/apache/spark/pull/30336#pullrequestreview-533371337",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6e73ca53-20ad-4e9b-bf4f-9b04a0493625",
        "parentId" : null,
        "authorId" : "3a227965-84e0-47cf-9974-11293764f028",
        "body" : "Hmm, though users might possibly infer the unit for the current available custom metrics,  we can't easily make the label of y-axis for custom metrics...",
        "createdAt" : "2020-11-17T13:49:43Z",
        "updatedAt" : "2020-11-24T18:09:50Z",
        "lastEditedBy" : "3a227965-84e0-47cf-9974-11293764f028",
        "tags" : [
        ]
      },
      {
        "id" : "038e4e9c-b81d-467d-8ffa-944291627cb1",
        "parentId" : "6e73ca53-20ad-4e9b-bf4f-9b04a0493625",
        "authorId" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "body" : "It would be definitely good to add something better, but I have similar problem like in tooltip. Every custom metric can have its own unit.\r\nI've just double checked and custom metrics stored in the following way: `java.util.Map[String, java.lang.Long]`\r\nSince this structure doesn't contain anything what the metric unit is I'm not sure from where it could come from.\r\nAny suggestion?",
        "createdAt" : "2020-11-17T14:10:17Z",
        "updatedAt" : "2020-11-24T18:09:50Z",
        "lastEditedBy" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "tags" : [
        ]
      },
      {
        "id" : "ae791ffc-3b9a-4da4-9931-364ddefd609f",
        "parentId" : "6e73ca53-20ad-4e9b-bf4f-9b04a0493625",
        "authorId" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "body" : "I think the way could be to introduce metric unit in the mentioned structure.\r\nSince it doesn't exist I can't see possibilities for now.",
        "createdAt" : "2020-11-17T14:13:40Z",
        "updatedAt" : "2020-11-24T18:09:50Z",
        "lastEditedBy" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "tags" : [
        ]
      },
      {
        "id" : "0d499d9c-a9e3-4930-9527-3db7613dcfba",
        "parentId" : "6e73ca53-20ad-4e9b-bf4f-9b04a0493625",
        "authorId" : "3a227965-84e0-47cf-9974-11293764f028",
        "body" : "How about following idea?\r\n\r\n1. Add `unit` to `StateStoreCustomMetric`\r\n2. Call `StateStoreProvider.create(conf.get(STATE_STORE_PROVIDER_CLASS)).supportedCustomMetrics` and get the `Seq` of `StateStoreCustomMetric` in `StreamingQueryStatisticsPage`.\r\n3. Refer `desc` and `unit` from the `StateStoreCustomMetric`\r\n\r\n@HeartSaVioR  What do you tihnk?",
        "createdAt" : "2020-11-17T14:42:49Z",
        "updatedAt" : "2020-11-24T18:09:50Z",
        "lastEditedBy" : "3a227965-84e0-47cf-9974-11293764f028",
        "tags" : [
        ]
      },
      {
        "id" : "c8863cc2-73f9-4210-8703-a45117cd9231",
        "parentId" : "6e73ca53-20ad-4e9b-bf4f-9b04a0493625",
        "authorId" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "body" : "+1 on this idea, though not sure what kind of side effects we face. For instance does UI have `SparkEnv`?",
        "createdAt" : "2020-11-17T15:29:55Z",
        "updatedAt" : "2020-11-24T18:09:50Z",
        "lastEditedBy" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "tags" : [
        ]
      },
      {
        "id" : "4c99f1ed-93c5-496c-91d3-f6f89e6d47dd",
        "parentId" : "6e73ca53-20ad-4e9b-bf4f-9b04a0493625",
        "authorId" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "body" : "Never mind, these are `lazy val`s in the provider implementation.",
        "createdAt" : "2020-11-17T15:32:25Z",
        "updatedAt" : "2020-11-24T18:09:50Z",
        "lastEditedBy" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "tags" : [
        ]
      },
      {
        "id" : "f3b9a4c5-7f26-487d-9470-aeb5d88ce5a7",
        "parentId" : "6e73ca53-20ad-4e9b-bf4f-9b04a0493625",
        "authorId" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "body" : "The only concern what I see is that all `StateStoreProvider` implementation must support lightweight initialization which can be done from UI thread w/o exception. Not sure this implicit requirement is or will be known to all `StateStoreProvider` implementor.",
        "createdAt" : "2020-11-17T15:51:16Z",
        "updatedAt" : "2020-11-24T18:09:50Z",
        "lastEditedBy" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "tags" : [
        ]
      },
      {
        "id" : "a1b96795-6b67-43be-ad30-dfc35bf8ee78",
        "parentId" : "6e73ca53-20ad-4e9b-bf4f-9b04a0493625",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "The idea looks promising. I see the concern from @gaborgsomogyi but given it has separate `init` method to bootstrap, more likely the implementation wouldn't do something in constructor.",
        "createdAt" : "2020-11-18T03:21:10Z",
        "updatedAt" : "2020-11-24T18:09:50Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      },
      {
        "id" : "58ffc08a-3336-433a-b7f6-1614084b3963",
        "parentId" : "6e73ca53-20ad-4e9b-bf4f-9b04a0493625",
        "authorId" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "body" : "Since we're not calling `init` it doesn't play as you've mentioned. The restriction is not to put anything nasty in the constructor. I can live with it just wanted to highlight. Since I don't feel objection from @HeartSaVioR I'm starting to add it.",
        "createdAt" : "2020-11-18T07:50:38Z",
        "updatedAt" : "2020-11-24T18:09:50Z",
        "lastEditedBy" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "tags" : [
        ]
      },
      {
        "id" : "c07fd69c-2360-4e1d-af01-6f7fcb0468c1",
        "parentId" : "6e73ca53-20ad-4e9b-bf4f-9b04a0493625",
        "authorId" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "body" : "I've added it and working fine so closing this thread.",
        "createdAt" : "2020-11-18T11:55:41Z",
        "updatedAt" : "2020-11-24T18:09:50Z",
        "lastEditedBy" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "tags" : [
        ]
      }
    ],
    "commit" : "e2f15947ef6e97fbcee5f9f328e6e8315a2eea66",
    "line" : 150,
    "diffHunk" : "@@ -1,1 +288,292 @@            0,\n            max,\n            \"\")\n        graphUIData.generateDataJs(jsCollector)\n"
  },
  {
    "id" : "6512df1b-c3f9-40c0-9a84-4265c8749ac2",
    "prId" : 30336,
    "prUrl" : "https://github.com/apache/spark/pull/30336#pullrequestreview-537402642",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b651c64a-9a7c-4937-9e22-2f50ccca4adc",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "How about moving this into `generateAggregatedCustomMetrics` and only having it when `enabledCustomMetrics` isn't empty?",
        "createdAt" : "2020-11-21T18:19:50Z",
        "updatedAt" : "2020-11-24T18:09:50Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "452fff1b-4fea-4a42-8325-f8f8d7323418",
        "parentId" : "b651c64a-9a7c-4937-9e22-2f50ccca4adc",
        "authorId" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "body" : "Yeah, this makes the code more compact so added.",
        "createdAt" : "2020-11-24T11:34:12Z",
        "updatedAt" : "2020-11-24T18:09:50Z",
        "lastEditedBy" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "tags" : [
        ]
      }
    ],
    "commit" : "e2f15947ef6e97fbcee5f9f328e6e8315a2eea66",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +40,44 @@  private val supportedCustomMetrics = StateStoreProvider.create(\n    parent.parent.conf.get(STATE_STORE_PROVIDER_CLASS)).supportedCustomMetrics\n  logDebug(s\"Supported custom metrics: $supportedCustomMetrics\")\n\n  private val enabledCustomMetrics ="
  }
]