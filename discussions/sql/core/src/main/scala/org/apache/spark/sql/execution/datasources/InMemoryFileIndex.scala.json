[
  {
    "id" : "ab53db90-e85d-4486-923d-a92ca2823f3f",
    "prId" : 27801,
    "prUrl" : "https://github.com/apache/spark/pull/27801#pullrequestreview-374064417",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "26441aa6-9f54-4479-b16a-5442a4986b9c",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Hi, @manuzhang .\r\nWhich test did you referring in the PR description? Could you add a UT explicitly?\r\n```\r\n## How was this patch tested?\r\n\r\nExisting tests.\r\n```",
        "createdAt" : "2020-03-12T03:49:46Z",
        "updatedAt" : "2020-03-13T05:54:59Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "2bd2fb93-ca01-4798-88e2-93a8aba74614",
        "parentId" : "26441aa6-9f54-4479-b16a-5442a4986b9c",
        "authorId" : "334a081c-cba1-403e-ac80-30e6124077d1",
        "body" : "Sorry, I didn't find a UT for `DistributedFileSystem`. Could you suggest on how to test it ?",
        "createdAt" : "2020-03-12T06:27:03Z",
        "updatedAt" : "2020-03-13T05:54:59Z",
        "lastEditedBy" : "334a081c-cba1-403e-ac80-30e6124077d1",
        "tags" : [
        ]
      },
      {
        "id" : "eecf5c3a-182e-4288-9f88-bb0bd89b2ca5",
        "parentId" : "26441aa6-9f54-4479-b16a-5442a4986b9c",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "`Mock`?\r\n```\r\n$ git grep 'DistributedFileSystem' | grep Suite\r\ncore/src/test/scala/org/apache/spark/deploy/history/FsHistoryProviderSuite.scala:import org.apache.hadoop.hdfs.{DFSInputStream, DistributedFileSystem}\r\ncore/src/test/scala/org/apache/spark/deploy/history/FsHistoryProviderSuite.scala:    val dfs = mock(classOf[DistributedFileSystem])\r\nsql/core/src/test/scala/org/apache/spark/sql/execution/datasources/FileSourceStrategySuite.scala:      \"fs.file.impl\" -> classOf[MockDistributedFileSystem].getName,\r\nsql/core/src/test/scala/org/apache/spark/sql/execution/datasources/FileSourceStrategySuite.scala:// This file system is for SPARK-14959 (DistributedFileSystem will throw an exception\r\nsql/core/src/test/scala/org/apache/spark/sql/execution/datasources/FileSourceStrategySuite.scala:class MockDistributedFileSystem extends RawLocalFileSystem {\r\n```",
        "createdAt" : "2020-03-12T08:47:24Z",
        "updatedAt" : "2020-03-13T05:54:59Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "c89a08e3-a90d-4506-b0da-d063017d9f5e",
        "parentId" : "26441aa6-9f54-4479-b16a-5442a4986b9c",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "BTW, without a test case, your contribution is not protected from accidental removal. That's the reason why we ask a UT always.",
        "createdAt" : "2020-03-12T08:48:30Z",
        "updatedAt" : "2020-03-13T05:54:59Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "c6584f4c-6a28-4dad-a084-5d47fa5a2ea3",
        "parentId" : "26441aa6-9f54-4479-b16a-5442a4986b9c",
        "authorId" : "334a081c-cba1-403e-ac80-30e6124077d1",
        "body" : "thanks, UT added",
        "createdAt" : "2020-03-13T05:56:02Z",
        "updatedAt" : "2020-03-13T05:56:03Z",
        "lastEditedBy" : "334a081c-cba1-403e-ac80-30e6124077d1",
        "tags" : [
        ]
      }
    ],
    "commit" : "93e7e0da42931801cbd4d06493d7753f3a8364e0",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +315,319 @@        // to listStatus is because the default implementation would potentially throw a\n        // FileNotFoundException which is better handled by doing the lookups manually below.\n        case (_: DistributedFileSystem | _: ViewFileSystem) if !ignoreLocality =>\n          val remoteIter = fs.listLocatedStatus(path)\n          new Iterator[LocatedFileStatus]() {"
  },
  {
    "id" : "fbbb761f-4b32-4939-ad1e-2170913428ff",
    "prId" : 27213,
    "prUrl" : "https://github.com/apache/spark/pull/27213#pullrequestreview-352691079",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fd8c1513-7d56-479c-b681-a38885db33e1",
        "parentId" : null,
        "authorId" : "f06b291a-bc5c-4fd8-9bac-e5a6d035891b",
        "body" : "Just add an assertion incidentally here, this is not necessary for this PR.\r\nif not ok, i can remove it.",
        "createdAt" : "2020-02-04T02:30:25Z",
        "updatedAt" : "2020-02-10T08:58:10Z",
        "lastEditedBy" : "f06b291a-bc5c-4fd8-9bac-e5a6d035891b",
        "tags" : [
        ]
      }
    ],
    "commit" : "2e210a092442bbc65ff92f97a2eb2c06aaf83376",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +61,65 @@    s\"The rootPathsSpecified ($rootPathsSpecified) is inconsistent with the file paths \" +\n      s\"of userSpecifiedPartitionSpec (${userSpecifiedPartitionSpec.get.partitions.map(_.path)}).\")\n\n  // Filter out streaming metadata dirs or files such as \"/.../_spark_metadata\" (the metadata dir)\n  // or \"/.../_spark_metadata/0\" (a file in the metadata dir). `rootPathsSpecified` might contain"
  },
  {
    "id" : "32fc0619-aae4-413f-858b-2e91fc5a444a",
    "prId" : 27079,
    "prUrl" : "https://github.com/apache/spark/pull/27079#pullrequestreview-339609440",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0e1dacc7-e07a-4866-a63d-e2890306dbf2",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Nit: there may not be 100 paths here. Just say \"The first several paths are ...\" and maybe just show like 10?",
        "createdAt" : "2020-01-07T14:33:44Z",
        "updatedAt" : "2020-01-08T01:45:47Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "eefc50c5-ba35-4235-a653-9bc3164dcec7",
        "parentId" : "0e1dacc7-e07a-4866-a63d-e2890306dbf2",
        "authorId" : "78cb7df6-a1c6-4bcb-99c1-16fd18fb32f7",
        "body" : "yes, that seems better",
        "createdAt" : "2020-01-08T01:48:57Z",
        "updatedAt" : "2020-01-08T01:48:57Z",
        "lastEditedBy" : "78cb7df6-a1c6-4bcb-99c1-16fd18fb32f7",
        "tags" : [
        ]
      }
    ],
    "commit" : "b7ac910a8431f7bad97efe5d0cbeb2b64d04e775",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +192,196 @@    }\n\n    logInfo(s\"Listing leaf files and directories in parallel under ${paths.length} paths.\" +\n      s\" The first several paths are: ${paths.take(10).mkString(\", \")}.\")\n    HiveCatalogMetrics.incrementParallelListingJobCount(1)"
  }
]