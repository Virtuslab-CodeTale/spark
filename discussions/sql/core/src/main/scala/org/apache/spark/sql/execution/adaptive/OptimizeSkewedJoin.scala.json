[
  {
    "id" : "9fd93545-8fe9-411e-b780-d87552a93d13",
    "prId" : 33541,
    "prUrl" : "https://github.com/apache/spark/pull/33541#pullrequestreview-716593700",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "aaf3fc6d-2c81-45fc-b8bf-21436332f81e",
        "parentId" : null,
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "style seems wrong",
        "createdAt" : "2021-07-28T03:40:54Z",
        "updatedAt" : "2021-07-28T03:55:46Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      },
      {
        "id" : "e2fad8f5-df9d-43e9-b5a7-6f8fbbb5c710",
        "parentId" : "aaf3fc6d-2c81-45fc-b8bf-21436332f81e",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I moved this object into the class",
        "createdAt" : "2021-07-28T04:44:13Z",
        "updatedAt" : "2021-07-28T04:44:13Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "28fb3ef5-a593-4290-bef9-341309912d2e",
        "parentId" : "aaf3fc6d-2c81-45fc-b8bf-21436332f81e",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "ah, I see",
        "createdAt" : "2021-07-28T05:30:36Z",
        "updatedAt" : "2021-07-28T05:30:36Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "61cc6751e4baad96f0a8b251296c6e58ffbbf3a3",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +257,261 @@  }\n\n  object ShuffleStage {\n    def unapply(plan: SparkPlan): Option[ShuffleQueryStageExec] = plan match {\n      case s: ShuffleQueryStageExec if s.mapStats.isDefined && isSupported(s.shuffle) =>"
  },
  {
    "id" : "68c62dfa-5ea4-481c-b06b-7c0d05b1567b",
    "prId" : 32685,
    "prUrl" : "https://github.com/apache/spark/pull/32685#pullrequestreview-669818725",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3bb97936-0641-4755-8251-662d023112a8",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "now we don't need to call `isSkewed` repeatedly",
        "createdAt" : "2021-05-27T07:14:07Z",
        "updatedAt" : "2021-05-27T07:14:07Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "9e469d093bdee7a51a81ae442c1c04679d8ed748",
    "line" : 65,
    "diffHunk" : "@@ -1,1 +187,191 @@    for (partitionIndex <- 0 until numPartitions) {\n      val leftSize = leftSizes(partitionIndex)\n      val isLeftSkew = canSplitLeft && leftSize > leftSkewThreshold\n      val rightSize = rightSizes(partitionIndex)\n      val isRightSkew = canSplitRight && rightSize > rightSkewThreshold"
  },
  {
    "id" : "3d6833c3-16d1-4d25-b445-d4bf54809947",
    "prId" : 32328,
    "prUrl" : "https://github.com/apache/spark/pull/32328#pullrequestreview-646635361",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a900fc9d-8be9-46da-9b8c-ff6e3efbfd90",
        "parentId" : null,
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "immature thoughts on this optimization:\r\n\r\n`OptimizeSkewedJoin` try to make sizes of shuffle partitions more even. \r\n\r\nFor bhj, should we change the *optimization goal of build side* to making sure build side fit in memory to avoid OOM or fallback to smj.\r\n\r\nIs it possible that the build side is skewed according current criterions, but the shuffle partitions all fit in memory?\r\n\r\n",
        "createdAt" : "2021-04-28T02:32:39Z",
        "updatedAt" : "2021-04-28T02:32:39Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      },
      {
        "id" : "99c631e1-e4ac-4322-83ac-3ad19c0b5b60",
        "parentId" : "a900fc9d-8be9-46da-9b8c-ff6e3efbfd90",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "In current implementaion, we have already supported optimize skew build side with inner join. For other join type we cann't optimize it due to the semantics.\r\n\r\nIMO It's better to consider OOM at shj itself instead of fallback to smj which might make things more complicated. Actually, we might change smj to shj at `reOptimize` if we disable the `preferSortMerge`, so it's confused to change join strategy again.",
        "createdAt" : "2021-04-28T05:29:34Z",
        "updatedAt" : "2021-04-28T05:29:34Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      },
      {
        "id" : "568326e7-d3b3-45d8-b413-b2701009c412",
        "parentId" : "a900fc9d-8be9-46da-9b8c-ff6e3efbfd90",
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "Sorry my comment was misleading, the `fallback to smj` there means https://github.com/apache/spark/pull/32210\r\n\r\nMy thought is that we may take potential OOM into account here,\r\nlet build side A inner join stream side B, for a build partition A_0:\r\n\r\n- if A_0 is skewed but is less than a OOM threshold, we may not split it;\r\n- if A_0 is not skewed but greater than that threshold, we may still need to split it;\r\n\r\n",
        "createdAt" : "2021-04-28T06:08:23Z",
        "updatedAt" : "2021-04-28T06:08:24Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      },
      {
        "id" : "58014f86-ddd1-4a58-8772-6449703aa95b",
        "parentId" : "a900fc9d-8be9-46da-9b8c-ff6e3efbfd90",
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "My hunch is when the build side can be potentially OOM-ed, it should already be considered as skewed. So after AQE skew handling, some of potentially OOM-ed build side (inner join only) can be avoided.\r\n\r\nHowever, for queries with other join types, queries not having shuffle before join, and queries with run-time hash map being significantly larger than partition size, we should have run-time fallback mechanism in shuffled hash join itself. This PR and #32210 should be good to have and orthogonal to each other.",
        "createdAt" : "2021-04-28T06:25:50Z",
        "updatedAt" : "2021-04-28T06:25:50Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      }
    ],
    "commit" : "cab5290a89526a32f826f1d2fffff9132d6e2a8d",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +147,151 @@\n  /*\n   * This method aim to optimize the skewed join with the following steps:\n   * 1. Check whether the shuffle partition is skewed based on the median size\n   *    and the skewed partition threshold in origin shuffled join (smj and shj)."
  },
  {
    "id" : "9fc719d7-99fd-4ac4-85cd-490b9b1bab1f",
    "prId" : 31653,
    "prUrl" : "https://github.com/apache/spark/pull/31653#pullrequestreview-625954479",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fc0aeb06-f5a5-43c6-b3a8-83388b45294f",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Currently this rule is very limited: it only applies to SMJ with 2 shuffle query stages as the direct children.\r\n\r\nI don't think it's a big difference if we move this rule to `queryStagePreparationRules`. We still need to match SMJ with 2 shuffle query stages as the direct children, with an additional check that the query stages must be materialized, which is guaranteed for query stage optimization rules.",
        "createdAt" : "2021-03-29T17:03:13Z",
        "updatedAt" : "2021-03-29T17:14:45Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "f55c882e-b7e1-49f8-bd5b-c86df7d6c5bd",
        "parentId" : "fc0aeb06-f5a5-43c6-b3a8-83388b45294f",
        "authorId" : "9acf210d-4935-4e03-8384-d944eb558b45",
        "body" : "1. with this PR, if you have \r\n```\r\nSMJ1\r\n |-...\r\n |-SMJ2\r\n    |-...\r\n    |-...\r\n```\r\nin a single stage, `OprimizeSkewedJoin` has to pay attention to it because it may decide to mitigate skew in SMJ2 and insert a shuffle above it, breaking up the stage\r\n2. My comment in the code was referring to something different.  When `OprimizeSkewedJoin` runs as part of `queryStagePreparationRules`, it may run over a plan like this for example\r\n```\r\nSMJ0\r\n|-Exch\r\n |-SMJ1\r\n    |-...\r\n    |-...\r\n|-Exch \r\n |-SMJ2\r\n    |-...\r\n    |-...\r\n```\r\nwhere all inputs to SMJ1/SMJ2 are materialized.  And it has to make a decision about each SMJ separately.  Previously (when `OprimizeSkewedJoin` was part of `queryStageOptimizerRules`, any given run of `OprimizeSkewedJoin` would either see SMJ1 or SMJ2 but not both)\r\n",
        "createdAt" : "2021-03-30T17:47:20Z",
        "updatedAt" : "2021-03-30T17:47:20Z",
        "lastEditedBy" : "9acf210d-4935-4e03-8384-d944eb558b45",
        "tags" : [
        ]
      },
      {
        "id" : "68ce837d-a0d2-4e8e-9cde-de041b77b602",
        "parentId" : "fc0aeb06-f5a5-43c6-b3a8-83388b45294f",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Maybe we don't have to be optimal in the first version. We can optimize all the leaf SMJs, and revert all of them if extra shuffles are introduced. The optimal solution is to find out which SMJ caused the extra shuffle and only revert it. We can do it later.",
        "createdAt" : "2021-03-31T05:58:39Z",
        "updatedAt" : "2021-03-31T05:58:39Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "3c0b70ce-d0fb-45a6-8cf0-0e1acd7782d4",
        "parentId" : "fc0aeb06-f5a5-43c6-b3a8-83388b45294f",
        "authorId" : "9acf210d-4935-4e03-8384-d944eb558b45",
        "body" : "Not sure I follow.  This point of this PR is to allow `OptimizeSkewedJoin` to add extra shuffles...",
        "createdAt" : "2021-03-31T20:06:19Z",
        "updatedAt" : "2021-03-31T20:06:19Z",
        "lastEditedBy" : "9acf210d-4935-4e03-8384-d944eb558b45",
        "tags" : [
        ]
      },
      {
        "id" : "42e67624-cb97-4fe9-8c39-e0015eef4cfc",
        "parentId" : "fc0aeb06-f5a5-43c6-b3a8-83388b45294f",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I was talking about the default case. If we enable the config and allow extra shuffles, then it's pretty straightforward and we just optimize all the leaf SMJs.",
        "createdAt" : "2021-04-01T07:02:26Z",
        "updatedAt" : "2021-04-01T07:02:26Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "7cfda59a1e9a8e0f86e2e6424c21639c1b5b14e3",
    "line" : 112,
    "diffHunk" : "@@ -1,1 +310,314 @@  /**\n   * Now this runs as part of queryStagePreparationRules() which means it runs over the whole plan\n   * which may have any number of ExchangeExec nodes, i.e. multiple \"query stages\"\n   *\n   * This runs optimizeSkewJoin() on each \"query stage\" separately so that"
  },
  {
    "id" : "bf8fb112-e9e8-4213-847f-65dcacca19db",
    "prId" : 29692,
    "prUrl" : "https://github.com/apache/spark/pull/29692#pullrequestreview-492165531",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "708de2e4-3ec3-4ed8-9854-e2b33ca43ec5",
        "parentId" : null,
        "authorId" : "334a081c-cba1-403e-ac80-30e6124077d1",
        "body" : "Does this mean we will also handle multi-table join (e.g. three-table join) ?",
        "createdAt" : "2020-09-14T03:33:48Z",
        "updatedAt" : "2020-09-14T03:33:48Z",
        "lastEditedBy" : "334a081c-cba1-403e-ac80-30e6124077d1",
        "tags" : [
        ]
      },
      {
        "id" : "ed3398ed-9c15-4bfe-970b-0c3c969ba979",
        "parentId" : "708de2e4-3ec3-4ed8-9854-e2b33ca43ec5",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> Does this mean we will also handle multi-table join (e.g. three-table join) ?\r\n\r\nSince broadcast nested loop join only can have one side shuffle exchange, but sort merge join with two",
        "createdAt" : "2020-09-20T01:34:53Z",
        "updatedAt" : "2020-09-20T01:34:53Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "5c6f895f4e351589cc46adf0a50ad08a8f9a1c51",
    "line" : 177,
    "diffHunk" : "@@ -1,1 +355,359 @@    val shuffleStages = collectShuffleStages(plan)\n\n    if (shuffleStages.length >= 1) {\n      // When multi table join, there will be too many complex combination to consider.\n      // Currently we only handle 2 table join like following use case."
  }
]