[
  {
    "id" : "9fd93545-8fe9-411e-b780-d87552a93d13",
    "prId" : 33541,
    "prUrl" : "https://github.com/apache/spark/pull/33541#pullrequestreview-716593700",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "aaf3fc6d-2c81-45fc-b8bf-21436332f81e",
        "parentId" : null,
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "style seems wrong",
        "createdAt" : "2021-07-28T03:40:54Z",
        "updatedAt" : "2021-07-28T03:55:46Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      },
      {
        "id" : "e2fad8f5-df9d-43e9-b5a7-6f8fbbb5c710",
        "parentId" : "aaf3fc6d-2c81-45fc-b8bf-21436332f81e",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I moved this object into the class",
        "createdAt" : "2021-07-28T04:44:13Z",
        "updatedAt" : "2021-07-28T04:44:13Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "28fb3ef5-a593-4290-bef9-341309912d2e",
        "parentId" : "aaf3fc6d-2c81-45fc-b8bf-21436332f81e",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "ah, I see",
        "createdAt" : "2021-07-28T05:30:36Z",
        "updatedAt" : "2021-07-28T05:30:36Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "61cc6751e4baad96f0a8b251296c6e58ffbbf3a3",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +257,261 @@  }\n\n  object ShuffleStage {\n    def unapply(plan: SparkPlan): Option[ShuffleQueryStageExec] = plan match {\n      case s: ShuffleQueryStageExec if s.mapStats.isDefined && isSupported(s.shuffle) =>"
  },
  {
    "id" : "68c62dfa-5ea4-481c-b06b-7c0d05b1567b",
    "prId" : 32685,
    "prUrl" : "https://github.com/apache/spark/pull/32685#pullrequestreview-669818725",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3bb97936-0641-4755-8251-662d023112a8",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "now we don't need to call `isSkewed` repeatedly",
        "createdAt" : "2021-05-27T07:14:07Z",
        "updatedAt" : "2021-05-27T07:14:07Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "9e469d093bdee7a51a81ae442c1c04679d8ed748",
    "line" : 65,
    "diffHunk" : "@@ -1,1 +187,191 @@    for (partitionIndex <- 0 until numPartitions) {\n      val leftSize = leftSizes(partitionIndex)\n      val isLeftSkew = canSplitLeft && leftSize > leftSkewThreshold\n      val rightSize = rightSizes(partitionIndex)\n      val isRightSkew = canSplitRight && rightSize > rightSkewThreshold"
  },
  {
    "id" : "3d6833c3-16d1-4d25-b445-d4bf54809947",
    "prId" : 32328,
    "prUrl" : "https://github.com/apache/spark/pull/32328#pullrequestreview-646635361",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a900fc9d-8be9-46da-9b8c-ff6e3efbfd90",
        "parentId" : null,
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "immature thoughts on this optimization:\r\n\r\n`OptimizeSkewedJoin` try to make sizes of shuffle partitions more even. \r\n\r\nFor bhj, should we change the *optimization goal of build side* to making sure build side fit in memory to avoid OOM or fallback to smj.\r\n\r\nIs it possible that the build side is skewed according current criterions, but the shuffle partitions all fit in memory?\r\n\r\n",
        "createdAt" : "2021-04-28T02:32:39Z",
        "updatedAt" : "2021-04-28T02:32:39Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      },
      {
        "id" : "99c631e1-e4ac-4322-83ac-3ad19c0b5b60",
        "parentId" : "a900fc9d-8be9-46da-9b8c-ff6e3efbfd90",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "In current implementaion, we have already supported optimize skew build side with inner join. For other join type we cann't optimize it due to the semantics.\r\n\r\nIMO It's better to consider OOM at shj itself instead of fallback to smj which might make things more complicated. Actually, we might change smj to shj at `reOptimize` if we disable the `preferSortMerge`, so it's confused to change join strategy again.",
        "createdAt" : "2021-04-28T05:29:34Z",
        "updatedAt" : "2021-04-28T05:29:34Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      },
      {
        "id" : "568326e7-d3b3-45d8-b413-b2701009c412",
        "parentId" : "a900fc9d-8be9-46da-9b8c-ff6e3efbfd90",
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "Sorry my comment was misleading, the `fallback to smj` there means https://github.com/apache/spark/pull/32210\r\n\r\nMy thought is that we may take potential OOM into account here,\r\nlet build side A inner join stream side B, for a build partition A_0:\r\n\r\n- if A_0 is skewed but is less than a OOM threshold, we may not split it;\r\n- if A_0 is not skewed but greater than that threshold, we may still need to split it;\r\n\r\n",
        "createdAt" : "2021-04-28T06:08:23Z",
        "updatedAt" : "2021-04-28T06:08:24Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      },
      {
        "id" : "58014f86-ddd1-4a58-8772-6449703aa95b",
        "parentId" : "a900fc9d-8be9-46da-9b8c-ff6e3efbfd90",
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "My hunch is when the build side can be potentially OOM-ed, it should already be considered as skewed. So after AQE skew handling, some of potentially OOM-ed build side (inner join only) can be avoided.\r\n\r\nHowever, for queries with other join types, queries not having shuffle before join, and queries with run-time hash map being significantly larger than partition size, we should have run-time fallback mechanism in shuffled hash join itself. This PR and #32210 should be good to have and orthogonal to each other.",
        "createdAt" : "2021-04-28T06:25:50Z",
        "updatedAt" : "2021-04-28T06:25:50Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      }
    ],
    "commit" : "cab5290a89526a32f826f1d2fffff9132d6e2a8d",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +147,151 @@\n  /*\n   * This method aim to optimize the skewed join with the following steps:\n   * 1. Check whether the shuffle partition is skewed based on the median size\n   *    and the skewed partition threshold in origin shuffled join (smj and shj)."
  },
  {
    "id" : "9fc719d7-99fd-4ac4-85cd-490b9b1bab1f",
    "prId" : 31653,
    "prUrl" : "https://github.com/apache/spark/pull/31653#pullrequestreview-625954479",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fc0aeb06-f5a5-43c6-b3a8-83388b45294f",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Currently this rule is very limited: it only applies to SMJ with 2 shuffle query stages as the direct children.\r\n\r\nI don't think it's a big difference if we move this rule to `queryStagePreparationRules`. We still need to match SMJ with 2 shuffle query stages as the direct children, with an additional check that the query stages must be materialized, which is guaranteed for query stage optimization rules.",
        "createdAt" : "2021-03-29T17:03:13Z",
        "updatedAt" : "2021-03-29T17:14:45Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "f55c882e-b7e1-49f8-bd5b-c86df7d6c5bd",
        "parentId" : "fc0aeb06-f5a5-43c6-b3a8-83388b45294f",
        "authorId" : "9acf210d-4935-4e03-8384-d944eb558b45",
        "body" : "1. with this PR, if you have \r\n```\r\nSMJ1\r\n |-...\r\n |-SMJ2\r\n    |-...\r\n    |-...\r\n```\r\nin a single stage, `OprimizeSkewedJoin` has to pay attention to it because it may decide to mitigate skew in SMJ2 and insert a shuffle above it, breaking up the stage\r\n2. My comment in the code was referring to something different.  When `OprimizeSkewedJoin` runs as part of `queryStagePreparationRules`, it may run over a plan like this for example\r\n```\r\nSMJ0\r\n|-Exch\r\n |-SMJ1\r\n    |-...\r\n    |-...\r\n|-Exch \r\n |-SMJ2\r\n    |-...\r\n    |-...\r\n```\r\nwhere all inputs to SMJ1/SMJ2 are materialized.  And it has to make a decision about each SMJ separately.  Previously (when `OprimizeSkewedJoin` was part of `queryStageOptimizerRules`, any given run of `OprimizeSkewedJoin` would either see SMJ1 or SMJ2 but not both)\r\n",
        "createdAt" : "2021-03-30T17:47:20Z",
        "updatedAt" : "2021-03-30T17:47:20Z",
        "lastEditedBy" : "9acf210d-4935-4e03-8384-d944eb558b45",
        "tags" : [
        ]
      },
      {
        "id" : "68ce837d-a0d2-4e8e-9cde-de041b77b602",
        "parentId" : "fc0aeb06-f5a5-43c6-b3a8-83388b45294f",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Maybe we don't have to be optimal in the first version. We can optimize all the leaf SMJs, and revert all of them if extra shuffles are introduced. The optimal solution is to find out which SMJ caused the extra shuffle and only revert it. We can do it later.",
        "createdAt" : "2021-03-31T05:58:39Z",
        "updatedAt" : "2021-03-31T05:58:39Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "3c0b70ce-d0fb-45a6-8cf0-0e1acd7782d4",
        "parentId" : "fc0aeb06-f5a5-43c6-b3a8-83388b45294f",
        "authorId" : "9acf210d-4935-4e03-8384-d944eb558b45",
        "body" : "Not sure I follow.  This point of this PR is to allow `OptimizeSkewedJoin` to add extra shuffles...",
        "createdAt" : "2021-03-31T20:06:19Z",
        "updatedAt" : "2021-03-31T20:06:19Z",
        "lastEditedBy" : "9acf210d-4935-4e03-8384-d944eb558b45",
        "tags" : [
        ]
      },
      {
        "id" : "42e67624-cb97-4fe9-8c39-e0015eef4cfc",
        "parentId" : "fc0aeb06-f5a5-43c6-b3a8-83388b45294f",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I was talking about the default case. If we enable the config and allow extra shuffles, then it's pretty straightforward and we just optimize all the leaf SMJs.",
        "createdAt" : "2021-04-01T07:02:26Z",
        "updatedAt" : "2021-04-01T07:02:26Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "7cfda59a1e9a8e0f86e2e6424c21639c1b5b14e3",
    "line" : 112,
    "diffHunk" : "@@ -1,1 +310,314 @@  /**\n   * Now this runs as part of queryStagePreparationRules() which means it runs over the whole plan\n   * which may have any number of ExchangeExec nodes, i.e. multiple \"query stages\"\n   *\n   * This runs optimizeSkewJoin() on each \"query stage\" separately so that"
  },
  {
    "id" : "bf8fb112-e9e8-4213-847f-65dcacca19db",
    "prId" : 29692,
    "prUrl" : "https://github.com/apache/spark/pull/29692#pullrequestreview-492165531",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "708de2e4-3ec3-4ed8-9854-e2b33ca43ec5",
        "parentId" : null,
        "authorId" : "334a081c-cba1-403e-ac80-30e6124077d1",
        "body" : "Does this mean we will also handle multi-table join (e.g. three-table join) ?",
        "createdAt" : "2020-09-14T03:33:48Z",
        "updatedAt" : "2020-09-14T03:33:48Z",
        "lastEditedBy" : "334a081c-cba1-403e-ac80-30e6124077d1",
        "tags" : [
        ]
      },
      {
        "id" : "ed3398ed-9c15-4bfe-970b-0c3c969ba979",
        "parentId" : "708de2e4-3ec3-4ed8-9854-e2b33ca43ec5",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> Does this mean we will also handle multi-table join (e.g. three-table join) ?\r\n\r\nSince broadcast nested loop join only can have one side shuffle exchange, but sort merge join with two",
        "createdAt" : "2020-09-20T01:34:53Z",
        "updatedAt" : "2020-09-20T01:34:53Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "5c6f895f4e351589cc46adf0a50ad08a8f9a1c51",
    "line" : 177,
    "diffHunk" : "@@ -1,1 +355,359 @@    val shuffleStages = collectShuffleStages(plan)\n\n    if (shuffleStages.length >= 1) {\n      // When multi table join, there will be too many complex combination to consider.\n      // Currently we only handle 2 table join like following use case."
  },
  {
    "id" : "4035eb64-3285-4d8b-8ad6-fabea2c29a40",
    "prId" : 29266,
    "prUrl" : "https://github.com/apache/spark/pull/29266#pullrequestreview-461289288",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6698bc2c-d320-4a5f-bb23-ec76195a7b04",
        "parentId" : null,
        "authorId" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "body" : "Why is it that we don't need `if (qs.shuffleStage.shuffle.canChangeNumPartitions && canSplitLeftSide(joinType))` here??",
        "createdAt" : "2020-08-04T15:45:03Z",
        "updatedAt" : "2020-08-04T15:45:03Z",
        "lastEditedBy" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "tags" : [
        ]
      },
      {
        "id" : "c7dbbf1d-d7b7-410c-938c-ff28c944bc59",
        "parentId" : "6698bc2c-d320-4a5f-bb23-ec76195a7b04",
        "authorId" : "808d9715-b3bd-4481-9935-20d7ca698e42",
        "body" : "My fault, missed some code..",
        "createdAt" : "2020-08-05T02:01:08Z",
        "updatedAt" : "2020-08-05T02:01:09Z",
        "lastEditedBy" : "808d9715-b3bd-4481-9935-20d7ca698e42",
        "tags" : [
        ]
      }
    ],
    "commit" : "1920c7bf3283083f6ee8851a731deacd9a7374a3",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +271,275 @@    case smj @ SortMergeJoinExec(_, _, _, _, left,\n        sort @ SortExec(_, _, ShuffleStage(qs: ShuffleStageInfo), _), _) =>\n      val (numSkewed, splitPartitions, partitionIndexes) = handleSkewed(qs)\n      if (numSkewed > 0) {\n        logInfo(s\"number of skewed partitions $numSkewed\")"
  },
  {
    "id" : "b5b6306b-3f6c-4e61-85a5-6cad5088aa51",
    "prId" : 29266,
    "prUrl" : "https://github.com/apache/spark/pull/29266#pullrequestreview-461283251",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2deab149-be25-4d14-a09d-0661db48ed8c",
        "parentId" : null,
        "authorId" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "body" : "Is it possible to integrate this logic into the two-query-stage skew processing?\r\nWe can just treat the non-query-stage side as \"canSplitXXXSide(...) = false\", right?",
        "createdAt" : "2020-08-04T15:46:38Z",
        "updatedAt" : "2020-08-04T15:46:39Z",
        "lastEditedBy" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "tags" : [
        ]
      },
      {
        "id" : "5ef56b86-8340-4c18-9d27-87c92e46bbfa",
        "parentId" : "2deab149-be25-4d14-a09d-0661db48ed8c",
        "authorId" : "808d9715-b3bd-4481-9935-20d7ca698e42",
        "body" : "That's a good idea. I will have a try.",
        "createdAt" : "2020-08-05T01:40:44Z",
        "updatedAt" : "2020-08-05T01:40:44Z",
        "lastEditedBy" : "808d9715-b3bd-4481-9935-20d7ca698e42",
        "tags" : [
        ]
      }
    ],
    "commit" : "1920c7bf3283083f6ee8851a731deacd9a7374a3",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +252,256 @@  }\n\n  def optimizeSingleStageSkewJoin(plan: SparkPlan): SparkPlan = plan.transformUp {\n    case smj @ SortMergeJoinExec(_, _, joinType, _,\n        sort @ SortExec(_, _, ShuffleStage(qs: ShuffleStageInfo), _), right, _) =>"
  },
  {
    "id" : "47dae22b-d01d-4692-b65d-497c2b74745a",
    "prId" : 29021,
    "prUrl" : "https://github.com/apache/spark/pull/29021#pullrequestreview-454697928",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "54d35a75-b01b-4968-8a09-6ee684143bc7",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "why not we break this limitation first?",
        "createdAt" : "2020-07-24T03:27:17Z",
        "updatedAt" : "2020-07-24T03:27:17Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "70f75ce0-6398-409a-9a30-077ae29bfbbf",
        "parentId" : "54d35a75-b01b-4968-8a09-6ee684143bc7",
        "authorId" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "body" : "Because this PR is not to address the case which has multiple SMJ. We have another PR to change this limitation:\r\n1. `optimizeSingleStageSkewJoin`. This is the case one table is a bucket table and the SMJ is bucketing join with one side shuffle and skewing\r\n2. `optimizeThreeShuffleStageSkewJoin`. This is to address three tables SMJ (Two SMJs in one stage and no one can be changed to BCJ in AQE).",
        "createdAt" : "2020-07-24T07:58:16Z",
        "updatedAt" : "2020-07-24T07:58:16Z",
        "lastEditedBy" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "tags" : [
        ]
      }
    ],
    "commit" : "5bed68ceed90c89457ff04af6da62f2222c795b7",
    "line" : 252,
    "diffHunk" : "@@ -1,1 +299,303 @@    val shuffleStages = collectShuffleStages(plan)\n\n    if (shuffleStages.length == 2) {\n      // SPARK-32201. Skew join supports below pattern, \"..\" may contain any number of nodes,\n      // includes such as BroadcastHashJoinExec. So it can handle more than two tables join."
  },
  {
    "id" : "85a126fa-1480-417b-9d11-1efcb09cf0c1",
    "prId" : 29021,
    "prUrl" : "https://github.com/apache/spark/pull/29021#pullrequestreview-454695097",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1a10bafd-7c0e-4d99-855e-b1a0676c99fb",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This PR is very hard to reason about. We need to clearly define:\r\n1. what nodes can appear between the shuffle stage and SMJ. As we discussed before, Agg can't appear at the skew side.\r\n2. how to estimate the size? Since there are nodes in the middle, the stats of the shuffle stage may not be accurate for the final join child. (e.g. Filter in the middle)",
        "createdAt" : "2020-07-24T03:29:57Z",
        "updatedAt" : "2020-07-24T03:29:57Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "4a9fcb17-cc27-44ef-bdcd-5948152da882",
        "parentId" : "1a10bafd-7c0e-4d99-855e-b1a0676c99fb",
        "authorId" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "body" : "> 1. what nodes can appear between the shuffle stage and SMJ. As we discussed before, Agg can't appear at the skew side.\r\n\r\nIn the `canSplitLeftSide` and `canSplitRightSide`, I added a `allUnspecifiedDistribution(plan)` check. Current we only support the nodes with `UnspecifiedDistribution`.\r\n\r\n> 2. how to estimate the size? Since there are nodes in the middle, the stats of the shuffle stage may not be accurate for the final join child. (e.g. Filter in the middle)\r\n\r\nFilter should be pushdown to leaf, I didn't see this user case. Project may be a command case in the middle? Yes. the input size of shuffle stage may not be accurate. But the disadvantage is launching more tasks. I think the benefit from handling the skewing is more important than the disadvantage.",
        "createdAt" : "2020-07-24T07:53:07Z",
        "updatedAt" : "2020-07-24T07:53:39Z",
        "lastEditedBy" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "tags" : [
        ]
      }
    ],
    "commit" : "5bed68ceed90c89457ff04af6da62f2222c795b7",
    "line" : 125,
    "diffHunk" : "@@ -1,1 +196,200 @@        assert(left.partitionsWithSizes.length == right.partitionsWithSizes.length)\n        val numPartitions = left.partitionsWithSizes.length\n        // We use the median size of the original shuffle partitions to detect skewed partitions.\n        val leftMedSize = medianSize(left.mapStats)\n        val rightMedSize = medianSize(right.mapStats)"
  },
  {
    "id" : "e6080d64-09bb-4357-af9b-28b474afc0ba",
    "prId" : 28947,
    "prUrl" : "https://github.com/apache/spark/pull/28947#pullrequestreview-440858516",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6e034c8e-068e-483b-94c6-e18606f0920c",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Can we make it more general? It seems like we can optimize any SMJ if its 2 children are both shuffle stages. cc @JkSelf @maryannxue ",
        "createdAt" : "2020-07-01T07:34:40Z",
        "updatedAt" : "2020-07-01T07:36:04Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "e6de2abd-dc41-4077-b974-0a8d3073f11c",
        "parentId" : "6e034c8e-068e-483b-94c6-e18606f0920c",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "For 3-table join, if they are in the same query stage, it means the shuffles are all leaf, and we will only optimize the first SMJ, as the second SMJ has only one side as shuffle stage.",
        "createdAt" : "2020-07-01T07:35:53Z",
        "updatedAt" : "2020-07-01T07:35:54Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "62853604-6cfe-4ff0-9913-c30e54f5408e",
        "parentId" : "6e034c8e-068e-483b-94c6-e18606f0920c",
        "authorId" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "body" : "> For 3-table join, if they are in the same query stage, it means the shuffles are all leaf, and we will only optimize the first SMJ, as the second SMJ has only one side as shuffle stage.\r\n\r\nWe have a 3-table skewed join implamentation in our internal code base. But we have replaced the skew join handling logic by community's. So our optimization is not work based on currnet `OptimizeSkewedJoin`. I will try to re-implement it in current `OptimizeSkewedJoin` and submit a PR later.",
        "createdAt" : "2020-07-01T13:11:19Z",
        "updatedAt" : "2020-07-01T13:20:42Z",
        "lastEditedBy" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "tags" : [
        ]
      },
      {
        "id" : "7e97fbd3-8bcf-4a31-be4a-323c2a39ff1d",
        "parentId" : "6e034c8e-068e-483b-94c6-e18606f0920c",
        "authorId" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "body" : "> Can we make it more general? It seems like we can optimize any SMJ if its 2 children are both shuffle stages. cc @JkSelf @maryannxue\r\n\r\nYes. we usually implemented some optimizations based on our inner usages and issues. So it may be not general. I only see the UNION case so far.",
        "createdAt" : "2020-07-01T13:16:16Z",
        "updatedAt" : "2020-07-01T13:16:43Z",
        "lastEditedBy" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "tags" : [
        ]
      }
    ],
    "commit" : "d011e9a11f416c73af4a602f9966db35c2643dd8",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +290,294 @@    }\n\n    // Try to handle skew join with union case, like\n    // Union\n    //   SMJ"
  },
  {
    "id" : "1d55117f-b898-42be-ab4b-8a3b03a025a4",
    "prId" : 28226,
    "prUrl" : "https://github.com/apache/spark/pull/28226#pullrequestreview-393833834",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "627fed44-bfb1-4ab2-a2b8-483ac96ae4fc",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I'll backport this fix to 3.0 later.",
        "createdAt" : "2020-04-15T14:32:58Z",
        "updatedAt" : "2020-04-20T07:01:24Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "3eccb706b9047e3d815850986bc99859cfda626e",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +93,97 @@    } else {\n      math.max(advisorySize, nonSkewSizes.sum / nonSkewSizes.length)\n    }\n  }\n"
  },
  {
    "id" : "755111a8-2d84-4456-a1e1-b220bea42950",
    "prId" : 28226,
    "prUrl" : "https://github.com/apache/spark/pull/28226#pullrequestreview-396171306",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ef1e773a-74d3-4bbd-9f53-227cade60769",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Why it's possible empty now?",
        "createdAt" : "2020-04-20T03:57:52Z",
        "updatedAt" : "2020-04-20T07:01:24Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "70ddc9c0-c0f6-4a3c-a2a7-7f5f963082b9",
        "parentId" : "ef1e773a-74d3-4bbd-9f53-227cade60769",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "because we calculate the median size based on the original map stats, but the input partitions are coalesced. It's possible all partitions (after coalesce) are skewed.",
        "createdAt" : "2020-04-20T05:27:33Z",
        "updatedAt" : "2020-04-20T07:01:24Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "473a27b4-0fec-468d-b028-273699e817bb",
        "parentId" : "ef1e773a-74d3-4bbd-9f53-227cade60769",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "I see, thanks!",
        "createdAt" : "2020-04-20T06:30:26Z",
        "updatedAt" : "2020-04-20T07:01:24Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "3eccb706b9047e3d815850986bc99859cfda626e",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +89,93 @@    val advisorySize = conf.getConf(SQLConf.ADVISORY_PARTITION_SIZE_IN_BYTES)\n    val nonSkewSizes = sizes.filterNot(isSkewed(_, medianSize))\n    if (nonSkewSizes.isEmpty) {\n      advisorySize\n    } else {"
  },
  {
    "id" : "11d40bd7-ec3d-4e4e-9077-8094e742f6d1",
    "prId" : 28022,
    "prUrl" : "https://github.com/apache/spark/pull/28022#pullrequestreview-383969110",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3322a8b7-5318-4a06-a8a1-0ad0e33843f7",
        "parentId" : null,
        "authorId" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "body" : "Would it make sense to make this size part of the return value from `splitSizeListByTargetSize`?\r\nOr even make `splitSizeListByTargetSize` return partition specs directly, like the other utility func?",
        "createdAt" : "2020-03-26T15:55:29Z",
        "updatedAt" : "2020-03-31T06:46:21Z",
        "lastEditedBy" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "tags" : [
        ]
      },
      {
        "id" : "307b2b31-789d-4773-87bf-11207735cc56",
        "parentId" : "3322a8b7-5318-4a06-a8a1-0ad0e33843f7",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I'd like to keep `splitSizeListByTargetSize` simple so that we can reuse it in more places, e.g. coalescing the shuffle partitions.",
        "createdAt" : "2020-03-30T15:25:05Z",
        "updatedAt" : "2020-03-31T06:46:21Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "a2e4ab37263d577b1211d8bd2fe56f8329cec357",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +121,125 @@          mapStartIndices(i + 1)\n        }\n        val dataSize = startMapIndex.until(endMapIndex).map(mapPartitionSizes(_)).sum\n        PartialReducerPartitionSpec(reducerId, startMapIndex, endMapIndex, dataSize)\n      })"
  },
  {
    "id" : "78f8e330-841f-4ac5-9fcc-c23bdea1f15a",
    "prId" : 27967,
    "prUrl" : "https://github.com/apache/spark/pull/27967#pullrequestreview-380881708",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f9b23cb9-c85d-4e29-b08d-2fe2ec27f79e",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Do we still guarantee this after having s separate conf?\r\nhttps://github.com/apache/spark/blob/30d95356f1881c32eb39e51525d2bcb331fcf867/sql/core/src/main/scala/org/apache/spark/sql/execution/adaptive/OptimizeSkewedJoin.scala#L196 ",
        "createdAt" : "2020-03-25T01:35:46Z",
        "updatedAt" : "2020-03-25T08:58:45Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "73c339b1-d7d3-4b77-89ca-20a0d9374ae2",
        "parentId" : "f9b23cb9-c85d-4e29-b08d-2fe2ec27f79e",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "now it's possible, if people set `SKEW_JOIN_SKEWED_PARTITION_THRESHOLD` much lower than `ADVISORY_PARTITION_SIZE_IN_BYTES`. But that's more like a malformed setting and we should simply ignore it.",
        "createdAt" : "2020-03-25T06:09:18Z",
        "updatedAt" : "2020-03-25T08:58:45Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "392400eb-082c-42b3-9dab-5b1372d2b5f1",
        "parentId" : "f9b23cb9-c85d-4e29-b08d-2fe2ec27f79e",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "We'd better to update doc to warn user not to do so.",
        "createdAt" : "2020-03-25T06:21:35Z",
        "updatedAt" : "2020-03-25T08:58:45Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "914eaf59db2beb11a1ac843acd5b2ae59e612315",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +68,72 @@  private def isSkewed(size: Long, medianSize: Long): Boolean = {\n    size > medianSize * conf.getConf(SQLConf.SKEW_JOIN_SKEWED_PARTITION_FACTOR) &&\n      size > conf.getConf(SQLConf.SKEW_JOIN_SKEWED_PARTITION_THRESHOLD)\n  }\n"
  },
  {
    "id" : "2b5d425a-7097-4beb-9594-2a7bc85b715f",
    "prId" : 27893,
    "prUrl" : "https://github.com/apache/spark/pull/27893#pullrequestreview-374368769",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d7aca520-5618-4ab6-8170-762fbb14dcc9",
        "parentId" : null,
        "authorId" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "body" : "nit: partitions -> partitionsWithSizes?",
        "createdAt" : "2020-03-13T14:58:31Z",
        "updatedAt" : "2020-03-16T17:12:12Z",
        "lastEditedBy" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "tags" : [
        ]
      }
    ],
    "commit" : "c67590a7163aa0435c64df3380932037330002a4",
    "line" : 339,
    "diffHunk" : "@@ -1,1 +322,326 @@}\n\nprivate case class ShuffleStageInfo(\n    shuffleStage: ShuffleQueryStageExec,\n    mapStats: MapOutputStatistics,"
  },
  {
    "id" : "520a4d5d-4d8e-40e2-bccd-1aea5d62093c",
    "prId" : 27893,
    "prUrl" : "https://github.com/apache/spark/pull/27893#pullrequestreview-374892661",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8180a39f-0036-469b-9aaf-c617cc6e0284",
        "parentId" : null,
        "authorId" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "body" : "nit: sizes.slice(start, end).sum?",
        "createdAt" : "2020-03-13T15:36:28Z",
        "updatedAt" : "2020-03-16T17:12:12Z",
        "lastEditedBy" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "tags" : [
        ]
      },
      {
        "id" : "3ef29bde-ba35-46e3-b2bd-f6bc0c101c97",
        "parentId" : "8180a39f-0036-469b-9aaf-c617cc6e0284",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "`slice` will create a new array, which is less efficient.",
        "createdAt" : "2020-03-16T03:22:25Z",
        "updatedAt" : "2020-03-16T17:12:12Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "c67590a7163aa0435c64df3380932037330002a4",
    "line" : 317,
    "diffHunk" : "@@ -1,1 +300,304 @@      val partitions = partitionSpecs.map {\n        case spec @ CoalescedPartitionSpec(start, end) =>\n          var sum = 0L\n          var i = start\n          while (i < end) {"
  },
  {
    "id" : "b16ff9b5-f2b3-45ee-8e8a-553a2cb2cbc3",
    "prId" : 27893,
    "prUrl" : "https://github.com/apache/spark/pull/27893#pullrequestreview-375383498",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c8b91876-f7da-461d-a499-225cf639b1a0",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "@JkSelf I tried to create a common method to handle both sides, but the method takes too many parameters so I give up. Besides, it's not much duplicated code here.",
        "createdAt" : "2020-03-16T16:31:53Z",
        "updatedAt" : "2020-03-16T17:12:12Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "c67590a7163aa0435c64df3380932037330002a4",
    "line" : 186,
    "diffHunk" : "@@ -1,1 +195,199 @@\n        // A skewed partition should never be coalesced, but skip it here just to be safe.\n        val leftParts = if (isLeftSkew && !isLeftCoalesced) {\n          val reducerId = leftPartSpec.startReducerIndex\n          val skewSpecs = createSkewPartitionSpecs("
  },
  {
    "id" : "be9cd959-fba5-4d8a-93f3-fbc2190a814c",
    "prId" : 27893,
    "prUrl" : "https://github.com/apache/spark/pull/27893#pullrequestreview-375762672",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9b26b0db-f166-4d3f-8b98-9c2ee74e7998",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Say we have original map output: 100, 10, 2000, and the coalesce target is 100. So, after `CoalesceShufflePartitions`, we shall have `CoalescedPartitionSpec(0, 1)` and `CoalescedPartitionSpec(1, 3)`. Then, we start to apply `OptimizeSkewedJoin` where `CoalescedPartitionSpec(1, 3)` is obviously skewed but can be missed. Right?",
        "createdAt" : "2020-03-17T02:46:10Z",
        "updatedAt" : "2020-03-17T02:46:15Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "9fab5479-90a7-4eb6-81ac-c2a95d7eefc4",
        "parentId" : "9b26b0db-f166-4d3f-8b98-9c2ee74e7998",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I don't think the coalesce rule will coalesce `10` and `2000`, can you double check?",
        "createdAt" : "2020-03-17T04:03:13Z",
        "updatedAt" : "2020-03-17T04:03:13Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "60b2d043-d469-4966-8fae-5e29b6b090ea",
        "parentId" : "9b26b0db-f166-4d3f-8b98-9c2ee74e7998",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Oh yeah, I checked, you're right!",
        "createdAt" : "2020-03-17T06:14:13Z",
        "updatedAt" : "2020-03-17T06:14:13Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "c67590a7163aa0435c64df3380932037330002a4",
    "line" : 185,
    "diffHunk" : "@@ -1,1 +194,198 @@        val isRightCoalesced = rightPartSpec.startReducerIndex + 1 < rightPartSpec.endReducerIndex\n\n        // A skewed partition should never be coalesced, but skip it here just to be safe.\n        val leftParts = if (isLeftSkew && !isLeftCoalesced) {\n          val reducerId = leftPartSpec.startReducerIndex"
  },
  {
    "id" : "da814e38-dd13-48cb-9f41-180b0d83773f",
    "prId" : 27669,
    "prUrl" : "https://github.com/apache/spark/pull/27669#pullrequestreview-363507529",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a9f5b917-6cdc-4198-a3a8-8a6850de63d6",
        "parentId" : null,
        "authorId" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "body" : "We can move this repetitive calc of non-skew average size out of this method, which will leave us just two local variables before the main loop below: `targetPostShuffleSizeConf` and `nonSkewAvgSize`. Then we only need to do: `max(targetPostShuffleSizeConf, nonSkewAvgSize)` without a method call.",
        "createdAt" : "2020-02-21T15:58:25Z",
        "updatedAt" : "2020-02-25T06:55:56Z",
        "lastEditedBy" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "tags" : [
        ]
      },
      {
        "id" : "7db57bb2-f390-470d-b544-1bbf3c3f2f86",
        "parentId" : "a9f5b917-6cdc-4198-a3a8-8a6850de63d6",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This method is called before entering the main loop, so it's not repetitive calc.",
        "createdAt" : "2020-02-24T13:42:58Z",
        "updatedAt" : "2020-02-25T06:55:56Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "1cb5196b-829f-4cab-9151-89755c6f31e0",
        "parentId" : "a9f5b917-6cdc-4198-a3a8-8a6850de63d6",
        "authorId" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "body" : "yeah, you are right!",
        "createdAt" : "2020-02-24T16:08:22Z",
        "updatedAt" : "2020-02-25T06:55:56Z",
        "lastEditedBy" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "tags" : [
        ]
      }
    ],
    "commit" : "4755526bd20f44aa24f91a120c98518330081398",
    "line" : 58,
    "diffHunk" : "@@ -1,1 +93,97 @@  private def targetSize(stats: MapOutputStatistics, medianSize: Long): Long = {\n    val targetPostShuffleSize = conf.getConf(SQLConf.SHUFFLE_TARGET_POSTSHUFFLE_INPUT_SIZE)\n    val nonSkewSizes = stats.bytesByPartitionId.filterNot(isSkewed(_, medianSize))\n    // It's impossible that all the partitions are skewed, as we use median size to define skew.\n    assert(nonSkewSizes.nonEmpty)"
  },
  {
    "id" : "d82df45c-d2a8-4544-a17f-494cc4666177",
    "prId" : 27669,
    "prUrl" : "https://github.com/apache/spark/pull/27669#pullrequestreview-368383402",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e1a1ce11-06ff-45de-aff5-0a67a3a6bb21",
        "parentId" : null,
        "authorId" : "1b84a7ff-6bf9-4417-bf9f-e46e997e5974",
        "body" : "When user enable skewed join optimization and want to change the skewed condition by adjusting the `targetPostShuffleSize`. If we use the `SHUFFLE_TARGET_POSTSHUFFLE_INPUT_SIZE` here, it may also effect the task numbers in map stage.  It is better to use the `ADAPTIVE_EXECUTION_SKEWED_PARTITION_SIZE_THRESHOLD` config  to set the `targetPostShuffleSize` in skewed join optimization?",
        "createdAt" : "2020-02-25T01:01:45Z",
        "updatedAt" : "2020-02-25T06:55:56Z",
        "lastEditedBy" : "1b84a7ff-6bf9-4417-bf9f-e46e997e5974",
        "tags" : [
        ]
      },
      {
        "id" : "e4bd37e0-fa80-4a46-a1e5-d959daba5214",
        "parentId" : "e1a1ce11-06ff-45de-aff5-0a67a3a6bb21",
        "authorId" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "body" : "Why would user want the new partition size after split to be different from the sizes of non-skew partition size? The goal of this rule is to coordinate all partitions to be around the same size if possible...",
        "createdAt" : "2020-02-25T04:34:14Z",
        "updatedAt" : "2020-02-25T06:55:56Z",
        "lastEditedBy" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "tags" : [
        ]
      },
      {
        "id" : "aff42ab0-7aa0-4926-aade-951f0a4017dd",
        "parentId" : "e1a1ce11-06ff-45de-aff5-0a67a3a6bb21",
        "authorId" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "body" : "The problem with the old approach was the new skew partition size after split can be much smaller than that of the non-skew partition size. Being small itself is not a problem, but having more splits may come with a price, esp. with both side skews, and meanwhile if non-skew partitions take longer to finish, it wouldn't be worth that price.",
        "createdAt" : "2020-02-25T04:38:53Z",
        "updatedAt" : "2020-02-25T06:55:56Z",
        "lastEditedBy" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "tags" : [
        ]
      },
      {
        "id" : "ce02a152-411b-4d0d-9a9c-f74abfd6aa8b",
        "parentId" : "e1a1ce11-06ff-45de-aff5-0a67a3a6bb21",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "@JkSelf do you have any real-world use cases for it? I noticed it as well but have the same feeling with @maryannxue : why would users set a different value?",
        "createdAt" : "2020-02-25T08:59:34Z",
        "updatedAt" : "2020-02-25T08:59:34Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "a35875fb-39ad-4d6d-a9f6-3bbb2daef1a8",
        "parentId" : "e1a1ce11-06ff-45de-aff5-0a67a3a6bb21",
        "authorId" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "body" : "After coming across the config description of `ADAPTIVE_EXECUTION_SKEWED_PARTITION_SIZE_THRESHOLD`, I probably get @JkSelf 's point. In the description, it is meant to test if a partition is skewed... but the way it is actually used here in this class, it is more like the target size for splitting the skewed partitions.\r\nSo we need to changes here:\r\n1. bring this conf back and use it in `isSkewed` instead.\r\n2. if eventually the entire \"skewed\" partition is not split at all because the size is smaller than the target size, we need to avoid adding the SkewDesc for that partition.",
        "createdAt" : "2020-03-03T22:47:49Z",
        "updatedAt" : "2020-03-03T22:47:49Z",
        "lastEditedBy" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "tags" : [
        ]
      }
    ],
    "commit" : "4755526bd20f44aa24f91a120c98518330081398",
    "line" : 57,
    "diffHunk" : "@@ -1,1 +92,96 @@   */\n  private def targetSize(stats: MapOutputStatistics, medianSize: Long): Long = {\n    val targetPostShuffleSize = conf.getConf(SQLConf.SHUFFLE_TARGET_POSTSHUFFLE_INPUT_SIZE)\n    val nonSkewSizes = stats.bytesByPartitionId.filterNot(isSkewed(_, medianSize))\n    // It's impossible that all the partitions are skewed, as we use median size to define skew."
  },
  {
    "id" : "9fe049a5-8d57-49d5-9b32-ace33201754e",
    "prId" : 27669,
    "prUrl" : "https://github.com/apache/spark/pull/27669#pullrequestreview-364594023",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "55ecaa04-d8cd-42c5-83a6-1897f16b694e",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "This seems to be a mistake. Did you want to say the following?\r\n```\r\n- (L1, R1), (L2, R2), (L2, R2), (L2, R2).\r\n+ (L1, R1), (L2, R2), (L3, R3), (L4, R4).\r\n```",
        "createdAt" : "2020-02-25T22:21:24Z",
        "updatedAt" : "2020-02-25T22:21:24Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "74b920b1-baa4-4f3a-ae6c-2f1b48e0f164",
        "parentId" : "55ecaa04-d8cd-42c5-83a6-1897f16b694e",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ah yes! will fix it soon",
        "createdAt" : "2020-02-26T02:55:46Z",
        "updatedAt" : "2020-02-26T02:55:46Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "4755526bd20f44aa24f91a120c98518330081398",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +49,53 @@ *\n * Let's say L2, L4 and R3, R4 are skewed, and each of them get split into 2 sub-partitions. This\n * is scheduled to run 4 tasks at the beginning: (L1, R1), (L2, R2), (L2, R2), (L2, R2).\n * This rule expands it to 9 tasks to increase parallelism:\n * (L1, R1),"
  },
  {
    "id" : "bce16ed6-6dbf-4507-8053-7d9ef6f77897",
    "prId" : 27493,
    "prUrl" : "https://github.com/apache/spark/pull/27493#pullrequestreview-356013785",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8679ba87-874d-49f3-afa2-93fddc8f7a90",
        "parentId" : null,
        "authorId" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "body" : "Can we add a comment here about `nonSkewPartitionIndices` used to delay creation of non-skew partitions and for potential coalescing?",
        "createdAt" : "2020-02-10T15:33:36Z",
        "updatedAt" : "2020-02-13T12:28:23Z",
        "lastEditedBy" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "tags" : [
        ]
      }
    ],
    "commit" : "b4a0606c240476d037a912e238b4a25e33b4e6da",
    "line" : 73,
    "diffHunk" : "@@ -1,1 +162,166 @@      // This is used to delay the creation of non-skew partitions so that we can potentially\n      // coalesce them like `ReduceNumShufflePartitions` does.\n      val nonSkewPartitionIndices = mutable.ArrayBuffer.empty[Int]\n      val leftSkewDesc = new SkewDesc\n      val rightSkewDesc = new SkewDesc"
  },
  {
    "id" : "882738fc-ab96-4585-a0dc-3d260c3d9ac1",
    "prId" : 27493,
    "prUrl" : "https://github.com/apache/spark/pull/27493#pullrequestreview-356013785",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d694e94e-f905-4341-a2e1-56aab650591c",
        "parentId" : null,
        "authorId" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "body" : "code comment: as soon as we see a skew, we'll \"flush\" out unhandled non-skew partitions.",
        "createdAt" : "2020-02-10T15:35:47Z",
        "updatedAt" : "2020-02-13T12:28:23Z",
        "lastEditedBy" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "tags" : [
        ]
      }
    ],
    "commit" : "b4a0606c240476d037a912e238b4a25e33b4e6da",
    "line" : 82,
    "diffHunk" : "@@ -1,1 +171,175 @@        val isRightSkew = isSkewed(rightSize, rightMedSize) && canSplitRight\n        if (isLeftSkew || isRightSkew) {\n          if (nonSkewPartitionIndices.nonEmpty) {\n            // As soon as we see a skew, we'll \"flush\" out unhandled non-skew partitions.\n            createNonSkewPartitions(leftStats, rightStats, nonSkewPartitionIndices).foreach { p =>"
  },
  {
    "id" : "bd8d9764-ca35-4afa-92b3-582659eb7e36",
    "prId" : 27493,
    "prUrl" : "https://github.com/apache/spark/pull/27493#pullrequestreview-357284988",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "092f5d75-fe52-4a8c-be2c-6f6df40b890b",
        "parentId" : null,
        "authorId" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "body" : "Eventually we should be able to just have one reader, right?",
        "createdAt" : "2020-02-10T15:43:31Z",
        "updatedAt" : "2020-02-13T12:28:23Z",
        "lastEditedBy" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "tags" : [
        ]
      },
      {
        "id" : "e0fa8ded-c26b-4918-9f15-05dc0d2cb7bb",
        "parentId" : "092f5d75-fe52-4a8c-be2c-6f6df40b890b",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I think we still need multiple shuffle readers, but use the same RDD.\r\n\r\nFor example, `LocalShuffleReaderExec` override `outputPartitioning`",
        "createdAt" : "2020-02-10T15:56:35Z",
        "updatedAt" : "2020-02-13T12:28:23Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "bc18d44e-8c6c-4674-a9b8-09f5219668ab",
        "parentId" : "092f5d75-fe52-4a8c-be2c-6f6df40b890b",
        "authorId" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "body" : "You could just have one reader, that just takes the output partitioning as a parameter. I am kind of in favor of this since it eliminates 3 nearly identical nodes.",
        "createdAt" : "2020-02-12T09:07:03Z",
        "updatedAt" : "2020-02-13T12:28:23Z",
        "lastEditedBy" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "tags" : [
        ]
      }
    ],
    "commit" : "b4a0606c240476d037a912e238b4a25e33b4e6da",
    "line" : 319,
    "diffHunk" : "@@ -1,1 +361,365 @@ * @param skewDesc The description of the skewed partitions.\n */\ncase class SkewJoinShuffleReaderExec(\n    child: SparkPlan,\n    partitionSpecs: Array[ShufflePartitionSpec],"
  },
  {
    "id" : "e5fee1b7-9332-4fe2-97eb-aead64e4ad7f",
    "prId" : 27493,
    "prUrl" : "https://github.com/apache/spark/pull/27493#pullrequestreview-357841031",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "85c93f22-538c-4ce8-b9e2-711bf735a5a4",
        "parentId" : null,
        "authorId" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "body" : "This is pretty neat.",
        "createdAt" : "2020-02-12T22:39:01Z",
        "updatedAt" : "2020-02-13T12:28:23Z",
        "lastEditedBy" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "tags" : [
        ]
      }
    ],
    "commit" : "b4a0606c240476d037a912e238b4a25e33b4e6da",
    "line" : 199,
    "diffHunk" : "@@ -1,1 +244,248 @@      Seq(SinglePartitionSpec(nonSkewPartitionIndices.head))\n    } else {\n      val startIndices = ShufflePartitionsCoalescer.coalescePartitions(\n        Array(leftStats, rightStats),\n        firstPartitionIndex = nonSkewPartitionIndices.head,"
  },
  {
    "id" : "43b6d4f8-cda8-454d-b252-c9d2cb8da632",
    "prId" : 27253,
    "prUrl" : "https://github.com/apache/spark/pull/27253#pullrequestreview-345148873",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "00612194-fb34-4e0b-8150-2efbf8bf4e9e",
        "parentId" : null,
        "authorId" : "334a081c-cba1-403e-ac80-30e6124077d1",
        "body" : "minor: only one case now",
        "createdAt" : "2020-01-20T08:46:42Z",
        "updatedAt" : "2020-01-20T08:46:42Z",
        "lastEditedBy" : "334a081c-cba1-403e-ac80-30e6124077d1",
        "tags" : [
        ]
      }
    ],
    "commit" : "0b6aae422ba37a13531e98c8801589f5f3cb28e0",
    "line" : 77,
    "diffHunk" : "@@ -1,1 +225,229 @@    if (shuffleStages.length == 2) {\n      // When multi table join, there will be too many complex combination to consider.\n      // Currently we only handle 2 table join like following two use cases.\n      // SMJ\n      //   Sort"
  },
  {
    "id" : "208980b5-4eb1-428a-855e-79e7d1a75c74",
    "prId" : 27226,
    "prUrl" : "https://github.com/apache/spark/pull/27226#pullrequestreview-344049019",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "21dcedda-5145-4cc0-981d-29a120f54e72",
        "parentId" : null,
        "authorId" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "body" : "Sorry that my previous comment was wrong. Once we have shuffle, there should always be a sort. So we don't need to match this.",
        "createdAt" : "2020-01-16T16:32:04Z",
        "updatedAt" : "2020-01-16T16:32:05Z",
        "lastEditedBy" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "tags" : [
        ]
      }
    ],
    "commit" : "c37f39774825c052cd93f35288ff105c8292c343",
    "line" : 154,
    "diffHunk" : "@@ -1,1 +248,252 @@      // When multi table join, there will be too many complex combination to consider.\n      // Currently we only handle 2 table join like following two use cases.\n      // SMJ                    SMJ\n      //   Sort                   Shuffle\n      //     Shuffle      or      Shuffle"
  }
]