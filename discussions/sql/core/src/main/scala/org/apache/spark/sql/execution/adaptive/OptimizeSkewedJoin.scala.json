[
  {
    "id" : "9fd93545-8fe9-411e-b780-d87552a93d13",
    "prId" : 33541,
    "prUrl" : "https://github.com/apache/spark/pull/33541#pullrequestreview-716593700",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "aaf3fc6d-2c81-45fc-b8bf-21436332f81e",
        "parentId" : null,
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "style seems wrong",
        "createdAt" : "2021-07-28T03:40:54Z",
        "updatedAt" : "2021-07-28T03:55:46Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      },
      {
        "id" : "e2fad8f5-df9d-43e9-b5a7-6f8fbbb5c710",
        "parentId" : "aaf3fc6d-2c81-45fc-b8bf-21436332f81e",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I moved this object into the class",
        "createdAt" : "2021-07-28T04:44:13Z",
        "updatedAt" : "2021-07-28T04:44:13Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "28fb3ef5-a593-4290-bef9-341309912d2e",
        "parentId" : "aaf3fc6d-2c81-45fc-b8bf-21436332f81e",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "ah, I see",
        "createdAt" : "2021-07-28T05:30:36Z",
        "updatedAt" : "2021-07-28T05:30:36Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "61cc6751e4baad96f0a8b251296c6e58ffbbf3a3",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +257,261 @@  }\n\n  object ShuffleStage {\n    def unapply(plan: SparkPlan): Option[ShuffleQueryStageExec] = plan match {\n      case s: ShuffleQueryStageExec if s.mapStats.isDefined && isSupported(s.shuffle) =>"
  },
  {
    "id" : "68c62dfa-5ea4-481c-b06b-7c0d05b1567b",
    "prId" : 32685,
    "prUrl" : "https://github.com/apache/spark/pull/32685#pullrequestreview-669818725",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3bb97936-0641-4755-8251-662d023112a8",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "now we don't need to call `isSkewed` repeatedly",
        "createdAt" : "2021-05-27T07:14:07Z",
        "updatedAt" : "2021-05-27T07:14:07Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "9e469d093bdee7a51a81ae442c1c04679d8ed748",
    "line" : 65,
    "diffHunk" : "@@ -1,1 +187,191 @@    for (partitionIndex <- 0 until numPartitions) {\n      val leftSize = leftSizes(partitionIndex)\n      val isLeftSkew = canSplitLeft && leftSize > leftSkewThreshold\n      val rightSize = rightSizes(partitionIndex)\n      val isRightSkew = canSplitRight && rightSize > rightSkewThreshold"
  },
  {
    "id" : "3d6833c3-16d1-4d25-b445-d4bf54809947",
    "prId" : 32328,
    "prUrl" : "https://github.com/apache/spark/pull/32328#pullrequestreview-646635361",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a900fc9d-8be9-46da-9b8c-ff6e3efbfd90",
        "parentId" : null,
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "immature thoughts on this optimization:\r\n\r\n`OptimizeSkewedJoin` try to make sizes of shuffle partitions more even. \r\n\r\nFor bhj, should we change the *optimization goal of build side* to making sure build side fit in memory to avoid OOM or fallback to smj.\r\n\r\nIs it possible that the build side is skewed according current criterions, but the shuffle partitions all fit in memory?\r\n\r\n",
        "createdAt" : "2021-04-28T02:32:39Z",
        "updatedAt" : "2021-04-28T02:32:39Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      },
      {
        "id" : "99c631e1-e4ac-4322-83ac-3ad19c0b5b60",
        "parentId" : "a900fc9d-8be9-46da-9b8c-ff6e3efbfd90",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "In current implementaion, we have already supported optimize skew build side with inner join. For other join type we cann't optimize it due to the semantics.\r\n\r\nIMO It's better to consider OOM at shj itself instead of fallback to smj which might make things more complicated. Actually, we might change smj to shj at `reOptimize` if we disable the `preferSortMerge`, so it's confused to change join strategy again.",
        "createdAt" : "2021-04-28T05:29:34Z",
        "updatedAt" : "2021-04-28T05:29:34Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      },
      {
        "id" : "568326e7-d3b3-45d8-b413-b2701009c412",
        "parentId" : "a900fc9d-8be9-46da-9b8c-ff6e3efbfd90",
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "Sorry my comment was misleading, the `fallback to smj` there means https://github.com/apache/spark/pull/32210\r\n\r\nMy thought is that we may take potential OOM into account here,\r\nlet build side A inner join stream side B, for a build partition A_0:\r\n\r\n- if A_0 is skewed but is less than a OOM threshold, we may not split it;\r\n- if A_0 is not skewed but greater than that threshold, we may still need to split it;\r\n\r\n",
        "createdAt" : "2021-04-28T06:08:23Z",
        "updatedAt" : "2021-04-28T06:08:24Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      },
      {
        "id" : "58014f86-ddd1-4a58-8772-6449703aa95b",
        "parentId" : "a900fc9d-8be9-46da-9b8c-ff6e3efbfd90",
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "My hunch is when the build side can be potentially OOM-ed, it should already be considered as skewed. So after AQE skew handling, some of potentially OOM-ed build side (inner join only) can be avoided.\r\n\r\nHowever, for queries with other join types, queries not having shuffle before join, and queries with run-time hash map being significantly larger than partition size, we should have run-time fallback mechanism in shuffled hash join itself. This PR and #32210 should be good to have and orthogonal to each other.",
        "createdAt" : "2021-04-28T06:25:50Z",
        "updatedAt" : "2021-04-28T06:25:50Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      }
    ],
    "commit" : "cab5290a89526a32f826f1d2fffff9132d6e2a8d",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +147,151 @@\n  /*\n   * This method aim to optimize the skewed join with the following steps:\n   * 1. Check whether the shuffle partition is skewed based on the median size\n   *    and the skewed partition threshold in origin shuffled join (smj and shj)."
  },
  {
    "id" : "9fc719d7-99fd-4ac4-85cd-490b9b1bab1f",
    "prId" : 31653,
    "prUrl" : "https://github.com/apache/spark/pull/31653#pullrequestreview-625954479",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fc0aeb06-f5a5-43c6-b3a8-83388b45294f",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Currently this rule is very limited: it only applies to SMJ with 2 shuffle query stages as the direct children.\r\n\r\nI don't think it's a big difference if we move this rule to `queryStagePreparationRules`. We still need to match SMJ with 2 shuffle query stages as the direct children, with an additional check that the query stages must be materialized, which is guaranteed for query stage optimization rules.",
        "createdAt" : "2021-03-29T17:03:13Z",
        "updatedAt" : "2021-03-29T17:14:45Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "f55c882e-b7e1-49f8-bd5b-c86df7d6c5bd",
        "parentId" : "fc0aeb06-f5a5-43c6-b3a8-83388b45294f",
        "authorId" : "9acf210d-4935-4e03-8384-d944eb558b45",
        "body" : "1. with this PR, if you have \r\n```\r\nSMJ1\r\n |-...\r\n |-SMJ2\r\n    |-...\r\n    |-...\r\n```\r\nin a single stage, `OprimizeSkewedJoin` has to pay attention to it because it may decide to mitigate skew in SMJ2 and insert a shuffle above it, breaking up the stage\r\n2. My comment in the code was referring to something different.  When `OprimizeSkewedJoin` runs as part of `queryStagePreparationRules`, it may run over a plan like this for example\r\n```\r\nSMJ0\r\n|-Exch\r\n |-SMJ1\r\n    |-...\r\n    |-...\r\n|-Exch \r\n |-SMJ2\r\n    |-...\r\n    |-...\r\n```\r\nwhere all inputs to SMJ1/SMJ2 are materialized.  And it has to make a decision about each SMJ separately.  Previously (when `OprimizeSkewedJoin` was part of `queryStageOptimizerRules`, any given run of `OprimizeSkewedJoin` would either see SMJ1 or SMJ2 but not both)\r\n",
        "createdAt" : "2021-03-30T17:47:20Z",
        "updatedAt" : "2021-03-30T17:47:20Z",
        "lastEditedBy" : "9acf210d-4935-4e03-8384-d944eb558b45",
        "tags" : [
        ]
      },
      {
        "id" : "68ce837d-a0d2-4e8e-9cde-de041b77b602",
        "parentId" : "fc0aeb06-f5a5-43c6-b3a8-83388b45294f",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Maybe we don't have to be optimal in the first version. We can optimize all the leaf SMJs, and revert all of them if extra shuffles are introduced. The optimal solution is to find out which SMJ caused the extra shuffle and only revert it. We can do it later.",
        "createdAt" : "2021-03-31T05:58:39Z",
        "updatedAt" : "2021-03-31T05:58:39Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "3c0b70ce-d0fb-45a6-8cf0-0e1acd7782d4",
        "parentId" : "fc0aeb06-f5a5-43c6-b3a8-83388b45294f",
        "authorId" : "9acf210d-4935-4e03-8384-d944eb558b45",
        "body" : "Not sure I follow.  This point of this PR is to allow `OptimizeSkewedJoin` to add extra shuffles...",
        "createdAt" : "2021-03-31T20:06:19Z",
        "updatedAt" : "2021-03-31T20:06:19Z",
        "lastEditedBy" : "9acf210d-4935-4e03-8384-d944eb558b45",
        "tags" : [
        ]
      },
      {
        "id" : "42e67624-cb97-4fe9-8c39-e0015eef4cfc",
        "parentId" : "fc0aeb06-f5a5-43c6-b3a8-83388b45294f",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I was talking about the default case. If we enable the config and allow extra shuffles, then it's pretty straightforward and we just optimize all the leaf SMJs.",
        "createdAt" : "2021-04-01T07:02:26Z",
        "updatedAt" : "2021-04-01T07:02:26Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "7cfda59a1e9a8e0f86e2e6424c21639c1b5b14e3",
    "line" : 112,
    "diffHunk" : "@@ -1,1 +310,314 @@  /**\n   * Now this runs as part of queryStagePreparationRules() which means it runs over the whole plan\n   * which may have any number of ExchangeExec nodes, i.e. multiple \"query stages\"\n   *\n   * This runs optimizeSkewJoin() on each \"query stage\" separately so that"
  },
  {
    "id" : "bf8fb112-e9e8-4213-847f-65dcacca19db",
    "prId" : 29692,
    "prUrl" : "https://github.com/apache/spark/pull/29692#pullrequestreview-492165531",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "708de2e4-3ec3-4ed8-9854-e2b33ca43ec5",
        "parentId" : null,
        "authorId" : "334a081c-cba1-403e-ac80-30e6124077d1",
        "body" : "Does this mean we will also handle multi-table join (e.g. three-table join) ?",
        "createdAt" : "2020-09-14T03:33:48Z",
        "updatedAt" : "2020-09-14T03:33:48Z",
        "lastEditedBy" : "334a081c-cba1-403e-ac80-30e6124077d1",
        "tags" : [
        ]
      },
      {
        "id" : "ed3398ed-9c15-4bfe-970b-0c3c969ba979",
        "parentId" : "708de2e4-3ec3-4ed8-9854-e2b33ca43ec5",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> Does this mean we will also handle multi-table join (e.g. three-table join) ?\r\n\r\nSince broadcast nested loop join only can have one side shuffle exchange, but sort merge join with two",
        "createdAt" : "2020-09-20T01:34:53Z",
        "updatedAt" : "2020-09-20T01:34:53Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "5c6f895f4e351589cc46adf0a50ad08a8f9a1c51",
    "line" : 177,
    "diffHunk" : "@@ -1,1 +355,359 @@    val shuffleStages = collectShuffleStages(plan)\n\n    if (shuffleStages.length >= 1) {\n      // When multi table join, there will be too many complex combination to consider.\n      // Currently we only handle 2 table join like following use case."
  },
  {
    "id" : "4035eb64-3285-4d8b-8ad6-fabea2c29a40",
    "prId" : 29266,
    "prUrl" : "https://github.com/apache/spark/pull/29266#pullrequestreview-461289288",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6698bc2c-d320-4a5f-bb23-ec76195a7b04",
        "parentId" : null,
        "authorId" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "body" : "Why is it that we don't need `if (qs.shuffleStage.shuffle.canChangeNumPartitions && canSplitLeftSide(joinType))` here??",
        "createdAt" : "2020-08-04T15:45:03Z",
        "updatedAt" : "2020-08-04T15:45:03Z",
        "lastEditedBy" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "tags" : [
        ]
      },
      {
        "id" : "c7dbbf1d-d7b7-410c-938c-ff28c944bc59",
        "parentId" : "6698bc2c-d320-4a5f-bb23-ec76195a7b04",
        "authorId" : "808d9715-b3bd-4481-9935-20d7ca698e42",
        "body" : "My fault, missed some code..",
        "createdAt" : "2020-08-05T02:01:08Z",
        "updatedAt" : "2020-08-05T02:01:09Z",
        "lastEditedBy" : "808d9715-b3bd-4481-9935-20d7ca698e42",
        "tags" : [
        ]
      }
    ],
    "commit" : "1920c7bf3283083f6ee8851a731deacd9a7374a3",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +271,275 @@    case smj @ SortMergeJoinExec(_, _, _, _, left,\n        sort @ SortExec(_, _, ShuffleStage(qs: ShuffleStageInfo), _), _) =>\n      val (numSkewed, splitPartitions, partitionIndexes) = handleSkewed(qs)\n      if (numSkewed > 0) {\n        logInfo(s\"number of skewed partitions $numSkewed\")"
  },
  {
    "id" : "b5b6306b-3f6c-4e61-85a5-6cad5088aa51",
    "prId" : 29266,
    "prUrl" : "https://github.com/apache/spark/pull/29266#pullrequestreview-461283251",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2deab149-be25-4d14-a09d-0661db48ed8c",
        "parentId" : null,
        "authorId" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "body" : "Is it possible to integrate this logic into the two-query-stage skew processing?\r\nWe can just treat the non-query-stage side as \"canSplitXXXSide(...) = false\", right?",
        "createdAt" : "2020-08-04T15:46:38Z",
        "updatedAt" : "2020-08-04T15:46:39Z",
        "lastEditedBy" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "tags" : [
        ]
      },
      {
        "id" : "5ef56b86-8340-4c18-9d27-87c92e46bbfa",
        "parentId" : "2deab149-be25-4d14-a09d-0661db48ed8c",
        "authorId" : "808d9715-b3bd-4481-9935-20d7ca698e42",
        "body" : "That's a good idea. I will have a try.",
        "createdAt" : "2020-08-05T01:40:44Z",
        "updatedAt" : "2020-08-05T01:40:44Z",
        "lastEditedBy" : "808d9715-b3bd-4481-9935-20d7ca698e42",
        "tags" : [
        ]
      }
    ],
    "commit" : "1920c7bf3283083f6ee8851a731deacd9a7374a3",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +252,256 @@  }\n\n  def optimizeSingleStageSkewJoin(plan: SparkPlan): SparkPlan = plan.transformUp {\n    case smj @ SortMergeJoinExec(_, _, joinType, _,\n        sort @ SortExec(_, _, ShuffleStage(qs: ShuffleStageInfo), _), right, _) =>"
  },
  {
    "id" : "47dae22b-d01d-4692-b65d-497c2b74745a",
    "prId" : 29021,
    "prUrl" : "https://github.com/apache/spark/pull/29021#pullrequestreview-454697928",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "54d35a75-b01b-4968-8a09-6ee684143bc7",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "why not we break this limitation first?",
        "createdAt" : "2020-07-24T03:27:17Z",
        "updatedAt" : "2020-07-24T03:27:17Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "70f75ce0-6398-409a-9a30-077ae29bfbbf",
        "parentId" : "54d35a75-b01b-4968-8a09-6ee684143bc7",
        "authorId" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "body" : "Because this PR is not to address the case which has multiple SMJ. We have another PR to change this limitation:\r\n1. `optimizeSingleStageSkewJoin`. This is the case one table is a bucket table and the SMJ is bucketing join with one side shuffle and skewing\r\n2. `optimizeThreeShuffleStageSkewJoin`. This is to address three tables SMJ (Two SMJs in one stage and no one can be changed to BCJ in AQE).",
        "createdAt" : "2020-07-24T07:58:16Z",
        "updatedAt" : "2020-07-24T07:58:16Z",
        "lastEditedBy" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "tags" : [
        ]
      }
    ],
    "commit" : "5bed68ceed90c89457ff04af6da62f2222c795b7",
    "line" : 252,
    "diffHunk" : "@@ -1,1 +299,303 @@    val shuffleStages = collectShuffleStages(plan)\n\n    if (shuffleStages.length == 2) {\n      // SPARK-32201. Skew join supports below pattern, \"..\" may contain any number of nodes,\n      // includes such as BroadcastHashJoinExec. So it can handle more than two tables join."
  },
  {
    "id" : "85a126fa-1480-417b-9d11-1efcb09cf0c1",
    "prId" : 29021,
    "prUrl" : "https://github.com/apache/spark/pull/29021#pullrequestreview-454695097",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1a10bafd-7c0e-4d99-855e-b1a0676c99fb",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This PR is very hard to reason about. We need to clearly define:\r\n1. what nodes can appear between the shuffle stage and SMJ. As we discussed before, Agg can't appear at the skew side.\r\n2. how to estimate the size? Since there are nodes in the middle, the stats of the shuffle stage may not be accurate for the final join child. (e.g. Filter in the middle)",
        "createdAt" : "2020-07-24T03:29:57Z",
        "updatedAt" : "2020-07-24T03:29:57Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "4a9fcb17-cc27-44ef-bdcd-5948152da882",
        "parentId" : "1a10bafd-7c0e-4d99-855e-b1a0676c99fb",
        "authorId" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "body" : "> 1. what nodes can appear between the shuffle stage and SMJ. As we discussed before, Agg can't appear at the skew side.\r\n\r\nIn the `canSplitLeftSide` and `canSplitRightSide`, I added a `allUnspecifiedDistribution(plan)` check. Current we only support the nodes with `UnspecifiedDistribution`.\r\n\r\n> 2. how to estimate the size? Since there are nodes in the middle, the stats of the shuffle stage may not be accurate for the final join child. (e.g. Filter in the middle)\r\n\r\nFilter should be pushdown to leaf, I didn't see this user case. Project may be a command case in the middle? Yes. the input size of shuffle stage may not be accurate. But the disadvantage is launching more tasks. I think the benefit from handling the skewing is more important than the disadvantage.",
        "createdAt" : "2020-07-24T07:53:07Z",
        "updatedAt" : "2020-07-24T07:53:39Z",
        "lastEditedBy" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "tags" : [
        ]
      }
    ],
    "commit" : "5bed68ceed90c89457ff04af6da62f2222c795b7",
    "line" : 125,
    "diffHunk" : "@@ -1,1 +196,200 @@        assert(left.partitionsWithSizes.length == right.partitionsWithSizes.length)\n        val numPartitions = left.partitionsWithSizes.length\n        // We use the median size of the original shuffle partitions to detect skewed partitions.\n        val leftMedSize = medianSize(left.mapStats)\n        val rightMedSize = medianSize(right.mapStats)"
  },
  {
    "id" : "e6080d64-09bb-4357-af9b-28b474afc0ba",
    "prId" : 28947,
    "prUrl" : "https://github.com/apache/spark/pull/28947#pullrequestreview-440858516",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6e034c8e-068e-483b-94c6-e18606f0920c",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Can we make it more general? It seems like we can optimize any SMJ if its 2 children are both shuffle stages. cc @JkSelf @maryannxue ",
        "createdAt" : "2020-07-01T07:34:40Z",
        "updatedAt" : "2020-07-01T07:36:04Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "e6de2abd-dc41-4077-b974-0a8d3073f11c",
        "parentId" : "6e034c8e-068e-483b-94c6-e18606f0920c",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "For 3-table join, if they are in the same query stage, it means the shuffles are all leaf, and we will only optimize the first SMJ, as the second SMJ has only one side as shuffle stage.",
        "createdAt" : "2020-07-01T07:35:53Z",
        "updatedAt" : "2020-07-01T07:35:54Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "62853604-6cfe-4ff0-9913-c30e54f5408e",
        "parentId" : "6e034c8e-068e-483b-94c6-e18606f0920c",
        "authorId" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "body" : "> For 3-table join, if they are in the same query stage, it means the shuffles are all leaf, and we will only optimize the first SMJ, as the second SMJ has only one side as shuffle stage.\r\n\r\nWe have a 3-table skewed join implamentation in our internal code base. But we have replaced the skew join handling logic by community's. So our optimization is not work based on currnet `OptimizeSkewedJoin`. I will try to re-implement it in current `OptimizeSkewedJoin` and submit a PR later.",
        "createdAt" : "2020-07-01T13:11:19Z",
        "updatedAt" : "2020-07-01T13:20:42Z",
        "lastEditedBy" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "tags" : [
        ]
      },
      {
        "id" : "7e97fbd3-8bcf-4a31-be4a-323c2a39ff1d",
        "parentId" : "6e034c8e-068e-483b-94c6-e18606f0920c",
        "authorId" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "body" : "> Can we make it more general? It seems like we can optimize any SMJ if its 2 children are both shuffle stages. cc @JkSelf @maryannxue\r\n\r\nYes. we usually implemented some optimizations based on our inner usages and issues. So it may be not general. I only see the UNION case so far.",
        "createdAt" : "2020-07-01T13:16:16Z",
        "updatedAt" : "2020-07-01T13:16:43Z",
        "lastEditedBy" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "tags" : [
        ]
      }
    ],
    "commit" : "d011e9a11f416c73af4a602f9966db35c2643dd8",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +290,294 @@    }\n\n    // Try to handle skew join with union case, like\n    // Union\n    //   SMJ"
  },
  {
    "id" : "1d55117f-b898-42be-ab4b-8a3b03a025a4",
    "prId" : 28226,
    "prUrl" : "https://github.com/apache/spark/pull/28226#pullrequestreview-393833834",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "627fed44-bfb1-4ab2-a2b8-483ac96ae4fc",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I'll backport this fix to 3.0 later.",
        "createdAt" : "2020-04-15T14:32:58Z",
        "updatedAt" : "2020-04-20T07:01:24Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "3eccb706b9047e3d815850986bc99859cfda626e",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +93,97 @@    } else {\n      math.max(advisorySize, nonSkewSizes.sum / nonSkewSizes.length)\n    }\n  }\n"
  },
  {
    "id" : "755111a8-2d84-4456-a1e1-b220bea42950",
    "prId" : 28226,
    "prUrl" : "https://github.com/apache/spark/pull/28226#pullrequestreview-396171306",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ef1e773a-74d3-4bbd-9f53-227cade60769",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Why it's possible empty now?",
        "createdAt" : "2020-04-20T03:57:52Z",
        "updatedAt" : "2020-04-20T07:01:24Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "70ddc9c0-c0f6-4a3c-a2a7-7f5f963082b9",
        "parentId" : "ef1e773a-74d3-4bbd-9f53-227cade60769",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "because we calculate the median size based on the original map stats, but the input partitions are coalesced. It's possible all partitions (after coalesce) are skewed.",
        "createdAt" : "2020-04-20T05:27:33Z",
        "updatedAt" : "2020-04-20T07:01:24Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "473a27b4-0fec-468d-b028-273699e817bb",
        "parentId" : "ef1e773a-74d3-4bbd-9f53-227cade60769",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "I see, thanks!",
        "createdAt" : "2020-04-20T06:30:26Z",
        "updatedAt" : "2020-04-20T07:01:24Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "3eccb706b9047e3d815850986bc99859cfda626e",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +89,93 @@    val advisorySize = conf.getConf(SQLConf.ADVISORY_PARTITION_SIZE_IN_BYTES)\n    val nonSkewSizes = sizes.filterNot(isSkewed(_, medianSize))\n    if (nonSkewSizes.isEmpty) {\n      advisorySize\n    } else {"
  }
]