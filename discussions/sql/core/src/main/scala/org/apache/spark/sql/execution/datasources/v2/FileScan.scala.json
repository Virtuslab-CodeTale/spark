[
  {
    "id" : "61828185-25c3-4a00-afff-b113793cfb66",
    "prId" : 31848,
    "prUrl" : "https://github.com/apache/spark/pull/31848#pullrequestreview-615735662",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1646b0c1-2b1a-4a9f-ba93-8d0711663053",
        "parentId" : null,
        "authorId" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "body" : "Shall I update `hashCode()` as well? Looks like we can easily come up with a better one...",
        "createdAt" : "2021-03-18T18:05:20Z",
        "updatedAt" : "2021-03-22T13:36:26Z",
        "lastEditedBy" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "tags" : [
        ]
      },
      {
        "id" : "f4080396-880e-49d3-a0b1-80107fc0adb7",
        "parentId" : "1646b0c1-2b1a-4a9f-ba93-8d0711663053",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Shall we do that separately because it's irrelevant to the correctness issue?\r\nIn general, we expect a performance improvement with that, don't we?\r\nApache Spark doesn't allow to backport performance improvement.",
        "createdAt" : "2021-03-18T18:25:33Z",
        "updatedAt" : "2021-03-22T13:36:26Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "7668deee-6b0f-48cb-85da-ff48770c4721",
        "parentId" : "1646b0c1-2b1a-4a9f-ba93-8d0711663053",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Please file a new JIRA and go for it, @peter-toth ! :)",
        "createdAt" : "2021-03-18T18:26:10Z",
        "updatedAt" : "2021-03-22T13:36:26Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "0d38ac27dec27b77e0057113fbb57de8ea4cd3ca",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +99,103 @@  }\n\n  override def equals(obj: Any): Boolean = obj match {\n    case f: FileScan =>\n      fileIndex == f.fileIndex && readSchema == f.readSchema &&"
  }
]