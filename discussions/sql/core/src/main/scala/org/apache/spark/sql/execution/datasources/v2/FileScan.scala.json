[
  {
    "id" : "61828185-25c3-4a00-afff-b113793cfb66",
    "prId" : 31848,
    "prUrl" : "https://github.com/apache/spark/pull/31848#pullrequestreview-615735662",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1646b0c1-2b1a-4a9f-ba93-8d0711663053",
        "parentId" : null,
        "authorId" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "body" : "Shall I update `hashCode()` as well? Looks like we can easily come up with a better one...",
        "createdAt" : "2021-03-18T18:05:20Z",
        "updatedAt" : "2021-03-22T13:36:26Z",
        "lastEditedBy" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "tags" : [
        ]
      },
      {
        "id" : "f4080396-880e-49d3-a0b1-80107fc0adb7",
        "parentId" : "1646b0c1-2b1a-4a9f-ba93-8d0711663053",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Shall we do that separately because it's irrelevant to the correctness issue?\r\nIn general, we expect a performance improvement with that, don't we?\r\nApache Spark doesn't allow to backport performance improvement.",
        "createdAt" : "2021-03-18T18:25:33Z",
        "updatedAt" : "2021-03-22T13:36:26Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "7668deee-6b0f-48cb-85da-ff48770c4721",
        "parentId" : "1646b0c1-2b1a-4a9f-ba93-8d0711663053",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Please file a new JIRA and go for it, @peter-toth ! :)",
        "createdAt" : "2021-03-18T18:26:10Z",
        "updatedAt" : "2021-03-22T13:36:26Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "0d38ac27dec27b77e0057113fbb57de8ea4cd3ca",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +99,103 @@  }\n\n  override def equals(obj: Any): Boolean = obj match {\n    case f: FileScan =>\n      fileIndex == f.fileIndex && readSchema == f.readSchema &&"
  },
  {
    "id" : "2283a719-abc0-4a42-b058-21eccfa0eddf",
    "prId" : 28425,
    "prUrl" : "https://github.com/apache/spark/pull/28425#pullrequestreview-446848884",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "068207b0-87c2-43c8-952d-711619755a60",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Just a question. Is this a new metadata?",
        "createdAt" : "2020-07-11T15:01:06Z",
        "updatedAt" : "2020-07-12T06:12:07Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "a57c7416-5c1f-4152-860f-e23f665fc032",
        "parentId" : "068207b0-87c2-43c8-952d-711619755a60",
        "authorId" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "body" : "@dongjoon-hyun Previously we used to print the scan node class name and in the new format, we print it in its own line. Please see the old output in the pr description. We have it printed as `ParquetScan`.",
        "createdAt" : "2020-07-12T06:07:54Z",
        "updatedAt" : "2020-07-12T06:12:07Z",
        "lastEditedBy" : "a2fcc15e-a51a-42f0-87a6-137048a28e30",
        "tags" : [
        ]
      }
    ],
    "commit" : "e177c2a3a99ce2ed64c0562035f0552a4c25c919",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +113,117 @@        Utils.buildLocationMetadata(fileIndex.rootPaths, maxMetadataValueLength)\n    Map(\n      \"Format\" -> s\"${this.getClass.getSimpleName.replace(\"Scan\", \"\").toLowerCase(Locale.ROOT)}\",\n      \"ReadSchema\" -> readDataSchema.catalogString,\n      \"PartitionFilters\" -> seqToString(partitionFilters),"
  }
]