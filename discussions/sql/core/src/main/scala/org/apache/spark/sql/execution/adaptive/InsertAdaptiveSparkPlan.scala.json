[
  {
    "id" : "f7394df1-0347-4e81-9b00-6da148a4a887",
    "prId" : 27971,
    "prUrl" : "https://github.com/apache/spark/pull/27971#pullrequestreview-378579390",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a4dc261e-be0b-4ed3-a2a0-39cdfa287c3e",
        "parentId" : null,
        "authorId" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "body" : "Not that I think it actually matters... but just for the argument itself, how can we guarantee it's the same de-queue order?\r\nIt's just some sort of waste to add duplicates for the mere sake of consistency...",
        "createdAt" : "2020-03-20T15:24:02Z",
        "updatedAt" : "2020-03-20T15:24:03Z",
        "lastEditedBy" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "tags" : [
        ]
      }
    ],
    "commit" : "294b62adbb6804404712a799ec096c94967984ce",
    "line" : 35,
    "diffHunk" : "@@ -1,1 +129,133 @@        verifyAdaptivePlan(executedPlan, query)\n        val subquery = SubqueryExec(s\"subquery#${exprId.id}\", executedPlan)\n        val subqueries = subqueryMap.getOrElseUpdate(exprId.id, mutable.Queue())\n        subqueries.enqueue(subquery)\n      case _ =>"
  },
  {
    "id" : "77d90e0f-c179-4c50-b80b-7e7092316774",
    "prId" : 27452,
    "prUrl" : "https://github.com/apache/spark/pull/27452#pullrequestreview-354591753",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2c0a7e5e-9538-4ef5-add7-df9820f6249a",
        "parentId" : null,
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "This is much clear than the original code. ",
        "createdAt" : "2020-02-06T16:29:20Z",
        "updatedAt" : "2020-02-06T16:29:21Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      }
    ],
    "commit" : "a796d191013a1dee296b92539e489c8ab471b21d",
    "line" : 82,
    "diffHunk" : "@@ -1,1 +83,87 @@  //     we just check `SparkPlan.requiredChildDistribution` and see if it's possible that the\n  //     the query needs to add exchanges later.\n  //   - The query contains sub-query.\n  private def shouldApplyAQE(plan: SparkPlan, isSubquery: Boolean): Boolean = {\n    conf.getConf(SQLConf.ADAPTIVE_EXECUTION_FORCE_APPLY) || isSubquery || {"
  },
  {
    "id" : "64311705-8afc-4657-aed9-22324be11506",
    "prId" : 26813,
    "prUrl" : "https://github.com/apache/spark/pull/26813#pullrequestreview-350664586",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2f87be19-e905-42b8-840e-d4405befdcf8",
        "parentId" : null,
        "authorId" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "body" : "It is absolutely ridiculous to do so here. We deliberately added `SubqueryAdaptiveNotSupportedException` to make sure that it's all-in or all-out for the main query and all its subqueries in order to ensure subquery reuse in AQE.",
        "createdAt" : "2020-01-28T16:38:49Z",
        "updatedAt" : "2020-01-28T16:38:50Z",
        "lastEditedBy" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "tags" : [
        ]
      },
      {
        "id" : "ee1d615b-1cad-46ba-b42a-f5ba942b0ea7",
        "parentId" : "2f87be19-e905-42b8-840e-d4405befdcf8",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "It's still all-in or all-out. The complete check is `isSubquery || containShuffle(plan) || containSubQuery(plan)`, so we only call `containSubQuery` for the main query.",
        "createdAt" : "2020-01-30T09:00:59Z",
        "updatedAt" : "2020-01-30T09:00:59Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "8b5e7442c63fe326db7c7f46f7a194fbae8f0d46",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +50,54 @@\n  def containSubQuery(plan: SparkPlan): Boolean = {\n    plan.find(_.expressions.exists(_.find {\n      case _: SubqueryExpression => true\n      case _ => false"
  },
  {
    "id" : "27554baf-3c41-4e5f-9848-594e8828f081",
    "prId" : 26813,
    "prUrl" : "https://github.com/apache/spark/pull/26813#pullrequestreview-350945196",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c43bcf34-b3ed-4ef2-b7a1-5d6a690052dc",
        "parentId" : null,
        "authorId" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "body" : "Do you remember which case would fail because of this? We should not see an Exchange without a logical link in `sparkPlan`, right? If there is one, we need to find out the reason and fix it. ",
        "createdAt" : "2020-01-28T16:40:19Z",
        "updatedAt" : "2020-01-28T16:40:19Z",
        "lastEditedBy" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "tags" : [
        ]
      },
      {
        "id" : "67d36b9d-021e-49ad-89a3-40017b3eac01",
        "parentId" : "c43bcf34-b3ed-4ef2-b7a1-5d6a690052dc",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "it's not about \"no logical plan link\", it's just: we should do AQE if there are already exchanges in the physical plan before `EnsureRequirements`",
        "createdAt" : "2020-01-30T08:56:31Z",
        "updatedAt" : "2020-01-30T09:00:30Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "9cb3bd6e-a933-4b69-8bda-5ceb157b714f",
        "parentId" : "c43bcf34-b3ed-4ef2-b7a1-5d6a690052dc",
        "authorId" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "body" : "If it's test failure related, we need to look into it, otherwise can we pull these changes out into a separate PR, and control the bypass with a flag, so at least we can still cover this code path in testing?",
        "createdAt" : "2020-01-30T16:07:59Z",
        "updatedAt" : "2020-01-30T16:07:59Z",
        "lastEditedBy" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "tags" : [
        ]
      }
    ],
    "commit" : "8b5e7442c63fe326db7c7f46f7a194fbae8f0d46",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +44,48 @@  def containShuffle(plan: SparkPlan): Boolean = {\n    plan.find {\n      case _: Exchange => true\n      case s: SparkPlan => !s.requiredChildDistribution.forall(_ == UnspecifiedDistribution)\n    }.isDefined"
  },
  {
    "id" : "e5c0027e-b070-4190-a80c-865bd652375f",
    "prId" : 25316,
    "prUrl" : "https://github.com/apache/spark/pull/25316#pullrequestreview-269614145",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "694efa39-5438-4e0b-a0d5-45ce3d0ab401",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "When we reach here, it means we are creating `AdaptiveSparkPlanExec` for a subquery. Shall we simply set a boolean flag here (e.g. `adaptivePlan.copy(isSubquery = true)`) instead of passing around the `QueryExecution`?",
        "createdAt" : "2019-08-01T08:25:16Z",
        "updatedAt" : "2019-08-07T17:40:35Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "83386df0-38ad-42cf-bd56-6b3d9ae89dd8",
        "parentId" : "694efa39-5438-4e0b-a0d5-45ce3d0ab401",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "nvm, this is more flexible, in case some places create `QueryExecution` without execution id and execute.",
        "createdAt" : "2019-08-01T13:23:27Z",
        "updatedAt" : "2019-08-07T17:40:35Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "f5702810ac5e925e998331029f6927cfc94448e3",
    "line" : 35,
    "diffHunk" : "@@ -1,1 +125,129 @@    // Apply the same instance of this rule to sub-queries so that sub-queries all share the\n    // same `stageCache` for Exchange reuse.\n    val adaptivePlan = this.applyInternal(queryExec.sparkPlan, queryExec)\n    if (!adaptivePlan.isInstanceOf[AdaptiveSparkPlanExec]) {\n      throw SubqueryAdaptiveNotSupportedException(plan)"
  }
]