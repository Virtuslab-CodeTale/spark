[
  {
    "id" : "f7394df1-0347-4e81-9b00-6da148a4a887",
    "prId" : 27971,
    "prUrl" : "https://github.com/apache/spark/pull/27971#pullrequestreview-378579390",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a4dc261e-be0b-4ed3-a2a0-39cdfa287c3e",
        "parentId" : null,
        "authorId" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "body" : "Not that I think it actually matters... but just for the argument itself, how can we guarantee it's the same de-queue order?\r\nIt's just some sort of waste to add duplicates for the mere sake of consistency...",
        "createdAt" : "2020-03-20T15:24:02Z",
        "updatedAt" : "2020-03-20T15:24:03Z",
        "lastEditedBy" : "4916859c-0e27-4e9d-ac39-ad95bc1382d3",
        "tags" : [
        ]
      }
    ],
    "commit" : "294b62adbb6804404712a799ec096c94967984ce",
    "line" : 35,
    "diffHunk" : "@@ -1,1 +129,133 @@        verifyAdaptivePlan(executedPlan, query)\n        val subquery = SubqueryExec(s\"subquery#${exprId.id}\", executedPlan)\n        val subqueries = subqueryMap.getOrElseUpdate(exprId.id, mutable.Queue())\n        subqueries.enqueue(subquery)\n      case _ =>"
  },
  {
    "id" : "77d90e0f-c179-4c50-b80b-7e7092316774",
    "prId" : 27452,
    "prUrl" : "https://github.com/apache/spark/pull/27452#pullrequestreview-354591753",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2c0a7e5e-9538-4ef5-add7-df9820f6249a",
        "parentId" : null,
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "This is much clear than the original code. ",
        "createdAt" : "2020-02-06T16:29:20Z",
        "updatedAt" : "2020-02-06T16:29:21Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      }
    ],
    "commit" : "a796d191013a1dee296b92539e489c8ab471b21d",
    "line" : 82,
    "diffHunk" : "@@ -1,1 +83,87 @@  //     we just check `SparkPlan.requiredChildDistribution` and see if it's possible that the\n  //     the query needs to add exchanges later.\n  //   - The query contains sub-query.\n  private def shouldApplyAQE(plan: SparkPlan, isSubquery: Boolean): Boolean = {\n    conf.getConf(SQLConf.ADAPTIVE_EXECUTION_FORCE_APPLY) || isSubquery || {"
  }
]