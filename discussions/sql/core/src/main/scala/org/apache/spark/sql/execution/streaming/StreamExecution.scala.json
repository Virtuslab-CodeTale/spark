[
  {
    "id" : "b9112c77-9421-4979-b137-a7a538eb64f3",
    "prId" : 31842,
    "prUrl" : "https://github.com/apache/spark/pull/31842#pullrequestreview-614288333",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "63d6f3d2-f0e6-4b4d-8093-50600a602ef7",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "where do we call it outside of `StreamExecution`?",
        "createdAt" : "2021-03-17T08:12:01Z",
        "updatedAt" : "2021-03-19T14:29:22Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "643244f8-eb96-49fd-a965-760c599a452a",
        "parentId" : "63d6f3d2-f0e6-4b4d-8093-50600a602ef7",
        "authorId" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "body" : "Here we removed `analyzedPlan` in the subclass params: https://github.com/apache/spark/pull/31842/files#diff-cf2dc65d70aa7bc490d237f1c50f5fdf51e244fabed782977a94d2934c208551L41. Now the `analyzedPlan` is called directly in subclass `MicroBatchExecution` and `ContinuousExecution`.",
        "createdAt" : "2021-03-17T13:14:20Z",
        "updatedAt" : "2021-03-19T14:29:22Z",
        "lastEditedBy" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "tags" : [
        ]
      }
    ],
    "commit" : "7ec1afb4bfe269b472bf3110fc7bd580ae05e084",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +70,74 @@    override val name: String,\n    private val checkpointRoot: String,\n    val analyzedPlan: LogicalPlan,\n    val sink: Table,\n    val trigger: Trigger,"
  },
  {
    "id" : "248c8052-92b7-429f-b032-007276e30b1b",
    "prId" : 31842,
    "prUrl" : "https://github.com/apache/spark/pull/31842#pullrequestreview-614016689",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2948d4c1-b486-4e1b-a4cc-b2e4df0a1ae7",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "where do we call it outside of `StreamExecution`?",
        "createdAt" : "2021-03-17T08:12:15Z",
        "updatedAt" : "2021-03-19T14:29:22Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "7ec1afb4bfe269b472bf3110fc7bd580ae05e084",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +70,74 @@    override val name: String,\n    private val checkpointRoot: String,\n    val analyzedPlan: LogicalPlan,\n    val sink: Table,\n    val trigger: Trigger,"
  },
  {
    "id" : "2eb58e52-0061-4223-bddf-fcbcdc0ec983",
    "prId" : 31600,
    "prUrl" : "https://github.com/apache/spark/pull/31600#pullrequestreview-598743701",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c2d33b35-b092-4410-83f9-59612147fd6c",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Using `withActive` to keep safe for the `StreamExecution` to avoid using the wrong active session.",
        "createdAt" : "2021-02-25T16:14:44Z",
        "updatedAt" : "2021-02-25T16:14:44Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "ddbeca731c1219dbeb96de64840e80b7a4b715c7",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +324,328 @@\n      // While active, repeatedly attempt to run batches.\n      sparkSessionForStream.withActive {\n        // Adaptive execution can change num shuffle partitions, disallow\n        sparkSessionForStream.conf.set(SQLConf.ADAPTIVE_EXECUTION_ENABLED.key, \"false\")"
  }
]