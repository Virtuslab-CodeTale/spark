[
  {
    "id" : "5b43fb9f-388e-4c03-b5e4-97ed90030d94",
    "prId" : 31560,
    "prUrl" : "https://github.com/apache/spark/pull/31560#pullrequestreview-594734813",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "946191e5-e0e7-4939-bd70-e3de3ff74702",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "It would be great if you add a class description here, @kevincmchen . Please refer [Scala version](https://github.com/apache/spark/blob/master/sql/core/src/test/scala/org/apache/spark/sql/connector/SimpleWritableDataSource.scala#L40-L42).",
        "createdAt" : "2021-02-17T05:47:43Z",
        "updatedAt" : "2021-02-21T15:01:48Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "dd48ba2c-44a7-4a72-9833-23ec5623392e",
        "parentId" : "946191e5-e0e7-4939-bd70-e3de3ff74702",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Do we need to use `TestingV2Source`? Shall we use `SimpleTableProvider` instead?",
        "createdAt" : "2021-02-17T05:51:35Z",
        "updatedAt" : "2021-02-21T15:01:48Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "39580bd3-4dcf-40ba-9332-937cba19befd",
        "parentId" : "946191e5-e0e7-4939-bd70-e3de3ff74702",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Yea I think we should follow the scala version and use `SimpleTableProvider`. `TestingV2Source.inferSchema` doesn't match the schema here. ",
        "createdAt" : "2021-02-17T14:12:20Z",
        "updatedAt" : "2021-02-21T15:01:48Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "50c5dd80-dc09-4b3b-9cf9-23f21d75d1d8",
        "parentId" : "946191e5-e0e7-4939-bd70-e3de3ff74702",
        "authorId" : "2c763047-6f31-4947-8450-8389844e874d",
        "body" : "> Yea I think we should follow the scala version and use `SimpleTableProvider`. `TestingV2Source.inferSchema` doesn't match the schema here.\r\n\r\nusing SimpleTableProvider will cause  compile error and the error is \r\n`java: test.org.apache.spark.sql.connector.JavaSimpleWritableDataSource is not abstract and does not override abstract method org$apache$spark$sql$internal$connector$SimpleTableProvider$$loadedTable_$eq(org.apache.spark.sql.connector.catalog.Table) in org.apache.spark.sql.internal.connector.SimpleTableProvider`\r\n\r\nthe reason is that scala traits cannot be extended in Java if they have any implementation details. ",
        "createdAt" : "2021-02-18T09:21:57Z",
        "updatedAt" : "2021-02-21T15:01:48Z",
        "lastEditedBy" : "2c763047-6f31-4947-8450-8389844e874d",
        "tags" : [
        ]
      },
      {
        "id" : "98302ea1-620e-4d35-ae3b-fc9f54ea1f15",
        "parentId" : "946191e5-e0e7-4939-bd70-e3de3ff74702",
        "authorId" : "2c763047-6f31-4947-8450-8389844e874d",
        "body" : "so i used TestingV2Source instead of  SimpleTableProvider and override inferSchema function.\r\n",
        "createdAt" : "2021-02-18T09:44:08Z",
        "updatedAt" : "2021-02-21T15:01:48Z",
        "lastEditedBy" : "2c763047-6f31-4947-8450-8389844e874d",
        "tags" : [
        ]
      },
      {
        "id" : "58cfa930-87e3-4636-ac06-80ae8fb540e6",
        "parentId" : "946191e5-e0e7-4939-bd70-e3de3ff74702",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Ah, I see. Makes sense.\r\n\r\nMaybe we can change the schema of this writable v2 source (as well as the read part), to match `TestingV2Source`, so that the scala version can also use `TestingV2Source`, to be consistent with the java version.",
        "createdAt" : "2021-02-19T13:56:35Z",
        "updatedAt" : "2021-02-21T15:01:48Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "d49d3853-08ab-4fe2-98b5-b74ffa87a639",
        "parentId" : "946191e5-e0e7-4939-bd70-e3de3ff74702",
        "authorId" : "2c763047-6f31-4947-8450-8389844e874d",
        "body" : "I have already fixed it, thx a lot.",
        "createdAt" : "2021-02-20T09:41:20Z",
        "updatedAt" : "2021-02-21T15:01:48Z",
        "lastEditedBy" : "2c763047-6f31-4947-8450-8389844e874d",
        "tags" : [
        ]
      }
    ],
    "commit" : "0d85f08a9e41322e62398ab45ba78046f8d2a78c",
    "line" : 53,
    "diffHunk" : "@@ -1,1 +51,55 @@ * Each job moves files from `target/_temporary/uniqueId/` to `target`.\n */\npublic class JavaSimpleWritableDataSource implements TestingV2Source, SessionConfigSupport {\n\n  @Override"
  },
  {
    "id" : "732509a3-fa6f-4112-9502-54254f22fcf7",
    "prId" : 31560,
    "prUrl" : "https://github.com/apache/spark/pull/31560#pullrequestreview-591860724",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a43fa5ec-56d0-4812-8d62-1305c6ac0ed7",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Thanks for using a new API instead of the deprecated ones.",
        "createdAt" : "2021-02-17T06:00:25Z",
        "updatedAt" : "2021-02-21T15:01:48Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "0d85f08a9e41322e62398ab45ba78046f8d2a78c",
    "line" : 117,
    "diffHunk" : "@@ -1,1 +115,119 @@\n    @Override\n    public Write build() {\n      return new MyWrite(path, queryId, needTruncate);\n    }"
  },
  {
    "id" : "3fccdd79-4efc-437d-97c1-f76c7ece1968",
    "prId" : 31560,
    "prUrl" : "https://github.com/apache/spark/pull/31560#pullrequestreview-594747717",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1928bc22-76d6-421d-ab69-ff389661ff31",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "~Ur, we need `capabilities` because we have `SupportsWrite`~\r\n\r\nOh, I didn't notice the difference. I'm taking back my above words.\r\n- `SimpleBatchTable`'s capability is `BATCH_READ`.\r\n- `JavaSimpleBatchTable`'s capability is `BATCH_READ`, `BATCH_WRITE`, `TRUNCATE`.\r\n",
        "createdAt" : "2021-02-17T06:12:06Z",
        "updatedAt" : "2021-02-21T15:01:48Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "e5ffc5f9-9bb0-4cad-a020-0c9a5895a613",
        "parentId" : "1928bc22-76d6-421d-ab69-ff389661ff31",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This seems like an unnecessary inconsistency, as before this PR `JavaSimpleBatchTable` doesn't need to have write table capability at all.\r\n\r\nWe can probably remove `BATCH_WRITE` and `TRUNCATE` from `JavaSimpleBatchTable` and add it here, to follow the scala version.",
        "createdAt" : "2021-02-19T14:16:28Z",
        "updatedAt" : "2021-02-21T15:01:48Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "be354ee9-0dc9-4da9-92e2-06013574c7bf",
        "parentId" : "1928bc22-76d6-421d-ab69-ff389661ff31",
        "authorId" : "2c763047-6f31-4947-8450-8389844e874d",
        "body" : "I have already fixed it, thx a lot.",
        "createdAt" : "2021-02-20T12:26:30Z",
        "updatedAt" : "2021-02-21T15:01:48Z",
        "lastEditedBy" : "2c763047-6f31-4947-8450-8389844e874d",
        "tags" : [
        ]
      }
    ],
    "commit" : "0d85f08a9e41322e62398ab45ba78046f8d2a78c",
    "line" : 369,
    "diffHunk" : "@@ -1,1 +367,371 @@    @Override\n    public void close() {\n    }\n  }\n}"
  },
  {
    "id" : "8943dbc9-0c88-4022-aa6a-dafeeb495294",
    "prId" : 31560,
    "prUrl" : "https://github.com/apache/spark/pull/31560#pullrequestreview-599622677",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "49db7f90-742f-4712-8d26-18bbb06e0bec",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This seems not java friendly, I think we should update `Batch#planInputPartitions` to add `throws IOException`, the same as `PartitionReader#next`.\r\n\r\nThe `throws` clause is a compile-time check and won't break binary compatibility. Also cc @rdblue ",
        "createdAt" : "2021-02-19T14:02:55Z",
        "updatedAt" : "2021-02-21T15:01:48Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "80e888ca-f8ba-490e-940f-c7090949f9c9",
        "parentId" : "49db7f90-742f-4712-8d26-18bbb06e0bec",
        "authorId" : "2c763047-6f31-4947-8450-8389844e874d",
        "body" : "I feel the same.",
        "createdAt" : "2021-02-20T09:38:31Z",
        "updatedAt" : "2021-02-21T15:01:48Z",
        "lastEditedBy" : "2c763047-6f31-4947-8450-8389844e874d",
        "tags" : [
        ]
      },
      {
        "id" : "26512fb1-0414-4df5-9d83-3014cf60d2f1",
        "parentId" : "49db7f90-742f-4712-8d26-18bbb06e0bec",
        "authorId" : "2c763047-6f31-4947-8450-8389844e874d",
        "body" : "I have some different opinions recently.\r\n\r\n1. for `Batch#planInputPartitions`, If this method fails (by throwing an exception), the underlying data source scan may require manual cleanup .\r\n2. for `BatchWrite#commit`, If this method fails (by throwing an exception), this writing job is considered to have been failed, and `BatchWrite#abort` would be called，but `BatchWrite#abort` may not be able to deal with it. more details, pls see the comments of `BatchWrite#abort` \r\n\r\nso its better to deal with these exceptions in `Batch#planInputPartitions` and `BatchWrite#commit`;  \r\n\r\n@cloud-fan ",
        "createdAt" : "2021-02-26T14:25:32Z",
        "updatedAt" : "2021-02-27T07:22:18Z",
        "lastEditedBy" : "2c763047-6f31-4947-8450-8389844e874d",
        "tags" : [
        ]
      }
    ],
    "commit" : "0d85f08a9e41322e62398ab45ba78046f8d2a78c",
    "line" : 88,
    "diffHunk" : "@@ -1,1 +86,90 @@        }\n      } catch (IOException e) {\n        throw new RuntimeException(e);\n      }\n    }"
  },
  {
    "id" : "107a3683-6190-40f4-8ced-414ebe68c3b3",
    "prId" : 31560,
    "prUrl" : "https://github.com/apache/spark/pull/31560#pullrequestreview-595314034",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bc6b5f00-2142-4173-ab54-5c75fa0f35a0",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Seems like we don't need to implement `SessionConfigSupport`. Can you open a follow-up PR to remove it from both the Scala and Java versions?",
        "createdAt" : "2021-02-22T09:32:13Z",
        "updatedAt" : "2021-02-22T09:32:13Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "dfb07c35-4561-4d78-a6e3-b16ee062d6d6",
        "parentId" : "bc6b5f00-2142-4173-ab54-5c75fa0f35a0",
        "authorId" : "2c763047-6f31-4947-8450-8389844e874d",
        "body" : "all right",
        "createdAt" : "2021-02-22T12:48:44Z",
        "updatedAt" : "2021-02-22T12:53:47Z",
        "lastEditedBy" : "2c763047-6f31-4947-8450-8389844e874d",
        "tags" : [
        ]
      }
    ],
    "commit" : "0d85f08a9e41322e62398ab45ba78046f8d2a78c",
    "line" : 57,
    "diffHunk" : "@@ -1,1 +55,59 @@  @Override\n  public String keyPrefix() {\n    return \"javaSimpleWritableDataSource\";\n  }\n"
  },
  {
    "id" : "d41203cc-d599-44c2-b3c6-2745742b056d",
    "prId" : 31560,
    "prUrl" : "https://github.com/apache/spark/pull/31560#pullrequestreview-595314034",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "231021de-e72d-489b-b970-feee72d27a2d",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can we change the Scala version as well in a follow-up PR?",
        "createdAt" : "2021-02-22T09:34:28Z",
        "updatedAt" : "2021-02-22T09:34:28Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "f0e208dc-942c-40c3-8fd9-1ac99122fb07",
        "parentId" : "231021de-e72d-489b-b970-feee72d27a2d",
        "authorId" : "2c763047-6f31-4947-8450-8389844e874d",
        "body" : "ok，i'll change the scala version",
        "createdAt" : "2021-02-22T12:53:47Z",
        "updatedAt" : "2021-02-22T12:53:47Z",
        "lastEditedBy" : "2c763047-6f31-4947-8450-8389844e874d",
        "tags" : [
        ]
      }
    ],
    "commit" : "0d85f08a9e41322e62398ab45ba78046f8d2a78c",
    "line" : 294,
    "diffHunk" : "@@ -1,1 +292,296 @@                Arrays.stream(currentLine.split(\",\"))\n                    .map(String::trim)\n                    .map(Integer::parseInt)\n                    .toArray();\n            return new GenericInternalRow(objects);"
  }
]