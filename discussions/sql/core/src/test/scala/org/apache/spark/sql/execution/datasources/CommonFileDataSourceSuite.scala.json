[
  {
    "id" : "83c2d932-ecd3-4248-aebb-fd9cd6c05498",
    "prId" : 30067,
    "prUrl" : "https://github.com/apache/spark/pull/30067#pullrequestreview-511125696",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8f2d1be8-0739-4d53-a096-5f1cf5b6e80c",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Shall we add this test into `FileBasedDataSourceSuite`?",
        "createdAt" : "2020-10-18T08:42:15Z",
        "updatedAt" : "2020-10-19T06:02:51Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "2d63cd92-fada-49cd-b506-961888577eca",
        "parentId" : "8f2d1be8-0739-4d53-a096-5f1cf5b6e80c",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Do you mean add it to `FileBasedDataSourceSuite` and remove it from `JsonSuite`, `CSVSuite` and so on? In that case, we will not test both DS v1 and v2.",
        "createdAt" : "2020-10-18T09:05:49Z",
        "updatedAt" : "2020-10-19T06:02:51Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "10ee67dc-e95f-449c-88d0-de8a591f1848",
        "parentId" : "8f2d1be8-0739-4d53-a096-5f1cf5b6e80c",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "If I place the test to `FileBasedDataSourceSuite`, will I be able to test Avro? It will look like slightly strange that we test `external/avro` in `sql/core`, won't it?",
        "createdAt" : "2020-10-18T09:12:30Z",
        "updatedAt" : "2020-10-19T06:02:51Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "65c90f45-dccd-47b3-95b2-3264428ed9b7",
        "parentId" : "8f2d1be8-0739-4d53-a096-5f1cf5b6e80c",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Hmmm.. okay",
        "createdAt" : "2020-10-18T09:30:20Z",
        "updatedAt" : "2020-10-19T06:02:51Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "a397ead711695946c32e81f29e29cbdb422d25bc",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +34,38 @@  protected def inputDataset: Dataset[_] = spark.createDataset(Seq(\"abc\"))(Encoders.STRING)\n\n  test(s\"Propagate Hadoop configs from $dataSourceFormat options to underlying file system\") {\n    withSQLConf(\n      \"fs.file.impl\" -> classOf[FakeFileSystemRequiringDSOption].getName,"
  }
]