[
  {
    "id" : "d8ccd4db-be03-4660-a55d-8287ea47b8fc",
    "prId" : 31966,
    "prUrl" : "https://github.com/apache/spark/pull/31966#pullrequestreview-636369873",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a7692ce4-395b-4820-9a97-dc624a98801d",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Can this work correctly if `explode` has another func in its child, e.g., `explode(filter(friends, x -> x is not null))`?",
        "createdAt" : "2021-04-13T02:31:32Z",
        "updatedAt" : "2021-04-25T00:49:15Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "3dda7e8c-c30b-4f80-92d9-558c220ff0af",
        "parentId" : "a7692ce4-395b-4820-9a97-dc624a98801d",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Let me add a test to verify it.",
        "createdAt" : "2021-04-15T06:28:18Z",
        "updatedAt" : "2021-04-25T00:49:15Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "753ee96c-9b1b-47ac-bcc5-09b0ec883919",
        "parentId" : "a7692ce4-395b-4820-9a97-dc624a98801d",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Oh, because in the lambda function you access `friends`, Spark cannot prune it.",
        "createdAt" : "2021-04-15T07:31:41Z",
        "updatedAt" : "2021-04-25T00:49:15Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "f8bf046e-bada-4965-b212-0d4117e751a2",
        "parentId" : "a7692ce4-395b-4820-9a97-dc624a98801d",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "The higher order function expression is a special case. I just looked at it with more details. For example, `ArrayFilter` holds the complex expression `friends`, so from the point of view of Spark, `friends` is thought to be used by `ArrayFilter`.\r\n\r\nI think it has some space to optimize it more, targeting higher order function expression. It is out of the scope of this PR, however. I will take some time to look at this after.\r\n\r\n",
        "createdAt" : "2021-04-15T07:47:44Z",
        "updatedAt" : "2021-04-25T00:49:15Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "a7194092ebc3a9ca97daba29fda0fcc0ec099cf4",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +354,358 @@  testSchemaPruning(\"SPARK-34638: nested column prune on generator output\") {\n    val query1 = spark.table(\"contacts\")\n      .select(explode(col(\"friends\")).as(\"friend\"))\n      .select(\"friend.first\")\n    checkScan(query1, \"struct<friends:array<struct<first:string>>>\")"
  },
  {
    "id" : "3c222462-6d80-4205-8dd1-ebaa2c4da521",
    "prId" : 28988,
    "prUrl" : "https://github.com/apache/spark/pull/28988#pullrequestreview-442714714",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8e368d92-b032-469a-ad07-0e2106e0d1c0",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "This issue cannot happen in branch-3.0? \r\nhttps://github.com/apache/spark/blob/fc2660c302b0c83a9a8a5bec3cc7ae28f8fecdd6/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/optimizer/NestedColumnAliasing.scala#L80-L85",
        "createdAt" : "2020-07-05T11:48:42Z",
        "updatedAt" : "2020-07-07T15:39:33Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "ca307124-72cb-4a22-a4c6-452f151696c0",
        "parentId" : "8e368d92-b032-469a-ad07-0e2106e0d1c0",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "This test case is only for master branch. However this issue can happen in branch-3.0 too. I added another new test here, which is for branch-3.0.\r\n\r\nBut when we backport this to branch-3.0, we need to remove first test case as it will fail on `checkScan(query, \"struct<name:struct<first:string,last:string>>\")`, because branch-3.0 doesn't prune for repartition by expression.",
        "createdAt" : "2020-07-05T17:59:27Z",
        "updatedAt" : "2020-07-07T15:39:33Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "f2310a9c-6997-4055-8edc-40d61a078127",
        "parentId" : "8e368d92-b032-469a-ad07-0e2106e0d1c0",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Yea, thanks for adding the test.",
        "createdAt" : "2020-07-05T23:25:20Z",
        "updatedAt" : "2020-07-07T15:39:33Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "d352dbcdecfbdab08607c2416748e7650294fa42",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +501,505 @@    withTempView(\"contact_alias\") {\n      sql(\"select * from contacts\")\n        .repartition(100, col(\"name.first\"), col(\"name.last\"))\n        .selectExpr(\"name\").createOrReplaceTempView(\"contact_alias\")\n"
  },
  {
    "id" : "0d3d178d-e7d7-4cef-bdf7-96febe214e84",
    "prId" : 28988,
    "prUrl" : "https://github.com/apache/spark/pull/28988#pullrequestreview-443977652",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2d8a99e3-e8a3-49d7-8332-1e09b8743298",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "@maropu This test is for branch-3.0.",
        "createdAt" : "2020-07-05T18:01:05Z",
        "updatedAt" : "2020-07-07T15:39:33Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "691715b6-6623-4be5-9522-223a2116aacc",
        "parentId" : "2d8a99e3-e8a3-49d7-8332-1e09b8743298",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Thank you for the test case.",
        "createdAt" : "2020-07-07T14:59:10Z",
        "updatedAt" : "2020-07-07T15:39:33Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "d352dbcdecfbdab08607c2416748e7650294fa42",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +514,518 @@      val query2 = sql(\"select friends.middle, col from contact_alias\")\n      checkScan(query2, \"struct<friends:array<struct<first:string,middle:string>>>\")\n      checkAnswer(query2, Row(Array(\"Z.\"), \"Susan\") :: Nil)\n    }\n  }"
  },
  {
    "id" : "57ff6807-f849-4d82-8c3b-451951771390",
    "prId" : 28560,
    "prUrl" : "https://github.com/apache/spark/pull/28560#pullrequestreview-416605282",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "62f823be-4617-4b85-a4da-989737c929bb",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Is this test related to this PR?",
        "createdAt" : "2020-05-22T01:00:56Z",
        "updatedAt" : "2020-05-22T01:00:56Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "74cf168b-9a1f-4e2f-ab93-2840c07261f7",
        "parentId" : "62f823be-4617-4b85-a4da-989737c929bb",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Not for this change, but we don't have test case for repartition. Added one to improve test coverage.",
        "createdAt" : "2020-05-22T01:34:55Z",
        "updatedAt" : "2020-05-22T01:34:56Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "df1afb7a-5a90-411c-a9e8-1fd193c6da2a",
        "parentId" : "62f823be-4617-4b85-a4da-989737c929bb",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ah, ok.",
        "createdAt" : "2020-05-22T02:12:45Z",
        "updatedAt" : "2020-05-22T02:12:46Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "b2e56d55fe1dda39a47ba654e2b60a81fea7e492",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +341,345 @@  }\n\n  testSchemaPruning(\"select one deep nested complex field after repartition\") {\n    val query = sql(\"select * from contacts\")\n      .repartition(100)"
  },
  {
    "id" : "1efcf086-62f2-4a29-b694-54ceeaec3e22",
    "prId" : 28556,
    "prUrl" : "https://github.com/apache/spark/pull/28556#pullrequestreview-416123792",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e91f7bf4-b6fd-430f-9f95-648d0c9be943",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Thanks for adding the tests.",
        "createdAt" : "2020-05-21T13:05:14Z",
        "updatedAt" : "2020-06-10T21:42:46Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "ce5d8dcc8b5cc61d66bad619638606716b3f44bf",
    "line" : 94,
    "diffHunk" : "@@ -1,1 +420,424 @@  }\n\n  testSchemaPruning(\"select one deep nested complex field after outer join\") {\n    val query1 = sql(\"select departments.contactId, contacts.name.middle from departments \" +\n      \"left outer join contacts on departments.contactId = contacts.id\")"
  },
  {
    "id" : "1cfef316-67b3-473b-b583-df4045e9aeb6",
    "prId" : 28556,
    "prUrl" : "https://github.com/apache/spark/pull/28556#pullrequestreview-416655687",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2ab61eb3-a5ae-4b19-8423-6b37fed8368d",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "nit: I think its better to use uppercases for SQL keywords where possible.",
        "createdAt" : "2020-05-21T13:06:55Z",
        "updatedAt" : "2020-06-10T21:42:46Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "352f99e1-0de3-4ee9-9d56-9b641d948bc9",
        "parentId" : "2ab61eb3-a5ae-4b19-8423-6b37fed8368d",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Seems all tests in this test suite are using lowercases. Changing all tests seems too bothering... :)",
        "createdAt" : "2020-05-22T05:26:22Z",
        "updatedAt" : "2020-06-10T21:42:46Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "ce5d8dcc8b5cc61d66bad619638606716b3f44bf",
    "line" : 78,
    "diffHunk" : "@@ -1,1 +404,408 @@    checkAnswer(query1, Row(\"X.\") :: Row(\"Y.\") :: Nil)\n\n    val query2 = sql(\"select contacts.name.middle from contacts, departments where \" +\n      \"contacts.employer = departments.employer\")\n    checkScan(query2,"
  },
  {
    "id" : "d02e2518-0b21-4c00-8073-4698ad2da950",
    "prId" : 27503,
    "prUrl" : "https://github.com/apache/spark/pull/27503#pullrequestreview-355584146",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e0b5ec0e-d1a3-429a-8bb8-ccdc052f82ce",
        "parentId" : null,
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "Instead of fixing case by case, can we try to find all the possible cases and ensure we can cover all the possible query plans? Includes negative and positive cases. \r\n\r\nAlso, we need to have the unit test cases for these optimizer rules. ",
        "createdAt" : "2020-02-09T05:08:20Z",
        "updatedAt" : "2020-02-09T05:09:25Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      }
    ],
    "commit" : "2e2302f594fe4be55ef1ba79c0375b2838211320",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +335,339 @@\n  testSchemaPruning(\"select explode of nested field of array of struct and \" +\n      \"all remaining nested fields\") {\n    val query = spark.table(\"contacts\")\n      .select(explode(col(\"friends.first\")), col(\"friends.middle\"), col(\"friends.last\"))"
  }
]