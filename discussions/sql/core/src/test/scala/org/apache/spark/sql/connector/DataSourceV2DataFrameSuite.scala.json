[
  {
    "id" : "9dfdca81-6b22-4ddd-8bbb-6bcec6b7426b",
    "prId" : 32949,
    "prUrl" : "https://github.com/apache/spark/pull/32949#pullrequestreview-704261919",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "41bd14a4-f229-4c82-ba9f-ccc06f27d2f6",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "not related to this PR: so DS v2 can't fail correctly when writing out new interval types?",
        "createdAt" : "2021-07-12T15:36:54Z",
        "updatedAt" : "2021-07-12T15:36:54Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "236c9a82-732c-4f65-9c65-d2b84e34d8ad",
        "parentId" : "41bd14a4-f229-4c82-ba9f-ccc06f27d2f6",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "cc @imback82 ",
        "createdAt" : "2021-07-12T15:37:23Z",
        "updatedAt" : "2021-07-12T15:37:24Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "48f080fc5b3bb2a2d704a0cc6bddb8d6be56f328",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +173,177 @@\n  test(\"Cannot write data with intervals to v2\") {\n    withSQLConf(SQLConf.LEGACY_INTERVAL_ENABLED.key -> \"true\") {\n      withTable(\"testcat.table_name\") {\n        val testCatalog = spark.sessionState.catalogManager.catalog(\"testcat\").asTableCatalog"
  },
  {
    "id" : "5f98eddd-b01d-4d54-93b9-c350439e18e7",
    "prId" : 26474,
    "prUrl" : "https://github.com/apache/spark/pull/26474#pullrequestreview-316455731",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ff0189eb-b07c-4ccc-a64d-df333a10a979",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "nit. `query,\"` -> `query, \"`.",
        "createdAt" : "2019-11-13T18:01:07Z",
        "updatedAt" : "2019-11-13T18:01:08Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "d14d3ffd-7e3a-47a5-afe8-bd06dd9640cd",
        "parentId" : "ff0189eb-b07c-4ccc-a64d-df333a10a979",
        "authorId" : "f3565002-f4c0-403a-acd1-fcb849b91b5c",
        "body" : "@dongjoon-hyun I won't be able to get to this until Thursday evening. I'm willing to address it, but I didn't know how soon this needed to be merged.\r\n\r\ncc: @brkyvz ",
        "createdAt" : "2019-11-13T18:14:35Z",
        "updatedAt" : "2019-11-13T18:14:36Z",
        "lastEditedBy" : "f3565002-f4c0-403a-acd1-fcb849b91b5c",
        "tags" : [
        ]
      },
      {
        "id" : "b7580879-ac13-45e6-8104-f09075dc471d",
        "parentId" : "ff0189eb-b07c-4ccc-a64d-df333a10a979",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "I see, @SpaceRangerWes .",
        "createdAt" : "2019-11-13T18:21:47Z",
        "updatedAt" : "2019-11-13T18:21:47Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "b80f2ec736dc2f59d0190a587ae16f3853425939",
    "line" : 40,
    "diffHunk" : "@@ -1,1 +155,159 @@          assert(p.writeOptions == Map(\"other\" -> \"20\"))\n        case other =>\n          fail(s\"Expected to parse ${classOf[AppendData].getName} from query,\" +\n            s\"got ${other.getClass.getName}: $plan\")\n      }"
  }
]