[
  {
    "id" : "07c52600-691a-47e1-a298-072f3752490c",
    "prId" : 32831,
    "prUrl" : "https://github.com/apache/spark/pull/32831#pullrequestreview-697044801",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bb72fe1b-19c7-4256-a001-60447b48cc06",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "oh I missed it . It's better to move this test to PersistedViewTestSuite\r\n\r\nYou can fix it in https://github.com/apache/spark/pull/32832",
        "createdAt" : "2021-07-01T09:48:11Z",
        "updatedAt" : "2021-07-01T09:48:11Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "2fede50b9df0f1775fff86272a06e3fa2fe0eccd",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +913,917 @@  }\n\n  test(\"SPARK-35685: Prompt recreating view message for schema mismatch\") {\n    withTable(\"t\") {\n      sql(\"CREATE TABLE t USING json AS SELECT 1 AS col_i\")"
  },
  {
    "id" : "b947187e-441b-46f5-84fd-75eab91f2b88",
    "prId" : 31422,
    "prUrl" : "https://github.com/apache/spark/pull/31422#pullrequestreview-582020446",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "41869148-d264-4197-8eff-6f7237628cdb",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "cc @MaxGekk we should add tests here.",
        "createdAt" : "2021-02-02T19:01:13Z",
        "updatedAt" : "2021-02-02T19:01:14Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "d48c348a-28f5-48c1-a3df-0e50d53c2a97",
        "parentId" : "41869148-d264-4197-8eff-6f7237628cdb",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "And I guess to `HiveDDLSuite` too, right? I just wonder if we test v2 and v1 Hive external catalog, should we test v1 In-Memory catalog in that case?",
        "createdAt" : "2021-02-02T19:44:43Z",
        "updatedAt" : "2021-02-02T19:44:50Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "283b12af-4d27-43c1-9507-110845e5a3e7",
        "parentId" : "41869148-d264-4197-8eff-6f7237628cdb",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I don't think so. It's UT and we know how the code works. The catalog implementation doesn't matter. Testing it once with whatever catalog is good enough.",
        "createdAt" : "2021-02-03T05:43:50Z",
        "updatedAt" : "2021-02-03T05:43:50Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "8610b8e5924eba64394607ae80bcb0db89da5741",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +171,175 @@        s\"ALTER TABLE $viewName SET TBLPROPERTIES ('p' = 'an')\",\n        s\"$viewName is a temp view. 'ALTER TABLE ... SET TBLPROPERTIES' expects a table\")\n      assertAnalysisError(\n        s\"ALTER TABLE $viewName UNSET TBLPROPERTIES ('p')\",\n        s\"$viewName is a temp view. 'ALTER TABLE ... UNSET TBLPROPERTIES' expects a table\")"
  },
  {
    "id" : "58497e9e-3bb7-4ef1-a05d-2a10ee36badf",
    "prId" : 30567,
    "prUrl" : "https://github.com/apache/spark/pull/30567#pullrequestreview-542886673",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a2e4b000-956a-4fb9-8586-30f1234caedc",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "let's also test the first created view and make sure it respect `STORE_ANALYZED_PLAN_FOR_VIEW`",
        "createdAt" : "2020-12-02T14:26:20Z",
        "updatedAt" : "2020-12-04T02:37:28Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "db9f0baffd424beba5f9efd19620d781cfb2b22b",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +784,788 @@      withView(\"v1\") {\n        withSQLConf(STORE_ANALYZED_PLAN_FOR_VIEW.key -> \"true\") {\n          sql(\"CREATE TEMPORARY VIEW v1 AS SELECT * FROM t\")\n          Seq(4, 6, 5).toDF(\"c1\").write.mode(\"overwrite\").format(\"parquet\").saveAsTable(\"t\")\n          val e = intercept[SparkException] {"
  }
]