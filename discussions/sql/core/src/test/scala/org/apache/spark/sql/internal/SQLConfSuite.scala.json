[
  {
    "id" : "338afa25-4e6b-4075-b6b4-f7790bb279dc",
    "prId" : 32265,
    "prUrl" : "https://github.com/apache/spark/pull/32265#pullrequestreview-644081439",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ef41ea72-c0c1-4160-bd2d-51ab89db0212",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Is it better to set `COALESCE_PARTITIONS_ENABLED`, too?",
        "createdAt" : "2021-04-23T12:36:10Z",
        "updatedAt" : "2021-04-23T15:35:38Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "406de58e-784f-4f4c-a568-9778d1f1a95b",
        "parentId" : "ef41ea72-c0c1-4160-bd2d-51ab89db0212",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "thanks,updated",
        "createdAt" : "2021-04-25T01:57:18Z",
        "updatedAt" : "2021-04-25T01:57:18Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "8d55ea8bc0f9d0fc48777f56a61a731a3fb03f8d",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +122,126 @@    spark.sessionState.conf.clear()\n    try {\n      sql(s\"SET ${SQLConf.ADAPTIVE_EXECUTION_ENABLED.key}=true\")\n      sql(s\"SET ${SQLConf.COALESCE_PARTITIONS_ENABLED.key}=true\")\n      sql(s\"SET ${SQLConf.COALESCE_PARTITIONS_INITIAL_PARTITION_NUM.key}=1\")"
  },
  {
    "id" : "5c0e2715-628f-4898-a5b5-085f1e2d38c9",
    "prId" : 29146,
    "prUrl" : "https://github.com/apache/spark/pull/29146#pullrequestreview-451229133",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a657f650-ef12-4f06-94e6-99b1520a79f7",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "The existing code looks incorrect.",
        "createdAt" : "2020-07-20T01:56:59Z",
        "updatedAt" : "2020-08-03T10:05:19Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "3065ed9aa5ce232ce4f16335cbf830bd93a73f3f",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +116,120 @@      assert(spark.conf.get(SQLConf.SHUFFLE_PARTITIONS) === 10)\n    } finally {\n      sql(s\"set ${SQLConf.SHUFFLE_PARTITIONS.key}=$original\")\n    }\n  }"
  },
  {
    "id" : "4fbcbb31-e7f8-426e-a579-ca350e217b8b",
    "prId" : 27792,
    "prUrl" : "https://github.com/apache/spark/pull/27792#pullrequestreview-369223550",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a6c7af34-692b-43ce-885d-82c85e9e2b77",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Please check the error messages here.",
        "createdAt" : "2020-03-05T00:34:40Z",
        "updatedAt" : "2020-03-05T02:25:00Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "641b74b4a3987476961e047103a33a03d8743bca",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +364,368 @@    }\n    val e = intercept[IllegalArgumentException] {\n      spark.conf.set(SQLConf.SESSION_LOCAL_TIMEZONE.key, \"Asia/shanghai\")\n    }\n    assert(e.getMessage === \"Cannot resolve the given timezone with ZoneId.of(_, ZoneId.SHORT_IDS)\")"
  },
  {
    "id" : "14109301-a7e8-4a22-88d5-9981602de50d",
    "prId" : 27092,
    "prUrl" : "https://github.com/apache/spark/pull/27092#pullrequestreview-339751308",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1fc7ed6a-b08a-4b2e-8cf1-579fed5fa25f",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "nit: The same class `logAppender` seems to be defined in some places below, so can we define a helper method for this test purpose somewhere (e.g., `TestUtils`)?\r\n```\r\n$grep -nr \"extends AppenderSkeleton\" .\r\n./catalyst/src/test/scala/org/apache/spark/sql/catalyst/analysis/ResolveHintsSuite.scala:36:  class MockAppender extends AppenderSkeleton {\r\n./catalyst/src/test/scala/org/apache/spark/sql/catalyst/expressions/CodeGenerationSuite.scala:525:    class MockAppender extends AppenderSkeleton {\r\n./catalyst/src/test/scala/org/apache/spark/sql/catalyst/optimizer/OptimizerLoggingSuite.scala:42:  class MockAppender extends AppenderSkeleton {\r\n./core/src/test/scala/org/apache/spark/sql/execution/datasources/csv/CSVSuite.scala:1766:    class TestAppender extends AppenderSkeleton {\r\n./core/src/test/scala/org/apache/spark/sql/JoinHintSuite.scala:41:  class MockAppender extends AppenderSkeleton {\r\n```",
        "createdAt" : "2020-01-08T00:40:19Z",
        "updatedAt" : "2020-01-09T05:42:10Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "ee4bb37a-f3f5-4ad3-bc8c-833d764abfd4",
        "parentId" : "1fc7ed6a-b08a-4b2e-8cf1-579fed5fa25f",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "it is slightly orthogonal to the PR but if you think it makes sense I will do that here.",
        "createdAt" : "2020-01-08T09:49:15Z",
        "updatedAt" : "2020-01-09T05:42:10Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "882ce248-2f5e-4708-8ee9-a8cde3caa72a",
        "parentId" : "1fc7ed6a-b08a-4b2e-8cf1-579fed5fa25f",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Yea, I think its ok in follow-up.",
        "createdAt" : "2020-01-08T09:52:05Z",
        "updatedAt" : "2020-01-09T05:42:10Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "faf88e8f461842e1b7a549088ebcacf0ec8e4cae",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +338,342 @@\n  test(\"log deprecation warnings\") {\n    val logAppender = new AppenderSkeleton {\n      val loggingEvents = new ArrayBuffer[LoggingEvent]()\n"
  },
  {
    "id" : "bb60b199-bcce-496c-86ac-646e0eb676b6",
    "prId" : 25753,
    "prUrl" : "https://github.com/apache/spark/pull/25753#pullrequestreview-288332994",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "88ff0898-eaa4-4e34-af41-f1f5dbffc3ac",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Hi, All.\r\n\r\nUr, I'm wondering if this PR's test case is safe in concurrent testing environments?\r\nThis might be the root cause of the current outage in Apache Spark Jenkins jobs.\r\nAfter this PR, all Jenkins on `master` branch never succeeds.\r\n- https://amplab.cs.berkeley.edu/jenkins/view/Spark%20QA%20Test%20(Dashboard)/\r\n\r\nCould you take a look a little bit?",
        "createdAt" : "2019-09-13T23:37:07Z",
        "updatedAt" : "2019-09-13T23:39:52Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "83fa0ed8-4109-4991-9af1-e96ad7f9fdb2",
        "parentId" : "88ff0898-eaa4-4e34-af41-f1f5dbffc3ac",
        "authorId" : "0b3111e2-9584-4813-8cb5-8f40e119f71c",
        "body" : "Given this is late Friday, just revert this if you thinks it's breaking things.",
        "createdAt" : "2019-09-13T23:49:22Z",
        "updatedAt" : "2019-09-13T23:49:22Z",
        "lastEditedBy" : "0b3111e2-9584-4813-8cb5-8f40e119f71c",
        "tags" : [
        ]
      },
      {
        "id" : "1ae4b78b-7128-4463-8bca-fab27cc9261a",
        "parentId" : "88ff0898-eaa4-4e34-af41-f1f5dbffc3ac",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Yes. I've been investigating this and the other commits. But, this is the usual suspect given the error message. Since master branch has been broken over 2 days and it seems that we cannot fix this during weekend, I'll revert this.",
        "createdAt" : "2019-09-14T03:45:39Z",
        "updatedAt" : "2019-09-14T07:18:20Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "a9ef5bd7-a0d1-4da7-b23e-62109710c596",
        "parentId" : "88ff0898-eaa4-4e34-af41-f1f5dbffc3ac",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "Thanks for finding. I haven't noticed concurrent tests are executed, as there're many tests leveraging single object like SparkContext. I'll just exclude test code in new PR as I don't see other way to test this.\r\n\r\nBtw, do we run different options between PR and master build? I'm curious about the reason - as we tend to guess PR build pass as \"OK\".",
        "createdAt" : "2019-09-14T13:17:36Z",
        "updatedAt" : "2019-09-14T13:17:36Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      },
      {
        "id" : "78af6fb7-8e95-42f4-9ab6-7609df7a3d84",
        "parentId" : "88ff0898-eaa4-4e34-af41-f1f5dbffc3ac",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "I think the issue is probably Maven vs SBT testing differences. I personally would prefer to standardize on the Maven build for everything.",
        "createdAt" : "2019-09-14T15:35:14Z",
        "updatedAt" : "2019-09-14T15:35:14Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "f3e46a3d-be13-4504-8765-53705e2b77e9",
        "parentId" : "88ff0898-eaa4-4e34-af41-f1f5dbffc3ac",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "@HeartSaVioR  . PRBuilder is the same. PRBuilder has been very flaky last two days. I hit the same failure on my independent PRs too many times. That was the reason I investigated this and reached here to ask help.\r\n\r\n@srowen . According to the Jenkins status, All Jenkins job combinations failed. This is irrelevant to SBT and Maven difference.\r\n\r\n- https://amplab.cs.berkeley.edu/jenkins/view/Spark%20QA%20Test%20(Dashboard)/",
        "createdAt" : "2019-09-14T19:15:50Z",
        "updatedAt" : "2019-09-14T19:15:50Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "a1472e83f893c7a171b3b00a75814538246c0720",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +337,341 @@      }\n    } {\n      oldSparkContext.orElse(Some(null)).foreach(SparkContext.setActiveContext)\n    }\n  }"
  }
]