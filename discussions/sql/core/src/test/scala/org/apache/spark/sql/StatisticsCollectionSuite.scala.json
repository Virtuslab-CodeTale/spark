[
  {
    "id" : "bc69f33b-5a0b-4099-b34e-a2205f4af5d1",
    "prId" : 24725,
    "prUrl" : "https://github.com/apache/spark/pull/24725#pullrequestreview-242593270",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b4e78184-27c6-4eab-9412-032125703c41",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "nits:\r\n\r\n```diff\r\n@@ -619,7 +619,7 @@ class StatisticsCollectionSuite extends StatisticsCollectionTestBase with Shared\r\n     withTempDir { tempDir =>\r\n       val tableName = \"t1\"\r\n       val stagingDirName = \".test-staging-dir\"\r\n-      val tableLocation = s\"${tempDir.getCanonicalPath}/$tableName\"\r\n+      val tableLocation = s\"${tempDir.toURI}/$tableName\"\r\n       withSQLConf(\r\n         SQLConf.AUTO_SIZE_UPDATE_ENABLED.key -> \"true\",\r\n         \"hive.exec.stagingdir\" -> stagingDirName) {\r\n@@ -627,21 +627,22 @@ class StatisticsCollectionSuite extends StatisticsCollectionTestBase with Shared\r\n           sql(s\"CREATE TABLE $tableName(c1 BIGINT) USING PARQUET LOCATION '$tableLocation'\")\r\n           sql(s\"INSERT INTO TABLE $tableName VALUES(1)\")\r\n\r\n-          val staging = new File(s\"$tableLocation/$stagingDirName\")\r\n-          val stagingWriter = new PrintWriter(staging)\r\n-          stagingWriter.write(\"12\")\r\n-          stagingWriter.close()\r\n+          val staging = new File(new URI(s\"$tableLocation/$stagingDirName\"))\r\n+          Utils.tryWithResource(new PrintWriter(staging)) { stagingWriter =>\r\n+            stagingWriter.write(\"12\")\r\n+          }\r\n+\r\n+          val metadata = new File(new URI(s\"$tableLocation/_metadata\"))\r\n\r\n-          val metadata = new File(s\"$tableLocation/_metadata\")\r\n-          val metadataWriter = new PrintWriter(metadata)\r\n-          metadataWriter.write(\"1234\")\r\n-          metadataWriter.close()\r\n+          Utils.tryWithResource(new PrintWriter(staging)) { metadataWriter =>\r\n+            metadataWriter.write(\"1234\")\r\n+          }\r\n\r\n           sql(s\"INSERT INTO TABLE $tableName VALUES(1)\")\r\n\r\n           val stagingFileSize = staging.length()\r\n           val metadataFileSize = metadata.length()\r\n-          val tableLocationSize = getDataSize(new File(tableLocation))\r\n+          val tableLocationSize = getDataSize(new File(new URI(tableLocation)))\r\n\r\n           val stats = checkTableStats(tableName, hasSizeInBytes = true, expectedRowCounts = None)\r\n           assert(stats.get.sizeInBytes === tableLocationSize - stagingFileSize - metadataFileSize)\r\n```\r\n\r\nUsing URI makes the test working on Windows too. If the test isn't specific to paths, it's better to stick to using URI.",
        "createdAt" : "2019-05-28T10:25:55Z",
        "updatedAt" : "2019-05-28T11:24:00Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "0d6905f4-7ec9-4dda-b969-893de450ad7c",
        "parentId" : "b4e78184-27c6-4eab-9412-032125703c41",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "OK. Thank you @HyukjinKwon",
        "createdAt" : "2019-05-28T10:59:17Z",
        "updatedAt" : "2019-05-28T11:24:00Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      }
    ],
    "commit" : "fb44905b6eff346919965065bc39da35fa247ef7",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +617,621 @@  }\n\n  test(\"Metadata files and temporary files should not be counted as data files\") {\n    withTempDir { tempDir =>\n      val tableName = \"t1\""
  },
  {
    "id" : "5f218d20-4961-47a0-b052-4a88f9606d45",
    "prId" : 24315,
    "prUrl" : "https://github.com/apache/spark/pull/24315#pullrequestreview-225119643",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "56c28db1-5a39-41d7-a83f-438b32e6491c",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Thank you for updating, @sujith71955 . Here are two issues.\r\n1. We need to test both cases by using `Seq(false, true).foreach { autoUpdate =>`\r\n2. The current indentation is wrong at 343.\r\n\r\nIf you fix (1), (2) will be fixed together.",
        "createdAt" : "2019-04-09T22:51:31Z",
        "updatedAt" : "2019-04-10T17:35:00Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "43439fa1-ecdf-4ba6-9b55-b9a734a80863",
        "parentId" : "56c28db1-5a39-41d7-a83f-438b32e6491c",
        "authorId" : "af3c4746-a0c1-471e-870b-484d8f09968a",
        "body" : "Handled the comment. thanks",
        "createdAt" : "2019-04-10T17:40:56Z",
        "updatedAt" : "2019-04-10T17:40:56Z",
        "lastEditedBy" : "af3c4746-a0c1-471e-870b-484d8f09968a",
        "tags" : [
        ]
      }
    ],
    "commit" : "3692775ab281be2434e8e4af916e7a655f0d0377",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +341,345 @@    val table = \"change_stats_insert_datasource_table\"\n    Seq(false, true).foreach { autoUpdate =>\n      withSQLConf(SQLConf.AUTO_SIZE_UPDATE_ENABLED.key -> autoUpdate.toString) {\n        withTable(table) {\n          sql(s\"CREATE TABLE $table (i int, j string) USING PARQUET\")"
  }
]