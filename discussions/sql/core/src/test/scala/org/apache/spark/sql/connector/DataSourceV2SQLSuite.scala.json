[
  {
    "id" : "59115b34-5d86-4747-a4ab-1d04238ba1cd",
    "prId" : 33343,
    "prUrl" : "https://github.com/apache/spark/pull/33343#pullrequestreview-706913332",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "347a7258-a5b4-48b1-9915-561b0f42a166",
        "parentId" : null,
        "authorId" : "3a227965-84e0-47cf-9974-11293764f028",
        "body" : "The modified test fails with both Scala `2.12` and `2.13` without the change in `ShowCreateTableExec.scala`.",
        "createdAt" : "2021-07-15T04:28:37Z",
        "updatedAt" : "2021-07-15T04:28:37Z",
        "lastEditedBy" : "3a227965-84e0-47cf-9974-11293764f028",
        "tags" : [
        ]
      }
    ],
    "commit" : "4d6d401a0ab101a0262c48105726a169393d68dc",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +2015,2019 @@        \"'prop2' = '2',\",\n        \"'prop3' = '3',\",\n        \"'prop4' = '4')\"\n      ))\n    }"
  },
  {
    "id" : "318b4404-9887-4c7b-9fd3-c3b3fb3511e9",
    "prId" : 32931,
    "prUrl" : "https://github.com/apache/spark/pull/32931#pullrequestreview-692662262",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "97e82b67-b589-487b-b3d8-e31648e282e0",
        "parentId" : null,
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "shall these attributes be quoted too?",
        "createdAt" : "2021-06-23T09:51:57Z",
        "updatedAt" : "2021-06-23T09:51:57Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "905fe519-27c8-4cd1-8233-5ee4cefe16a5",
        "parentId" : "97e82b67-b589-487b-b3d8-e31648e282e0",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I think we should not quote the column names in other places instead, if there is no special char.",
        "createdAt" : "2021-06-23T09:57:53Z",
        "updatedAt" : "2021-06-23T09:57:53Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "c9275104-dbff-48f5-9d2a-7458ecf572b3",
        "parentId" : "97e82b67-b589-487b-b3d8-e31648e282e0",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "> I think we should not quote the column names in other places instead, if there is no special char.\r\n\r\n+1",
        "createdAt" : "2021-06-23T09:59:26Z",
        "updatedAt" : "2021-06-23T09:59:26Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "0652305d-dc1a-4f2b-9681-52356255ac45",
        "parentId" : "97e82b67-b589-487b-b3d8-e31648e282e0",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "@Peng-Lei can you address this?\r\n\r\n> I think we should not quote the column names in other places instead, if there is no special char.\r\n\r\n",
        "createdAt" : "2021-06-25T10:01:15Z",
        "updatedAt" : "2021-06-25T10:01:15Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "b8e6db8840b5de34213179ea54e02db287d6427f",
    "line" : 100,
    "diffHunk" : "@@ -1,1 +2055,2059 @@        \"`ts` TIMESTAMP)\",\n        \"USING foo\",\n        \"PARTITIONED BY (a, bucket(16, b), years(ts), months(ts), days(ts), hours(ts))\"\n      ))\n    }"
  },
  {
    "id" : "cc50b3c8-bdfa-4567-a8ae-72da0a6afc53",
    "prId" : 31654,
    "prUrl" : "https://github.com/apache/spark/pull/31654#pullrequestreview-601092928",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2086c97b-fa17-4e4d-baee-77e963bf7fab",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I'm a bit confused. We have a test `SPARK-31255: Projects data column when metadata column has the same name` in this file, which tests when column name and metadata column name have conflicts. Why does that test work?",
        "createdAt" : "2021-03-01T05:31:28Z",
        "updatedAt" : "2021-03-01T19:53:18Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "3924d5a0-0505-4708-af6d-f3ad4167b645",
        "parentId" : "2086c97b-fa17-4e4d-baee-77e963bf7fab",
        "authorId" : "ada71464-b8c9-4d7b-9020-d49c27251fdb",
        "body" : "This is covered at the [level](https://github.com/apache/spark/blob/62737e140c7b04805726a33c392c297335db7b45/sql/catalyst/src/main/scala/org/apache/spark/sql/execution/datasources/v2/DataSourceV2Relation.scala#L59) of the DatasourceV2Relation, but does not apply above it.",
        "createdAt" : "2021-03-01T05:35:19Z",
        "updatedAt" : "2021-03-01T19:53:18Z",
        "lastEditedBy" : "ada71464-b8c9-4d7b-9020-d49c27251fdb",
        "tags" : [
        ]
      },
      {
        "id" : "76091593-32e1-4369-a5f5-6f52e8e642b0",
        "parentId" : "2086c97b-fa17-4e4d-baee-77e963bf7fab",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Ah I see! Can we remove the hack in `DatasourceV2Relation` now?",
        "createdAt" : "2021-03-01T05:54:42Z",
        "updatedAt" : "2021-03-01T19:53:18Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "9ec951e4-3256-456c-8a92-bd79f5c63889",
        "parentId" : "2086c97b-fa17-4e4d-baee-77e963bf7fab",
        "authorId" : "ada71464-b8c9-4d7b-9020-d49c27251fdb",
        "body" : "We can remove it from `metadataOutput`, but I don't believe we can remove it in `withMetadataColumns` due to the output containing a name collision.",
        "createdAt" : "2021-03-01T19:32:34Z",
        "updatedAt" : "2021-03-01T19:53:18Z",
        "lastEditedBy" : "ada71464-b8c9-4d7b-9020-d49c27251fdb",
        "tags" : [
        ]
      }
    ],
    "commit" : "5a7209edd25fd0f59a0eadc1b0dabd2d146d2a70",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +2493,2497 @@  }\n\n  test(\"SPARK-34547: metadata columns are resolved last\") {\n    val t1 = s\"${catalogAndNamespace}tableOne\"\n    val t2 = \"t2\""
  },
  {
    "id" : "08ec4cbc-c318-4ea5-9c12-249545834434",
    "prId" : 31427,
    "prUrl" : "https://github.com/apache/spark/pull/31427#pullrequestreview-587019861",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b2828a02-35c7-4e24-aa4b-cbc73d1397a9",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "nit: Is it okay to remove the information about why a given name is unsupported?",
        "createdAt" : "2021-02-02T01:05:10Z",
        "updatedAt" : "2021-02-02T01:05:10Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "49f59e27-fc4a-4799-aa02-20dea87a4186",
        "parentId" : "b2828a02-35c7-4e24-aa4b-cbc73d1397a9",
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "So the reason isn't that the namespace in session catalog must have exactly one name part anymore, so I think it's an OK change.",
        "createdAt" : "2021-02-04T17:55:44Z",
        "updatedAt" : "2021-02-04T17:55:44Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      },
      {
        "id" : "e308f382-22a6-4c75-984a-59236e3bda6f",
        "parentId" : "b2828a02-35c7-4e24-aa4b-cbc73d1397a9",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Do you mean now we have the allowed case? Do we have a test case when it works if so?",
        "createdAt" : "2021-02-09T21:18:44Z",
        "updatedAt" : "2021-02-09T21:18:44Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "23964ff1b4bdae26f4e5617322316197a388ae2c",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +2101,2105 @@      sql(\"DESCRIBE FUNCTION default.ns1.ns2.fun\")\n    }\n    assert(e1.message.contains(\"Unsupported function name 'default.ns1.ns2.fun'\"))\n  }\n"
  },
  {
    "id" : "8e89029d-6091-4594-b661-63c6fd9d802c",
    "prId" : 31427,
    "prUrl" : "https://github.com/apache/spark/pull/31427#pullrequestreview-587260747",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "33deed84-afd6-4e6a-af7f-5ce45ed771f8",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "The error message is confusing now because there is a table `t` and Spark still complains that `Table or view not found`. ",
        "createdAt" : "2021-02-10T05:10:28Z",
        "updatedAt" : "2021-02-10T05:10:28Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "23964ff1b4bdae26f4e5617322316197a388ae2c",
    "line" : 57,
    "diffHunk" : "@@ -1,1 +2217,2221 @@        def verify(sql: String): Unit = {\n          val e = intercept[AnalysisException](spark.sql(sql))\n          assert(e.message.contains(s\"Table or view not found: $t\"),\n            s\"Error message did not contain expected text while evaluting $sql\")\n        }"
  },
  {
    "id" : "8135daeb-ea85-40be-b15f-eb3db814ca68",
    "prId" : 31273,
    "prUrl" : "https://github.com/apache/spark/pull/31273#pullrequestreview-572985627",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "55c07a3e-2047-46ea-963e-9c97c376ae70",
        "parentId" : null,
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "This needs to be updated now that `ResolveSessionCatalog` handles `CreateViewStatement` only if its `child` is resolved.",
        "createdAt" : "2021-01-21T05:03:28Z",
        "updatedAt" : "2021-02-24T04:37:19Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "82d58baa98235f912141b2b40cdcd3bf0bdbe744",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1993,1997 @@    val v = \"testcat.ns1.ns2.v\"\n    val e = intercept[AnalysisException] {\n      sql(s\"CREATE VIEW $v AS SELECT 1\")\n    }\n    assert(e.message.contains(\"CREATE VIEW is only supported with v1 tables\"))"
  },
  {
    "id" : "80ef0bfb-de47-499b-bbee-3e74c92e60b2",
    "prId" : 31172,
    "prUrl" : "https://github.com/apache/spark/pull/31172#pullrequestreview-567884591",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "70ea925f-0f79-4b0a-ad08-de94624176f5",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "This PR can be considered as a bug fix. Before this PR, `REFRESH TABLE` uncaches all dependencies from the cache.",
        "createdAt" : "2021-01-13T19:37:55Z",
        "updatedAt" : "2021-01-13T19:37:55Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "2f877ff8-fc92-4ca1-9393-ab89b8ccf818",
        "parentId" : "70ea925f-0f79-4b0a-ad08-de94624176f5",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "Hmm... curious why is it a bug fix, `REFRESH TABLE` still recaches the table itself right? and uncaches all dependencies is just conservative but not incorrect?",
        "createdAt" : "2021-01-13T21:54:20Z",
        "updatedAt" : "2021-01-13T21:54:21Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "b857058b-150d-4425-8782-69f424f561dd",
        "parentId" : "70ea925f-0f79-4b0a-ad08-de94624176f5",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "> REFRESH TABLE still recaches the table itself right?\r\n\r\nRight.\r\n\r\n> and uncaches all dependencies is just conservative but not incorrect?\r\n\r\nCorrect, in term of correctness, this is not a bug.",
        "createdAt" : "2021-01-13T22:13:15Z",
        "updatedAt" : "2021-01-13T22:13:15Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "11fa5e5b-279c-4c11-9dd8-28d38ce7c6d4",
        "parentId" : "70ea925f-0f79-4b0a-ad08-de94624176f5",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "What's the behavior of 3.0? do we recache or simply uncache?",
        "createdAt" : "2021-01-14T03:48:02Z",
        "updatedAt" : "2021-01-14T03:48:02Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "eb879ddb-34dd-49fc-ac68-c830da9349a1",
        "parentId" : "70ea925f-0f79-4b0a-ad08-de94624176f5",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ah it's a new behavior for v2 table in 3.1. What's the behavior for v1 table?",
        "createdAt" : "2021-01-14T03:49:16Z",
        "updatedAt" : "2021-01-14T03:49:16Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "22bd6280-60e7-47fb-b93f-1d2d08c9eccf",
        "parentId" : "70ea925f-0f79-4b0a-ad08-de94624176f5",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "Uncaching (as opposed to recaching) dependencies has been the behavior for v1 since 2.0.0 via [SPARK-15367](https://issues.apache.org/jira/browse/SPARK-15367). We followed the same behavior when adding the logic to v2 in #30359.",
        "createdAt" : "2021-01-14T04:04:28Z",
        "updatedAt" : "2021-01-14T04:04:28Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "b6011b21-b71b-4013-8f51-c44dd0c004f0",
        "parentId" : "70ea925f-0f79-4b0a-ad08-de94624176f5",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "@MaxGekk what's the motivation to change the behavior only for v2 tables?",
        "createdAt" : "2021-01-14T04:06:30Z",
        "updatedAt" : "2021-01-14T04:06:30Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "2d2a29dc-a391-4abf-9d09-29f17e02994e",
        "parentId" : "70ea925f-0f79-4b0a-ad08-de94624176f5",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "The number of cases that need to handle in `DataSourceV2Strategy` - just one `DataSourceV2Relation`.\r\n\r\nThe main motivation for such changes is to \"fix\" `CatalogImpl.refreshTable()` too because it brought significant overhead even for uncached tables since we started to use it in fixing bugs in v1 DDL commands. Just in case, `CatalogImpl.refreshTable()` can be used for v1 as well as for v2 tables (available as public API to users).\r\n\r\n > the behavior only for v2 tables\r\n\r\nhmm, you probably asking about v1 DDL commands like `ALTER TABLE .. ADD/DROP PARTITION` (touched in this PR) but recaching of v1 tables didn't work at all a couple weeks ago for some commands and v1 tables. I don't think that comparison of changes here and in `CatalogImpl.refreshTable()` is fair. If we look at the 2.4 branch, it still has troubles. ",
        "createdAt" : "2021-01-14T06:10:57Z",
        "updatedAt" : "2021-01-14T06:10:57Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "92130d91-ec5b-4110-9275-7b416dbd90df",
        "parentId" : "70ea925f-0f79-4b0a-ad08-de94624176f5",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "To be clear: does this PR have behavior change?",
        "createdAt" : "2021-01-14T06:22:58Z",
        "updatedAt" : "2021-01-14T06:22:58Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "5c405c0d-5ca1-472f-b792-b7df18fe9550",
        "parentId" : "70ea925f-0f79-4b0a-ad08-de94624176f5",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Should not. Results of queries are the same. Since it keeps dependences cached, second actions should be faster.",
        "createdAt" : "2021-01-14T06:41:51Z",
        "updatedAt" : "2021-01-14T06:41:52Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "f4415ebe42443ce4127aebf4f83cf3f93ec531b2",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +1644,1648 @@        assert(spark.sharedState.cacheManager.lookupCachedData(spark.table(\"t\")).isDefined)\n        sql(s\"REFRESH TABLE $tblName\")\n        assert(spark.sharedState.cacheManager.lookupCachedData(spark.table(\"t\")).isDefined)\n        checkAnswer(spark.table(tblName), Seq(Row(0), Row(1)))\n        checkAnswer(spark.table(\"t\"), Seq(Row(0), Row(1)))"
  },
  {
    "id" : "31adc4bb-2985-4dc3-8b86-04eaf7598cc5",
    "prId" : 30881,
    "prUrl" : "https://github.com/apache/spark/pull/30881#pullrequestreview-559780606",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "64194562-ddc2-4c70-85dd-eb0913390702",
        "parentId" : null,
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "The error message is different for v1 / v2 tables when the column does not exist.\r\nv1: `Column invalid_col does not exist`\r\nv2: ```cannot resolve '`invalid_col`' given input columns: [testcat.tbl.data, testcat.tbl.id]```\r\n`CheckAnalysis` handles `UnresolvedAttribute` automatically for v2. Should we make this consistent (i.e., make v2 emit messages like v1)?",
        "createdAt" : "2020-12-30T01:38:47Z",
        "updatedAt" : "2020-12-30T16:14:02Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      },
      {
        "id" : "dd192e4b-70ad-4bab-89cf-0f6d52da2e77",
        "parentId" : "64194562-ddc2-4c70-85dd-eb0913390702",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I think v2 is better. Let's keep it.",
        "createdAt" : "2020-12-30T05:01:21Z",
        "updatedAt" : "2020-12-30T16:14:02Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "a19f5f0b965d6c9dc59f1963ce6296e1639df751",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +176,180 @@      assertAnalysisError(\n        s\"DESCRIBE $t invalid_col\",\n        \"cannot resolve '`invalid_col`' given input columns: [testcat.tbl.data, testcat.tbl.id]\")\n    }\n  }"
  },
  {
    "id" : "3cb53f51-5e46-4410-8713-f0a75b99b118",
    "prId" : 30475,
    "prUrl" : "https://github.com/apache/spark/pull/30475#pullrequestreview-537736276",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "282484b3-132e-41c6-b675-82ae6bd098c5",
        "parentId" : null,
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "This message could be misleading since `DROP TABLE` supports table and a temporary view. To fix this, we can add `allowPermanentView` as the following and update `Analyzer` accordingly:\r\n```scala\r\ncase class UnresolvedTableOrView(\r\n    multipartIdentifier: Seq[String],\r\n    commandName: String,\r\n    allowTempView: Boolean = true,\r\n    allowPermanentView: Boolean = true) extends LeafNode {\r\n  require(allowTempView || allowPermanentView)\r\n  override lazy val resolved: Boolean = false\r\n  override def output: Seq[Attribute] = Nil\r\n}\r\n```\r\nsuch that the exception message can be updated to\r\n`Table or temporary view not found for 'DROP TABLE': t`.\r\n\r\nOne downside is that if `t` is resolved to a view, the message will become:\r\n```\r\nt is a permanent view. 'DROP TABLE' expects a table or temporary view.\r\n```\r\ninstead of (current message):\r\n```\r\nCannot drop a view with DROP TABLE. Please use DROP VIEW instead\r\n```\r\n, meaning it will lose the \"hint\" (which we can add it to `Unresolved*` if required).\r\n\r\n@cloud-fan WDYT? If you are OK with introducing `allowPermanentView`, I can do it as a separate PR.",
        "createdAt" : "2020-11-23T21:57:51Z",
        "updatedAt" : "2020-11-27T08:17:30Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      },
      {
        "id" : "4b0db226-7f96-44eb-95f1-f577edbff72f",
        "parentId" : "282484b3-132e-41c6-b675-82ae6bd098c5",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Sorry I don't get it. In this case, `testcat.db.notbl` is not a permanent view, but a non-existing relation.",
        "createdAt" : "2020-11-24T05:53:41Z",
        "updatedAt" : "2020-11-27T08:17:30Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "451247de-35d5-47cd-8fc0-128c9bf289b6",
        "parentId" : "282484b3-132e-41c6-b675-82ae6bd098c5",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "When I read `Table or view not found for 'DROP TABLE': t`, it sounded like `DROP TABLE` also supports permanent views.\r\n\r\nSo, I was suggesting `Table or temporary view not found for 'DROP TABLE': t` since `DROP TABLE` requires either a table or temporary view. But, I guess `Table or view not found` sounds better if we want to point out the non-existing relation.",
        "createdAt" : "2020-11-24T07:40:24Z",
        "updatedAt" : "2020-11-27T08:17:30Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      },
      {
        "id" : "9c8bcac5-747a-43df-af00-a17e5bdc41c6",
        "parentId" : "282484b3-132e-41c6-b675-82ae6bd098c5",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "> since DROP TABLE requires either a table or temporary view\r\n\r\nDo we have such a test case for v2 DROP TABLE?",
        "createdAt" : "2020-11-24T08:43:07Z",
        "updatedAt" : "2020-11-27T08:17:30Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "06744e4d-57ff-4cd5-9b34-66097a24712a",
        "parentId" : "282484b3-132e-41c6-b675-82ae6bd098c5",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "v2 `DROP TABLE` only handles `ResolvedTable`. If it's resolved to a view, it will be handled in `ResolveSessionCatalog` and tested here:\r\nhttps://github.com/apache/spark/blob/fdd6c73b3cfac5af30c789c7f70b92367a79f7e7/sql/hive/src/test/scala/org/apache/spark/sql/hive/execution/HiveDDLSuite.scala#L1056-L1070",
        "createdAt" : "2020-11-24T17:15:54Z",
        "updatedAt" : "2020-11-27T08:17:30Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "46a4c4e138c2d649889dced98caabab2db750096",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +730,734 @@      sql(\"DROP TABLE testcat.db.notbl\")\n    }\n    assert(ex.getMessage.contains(\"Table or view not found for 'DROP TABLE': testcat.db.notbl\"))\n    sql(\"DROP TABLE IF EXISTS testcat.db.notbl\")\n  }"
  },
  {
    "id" : "4a3f6ac8-84d0-4653-b504-66bf6ca24d93",
    "prId" : 30449,
    "prUrl" : "https://github.com/apache/spark/pull/30449#pullrequestreview-535804330",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8a106e97-996b-4e16-a1d1-2d47ea6fb9e9",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Yep. Good to have. +1.",
        "createdAt" : "2020-11-20T21:57:44Z",
        "updatedAt" : "2020-11-20T21:57:44Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "362e8b86ae18d5833c281717924a778e1108085a",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +2477,2481 @@      assert(partTable.partitionExists(expectedPartitionIdent))\n      // Insert into the existing partition must not fail\n      sql(s\"INSERT INTO $t PARTITION(id = 1, city = 'NY') SELECT 'def'\")\n      assert(partTable.partitionExists(expectedPartitionIdent))\n    }"
  },
  {
    "id" : "3359bcf9-ec0d-4556-b265-70740a18f887",
    "prId" : 30403,
    "prUrl" : "https://github.com/apache/spark/pull/30403#pullrequestreview-537163823",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "75d8a43c-3847-4c63-839b-6e89100db713",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "shall we also test CACHE TABLE AS SELECT? with temp view exists and not.",
        "createdAt" : "2020-11-24T07:23:41Z",
        "updatedAt" : "2020-11-27T21:30:33Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "9970aea4-02ea-46e3-bb62-5ce4b17801de",
        "parentId" : "75d8a43c-3847-4c63-839b-6e89100db713",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "Added a test with an existing temp view to `CachedTableSuite`.",
        "createdAt" : "2020-11-24T08:05:03Z",
        "updatedAt" : "2020-11-27T21:30:33Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "7e788cea5c2dd03f71ee30b0106e04d7f036f30f",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +2020,2024 @@  }\n\n  test(\"CACHE/UNCACHE TABLE\") {\n    val t = \"testcat.ns1.ns2.tbl\"\n    withTable(t) {"
  },
  {
    "id" : "4f44f8d7-5060-4257-8098-fba55e1494a3",
    "prId" : 30403,
    "prUrl" : "https://github.com/apache/spark/pull/30403#pullrequestreview-542418593",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "91d90341-2b2b-4782-b625-1a1548765b0f",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "unnecessary change. This is minor and let's fix it in your next PR.",
        "createdAt" : "2020-11-30T05:36:13Z",
        "updatedAt" : "2020-11-30T05:36:13Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "0fc49a0e-1e3d-4261-93eb-ee337480a9b3",
        "parentId" : "91d90341-2b2b-4782-b625-1a1548765b0f",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "Ok, will fix.",
        "createdAt" : "2020-12-02T00:58:52Z",
        "updatedAt" : "2020-12-02T00:58:52Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "7e788cea5c2dd03f71ee30b0106e04d7f036f30f",
    "line" : 58,
    "diffHunk" : "@@ -1,1 +2558,2562 @@  }\n\n  private def testNotSupportedV2Command(\n      sqlCommand: String,\n      sqlParams: String,"
  },
  {
    "id" : "0249c634-65fe-46a9-88b8-9199648eadc6",
    "prId" : 30229,
    "prUrl" : "https://github.com/apache/spark/pull/30229#pullrequestreview-523053658",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "18d6f082-a62b-46a9-be91-c9656146ccf5",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Not related to this PR, but we should unify the error message, to either  `is not supported for v2 tables` or `is only supported with v1 tables`",
        "createdAt" : "2020-11-04T05:13:52Z",
        "updatedAt" : "2020-11-04T05:13:52Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "e9a228a3-283c-49e7-a0dc-cc4ddd894345",
        "parentId" : "18d6f082-a62b-46a9-be91-c9656146ccf5",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "Yes, the plan is to move all the commands using `parseV1Table` in `ResolveSessionCatalog` to use the new framework and unify the message in the process.",
        "createdAt" : "2020-11-04T05:32:21Z",
        "updatedAt" : "2020-11-04T05:32:21Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "c80e8eb5828ff68a1ebab4f9ee56b55b852ba7d0",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +2611,2615 @@      sql(s\"$sqlCommand $sqlParams\")\n    }\n    assert(e.message.contains(s\"$sqlCommand is not supported for v2 tables\"))\n  }\n"
  },
  {
    "id" : "66305289-116d-4d36-9f7e-0021d0b62e1e",
    "prId" : 30211,
    "prUrl" : "https://github.com/apache/spark/pull/30211#pullrequestreview-526962035",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a8ed4796-6fe2-4a58-9ddf-8f71361c49ab",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can we also check that `view` is not cached either?",
        "createdAt" : "2020-11-10T05:17:37Z",
        "updatedAt" : "2020-11-10T09:11:06Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "59c56aec-cbef-4cf1-8619-6ab2aa14929f",
        "parentId" : "a8ed4796-6fe2-4a58-9ddf-8f71361c49ab",
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "hmm can you elaborate? I thought this is checking that `view` is not cached.",
        "createdAt" : "2020-11-10T07:06:18Z",
        "updatedAt" : "2020-11-10T09:11:06Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "787ee369-1410-40ea-98d3-e97948be5598",
        "parentId" : "a8ed4796-6fe2-4a58-9ddf-8f71361c49ab",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "sorry I misread the code.",
        "createdAt" : "2020-11-10T08:32:10Z",
        "updatedAt" : "2020-11-10T09:11:06Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "1b7c991e385d160f0ab80db77329170dd713c97e",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +796,800 @@\n        sql(s\"DROP TABLE $t\")\n        assert(spark.sharedState.cacheManager.lookupCachedData(spark.table(view)).isEmpty)\n      }\n    }"
  },
  {
    "id" : "b44fb161-e3e4-4fac-8673-d832be46c8ac",
    "prId" : 29880,
    "prUrl" : "https://github.com/apache/spark/pull/29880#pullrequestreview-497037120",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b411791e-8d2a-4cbc-a5a0-e73966a209bc",
        "parentId" : null,
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "There doesn't seem to be a test coverage for this, so I am adding here.",
        "createdAt" : "2020-09-26T23:22:08Z",
        "updatedAt" : "2020-10-06T19:46:53Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "97a4deb99439fb6f5903c44d3ca6b74bae1c2f78",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +171,175 @@  }\n\n  test(\"Describe column is not supported for v2 catalog\") {\n    withTable(\"testcat.tbl\") {\n      spark.sql(\"CREATE TABLE testcat.tbl (id bigint) USING foo\")"
  },
  {
    "id" : "ad54d2e6-ed73-42d2-bf0b-c94422366bbd",
    "prId" : 29880,
    "prUrl" : "https://github.com/apache/spark/pull/29880#pullrequestreview-501438059",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "28a0b619-d9ec-48e1-b0b8-f9cd4322c43b",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "If there is no API limitation to support it, can we implement describe column for v2 catalogs later? @imback82 ",
        "createdAt" : "2020-09-29T13:04:27Z",
        "updatedAt" : "2020-10-06T19:46:53Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "a34e918b-f95b-4c38-8d9b-6b63dcc63410",
        "parentId" : "28a0b619-d9ec-48e1-b0b8-f9cd4322c43b",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "OK, I will take a look.",
        "createdAt" : "2020-10-02T20:47:31Z",
        "updatedAt" : "2020-10-06T19:46:53Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "97a4deb99439fb6f5903c44d3ca6b74bae1c2f78",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +177,181 @@        spark.sql(\"DESCRIBE testcat.tbl id\")\n      }\n      assert(ex.message.contains(\"Describing columns is not supported for v2 tables\"))\n    }\n  }"
  },
  {
    "id" : "4c004493-b359-40a2-82ef-bac874137c3e",
    "prId" : 27650,
    "prUrl" : "https://github.com/apache/spark/pull/27650#pullrequestreview-362402757",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2c0e3550-0b75-4bee-9a99-c64b17a1fd59",
        "parentId" : null,
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "Add a test for `CREATE TABLE ... AS SELECT` as well?",
        "createdAt" : "2020-02-21T05:11:44Z",
        "updatedAt" : "2020-02-27T16:22:43Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "6685dc5dbbbea0f4cd069f1a5e92ccb70033f493",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +267,271 @@    assert(!t1.properties.containsKey(TableCatalog.PROP_PROVIDER))\n\n    sql(\"CREATE TABLE t2 (id int)\")\n    val t2 = spark.sessionState.catalogManager.v2SessionCatalog.asTableCatalog\n      .loadTable(Identifier.of(Array(\"default\"), \"t2\")).asInstanceOf[V1Table]"
  }
]