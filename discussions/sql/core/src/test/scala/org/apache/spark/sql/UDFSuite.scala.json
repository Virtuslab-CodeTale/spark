[
  {
    "id" : "6176127f-002c-41d5-8a92-ac411bea23a3",
    "prId" : 29106,
    "prUrl" : "https://github.com/apache/spark/pull/29106#pullrequestreview-608610553",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "945777c7-3334-42d3-b55f-dce10db096e7",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Aggression ? Maybe Aggregation?",
        "createdAt" : "2021-03-08T11:12:47Z",
        "updatedAt" : "2021-03-08T11:12:59Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "9013bdba-4958-4e6c-b1a6-058739721cbd",
        "parentId" : "945777c7-3334-42d3-b55f-dce10db096e7",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "yea should be Aggregation",
        "createdAt" : "2021-03-08T11:45:33Z",
        "updatedAt" : "2021-03-08T11:45:33Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "8b7a37a3-b595-48b3-8f49-1af2e65baeeb",
        "parentId" : "945777c7-3334-42d3-b55f-dce10db096e7",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "I am writing tests for intervals in UDF now. I will fix this in the PR for intervals, if you don't mind.",
        "createdAt" : "2021-03-08T11:54:11Z",
        "updatedAt" : "2021-03-08T11:54:46Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "e1cd634c-59e3-4fe6-a2a6-27b027844320",
        "parentId" : "945777c7-3334-42d3-b55f-dce10db096e7",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "thanks!",
        "createdAt" : "2021-03-08T12:09:16Z",
        "updatedAt" : "2021-03-08T12:09:16Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "0435bc76-1eda-4f36-930c-2558ccea97e0",
        "parentId" : "945777c7-3334-42d3-b55f-dce10db096e7",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Here is the PR with the fix: https://github.com/apache/spark/pull/31779",
        "createdAt" : "2021-03-08T12:33:56Z",
        "updatedAt" : "2021-03-08T12:33:56Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "1e0d320c-48a3-4511-bf50-5f524e3f403a",
        "parentId" : "945777c7-3334-42d3-b55f-dce10db096e7",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "lol",
        "createdAt" : "2021-03-10T11:33:00Z",
        "updatedAt" : "2021-03-10T11:33:00Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "427d112f3fcff00076f2895dc3a47a1ba9e035a7",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +777,781 @@  }\n\n  test(\"SPARK-32307: Aggression that use map type input UDF as group expression\") {\n    spark.udf.register(\"key\", udf((m: Map[String, String]) => m.keys.head.toInt))\n    Seq(Map(\"1\" -> \"one\", \"2\" -> \"two\")).toDF(\"a\").createOrReplaceTempView(\"t\")"
  },
  {
    "id" : "e5d16b34-70fc-4c57-ad56-a515393b6479",
    "prId" : 29050,
    "prUrl" : "https://github.com/apache/spark/pull/29050#pullrequestreview-446096832",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "382f8aca-bb51-4a48-af84-51305e331b52",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Just a qestion; we need the two cases here for checking the issue? I mean; is either one not enough for tests? ",
        "createdAt" : "2020-07-09T11:26:54Z",
        "updatedAt" : "2020-07-09T11:36:31Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "0f08bf4c-021f-4053-a09f-721fca386e99",
        "parentId" : "382f8aca-bb51-4a48-af84-51305e331b52",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "It should be enough. But just want to improve test coverage on both non-primitive and primitive types for Scala UDF.",
        "createdAt" : "2020-07-10T03:17:55Z",
        "updatedAt" : "2020-07-10T03:17:56Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "08749bd0c1c2e6524866c7eb8e36e3c0ffb57835",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +686,690 @@    OuterScopes.addOuterScope(MalformedClassObject)\n    val f1 = new MalformedClassObject.MalformedNonPrimitiveFunction()\n    val f2 = new MalformedClassObject.MalformedPrimitiveFunction()\n\n    val e1 = intercept[SparkException] {"
  },
  {
    "id" : "34c2ac31-85d9-4055-9260-465850f1170d",
    "prId" : 28979,
    "prUrl" : "https://github.com/apache/spark/pull/28979#pullrequestreview-441658508",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f1b21483-c163-4a0f-bae5-512bf0b6d509",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can we add one more test to combine `Instant` and `Timestamp`? This is not possible before this PR.",
        "createdAt" : "2020-07-02T13:06:00Z",
        "updatedAt" : "2020-07-09T13:18:13Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "871c35ffd3d71cef6040849561ae07a8d4e6b370",
    "line" : 65,
    "diffHunk" : "@@ -1,1 +531,535 @@  }\n\n  test(\"Using combined types of Instant/LocalDate in UDF\") {\n    val dtf = DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\")\n    val date = LocalDate.parse(\"2019-02-26\")"
  },
  {
    "id" : "4b36beb2-6643-4ad4-b489-d0c7a5596c23",
    "prId" : 28979,
    "prUrl" : "https://github.com/apache/spark/pull/28979#pullrequestreview-444548726",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b79a1350-d821-4992-80a2-65451e35cdf6",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Thanks for adding this test. To check the unsupported case, could you add tests for the toplevel-null case (catch encoder exceptions)? https://github.com/apache/spark/pull/28979#discussion_r450548418\r\n",
        "createdAt" : "2020-07-08T02:56:43Z",
        "updatedAt" : "2020-07-09T13:18:13Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "e65d81c8-93f7-44ef-aea6-9c06e8eeb94d",
        "parentId" : "b79a1350-d821-4992-80a2-65451e35cdf6",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "added in 8314a04",
        "createdAt" : "2020-07-08T09:00:52Z",
        "updatedAt" : "2020-07-09T13:18:13Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "871c35ffd3d71cef6040849561ae07a8d4e6b370",
    "line" : 122,
    "diffHunk" : "@@ -1,1 +588,592 @@      udf((t: Timestamp, i: Instant) => null.asInstanceOf[TimestampInstantType]))\n    checkAnswer(df.selectExpr(\"buildTimestampInstantType(t, i) as ti\"),\n      Row(null))\n  }\n"
  }
]