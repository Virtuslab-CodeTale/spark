[
  {
    "id" : "ef4ab432-7e7c-4206-829b-10bc2625865e",
    "prId" : 32090,
    "prUrl" : "https://github.com/apache/spark/pull/32090#pullrequestreview-631558467",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cfa50fb9-518a-4dc9-99d1-05df67dab73f",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "+1 for moving the test case to this suite.",
        "createdAt" : "2021-04-08T15:45:10Z",
        "updatedAt" : "2021-04-13T02:32:16Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "d182f659d2d0f82a2db7783f1dc2fbc3fcf6781f",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +842,846 @@  }\n\n  test(\"SPARK-34212 Parquet should read decimals correctly\") {\n    def readParquet(schema: String, path: File): DataFrame = {\n      spark.read.schema(schema).parquet(path.toString)"
  },
  {
    "id" : "25487e80-16f8-47f2-8684-971dff4f6cda",
    "prId" : 32090,
    "prUrl" : "https://github.com/apache/spark/pull/32090#pullrequestreview-636248038",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5bb8614f-0215-41bb-bd44-17c285b14ef6",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "@viirya looking at the test, I think it was decided before that reading plain int/long as decimal is hard to implement in vectorized reader.\r\n\r\nBasically we need to do 2 steps:\r\n1. read the decimal from int/long as its actual precision/scale. Since it's a plain int/long, the precision should be max precision for int/long.\r\n2. cast the decimal to the required precision/scale.\r\n\r\nFor vectorized reader, we can create a `Decimal` object with max precision for int/long, do the cast, and set the int/long to the vector if there is no overflow. This is super slow, but is still doable.\r\n\r\nIt's not a real regression, as @wangyum demonstrated before, the previous behavior in 2.4 was not reasonable when overflow happens.",
        "createdAt" : "2021-04-15T03:52:01Z",
        "updatedAt" : "2021-04-15T03:52:02Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "d182f659d2d0f82a2db7783f1dc2fbc3fcf6781f",
    "line" : 47,
    "diffHunk" : "@@ -1,1 +875,879 @@    }\n\n    // tests for parquet types without decimal metadata.\n    withTempPath { path =>\n      val df = sql(s\"SELECT 1 a, 123456 b, ${Int.MaxValue.toLong * 10} c, CAST('1.2' AS BINARY) d\")"
  },
  {
    "id" : "16bc9524-ef6d-48b1-a190-c1870dc2c815",
    "prId" : 24417,
    "prUrl" : "https://github.com/apache/spark/pull/24417#pullrequestreview-228922569",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3021e75b-2683-43bb-bcf6-e32bb2fad97d",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Hi, @MaxGekk .\r\nDo we need to test `TIMESTAMP_MILLIS` together here for completeness because we have three types?\r\n```scala\r\n  object ParquetOutputTimestampType extends Enumeration {\r\n    val INT96, TIMESTAMP_MICROS, TIMESTAMP_MILLIS = Value\r\n  }\r\n```",
        "createdAt" : "2019-04-21T18:17:31Z",
        "updatedAt" : "2019-04-21T18:17:31Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "f0495b8b-b310-49b7-8cc6-70dcc75657cc",
        "parentId" : "3021e75b-2683-43bb-bcf6-e32bb2fad97d",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "@dongjoon-hyun Thank you for looking at this. Purpose of this PR is to check that migration from current logical type for timestamps - `INT96` to `TIMESTAMP_MICROS` is safe ... but we can check `TIMESTAMP_MILLIS` as well though it will require to change the test because `TIMESTAMP_MILLIS` obviously truncates Catalyst's timestamps. ",
        "createdAt" : "2019-04-21T18:38:27Z",
        "updatedAt" : "2019-04-21T18:38:27Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "19fb7f5b764604dd6ca56aa6da71e91c873bad89",
    "line" : 52,
    "diffHunk" : "@@ -1,1 +923,927 @@\n    testMigration(fromTsType = \"INT96\", toTsType = \"TIMESTAMP_MICROS\")\n    testMigration(fromTsType = \"TIMESTAMP_MICROS\", toTsType = \"INT96\")\n  }\n}"
  }
]