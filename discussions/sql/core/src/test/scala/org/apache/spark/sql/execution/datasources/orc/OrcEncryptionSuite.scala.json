[
  {
    "id" : "c909d04d-5605-484e-9db2-53da912bafc8",
    "prId" : 31697,
    "prUrl" : "https://github.com/apache/spark/pull/31697#pullrequestreview-601475489",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "014f3b24-dbaa-4a82-9565-b15ede494402",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Just a question; `old` means v2.6 and earlier?",
        "createdAt" : "2021-03-02T06:28:21Z",
        "updatedAt" : "2021-03-02T06:28:21Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "0a10f040-487b-4d6b-947c-c5e7ddf2d85c",
        "parentId" : "014f3b24-dbaa-4a82-9565-b15ede494402",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Yes~ 2.6 and below here.",
        "createdAt" : "2021-03-02T06:51:26Z",
        "updatedAt" : "2021-03-02T06:51:26Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "27c87a56c55217e992669634577559bab246526f",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +36,40 @@    val provider = HadoopShimsFactory.get.getHadoopKeyProvider(conf, new Random)\n    assume(!provider.getKeyNames.isEmpty,\n      s\"$provider doesn't has the test keys. ORC shim is created with old Hadoop libraries\")\n\n    val df = originalData.toDF(\"ssn\", \"email\", \"name\")"
  },
  {
    "id" : "3abe4b28-1605-44ca-b282-c8502ad425f1",
    "prId" : 31603,
    "prUrl" : "https://github.com/apache/spark/pull/31603#pullrequestreview-594892182",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1758b7c2-638f-4fb2-b189-f8c815d31658",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Out of curiosity, when inserting/reading the table, is it allowed to specify different security options other than the ones in `create table`?",
        "createdAt" : "2021-02-21T18:27:46Z",
        "updatedAt" : "2021-02-21T18:42:33Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "e3074c43-b00e-4757-90a8-d97d02273d99",
        "parentId" : "1758b7c2-638f-4fb2-b189-f8c815d31658",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Yes, it's possible but it should comply with the original ones. Otherwise, it will read encrypted values like line 96.",
        "createdAt" : "2021-02-21T23:04:53Z",
        "updatedAt" : "2021-02-21T23:04:53Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "203c21257d4fc3551ebad4e05bdca561762d933b",
    "line" : 78,
    "diffHunk" : "@@ -1,1 +76,80 @@            |\"\"\".stripMargin)\n        sql(\"INSERT INTO encrypted VALUES('123456789', 'dongjoon@apache.org', 'Dongjoon Hyun')\")\n        checkAnswer(sql(\"SELECT * FROM encrypted\"), df)\n      }\n      withTable(\"normal\") {"
  },
  {
    "id" : "a7d02567-0aab-48f9-921d-232d3c8505c2",
    "prId" : 31065,
    "prUrl" : "https://github.com/apache/spark/pull/31065#pullrequestreview-562699705",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "78a5e0a6-36f6-4876-accc-dd317a07a62a",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "nit: how about just creating a dataframe of `originalData` here instead of creating it in each test (L31 and L54)?",
        "createdAt" : "2021-01-06T13:00:41Z",
        "updatedAt" : "2021-01-06T17:23:36Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "68414ff3-b5bb-4d18-a623-45aae893223f",
        "parentId" : "78a5e0a6-36f6-4876-accc-dd317a07a62a",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "It's not possible here because `SharedSparkSession` initializes `SparkSession` at `beforeAll` method.",
        "createdAt" : "2021-01-06T13:11:44Z",
        "updatedAt" : "2021-01-06T17:23:36Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "551a3a0b-1a1e-4ffb-ad94-986d28f20695",
        "parentId" : "78a5e0a6-36f6-4876-accc-dd317a07a62a",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Oh, I see.",
        "createdAt" : "2021-01-06T13:17:32Z",
        "updatedAt" : "2021-01-06T17:23:36Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "070d3fdff5ee3b3f555a4bb844e5eb6041d6c2d3",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +24,28 @@  import testImplicits._\n\n  val originalData = Seq((\"123456789\", \"dongjoon@apache.org\", \"Dongjoon Hyun\"))\n  val rowDataWithoutKey =\n    Row(null, \"841626795E7D351555B835A002E3BF10669DE9B81C95A3D59E10865AC37EA7C3\", \"Dongjoon Hyun\")"
  }
]