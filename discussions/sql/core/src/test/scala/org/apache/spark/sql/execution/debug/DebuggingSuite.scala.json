[
  {
    "id" : "9a28be9e-7579-4b66-b661-6e729d40e55b",
    "prId" : 25434,
    "prUrl" : "https://github.com/apache/spark/pull/25434#pullrequestreview-275298392",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c6906e1c-cc57-402f-af6d-296b2d19e063",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "We need to always print this id? only for reuse cases?",
        "createdAt" : "2019-08-15T01:49:36Z",
        "updatedAt" : "2019-08-15T01:49:36Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "d855ac2c-84a9-4206-a8d8-630140a11e9b",
        "parentId" : "c6906e1c-cc57-402f-af6d-296b2d19e063",
        "authorId" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "body" : "Then you need to make two passes over the tree. The first one to figure out which exchanges are reused and the second to print the tree. This seems a bit excessive for a debugging tool.",
        "createdAt" : "2019-08-15T07:45:04Z",
        "updatedAt" : "2019-08-15T07:45:04Z",
        "lastEditedBy" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "tags" : [
        ]
      }
    ],
    "commit" : "0ddfeb8d9776a2de446ec239ffd1f36b55f76751",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +64,68 @@    val output = captured.toString()\n    assert(output.replaceAll(\"\\\\[id=#\\\\d+\\\\]\", \"[id=#x]\").contains(\n      \"\"\"== BroadcastExchange HashedRelationBroadcastMode(List(input[0, bigint, false])), [id=#x] ==\n        |Tuples output: 0\n        | id LongType: {}"
  },
  {
    "id" : "882b5e36-e5c7-47e8-8510-1605033e3227",
    "prId" : 25274,
    "prUrl" : "https://github.com/apache/spark/pull/25274#pullrequestreview-270501851",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fb9f828f-77be-4142-bccc-8e34fe727f04",
        "parentId" : null,
        "authorId" : "24e1dd39-ae3f-4bbb-a391-f60afb62d075",
        "body" : "can we split this into 2 different tests?",
        "createdAt" : "2019-08-04T14:59:52Z",
        "updatedAt" : "2019-08-04T16:08:00Z",
        "lastEditedBy" : "24e1dd39-ae3f-4bbb-a391-f60afb62d075",
        "tags" : [
        ]
      }
    ],
    "commit" : "46c6598cf791191fbf5d0fbaeafb31460d4b9319",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +76,80 @@\n  test(\"SPARK-28537: DebugExec cannot debug columnar related queries\") {\n    val df = spark.range(5)\n    df.persist()\n"
  },
  {
    "id" : "8be9a0a6-a822-44ca-8ed9-28fcdb3c7ab2",
    "prId" : 25274,
    "prUrl" : "https://github.com/apache/spark/pull/25274#pullrequestreview-270503873",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e1b7f3b1-c996-4702-bcaa-b1a84f6e7e2d",
        "parentId" : null,
        "authorId" : "24e1dd39-ae3f-4bbb-a391-f60afb62d075",
        "body" : "shall we unpersist this?",
        "createdAt" : "2019-08-04T15:52:01Z",
        "updatedAt" : "2019-08-04T16:08:00Z",
        "lastEditedBy" : "24e1dd39-ae3f-4bbb-a391-f60afb62d075",
        "tags" : [
        ]
      }
    ],
    "commit" : "46c6598cf791191fbf5d0fbaeafb31460d4b9319",
    "line" : 39,
    "diffHunk" : "@@ -1,1 +77,81 @@  test(\"SPARK-28537: DebugExec cannot debug columnar related queries\") {\n    val df = spark.range(5)\n    df.persist()\n\n    val captured = new ByteArrayOutputStream()"
  }
]