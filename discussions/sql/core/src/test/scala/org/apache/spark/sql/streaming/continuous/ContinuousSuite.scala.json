[
  {
    "id" : "4f7d9a06-3ab8-4f90-b5e0-9af966df332a",
    "prId" : 30175,
    "prUrl" : "https://github.com/apache/spark/pull/30175#pullrequestreview-577672893",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f41707f4-1a74-49fa-a6bf-7361e6ef0ff8",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Hmm, shall we add a test case to see if we really throw the error when the number of tasks is less than Kafka number of partitions?",
        "createdAt" : "2021-01-26T21:25:19Z",
        "updatedAt" : "2021-02-25T19:09:00Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "e6738b82-5e9b-4690-b377-a2894deaa325",
        "parentId" : "f41707f4-1a74-49fa-a6bf-7361e6ef0ff8",
        "authorId" : "cf8c9534-0cf3-4aad-8ead-54c363cfa86e",
        "body" : "Added test case",
        "createdAt" : "2021-01-27T19:12:29Z",
        "updatedAt" : "2021-02-25T19:09:00Z",
        "lastEditedBy" : "cf8c9534-0cf3-4aad-8ead-54c363cfa86e",
        "tags" : [
        ]
      }
    ],
    "commit" : "103836b38651169aac701a371bfd0d33b1631be4",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +39,43 @@      \"continuous-stream-test-sql-context\",\n      sparkConf\n    ))\n\n  override protected def sparkConf = {"
  }
]