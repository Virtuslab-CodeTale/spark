[
  {
    "id" : "4f7d9a06-3ab8-4f90-b5e0-9af966df332a",
    "prId" : 30175,
    "prUrl" : "https://github.com/apache/spark/pull/30175#pullrequestreview-577672893",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f41707f4-1a74-49fa-a6bf-7361e6ef0ff8",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Hmm, shall we add a test case to see if we really throw the error when the number of tasks is less than Kafka number of partitions?",
        "createdAt" : "2021-01-26T21:25:19Z",
        "updatedAt" : "2021-02-25T19:09:00Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "e6738b82-5e9b-4690-b377-a2894deaa325",
        "parentId" : "f41707f4-1a74-49fa-a6bf-7361e6ef0ff8",
        "authorId" : "cf8c9534-0cf3-4aad-8ead-54c363cfa86e",
        "body" : "Added test case",
        "createdAt" : "2021-01-27T19:12:29Z",
        "updatedAt" : "2021-02-25T19:09:00Z",
        "lastEditedBy" : "cf8c9534-0cf3-4aad-8ead-54c363cfa86e",
        "tags" : [
        ]
      }
    ],
    "commit" : "103836b38651169aac701a371bfd0d33b1631be4",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +39,43 @@      \"continuous-stream-test-sql-context\",\n      sparkConf\n    ))\n\n  override protected def sparkConf = {"
  },
  {
    "id" : "36357faf-62ae-4087-9b94-322ffb5eb63b",
    "prId" : 25154,
    "prUrl" : "https://github.com/apache/spark/pull/25154#pullrequestreview-261601805",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2311dad3-bcac-416b-b4a0-6dc6cbba2cfa",
        "parentId" : null,
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "Given the approach of calculating wait time is changed, this can reduce around 150 seconds without breaking test.",
        "createdAt" : "2019-07-14T22:19:11Z",
        "updatedAt" : "2019-07-14T22:20:00Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3b870e70dc1fb3d806c25c41102de1eaff508c3",
    "line" : 80,
    "diffHunk" : "@@ -1,1 +269,273 @@      StartStream(longContinuousTrigger),\n      AwaitEpoch(0),\n      Execute { exec =>\n        waitForRateSourceTriggers(exec.asInstanceOf[ContinuousExecution], 50)\n      },"
  },
  {
    "id" : "c2b26b98-e574-4f4d-bc80-a5639eaebc6f",
    "prId" : 25154,
    "prUrl" : "https://github.com/apache/spark/pull/25154#pullrequestreview-261601841",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "15721e0c-346f-4d48-823f-88eb6e6ee341",
        "parentId" : null,
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "same here: reduced around 150 seconds",
        "createdAt" : "2019-07-14T22:20:19Z",
        "updatedAt" : "2019-07-14T22:20:19Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      }
    ],
    "commit" : "c3b870e70dc1fb3d806c25c41102de1eaff508c3",
    "line" : 92,
    "diffHunk" : "@@ -1,1 +290,294 @@      AwaitEpoch(0),\n      Execute { exec =>\n        waitForRateSourceTriggers(exec.asInstanceOf[ContinuousExecution], 50)\n      },\n      IncrementEpoch(),"
  }
]