[
  {
    "id" : "41070f44-37df-468d-ac8b-bdcbfe3c4c1f",
    "prId" : 25215,
    "prUrl" : "https://github.com/apache/spark/pull/25215#pullrequestreview-270076949",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4767f8ad-f8d1-4598-a6a2-b8b9fcbf9f71",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "BTW, thanks for changing this into DSL. It was rather a nit that needs some efforts.",
        "createdAt" : "2019-08-02T09:29:35Z",
        "updatedAt" : "2019-08-02T09:29:35Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "24c674408708cfa961055102f5483af0c78e0e43",
    "line" : 39,
    "diffHunk" : "@@ -1,1 +37,41 @@\n  test(\"SPARK-28445: PythonUDF as grouping key and aggregate expressions\") {\n    val df1 = base.groupBy(scalaTestUDF(base(\"a\") + 1))\n      .agg(scalaTestUDF(base(\"a\") + 1), scalaTestUDF(count(base(\"b\"))))\n    val df2 = base.groupBy(pythonTestUDF(base(\"a\") + 1))"
  }
]