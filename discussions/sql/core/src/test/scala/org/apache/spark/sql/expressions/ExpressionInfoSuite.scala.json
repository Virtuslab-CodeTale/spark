[
  {
    "id" : "ef5b25b3-9f87-4584-b9be-7f3fa9548af0",
    "prId" : 30867,
    "prUrl" : "https://github.com/apache/spark/pull/30867#pullrequestreview-556090362",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e8c38dea-cb71-4f6e-a56b-f455d6ecaba0",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Thanks for enforcing this.",
        "createdAt" : "2020-12-21T01:51:16Z",
        "updatedAt" : "2020-12-21T07:20:26Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "4e82580cdc1b44a1680631ad54121e327f37b9e0",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +126,130 @@          assert(info.getExamples.endsWith(\"\\n  \"))\n          assert(info.getSince.matches(\"[0-9]+\\\\.[0-9]+\\\\.[0-9]+\"))\n          assert(info.getGroup.nonEmpty)\n\n          if (info.getArguments.nonEmpty) {"
  },
  {
    "id" : "0f169e33-88b2-40df-8745-5e5c2ff58f91",
    "prId" : 30400,
    "prUrl" : "https://github.com/apache/spark/pull/30400#pullrequestreview-535666051",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1f52d70e-efe1-4230-a4ad-1243982c4f57",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Shall we add this after `CurrentTimestamp` like the following?\r\n```scala\r\n\"org.apache.spark.sql.catalyst.expressions.CurrentTimestamp\",\r\n\"org.apache.spark.sql.catalyst.expressions.CurrentTimeZone\",\r\n\"org.apache.spark.sql.catalyst.expressions.Now\",\r\n```",
        "createdAt" : "2020-11-20T18:08:40Z",
        "updatedAt" : "2020-11-22T06:16:55Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "c83da46530ad1d4c5527a05e94c7fbad3eafba84",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +150,154 @@      \"org.apache.spark.sql.catalyst.expressions.CurrentDate\",\n      \"org.apache.spark.sql.catalyst.expressions.CurrentTimestamp\",\n      \"org.apache.spark.sql.catalyst.expressions.CurrentTimeZone\",\n      \"org.apache.spark.sql.catalyst.expressions.Now\",\n      // Random output without a seed"
  },
  {
    "id" : "ba0bb40a-67c5-4843-9fd1-6dfeb59547a3",
    "prId" : 29743,
    "prUrl" : "https://github.com/apache/spark/pull/29743#pullrequestreview-488436355",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9472e124-7596-40f9-899d-d7b8539f712b",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Looks these checks have already been done in the `ExpressionInfo` constructor?",
        "createdAt" : "2020-09-15T00:13:56Z",
        "updatedAt" : "2020-09-19T19:00:31Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "ed3bb42f-7185-438c-bb23-4fb14741012f",
        "parentId" : "9472e124-7596-40f9-899d-d7b8539f712b",
        "authorId" : "a8e23d47-3ae4-4385-848c-38a216d1bd08",
        "body" : "These ones are a bit more strict. \r\nFor example this extra space made the Example for `typeof` not appear in http://spark.apache.org/docs/latest/api/sql/#typeof\r\n\r\nhttps://github.com/apache/spark/pull/29743/files#diff-25282ab1377a3d87999d1d0d7a8ec270R208-R214\r\n\r\nI didn't want to add these checks to the constructor, because I'm afraid that they might break some UDFs and also I have no way to exclude some from the checks.",
        "createdAt" : "2020-09-15T03:11:54Z",
        "updatedAt" : "2020-09-19T19:00:31Z",
        "lastEditedBy" : "a8e23d47-3ae4-4385-848c-38a216d1bd08",
        "tags" : [
        ]
      },
      {
        "id" : "6c2961c6-6ff2-4eee-824d-b91ab5554481",
        "parentId" : "9472e124-7596-40f9-899d-d7b8539f712b",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "> I didn't want to add these checks to the constructor, because I'm afraid that they might break some UDFs and also I have no way to exclude some from the checks.\r\n\r\nIf we make the checks more strict in the ctor and we find existing expressions throwing exceptions, I think it is okay just to fix them. Any problem there? ",
        "createdAt" : "2020-09-15T07:58:50Z",
        "updatedAt" : "2020-09-19T19:00:31Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "1914b2bf-1fcb-48bc-9a70-ad3c531dcb49",
        "parentId" : "9472e124-7596-40f9-899d-d7b8539f712b",
        "authorId" : "a8e23d47-3ae4-4385-848c-38a216d1bd08",
        "body" : "No, problems with current ones - only some dummy functions in tests.",
        "createdAt" : "2020-09-15T08:16:04Z",
        "updatedAt" : "2020-09-19T19:00:31Z",
        "lastEditedBy" : "a8e23d47-3ae4-4385-848c-38a216d1bd08",
        "tags" : [
        ]
      }
    ],
    "commit" : "4162b41d325da3f9b732d835168a546916b50499",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +121,125 @@          assert(info.getExamples.startsWith(\"\\n    Examples:\\n\"))\n          assert(info.getExamples.endsWith(\"\\n  \"))\n          assert(info.getSince.matches(\"[0-9]+\\\\.[0-9]+\\\\.[0-9]+\"))\n\n          if (info.getArguments.nonEmpty) {"
  },
  {
    "id" : "87623518-07cd-4178-bd3a-0b49d9b7f4d0",
    "prId" : 29646,
    "prUrl" : "https://github.com/apache/spark/pull/29646#pullrequestreview-482460979",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "81acc58a-31a4-4a55-be5a-fc6909ed4fd2",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "@maropu, I think the asserts in the constructor of `ExpressionInfo` would cover what this PR aims. About ensuring to have the `since` for new expressions, I think it's less likely that we miss adding `since` during the review of other PRs just given my experience.",
        "createdAt" : "2020-09-04T08:12:03Z",
        "updatedAt" : "2020-09-04T08:12:04Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "510ab184-b226-4a1e-b79d-3c7c68d54b14",
        "parentId" : "81acc58a-31a4-4a55-be5a-fc6909ed4fd2",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "okay, I will close this. Thanks for the check, @HyukjinKwon ",
        "createdAt" : "2020-09-04T08:28:50Z",
        "updatedAt" : "2020-09-04T08:28:50Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "21496cc98118d5377d776fa5058fc4a02f137c58",
    "line" : 79,
    "diffHunk" : "@@ -1,1 +267,271 @@      .map(spark.sessionState.catalog.lookupFunctionInfo)\n      .filterNot(e => ignoreSet.contains(e.getClassName))\n      .filter(funcInfo => !funcInfo.getSince.matches(\"[0-9]+\\\\.[0-9]+\\\\.[0-9]+\"))\n      .map(_.getClassName)\n      .distinct"
  }
]