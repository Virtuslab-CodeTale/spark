[
  {
    "id" : "456b1839-887f-4bb1-86b2-b0851ba4bed4",
    "prId" : 28477,
    "prUrl" : "https://github.com/apache/spark/pull/28477#pullrequestreview-407738091",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "15a55e28-b033-4b30-b860-7f9601a2515c",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "mode has String type, so, no need to call toString()",
        "createdAt" : "2020-05-07T20:00:11Z",
        "updatedAt" : "2020-05-12T14:35:21Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "eb61edb3058653d40ac35e3e92d4314e7011cc01",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +166,170 @@                    withSQLConf(\n                      SQLConf.PARQUET_OUTPUT_TIMESTAMP_TYPE.key -> getOutputType(dateTime),\n                      SQLConf.LEGACY_PARQUET_REBASE_MODE_IN_WRITE.key -> mode.toString) {\n                      genDF(rowsNum, dateTime, modernDates)\n                        .write"
  },
  {
    "id" : "b1c2888a-a2f5-45de-b708-5a52a0b98542",
    "prId" : 28057,
    "prUrl" : "https://github.com/apache/spark/pull/28057#pullrequestreview-383535067",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "35cbd19d-d092-4648-b050-4fde9c308130",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "do you include the dataframe generation in the benchmark number? I think it should be excluded.",
        "createdAt" : "2020-03-30T03:35:44Z",
        "updatedAt" : "2020-03-30T06:13:03Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "e69191ec-7e53-460b-b688-dfcfda4e50c5",
        "parentId" : "35cbd19d-d092-4648-b050-4fde9c308130",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "We have already discussed this in PRs for another benchmarks. The overhead of preparing input dataframe is assumed to be subtracted from other numbers.",
        "createdAt" : "2020-03-30T05:04:27Z",
        "updatedAt" : "2020-03-30T06:13:03Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "e1fd4cfb-0811-472c-8187-cb751779ab29",
        "parentId" : "35cbd19d-d092-4648-b050-4fde9c308130",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "For example:\r\n```\r\nafter 1582, noop                                   9272           9272           0         10.8          92.7       1.0X\r\n```\r\n```\r\nafter 1582, rebase off                            21841          21841           0          4.6         218.4       0.4X\r\n```\r\nThe `noop` benchmark shows non-avoidable overhead. If we subtract it, we get 21841 - 9272 = 12569. So, overhead of preparing input data is roughly 45%. I do believe this is important info, and we should keep in the benchmark results.",
        "createdAt" : "2020-03-30T05:14:27Z",
        "updatedAt" : "2020-03-30T06:13:03Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "e0aedf5dbf363477ca88b6c6a7fb0038bafe8261",
    "line" : 101,
    "diffHunk" : "@@ -1,1 +99,103 @@          val benchmark = new Benchmark(s\"Save ${dateTime}s to parquet\", rowsNum, output = output)\n          benchmark.addCase(\"after 1582, noop\", 1) { _ =>\n            genDF(rowsNum, dateTime, after1582 = true).noop()\n          }\n          benchmark.addCase(\"before 1582, noop\", 1) { _ =>"
  }
]