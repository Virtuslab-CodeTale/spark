[
  {
    "id" : "c0f769bf-f958-4db2-b224-50bdc9182f9e",
    "prId" : 29608,
    "prUrl" : "https://github.com/apache/spark/pull/29608#pullrequestreview-481667263",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c26a3d9d-3eae-4103-9e41-a998b0e192aa",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "I think should put  these assert on line 163",
        "createdAt" : "2020-09-03T06:14:52Z",
        "updatedAt" : "2020-09-03T09:34:36Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      },
      {
        "id" : "7ff22075-6beb-48f0-af21-de405b33751b",
        "parentId" : "c26a3d9d-3eae-4103-9e41-a998b0e192aa",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "~`numberOfQueries == outputSize`~\r\nAh, I got it. But if a new function here, `expectedOutputs.size` must not equal to `numberOfQueries`.\r\n`expectedOutputs.size == outputSize` in fact.",
        "createdAt" : "2020-09-03T06:17:51Z",
        "updatedAt" : "2020-09-03T09:34:36Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      },
      {
        "id" : "fe587770-e17e-4f2c-a506-9d28427468ad",
        "parentId" : "c26a3d9d-3eae-4103-9e41-a998b0e192aa",
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "@beliefer This assert place here to verify the consistency of the file contents to avoid inconsistency caused by manual modification, and I think line 189  `assert expectedOutputs.size == outputSize` achieves the same goal as `numberOfQueries == outputSize`. Is this acceptable?\r\n",
        "createdAt" : "2020-09-03T07:04:38Z",
        "updatedAt" : "2020-09-03T09:34:36Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      },
      {
        "id" : "94c91b0f-b6b3-41e1-a19f-dca267653257",
        "parentId" : "c26a3d9d-3eae-4103-9e41-a998b0e192aa",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "You can try to mock a new function with comments and test this suite.",
        "createdAt" : "2020-09-03T07:54:39Z",
        "updatedAt" : "2020-09-03T09:34:36Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      },
      {
        "id" : "3108da58-71d2-4e63-ae4c-e86e38c6f957",
        "parentId" : "c26a3d9d-3eae-4103-9e41-a998b0e192aa",
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "> You can try to mock a new function with comments and test this suite.\r\n\r\nYou are right,  [Spark-24884](https://github.com/apache/spark/pull/27507) already trigger this problem cause by incomplete manual modification.\r\n\r\nWith the new function add scene, I think the right way is run this case with `SPARK_GENERATE_GOLDEN_FILES = 1` to automatically regenerate the correct `sql-expression-schema.md` becasuse `sql-expression-schema.md` header said `Automatically generated by ExpressionsSchemaSuite`.",
        "createdAt" : "2020-09-03T08:18:28Z",
        "updatedAt" : "2020-09-03T09:34:36Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      },
      {
        "id" : "a835d917-5ddc-4c49-be57-3963cc9cc656",
        "parentId" : "c26a3d9d-3eae-4103-9e41-a998b0e192aa",
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "Therefore, if the file is manually modified instead of automatically generated,  I think the assertion failure caused by incorrect modification should be expected.\r\n\r\nDo we need to tell users clearly with `Try regenerating the result files with sys env  SPARK_GENERATE_GOLDEN_FILES = 1`?",
        "createdAt" : "2020-09-03T08:34:44Z",
        "updatedAt" : "2020-09-03T09:34:36Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      },
      {
        "id" : "e685383c-ce17-4951-85d7-511d2208e2ef",
        "parentId" : "c26a3d9d-3eae-4103-9e41-a998b0e192aa",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "I got it. Thanks! Could you put these assert on line 163, so that it looks clear",
        "createdAt" : "2020-09-03T09:01:50Z",
        "updatedAt" : "2020-09-03T09:34:36Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      },
      {
        "id" : "3ac63f66-94f1-409e-b8bb-cde289e5f194",
        "parentId" : "c26a3d9d-3eae-4103-9e41-a998b0e192aa",
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "Address [6e6489b](https://github.com/apache/spark/pull/29608/commits/6e6489bff1291cf5d409b04b7dd21e56daf88e3c) reorder the assertions.",
        "createdAt" : "2020-09-03T09:35:27Z",
        "updatedAt" : "2020-09-03T09:35:27Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      }
    ],
    "commit" : "6e6489bff1291cf5d409b04b7dd21e56daf88e3c",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +172,176 @@      }\n\n      assert(numberOfQueries == expectedOutputs.size,\n        s\"expected outputs size: ${expectedOutputs.size} not same as numberOfQueries: \" +\n          s\"$numberOfQueries record in result file. Try regenerating the result files.\")"
  },
  {
    "id" : "10f58848-eed3-4b78-9390-39a041efba7c",
    "prId" : 28194,
    "prUrl" : "https://github.com/apache/spark/pull/28194#pullrequestreview-401036467",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e37d9c90-9754-4abc-bec6-3280bee0375d",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "The current implementation sorts them alphabetically by class name. But, when adding a new expression and re-generating the golden file, I think the diff. of the file tends to be larger. To mitigate this issue, could we sort them by   a different item, e.g., `since`? Or, how about removing the column `No`?",
        "createdAt" : "2020-04-20T06:59:02Z",
        "updatedAt" : "2020-04-29T12:44:12Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "bceb8ee5-a82f-495c-8f4c-bb7030fe2737",
        "parentId" : "e37d9c90-9754-4abc-bec6-3280bee0375d",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "I will remove the column `No`.",
        "createdAt" : "2020-04-27T14:57:09Z",
        "updatedAt" : "2020-04-29T12:44:12Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "a4d4de9e472dbd55ffbbc13ae1c8ad615a7e3455",
    "line" : 104,
    "diffHunk" : "@@ -1,1 +102,106 @@    }\n\n    val classFunsMap = funInfos.groupBy(_.getClassName).toSeq.sortBy(_._1)\n    val outputBuffer = new ArrayBuffer[String]\n    val outputs = new ArrayBuffer[QueryOutput]"
  },
  {
    "id" : "ffe91cca-da67-4357-9832-96adf0e8bcbd",
    "prId" : 28194,
    "prUrl" : "https://github.com/apache/spark/pull/28194#pullrequestreview-403173245",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cfbe5fb8-3d21-40b8-bfab-f305af719f5d",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "In `BenchmarkBase.main`, we generate the path by simply doing\r\n```\r\nval file = new File(s\"benchmarks/$resultFileName\")\r\n  if (!file.exists()) {\r\n    file.createNewFile()\r\n   }\r\n```\r\nDoes it work here?",
        "createdAt" : "2020-04-29T09:27:56Z",
        "updatedAt" : "2020-04-29T12:44:12Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "6381079a-1832-4460-b76c-734953630414",
        "parentId" : "cfbe5fb8-3d21-40b8-bfab-f305af719f5d",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "It's work too.",
        "createdAt" : "2020-04-29T11:47:28Z",
        "updatedAt" : "2020-04-29T12:44:12Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      },
      {
        "id" : "16e2879e-5791-41dd-b014-08292f5737f5",
        "parentId" : "cfbe5fb8-3d21-40b8-bfab-f305af719f5d",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "then why we write such complex code here to generate the path?",
        "createdAt" : "2020-04-29T15:03:25Z",
        "updatedAt" : "2020-04-29T15:03:26Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "6a2248e1-d121-4cbe-8645-cb037b73293f",
        "parentId" : "cfbe5fb8-3d21-40b8-bfab-f305af719f5d",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "There need to create the parent dir `sql-functions` first.\r\nI can replace the code below\r\n```\r\n    java.nio.file.Paths.get(sparkHome,\r\n      \"sql\", \"core\", \"src\", \"test\", \"resources\", \"sql-functions\").toFile\r\n```\r\n as\r\n```\r\nval file = new File(s\"$sparkHome/sql/core/src/test/resources/sql-functions\")\r\nif (!file.exists()) {\r\n  file.mkdir()\r\n}\r\n```\r\nBut I am neutral about this change. ",
        "createdAt" : "2020-04-30T03:08:14Z",
        "updatedAt" : "2020-04-30T03:09:04Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "a4d4de9e472dbd55ffbbc13ae1c8ad615a7e3455",
    "line" : 81,
    "diffHunk" : "@@ -1,1 +79,83 @@    }\n\n    java.nio.file.Paths.get(sparkHome,\n      \"sql\", \"core\", \"src\", \"test\", \"resources\", \"sql-functions\").toFile\n  }"
  },
  {
    "id" : "3899bf82-06c4-452f-a46c-9812f937ea04",
    "prId" : 28194,
    "prUrl" : "https://github.com/apache/spark/pull/28194#pullrequestreview-402753461",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a87ca9b6-1f4b-473f-aec3-8afaf9ce4718",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Sometimes we may need to test all the examples, e.g. `StringTrim`. It can have one or two parameters and thus the schema (auto-generated alias name) can be different.\r\n\r\nShall we create one entry for each example?",
        "createdAt" : "2020-04-29T09:34:31Z",
        "updatedAt" : "2020-04-29T12:44:12Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "eb7cbf47-c5b1-4ee3-83ae-d17c3bdcecca",
        "parentId" : "a87ca9b6-1f4b-473f-aec3-8afaf9ce4718",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "The fundamental purpose of this PR is to double check whether the alias of an expression can be displayed correctly in the schema. Although some expressions have multiple examples, only the first one is output here.\r\nhttps://github.com/apache/spark/pull/28194#discussion_r407235388\r\nhttps://github.com/apache/spark/blob/133456d2dc809ea7cd03139556998955074dd288/sql/core/src/test/scala/org/apache/spark/sql/ExpressionsSchemaSuite.scala#L123\r\nAlthough the number of parameters is different, as long as the aliases are the same, there is no need to output one by one.\r\n",
        "createdAt" : "2020-04-29T12:00:22Z",
        "updatedAt" : "2020-04-29T13:45:59Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      },
      {
        "id" : "c5c7e255-f679-44b6-8a0c-b87968fd50c6",
        "parentId" : "a87ca9b6-1f4b-473f-aec3-8afaf9ce4718",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "makes sense",
        "createdAt" : "2020-04-29T14:57:58Z",
        "updatedAt" : "2020-04-29T14:57:59Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "a4d4de9e472dbd55ffbbc13ae1c8ad615a7e3455",
    "line" : 121,
    "diffHunk" : "@@ -1,1 +119,123 @@        }\n\n        // If expression exists 'Examples' segment, the first element is 'Examples'. Because\n        // this test case is only used to print aliases of expressions for double checking.\n        // Therefore, we only need to output the first SQL and its corresponding schema."
  },
  {
    "id" : "8b768dde-9f4f-4f5f-bf54-1b5cbc05f066",
    "prId" : 28194,
    "prUrl" : "https://github.com/apache/spark/pull/28194#pullrequestreview-404033528",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "67fa036b-98d8-4cd7-af06-f449a4ae8625",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "nit: Needs to a space `by ${getClass.getSimpleName}`. We can fix it when updating this file next time.",
        "createdAt" : "2020-05-01T03:33:02Z",
        "updatedAt" : "2020-05-01T03:33:02Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "ee070c83-8243-45bd-b625-8287ec07a3da",
        "parentId" : "67fa036b-98d8-4cd7-af06-f449a4ae8625",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "Let me do it.\r\nhttps://github.com/apache/spark/pull/28164",
        "createdAt" : "2020-05-01T04:58:05Z",
        "updatedAt" : "2020-05-01T05:24:25Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      },
      {
        "id" : "77425c72-1941-425a-be1d-1517c07648b8",
        "parentId" : "67fa036b-98d8-4cd7-af06-f449a4ae8625",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ah, I see. Looks okay.",
        "createdAt" : "2020-05-01T06:04:02Z",
        "updatedAt" : "2020-05-01T06:04:02Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "a4d4de9e472dbd55ffbbc13ae1c8ad615a7e3455",
    "line" : 142,
    "diffHunk" : "@@ -1,1 +140,144 @@      val missingExampleStr = missingExamples.mkString(\",\")\n      val goldenOutput = {\n        s\"<!-- Automatically generated by${getClass.getSimpleName} -->\\n\" +\n        \"## Summary\\n\" +\n        s\"  - Number of queries: ${outputs.size}\\n\" +"
  }
]