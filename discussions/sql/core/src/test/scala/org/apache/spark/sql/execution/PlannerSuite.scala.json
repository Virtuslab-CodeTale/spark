[
  {
    "id" : "0d4edbcb-f7c4-4ad8-9d1b-ebb976b6f526",
    "prId" : 30300,
    "prUrl" : "https://github.com/apache/spark/pull/30300#pullrequestreview-529257217",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1232ea56-e5de-4f42-bc48-30b303038244",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ah, last my nit comment: could you check the query use `RangePartitioning` correctly in this test (I have the same comment for the other tests, too)?",
        "createdAt" : "2020-11-12T13:06:19Z",
        "updatedAt" : "2020-11-16T06:54:00Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "276301bd-c423-4810-8808-93c2c4973ab0",
        "parentId" : "1232ea56-e5de-4f42-bc48-30b303038244",
        "authorId" : "ad4cb313-47b2-4cfa-9c1f-0a3596794a67",
        "body" : "@maropu you mean to add assertions that the partitioning here is RangePartitioning and not something else?",
        "createdAt" : "2020-11-12T14:40:27Z",
        "updatedAt" : "2020-11-16T06:54:00Z",
        "lastEditedBy" : "ad4cb313-47b2-4cfa-9c1f-0a3596794a67",
        "tags" : [
        ]
      },
      {
        "id" : "e30f7fee-c7f4-42b3-9d4c-73aeab19db9a",
        "parentId" : "1232ea56-e5de-4f42-bc48-30b303038244",
        "authorId" : "ad4cb313-47b2-4cfa-9c1f-0a3596794a67",
        "body" : "Added checks to assert partitioning is what we expect.",
        "createdAt" : "2020-11-12T16:21:08Z",
        "updatedAt" : "2020-11-16T06:54:00Z",
        "lastEditedBy" : "ad4cb313-47b2-4cfa-9c1f-0a3596794a67",
        "tags" : [
        ]
      }
    ],
    "commit" : "16e1db202f3522ebe607894b93811bb54bdd9a0c",
    "line" : 70,
    "diffHunk" : "@@ -1,1 +962,966 @@      // if Project normalizes alias in its Range outputPartitioning, then no Exchange should come\n      // in between HashAggregates\n      val planned = df.queryExecution.executedPlan\n      val exchanges = planned.collect { case s: ShuffleExchangeExec => s }\n      assert(exchanges.isEmpty)"
  },
  {
    "id" : "94d84ef7-db4c-4c96-a3d2-59d3a28731ea",
    "prId" : 30300,
    "prUrl" : "https://github.com/apache/spark/pull/30300#pullrequestreview-550129516",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0206e27c-515f-49a3-96e7-e18fa5d4a504",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "not related to this PR: The `ProjectExec` only outputs `t1id` (after column pruning), and it's a bit redundant to return `PartitioningCollection` here, as `t1id` is the only output and other partitionings are just invalid.",
        "createdAt" : "2020-12-09T16:36:10Z",
        "updatedAt" : "2020-12-09T16:36:10Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "1c8a4845-a475-432d-b12c-fc40f8142460",
        "parentId" : "0206e27c-515f-49a3-96e7-e18fa5d4a504",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Oh, it looks interesting. Hi, @prakharjain09, are you interested in the improvement above?",
        "createdAt" : "2020-12-11T13:19:40Z",
        "updatedAt" : "2020-12-11T13:19:40Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "28f229f7-c4d3-4843-85ba-b1b8523b3cf9",
        "parentId" : "0206e27c-515f-49a3-96e7-e18fa5d4a504",
        "authorId" : "ad4cb313-47b2-4cfa-9c1f-0a3596794a67",
        "body" : "@maropu Sure. Basically the idea is to stop propagating partitionings and  sortOrders corresponding to attributes which are not part of outputset?\r\n\r\nWorking on this as part of https://issues.apache.org/jira/browse/SPARK-33758.",
        "createdAt" : "2020-12-11T14:10:50Z",
        "updatedAt" : "2020-12-11T14:10:50Z",
        "lastEditedBy" : "ad4cb313-47b2-4cfa-9c1f-0a3596794a67",
        "tags" : [
        ]
      }
    ],
    "commit" : "16e1db202f3522ebe607894b93811bb54bdd9a0c",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +919,923 @@        assert(projects.exists(_.outputPartitioning match {\n          case PartitioningCollection(Seq(HashPartitioning(Seq(k1: AttributeReference), _),\n            HashPartitioning(Seq(k2: AttributeReference), _))) if k1.name == \"t1id\" =>\n            true\n          case _ => false"
  }
]