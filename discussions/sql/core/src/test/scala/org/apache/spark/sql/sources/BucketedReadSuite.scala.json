[
  {
    "id" : "7e1a61ee-415e-4c65-b754-594a85f0fe66",
    "prId" : 31413,
    "prUrl" : "https://github.com/apache/spark/pull/31413#pullrequestreview-583056002",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d03a072f-58f7-499c-99a4-883e5f81934a",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "The code to check bucket pruning seems duplicated. Can we improve it?",
        "createdAt" : "2021-02-04T05:27:35Z",
        "updatedAt" : "2021-02-05T04:43:15Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "5e3d34ae-3309-49d4-9f93-c257c46817ab",
        "parentId" : "d03a072f-58f7-499c-99a4-883e5f81934a",
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "@cloud-fan - sure, improved to remove several statements.",
        "createdAt" : "2021-02-04T05:52:43Z",
        "updatedAt" : "2021-02-05T04:43:15Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      }
    ],
    "commit" : "03120af6b31af89dbc9fb9aad05045e98d52c699",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +161,165 @@\n          val bucketColumnType = bucketedDataFrame.schema.apply(bucketColumnIndex).dataType\n          val rowsWithInvalidBuckets = fileScan.execute().filter(row => {\n            // Return rows should have been pruned\n            val bucketColumnValue = row.get(bucketColumnIndex, bucketColumnType)"
  },
  {
    "id" : "9fc9ede8-5002-4f55-b0f4-e4ef2b20c960",
    "prId" : 30941,
    "prUrl" : "https://github.com/apache/spark/pull/30941#pullrequestreview-559018317",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e76ec2c6-8419-4bb8-b861-2a711c58081f",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "@Ngone51, seems like we still disable it here though. Can you mention this in PR description?",
        "createdAt" : "2020-12-28T06:11:40Z",
        "updatedAt" : "2020-12-28T06:11:40Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "92d04979-042a-43d5-98bc-0642d2c83cec",
        "parentId" : "e76ec2c6-8419-4bb8-b861-2a711c58081f",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Sure!",
        "createdAt" : "2020-12-28T07:00:24Z",
        "updatedAt" : "2020-12-28T07:00:24Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "d6be7c4b577f5b47b9ad8f965eb46f5e48f4b36b",
    "line" : 43,
    "diffHunk" : "@@ -1,1 +933,937 @@    withSQLConf(\n      SQLConf.COALESCE_BUCKETS_IN_JOIN_ENABLED.key -> \"true\",\n      SQLConf.ADAPTIVE_EXECUTION_ENABLED.key -> \"false\") {\n      // The side with bucketedTableTestSpec1 will be coalesced to have 4 output partitions.\n      // Currently, sort will be introduced for the side that is coalesced."
  },
  {
    "id" : "b06d06b7-b163-4ca4-9d6f-a864ab555558",
    "prId" : 28123,
    "prUrl" : "https://github.com/apache/spark/pull/28123#pullrequestreview-399617707",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d9825ea1-a876-43b6-9bf8-f149316159ae",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "We need to add more exhaustive tests for this optimization by using `COALESCE_BUCKET_IN_JOIN_MAX_NUM_BUCKETS_DIFF `, e.g., boundary config value tests.",
        "createdAt" : "2020-04-14T01:31:02Z",
        "updatedAt" : "2020-06-19T04:52:18Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "5f33ca9f-9577-449e-8e61-d9c5634be7c1",
        "parentId" : "d9825ea1-a876-43b6-9bf8-f149316159ae",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "Still working on this, will update tests in the next iteration.",
        "createdAt" : "2020-04-21T02:37:33Z",
        "updatedAt" : "2020-06-19T04:52:18Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      },
      {
        "id" : "45fcd630-97b8-4299-8d63-d380c2ac8c8b",
        "parentId" : "d9825ea1-a876-43b6-9bf8-f149316159ae",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "Added more tests.",
        "createdAt" : "2020-04-24T03:35:30Z",
        "updatedAt" : "2020-06-19T04:52:18Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "62a04a3e4d94e63b3787533f619e368a7e8d59f6",
    "line" : 55,
    "diffHunk" : "@@ -1,1 +876,880 @@  }\n\n  test(\"bucket coalescing eliminates shuffle\") {\n    withSQLConf(SQLConf.COALESCE_BUCKETS_IN_SORT_MERGE_JOIN_ENABLED.key -> \"true\") {\n      // The side with bucketedTableTestSpec1 will be coalesced to have 4 output partitions."
  }
]