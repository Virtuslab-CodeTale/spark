[
  {
    "id" : "82b9f39f-5751-4598-8626-8b6274b5d02e",
    "prId" : 29564,
    "prUrl" : "https://github.com/apache/spark/pull/29564#pullrequestreview-486649638",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "254eb646-0fb8-4acf-8389-781a0995a8fc",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "If we don't have an end-to-end test, how about a low-level UT? Create two `DataSourceV2ScanExec` instances and check `scan1.sameResult(scan2)`.",
        "createdAt" : "2020-09-11T07:17:46Z",
        "updatedAt" : "2020-09-11T14:57:42Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "b9c002e4-427a-4d66-a890-c09e4496cebd",
        "parentId" : "254eb646-0fb8-4acf-8389-781a0995a8fc",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "@cloud-fan I think this test case creates two `DataSourceV2ScanExec` and do the check. It looks ok to me.",
        "createdAt" : "2020-09-11T09:26:56Z",
        "updatedAt" : "2020-09-11T14:57:42Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "acadafee79d1f3f7c86b182740ad72f4dcfafc5c",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +395,399 @@  }\n\n  test(\"SPARK-32708: same columns with different ExprIds should be equal after canonicalization \") {\n    def getV2ScanExec(query: DataFrame): DataSourceV2ScanExec = {\n      query.queryExecution.executedPlan.collect {"
  },
  {
    "id" : "ed938b42-d0af-45ba-af71-513c61df7c22",
    "prId" : 29430,
    "prUrl" : "https://github.com/apache/spark/pull/29430#pullrequestreview-467903989",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ac1e865c-6aff-4c9a-8f39-4094c9759017",
        "parentId" : null,
        "authorId" : "0ab6d38d-4d3e-4e7f-8e1e-1b00f17b815d",
        "body" : "i think it might also be good to verify that two dataframes with the same filter compare to equal (i.e. we don't break the exchange reuse)",
        "createdAt" : "2020-08-14T20:14:35Z",
        "updatedAt" : "2020-08-14T22:21:26Z",
        "lastEditedBy" : "0ab6d38d-4d3e-4e7f-8e1e-1b00f17b815d",
        "tags" : [
        ]
      },
      {
        "id" : "088140bb-3865-463b-b865-ebe94a6fb94e",
        "parentId" : "ac1e865c-6aff-4c9a-8f39-4094c9759017",
        "authorId" : "d663a779-865e-4d52-8703-bc7c67922ec9",
        "body" : "Done",
        "createdAt" : "2020-08-14T22:22:07Z",
        "updatedAt" : "2020-08-14T22:22:07Z",
        "lastEditedBy" : "d663a779-865e-4d52-8703-bc7c67922ec9",
        "tags" : [
        ]
      }
    ],
    "commit" : "5b1b9b39eb612cbf9ec67efd4e364adafcff66c4",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +384,388 @@        val df = spark.read.format(cls.getName).load()\n        val q1 = df.select('i).filter('i > 6)\n        val q2 = df.select('i).filter('i > 5)\n        val q3 = df.select('i).filter('i > 5)\n        val scan1 = getScanExec(q1)"
  }
]