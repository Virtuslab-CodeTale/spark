[
  {
    "id" : "4953fa47-7a4d-40a0-ac45-75cfb6e54318",
    "prId" : 33651,
    "prUrl" : "https://github.com/apache/spark/pull/33651#pullrequestreview-723950350",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "08c3a499-06c1-430a-8f17-7a4b11ad44ae",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "we can use `spark.range` if you just want to control the number of partitions.",
        "createdAt" : "2021-08-06T03:12:40Z",
        "updatedAt" : "2021-08-06T03:12:41Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "84c8e488-8d5b-4b7a-afba-169d6a3194bf",
        "parentId" : "08c3a499-06c1-430a-8f17-7a4b11ad44ae",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "Actually I don't like use range here since it has output partitionging. If you don't mind I prefer use `parallelize`.",
        "createdAt" : "2021-08-06T03:23:24Z",
        "updatedAt" : "2021-08-06T03:23:24Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "6f28a37f420f781486c3e8c102156e02d9f830d7",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +2019,2023 @@    withTempView(\"v\") {\n      spark.sparkContext.parallelize(\n        (1 to 10).map(i => TestData(i, if (i > 2) \"2\" else i.toString)), 2)\n        .toDF(\"c1\", \"c2\").createOrReplaceTempView(\"v\")\n"
  },
  {
    "id" : "bad39635-9765-450f-9cf8-2f302a9e9bfb",
    "prId" : 33651,
    "prUrl" : "https://github.com/apache/spark/pull/33651#pullrequestreview-723982272",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "58f18fa7-b803-4371-94c2-2e6ac41aac8d",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Hm? What this test wants to tell? Both queries have no top level limit after AQE?",
        "createdAt" : "2021-08-06T04:58:14Z",
        "updatedAt" : "2021-08-06T04:58:33Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "860d797c-6858-4161-9859-9547676cbd52",
        "parentId" : "58f18fa7-b803-4371-94c2-2e6ac41aac8d",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Oh, I see.",
        "createdAt" : "2021-08-06T05:01:14Z",
        "updatedAt" : "2021-08-06T05:01:14Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "6f28a37f420f781486c3e8c102156e02d9f830d7",
    "line" : 48,
    "diffHunk" : "@@ -1,1 +2037,2041 @@          \"\"\".stripMargin)\n        assert(findTopLevelLimit(origin2).size == 1)\n        assert(findTopLevelLimit(adaptive2).isEmpty)\n      }\n    }"
  },
  {
    "id" : "2a1aea24-1646-4e76-b832-afb6ca02940a",
    "prId" : 33429,
    "prUrl" : "https://github.com/apache/spark/pull/33429#pullrequestreview-710298179",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0cab7749-b1e5-4859-96a6-8009262316b0",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "\"num readers\" seems more natural?",
        "createdAt" : "2021-07-20T06:55:53Z",
        "updatedAt" : "2021-07-20T06:55:53Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "4c8cb445-af82-4204-9882-c39413c04eb9",
        "parentId" : "0cab7749-b1e5-4859-96a6-8009262316b0",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "or \"num shuffles with local read\", but it's longer",
        "createdAt" : "2021-07-20T06:56:29Z",
        "updatedAt" : "2021-07-20T06:56:30Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "72409441-b62b-4124-bf77-7b30282aad10",
        "parentId" : "0cab7749-b1e5-4859-96a6-8009262316b0",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "I think it's fine. The number of local shuffle reads that refers the number of (local) `AQEShuffleReadExec`, the number of AQE read plans.",
        "createdAt" : "2021-07-20T08:12:18Z",
        "updatedAt" : "2021-07-20T08:12:18Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "19d6deebc8476849ceb4f547f013954e9857caa6",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +140,144 @@  }\n\n  private def checkNumLocalShuffleReads(\n      plan: SparkPlan, numShufflesWithoutLocalRead: Int = 0): Unit = {\n    val numShuffles = collect(plan) {"
  },
  {
    "id" : "a712c777-12ea-4174-955b-19e3d7b88b67",
    "prId" : 33188,
    "prUrl" : "https://github.com/apache/spark/pull/33188#pullrequestreview-698176151",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "55641ec8-3c50-483c-af7e-40ae07efe6de",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Ideally, when we optimize out the user-specified repartition (with num partitions), we should mark the operator that produces the same output partitioning as \"not optimizable\", so that we don't break the semantic of user-specified repartition.\r\n\r\nHowever, this is super complicated and it doesn't seem to be worthwhile to optimize user-specified repartitions. I'm +1 to just not optimize out user-specified repartition in AQE.",
        "createdAt" : "2021-07-02T13:16:35Z",
        "updatedAt" : "2021-07-02T13:16:35Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "7b668bbd9cef4ca2f0cfa84d2e16870464db4f1b",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +1527,1531 @@        dfRepartitionWithNum.collect()\n        val planWithNum = dfRepartitionWithNum.queryExecution.executedPlan\n        // The top shuffle from repartition is not optimized out.\n        assert(hasRepartitionShuffle(planWithNum))\n        val bhjWithNum = findTopLevelBroadcastHashJoin(planWithNum)"
  },
  {
    "id" : "e4fc330c-4544-4767-afa7-9a4212497626",
    "prId" : 32944,
    "prUrl" : "https://github.com/apache/spark/pull/32944#pullrequestreview-697933547",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4e96a279-2565-41ac-b849-72e8a66a5a53",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "does this custom cost evaluator change the query plan? It seems to be the same with the builtin cost evaluator.",
        "createdAt" : "2021-07-02T03:18:55Z",
        "updatedAt" : "2021-07-02T03:18:55Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "f9e0dc30-0cc1-4da8-b06d-bcdfc21c2909",
        "parentId" : "4e96a279-2565-41ac-b849-72e8a66a5a53",
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "@cloud-fan - this evaluator does not change plan, and to be the same with the builtin evaluator for this query. Do we want to come up a different one here? I think this just validates the custom evaluator works.",
        "createdAt" : "2021-07-02T07:59:03Z",
        "updatedAt" : "2021-07-02T07:59:03Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      },
      {
        "id" : "780bac9c-0321-4cb0-abb0-fe303531d136",
        "parentId" : "4e96a279-2565-41ac-b849-72e8a66a5a53",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "SGTM, let's leave it then",
        "createdAt" : "2021-07-02T08:09:12Z",
        "updatedAt" : "2021-07-02T08:09:24Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "ac5c12186035a47bbe7c0b1891564066db676354",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +1914,1918 @@\n      withSQLConf(SQLConf.ADAPTIVE_CUSTOM_COST_EVALUATOR_CLASS.key ->\n        \"org.apache.spark.sql.execution.adaptive.SimpleShuffleSortCostEvaluator\") {\n        val (plan, adaptivePlan) = runAdaptiveAndVerifyResult(query)\n        val smj = findTopLevelSortMergeJoin(plan)"
  },
  {
    "id" : "e01123cf-67e4-4cd2-a183-851922161d4e",
    "prId" : 32883,
    "prUrl" : "https://github.com/apache/spark/pull/32883#pullrequestreview-696204802",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "02ae8d95-be0a-402d-89f9-12ea6144d914",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can we tune the size a little more, so that coalesce also applies?",
        "createdAt" : "2021-06-30T13:20:26Z",
        "updatedAt" : "2021-06-30T13:20:36Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "f71ccb53-b3ae-4a8d-bbe9-a6026f4ee087",
        "parentId" : "02ae8d95-be0a-402d-89f9-12ea6144d914",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "yea, tune up to 150",
        "createdAt" : "2021-06-30T14:02:29Z",
        "updatedAt" : "2021-06-30T14:02:29Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "8e706ae5f289ce9d4f6a7ca624f1d58516a8a177",
    "line" : 41,
    "diffHunk" : "@@ -1,1 +1849,1853 @@\n        withSQLConf(SQLConf.ADVISORY_PARTITION_SIZE_IN_BYTES.key -> \"150\") {\n          // partition size [0,258,72,72,72]\n          checkPartitionNumber(\"SELECT /*+ REBALANCE(c1) */ * FROM v\", 2, 4)\n          // partition size [72,216,216,144,72]"
  }
]