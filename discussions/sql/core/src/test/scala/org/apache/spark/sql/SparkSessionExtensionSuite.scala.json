[
  {
    "id" : "da06e98b-2eeb-49bc-9947-fdeab66b3ea9",
    "prId" : 32648,
    "prUrl" : "https://github.com/apache/spark/pull/32648#pullrequestreview-666447786",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "268e29cd-c47a-454b-b301-5fe86ea20dfc",
        "parentId" : null,
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "```\r\n/spark/sql/core/src/test/scala/org/apache/spark/sql/SparkSessionExtensionSuite.scala:512:26\r\nweaker access privileges in overriding\r\ndef getChild(x$1: Int): org.apache.spark.sql.vectorized.ColumnVector (defined in class ColumnVector)\r\n  override should be public\r\n  override protected def getChild(ordinal: Int): ColumnVector = wrapped.getChild(ordinal)\r\n\r\n```",
        "createdAt" : "2021-05-24T06:56:34Z",
        "updatedAt" : "2021-05-24T06:56:34Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      }
    ],
    "commit" : "2a867a6277c1c6c4f1a6497973588304f907bede",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +510,514 @@  override def getBinary(rowId: Int): Array[Byte] = wrapped.getBinary(rowId)\n\n  override def getChild(ordinal: Int): ColumnVector = wrapped.getChild(ordinal)\n}\n"
  },
  {
    "id" : "251217ef-7729-4756-b8f6-b3bb3f10cd53",
    "prId" : 29134,
    "prUrl" : "https://github.com/apache/spark/pull/29134#pullrequestreview-450071083",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0233f0aa-7e93-48ee-9b33-fe62c0daa5d9",
        "parentId" : null,
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "might be nice to comment what 11121 equals in terms of the execs - MyBroadcastExchangeExec, etc..",
        "createdAt" : "2020-07-16T17:39:09Z",
        "updatedAt" : "2020-07-16T19:48:54Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      }
    ],
    "commit" : "2fd2c089c91df76d9ab2958e788853e954c9eb8d",
    "line" : 84,
    "diffHunk" : "@@ -1,1 +195,199 @@      // Verify that both pre and post processing of the plan worked.\n      val found = collectPlanSteps(df.queryExecution.executedPlan).sum\n      assert(found == 11121)\n      // Verify that we get back the expected, wrong, result\n      val result = df.collect()"
  }
]