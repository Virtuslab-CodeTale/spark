[
  {
    "id" : "ef4158ba-9c74-4d35-9061-0ac0b3557d9d",
    "prId" : 31131,
    "prUrl" : "https://github.com/apache/spark/pull/31131#pullrequestreview-565662654",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5a52b723-04c8-4b57-b1c7-537c3a382843",
        "parentId" : null,
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "hmm I'm not sure if this check is useful - seems it is unrelated to caching (does `getTableSize` look at cached table for stats?)",
        "createdAt" : "2021-01-11T18:37:07Z",
        "updatedAt" : "2021-01-12T17:21:06Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "377e43cc-c3d6-4937-87bf-712821a86c8c",
        "parentId" : "5a52b723-04c8-4b57-b1c7-537c3a382843",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "> does getTableSize look at cached table for stats\r\n\r\nNo, it doesn't but updating stats uncached table before the PR https://github.com/apache/spark/pull/31112\r\n\r\nActually, I moved the test from Hive specific test suite to the base test suite for v1 catalogs. Here, I made the test portable because table data has different sizes, so, instead of comparing exact numbers, I replaced that by this check (which is independent from table size).",
        "createdAt" : "2021-01-11T19:16:37Z",
        "updatedAt" : "2021-01-12T17:21:06Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "4153ba2b254756fb7d865e8746d48cc2defd1e91",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +62,66 @@        assert(spark.catalog.isCached(t))\n        val onePartSize = getTableSize(t)\n        assert(0 < onePartSize && onePartSize < twoPartSize)\n        checkAnswer(sql(s\"SELECT * FROM $t\"), Seq(Row(1, 1)))\n      }"
  },
  {
    "id" : "70da9409-4453-40b8-9c8c-9ad733b6134e",
    "prId" : 30983,
    "prUrl" : "https://github.com/apache/spark/pull/30983#pullrequestreview-560537536",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1a65fe9c-7a68-441d-83ee-d504e2c38c98",
        "parentId" : null,
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : " nit: it will be good to verify that the table is cached after the file index issue is solved :)",
        "createdAt" : "2020-12-31T17:08:41Z",
        "updatedAt" : "2021-01-03T08:33:20Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      },
      {
        "id" : "8cd3b198-8735-46f2-9da2-5c61f8091403",
        "parentId" : "1a65fe9c-7a68-441d-83ee-d504e2c38c98",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "I expected your suggestion ;-). Actually, when I added the check from previous PR:\r\n```scala\r\nassert(spark.sharedState.cacheManager.lookupCachedData(spark.table(\"t\")).isDefined)\r\n```\r\nit failed for v1 Hive external catalog. It even fails immediately after `sql(\"CACHE TABLE t\")`.\r\n\r\nSince this is an unified test for both In-Memory and Hive catalogs, I decided to skip the check because this fix is mostly about correctness, and `checkAnswer(sql(\"SELECT * FROM t\"), Seq(Row(1, 1)))` checks the correct result.",
        "createdAt" : "2020-12-31T18:30:55Z",
        "updatedAt" : "2021-01-03T08:33:20Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "638925ca-bb7e-4606-ae6f-85905706680e",
        "parentId" : "1a65fe9c-7a68-441d-83ee-d504e2c38c98",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "As an alternative solution, I can move this test from the base test suite to specific suites for v1 In-Memory and Hive catalogs, and add the check for In-Memory catalog.",
        "createdAt" : "2020-12-31T18:34:43Z",
        "updatedAt" : "2021-01-03T08:33:21Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "7e3e1512-9bfe-4009-8e86-b15120f1aa79",
        "parentId" : "1a65fe9c-7a68-441d-83ee-d504e2c38c98",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "For some reasons `lookupCachedData` cannot find the cached hive table by the dataset `spark.table(\"t\")`. I just checked the entire cache - is it empty or not.",
        "createdAt" : "2020-12-31T19:20:35Z",
        "updatedAt" : "2021-01-03T08:33:21Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "021c4ac89b4bfde874bdbaf814e3d7791cb88bc9",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +55,59 @@      sql(\"ALTER TABLE t DROP PARTITION (part=0)\")\n      assert(spark.catalog.isCached(\"t\"))\n      checkAnswer(sql(\"SELECT * FROM t\"), Seq(Row(1, 1)))\n    }\n  }"
  }
]