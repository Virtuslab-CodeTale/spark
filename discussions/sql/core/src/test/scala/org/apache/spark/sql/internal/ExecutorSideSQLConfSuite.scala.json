[
  {
    "id" : "13e58e71-8a71-417a-9889-8d110786f701",
    "prId" : 27516,
    "prUrl" : "https://github.com/apache/spark/pull/27516#pullrequestreview-355772486",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0126967f-9b04-4e03-bcea-92945c3e5475",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "I don't think this is particularly needed. The value here doesn't matter at all. It doesn't test if the given value itself was correct or not. It just tests if the value is set or not. But .. I am okay.",
        "createdAt" : "2020-02-10T09:02:24Z",
        "updatedAt" : "2020-02-10T09:02:25Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "51f7fc8ed925766d07ef6820439833ce3b1f67e4",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +147,151 @@\n        // set local configuration and assert\n        val confValue1 = UUID.randomUUID().toString()\n        createDataframe(confKey, confValue1).createOrReplaceTempView(\"m\")\n        spark.sparkContext.setLocalProperty(confKey, confValue1)"
  },
  {
    "id" : "74e1ebd1-0d74-4649-8786-5f5d65281752",
    "prId" : 27267,
    "prUrl" : "https://github.com/apache/spark/pull/27267#pullrequestreview-346072129",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5accca21-bbdd-4e6c-abb2-074e3725d14d",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "shall we create a method to define this df to save duplicated code?",
        "createdAt" : "2020-01-21T17:05:06Z",
        "updatedAt" : "2020-01-22T19:31:00Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "5cf04018-7a62-495f-ba4a-53790185ae1c",
        "parentId" : "5accca21-bbdd-4e6c-abb2-074e3725d14d",
        "authorId" : "2c1bd8aa-c665-4159-a689-57743063347c",
        "body" : "i have updated the PR with generic method to create df, is it ok now..?",
        "createdAt" : "2020-01-21T17:50:16Z",
        "updatedAt" : "2020-01-22T19:31:00Z",
        "lastEditedBy" : "2c1bd8aa-c665-4159-a689-57743063347c",
        "tags" : [
        ]
      }
    ],
    "commit" : "f1cac4de513dbe698604d6157fc8f663ecf8af72",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +142,146 @@              }\n            }\n        }\n\n        // set local configuration and assert"
  },
  {
    "id" : "79cea32e-bac3-4758-8c2b-aef6f9a9d9e0",
    "prId" : 27267,
    "prUrl" : "https://github.com/apache/spark/pull/27267#pullrequestreview-347268952",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "45d6e54f-b11f-4110-b78b-54d3d0505770",
        "parentId" : null,
        "authorId" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "body" : "IMO it is better to use something unique here to avoid a fluke. How about using `UUID.randomUUID().toString()`?",
        "createdAt" : "2020-01-23T12:33:40Z",
        "updatedAt" : "2020-01-23T12:33:41Z",
        "lastEditedBy" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "tags" : [
        ]
      },
      {
        "id" : "322b28da-c151-4f8c-a77c-77e47f3bb3b2",
        "parentId" : "45d6e54f-b11f-4110-b78b-54d3d0505770",
        "authorId" : "2c1bd8aa-c665-4159-a689-57743063347c",
        "body" : "I am neutral about both approaches. Just wanted to have a fixed input value to get predictable output value from testcase. I can update this and raise followup if you insist",
        "createdAt" : "2020-01-23T12:46:44Z",
        "updatedAt" : "2020-01-23T12:46:44Z",
        "lastEditedBy" : "2c1bd8aa-c665-4159-a689-57743063347c",
        "tags" : [
        ]
      }
    ],
    "commit" : "f1cac4de513dbe698604d6157fc8f663ecf8af72",
    "line" : 35,
    "diffHunk" : "@@ -1,1 +145,149 @@\n        // set local configuration and assert\n        val confValue1 = \"e\"\n        createDataframe(confKey, confValue1).createOrReplaceTempView(\"m\")\n        spark.sparkContext.setLocalProperty(confKey, confValue1)"
  }
]