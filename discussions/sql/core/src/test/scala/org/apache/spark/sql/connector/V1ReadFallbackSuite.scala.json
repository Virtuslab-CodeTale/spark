[
  {
    "id" : "5c319b60-5718-44bf-a83f-b83314c246f8",
    "prId" : 26231,
    "prUrl" : "https://github.com/apache/spark/pull/26231#pullrequestreview-335085078",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c211fa1a-d99b-4a5b-82fa-8ca999ef8f49",
        "parentId" : null,
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "We should have a test case that contains filters that can't be pushed down.",
        "createdAt" : "2019-12-19T19:44:07Z",
        "updatedAt" : "2020-01-16T08:35:54Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "6dc17c56-8ba4-4ab6-8f31-4faac6f9e422",
        "parentId" : "c211fa1a-d99b-4a5b-82fa-8ca999ef8f49",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "it already has: https://github.com/apache/spark/pull/26231/files#diff-e65f6ba43960e865ba29530572696f56R63",
        "createdAt" : "2019-12-20T06:23:23Z",
        "updatedAt" : "2020-01-16T08:35:54Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "a48e7bb31bdab8abcd2b6ba9aa37faa464351f61",
    "line" : 57,
    "diffHunk" : "@@ -1,1 +55,59 @@  }\n\n  test(\"filter push down\") {\n    val df = baseTableScan().filter(\"i > 1 and j < 30\")\n    val v1Scan = df.queryExecution.executedPlan.collect {"
  },
  {
    "id" : "529ed8af-91d8-41f9-be14-c55284928959",
    "prId" : 26231,
    "prUrl" : "https://github.com/apache/spark/pull/26231#pullrequestreview-343747644",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cdffa372-48c2-44e6-8bfa-26987848923c",
        "parentId" : null,
        "authorId" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "body" : "what about `unhandledFilters`?",
        "createdAt" : "2020-01-15T17:02:05Z",
        "updatedAt" : "2020-01-16T08:35:54Z",
        "lastEditedBy" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "tags" : [
        ]
      },
      {
        "id" : "26db871a-000a-484e-a27e-6d9bb32ec94a",
        "parentId" : "cdffa372-48c2-44e6-8bfa-26987848923c",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "The implementation doesn't need to track the unhandled filters.\r\n\r\nImplementation tells Spark the unhandled filters (a.k.a. post-scan filters) at https://github.com/apache/spark/pull/26231/files#diff-e65f6ba43960e865ba29530572696f56R150 , and then only need to track the pushed filters to evaluate them when scanning.",
        "createdAt" : "2020-01-16T08:42:57Z",
        "updatedAt" : "2020-01-16T08:42:58Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "a48e7bb31bdab8abcd2b6ba9aa37faa464351f61",
    "line" : 177,
    "diffHunk" : "@@ -1,1 +175,179 @@    context: SQLContext,\n    requiredSchema: StructType,\n    filters: Array[Filter]) extends BaseRelation with TableScan {\n  override def sqlContext: SQLContext = context\n  override def schema: StructType = requiredSchema"
  }
]