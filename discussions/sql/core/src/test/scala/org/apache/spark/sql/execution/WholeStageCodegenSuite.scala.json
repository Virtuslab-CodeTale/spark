[
  {
    "id" : "dcbee8c1-dcf6-4266-89e2-fa83b2ad4575",
    "prId" : 31931,
    "prUrl" : "https://github.com/apache/spark/pull/31931#pullrequestreview-618048273",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b2da5a0f-117d-4f95-a6dc-0551d83816fb",
        "parentId" : null,
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "how about adding an extra test case for broadcast side being empty?",
        "createdAt" : "2021-03-22T23:00:46Z",
        "updatedAt" : "2021-03-23T01:29:30Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      }
    ],
    "commit" : "8ee75369cb66abf85ecf6f7bde98cbdd3f1287b9",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +220,224 @@    Seq(true, false).foreach { codegenEnabled =>\n      withSQLConf(SQLConf.WHOLESTAGE_CODEGEN_ENABLED.key -> codegenEnabled.toString) {\n        // test left outer join\n        val leftOuterJoinDF = df1.join(df2, $\"k1\" > $\"k2\", \"left_outer\")\n        var hasJoinInCodegen = leftOuterJoinDF.queryExecution.executedPlan.collect {"
  },
  {
    "id" : "074c2e69-322c-45ee-879e-09ea04fe05aa",
    "prId" : 28715,
    "prUrl" : "https://github.com/apache/spark/pull/28715#pullrequestreview-428490919",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c8cde612-2383-43d7-9d64-cdaefad545e2",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "nit: remove blank lines",
        "createdAt" : "2020-06-10T09:27:24Z",
        "updatedAt" : "2021-03-17T23:03:54Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "f03097cd-eb8b-4120-88d8-0de29377161b",
        "parentId" : "c8cde612-2383-43d7-9d64-cdaefad545e2",
        "authorId" : "f3166ab8-4dba-4d22-b10b-31a984dfa2ad",
        "body" : "done",
        "createdAt" : "2020-06-10T23:16:33Z",
        "updatedAt" : "2021-03-17T23:03:54Z",
        "lastEditedBy" : "f3166ab8-4dba-4d22-b10b-31a984dfa2ad",
        "tags" : [
        ]
      }
    ],
    "commit" : "c8b676715b017e6cb5e1960d66d9674379721b2c",
    "line" : 66,
    "diffHunk" : "@@ -1,1 +113,117 @@      Array(Row(\"James\", Seq(\"Java\", \"Scala\"), Map(\"hair\" -> \"black\", \"eye\" -> \"brown\"), \"Java\"),\n        Row(\"James\", Seq(\"Java\", \"Scala\"), Map(\"hair\" -> \"black\", \"eye\" -> \"brown\"), \"Scala\")))\n\n    // Map - explode, selecting all columns\n    expDF = df.select($\"*\", explode($\"properties\"))"
  },
  {
    "id" : "f6ad59cc-7e29-494f-b948-dea46ff6a0d4",
    "prId" : 28715,
    "prUrl" : "https://github.com/apache/spark/pull/28715#pullrequestreview-431685041",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "04523046-66cc-4177-b6d8-0a64fb4d4567",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "nit the single blank is enough?",
        "createdAt" : "2020-06-16T07:18:30Z",
        "updatedAt" : "2021-03-17T23:03:54Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "fdd3a2c8-d1b0-4307-8433-23c52ee910b4",
        "parentId" : "04523046-66cc-4177-b6d8-0a64fb4d4567",
        "authorId" : "f3166ab8-4dba-4d22-b10b-31a984dfa2ad",
        "body" : "done",
        "createdAt" : "2020-06-16T16:28:33Z",
        "updatedAt" : "2021-03-17T23:03:54Z",
        "lastEditedBy" : "f3166ab8-4dba-4d22-b10b-31a984dfa2ad",
        "tags" : [
        ]
      }
    ],
    "commit" : "c8b676715b017e6cb5e1960d66d9674379721b2c",
    "line" : 54,
    "diffHunk" : "@@ -1,1 +101,105 @@    checkAnswer(expDF,\n      Array(Row(\"James\", 0, \"hair\", \"black\"), Row(\"James\", 1, \"eye\", \"brown\")))\n\n    // Array - explode , selecting all columns\n    expDF = df.select($\"*\", explode($\"knownLanguages\"))"
  },
  {
    "id" : "a9be0780-5ecf-4704-a1f6-fd44be3dd53e",
    "prId" : 28715,
    "prUrl" : "https://github.com/apache/spark/pull/28715#pullrequestreview-600459528",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4c544fb9-03bd-467f-a3cc-9496999376f5",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Could you use `testWithWholeStageCodegenOnAndOff` to check if queries work correctly with/without codegen?",
        "createdAt" : "2021-03-01T07:51:30Z",
        "updatedAt" : "2021-03-17T23:03:54Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "c8b676715b017e6cb5e1960d66d9674379721b2c",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +65,69 @@      case _ => !codegenEnabled.toBoolean\n    }.isDefined)\n    checkAnswer(expDF, Array(Row(\"James\", \"Java\", Map(\"hair\" -> \"black\", \"eye\" -> \"brown\")),\n      Row(\"James\", \"Scala\", Map(\"hair\" -> \"black\", \"eye\" -> \"brown\"))))\n"
  },
  {
    "id" : "647dd056-aed4-4165-888a-f8291f636843",
    "prId" : 25710,
    "prUrl" : "https://github.com/apache/spark/pull/25710#pullrequestreview-287400270",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b9070be6-a321-4f62-b35d-04702454ee3f",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "This test must be run under CODEGEN_SPLIT_AGGREGATE_FUNC = false?",
        "createdAt" : "2019-09-12T05:38:21Z",
        "updatedAt" : "2019-09-12T05:38:22Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "a9c432b1-e57c-42fe-bfca-accdf5f41674",
        "parentId" : "b9070be6-a321-4f62-b35d-04702454ee3f",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Yea, we need to. If that flag is true, `HashAggregateExec` throws an exception in this test: https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/execution/aggregate/HashAggregateExec.scala#L327",
        "createdAt" : "2019-09-12T12:45:54Z",
        "updatedAt" : "2019-09-12T12:45:54Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "3314954406203170fe2fff7ebf20a9e038bc689e",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +423,427 @@  test(\"Give up splitting subexpression code if a parameter length goes over the limit\") {\n    withSQLConf(\n        SQLConf.CODEGEN_SPLIT_AGGREGATE_FUNC.key -> \"false\",\n        SQLConf.CODEGEN_METHOD_SPLIT_THRESHOLD.key -> \"1\",\n        \"spark.sql.CodeGenerator.validParamLength\" -> \"0\") {"
  },
  {
    "id" : "c711cffa-9f04-493f-a36e-275b23dfdb2e",
    "prId" : 25131,
    "prUrl" : "https://github.com/apache/spark/pull/25131#pullrequestreview-261392651",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ae5f6af1-a216-4890-8a62-e1670a309d5a",
        "parentId" : null,
        "authorId" : "3a12ce0f-9e73-4cfb-a4b4-b19368cddc2f",
        "body" : "Could we please add a phrase at the end of this line, something like:\r\n> , which would imply a hit in the generated code cache.",
        "createdAt" : "2019-07-12T17:48:07Z",
        "updatedAt" : "2019-07-12T17:48:12Z",
        "lastEditedBy" : "3a12ce0f-9e73-4cfb-a4b4-b19368cddc2f",
        "tags" : [
        ]
      }
    ],
    "commit" : "ba919665cca5e5118cf0eb90e305d7d4ad12e2d6",
    "line" : 68,
    "diffHunk" : "@@ -1,1 +259,263 @@\n    withSQLConf(SQLConf.WHOLESTAGE_CODEGEN_USE_ID_IN_CLASS_NAME.key -> \"true\") {\n      // the same query run twice should produce identical code\n      val ds1 = spark.range(3).select('id + 2)\n      val code1 = genCode(ds1)"
  }
]