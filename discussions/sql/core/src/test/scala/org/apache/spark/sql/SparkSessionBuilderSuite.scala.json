[
  {
    "id" : "12dc24bb-b848-4096-91cc-b450a164bcc1",
    "prId" : 32623,
    "prUrl" : "https://github.com/apache/spark/pull/32623#pullrequestreview-665661729",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6da59d8d-28af-4686-8fd4-a8d2863b6017",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "I noticed that the previous test code fails because it's not cause the expected exception.\r\n`my_dir` is resolved as a local file system.\r\n```\r\nWarehouse path is 'file:/Users/dongjoon/APACHE/spark-merge/sql/core/my_dir'.\r\n```\r\n\r\n```scala\r\n  def qualifyWarehousePath(hadoopConf: Configuration, warehousePath: String): String = {\r\n    val tempPath = new Path(warehousePath)\r\n    val qualified = tempPath.getFileSystem(hadoopConf).makeQualified(tempPath).toString\r\n    logInfo(s\"Warehouse path is '$qualified'.\")\r\n    qualified\r\n  }\r\n```",
        "createdAt" : "2021-05-21T16:28:19Z",
        "updatedAt" : "2021-05-21T16:30:38Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "ce70b6fc-5934-4d6e-8d3a-2a372497d761",
        "parentId" : "6da59d8d-28af-4686-8fd4-a8d2863b6017",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "With the updated test case, I confirmed that the following exception occurs if we don't have @cloud-fan 's previous patch.\r\n```\r\n[info] - SPARK-34558: Create a working SparkSession with a broken FileSystem *** FAILED *** (52 milliseconds)\r\n[info]   org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme \"unknown\"\r\n```",
        "createdAt" : "2021-05-21T16:43:38Z",
        "updatedAt" : "2021-05-21T16:43:38Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "1949fd888afa1fdb394218811a0534788222776b",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +481,485 @@        SparkSession.builder()\n          .master(\"local\")\n          .config(WAREHOUSE_PATH.key, \"unknown:///mydir\")\n          .getOrCreate()\n      session.sql(\"SELECT 1\").collect()"
  },
  {
    "id" : "7c8d7938-da37-49e1-8129-0808fb788c49",
    "prId" : 32622,
    "prUrl" : "https://github.com/apache/spark/pull/32622#pullrequestreview-665626163",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bb4b6772-5f87-4ea6-9142-19e5a49e7ed7",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "SPARK-34558?",
        "createdAt" : "2021-05-21T15:59:16Z",
        "updatedAt" : "2021-05-21T15:59:16Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "8d493816-17c5-4059-8b97-c6d8e70af569",
        "parentId" : "bb4b6772-5f87-4ea6-9142-19e5a49e7ed7",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Sorry for missing this. Let me make a quick follow-up.",
        "createdAt" : "2021-05-21T15:59:52Z",
        "updatedAt" : "2021-05-21T15:59:52Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "072be786c5c058398075381d512e109cfc610a8a",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +474,478 @@  }\n\n  test(\"SPARK-33944: Create a working SparkSession with a broken FileSystem\") {\n    val msg = \"Cannot qualify the warehouse path, leaving it unqualified\"\n    val logAppender = new LogAppender(msg)"
  },
  {
    "id" : "1f9c8d3b-5ed1-44e8-b3a8-88288b2e3903",
    "prId" : 31839,
    "prUrl" : "https://github.com/apache/spark/pull/31839#pullrequestreview-612296869",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "201215f9-a6d5-476d-a5d9-c0c3023282ee",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "unnecessary changes",
        "createdAt" : "2021-03-15T15:01:27Z",
        "updatedAt" : "2021-03-17T14:31:40Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "9e81427eb7ac351d7511c0abec6d189eb7b9fbff",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +36,40 @@ * Test cases for the builder pattern of [[SparkSession]].\n */\nclass SparkSessionBuilderSuite extends SparkFunSuite with BeforeAndAfterEach with Eventually {\n\n  override def afterEach(): Unit = {"
  },
  {
    "id" : "1e52f9b5-7a74-49db-b87e-da8ec0d38060",
    "prId" : 31839,
    "prUrl" : "https://github.com/apache/spark/pull/31839#pullrequestreview-612893868",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7327ce7c-38ac-47af-93d4-46f4f0ff9a4f",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "how long does this test take?",
        "createdAt" : "2021-03-16T06:08:47Z",
        "updatedAt" : "2021-03-17T14:31:40Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "5441764e-6df1-4263-94fe-7ef64ce57ebc",
        "parentId" : "7327ce7c-38ac-47af-93d4-46f4f0ff9a4f",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "3s+ ",
        "createdAt" : "2021-03-16T06:41:14Z",
        "updatedAt" : "2021-03-17T14:31:40Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "9e81427eb7ac351d7511c0abec6d189eb7b9fbff",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +46,50 @@  }\n\n  test(\"SPARK-34087: Fix memory leak of ExecutionListenerBus\") {\n    val spark = SparkSession.builder()\n      .master(\"local\")"
  },
  {
    "id" : "eed02e7e-9013-4703-8a72-8411392477f8",
    "prId" : 31053,
    "prUrl" : "https://github.com/apache/spark/pull/31053#pullrequestreview-568062645",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9e6b468d-d400-4f08-ac5f-a15e1235dd31",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "is it duplicated with checking `assert(countListener(\"ExecutionListenerBus\", context) === 2)`?",
        "createdAt" : "2021-01-14T04:30:55Z",
        "updatedAt" : "2021-01-16T02:57:00Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "d0b28816-6613-4efe-9ce1-b499d29a6c82",
        "parentId" : "9e6b468d-d400-4f08-ac5f-a15e1235dd31",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "No. Here we want to ensure other potential listeners won't leak across SparkSessions.",
        "createdAt" : "2021-01-14T09:39:40Z",
        "updatedAt" : "2021-01-16T02:57:00Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "9c32d1828e9440c1eb38daab1434ce516b6bece3",
    "line" : 44,
    "diffHunk" : "@@ -1,1 +230,234 @@    SparkSession.clearDefaultSession()\n    // Minus 1 because the listener `ExecutionListenerBus` is created per SparkSession\n    assert(postFirstCreation == postSecondCreation - 1)\n    context.stop()\n  }"
  },
  {
    "id" : "2a8026a4-424f-4972-84a6-f4785bffad97",
    "prId" : 28899,
    "prUrl" : "https://github.com/apache/spark/pull/28899#pullrequestreview-435436740",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dda34615-f302-4e00-a87b-94017c228460",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This test relies on other tests to create and stop spark session, which is fragile.\r\n\r\nCan we explicitly create and stop a spark session in this test?",
        "createdAt" : "2020-06-23T04:47:03Z",
        "updatedAt" : "2020-06-23T06:07:29Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "708c9ff27ac0f234fbac0d4d6524adb90c9cf0b3",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +242,246 @@  }\n\n  test(\"SPARK-32062: reset listenerRegistered in SparkSession\") {\n    (1 to 2).foreach { i =>\n      val conf = new SparkConf()"
  },
  {
    "id" : "4c2741d8-3947-44fd-b53b-38e5c5870e2d",
    "prId" : 28899,
    "prUrl" : "https://github.com/apache/spark/pull/28899#pullrequestreview-435467839",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7b50b453-e3a9-43fd-bfc9-92c7020a2f9e",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "does this work? The test doesn't stop the spark context, and AFAIK we don't support having multiple spark context instance at the same time.",
        "createdAt" : "2020-06-23T06:01:33Z",
        "updatedAt" : "2020-06-23T06:07:29Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "afbec935-03fe-491a-b089-f186256f9359",
        "parentId" : "7b50b453-e3a9-43fd-bfc9-92c7020a2f9e",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "missed it.",
        "createdAt" : "2020-06-23T06:09:10Z",
        "updatedAt" : "2020-06-23T06:09:11Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "708c9ff27ac0f234fbac0d4d6524adb90c9cf0b3",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +247,251 @@        .setMaster(\"local\")\n        .setAppName(s\"test-SPARK-32062-$i\")\n      val context = new SparkContext(conf)\n      val beforeListenerSize = context.listenerBus.listeners.size()\n      SparkSession"
  },
  {
    "id" : "fae9baf3-30dc-4f15-8a32-4213829ce30d",
    "prId" : 28868,
    "prUrl" : "https://github.com/apache/spark/pull/28868#pullrequestreview-441646156",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2700acef-d7db-4108-bc33-c76f162a30f0",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "what's the behavior before this PR? is the session still use-able?",
        "createdAt" : "2020-07-02T12:49:01Z",
        "updatedAt" : "2020-07-02T12:49:02Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "f37ee6c7-91df-450c-bde2-5091f675b6f6",
        "parentId" : "2700acef-d7db-4108-bc33-c76f162a30f0",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "Yes, now we only clear default session, active session is still alive.",
        "createdAt" : "2020-07-02T12:50:46Z",
        "updatedAt" : "2020-07-02T12:50:46Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "a3b7d1e3191ac6ea6d396c0ffff49bc4aade76b8",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +275,279 @@    assert(msg.contains(\"Cannot call methods on a stopped SparkContext.\"))\n    val msg2 = intercept[IllegalStateException] {\n      SparkSession.getActiveSession\n    }.getMessage\n    assert(msg2.contains(\"Cannot call methods on a stopped SparkContext.\"))"
  },
  {
    "id" : "6023c7fa-ed18-4287-b94d-eb9db0592b84",
    "prId" : 28339,
    "prUrl" : "https://github.com/apache/spark/pull/28339#pullrequestreview-400359427",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3b110680-cdd5-47ed-8692-39254933f92a",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Now, I understand why you change the conf. This one is the safest test case change in `branch-2.4`.",
        "createdAt" : "2020-04-25T05:17:08Z",
        "updatedAt" : "2020-04-25T05:17:46Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "ce2c6633-713c-4f65-a667-af232013be7d",
        "parentId" : "3b110680-cdd5-47ed-8692-39254933f92a",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Need this one? Dropping this is okay to me though.",
        "createdAt" : "2020-04-25T05:21:57Z",
        "updatedAt" : "2020-04-25T05:22:12Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "959c8a498a5b727246f9518b79817c5fc77ab499",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +158,162 @@    val session = SparkSession.builder()\n      .master(\"local\")\n      .config(GLOBAL_TEMP_DATABASE.key, value = \"globaltempdb-spark-31234\")\n      .config(\"spark.app.name\", \"test-app-SPARK-31234\")\n      .getOrCreate()"
  },
  {
    "id" : "bb4779b7-f25e-41a5-a445-82fa4b561e04",
    "prId" : 28316,
    "prUrl" : "https://github.com/apache/spark/pull/28316#pullrequestreview-399560633",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "379a2c85-4aad-46c2-a801-61bb60aa4156",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "nit: remove this blank",
        "createdAt" : "2020-04-24T00:13:35Z",
        "updatedAt" : "2020-04-24T03:03:24Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "0c6a2708cfbdd417113a4baca2b825e24b9891af",
    "line" : 49,
    "diffHunk" : "@@ -1,1 +205,209 @@      .set(WAREHOUSE_PATH.key, \"SPARK-31532-db\")\n    SparkContext.getOrCreate(conf)\n\n    // propagate static sql configs if no existing session\n    val session = SparkSession"
  },
  {
    "id" : "bc0b99a0-6eab-4a2e-8774-0ee5dd4e291c",
    "prId" : 28316,
    "prUrl" : "https://github.com/apache/spark/pull/28316#pullrequestreview-399605858",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "84f4d82c-2f8b-4e07-a625-3227aba5d96e",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Just in case, could we add tests for the case where we should set static configs at SparkSession (In case that no active/default SparkSession exists)? Or, we already have such a test?",
        "createdAt" : "2020-04-24T00:19:22Z",
        "updatedAt" : "2020-04-24T03:03:24Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "6cb365ee-08a2-4674-8e45-5a9671dfee3c",
        "parentId" : "84f4d82c-2f8b-4e07-a625-3227aba5d96e",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "I add a new test for such a case, that is, if SparkContext instance exists but no SparkSession exists, then the static configs remain changeable before SparkSession is finally created.",
        "createdAt" : "2020-04-24T02:50:50Z",
        "updatedAt" : "2020-04-24T03:03:24Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "0c6a2708cfbdd417113a4baca2b825e24b9891af",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +172,176 @@  test(\"SPARK-31532: should not propagate static sql configs to the existing\" +\n    \" active/default SparkSession\") {\n    val session = SparkSession.builder()\n      .master(\"local\")\n      .config(GLOBAL_TEMP_DATABASE.key, value = \"globalTempDB-SPARK-31532\")"
  },
  {
    "id" : "de7e0e19-db10-423c-8bea-45a649ca2ebd",
    "prId" : 28265,
    "prUrl" : "https://github.com/apache/spark/pull/28265#pullrequestreview-396133562",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "175dcbbf-fb91-4a64-8b6e-b4197e219960",
        "parentId" : null,
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "This difference between Spark 2.4 and Spark 3.0 is caused by https://github.com/apache/spark/pull/24979/",
        "createdAt" : "2020-04-20T04:35:13Z",
        "updatedAt" : "2020-04-20T04:35:14Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      }
    ],
    "commit" : "a63ad80b75777e0d6aaf40f26825612b389518d8",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +164,168 @@\n    assert(session.sessionState.conf.getConfString(\"spark.app.name\") === \"test-app-SPARK-31234\")\n    assert(session.sessionState.conf.getConf(GLOBAL_TEMP_DATABASE) === \"globaltempdb-spark-31234\")\n    session.sql(\"RESET\")\n    assert(session.sessionState.conf.getConfString(\"spark.app.name\") === \"test-app-SPARK-31234\")"
  },
  {
    "id" : "8fbad925-e7ea-4f01-a2d1-31e8eafd796a",
    "prId" : 28262,
    "prUrl" : "https://github.com/apache/spark/pull/28262#pullrequestreview-396050885",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "377971fd-5fd5-4dfd-9f31-2167567502c0",
        "parentId" : null,
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "GLOBAL_TEMP_DATABASE is a typical example. The value is being used at the runtime. See the code https://github.com/apache/spark/blob/4381ad5719cddf557baa57c88a8c8859383d92f3/sql/core/src/main/scala/org/apache/spark/sql/execution/command/views.scala#L154",
        "createdAt" : "2020-04-19T19:00:19Z",
        "updatedAt" : "2020-04-19T19:00:19Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      }
    ],
    "commit" : "96dc679a590b58a9edc231b4401939b8182ed513",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +166,170 @@    session.sql(\"RESET\")\n    assert(session.sessionState.conf.getConfString(\"spark.app.name\") === \"test-app-SPARK-31234\")\n    assert(session.sessionState.conf.getConf(GLOBAL_TEMP_DATABASE) === \"globalTempDB-SPARK-31234\")\n  }\n}"
  }
]