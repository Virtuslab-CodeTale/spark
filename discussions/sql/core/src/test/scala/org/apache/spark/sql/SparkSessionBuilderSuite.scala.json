[
  {
    "id" : "12dc24bb-b848-4096-91cc-b450a164bcc1",
    "prId" : 32623,
    "prUrl" : "https://github.com/apache/spark/pull/32623#pullrequestreview-665661729",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6da59d8d-28af-4686-8fd4-a8d2863b6017",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "I noticed that the previous test code fails because it's not cause the expected exception.\r\n`my_dir` is resolved as a local file system.\r\n```\r\nWarehouse path is 'file:/Users/dongjoon/APACHE/spark-merge/sql/core/my_dir'.\r\n```\r\n\r\n```scala\r\n  def qualifyWarehousePath(hadoopConf: Configuration, warehousePath: String): String = {\r\n    val tempPath = new Path(warehousePath)\r\n    val qualified = tempPath.getFileSystem(hadoopConf).makeQualified(tempPath).toString\r\n    logInfo(s\"Warehouse path is '$qualified'.\")\r\n    qualified\r\n  }\r\n```",
        "createdAt" : "2021-05-21T16:28:19Z",
        "updatedAt" : "2021-05-21T16:30:38Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "ce70b6fc-5934-4d6e-8d3a-2a372497d761",
        "parentId" : "6da59d8d-28af-4686-8fd4-a8d2863b6017",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "With the updated test case, I confirmed that the following exception occurs if we don't have @cloud-fan 's previous patch.\r\n```\r\n[info] - SPARK-34558: Create a working SparkSession with a broken FileSystem *** FAILED *** (52 milliseconds)\r\n[info]   org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme \"unknown\"\r\n```",
        "createdAt" : "2021-05-21T16:43:38Z",
        "updatedAt" : "2021-05-21T16:43:38Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "1949fd888afa1fdb394218811a0534788222776b",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +481,485 @@        SparkSession.builder()\n          .master(\"local\")\n          .config(WAREHOUSE_PATH.key, \"unknown:///mydir\")\n          .getOrCreate()\n      session.sql(\"SELECT 1\").collect()"
  },
  {
    "id" : "7c8d7938-da37-49e1-8129-0808fb788c49",
    "prId" : 32622,
    "prUrl" : "https://github.com/apache/spark/pull/32622#pullrequestreview-665626163",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bb4b6772-5f87-4ea6-9142-19e5a49e7ed7",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "SPARK-34558?",
        "createdAt" : "2021-05-21T15:59:16Z",
        "updatedAt" : "2021-05-21T15:59:16Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "8d493816-17c5-4059-8b97-c6d8e70af569",
        "parentId" : "bb4b6772-5f87-4ea6-9142-19e5a49e7ed7",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Sorry for missing this. Let me make a quick follow-up.",
        "createdAt" : "2021-05-21T15:59:52Z",
        "updatedAt" : "2021-05-21T15:59:52Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "072be786c5c058398075381d512e109cfc610a8a",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +474,478 @@  }\n\n  test(\"SPARK-33944: Create a working SparkSession with a broken FileSystem\") {\n    val msg = \"Cannot qualify the warehouse path, leaving it unqualified\"\n    val logAppender = new LogAppender(msg)"
  },
  {
    "id" : "1f9c8d3b-5ed1-44e8-b3a8-88288b2e3903",
    "prId" : 31839,
    "prUrl" : "https://github.com/apache/spark/pull/31839#pullrequestreview-612296869",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "201215f9-a6d5-476d-a5d9-c0c3023282ee",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "unnecessary changes",
        "createdAt" : "2021-03-15T15:01:27Z",
        "updatedAt" : "2021-03-17T14:31:40Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "9e81427eb7ac351d7511c0abec6d189eb7b9fbff",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +36,40 @@ * Test cases for the builder pattern of [[SparkSession]].\n */\nclass SparkSessionBuilderSuite extends SparkFunSuite with BeforeAndAfterEach with Eventually {\n\n  override def afterEach(): Unit = {"
  },
  {
    "id" : "1e52f9b5-7a74-49db-b87e-da8ec0d38060",
    "prId" : 31839,
    "prUrl" : "https://github.com/apache/spark/pull/31839#pullrequestreview-612893868",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7327ce7c-38ac-47af-93d4-46f4f0ff9a4f",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "how long does this test take?",
        "createdAt" : "2021-03-16T06:08:47Z",
        "updatedAt" : "2021-03-17T14:31:40Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "5441764e-6df1-4263-94fe-7ef64ce57ebc",
        "parentId" : "7327ce7c-38ac-47af-93d4-46f4f0ff9a4f",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "3s+ ",
        "createdAt" : "2021-03-16T06:41:14Z",
        "updatedAt" : "2021-03-17T14:31:40Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "9e81427eb7ac351d7511c0abec6d189eb7b9fbff",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +46,50 @@  }\n\n  test(\"SPARK-34087: Fix memory leak of ExecutionListenerBus\") {\n    val spark = SparkSession.builder()\n      .master(\"local\")"
  }
]