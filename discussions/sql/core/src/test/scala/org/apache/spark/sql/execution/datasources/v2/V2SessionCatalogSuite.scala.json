[
  {
    "id" : "00d98c21-e2e7-4296-9295-2fca58fe8721",
    "prId" : 25363,
    "prUrl" : "https://github.com/apache/spark/pull/25363#pullrequestreview-282270816",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7d06e0df-2733-437e-8cd9-b9dd85af72d4",
        "parentId" : null,
        "authorId" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "body" : "can we add a TODO to go through the public APIs once these are implemented.",
        "createdAt" : "2019-08-26T20:55:45Z",
        "updatedAt" : "2019-08-31T00:20:20Z",
        "lastEditedBy" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "tags" : [
        ]
      },
      {
        "id" : "0af6b91f-d72a-492a-b4ce-0af578c9d40e",
        "parentId" : "7d06e0df-2733-437e-8cd9-b9dd85af72d4",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "Done.",
        "createdAt" : "2019-08-30T22:48:42Z",
        "updatedAt" : "2019-08-31T00:20:20Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      }
    ],
    "commit" : "9659f52c1e925cc9c4b8f70018764a4868b8a82c",
    "line" : 54,
    "diffHunk" : "@@ -1,1 +61,65 @@    // TODO: when there is a public API for v2 catalogs, use that instead\n    val catalog = newCatalog()\n    catalog.createNamespace(Array(\"db\"), emptyProps)\n    catalog.createNamespace(Array(\"db2\"), emptyProps)\n    catalog.createNamespace(Array(\"ns\"), emptyProps)"
  },
  {
    "id" : "fcbfec0a-10c0-4b90-a0bf-7cc5a37e8965",
    "prId" : 25363,
    "prUrl" : "https://github.com/apache/spark/pull/25363#pullrequestreview-282282824",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6d61acb3-7176-45c3-958c-88a6ccb363b0",
        "parentId" : null,
        "authorId" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "body" : "can you also check that the default database location is used? Also change that within the SparkSession as a conf, and see that the database location is used correctly.",
        "createdAt" : "2019-08-26T21:00:49Z",
        "updatedAt" : "2019-08-31T00:20:20Z",
        "lastEditedBy" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "tags" : [
        ]
      },
      {
        "id" : "5661ed2a-5b43-408f-b1f6-8c968b4f557e",
        "parentId" : "6d61acb3-7176-45c3-958c-88a6ccb363b0",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "Added.",
        "createdAt" : "2019-08-31T00:20:20Z",
        "updatedAt" : "2019-08-31T00:20:20Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      }
    ],
    "commit" : "9659f52c1e925cc9c4b8f70018764a4868b8a82c",
    "line" : 170,
    "diffHunk" : "@@ -1,1 +838,842 @@  }\n\n  test(\"createNamespace: basic behavior\") {\n    val catalog = newCatalog()\n    val expectedPath = sqlContext.sessionState.catalog.getDefaultDBPath(testNs(0)).toString"
  },
  {
    "id" : "531af194-95a4-4eb4-9ff3-bf51c2d9c123",
    "prId" : 25363,
    "prUrl" : "https://github.com/apache/spark/pull/25363#pullrequestreview-282282966",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6595d005-ccd9-4c45-8e77-bf54af658d77",
        "parentId" : null,
        "authorId" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "body" : "can you also check failing to change database location?",
        "createdAt" : "2019-08-26T21:01:53Z",
        "updatedAt" : "2019-08-31T00:20:20Z",
        "lastEditedBy" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "tags" : [
        ]
      },
      {
        "id" : "3f4fc424-25d5-499e-8e45-c9aa97b0d983",
        "parentId" : "6595d005-ccd9-4c45-8e77-bf54af658d77",
        "authorId" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "body" : "or not sure if that's supported or not. I think not. But you should be able to update the comment (description)",
        "createdAt" : "2019-08-26T21:02:48Z",
        "updatedAt" : "2019-08-31T00:20:20Z",
        "lastEditedBy" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "tags" : [
        ]
      },
      {
        "id" : "6b787ea5-86c6-4107-8e8b-05a3530944b5",
        "parentId" : "6595d005-ccd9-4c45-8e77-bf54af658d77",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "I added tests that fail to remove reserved properties, location and comment, because the catalog requires values. I also added tests that validate they can be updated by altering the namespace to set those properties.\r\n\r\nThis isn't actually exposed yet because there is no SQL or public API for altering a namespace. But this is how table properties work, so I think it makes sense to match the behavior.",
        "createdAt" : "2019-08-31T00:22:14Z",
        "updatedAt" : "2019-08-31T00:22:14Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      }
    ],
    "commit" : "9659f52c1e925cc9c4b8f70018764a4868b8a82c",
    "line" : 287,
    "diffHunk" : "@@ -1,1 +955,959 @@  }\n\n  test(\"alterNamespace: basic behavior\") {\n    val catalog = newCatalog()\n"
  },
  {
    "id" : "bf0d0445-2a8d-474d-9ea8-ea6ac2bc93fa",
    "prId" : 25363,
    "prUrl" : "https://github.com/apache/spark/pull/25363#pullrequestreview-282706591",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "08f129f4-ea7f-48cb-a7ee-fbd93fd11865",
        "parentId" : null,
        "authorId" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "body" : "cc @cloud-fan is this hive catalog behavior? I thought you can't change the location of a database.",
        "createdAt" : "2019-09-01T04:17:34Z",
        "updatedAt" : "2019-09-01T04:17:34Z",
        "lastEditedBy" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "tags" : [
        ]
      },
      {
        "id" : "afa7d6cd-0f6a-4ce1-abc8-c1bb3f4636be",
        "parentId" : "08f129f4-ea7f-48cb-a7ee-fbd93fd11865",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Hive supports it: https://issues.apache.org/jira/browse/HIVE-8472\r\n\r\nHowever, AFAIK Spark has a problem to support it: https://github.com/apache/spark/pull/25294\r\n\r\n@rdblue can we check if the newly created tables under this namespace can reflect the location change?",
        "createdAt" : "2019-09-02T05:44:36Z",
        "updatedAt" : "2019-09-02T05:44:36Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "bdb5e171-c617-4a51-a396-a5d4b3e9b8d4",
        "parentId" : "08f129f4-ea7f-48cb-a7ee-fbd93fd11865",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "Tables are correctly created using the database's location. We have been using this feature for a long time to put all tables for a database in a separate bucket.",
        "createdAt" : "2019-09-02T21:33:17Z",
        "updatedAt" : "2019-09-02T21:33:17Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      }
    ],
    "commit" : "9659f52c1e925cc9c4b8f70018764a4868b8a82c",
    "line" : 321,
    "diffHunk" : "@@ -1,1 +989,993 @@    assert(initialPath === spark.catalog.getDatabase(testNs(0)).locationUri.toString)\n\n    catalog.alterNamespace(testNs, NamespaceChange.setProperty(\"location\", newPath))\n\n    assert(newPath === spark.catalog.getDatabase(testNs(0)).locationUri.toString)"
  },
  {
    "id" : "4f5fac8d-ea0e-4fc0-8942-151c065bc856",
    "prId" : 25363,
    "prUrl" : "https://github.com/apache/spark/pull/25363#pullrequestreview-283233927",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ffe5c934-3f4a-4ca9-9986-6a8d29d1f20b",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "The session catalog has 2 implementations: in-memory and hive. Shall we follow `ExternalCatalogSuite` and run the tests in both sql/core and sql/hive?",
        "createdAt" : "2019-09-03T02:55:17Z",
        "updatedAt" : "2019-09-03T02:55:17Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "1ea28a72-1a73-4e0f-8dc7-33ed528a293b",
        "parentId" : "ffe5c934-3f4a-4ca9-9986-6a8d29d1f20b",
        "authorId" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "body" : "I'm not sure what you mean. These tests are for the Hive implementation. Applying these to a test v2 session catalog implementation sounds like a different PR to me. Is that what you're suggesting?",
        "createdAt" : "2019-09-03T16:27:27Z",
        "updatedAt" : "2019-09-03T16:27:28Z",
        "lastEditedBy" : "0fc9f1bc-0097-451e-915f-52da69a366f3",
        "tags" : [
        ]
      },
      {
        "id" : "cdefe5e8-b5be-4728-9494-ecf4c4c21648",
        "parentId" : "ffe5c934-3f4a-4ca9-9986-6a8d29d1f20b",
        "authorId" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "body" : "yeah seems like this can be done in a follow up",
        "createdAt" : "2019-09-03T20:12:25Z",
        "updatedAt" : "2019-09-03T20:12:25Z",
        "lastEditedBy" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "tags" : [
        ]
      }
    ],
    "commit" : "9659f52c1e925cc9c4b8f70018764a4868b8a82c",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +35,39 @@import org.apache.spark.sql.util.CaseInsensitiveStringMap\n\nclass V2SessionCatalogBaseSuite extends SparkFunSuite with SharedSparkSession with BeforeAndAfter {\n\n  val emptyProps: util.Map[String, String] = Collections.emptyMap[String, String]"
  }
]