[
  {
    "id" : "82820a6c-0293-44ca-bcd0-5e17d858034f",
    "prId" : 33172,
    "prUrl" : "https://github.com/apache/spark/pull/33172#pullrequestreview-697300023",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3f3bf983-a249-4fc5-8cd0-6807fec72eea",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "now partition coalescing applies here and then we are sorting one single partition, which fails this test. Adding the partition number to skip partition coalescing",
        "createdAt" : "2021-07-01T14:15:07Z",
        "updatedAt" : "2021-07-01T14:15:25Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "51546e87c33064c80f902d4eecff1f640222dfb2",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1814,1818 @@\n    // Distribute and order by.\n    val df4 = data.repartition(5, $\"a\").sortWithinPartitions($\"b\".desc)\n    // Walk each partition and verify that it is sorted descending and does not contain all\n    // the values."
  },
  {
    "id" : "2d0b31fb-2737-4af1-83c8-3ed4cd69d2a5",
    "prId" : 33103,
    "prUrl" : "https://github.com/apache/spark/pull/33103#pullrequestreview-693366749",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ed61eccd-19be-4c08-9a36-0c208dee0c6c",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Can we have a test coverage in `catalyst` module additionally?",
        "createdAt" : "2021-06-26T23:59:50Z",
        "updatedAt" : "2021-06-27T00:00:00Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "b610e17e-6f72-469d-8097-b9a45914e56b",
        "parentId" : "ed61eccd-19be-4c08-9a36-0c208dee0c6c",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Ok, let me add one.",
        "createdAt" : "2021-06-27T00:01:06Z",
        "updatedAt" : "2021-06-27T00:01:06Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "9a082844a1bf9c3eac5f956fbfde1f36b7a65ed3",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +2916,2920 @@  }\n\n  test(\"SPARK-35886: PromotePrecision should be subexpr replaced\") {\n    withTable(\"tbl\") {\n      sql("
  },
  {
    "id" : "9a33c559-886a-4a9b-a1e5-697c8d968668",
    "prId" : 32699,
    "prUrl" : "https://github.com/apache/spark/pull/32699#pullrequestreview-673870495",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "30664bf4-35ac-40dd-95c4-6e132e26feda",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Q: What if a tree has more deeply-nested common exprs? The current logic can work well? e.g., I thought it like this;\r\n```\r\n        // subExpr1 = simpleUDF($\"id\");\r\n        // subExpr2 = functions.length(subExpr1);\r\n        // subExpr3 = functions.xxxx(subExpr2);\r\n        // subExpr4 = ...\r\n```",
        "createdAt" : "2021-06-01T14:26:33Z",
        "updatedAt" : "2021-06-01T14:26:33Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "370c0cf7-6628-4a9a-a1c0-3e27672d6562",
        "parentId" : "30664bf4-35ac-40dd-95c4-6e132e26feda",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Yes, this is actually the cases this logic to deal with. Previous common expression gen-ed codes will put into the map. The code generator looks up into the map when generating code for later common expressions to replace the semantic-equal expression with gen-ed code value.\r\n",
        "createdAt" : "2021-06-01T16:19:19Z",
        "updatedAt" : "2021-06-01T16:19:20Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "60f44f15-128a-4bfe-a6fa-964a76e7b98b",
        "parentId" : "30664bf4-35ac-40dd-95c4-6e132e26feda",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Nice",
        "createdAt" : "2021-06-02T07:27:03Z",
        "updatedAt" : "2021-06-02T07:27:03Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "f1f64f7ba0f6246a21515ffddc2d99efbe2409db",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +2895,2899 @@        // Common exprs:\n        //  1. simpleUDF($\"id\")\n        //  2. functions.length(simpleUDF($\"id\"))\n        // We should only evaluate `simpleUDF($\"id\")` once, i.e.\n        // subExpr1 = simpleUDF($\"id\");"
  },
  {
    "id" : "750ba251-6d08-4a39-90b3-b506d6a7680a",
    "prId" : 32559,
    "prUrl" : "https://github.com/apache/spark/pull/32559#pullrequestreview-663732731",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ba627d44-4834-4ed0-8b22-1360aff0465d",
        "parentId" : null,
        "authorId" : "92aa9573-b64a-4a86-aebf-54c827df3ed0",
        "body" : "I think the fix for https://issues.apache.org/jira/browse/SPARK-35449 will break this, since it's really a \"bug\" that the case value is included in subexpression resolution without an else value. Not a huge deal, I can try to fix in my follow up once this is merged",
        "createdAt" : "2021-05-19T23:16:10Z",
        "updatedAt" : "2021-05-19T23:16:10Z",
        "lastEditedBy" : "92aa9573-b64a-4a86-aebf-54c827df3ed0",
        "tags" : [
        ]
      }
    ],
    "commit" : "9973c1a4d6bbaa089b120e47a8418e99b132704d",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +2870,2874 @@      s\n    })\n    val df1 = spark.range(5).select(when(functions.length(simpleUDF($\"id\")) > 0,\n      functions.length(simpleUDF($\"id\"))))\n    df1.collect()"
  },
  {
    "id" : "637d68d8-c9d8-4565-b975-02ab2b43616c",
    "prId" : 31955,
    "prUrl" : "https://github.com/apache/spark/pull/31955#pullrequestreview-620841563",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6d0fd560-83e3-4bd2-a054-6a499acababe",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Can this issue happens only in codegen paths? Could you add tests for interpreted paths, too?",
        "createdAt" : "2021-03-25T00:29:50Z",
        "updatedAt" : "2021-03-26T10:50:32Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "1b04d5fc-03e7-4d24-aff9-868276cd3982",
        "parentId" : "6d0fd560-83e3-4bd2-a054-6a499acababe",
        "authorId" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "body" : "I don't think there is a codegen path for `ArrayTransform`. It can call `ScalaUDF.eval()` on its interpreted path only (https://github.com/apache/spark/blob/master/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/higherOrderFunctions.scala#L282).",
        "createdAt" : "2021-03-25T08:35:44Z",
        "updatedAt" : "2021-03-26T10:50:32Z",
        "lastEditedBy" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "tags" : [
        ]
      }
    ],
    "commit" : "d00e70596e1b679d2331375629249905e9c75395",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +2763,2767 @@    val df = Seq(Array(\"abc\", \"def\")).toDF(\"array\")\n    val test = df.select(transform(col(\"array\"), s => reverse(s)))\n    checkAnswer(test, Row(Array(\"cba\", \"fed\")) :: Nil)\n\n    val df2 = Seq(Array(Bar2(\"abc\"), Bar2(\"def\"))).toDF(\"array\")"
  },
  {
    "id" : "7112aba4-bf4a-4fd6-b2ab-5c641b893395",
    "prId" : 31854,
    "prUrl" : "https://github.com/apache/spark/pull/31854#pullrequestreview-619340335",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "50a24d04-40a4-4ec7-b4d4-cbacd2879bfc",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I don't think this is intentional. How many tests are broken if we switch to `parseMultipartIdentifier`? We probably should make this behavior change.",
        "createdAt" : "2021-03-22T08:28:02Z",
        "updatedAt" : "2021-03-22T08:28:02Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "1103f284-b42a-4113-a955-47088a804776",
        "parentId" : "50a24d04-40a4-4ec7-b4d4-cbacd2879bfc",
        "authorId" : "3a227965-84e0-47cf-9974-11293764f028",
        "body" : "> ow many tests are broken if we switch to parseMultipartIdentifier\r\n\r\n40+ tests fail.\r\nhttps://github.com/apache/spark/runs/2164624369?check_suite_focus=true\r\n\r\n> I don't think this is intentional\r\n\r\nHmm, according to the comment on `UnresolvedAttribute.quotedString`, it seems to rely on the behavior.\r\nhttps://github.com/apache/spark/blob/master/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/unresolved.scala#L188-L193",
        "createdAt" : "2021-03-24T04:40:52Z",
        "updatedAt" : "2021-03-24T04:41:46Z",
        "lastEditedBy" : "3a227965-84e0-47cf-9974-11293764f028",
        "tags" : [
        ]
      },
      {
        "id" : "250fc2d2-fc05-489c-a183-ddbed75a035c",
        "parentId" : "50a24d04-40a4-4ec7-b4d4-cbacd2879bfc",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "If 40+ tests fail, we definitely shouldn't do it in this PR.\r\n\r\nIt's intentional when we write the code, but I don't think it's intentional to allow end-users to do something like `df3.select($\"*-#&% ?.`a``b.c`\")`.",
        "createdAt" : "2021-03-24T05:32:02Z",
        "updatedAt" : "2021-03-24T05:32:02Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "249f8ccf3c910b58fe3440ace768700b267e623f",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +2761,2765 @@    checkAnswer(df3.select(df3(\"*-#&% ?.`a``b.c`\")), Row(\"col1\"))\n    checkAnswer(df3.select(col(\"*-#&% ?.`a``b.c`\")), Row(\"col1\"))\n    checkAnswer(df3.select($\"*-#&% ?.`a``b.c`\"), Row(\"col1\"))\n  }\n"
  },
  {
    "id" : "b54008a6-4626-4f60-a0da-ec740b07c6f3",
    "prId" : 31254,
    "prUrl" : "https://github.com/apache/spark/pull/31254#pullrequestreview-572488562",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "75d554af-32bd-4139-b453-88619905e41c",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Could you move this test into `DataFrameStatSuite`?",
        "createdAt" : "2021-01-20T04:42:06Z",
        "updatedAt" : "2021-01-20T17:57:30Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "84dc11e4-f6b1-4ab6-9a47-1457b2f90859",
        "parentId" : "75d554af-32bd-4139-b453-88619905e41c",
        "authorId" : "e1bdd418-d9b9-4129-91a0-0865740d24d2",
        "body" : "All the other Dataset#summary related tests are here, so might be best to keep them all in one place.  It is a little tricky to find the tests sometimes, so might be good to address the test organization as part of a larger refactoring.",
        "createdAt" : "2021-01-20T18:00:46Z",
        "updatedAt" : "2021-01-20T18:00:47Z",
        "lastEditedBy" : "e1bdd418-d9b9-4129-91a0-0865740d24d2",
        "tags" : [
        ]
      }
    ],
    "commit" : "bc547a2c949dba8322378a334d8f7221e46e3784",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +831,835 @@    (\"Amy\", 24, 180)).toDF(\"name\", \"age\", \"height\")\n\n  private lazy val person3: DataFrame = Seq(\n    (\"Luis\", 1, 99),\n    (\"Luis\", 16, 99),"
  },
  {
    "id" : "237bb1de-bf4f-4e37-8fed-0d7bdc941427",
    "prId" : 30974,
    "prUrl" : "https://github.com/apache/spark/pull/30974#pullrequestreview-560762287",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a92f60a6-bd13-4a12-90bb-0541846ce9e0",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "nit: could you add tests for the array of structs?",
        "createdAt" : "2021-01-04T02:05:42Z",
        "updatedAt" : "2021-01-19T03:57:19Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "508fb02d-e10f-4df8-bf6d-ab52f3f66603",
        "parentId" : "a92f60a6-bd13-4a12-90bb-0541846ce9e0",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "Added.",
        "createdAt" : "2021-01-04T03:16:50Z",
        "updatedAt" : "2021-01-19T03:57:19Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "1b00b8537cd4c2be4ad7715f4106947c3dc9a53a",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +2620,2624 @@    val df = spark.range(1).selectExpr(\"id as id1\", \"id as id2\")\n    val df1 = df.selectExpr(\"cast(struct(id1, id2).id1 as int)\")\n    assert(df1.schema.head.name == \"CAST(struct(id1, id2).id1 AS INT)\")\n\n    val df2 = df.selectExpr(\"cast(array(struct(id1, id2))[0].id1 as int)\")"
  },
  {
    "id" : "68f1deef-81b0-4d82-a83a-7a91291611e5",
    "prId" : 29771,
    "prUrl" : "https://github.com/apache/spark/pull/29771#pullrequestreview-490903588",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c3f7f277-c087-4eef-ab9e-ae9937851e8e",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Although this end-to-end test is also useful, we had better have a narrow-downed test coverage at `FoldablePropagationSuite` in `catalyst` module, too. Could you add one please? If then, we can easily detect regression in `catalyst` module test instead of running full `sql` tests.",
        "createdAt" : "2020-09-17T18:24:45Z",
        "updatedAt" : "2020-09-17T18:26:49Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "7d0bc6f7-b255-4066-aa2e-9b5e5a009872",
        "parentId" : "c3f7f277-c087-4eef-ab9e-ae9937851e8e",
        "authorId" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "body" : "Ok, I will try to add a test case to `FoldablePropagationSuite` tomorrow.",
        "createdAt" : "2020-09-17T18:46:09Z",
        "updatedAt" : "2020-09-17T18:46:09Z",
        "lastEditedBy" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "tags" : [
        ]
      },
      {
        "id" : "5e46e414-5be2-4edd-b138-3bad3c6e3d08",
        "parentId" : "c3f7f277-c087-4eef-ab9e-ae9937851e8e",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Thanks!",
        "createdAt" : "2020-09-17T19:08:30Z",
        "updatedAt" : "2020-09-17T19:08:30Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "61548c7df0f86a05ab99f273f818c51ba2b745c6",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +2557,2561 @@  }\n\n  test(\"SPARK-32635: Replace references with foldables coming only from the node's children\") {\n    val a = Seq(\"1\").toDF(\"col1\").withColumn(\"col2\", lit(\"1\"))\n    val b = Seq(\"2\").toDF(\"col1\").withColumn(\"col2\", lit(\"2\"))"
  },
  {
    "id" : "90325d86-cbca-42fd-8d8a-9a8ff5411170",
    "prId" : 29495,
    "prUrl" : "https://github.com/apache/spark/pull/29495#pullrequestreview-471998284",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4b615852-458a-4ff5-b705-8aba672b2b71",
        "parentId" : null,
        "authorId" : "3a12ce0f-9e73-4cfb-a4b4-b19368cddc2f",
        "body" : "Question: does this actually trigger codegen? It gets converted to LocalRelation during logical optimization, right?\r\n(If this test fails before reverting Janino and passes after the revert, then I guess it's still valid to have it here, otherwise I'm a bit confused)",
        "createdAt" : "2020-08-20T19:56:56Z",
        "updatedAt" : "2020-08-20T19:56:56Z",
        "lastEditedBy" : "3a12ce0f-9e73-4cfb-a4b4-b19368cddc2f",
        "tags" : [
        ]
      },
      {
        "id" : "344ce29e-c77e-44c1-ae64-e333957b5d14",
        "parentId" : "4b615852-458a-4ff5-b705-8aba672b2b71",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Yea, it does; `ConvertToLocalRelation` disabled in tests: https://github.com/apache/spark/blob/8b119f1663dc65c96f20606ac8405169d8f9d31d/sql/core/src/test/scala/org/apache/spark/sql/test/SharedSparkSession.scala#L70-L74",
        "createdAt" : "2020-08-20T21:25:40Z",
        "updatedAt" : "2020-08-20T21:25:40Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "7814be93-a8c9-4494-b30f-6cd08ee3c400",
        "parentId" : "4b615852-458a-4ff5-b705-8aba672b2b71",
        "authorId" : "3a12ce0f-9e73-4cfb-a4b4-b19368cddc2f",
        "body" : "Cool, thanks for confirming!",
        "createdAt" : "2020-08-20T21:27:39Z",
        "updatedAt" : "2020-08-20T21:27:39Z",
        "lastEditedBy" : "3a12ce0f-9e73-4cfb-a4b4-b19368cddc2f",
        "tags" : [
        ]
      }
    ],
    "commit" : "0e2faf6171bee2cb27a86cea1045e31260d26e38",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +2545,2549 @@  test(\"SPARK-32640: ln(NaN) should return NaN\") {\n    val df = Seq(Double.NaN).toDF(\"d\")\n    checkAnswer(df.selectExpr(\"ln(d)\"), Row(Double.NaN))\n  }\n}"
  },
  {
    "id" : "dcc9cc9e-c0aa-49b1-bd7c-d810e92f26a7",
    "prId" : 29448,
    "prUrl" : "https://github.com/apache/spark/pull/29448#pullrequestreview-468187845",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f2124c51-d8f7-41cf-8583-f4a3010bbdd0",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Can we add a comment to say that we have to fail overflow with non-ansi mode as well, and link the related JIRA tickets?",
        "createdAt" : "2020-08-17T06:15:51Z",
        "updatedAt" : "2020-08-17T06:15:51Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "69278b29c65f34f073efcf7c6e463b66663a20dc",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +202,206 @@        val structDf = largeDecimals.select(\"a\").agg(sum(\"a\"))\n        val e = intercept[SparkException] {\n          structDf.collect\n        }\n        assert(e.getCause.getClass.equals(classOf[ArithmeticException]))"
  }
]