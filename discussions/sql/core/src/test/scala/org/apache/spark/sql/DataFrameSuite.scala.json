[
  {
    "id" : "82820a6c-0293-44ca-bcd0-5e17d858034f",
    "prId" : 33172,
    "prUrl" : "https://github.com/apache/spark/pull/33172#pullrequestreview-697300023",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3f3bf983-a249-4fc5-8cd0-6807fec72eea",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "now partition coalescing applies here and then we are sorting one single partition, which fails this test. Adding the partition number to skip partition coalescing",
        "createdAt" : "2021-07-01T14:15:07Z",
        "updatedAt" : "2021-07-01T14:15:25Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "51546e87c33064c80f902d4eecff1f640222dfb2",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1814,1818 @@\n    // Distribute and order by.\n    val df4 = data.repartition(5, $\"a\").sortWithinPartitions($\"b\".desc)\n    // Walk each partition and verify that it is sorted descending and does not contain all\n    // the values."
  },
  {
    "id" : "2d0b31fb-2737-4af1-83c8-3ed4cd69d2a5",
    "prId" : 33103,
    "prUrl" : "https://github.com/apache/spark/pull/33103#pullrequestreview-693366749",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ed61eccd-19be-4c08-9a36-0c208dee0c6c",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Can we have a test coverage in `catalyst` module additionally?",
        "createdAt" : "2021-06-26T23:59:50Z",
        "updatedAt" : "2021-06-27T00:00:00Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "b610e17e-6f72-469d-8097-b9a45914e56b",
        "parentId" : "ed61eccd-19be-4c08-9a36-0c208dee0c6c",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Ok, let me add one.",
        "createdAt" : "2021-06-27T00:01:06Z",
        "updatedAt" : "2021-06-27T00:01:06Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "9a082844a1bf9c3eac5f956fbfde1f36b7a65ed3",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +2916,2920 @@  }\n\n  test(\"SPARK-35886: PromotePrecision should be subexpr replaced\") {\n    withTable(\"tbl\") {\n      sql("
  },
  {
    "id" : "9a33c559-886a-4a9b-a1e5-697c8d968668",
    "prId" : 32699,
    "prUrl" : "https://github.com/apache/spark/pull/32699#pullrequestreview-673870495",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "30664bf4-35ac-40dd-95c4-6e132e26feda",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Q: What if a tree has more deeply-nested common exprs? The current logic can work well? e.g., I thought it like this;\r\n```\r\n        // subExpr1 = simpleUDF($\"id\");\r\n        // subExpr2 = functions.length(subExpr1);\r\n        // subExpr3 = functions.xxxx(subExpr2);\r\n        // subExpr4 = ...\r\n```",
        "createdAt" : "2021-06-01T14:26:33Z",
        "updatedAt" : "2021-06-01T14:26:33Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "370c0cf7-6628-4a9a-a1c0-3e27672d6562",
        "parentId" : "30664bf4-35ac-40dd-95c4-6e132e26feda",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Yes, this is actually the cases this logic to deal with. Previous common expression gen-ed codes will put into the map. The code generator looks up into the map when generating code for later common expressions to replace the semantic-equal expression with gen-ed code value.\r\n",
        "createdAt" : "2021-06-01T16:19:19Z",
        "updatedAt" : "2021-06-01T16:19:20Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "60f44f15-128a-4bfe-a6fa-964a76e7b98b",
        "parentId" : "30664bf4-35ac-40dd-95c4-6e132e26feda",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Nice",
        "createdAt" : "2021-06-02T07:27:03Z",
        "updatedAt" : "2021-06-02T07:27:03Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "f1f64f7ba0f6246a21515ffddc2d99efbe2409db",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +2895,2899 @@        // Common exprs:\n        //  1. simpleUDF($\"id\")\n        //  2. functions.length(simpleUDF($\"id\"))\n        // We should only evaluate `simpleUDF($\"id\")` once, i.e.\n        // subExpr1 = simpleUDF($\"id\");"
  },
  {
    "id" : "750ba251-6d08-4a39-90b3-b506d6a7680a",
    "prId" : 32559,
    "prUrl" : "https://github.com/apache/spark/pull/32559#pullrequestreview-663732731",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ba627d44-4834-4ed0-8b22-1360aff0465d",
        "parentId" : null,
        "authorId" : "92aa9573-b64a-4a86-aebf-54c827df3ed0",
        "body" : "I think the fix for https://issues.apache.org/jira/browse/SPARK-35449 will break this, since it's really a \"bug\" that the case value is included in subexpression resolution without an else value. Not a huge deal, I can try to fix in my follow up once this is merged",
        "createdAt" : "2021-05-19T23:16:10Z",
        "updatedAt" : "2021-05-19T23:16:10Z",
        "lastEditedBy" : "92aa9573-b64a-4a86-aebf-54c827df3ed0",
        "tags" : [
        ]
      }
    ],
    "commit" : "9973c1a4d6bbaa089b120e47a8418e99b132704d",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +2870,2874 @@      s\n    })\n    val df1 = spark.range(5).select(when(functions.length(simpleUDF($\"id\")) > 0,\n      functions.length(simpleUDF($\"id\"))))\n    df1.collect()"
  }
]