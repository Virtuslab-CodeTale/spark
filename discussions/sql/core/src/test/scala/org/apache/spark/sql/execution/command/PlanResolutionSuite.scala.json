[
  {
    "id" : "eb2e1af0-99fb-41a1-b0f8-a88f1aff585f",
    "prId" : 32067,
    "prUrl" : "https://github.com/apache/spark/pull/32067#pullrequestreview-629470987",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "92340b2f-23e7-4306-97e9-67c920a01807",
        "parentId" : null,
        "authorId" : "9cd657f0-37cd-41bd-908a-f2c996b95a7a",
        "body" : "this is a test for the resolution bug mentioned earlier.",
        "createdAt" : "2021-04-06T22:57:39Z",
        "updatedAt" : "2021-04-07T14:06:10Z",
        "lastEditedBy" : "9cd657f0-37cd-41bd-908a-f2c996b95a7a",
        "tags" : [
        ]
      }
    ],
    "commit" : "65fd370fc1f80212915fae84b36b984400f58336",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +1311,1315 @@        }\n\n        // merge with star should get resolved into specific actions even if there\n        // is no other unresolved expression in the merge\n        parseAndResolve(s\"\"\""
  },
  {
    "id" : "4d31f727-81df-4d6b-b181-cbd092946066",
    "prId" : 30574,
    "prUrl" : "https://github.com/apache/spark/pull/30574#pullrequestreview-543821608",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2318a9b9-ad15-4ed7-964d-4e6b50f67862",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Is this relevant to this Analyzer change?",
        "createdAt" : "2020-12-02T21:11:10Z",
        "updatedAt" : "2020-12-02T21:11:11Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "dff5037c-ae4a-4634-9241-67a08b98d998",
        "parentId" : "2318a9b9-ad15-4ed7-964d-4e6b50f67862",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "yes, otherwise some tests fail because they insert into the table and need to check the table partition columns.",
        "createdAt" : "2020-12-03T10:39:40Z",
        "updatedAt" : "2020-12-03T10:39:40Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "cff33a924e275f06933af763d4d4245359cf8b85",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +52,56 @@    val t = mock(classOf[Table])\n    when(t.schema()).thenReturn(new StructType().add(\"i\", \"int\").add(\"s\", \"string\"))\n    when(t.partitioning()).thenReturn(Array.empty[Transform])\n    t\n  }"
  },
  {
    "id" : "34c4dbdd-1070-475b-b54e-7b5eeaef2a7e",
    "prId" : 30574,
    "prUrl" : "https://github.com/apache/spark/pull/30574#pullrequestreview-543822189",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a4079ab4-03f8-41b0-b6e8-458d76c3beb8",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "ditto. Is this relevant to this Analyzer change?",
        "createdAt" : "2020-12-02T21:11:48Z",
        "updatedAt" : "2020-12-02T21:11:48Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "debe1720-3ba0-4b73-83a4-0b7e066b9268",
        "parentId" : "a4079ab4-03f8-41b0-b6e8-458d76c3beb8",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "yes, otherwise some tests fail because the input query has a different number of columns compared to the table schema.",
        "createdAt" : "2020-12-03T10:40:25Z",
        "updatedAt" : "2020-12-03T10:40:25Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "cff33a924e275f06933af763d4d4245359cf8b85",
    "line" : 64,
    "diffHunk" : "@@ -1,1 +1152,1156 @@      (\"INSERT INTO TABLE tab VALUES (1, 'a')\", false),\n      (\"INSERT INTO TABLE testcat.tab VALUES (1, 'a')\", false),\n      (s\"INSERT INTO TABLE $v2SessionCatalogTable VALUES (1, 'a')\", true),\n      (\"DESC TABLE tab\", false),\n      (\"DESC TABLE testcat.tab\", false),"
  },
  {
    "id" : "2c3a128f-02bb-46b6-befd-54de36fc274c",
    "prId" : 30079,
    "prUrl" : "https://github.com/apache/spark/pull/30079#pullrequestreview-515978837",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0e11fee2-dd0f-4ad1-8c9e-f06f2a7f500d",
        "parentId" : null,
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "We need to use an existing table now that table resolution is happening during analysis.",
        "createdAt" : "2020-10-23T20:06:43Z",
        "updatedAt" : "2020-10-27T21:04:52Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "dfc44923d10fa7cbb5cd6cde4dfcffa19a9e994d",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +631,635 @@\n  test(\"drop table\") {\n    val tableName1 = \"db.v1Table\"\n    val tableIdent1 = TableIdentifier(\"v1Table\", Option(\"db\"))\n    val tableName2 = \"v1Table\""
  },
  {
    "id" : "28fb69c2-30d1-493a-9cd6-f65c8137186e",
    "prId" : 27718,
    "prUrl" : "https://github.com/apache/spark/pull/27718#pullrequestreview-366834690",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "67a701e1-7168-4cfa-a46a-374dd1a30523",
        "parentId" : null,
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "This needs to be updated since the current catalog is a session catalog.",
        "createdAt" : "2020-03-01T04:34:52Z",
        "updatedAt" : "2020-03-03T18:01:27Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "4add7b2424be83cb9dce5320e8d0502ab3d36b40",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +129,133 @@    })\n    when(manager.currentCatalog).thenReturn(v2SessionCatalog)\n    when(manager.currentNamespace).thenReturn(Array(\"default\"))\n    when(manager.v1SessionCatalog).thenReturn(v1SessionCatalog)\n    manager"
  },
  {
    "id" : "d1e11dca-7836-4283-8152-28f4aaf9afd8",
    "prId" : 27265,
    "prUrl" : "https://github.com/apache/spark/pull/27265#pullrequestreview-345124769",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d9d57660-1643-4393-94bd-4fe2a2822528",
        "parentId" : null,
        "authorId" : "9cd657f0-37cd-41bd-908a-f2c996b95a7a",
        "body" : "nit: Should these be in the same order as they are in the actual analyzer? If so, how do we make sure that we dont break this constraint? At the very least this should be commented as it is critical for the tests to run correctly .. isnt it?\r\n\r\nThis is probably not relevant for this PR, but I am curious.... instead of pulling out a few rules from the analyzer, why are we not using the Analyzer directly (with all the rules) to parse and resolve?",
        "createdAt" : "2020-01-17T21:43:00Z",
        "updatedAt" : "2020-01-22T07:14:05Z",
        "lastEditedBy" : "9cd657f0-37cd-41bd-908a-f2c996b95a7a",
        "tags" : [
        ]
      },
      {
        "id" : "3dd806af-4621-4592-9d62-73da3e668c7d",
        "parentId" : "d9d57660-1643-4393-94bd-4fe2a2822528",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I tried to use the analyzer then a lof of tests failed. I've added a TODO to fix it.",
        "createdAt" : "2020-01-20T07:52:49Z",
        "updatedAt" : "2020-01-22T07:14:05Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "952b8b08419a9dafe2a19ab13ea97c292464995c",
    "line" : 41,
    "diffHunk" : "@@ -1,1 +137,141 @@      new ResolveSessionCatalog(catalogManager, conf, _ == Seq(\"v\")),\n      analyzer.ResolveTables,\n      analyzer.ResolveReferences,\n      analyzer.ResolveSubqueryColumnAliases,\n      analyzer.ResolveReferences)"
  },
  {
    "id" : "1c2a5a67-7c52-4609-9f00-e2dab5c0b51d",
    "prId" : 27265,
    "prUrl" : "https://github.com/apache/spark/pull/27265#pullrequestreview-346380884",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2a3ee8ca-d73b-4929-aece-b2f22fb939e8",
        "parentId" : null,
        "authorId" : "9cd657f0-37cd-41bd-908a-f2c996b95a7a",
        "body" : "super nit: I suggest making these tests a bit more robust by not depending on the order of columns. Changes in the resolving of the star can easily change the order of columns and expressions, and will unnecessarily fail the tests.",
        "createdAt" : "2020-01-21T22:27:40Z",
        "updatedAt" : "2020-01-22T07:14:05Z",
        "lastEditedBy" : "9cd657f0-37cd-41bd-908a-f2c996b95a7a",
        "tags" : [
        ]
      },
      {
        "id" : "2d51158f-c7ea-4488-8c4e-1dc9d37499b0",
        "parentId" : "2a3ee8ca-d73b-4929-aece-b2f22fb939e8",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "on the other hand, this test also verifies the column order after resolving the star. Maybe good to keep it?",
        "createdAt" : "2020-01-22T07:12:46Z",
        "updatedAt" : "2020-01-22T07:14:05Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "952b8b08419a9dafe2a19ab13ea97c292464995c",
    "line" : 78,
    "diffHunk" : "@@ -1,1 +1088,1092 @@      if (starInUpdate) {\n        assert(updateAssigns.size == 2)\n        assert(updateAssigns(0).key.asInstanceOf[AttributeReference].sameRef(ti))\n        assert(updateAssigns(0).value.asInstanceOf[AttributeReference].sameRef(si))\n        assert(updateAssigns(1).key.asInstanceOf[AttributeReference].sameRef(ts))"
  },
  {
    "id" : "25234819-dc40-493a-87eb-e5661b5823ff",
    "prId" : 27265,
    "prUrl" : "https://github.com/apache/spark/pull/27265#pullrequestreview-346236141",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3de38042-bab9-47a9-834a-306549e393e2",
        "parentId" : null,
        "authorId" : "9cd657f0-37cd-41bd-908a-f2c996b95a7a",
        "body" : "same comment about column order as above.",
        "createdAt" : "2020-01-21T22:27:52Z",
        "updatedAt" : "2020-01-22T07:14:05Z",
        "lastEditedBy" : "9cd657f0-37cd-41bd-908a-f2c996b95a7a",
        "tags" : [
        ]
      }
    ],
    "commit" : "952b8b08419a9dafe2a19ab13ea97c292464995c",
    "line" : 88,
    "diffHunk" : "@@ -1,1 +1098,1102 @@      }\n      assert(insertAssigns.size == 2)\n      assert(insertAssigns(0).key.asInstanceOf[AttributeReference].sameRef(ti))\n      assert(insertAssigns(0).value.asInstanceOf[AttributeReference].sameRef(si))\n      assert(insertAssigns(1).key.asInstanceOf[AttributeReference].sameRef(ts))"
  },
  {
    "id" : "0792a945-ad05-45cc-aa28-2082984f3b07",
    "prId" : 27265,
    "prUrl" : "https://github.com/apache/spark/pull/27265#pullrequestreview-346240042",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ac0a48a0-cbf1-498e-a0cf-e35b185d4d1b",
        "parentId" : null,
        "authorId" : "9cd657f0-37cd-41bd-908a-f2c996b95a7a",
        "body" : "why cant you still use the `checkResolution` function here. ",
        "createdAt" : "2020-01-21T22:34:18Z",
        "updatedAt" : "2020-01-22T07:14:05Z",
        "lastEditedBy" : "9cd657f0-37cd-41bd-908a-f2c996b95a7a",
        "tags" : [
        ]
      },
      {
        "id" : "831f0f28-3c34-41a9-b1b1-32708ac0815e",
        "parentId" : "ac0a48a0-cbf1-498e-a0cf-e35b185d4d1b",
        "authorId" : "9cd657f0-37cd-41bd-908a-f2c996b95a7a",
        "body" : "nvm. I see the significant differences.",
        "createdAt" : "2020-01-21T22:35:58Z",
        "updatedAt" : "2020-01-22T07:14:05Z",
        "lastEditedBy" : "9cd657f0-37cd-41bd-908a-f2c996b95a7a",
        "tags" : [
        ]
      }
    ],
    "commit" : "952b8b08419a9dafe2a19ab13ea97c292464995c",
    "line" : 415,
    "diffHunk" : "@@ -1,1 +1274,1278 @@          assert(il.sameRef(ss))\n          assert(updateAssigns.size == 1)\n          // UPDATE key is resolved with target table only, so column `s` is not ambiguous.\n          assert(updateAssigns.head.key.asInstanceOf[AttributeReference].sameRef(ts))\n          assert(insertAssigns.size == 1)"
  },
  {
    "id" : "7f1ea73f-be84-4ba3-9f8c-a8fa0ca1bf55",
    "prId" : 26957,
    "prUrl" : "https://github.com/apache/spark/pull/26957#pullrequestreview-348281970",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9211f484-6f11-4f15-af7f-d7a9eb70cfb9",
        "parentId" : null,
        "authorId" : "8fec0990-98ca-4639-aa0d-4d79de603820",
        "body" : "@brkyvz by looking at @cloud-fan's recent change on this, I'm a little uncertain whether we should be passing the table identifier with the DataSourceV2Relation. It feels like the Analyzer should resolve DataSourceV2Relation to ResolvedTable if table information should be included? ",
        "createdAt" : "2020-01-24T08:11:50Z",
        "updatedAt" : "2020-01-24T17:49:38Z",
        "lastEditedBy" : "8fec0990-98ca-4639-aa0d-4d79de603820",
        "tags" : [
        ]
      },
      {
        "id" : "0297b8a3-1c8f-478a-85c3-cadd321d5d1e",
        "parentId" : "9211f484-6f11-4f15-af7f-d7a9eb70cfb9",
        "authorId" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "body" : "That's still under discussion. ResolvedTable is only proposed for DDL commands IIUC",
        "createdAt" : "2020-01-24T16:13:24Z",
        "updatedAt" : "2020-01-24T17:49:38Z",
        "lastEditedBy" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "tags" : [
        ]
      },
      {
        "id" : "4488bbfc-22c9-4ab0-b0ac-cf5171ab1694",
        "parentId" : "9211f484-6f11-4f15-af7f-d7a9eb70cfb9",
        "authorId" : "8fec0990-98ca-4639-aa0d-4d79de603820",
        "body" : "Got it, thanks!",
        "createdAt" : "2020-01-24T23:41:54Z",
        "updatedAt" : "2020-01-24T23:41:55Z",
        "lastEditedBy" : "8fec0990-98ca-4639-aa0d-4d79de603820",
        "tags" : [
        ]
      }
    ],
    "commit" : "df29683d38260cb7f69adfccdc7fab2d315e663e",
    "line" : 71,
    "diffHunk" : "@@ -1,1 +1112,1116 @@          assert(r.catalog.exists(_ == catlogIdent))\n          assert(r.identifier.exists(_.name() == tableIdent))\n        case DescribeRelation(r: ResolvedTable, _, _) =>\n          assert(r.catalog == catlogIdent)\n          assert(r.identifier.name() == tableIdent)"
  },
  {
    "id" : "5b6bb81c-b9ec-4d2b-9121-7fb00e74dbf1",
    "prId" : 26684,
    "prUrl" : "https://github.com/apache/spark/pull/26684#pullrequestreview-323429418",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "31754ce9-8dae-4fa7-aaba-8270b30d182c",
        "parentId" : null,
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "I wasn't quite sure whether this test is only for `ResolveTables`. Any thoughts @cloud-fan?",
        "createdAt" : "2019-11-27T01:36:45Z",
        "updatedAt" : "2019-12-06T05:48:45Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      },
      {
        "id" : "6f9aa7e7-70d3-4648-a5ee-e4e37a229a1a",
        "parentId" : "31754ce9-8dae-4fa7-aaba-8270b30d182c",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "We should just test `ResolveRelations`, which calls `ResolveTables`",
        "createdAt" : "2019-11-27T04:57:41Z",
        "updatedAt" : "2019-12-06T05:48:45Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "23cc9d3894fe39f989ea7511433213dc44a60e5c",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +142,146 @@      new ResolveCatalogs(catalogManager),\n      new ResolveSessionCatalog(catalogManager, conf, _ == Seq(\"v\")),\n      analyzer.ResolveTables,\n      analyzer.ResolveRelations)\n    rules.foldLeft(parsePlan(query)) {"
  },
  {
    "id" : "efc3d9fd-9eb8-49f7-b40e-d178430f72ba",
    "prId" : 25747,
    "prUrl" : "https://github.com/apache/spark/pull/25747#pullrequestreview-289673422",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2e5471bd-79fe-4222-872e-5401b73132d3",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "improve the test coverage of this test suite, to covert all the cases:\r\n1. statement is converted to v1 command.\r\n2. statement is converted to v2 command.\r\n3. statement is left unchanged because table not found.",
        "createdAt" : "2019-09-18T05:16:56Z",
        "updatedAt" : "2019-10-04T02:49:47Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "9ad516ea9a0ec7525308c9ca64d36d4069531ae0",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +38,42 @@import org.apache.spark.sql.types.{DoubleType, IntegerType, LongType, StringType, StructType}\n\nclass PlanResolutionSuite extends AnalysisTest {\n  import CatalystSqlParser._\n"
  },
  {
    "id" : "0535a185-a3d4-473d-8151-39844937d290",
    "prId" : 25747,
    "prUrl" : "https://github.com/apache/spark/pull/25747#pullrequestreview-290396964",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "364e1aa9-7ff3-4ad3-b7b9-95efd06f19a9",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I added one more test here, eventually we should test all the v2 SQL statements.",
        "createdAt" : "2019-09-19T08:22:12Z",
        "updatedAt" : "2019-10-04T02:49:47Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "9ad516ea9a0ec7525308c9ca64d36d4069531ae0",
    "line" : 271,
    "diffHunk" : "@@ -1,1 +795,799 @@  }\n\n  test(\"describe table\") {\n    Seq(\"v1Table\" -> true, \"v2Table\" -> false, \"testcat.tab\" -> false).foreach {\n      case (tblName, useV1Command) =>"
  },
  {
    "id" : "878e0871-dc51-4c2d-8a55-370c0eaf1af1",
    "prId" : 25747,
    "prUrl" : "https://github.com/apache/spark/pull/25747#pullrequestreview-328014579",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5b86fdf3-cf6e-4f71-9aee-2e3553c414cd",
        "parentId" : null,
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "Hi @cloud-fan I'm curious why we need convert non-existing table to v2 command. In my idea, we can just handle this in v1 command.",
        "createdAt" : "2019-12-06T02:29:07Z",
        "updatedAt" : "2019-12-06T02:29:07Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      },
      {
        "id" : "9c629e91-4419-4416-a291-808bd1ffb1d2",
        "parentId" : "5b86fdf3-cf6e-4f71-9aee-2e3553c414cd",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "we use v2 command for v2 table, and v1 command for v1 table. If table not exists, I think v2 command is better, as we want to migrate everything to v2 command in the future.",
        "createdAt" : "2019-12-06T03:41:48Z",
        "updatedAt" : "2019-12-06T03:41:49Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "4d7d099c-c282-48e2-aed1-4d15d8d8e376",
        "parentId" : "5b86fdf3-cf6e-4f71-9aee-2e3553c414cd",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "I do agree v2 command is better than v1. But it will make some things unexpected. when load table return none, `ResolveSessionCatalog` will check if v2 support it, and throw not support msg when not support and throw table not found when support. I do not determine which msg is the high priority. Here is a example: \r\n```\r\ncreate table test(c int);\r\n// throw Table not found\r\ndesc tes;\r\n// throw Describing columns is not supported for v2 tables.;\r\ndesc tes c;\r\n```\r\nShall we keep this consistent when table is non-existing ?",
        "createdAt" : "2019-12-06T04:07:21Z",
        "updatedAt" : "2019-12-06T05:20:52Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      },
      {
        "id" : "7fb75f8f-a1ec-4c69-b84e-528acd469810",
        "parentId" : "5b86fdf3-cf6e-4f71-9aee-2e3553c414cd",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "If we use v1 command directly, things will be more simple. We even not need load table(it will affect perf), just use v1 command when catalog is session catalog.\r\nE.G. \r\n```\r\ncase DescribeTableStatement(SessionCatalog(_, tableName), partitionSpec, isExtended) =>\r\n  DescribeTableCommand(tableName.asTableIdentifier, partitionSpec, isExtended)\r\n\r\ncase DescribeColumnStatement(SessionCatalog(_, tableName), colNameParts, isExtended) =>\r\n  DescribeColumnCommand(tableName.asTableIdentifier, colNameParts, isExtended)\r\n```",
        "createdAt" : "2019-12-06T04:23:40Z",
        "updatedAt" : "2019-12-06T04:24:45Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      },
      {
        "id" : "f7953c59-bbba-4435-8a77-e9bfa2f44965",
        "parentId" : "5b86fdf3-cf6e-4f71-9aee-2e3553c414cd",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I think it's fine. fail earlier is better than looking up the table and report table not found.",
        "createdAt" : "2019-12-06T05:32:48Z",
        "updatedAt" : "2019-12-06T05:32:48Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "02cf6f77-170b-4a0d-a199-afb6f25d6c2d",
        "parentId" : "5b86fdf3-cf6e-4f71-9aee-2e3553c414cd",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "That's OK. Thanks.",
        "createdAt" : "2019-12-06T06:19:15Z",
        "updatedAt" : "2019-12-06T06:19:16Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "9ad516ea9a0ec7525308c9ca64d36d4069531ae0",
    "line" : 190,
    "diffHunk" : "@@ -1,1 +734,738 @@    val parsed5 = parseAndResolve(sql5)\n\n    // For non-existing tables, we convert it to v2 command with `UnresolvedV2Table`\n    parsed4 match {\n      case AlterTable(_, _, _: UnresolvedV2Relation, _) => // OK"
  }
]