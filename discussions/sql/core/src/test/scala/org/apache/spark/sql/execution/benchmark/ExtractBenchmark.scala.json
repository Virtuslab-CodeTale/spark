[
  {
    "id" : "2a39eb04-6665-4f31-98ed-e6e021e929d6",
    "prId" : 32035,
    "prUrl" : "https://github.com/apache/spark/pull/32035#pullrequestreview-626811022",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2d0a4a93-a547-44dd-8302-783a3578646a",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "BTW, I asked (offline) to don't generate the benchmark results because I plan to regenerate everything after https://github.com/apache/spark/pull/32015",
        "createdAt" : "2021-04-02T06:29:39Z",
        "updatedAt" : "2021-04-02T06:29:40Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "a7327e42579b101987c4324ffee14aca457453d2",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +42,46 @@    withSQLConf(\n      SQLConf.LEGACY_INTERVAL_ENABLED.key -> \"true\",\n      SQLConf.WHOLESTAGE_CODEGEN_ENABLED.key -> \"true\") {\n      spark\n        .range(sinceSecond, sinceSecond + cardinality, 1, 1)"
  },
  {
    "id" : "972aac72-214d-4b60-bae6-ace6aee18576",
    "prId" : 26175,
    "prUrl" : "https://github.com/apache/spark/pull/26175#pullrequestreview-304459254",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "05f1db2d-5c23-4612-bcc7-b946f23b3f86",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Out of curiosity, why do we need to add alias?",
        "createdAt" : "2019-10-21T10:09:12Z",
        "updatedAt" : "2019-10-21T10:09:12Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "b4bea4b9-731d-4595-ac6c-d3db03bffe11",
        "parentId" : "05f1db2d-5c23-4612-bcc7-b946f23b3f86",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "When I debugged this, I showed dataframes to terminal. And printed tables were so wide.",
        "createdAt" : "2019-10-21T10:15:05Z",
        "updatedAt" : "2019-10-21T10:15:05Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "b361b517bb6c387ad63a6f6a30d5643bfb8aeff6",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +78,82 @@    val expr = func match {\n      case \"extract\" => s\"EXTRACT($field FROM ${castExpr(from)}) AS $field\"\n      case \"date_part\" => s\"DATE_PART('$field', ${castExpr(from)}) AS $field\"\n      case other => throw new IllegalArgumentException(\n        s\"Unsupported function '$other'. Valid functions are 'extract' and 'date_part'.\")"
  },
  {
    "id" : "d0b60e29-5b28-4470-9e8a-4ec5f5c81b6f",
    "prId" : 26175,
    "prUrl" : "https://github.com/apache/spark/pull/26175#pullrequestreview-304479850",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dac63acb-0c0b-4420-b40a-065a36179ba0",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "not a big deal but `Settings` seems only used within `runBenchmarkSuite`. I think it's fine to just make this pretty with indentation.",
        "createdAt" : "2019-10-21T10:11:13Z",
        "updatedAt" : "2019-10-21T10:11:13Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "2e0ce64b-ff9d-41d7-a5ab-3782228279f5",
        "parentId" : "dac63acb-0c0b-4420-b40a-065a36179ba0",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "? Could you clarify, please. Do you want to replace `Settings` by let's say tuples?",
        "createdAt" : "2019-10-21T10:17:15Z",
        "updatedAt" : "2019-10-21T10:17:16Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "7cc16e9e-afb6-4bbb-ac66-1c32ce3a88cb",
        "parentId" : "dac63acb-0c0b-4420-b40a-065a36179ba0",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "This one?\r\n```scala\r\n    for {\r\n      (dataType, (fields, funcs, iterNum)) <- Map(\r\n        \"timestamp\" -> (datetimeFields, Seq(\"extract\", \"date_part\"), N),\r\n        \"date\" -> (datetimeFields, Seq(\"extract\", \"date_part\"), N),\r\n        \"interval\" -> (intervalFields, Seq(\"date_part\"), N))\r\n      func <- funcs} {\r\n```",
        "createdAt" : "2019-10-21T10:33:49Z",
        "updatedAt" : "2019-10-21T10:33:49Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "9e192fe0-a733-4106-a70d-1111cf6685d3",
        "parentId" : "dac63acb-0c0b-4420-b40a-065a36179ba0",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "yup, I was thinking like that. I don't mind if you prefer the current way. no biggie.",
        "createdAt" : "2019-10-21T10:58:14Z",
        "updatedAt" : "2019-10-21T10:58:14Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "b361b517bb6c387ad63a6f6a30d5643bfb8aeff6",
    "line" : 44,
    "diffHunk" : "@@ -1,1 +102,106 @@      \"HOUR\", \"MINUTE\", \"SECOND\",\n      \"MILLISECONDS\", \"MICROSECONDS\", \"EPOCH\")\n    val settings = Map(\n      \"timestamp\" -> Settings(datetimeFields, Seq(\"extract\", \"date_part\"), N),\n      \"date\" -> Settings(datetimeFields, Seq(\"extract\", \"date_part\"), N),"
  }
]