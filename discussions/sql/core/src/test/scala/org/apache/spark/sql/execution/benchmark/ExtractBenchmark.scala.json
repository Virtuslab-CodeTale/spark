[
  {
    "id" : "2a39eb04-6665-4f31-98ed-e6e021e929d6",
    "prId" : 32035,
    "prUrl" : "https://github.com/apache/spark/pull/32035#pullrequestreview-626811022",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2d0a4a93-a547-44dd-8302-783a3578646a",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "BTW, I asked (offline) to don't generate the benchmark results because I plan to regenerate everything after https://github.com/apache/spark/pull/32015",
        "createdAt" : "2021-04-02T06:29:39Z",
        "updatedAt" : "2021-04-02T06:29:40Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "a7327e42579b101987c4324ffee14aca457453d2",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +42,46 @@    withSQLConf(\n      SQLConf.LEGACY_INTERVAL_ENABLED.key -> \"true\",\n      SQLConf.WHOLESTAGE_CODEGEN_ENABLED.key -> \"true\") {\n      spark\n        .range(sinceSecond, sinceSecond + cardinality, 1, 1)"
  },
  {
    "id" : "972aac72-214d-4b60-bae6-ace6aee18576",
    "prId" : 26175,
    "prUrl" : "https://github.com/apache/spark/pull/26175#pullrequestreview-304459254",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "05f1db2d-5c23-4612-bcc7-b946f23b3f86",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Out of curiosity, why do we need to add alias?",
        "createdAt" : "2019-10-21T10:09:12Z",
        "updatedAt" : "2019-10-21T10:09:12Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "b4bea4b9-731d-4595-ac6c-d3db03bffe11",
        "parentId" : "05f1db2d-5c23-4612-bcc7-b946f23b3f86",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "When I debugged this, I showed dataframes to terminal. And printed tables were so wide.",
        "createdAt" : "2019-10-21T10:15:05Z",
        "updatedAt" : "2019-10-21T10:15:05Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "b361b517bb6c387ad63a6f6a30d5643bfb8aeff6",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +78,82 @@    val expr = func match {\n      case \"extract\" => s\"EXTRACT($field FROM ${castExpr(from)}) AS $field\"\n      case \"date_part\" => s\"DATE_PART('$field', ${castExpr(from)}) AS $field\"\n      case other => throw new IllegalArgumentException(\n        s\"Unsupported function '$other'. Valid functions are 'extract' and 'date_part'.\")"
  },
  {
    "id" : "d0b60e29-5b28-4470-9e8a-4ec5f5c81b6f",
    "prId" : 26175,
    "prUrl" : "https://github.com/apache/spark/pull/26175#pullrequestreview-304479850",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dac63acb-0c0b-4420-b40a-065a36179ba0",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "not a big deal but `Settings` seems only used within `runBenchmarkSuite`. I think it's fine to just make this pretty with indentation.",
        "createdAt" : "2019-10-21T10:11:13Z",
        "updatedAt" : "2019-10-21T10:11:13Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "2e0ce64b-ff9d-41d7-a5ab-3782228279f5",
        "parentId" : "dac63acb-0c0b-4420-b40a-065a36179ba0",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "? Could you clarify, please. Do you want to replace `Settings` by let's say tuples?",
        "createdAt" : "2019-10-21T10:17:15Z",
        "updatedAt" : "2019-10-21T10:17:16Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "7cc16e9e-afb6-4bbb-ac66-1c32ce3a88cb",
        "parentId" : "dac63acb-0c0b-4420-b40a-065a36179ba0",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "This one?\r\n```scala\r\n    for {\r\n      (dataType, (fields, funcs, iterNum)) <- Map(\r\n        \"timestamp\" -> (datetimeFields, Seq(\"extract\", \"date_part\"), N),\r\n        \"date\" -> (datetimeFields, Seq(\"extract\", \"date_part\"), N),\r\n        \"interval\" -> (intervalFields, Seq(\"date_part\"), N))\r\n      func <- funcs} {\r\n```",
        "createdAt" : "2019-10-21T10:33:49Z",
        "updatedAt" : "2019-10-21T10:33:49Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "9e192fe0-a733-4106-a70d-1111cf6685d3",
        "parentId" : "dac63acb-0c0b-4420-b40a-065a36179ba0",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "yup, I was thinking like that. I don't mind if you prefer the current way. no biggie.",
        "createdAt" : "2019-10-21T10:58:14Z",
        "updatedAt" : "2019-10-21T10:58:14Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "b361b517bb6c387ad63a6f6a30d5643bfb8aeff6",
    "line" : 44,
    "diffHunk" : "@@ -1,1 +102,106 @@      \"HOUR\", \"MINUTE\", \"SECOND\",\n      \"MILLISECONDS\", \"MICROSECONDS\", \"EPOCH\")\n    val settings = Map(\n      \"timestamp\" -> Settings(datetimeFields, Seq(\"extract\", \"date_part\"), N),\n      \"date\" -> Settings(datetimeFields, Seq(\"extract\", \"date_part\"), N),"
  },
  {
    "id" : "9f464810-c6eb-489e-b4d5-d81f56daa608",
    "prId" : 25772,
    "prUrl" : "https://github.com/apache/spark/pull/25772#pullrequestreview-289735919",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e860a2e2-f269-4939-98ea-a942a488a8db",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Ur, is there other reason not to use `SqlBasedBenchmark`? You can do `override def getSparkSession`  from `SqlBasedBenchmark` like `DatasetBenchmark` does.",
        "createdAt" : "2019-09-12T18:38:54Z",
        "updatedAt" : "2019-09-12T18:38:54Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "6ddd167f-0140-4a30-abee-89ebad561a15",
        "parentId" : "e860a2e2-f269-4939-98ea-a942a488a8db",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Having unused dependency is better, from my point of view. If you think it makes sense, I could change that in a separate PR, and override `getSparkSession` in other benchmarks like `FilterPushdownBenchmark`, `OrcReadBenchmark`, `PrimitiveArrayBenchmark`.",
        "createdAt" : "2019-09-13T11:46:49Z",
        "updatedAt" : "2019-09-13T11:46:49Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "30a02a35-4009-4a4f-b456-c3109285b510",
        "parentId" : "e860a2e2-f269-4939-98ea-a942a488a8db",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Maybe later. For now, never mind. We have more important things to do~ 3.0.0-preview is coming! ðŸ˜„ ",
        "createdAt" : "2019-09-13T15:10:08Z",
        "updatedAt" : "2019-09-13T15:10:08Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "01dc0c76-7a5c-47cc-b27f-dbb735cf018e",
        "parentId" : "e860a2e2-f269-4939-98ea-a942a488a8db",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "> We have more important things to do~ 3.0.0-preview is coming!\r\n\r\nPlease, ping me if you think I could help.",
        "createdAt" : "2019-09-13T16:31:02Z",
        "updatedAt" : "2019-09-13T16:31:02Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "b51bbedd-3fdb-4746-8427-6875ba021c3a",
        "parentId" : "e860a2e2-f269-4939-98ea-a942a488a8db",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Here is the PR https://github.com/apache/spark/pull/25828 , just in case.",
        "createdAt" : "2019-09-18T08:03:37Z",
        "updatedAt" : "2019-09-18T08:03:37Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "766110ad07bc1a9911b80a179033df6ad9c924fb",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +41,45 @@    .master(\"local[1]\")\n    .appName(this.getClass.getCanonicalName)\n    .getOrCreate()\n\n  private def doBenchmark(cardinality: Long, exprs: String*): Unit = {"
  }
]