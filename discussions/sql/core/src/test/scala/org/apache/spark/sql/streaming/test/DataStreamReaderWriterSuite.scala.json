[
  {
    "id" : "0aa4b2ab-e2ac-4763-ba03-ec123a7de5f3",
    "prId" : 29730,
    "prUrl" : "https://github.com/apache/spark/pull/29730#pullrequestreview-487007585",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bdc5917a-7fbf-495c-9d62-c558ab635121",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "I keep this name for the other cases in order to reduce the patch size.",
        "createdAt" : "2020-09-11T14:59:18Z",
        "updatedAt" : "2020-09-11T15:14:42Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "e07fafe8-b85a-43d6-bfe2-d9919d0d304a",
        "parentId" : "bdc5917a-7fbf-495c-9d62-c558ab635121",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "How about add a comment?",
        "createdAt" : "2020-09-11T17:52:19Z",
        "updatedAt" : "2020-09-11T17:52:20Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "9f2a0366bd46bdc1c1a8c65355781dd05eed2f68",
    "line" : 3,
    "diffHunk" : "@@ -1,1 +43,47 @@  var mockStreamSourceProvider = mock(classOf[StreamSourceProvider])\n  var mockStreamSinkProvider = mock(classOf[StreamSinkProvider])\n  var parameters: Map[String, String] = null\n  var sinkParameters: Map[String, String] = null\n  var schema: Option[StructType] = null"
  },
  {
    "id" : "7f47fe22-3370-4499-9f72-42e8444ef7b1",
    "prId" : 29543,
    "prUrl" : "https://github.com/apache/spark/pull/29543#pullrequestreview-485502901",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "87a1f7c1-a749-4a14-ad96-16314d14bade",
        "parentId" : null,
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "This could be flaky. The directory of tmp2 could be non-empty and contains illegal data. ",
        "createdAt" : "2020-09-10T00:33:43Z",
        "updatedAt" : "2020-09-10T00:33:43Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      },
      {
        "id" : "9ef08896-aa39-4c47-a0fb-12c100b2abbf",
        "parentId" : "87a1f7c1-a749-4a14-ad96-16314d14bade",
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "This is using `org.apache.spark.sql.streaming.test` as a format, which has a no-op implementation: https://github.com/apache/spark/blob/f7995c576aa16f04681ca8f43f8c0f71818a9f44/sql/core/src/test/scala/org/apache/spark/sql/streaming/test/DataStreamReaderWriterSuite.scala#L58-L59\r\n\r\nThis datasource is being used throughout this test suite with non-existent dirs: https://github.com/apache/spark/blob/f7995c576aa16f04681ca8f43f8c0f71818a9f44/sql/core/src/test/scala/org/apache/spark/sql/streaming/test/DataStreamReaderWriterSuite.scala#L227-L231\r\n\r\nAm I missing something? Thanks!",
        "createdAt" : "2020-09-10T01:08:05Z",
        "updatedAt" : "2020-09-10T01:08:05Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      },
      {
        "id" : "71e67765-5508-4d52-ad1c-3bbb82f21eeb",
        "parentId" : "87a1f7c1-a749-4a14-ad96-16314d14bade",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "You are right, I think this is not an issue here.",
        "createdAt" : "2020-09-10T01:20:52Z",
        "updatedAt" : "2020-09-10T01:20:53Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "261b6097907097a77b3c85606510e19c85a648d0",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +720,724 @@          .format(\"org.apache.spark.sql.streaming.test\")\n          .option(\"path\", \"tmp1\")\n          .load(\"tmp2\")\n        // The legacy behavior overwrites the path option.\n        assert(LastOptions.parameters(\"path\") == \"tmp2\")"
  }
]