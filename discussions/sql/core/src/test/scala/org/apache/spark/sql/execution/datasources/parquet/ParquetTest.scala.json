[
  {
    "id" : "163a8959-6e27-40f8-ac4b-7e1aac388e3a",
    "prId" : 28598,
    "prUrl" : "https://github.com/apache/spark/pull/28598#pullrequestreview-416581802",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "33f1e56f-0d96-488e-b3f4-8cc6ead6eb77",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can we simplify it?\r\n```\r\ndef withAllParquetReaders(code: => Unit): Unit = {\r\n  // test the row-based reader\r\n  withSQLConf(SQLConf.PARQUET_VECTORIZED_READER_ENABLED.key -> \"false\")(code)\r\n  // test the vectorized reader\r\n  withSQLConf(SQLConf.PARQUET_VECTORIZED_READER_ENABLED.key -> \"true\")(code)\r\n}\r\n```",
        "createdAt" : "2020-05-21T12:14:09Z",
        "updatedAt" : "2020-05-21T16:48:51Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "36b0bd3d-c01e-4f38-aaf4-6ba8ad0093bd",
        "parentId" : "33f1e56f-0d96-488e-b3f4-8cc6ead6eb77",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "done",
        "createdAt" : "2020-05-21T16:49:54Z",
        "updatedAt" : "2020-05-21T16:49:55Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "7c92105d-39c2-4dea-8f6e-37df0a7a1a78",
        "parentId" : "33f1e56f-0d96-488e-b3f4-8cc6ead6eb77",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "I would say code- > func but no big deal.",
        "createdAt" : "2020-05-22T00:47:00Z",
        "updatedAt" : "2020-05-22T00:47:01Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "5ffc1e43c6617e33b9750eb3c9032421c4d1cdca",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +164,168 @@  }\n\n  def withAllParquetReaders(code: => Unit): Unit = {\n    // test the row-based reader\n    withSQLConf(SQLConf.PARQUET_VECTORIZED_READER_ENABLED.key -> \"false\")(code)"
  },
  {
    "id" : "46405a94-3b41-4981-b0e3-18923f278096",
    "prId" : 27728,
    "prUrl" : "https://github.com/apache/spark/pull/27728#pullrequestreview-380849971",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0ea88116-534a-492e-941e-562e22ef538d",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Why do we need to change the test framework? We can support nested data structure with `Seq[T]`, like case class",
        "createdAt" : "2020-03-24T08:51:17Z",
        "updatedAt" : "2020-03-26T08:00:03Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "3d087066-c302-4a4e-9c38-995e6276548a",
        "parentId" : "0ea88116-534a-492e-941e-562e22ef538d",
        "authorId" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "body" : "It's because the original test framework takes `Seq[T]` which is very hard to programmatically to manipulate to create different favor of nested data as new test cases. See  \r\nhttps://github.com/apache/spark/pull/27728/files#diff-43b427b8b0b4b9d8dd7e4367c0526f83R128\r\n\r\nBy taking a dataframe instead, it's very easier to create new nested data based on single level data for tests. ",
        "createdAt" : "2020-03-25T04:19:14Z",
        "updatedAt" : "2020-03-26T08:00:03Z",
        "lastEditedBy" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "tags" : [
        ]
      }
    ],
    "commit" : "5fd97c0a90eb1885a93fffb9d04a262b35f62bc3",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +67,71 @@   * which is then passed to `f`. The Parquet file will be deleted after `f` returns.\n   */\n  protected def withParquetDataFrame(df: DataFrame, testVectorized: Boolean = true)\n      (f: DataFrame => Unit): Unit = {\n    withTempPath { file =>"
  }
]