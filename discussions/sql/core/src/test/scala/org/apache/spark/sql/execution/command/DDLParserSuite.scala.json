[
  {
    "id" : "d8e9cef6-e00d-4085-b74b-4921707fd1aa",
    "prId" : 28517,
    "prUrl" : "https://github.com/apache/spark/pull/28517#pullrequestreview-410507482",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c8475c5b-198f-4c21-81e1-dffc9f3d9780",
        "parentId" : null,
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "All of the changes in this test suite are simply done via reverting back to pre-SPARK-30098.",
        "createdAt" : "2020-05-12T23:17:04Z",
        "updatedAt" : "2020-05-15T05:20:01Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      },
      {
        "id" : "e4e90e32-96d1-4c7c-a1d0-5780db98e6c7",
        "parentId" : "c8475c5b-198f-4c21-81e1-dffc9f3d9780",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "Ref: https://github.com/apache/spark/blame/c1a5f94973213b1cad15388f3ef8a488424c34a7/sql/core/src/test/scala/org/apache/spark/sql/execution/command/DDLParserSuite.scala\r\n\r\nI had to remove the line `assert(desc.viewDefaultDatabase.isEmpty)` as `desc.viewDefaultDatabase` no longer exists. I hope it is expected.\r\n",
        "createdAt" : "2020-05-13T00:18:42Z",
        "updatedAt" : "2020-05-15T05:20:01Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      }
    ],
    "commit" : "84c172fb20321b082fc98fa419f9756ec44a6a7e",
    "line" : 1,
    "diffHunk" : "@@ -1,1 +38,42 @@import org.apache.spark.sql.internal.{HiveSerDe, SQLConf}\nimport org.apache.spark.sql.test.SharedSparkSession\nimport org.apache.spark.sql.types.{IntegerType, StructField, StructType}\n\nclass DDLParserSuite extends AnalysisTest with SharedSparkSession {"
  },
  {
    "id" : "38c8ce99-6a63-4dec-850c-ef1da1b105d4",
    "prId" : 27107,
    "prUrl" : "https://github.com/apache/spark/pull/27107#pullrequestreview-339026173",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b025502e-e26e-461a-83be-b21ee0254a40",
        "parentId" : null,
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "This clearly represents the change: `STORED AS parquet` was required to let the query statement fall into createHiveTable which has been optional. We no longer require it.",
        "createdAt" : "2020-01-06T12:53:10Z",
        "updatedAt" : "2020-01-06T12:53:10Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      },
      {
        "id" : "b81315c0-8d49-439d-8ffa-566836d30d09",
        "parentId" : "b025502e-e26e-461a-83be-b21ee0254a40",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Do we have to remove this `STORED AS parquet`? The best backward-compatible solution for this test case seems to keep both `STORED AS parquet` and the unsupported exception without any changes on this test case.",
        "createdAt" : "2020-01-07T03:56:44Z",
        "updatedAt" : "2020-01-07T03:56:44Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "2b956ec2-1469-4b6a-8df9-4dcd1a9d25de",
        "parentId" : "b025502e-e26e-461a-83be-b21ee0254a40",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Could you extend these test cases by only adding more examples, please?",
        "createdAt" : "2020-01-07T03:57:59Z",
        "updatedAt" : "2020-01-07T03:58:25Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "ec08dc4c-4787-4d39-b315-c0c32210180f",
        "parentId" : "b025502e-e26e-461a-83be-b21ee0254a40",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "So the test wasn't have `STORED AS parquet`, and SPARK-30098 added it. (I guess it was added because it didn't work without that.)\r\n\r\nThis change is just reverting to original one, but it's also OK to have another test for having `STORED AS`.",
        "createdAt" : "2020-01-07T04:31:50Z",
        "updatedAt" : "2020-01-07T04:33:13Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      }
    ],
    "commit" : "3f9e033d8d18678e4ef5a08aa30a7af1a5aeb60b",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +247,251 @@  test(\"create hive external table - location must be specified\") {\n    assertUnsupported(\n      sql = \"CREATE EXTERNAL TABLE my_tab\",\n      containsThesePhrases = Seq(\"create external table\", \"location\"))\n    val query = \"CREATE EXTERNAL TABLE my_tab LOCATION '/something/anything'\""
  },
  {
    "id" : "bbc8891a-6a6f-4c12-9411-07cc57029ff6",
    "prId" : 27107,
    "prUrl" : "https://github.com/apache/spark/pull/27107#pullrequestreview-338626761",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a578ad72-d15e-40e8-a554-905b9c654251",
        "parentId" : null,
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "The test was changed to deny the statement - we are reverting this.",
        "createdAt" : "2020-01-06T12:54:55Z",
        "updatedAt" : "2020-01-06T12:54:56Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      }
    ],
    "commit" : "3f9e033d8d18678e4ef5a08aa30a7af1a5aeb60b",
    "line" : 42,
    "diffHunk" : "@@ -1,1 +768,772 @@  test(\"create table - external\") {\n    val query = \"CREATE EXTERNAL TABLE tab1 (id int, name string) LOCATION '/path/to/nowhere'\"\n    val (desc, _) = extractTableDesc(query)\n    assert(desc.tableType == CatalogTableType.EXTERNAL)\n    assert(desc.storage.locationUri == Some(new URI(\"/path/to/nowhere\")))"
  }
]