[
  {
    "id" : "d8e9cef6-e00d-4085-b74b-4921707fd1aa",
    "prId" : 28517,
    "prUrl" : "https://github.com/apache/spark/pull/28517#pullrequestreview-410507482",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c8475c5b-198f-4c21-81e1-dffc9f3d9780",
        "parentId" : null,
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "All of the changes in this test suite are simply done via reverting back to pre-SPARK-30098.",
        "createdAt" : "2020-05-12T23:17:04Z",
        "updatedAt" : "2020-05-15T05:20:01Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      },
      {
        "id" : "e4e90e32-96d1-4c7c-a1d0-5780db98e6c7",
        "parentId" : "c8475c5b-198f-4c21-81e1-dffc9f3d9780",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "Ref: https://github.com/apache/spark/blame/c1a5f94973213b1cad15388f3ef8a488424c34a7/sql/core/src/test/scala/org/apache/spark/sql/execution/command/DDLParserSuite.scala\r\n\r\nI had to remove the line `assert(desc.viewDefaultDatabase.isEmpty)` as `desc.viewDefaultDatabase` no longer exists. I hope it is expected.\r\n",
        "createdAt" : "2020-05-13T00:18:42Z",
        "updatedAt" : "2020-05-15T05:20:01Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      }
    ],
    "commit" : "84c172fb20321b082fc98fa419f9756ec44a6a7e",
    "line" : 1,
    "diffHunk" : "@@ -1,1 +38,42 @@import org.apache.spark.sql.internal.{HiveSerDe, SQLConf}\nimport org.apache.spark.sql.test.SharedSparkSession\nimport org.apache.spark.sql.types.{IntegerType, StructField, StructType}\n\nclass DDLParserSuite extends AnalysisTest with SharedSparkSession {"
  },
  {
    "id" : "38c8ce99-6a63-4dec-850c-ef1da1b105d4",
    "prId" : 27107,
    "prUrl" : "https://github.com/apache/spark/pull/27107#pullrequestreview-339026173",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b025502e-e26e-461a-83be-b21ee0254a40",
        "parentId" : null,
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "This clearly represents the change: `STORED AS parquet` was required to let the query statement fall into createHiveTable which has been optional. We no longer require it.",
        "createdAt" : "2020-01-06T12:53:10Z",
        "updatedAt" : "2020-01-06T12:53:10Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      },
      {
        "id" : "b81315c0-8d49-439d-8ffa-566836d30d09",
        "parentId" : "b025502e-e26e-461a-83be-b21ee0254a40",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Do we have to remove this `STORED AS parquet`? The best backward-compatible solution for this test case seems to keep both `STORED AS parquet` and the unsupported exception without any changes on this test case.",
        "createdAt" : "2020-01-07T03:56:44Z",
        "updatedAt" : "2020-01-07T03:56:44Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "2b956ec2-1469-4b6a-8df9-4dcd1a9d25de",
        "parentId" : "b025502e-e26e-461a-83be-b21ee0254a40",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Could you extend these test cases by only adding more examples, please?",
        "createdAt" : "2020-01-07T03:57:59Z",
        "updatedAt" : "2020-01-07T03:58:25Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "ec08dc4c-4787-4d39-b315-c0c32210180f",
        "parentId" : "b025502e-e26e-461a-83be-b21ee0254a40",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "So the test wasn't have `STORED AS parquet`, and SPARK-30098 added it. (I guess it was added because it didn't work without that.)\r\n\r\nThis change is just reverting to original one, but it's also OK to have another test for having `STORED AS`.",
        "createdAt" : "2020-01-07T04:31:50Z",
        "updatedAt" : "2020-01-07T04:33:13Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      }
    ],
    "commit" : "3f9e033d8d18678e4ef5a08aa30a7af1a5aeb60b",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +247,251 @@  test(\"create hive external table - location must be specified\") {\n    assertUnsupported(\n      sql = \"CREATE EXTERNAL TABLE my_tab\",\n      containsThesePhrases = Seq(\"create external table\", \"location\"))\n    val query = \"CREATE EXTERNAL TABLE my_tab LOCATION '/something/anything'\""
  },
  {
    "id" : "bbc8891a-6a6f-4c12-9411-07cc57029ff6",
    "prId" : 27107,
    "prUrl" : "https://github.com/apache/spark/pull/27107#pullrequestreview-338626761",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a578ad72-d15e-40e8-a554-905b9c654251",
        "parentId" : null,
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "The test was changed to deny the statement - we are reverting this.",
        "createdAt" : "2020-01-06T12:54:55Z",
        "updatedAt" : "2020-01-06T12:54:56Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      }
    ],
    "commit" : "3f9e033d8d18678e4ef5a08aa30a7af1a5aeb60b",
    "line" : 42,
    "diffHunk" : "@@ -1,1 +768,772 @@  test(\"create table - external\") {\n    val query = \"CREATE EXTERNAL TABLE tab1 (id int, name string) LOCATION '/path/to/nowhere'\"\n    val (desc, _) = extractTableDesc(query)\n    assert(desc.tableType == CatalogTableType.EXTERNAL)\n    assert(desc.storage.locationUri == Some(new URI(\"/path/to/nowhere\")))"
  },
  {
    "id" : "61593927-1d96-47bd-b8f2-9894deca58c7",
    "prId" : 25294,
    "prUrl" : "https://github.com/apache/spark/pull/25294#pullrequestreview-269401630",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7a814e1a-ef53-4f04-96f2-f4f6442ebc83",
        "parentId" : null,
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "This is the parser test case. \r\n\r\nAdd both negative and positive end to end test cases? ",
        "createdAt" : "2019-07-30T16:30:25Z",
        "updatedAt" : "2019-08-03T05:37:24Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      },
      {
        "id" : "85d343cb-3010-433d-9833-8d6f50afcae5",
        "parentId" : "7a814e1a-ef53-4f04-96f2-f4f6442ebc83",
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "Add it to DDLSuite?",
        "createdAt" : "2019-07-30T16:31:45Z",
        "updatedAt" : "2019-08-03T05:37:24Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      },
      {
        "id" : "8ea18c53-4279-48e7-81b7-9c690f932a5f",
        "parentId" : "7a814e1a-ef53-4f04-96f2-f4f6442ebc83",
        "authorId" : "7e665d8b-d739-4edf-88c8-7379ff8585c2",
        "body" : "I add a positive e2e test case.\r\nWhat's the negative test case you want to add ?",
        "createdAt" : "2019-07-31T01:35:54Z",
        "updatedAt" : "2019-08-03T05:37:24Z",
        "lastEditedBy" : "7e665d8b-d739-4edf-88c8-7379ff8585c2",
        "tags" : [
        ]
      },
      {
        "id" : "65ceb035-e892-46ee-a039-9b6be62d8b32",
        "parentId" : "7a814e1a-ef53-4f04-96f2-f4f6442ebc83",
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "1. A database that does not exist before issuing this command?\r\n2. Setting an illegal path that could trigger an exception inside the function `stringToURI`",
        "createdAt" : "2019-08-01T05:26:28Z",
        "updatedAt" : "2019-08-03T05:37:24Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      }
    ],
    "commit" : "2a95580b985dfcf43e2c4d3336ce0286b7c245c0",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +187,191 @@  test(\"alter database set location\") {\n    // ALTER (DATABASE|SCHEMA) database_name SET LOCATION\n    val sql1 = \"ALTER DATABASE database_name SET LOCATION '/home/user/db'\"\n    val parsed1 = parser.parsePlan(sql1)\n"
  }
]