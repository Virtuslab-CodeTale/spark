[
  {
    "id" : "2b33c892-e8f5-459e-90ef-e439a6c7d0fd",
    "prId" : 32648,
    "prUrl" : "https://github.com/apache/spark/pull/32648#pullrequestreview-667647992",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9a99f207-eb56-4ab2-a16d-b8d968d5371a",
        "parentId" : null,
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "```\r\n[ERROR] [Error] /spark/sql/core/src/test/scala/org/apache/spark/sql/SQLQueryTestSuite.scala:225: The outer reference in this type test cannot be checked at run time.\r\n[ERROR] [Error] /spark/sql/core/src/test/scala/org/apache/spark/sql/SQLQueryTestSuite.scala:357: The outer reference in this type test cannot be checked at run time.\r\n[ERROR] [Error] /spark/sql/core/src/test/scala/org/apache/spark/sql/SQLQueryTestSuite.scala:363: The outer reference in this type test cannot be checked at run time.\r\n[ERROR] [Error] /spark/sql/core/src/test/scala/org/apache/spark/sql/SQLQueryTestSuite.scala:371: The outer reference in this type test cannot be checked at run time.\r\n[ERROR] [Error] /spark/sql/core/src/test/scala/org/apache/spark/sql/SQLQueryTestSuite.scala:414: The outer reference in this type test cannot be checked at run time.\r\n```",
        "createdAt" : "2021-05-24T06:50:39Z",
        "updatedAt" : "2021-05-24T06:50:39Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      },
      {
        "id" : "1f3db27c-378b-4aa3-80c5-773e56254081",
        "parentId" : "9a99f207-eb56-4ab2-a16d-b8d968d5371a",
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "@som-snytt It seems that this compilation fix is related [https://github.com/scala/scala/pull/9504](https://github.com/scala/scala/pull/9504).\r\n\r\nSo I have another question to ask you for help, `UDFTest`  is an internal `trait` defined in `SQLQueryTestSuite`,  must full path be used for this case in future Scala versions?\r\n\r\n\r\n\r\n",
        "createdAt" : "2021-05-25T08:58:02Z",
        "updatedAt" : "2021-05-25T08:58:02Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      },
      {
        "id" : "52becfa5-7bfc-4cef-9d55-a1b8e91e226e",
        "parentId" : "9a99f207-eb56-4ab2-a16d-b8d968d5371a",
        "authorId" : "6d99b742-247b-435a-a34f-d9bcc594780f",
        "body" : "I don't have a precise answer, but I would expect ongoing improvements and also some noise. You can use `-Wconf` to suppress (or escalate) the message. I will try to take another look tomorrow; I haven't followed the pattern matching changes yet.",
        "createdAt" : "2021-05-25T10:05:15Z",
        "updatedAt" : "2021-05-25T10:05:15Z",
        "lastEditedBy" : "6d99b742-247b-435a-a34f-d9bcc594780f",
        "tags" : [
        ]
      },
      {
        "id" : "b2f10e17-41c2-454c-a91e-662226c0f893",
        "parentId" : "9a99f207-eb56-4ab2-a16d-b8d968d5371a",
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "thanks, I tried to suppress this behavior in the past, but it seems that this is a compilation error now, I'll try it again",
        "createdAt" : "2021-05-25T10:17:31Z",
        "updatedAt" : "2021-05-25T10:17:31Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      }
    ],
    "commit" : "2a867a6277c1c6c4f1a6497973588304f907bede",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +223,227 @@      ignore(testCase.name) { /* Do nothing */ }\n    } else testCase match {\n      case udfTestCase: SQLQueryTestSuite#UDFTest\n          if udfTestCase.udf.isInstanceOf[TestPythonUDF] && !shouldTestPythonUDFs =>\n        ignore(s\"${testCase.name} is skipped because \" +"
  },
  {
    "id" : "76d451bf-031d-44a6-9729-7c045f9e7768",
    "prId" : 31996,
    "prUrl" : "https://github.com/apache/spark/pull/31996#pullrequestreview-624196962",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a28d6c46-051a-484e-8251-93d5d3f279e2",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "we need to do the same in thriftserver query test.",
        "createdAt" : "2021-03-30T12:31:06Z",
        "updatedAt" : "2021-03-30T16:24:17Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "cbe3248fa40a1af90dca73e071def2d54d30cf0d",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +384,388 @@    }\n    // TODO(SPARK-34905): Enable ANSI intervals in SQLQueryTestSuite\n    localSparkSession.conf.set(SQLConf.LEGACY_INTERVAL_ENABLED.key, true)\n\n    if (configSet.nonEmpty) {"
  },
  {
    "id" : "fa84dd8b-afac-4f8b-ae30-1d02a6f2c957",
    "prId" : 31946,
    "prUrl" : "https://github.com/apache/spark/pull/31946#pullrequestreview-619286834",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "961188ca-099a-40e0-a4a8-3c99d8f99676",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "I just removed the unnecessary part.",
        "createdAt" : "2021-03-24T03:48:05Z",
        "updatedAt" : "2021-03-24T03:48:05Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "a317cee9aa6c85743f98424d5a34a00e3a5c1b80",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +405,409 @@        s\"-- Automatically generated by ${getClass.getSimpleName}\\n\" +\n        s\"-- Number of queries: ${outputs.size}\\n\\n\\n\" +\n        outputs.mkString(\"\\n\\n\\n\") + \"\\n\"\n      }\n      val resultFile = new File(testCase.resultFile)"
  },
  {
    "id" : "e5129e15-ecd6-48cc-8923-ec1af682d16b",
    "prId" : 31886,
    "prUrl" : "https://github.com/apache/spark/pull/31886#pullrequestreview-615937859",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "812adc18-4969-4e86-ab5b-fcc127e6bbe9",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "I just removed the unnecessary code here.",
        "createdAt" : "2021-03-18T22:54:52Z",
        "updatedAt" : "2021-03-30T12:30:15Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "841005c36cda15352cc026c67401571e43e7610a",
    "line" : 52,
    "diffHunk" : "@@ -1,1 +396,400 @@        s\"-- Automatically generated by ${getClass.getSimpleName}\\n\" +\n        s\"-- Number of queries: ${outputs.size}\\n\\n\\n\" +\n        outputs.mkString(\"\\n\\n\\n\") + \"\\n\"\n      }\n      val resultFile = new File(testCase.resultFile)"
  },
  {
    "id" : "1eabf35e-c03c-4950-9681-cf89fa8f2650",
    "prId" : 31466,
    "prUrl" : "https://github.com/apache/spark/pull/31466#pullrequestreview-586088538",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "be194adf-7e61-472c-aeb0-17d3cc640c84",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "`SQL test 'transform.sql' will use` -> `SQL test 'transform.sql' which uses`",
        "createdAt" : "2021-02-08T13:17:23Z",
        "updatedAt" : "2021-02-08T13:17:24Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "7452c471-76b3-4b04-906d-4f90ba6600f8",
        "parentId" : "be194adf-7e61-472c-aeb0-17d3cc640c84",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "When there are other PRs in the future, change them by the way.",
        "createdAt" : "2021-02-09T02:04:39Z",
        "updatedAt" : "2021-02-09T02:04:39Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "01caf85014a7733402a0abcb091fa739eeafa32d",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +155,159 @@    .set(SQLConf.SHUFFLE_PARTITIONS, 4)\n\n  // SPARK-32106 Since we add SQL test 'transform.sql' will use `cat` command,\n  // here we need to ignore it.\n  private val otherIgnoreList ="
  },
  {
    "id" : "dedf669c-29b8-4c8c-a85a-85da3654ddf5",
    "prId" : 29085,
    "prUrl" : "https://github.com/apache/spark/pull/29085#pullrequestreview-452980893",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "df6bac75-1bd9-4d4c-bfe0-e15b9849be66",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Please add some comments about why this needed here.",
        "createdAt" : "2020-07-22T01:44:33Z",
        "updatedAt" : "2020-07-23T03:08:36Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "8b57648f-63c3-432e-ba19-c529a3bddc5a",
        "parentId" : "df6bac75-1bd9-4d4c-bfe0-e15b9849be66",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "Done",
        "createdAt" : "2020-07-22T04:10:19Z",
        "updatedAt" : "2020-07-23T03:08:36Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "03d3409f6ca641a4f10fdc2ac71479445220f676",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +261,265 @@    // SPARK-32106 Since we add SQL test 'transform.sql' will use `cat` command,\n    // here we need to check command available\n    assume(TestUtils.testCommandAvailable(\"/bin/bash\"))\n    val input = fileToString(new File(testCase.inputFile))\n"
  }
]