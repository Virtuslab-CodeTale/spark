[
  {
    "id" : "0f10713e-f061-4970-9990-29576ddb7ad0",
    "prId" : 31995,
    "prUrl" : "https://github.com/apache/spark/pull/31995#pullrequestreview-623793065",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "115118cd-ec8d-4451-aca1-eda36dac1f6e",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "nit: `< spark sql test jar>` -> `<spark sql test jar>`",
        "createdAt" : "2021-03-29T15:47:14Z",
        "updatedAt" : "2021-03-29T15:48:56Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "6d7c1071-280c-4be9-8085-183fa54fd3d5",
        "parentId" : "115118cd-ec8d-4451-aca1-eda36dac1f6e",
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "done ",
        "createdAt" : "2021-03-30T02:30:00Z",
        "updatedAt" : "2021-03-30T02:30:00Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      }
    ],
    "commit" : "c76be6774612ec2b95d03127538da37445a76083",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +26,30 @@ *   1. without sbt:\n *      bin/spark-submit --class <this class>\n *        --jars <spark core test jar>,<spark catalyst test jar> < spark sql test jar>\n *   2. build/sbt \"sql/test:runMain <this class>\"\n *   3. generate result: SPARK_GENERATE_BENCHMARK_FILES=1 build/sbt \"sql/test:runMain <this class>\""
  },
  {
    "id" : "4abf9381-91ff-47b2-b9f4-26d414d7c98c",
    "prId" : 30026,
    "prUrl" : "https://github.com/apache/spark/pull/30026#pullrequestreview-514598309",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3f2a1bb4-9c7b-4ded-8c43-ec32f0c0dea3",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "We need to run it and commit the benchmark result to the codebase.",
        "createdAt" : "2020-10-22T06:01:05Z",
        "updatedAt" : "2020-10-22T10:50:19Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "4ccc62ca-a4cf-450c-be2e-5f4df064647a",
        "parentId" : "3f2a1bb4-9c7b-4ded-8c43-ec32f0c0dea3",
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "Add 4f47e20 upload benchmark result file",
        "createdAt" : "2020-10-22T10:51:24Z",
        "updatedAt" : "2020-10-22T10:51:24Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      }
    ],
    "commit" : "4f47e205f2d130cf432b1a6c42589f919f2852e5",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +26,30 @@ *   1. without sbt: bin/spark-submit --class <this class> <spark sql test jar>\n *   2. build/sbt \"sql/test:runMain <this class>\"\n *   3. generate result: SPARK_GENERATE_BENCHMARK_FILES=1 build/sbt \"sql/test:runMain <this class>\"\n *      Results will be written to\n *      \"benchmarks/InsertTableWithDynamicPartitionsBenchmark-results.txt\"."
  },
  {
    "id" : "6d33752f-e63d-4e65-a3bc-ff709771ab02",
    "prId" : 30026,
    "prUrl" : "https://github.com/apache/spark/pull/30026#pullrequestreview-514423429",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9a1cfe08-0544-45d0-bd6a-3fb83c898e5b",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Seems we don't use the utils methods in `DataSourceWriteBenchmark`. I think we can implement `SqlBasedBenchmark` directly.",
        "createdAt" : "2020-10-22T06:04:08Z",
        "updatedAt" : "2020-10-22T10:50:19Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "ab5bf5d4-1d77-40a8-bd62-f20bbddbbb91",
        "parentId" : "9a1cfe08-0544-45d0-bd6a-3fb83c898e5b",
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "`withTable` method in `DataSourceWriteBenchmark ` is used(Line 91) to clean up the created table resources after benchmark",
        "createdAt" : "2020-10-22T07:15:33Z",
        "updatedAt" : "2020-10-22T10:50:19Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      }
    ],
    "commit" : "4f47e205f2d130cf432b1a6c42589f919f2852e5",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +31,35 @@ * }}}\n */\nobject InsertTableWithDynamicPartitionsBenchmark extends DataSourceWriteBenchmark {\n\n  def prepareSourceTableAndGetTotalRows(numberRows: Long, sourceTable: String,"
  }
]