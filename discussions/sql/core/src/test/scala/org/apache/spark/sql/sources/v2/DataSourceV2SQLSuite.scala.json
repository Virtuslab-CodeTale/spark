[
  {
    "id" : "3af4f0e4-0bba-43f2-bf35-34af796b6210",
    "prId" : 25536,
    "prUrl" : "https://github.com/apache/spark/pull/25536#pullrequestreview-278038221",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a061f8d9-9b89-46b4-9c63-03ade4c4ebf4",
        "parentId" : null,
        "authorId" : "1aba4faa-ea5e-4487-baf9-d552ca566126",
        "body" : "minor and non-blocking... \"table_name\" repeated many times and is it better to make it a test class variable and each test case referencing it?\r\n\r\nsorry maybe I'm being too nitpick lol\r\n\r\nPR looks good to me :)",
        "createdAt" : "2019-08-21T18:40:52Z",
        "updatedAt" : "2019-08-21T18:43:14Z",
        "lastEditedBy" : "1aba4faa-ea5e-4487-baf9-d552ca566126",
        "tags" : [
        ]
      },
      {
        "id" : "0da21d8a-9ca7-4878-9546-aaa553d8f88d",
        "parentId" : "a061f8d9-9b89-46b4-9c63-03ade4c4ebf4",
        "authorId" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "body" : "It's better to me if you don't have to jump around too much when reading the code.",
        "createdAt" : "2019-08-21T19:14:15Z",
        "updatedAt" : "2019-08-21T19:14:16Z",
        "lastEditedBy" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "tags" : [
        ]
      },
      {
        "id" : "7bc603ae-d438-4cc2-9cd0-0a6a47341cc7",
        "parentId" : "a061f8d9-9b89-46b4-9c63-03ade4c4ebf4",
        "authorId" : "1aba4faa-ea5e-4487-baf9-d552ca566126",
        "body" : "in your PR https://github.com/apache/spark/pull/25507/files `DataSourceV2DataFrameSessionCatalogSuite.scala`, there is a class variable `v2Format` being referenced by all test cases\r\n\r\n```\r\nprotected val v2Format: String = classOf[InMemoryTableProvider].getName\r\n```\r\n\r\nso I thought it's a style convention...",
        "createdAt" : "2019-08-21T19:59:05Z",
        "updatedAt" : "2019-08-21T19:59:06Z",
        "lastEditedBy" : "1aba4faa-ea5e-4487-baf9-d552ca566126",
        "tags" : [
        ]
      }
    ],
    "commit" : "655d07ef22bd3b775906fe69e04e4f8beb82a1a5",
    "line" : 78,
    "diffHunk" : "@@ -1,1 +510,514 @@        spark.sql(s\"CREATE TABLE $identifier USING foo AS SELECT 1 i\")\n\n        val table = catalog.loadTable(Identifier.of(Array(), \"table_name\"))\n\n        assert(table.name == identifier)"
  },
  {
    "id" : "6afb51d4-ab7c-47d1-887e-fce1a26a548b",
    "prId" : 25402,
    "prUrl" : "https://github.com/apache/spark/pull/25402#pullrequestreview-274667429",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "074d5627-67e1-4d43-8b5c-70632a62d146",
        "parentId" : null,
        "authorId" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "body" : "We can maintain this behavior, but I'd rather not, as the V2SessionCatalog can't properly handle views and such",
        "createdAt" : "2019-08-14T04:57:14Z",
        "updatedAt" : "2019-08-14T16:08:07Z",
        "lastEditedBy" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "tags" : [
        ]
      }
    ],
    "commit" : "a70e72676da6442a45e3a358c734b6f161c615d0",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +495,499 @@    sparkSession.sql(s\"CREATE TABLE table_name USING parquet AS SELECT id, data FROM source\")\n\n    checkAnswer(sparkSession.sql(s\"TABLE default.table_name\"), sparkSession.table(\"source\"))\n    // The fact that the following line doesn't throw an exception means, the session catalog\n    // can load the table."
  },
  {
    "id" : "abf06536-037d-4809-a47f-6251b5d502cf",
    "prId" : 25368,
    "prUrl" : "https://github.com/apache/spark/pull/25368#pullrequestreview-273496646",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fa0bffff-2bad-461c-a9a0-c69c4c3ade36",
        "parentId" : null,
        "authorId" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "body" : "`withSQLConf`? Otherwise you affect all tests below",
        "createdAt" : "2019-08-09T22:18:12Z",
        "updatedAt" : "2019-08-20T03:00:48Z",
        "lastEditedBy" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "tags" : [
        ]
      },
      {
        "id" : "c4f6f426-d0bf-4eaf-948b-c293f6514e75",
        "parentId" : "fa0bffff-2bad-461c-a9a0-c69c4c3ade36",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This test suite will clear all the configs after each test, see https://github.com/apache/spark/pull/25368/files#diff-b49f76fba19ee10a28e0e61c4b44e1a0R62",
        "createdAt" : "2019-08-12T02:31:06Z",
        "updatedAt" : "2019-08-20T03:00:48Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "4895a6eab6ec449238192715b78fea61217f7f54",
    "line" : 83,
    "diffHunk" : "@@ -1,1 +201,205 @@\n  test(\"CreateTable: use default catalog for v2 sources when default catalog is set\") {\n    spark.conf.set(\"spark.sql.default.catalog\", \"testcat\")\n    spark.sql(s\"CREATE TABLE table_name (id bigint, data string) USING foo\")\n"
  },
  {
    "id" : "784345a2-3b09-49d2-8c50-392689437308",
    "prId" : 25368,
    "prUrl" : "https://github.com/apache/spark/pull/25368#pullrequestreview-273381475",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "41abbb19-3421-46ad-a6be-9d09559553a5",
        "parentId" : null,
        "authorId" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "body" : "ditto",
        "createdAt" : "2019-08-09T22:18:54Z",
        "updatedAt" : "2019-08-20T03:00:48Z",
        "lastEditedBy" : "471c3dfe-259c-447a-9abd-f7fdecccd9a7",
        "tags" : [
        ]
      }
    ],
    "commit" : "4895a6eab6ec449238192715b78fea61217f7f54",
    "line" : 206,
    "diffHunk" : "@@ -1,1 +462,466 @@\n  test(\"CreateTableAsSelect: use default catalog for v2 sources when default catalog is set\") {\n    spark.conf.set(\"spark.sql.default.catalog\", \"testcat\")\n\n    val df = spark.createDataFrame(Seq((1L, \"a\"), (2L, \"b\"), (3L, \"c\"))).toDF(\"id\", \"data\")"
  }
]