[
  {
    "id" : "bcf513ef-b076-4118-bb06-44a3e7f8d0e2",
    "prId" : 28853,
    "prUrl" : "https://github.com/apache/spark/pull/28853#pullrequestreview-433683771",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a9b36d5d-3bb8-4bf2-a5d0-a4b637b67b90",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "This test case looks like capping the number of partition instead of giving a recommended minimum number of partitions. Could you add a different test case with `SQLConf.FILES_MIN_PARTITION_NUM = 10`?",
        "createdAt" : "2020-06-18T22:15:46Z",
        "updatedAt" : "2020-06-20T03:56:22Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "1fb9dc651d5e1041fef8612bdbd3299dcea494a5",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +537,541 @@          \"file3\" -> 1\n        ))\n      assert(table.rdd.partitions.length == 1)\n    }\n"
  },
  {
    "id" : "8aa65407-f050-4dca-83f6-f1e802003982",
    "prId" : 28853,
    "prUrl" : "https://github.com/apache/spark/pull/28853#pullrequestreview-433909700",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "31f600ee-e8de-4421-ab15-501f23c946f0",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can we add more tests to make sure that this is really for min partition number?\r\n\r\ne.g. we can create more partitions than the min number, as we make each partition 128mb.",
        "createdAt" : "2020-06-19T08:55:05Z",
        "updatedAt" : "2020-06-20T03:56:22Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "1fb9dc651d5e1041fef8612bdbd3299dcea494a5",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +548,552 @@        ))\n      assert(table.rdd.partitions.length == 3)\n    }\n\n    withSQLConf(SQLConf.FILES_MIN_PARTITION_NUM.key -> \"16\") {"
  },
  {
    "id" : "e68ca611-64f9-4677-b132-299620433945",
    "prId" : 28853,
    "prUrl" : "https://github.com/apache/spark/pull/28853#pullrequestreview-434000928",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fb9e2156-610f-40c2-b37f-86534cfdd7fa",
        "parentId" : null,
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "`100 * 128 / 16 > 128`, so max partition size is 128, partition number == file number.",
        "createdAt" : "2020-06-19T11:23:44Z",
        "updatedAt" : "2020-06-20T03:56:22Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "1fb9dc651d5e1041fef8612bdbd3299dcea494a5",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +554,558 @@      val table = createTable(files = partitions)\n      // partition is limited by filesMaxPartitionBytes(128MB)\n      assert(table.rdd.partitions.length == 100)\n    }\n"
  },
  {
    "id" : "441cf334-7d95-482b-bf6b-801960d6f6b2",
    "prId" : 28853,
    "prUrl" : "https://github.com/apache/spark/pull/28853#pullrequestreview-434173120",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ae9155ac-7c9e-452e-92ec-67f9cd078a86",
        "parentId" : null,
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "`800 * (4 + 4) / 32 > 128`, and use 128 as maxSplitSize, `800 * (4 + 4) / 128 = 50`",
        "createdAt" : "2020-06-19T15:39:24Z",
        "updatedAt" : "2020-06-20T03:56:22Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "1fb9dc651d5e1041fef8612bdbd3299dcea494a5",
    "line" : 35,
    "diffHunk" : "@@ -1,1 +560,564 @@      val partitions = (1 to 800).map(i => s\"file$i\" -> 4 * 1024 * 1024)\n      val table = createTable(files = partitions)\n      assert(table.rdd.partitions.length == 50)\n    }\n  }"
  }
]