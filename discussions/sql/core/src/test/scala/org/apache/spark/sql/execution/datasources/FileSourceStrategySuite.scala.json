[
  {
    "id" : "bcf513ef-b076-4118-bb06-44a3e7f8d0e2",
    "prId" : 28853,
    "prUrl" : "https://github.com/apache/spark/pull/28853#pullrequestreview-433683771",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a9b36d5d-3bb8-4bf2-a5d0-a4b637b67b90",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "This test case looks like capping the number of partition instead of giving a recommended minimum number of partitions. Could you add a different test case with `SQLConf.FILES_MIN_PARTITION_NUM = 10`?",
        "createdAt" : "2020-06-18T22:15:46Z",
        "updatedAt" : "2020-06-20T03:56:22Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "1fb9dc651d5e1041fef8612bdbd3299dcea494a5",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +537,541 @@          \"file3\" -> 1\n        ))\n      assert(table.rdd.partitions.length == 1)\n    }\n"
  },
  {
    "id" : "8aa65407-f050-4dca-83f6-f1e802003982",
    "prId" : 28853,
    "prUrl" : "https://github.com/apache/spark/pull/28853#pullrequestreview-433909700",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "31f600ee-e8de-4421-ab15-501f23c946f0",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can we add more tests to make sure that this is really for min partition number?\r\n\r\ne.g. we can create more partitions than the min number, as we make each partition 128mb.",
        "createdAt" : "2020-06-19T08:55:05Z",
        "updatedAt" : "2020-06-20T03:56:22Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "1fb9dc651d5e1041fef8612bdbd3299dcea494a5",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +548,552 @@        ))\n      assert(table.rdd.partitions.length == 3)\n    }\n\n    withSQLConf(SQLConf.FILES_MIN_PARTITION_NUM.key -> \"16\") {"
  },
  {
    "id" : "e68ca611-64f9-4677-b132-299620433945",
    "prId" : 28853,
    "prUrl" : "https://github.com/apache/spark/pull/28853#pullrequestreview-434000928",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fb9e2156-610f-40c2-b37f-86534cfdd7fa",
        "parentId" : null,
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "`100 * 128 / 16 > 128`, so max partition size is 128, partition number == file number.",
        "createdAt" : "2020-06-19T11:23:44Z",
        "updatedAt" : "2020-06-20T03:56:22Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "1fb9dc651d5e1041fef8612bdbd3299dcea494a5",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +554,558 @@      val table = createTable(files = partitions)\n      // partition is limited by filesMaxPartitionBytes(128MB)\n      assert(table.rdd.partitions.length == 100)\n    }\n"
  },
  {
    "id" : "441cf334-7d95-482b-bf6b-801960d6f6b2",
    "prId" : 28853,
    "prUrl" : "https://github.com/apache/spark/pull/28853#pullrequestreview-434173120",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ae9155ac-7c9e-452e-92ec-67f9cd078a86",
        "parentId" : null,
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "`800 * (4 + 4) / 32 > 128`, and use 128 as maxSplitSize, `800 * (4 + 4) / 128 = 50`",
        "createdAt" : "2020-06-19T15:39:24Z",
        "updatedAt" : "2020-06-20T03:56:22Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "1fb9dc651d5e1041fef8612bdbd3299dcea494a5",
    "line" : 35,
    "diffHunk" : "@@ -1,1 +560,564 @@      val partitions = (1 to 800).map(i => s\"file$i\" -> 4 * 1024 * 1024)\n      val table = createTable(files = partitions)\n      assert(table.rdd.partitions.length == 50)\n    }\n  }"
  },
  {
    "id" : "3e1937ff-5b43-459e-8daf-8944cc6fad8f",
    "prId" : 24553,
    "prUrl" : "https://github.com/apache/spark/pull/24553#pullrequestreview-242002409",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6d783d44-ccbc-4b68-8bd9-9fbe129eb4df",
        "parentId" : null,
        "authorId" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "body" : "I believe the new `ConstantPropagation` can remove these `IsNotNull` constraints as there is a stronger `EqualTo`.",
        "createdAt" : "2019-05-09T09:13:02Z",
        "updatedAt" : "2020-02-13T10:48:57Z",
        "lastEditedBy" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "tags" : [
        ]
      },
      {
        "id" : "be05083c-99e7-428f-b6ba-b329b5acaca1",
        "parentId" : "6d783d44-ccbc-4b68-8bd9-9fbe129eb4df",
        "authorId" : "24e1dd39-ae3f-4bbb-a391-f60afb62d075",
        "body" : "I am not sure about the reason of this change...where does it come from?",
        "createdAt" : "2019-05-24T18:49:33Z",
        "updatedAt" : "2020-02-13T10:48:57Z",
        "lastEditedBy" : "24e1dd39-ae3f-4bbb-a391-f60afb62d075",
        "tags" : [
        ]
      },
      {
        "id" : "3cee946d-06a4-4973-88f1-6b4f9cb230c8",
        "parentId" : "6d783d44-ccbc-4b68-8bd9-9fbe129eb4df",
        "authorId" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "body" : "The old `ConstantPropagation` replaced an attribute to a constant in `EqualTo` and `EqualNullSafe` expressions only. The new one doesn't make a such limitation.\r\nSince we know that `c1` equals to 1 in this example I think we can omit this trivial `IsNotNull` filter.",
        "createdAt" : "2019-05-24T19:33:26Z",
        "updatedAt" : "2020-02-13T10:48:57Z",
        "lastEditedBy" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "tags" : [
        ]
      },
      {
        "id" : "263e5343-5447-4bac-8cb6-386e859a45bf",
        "parentId" : "6d783d44-ccbc-4b68-8bd9-9fbe129eb4df",
        "authorId" : "24e1dd39-ae3f-4bbb-a391-f60afb62d075",
        "body" : "Yes, I think it is fine to omit it. Mine was just a question, I am just curious, as I don't really get the reason of this change: I mean I don't understand why this constraint isn't there anymore.",
        "createdAt" : "2019-05-25T08:23:53Z",
        "updatedAt" : "2020-02-13T10:48:57Z",
        "lastEditedBy" : "24e1dd39-ae3f-4bbb-a391-f60afb62d075",
        "tags" : [
        ]
      },
      {
        "id" : "3918cedb-8820-4f1f-865f-d359dbe80531",
        "parentId" : "6d783d44-ccbc-4b68-8bd9-9fbe129eb4df",
        "authorId" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "body" : "I don't see any reason why this limitation (https://github.com/apache/spark/pull/24553/files#diff-a1acb054bc8888376603ef510e6d0ee0L148) was there.",
        "createdAt" : "2019-05-25T13:08:19Z",
        "updatedAt" : "2020-02-13T10:48:57Z",
        "lastEditedBy" : "3d4870da-39a8-4406-b00d-131930d14cd8",
        "tags" : [
        ]
      }
    ],
    "commit" : "6d994abcf76b6ee48e8d6dd635a894b931bf8725",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +199,203 @@    }\n    // Only the filters that do not contain the partition column should be pushed down\n    checkDataFilters(Set(EqualTo(\"c1\", 1)))\n  }\n"
  }
]