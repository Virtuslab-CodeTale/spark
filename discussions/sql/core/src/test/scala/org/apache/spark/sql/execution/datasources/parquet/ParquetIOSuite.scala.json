[
  {
    "id" : "60cf8e58-9076-4d6a-9ae1-5f36705615f9",
    "prId" : 32777,
    "prUrl" : "https://github.com/apache/spark/pull/32777#pullrequestreview-678984212",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d5ba1b50-262b-4b82-a302-358aba8d58f1",
        "parentId" : null,
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "schema evolution from int to bigint (which seems like a common use case?) is unsupported for Parquet atm - plan to address it in https://issues.apache.org/jira/browse/SPARK-35461",
        "createdAt" : "2021-06-08T20:45:16Z",
        "updatedAt" : "2021-06-08T20:45:49Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      }
    ],
    "commit" : "ede6b02c5c0b7cfe908c754a991e36124e6b7138",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +508,512 @@  }\n\n  test(\"SPARK-35640: int as long should throw schema incompatible error\") {\n    val data = (1 to 4).map(i => Tuple1(i))\n    val readSchema = StructType(Seq(StructField(\"_1\", DataTypes.LongType)))"
  }
]