[
  {
    "id" : "60cf8e58-9076-4d6a-9ae1-5f36705615f9",
    "prId" : 32777,
    "prUrl" : "https://github.com/apache/spark/pull/32777#pullrequestreview-678984212",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d5ba1b50-262b-4b82-a302-358aba8d58f1",
        "parentId" : null,
        "authorId" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "body" : "schema evolution from int to bigint (which seems like a common use case?) is unsupported for Parquet atm - plan to address it in https://issues.apache.org/jira/browse/SPARK-35461",
        "createdAt" : "2021-06-08T20:45:16Z",
        "updatedAt" : "2021-06-08T20:45:49Z",
        "lastEditedBy" : "9ae00886-75a7-4f39-aed7-d47b26b67afb",
        "tags" : [
        ]
      }
    ],
    "commit" : "ede6b02c5c0b7cfe908c754a991e36124e6b7138",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +508,512 @@  }\n\n  test(\"SPARK-35640: int as long should throw schema incompatible error\") {\n    val data = (1 to 4).map(i => Tuple1(i))\n    val readSchema = StructType(Seq(StructField(\"_1\", DataTypes.LongType)))"
  },
  {
    "id" : "aca77070-8f32-4efd-9fa4-326f4450bbbe",
    "prId" : 31960,
    "prUrl" : "https://github.com/apache/spark/pull/31960#pullrequestreview-652999702",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3448f3b1-3f0e-4662-ba03-76c7c8258e6f",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can we also test with user-specified schema? What if the user-specified schema is not `decimal(20, 0)`? Do we return wrong result or fail?",
        "createdAt" : "2021-05-06T06:30:50Z",
        "updatedAt" : "2021-05-06T06:30:51Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "5e9a423f4ccd420389f618cb8e322f6415e3ded6",
    "line" : 49,
    "diffHunk" : "@@ -1,1 +486,490 @@        val path = new Path(dir.toURI.toString, \"part-r-0.parquet\")\n        makeRawParquetFile(path)\n        readParquetFile(path.toString) { df =>\n          checkAnswer(df, (-500 until 500).map { i =>\n            val bi = UnsignedLong.fromLongBits(i % 100L).bigIntegerValue()"
  },
  {
    "id" : "65f3f570-53b0-4b75-8ad7-0564779ffbef",
    "prId" : 30121,
    "prUrl" : "https://github.com/apache/spark/pull/30121#pullrequestreview-514147480",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1ef1cf96-28a4-46fa-91d9-0f1d4b74b5a1",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "No info about the writer. We take the mode from the SQL config and fail by default.",
        "createdAt" : "2020-10-21T20:11:22Z",
        "updatedAt" : "2020-10-21T20:11:23Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "33bb5c24dbdaa74fe45f70f172e3943ec3c15aab",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1023,1027 @@    }\n    Seq(\n      \"2_4_5\" -> failInRead _,\n      \"2_4_6\" -> successInRead _).foreach { case (version, checkDefaultRead) =>\n      withAllParquetReaders {"
  },
  {
    "id" : "5e550d4d-a95e-4533-985d-ee302f2410cd",
    "prId" : 28630,
    "prUrl" : "https://github.com/apache/spark/pull/28630#pullrequestreview-417804782",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "18a2d08b-bc1f-42a8-9484-92bdd0b5d75e",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "why we have 2 files for plain and dictionary-encoding for int96? other types just have one file and 2 columns.\r\n\r\nif it's caused by some parquet limitation, let's write a comment to explain it.",
        "createdAt" : "2020-05-25T14:04:03Z",
        "updatedAt" : "2020-05-25T16:32:53Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "7e0fb5c6-34e4-479d-9476-bb35a6477736",
        "parentId" : "18a2d08b-bc1f-42a8-9484-92bdd0b5d75e",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "because INT96 always use dictionary encoding independent from number of values and theirs uniqueness. I have to explicitly turn off dictionary encoding while saving to parquet files, see the test above.\r\n\r\nOther types don't have such \"problem\" - for one column parquet lib uses dict encoding because all values are unique, for another one it applies plain enc because all values in date/timestamp columns are the same.",
        "createdAt" : "2020-05-25T14:37:41Z",
        "updatedAt" : "2020-05-25T16:32:53Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "34c4dc81-dbaa-45ed-9af7-f2ba47395e27",
        "parentId" : "18a2d08b-bc1f-42a8-9484-92bdd0b5d75e",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "I added a comment",
        "createdAt" : "2020-05-25T16:33:03Z",
        "updatedAt" : "2020-05-25T16:33:04Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "3f2b474d8e19a89ee0b1f19183b8ac1c48f441df",
    "line" : 71,
    "diffHunk" : "@@ -1,1 +927,931 @@            usTs,\n            \"timestamp\",\n            s\"before_1582_timestamp_int96_plain_v$version.snappy.parquet\",\n            Map(\"parquet.enable.dictionary\" -> \"false\"))\n          save("
  }
]