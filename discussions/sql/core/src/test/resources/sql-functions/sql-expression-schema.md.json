[
  {
    "id" : "8caa020f-c221-480a-a971-e0cd3aac356c",
    "prId" : 29660,
    "prUrl" : "https://github.com/apache/spark/pull/29660#pullrequestreview-483655276",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "13452378-85fb-462c-b67c-8f3de73b1e9f",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Is this change part of the PR on purpose?",
        "createdAt" : "2020-09-07T15:23:01Z",
        "updatedAt" : "2020-09-09T03:02:25Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "2be67189-fcb3-4319-8324-6cf8944a99c0",
        "parentId" : "13452378-85fb-462c-b67c-8f3de73b1e9f",
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "> Add a manual sort to classFunsMap in ExpressionsSchemaSuite because Iterable.groupBy in Scala 2.13 has different result with TraversableLike.groupBy in Scala 2.12\r\n\r\nYes,  Because the change of `ExpressionsSchemaSuite`, this file need regenerate.",
        "createdAt" : "2020-09-07T15:54:30Z",
        "updatedAt" : "2020-09-09T03:02:25Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      },
      {
        "id" : "f9c07ae0-7d51-49d6-b89a-a4184fe35316",
        "parentId" : "13452378-85fb-462c-b67c-8f3de73b1e9f",
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "Code changed from \r\n```\r\nval classFunsMap = funInfos.groupBy(_.getClassName).toSeq.sortBy(_._1)\r\n```\r\nto\r\n```\r\nval classFunsMap = funInfos.groupBy(_.getClassName).toSeq.sortBy(_._1).map {\r\n      case (className, infos) => (className, infos.sortBy(_.getName))\r\n}\r\n```\r\nin `ExpressionsSchemaSuite`",
        "createdAt" : "2020-09-07T16:20:16Z",
        "updatedAt" : "2020-09-09T03:02:25Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      }
    ],
    "commit" : "9185a95c29bc532e9f0aea5bdd4f2185c5093642",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +3,7 @@  - Number of queries: 339\n  - Number of expressions that missing example: 34\n  - Expressions missing examples: and,bigint,binary,boolean,date,decimal,double,float,int,smallint,string,timestamp,tinyint,struct,cume_dist,dense_rank,input_file_block_length,input_file_block_start,input_file_name,lag,lead,monotonically_increasing_id,ntile,!,not,or,percent_rank,rank,row_number,spark_partition_id,version,window,positive,count_min_sketch\n## Schema of Built-in Functions\n| Class name | Function name or alias | Query example | Output schema |"
  },
  {
    "id" : "4a170fdc-f13d-45ef-9b12-7b13a8c2e21f",
    "prId" : 28764,
    "prUrl" : "https://github.com/apache/spark/pull/28764#pullrequestreview-452124812",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c6df5320-202f-41f8-be10-6f1668dde742",
        "parentId" : null,
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "The output schema is `widthbucket`? It should be `width_bucket ` if we define the prettyName to `width_bucket`?",
        "createdAt" : "2020-07-21T02:41:13Z",
        "updatedAt" : "2020-07-21T02:41:13Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      },
      {
        "id" : "0163c862-5e59-41a8-b708-255f57eb25b3",
        "parentId" : "c6df5320-202f-41f8-be10-6f1668dde742",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "yea, it looks better. I'll fix it later.",
        "createdAt" : "2020-07-21T04:53:25Z",
        "updatedAt" : "2020-07-21T04:53:25Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "9e8eab25eeffba0260d1a98a199f832251809c1d",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +292,296 @@| org.apache.spark.sql.catalyst.expressions.WeekDay | weekday | SELECT weekday('2009-07-30') | struct<weekday(CAST(2009-07-30 AS DATE)):int> |\n| org.apache.spark.sql.catalyst.expressions.WeekOfYear | weekofyear | SELECT weekofyear('2008-02-20') | struct<weekofyear(CAST(2008-02-20 AS DATE)):int> |\n| org.apache.spark.sql.catalyst.expressions.WidthBucket | width_bucket | SELECT width_bucket(5.3, 0.2, 10.6, 5) | struct<widthbucket(CAST(5.3 AS DOUBLE), CAST(0.2 AS DOUBLE), CAST(10.6 AS DOUBLE), CAST(5 AS BIGINT)):bigint> |\n| org.apache.spark.sql.catalyst.expressions.XxHash64 | xxhash64 | SELECT xxhash64('Spark', array(123), 2) | struct<xxhash64(Spark, array(123), 2):bigint> |\n| org.apache.spark.sql.catalyst.expressions.Year | year | SELECT year('2016-07-30') | struct<year(CAST(2016-07-30 AS DATE)):int> |"
  },
  {
    "id" : "b3a66aaa-14e5-4cac-b172-f82662abf4c6",
    "prId" : 28631,
    "prUrl" : "https://github.com/apache/spark/pull/28631#pullrequestreview-417375904",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8d0c3bdb-2e64-462e-8dd0-b0e4c30a0568",
        "parentId" : null,
        "authorId" : "6fc88871-fca6-485c-a47e-5e17709c7b68",
        "body" : "While you're in the same file, does it make sense to also add an example for this expression? I think you would only need to change line 333 in `sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/complexTypeCreator.scala`",
        "createdAt" : "2020-05-24T17:21:15Z",
        "updatedAt" : "2020-05-24T17:23:09Z",
        "lastEditedBy" : "6fc88871-fca6-485c-a47e-5e17709c7b68",
        "tags" : [
        ]
      }
    ],
    "commit" : "61945d4340a4160d064be9b1805c2c0195adc975",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +3,7 @@  - Number of queries: 336\n  - Number of expressions that missing example: 34\n  - Expressions missing examples: and,string,tinyint,double,smallint,date,decimal,boolean,float,binary,bigint,int,timestamp,struct,cume_dist,dense_rank,input_file_block_length,input_file_block_start,input_file_name,lag,lead,monotonically_increasing_id,ntile,!,not,or,percent_rank,rank,row_number,spark_partition_id,version,window,positive,count_min_sketch\n## Schema of Built-in Functions\n| Class name | Function name or alias | Query example | Output schema |"
  },
  {
    "id" : "aefd73c1-f5f2-4202-914a-d5c349828ebf",
    "prId" : 28194,
    "prUrl" : "https://github.com/apache/spark/pull/28194#pullrequestreview-402341838",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8d1677df-13ac-4b54-a668-be9bca57de2b",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "How about making the file name more clear for a golden file? For example, `sql-functions/sql-expression-schema.md` -> `sql-functions/sql-expression-schema-golden.md`.",
        "createdAt" : "2020-04-29T00:13:12Z",
        "updatedAt" : "2020-04-29T12:44:12Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "dd9833a1-82fa-4fe4-911f-814c6cf90966",
        "parentId" : "8d1677df-13ac-4b54-a668-be9bca57de2b",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "I don't think it's necessary. Thanks for your help.",
        "createdAt" : "2020-04-29T02:23:19Z",
        "updatedAt" : "2020-04-29T12:44:12Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      },
      {
        "id" : "682ccae8-e410-43df-b0b6-f0d24b33a03a",
        "parentId" : "8d1677df-13ac-4b54-a668-be9bca57de2b",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "One more comment: plz add the same comment with the SQLQueryTestSuite like `Automatically generated by ExpressionsSchemaSuite`\r\nhttps://github.com/apache/spark/blob/master/sql/core/src/test/resources/sql-tests/results/postgreSQL/boolean.sql.out#L1",
        "createdAt" : "2020-04-29T02:40:25Z",
        "updatedAt" : "2020-04-29T12:44:12Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "3ca63685-690a-4c3e-a6db-1a2b116de996",
        "parentId" : "8d1677df-13ac-4b54-a668-be9bca57de2b",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "OK. I will add it.",
        "createdAt" : "2020-04-29T03:16:46Z",
        "updatedAt" : "2020-04-29T12:44:12Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "a4d4de9e472dbd55ffbbc13ae1c8ad615a7e3455",
    "line" : 2,
    "diffHunk" : "@@ -1,1 +0,4 @@<!-- Automatically generated byExpressionsSchemaSuite -->\n## Summary\n  - Number of queries: 333\n  - Number of expressions that missing example: 34"
  },
  {
    "id" : "61f0fb2a-758f-4d24-965a-dcdffbfc56ca",
    "prId" : 28194,
    "prUrl" : "https://github.com/apache/spark/pull/28194#pullrequestreview-403190391",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "28a418fa-e702-44bb-abb2-7d996d1625a7",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "One case that running multiple examples is useful: `date + interval` will be replaced by `DateAddInterval` during analysis, and it's better to test it as well.\r\n\r\nWe can fix it in a followup.",
        "createdAt" : "2020-04-30T03:56:30Z",
        "updatedAt" : "2020-04-30T04:36:18Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "ae538b67-16c1-4690-a5d5-ce92982a7e00",
        "parentId" : "28a418fa-e702-44bb-abb2-7d996d1625a7",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "I checked the code of `DateAddInterval`\r\n`override def sql: String = s\"${left.sql} + ${right.sql}\"`\r\nThe alias of `DateAddInterval` is consistent with `Add`.\r\nIf we think `DateAddInterval` is one of inner implement for `Add`. This is not affect the user's use.",
        "createdAt" : "2020-04-30T04:20:32Z",
        "updatedAt" : "2020-04-30T04:23:17Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "a4d4de9e472dbd55ffbbc13ae1c8ad615a7e3455",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +10,14 @@| org.apache.spark.sql.catalyst.expressions.Acos | acos | SELECT acos(1) | struct<ACOS(CAST(1 AS DOUBLE)):double> |\n| org.apache.spark.sql.catalyst.expressions.Acosh | acosh | SELECT acosh(1) | struct<ACOSH(CAST(1 AS DOUBLE)):double> |\n| org.apache.spark.sql.catalyst.expressions.Add | + | SELECT 1 + 2 | struct<(1 + 2):int> |\n| org.apache.spark.sql.catalyst.expressions.AddMonths | add_months | SELECT add_months('2016-08-31', 1) | struct<add_months(CAST(2016-08-31 AS DATE), 1):date> |\n| org.apache.spark.sql.catalyst.expressions.And | and | N/A | N/A |"
  },
  {
    "id" : "346933a1-7d4c-46f5-b166-f11cec040972",
    "prId" : 28194,
    "prUrl" : "https://github.com/apache/spark/pull/28194#pullrequestreview-404063434",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d4b1c66b-6274-4500-beaa-82eb12ae22ac",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Why is this file md specifically?",
        "createdAt" : "2020-05-01T03:35:14Z",
        "updatedAt" : "2020-05-01T03:35:14Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "59339fce-2ed3-4833-972d-f9cfd53f2148",
        "parentId" : "d4b1c66b-6274-4500-beaa-82eb12ae22ac",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "See https://github.com/apache/spark/pull/28194#issuecomment-613854769\r\n\r\nI guess it's easier for humans the read the table.",
        "createdAt" : "2020-05-01T04:31:28Z",
        "updatedAt" : "2020-05-01T04:31:28Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "206a2fdf-2081-4acf-aa94-6f165927828a",
        "parentId" : "d4b1c66b-6274-4500-beaa-82eb12ae22ac",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Okay, but seems it's more difficult to track the diff. See https://amplab.cs.berkeley.edu/jenkins/job/spark-branch-3.0-test-sbt-hadoop-2.7-hive-2.3/431/testReport/junit/org.apache.spark.sql/ExpressionsSchemaSuite/Check_schemas_for_expression_examples/\r\n\r\n![Screen Shot 2020-05-01 at 2 06 10 PM](https://user-images.githubusercontent.com/6477701/80783491-f5a7a400-8bb4-11ea-9e91-880719bd472c.png)\r\n![Screen Shot 2020-05-01 at 2 06 04 PM](https://user-images.githubusercontent.com/6477701/80783494-f7716780-8bb4-11ea-9425-dfc348644649.png)\r\n![Screen Shot 2020-05-01 at 2 05 58 PM](https://user-images.githubusercontent.com/6477701/80783495-f8a29480-8bb4-11ea-8b7a-eb16cbcc9a8e.png)\r\n![Screen Shot 2020-05-01 at 2 05 48 PM](https://user-images.githubusercontent.com/6477701/80783498-f9d3c180-8bb4-11ea-82b4-6f865294a21f.png)\r\n![Screen Shot 2020-05-01 at 2 05 42 PM](https://user-images.githubusercontent.com/6477701/80783501-fa6c5800-8bb4-11ea-9ce6-f562aebf6b6c.png)\r\n![Screen Shot 2020-05-01 at 2 05 35 PM](https://user-images.githubusercontent.com/6477701/80783504-fb9d8500-8bb4-11ea-9a9a-f0e5eadcb596.png)\r\n\r\n",
        "createdAt" : "2020-05-01T05:07:02Z",
        "updatedAt" : "2020-05-01T05:07:03Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "8037d5b9-4cfb-43d4-8aaa-08f0f2d9015d",
        "parentId" : "d4b1c66b-6274-4500-beaa-82eb12ae22ac",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Hopefully we can improve the diff here ...",
        "createdAt" : "2020-05-01T05:09:21Z",
        "updatedAt" : "2020-05-01T05:09:21Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "829dea14-b23f-42c8-a911-3e8aba64c75f",
        "parentId" : "d4b1c66b-6274-4500-beaa-82eb12ae22ac",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This should be row-by-row diff, @beliefer can you help to fix it?",
        "createdAt" : "2020-05-01T06:15:06Z",
        "updatedAt" : "2020-05-01T06:15:07Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "9b53f749-5779-4202-ba8d-e3e0fa62b308",
        "parentId" : "d4b1c66b-6274-4500-beaa-82eb12ae22ac",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "@cloud-fan @HyukjinKwon \r\nThis checked exception is thrown when the number of expected SQL and the number of actual SQL are not equal.\r\nCould I not output all the SQL to the checked exception ?",
        "createdAt" : "2020-05-01T08:14:22Z",
        "updatedAt" : "2020-05-01T08:14:22Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "a4d4de9e472dbd55ffbbc13ae1c8ad615a7e3455",
    "line" : 1,
    "diffHunk" : "@@ -1,1 +-1,3 @@<!-- Automatically generated byExpressionsSchemaSuite -->\n## Summary\n  - Number of queries: 333"
  }
]