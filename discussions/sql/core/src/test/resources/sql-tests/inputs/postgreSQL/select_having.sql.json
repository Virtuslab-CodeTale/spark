[
  {
    "id" : "f6b0f30a-93a6-4ab6-8090-b1717c8d377c",
    "prId" : 29882,
    "prUrl" : "https://github.com/apache/spark/pull/29882#pullrequestreview-541826662",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ed4a0ff3-3cd8-4629-bea7-3f343dd391e9",
        "parentId" : null,
        "authorId" : "a80e0991-f7b1-415a-8d2e-ab615cc6ef4a",
        "body" : "I think this test case is wrong -- the next line says that it's to prove that we aren't scanning the table, but the condition `1 < 2` actually _does_ force us to scan the table. I think this test case should have used `HAVING 1 > 2`. Could you correct the test case and remove the comment?",
        "createdAt" : "2020-11-27T13:02:51Z",
        "updatedAt" : "2020-11-27T13:02:51Z",
        "lastEditedBy" : "a80e0991-f7b1-415a-8d2e-ab615cc6ef4a",
        "tags" : [
        ]
      },
      {
        "id" : "e699184d-7f39-43f3-8a95-830dec238db0",
        "parentId" : "ed4a0ff3-3cd8-4629-bea7-3f343dd391e9",
        "authorId" : "93b5fa84-bae4-4106-88af-f5f0f56a8164",
        "body" : "IIUC, the `HAVING` condition here is performed on the globally grouped result set. I think this query is to prove the row count of the global group does not affect the output of an always-true `HAVING` clause.",
        "createdAt" : "2020-12-01T02:43:50Z",
        "updatedAt" : "2020-12-01T02:43:51Z",
        "lastEditedBy" : "93b5fa84-bae4-4106-88af-f5f0f56a8164",
        "tags" : [
        ]
      },
      {
        "id" : "e83dde80-4e49-4880-b8a1-8d135f6d739c",
        "parentId" : "ed4a0ff3-3cd8-4629-bea7-3f343dd391e9",
        "authorId" : "93b5fa84-bae4-4106-88af-f5f0f56a8164",
        "body" : "I found that postgres returns correct results without errors for both `1 < 2` and `1 > 2`. While Spark SQL always scans the table and throws exceptions cause its optimizer does not take this case into account.",
        "createdAt" : "2020-12-01T03:59:33Z",
        "updatedAt" : "2020-12-01T03:59:34Z",
        "lastEditedBy" : "93b5fa84-bae4-4106-88af-f5f0f56a8164",
        "tags" : [
        ]
      },
      {
        "id" : "7fdb60a4-fc08-43df-a48a-4d460b2f7725",
        "parentId" : "ed4a0ff3-3cd8-4629-bea7-3f343dd391e9",
        "authorId" : "a80e0991-f7b1-415a-8d2e-ab615cc6ef4a",
        "body" : "Interesting! Would you mind filing a ticket for that?",
        "createdAt" : "2020-12-01T11:59:41Z",
        "updatedAt" : "2020-12-01T11:59:42Z",
        "lastEditedBy" : "a80e0991-f7b1-415a-8d2e-ab615cc6ef4a",
        "tags" : [
        ]
      }
    ],
    "commit" : "11188c356113b651435508b9137b5c084d4d990f",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +50,54 @@SELECT 1 AS one FROM test_having HAVING 1 < 2;\n\n-- [SPARK-33008] Spark SQL throws an exception\n-- and just to prove that we aren't scanning the table:\nSELECT 1 AS one FROM test_having WHERE 1/a = 1 HAVING 1 < 2;"
  }
]