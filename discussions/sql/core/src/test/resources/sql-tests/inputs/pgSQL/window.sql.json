[
  {
    "id" : "36baf499-583d-4530-af74-51901d725ca3",
    "prId" : 24881,
    "prUrl" : "https://github.com/apache/spark/pull/24881#pullrequestreview-266871817",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4163d2ff-d809-4797-aea1-41b99049a8d6",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Could you keep the original PostgreSQL comment like the following, too?\r\n```\r\n-- with GROUP BY\r\n```\r\n\r\nActually, those comments are markers. There are more missing comments in this file.",
        "createdAt" : "2019-07-25T19:42:24Z",
        "updatedAt" : "2019-09-07T15:04:47Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "82a89143-2d3e-4995-9fa9-f0907b63907e",
        "parentId" : "4163d2ff-d809-4797-aea1-41b99049a8d6",
        "authorId" : "36bbfc8a-d8be-48af-9a36-3413dadd8525",
        "body" : "Yes, I can add them. But I just checked and looks like the PgSQL file is way different from the time that I started to port it. What should I do? Migrate to the new version of the file or ignore the new additions and follow through the old one?",
        "createdAt" : "2019-07-25T20:13:50Z",
        "updatedAt" : "2019-09-07T15:04:47Z",
        "lastEditedBy" : "36bbfc8a-d8be-48af-9a36-3413dadd8525",
        "tags" : [
        ]
      },
      {
        "id" : "9675ae3e-92e5-4f61-8732-e896ac35b1eb",
        "parentId" : "4163d2ff-d809-4797-aea1-41b99049a8d6",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "As you wrote in the PR description, we are porting `REL_12_BETA2` tag instead of `branch`. Tag is not changed.\r\n- https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/window.sql",
        "createdAt" : "2019-07-25T20:38:53Z",
        "updatedAt" : "2019-09-07T15:04:47Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +30,34 @@\n-- with GROUP BY\nSELECT four, ten, SUM(SUM(four)) OVER (PARTITION BY four), AVG(ten) FROM tenk1\nGROUP BY four, ten ORDER BY four, ten;\n"
  },
  {
    "id" : "5cbd5db7-ed46-499e-89da-70bdeb3091fe",
    "prId" : 24881,
    "prUrl" : "https://github.com/apache/spark/pull/24881#pullrequestreview-271689136",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b7b09282-bf13-49fb-acd4-f3bacbd2f9a2",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Thanks for this explanation.",
        "createdAt" : "2019-08-07T01:22:02Z",
        "updatedAt" : "2019-09-07T15:04:47Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "line" : 1364,
    "diffHunk" : "@@ -1,1 +1362,1366 @@\n-- For the following queries Spark result differs from PgSQL:\n-- Spark handles division by zero as 'NaN' instead of 'NULL', which is the PgSQL behaviour\nSELECT STDDEV_SAMP(n) OVER (ORDER BY i ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING)\n  FROM (VALUES(1,NULL),(2,600),(3,470),(4,170),(5,430),(6,300)) r(i,n);"
  },
  {
    "id" : "342db274-0639-427b-8938-a4a4c6c1afb4",
    "prId" : 24881,
    "prUrl" : "https://github.com/apache/spark/pull/24881#pullrequestreview-285174319",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ff7735fe-27a2-48fa-95d6-92349b7ff1d8",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Can you describe a comment-out reason for each query where possible?",
        "createdAt" : "2019-08-26T06:01:21Z",
        "updatedAt" : "2019-09-07T15:04:47Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "8a7c8edf-eb59-4c2c-9d67-3092a5d2d557",
        "parentId" : "ff7735fe-27a2-48fa-95d6-92349b7ff1d8",
        "authorId" : "36bbfc8a-d8be-48af-9a36-3413dadd8525",
        "body" : "Done",
        "createdAt" : "2019-09-07T14:38:15Z",
        "updatedAt" : "2019-09-07T15:04:47Z",
        "lastEditedBy" : "36bbfc8a-d8be-48af-9a36-3413dadd8525",
        "tags" : [
        ]
      }
    ],
    "commit" : "80f29158d67574b6a69924a2d606ebc2fd94ada8",
    "line" : 1197,
    "diffHunk" : "@@ -1,1 +1195,1199 @@\n-- Spark doesn't handle UDFs in SQL\n-- SELECT\n-- \ti::text || ':' || COALESCE(v::text, 'NULL') as row,\n-- \tlogging_agg_strict(v::text) filter(where true)"
  }
]