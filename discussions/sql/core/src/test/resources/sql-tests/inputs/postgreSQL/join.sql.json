[
  {
    "id" : "663f6344-3982-45bc-9a5f-ad038c8192d6",
    "prId" : 31286,
    "prUrl" : "https://github.com/apache/spark/pull/31286#pullrequestreview-578050742",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "92c45edf-deaa-47c2-9701-bf835a145536",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "`count(t2.*)` means `count(1)` in pgsql?",
        "createdAt" : "2021-01-26T15:22:56Z",
        "updatedAt" : "2021-02-02T03:04:18Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "efba7879-e9ad-4866-8138-b0a1f3ecf20f",
        "parentId" : "92c45edf-deaa-47c2-9701-bf835a145536",
        "authorId" : "29c89154-22f7-40ee-b295-115a55734d6c",
        "body" : "Yes, in pgsql\r\n```\r\nselect * from (select 1 as a, null as b) as t1 join (select 1 as a, 'c' as b) as t2 on t1.a = t2.a\r\noutput:\r\n\r\na  | b      | a  | b\r\n-- | --     | -- | --\r\n1  | (null) | 1  | c\r\n\r\nselect count(t1.*) from (select 1 as a, null as b) as t1 join (select 1 as a, 'c' as b) as t2 on t1.a = t2.a\r\noutput:\r\n\r\ncount\r\n--\r\n1\r\n``",
        "createdAt" : "2021-01-27T01:57:59Z",
        "updatedAt" : "2021-02-02T03:04:18Z",
        "lastEditedBy" : "29c89154-22f7-40ee-b295-115a55734d6c",
        "tags" : [
        ]
      },
      {
        "id" : "640f13ff-fefb-4450-a300-733d72b47c66",
        "parentId" : "92c45edf-deaa-47c2-9701-bf835a145536",
        "authorId" : "29c89154-22f7-40ee-b295-115a55734d6c",
        "body" : "in spark, the second query will output 0",
        "createdAt" : "2021-01-27T02:20:11Z",
        "updatedAt" : "2021-02-02T03:04:18Z",
        "lastEditedBy" : "29c89154-22f7-40ee-b295-115a55734d6c",
        "tags" : [
        ]
      },
      {
        "id" : "794d5362-cbdc-4771-aec3-61f1209946fa",
        "parentId" : "92c45edf-deaa-47c2-9701-bf835a145536",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "since it's pgsql test, shall we use `count(1)` to match pgsql test intention?",
        "createdAt" : "2021-01-27T05:09:12Z",
        "updatedAt" : "2021-02-02T03:04:18Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "fbd94aae-aca6-47c5-b3c9-5e5af2852b94",
        "parentId" : "92c45edf-deaa-47c2-9701-bf835a145536",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "+1 for the @cloud-fan advice. Also, could you leave some comment there about why we change the original test query?",
        "createdAt" : "2021-01-28T02:16:06Z",
        "updatedAt" : "2021-02-02T03:04:18Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "e8a554df-5d8e-41a6-a7d9-4995321a316f",
        "parentId" : "92c45edf-deaa-47c2-9701-bf835a145536",
        "authorId" : "29c89154-22f7-40ee-b295-115a55734d6c",
        "body" : "@cloud-fan , @maropu , I did more tests on pgsql, seems it is much more weird than I thought.\r\nTLDR: in pgsql, `count(t2.*)` means how many MATCHING rows from t2 table. and spark doesn't have such a semantic. Here, if we want to keep the output unchanged. it should be `count(t2.q1, t2.q2)`\r\n\r\nHere is the example:\r\n```\r\nCREATE TABLE INT8_TBL AS SELECT * FROM (VALUES (1, 2), (2, 1), (3, NULL), (NULL, NULL)) AS v(q1, q2);\r\nselect * from int8_tbl as t1 left join int8_tbl as t2 on t1.q1 = t2.q2;\r\n\r\nt1.q1  | t1.q2  | t2.q1  | t2.q2\r\n--     | --     | --     | --\r\n1      | 2      | 2      | 1\r\n2      | 1      | 1      | 2\r\n3      | (null) | (null) | (null)\r\n(null) | (null) | (null) | (null)\r\n\r\nselect count(t1.*), count(t2.*) from int8_tbl as t1 left join int8_tbl as t2 on t1.q1 = t2.q2;\r\n\r\nt1.count | t2.count\r\n--       | --\r\n4        | 2\r\n\r\n```  \r\n",
        "createdAt" : "2021-01-28T07:34:53Z",
        "updatedAt" : "2021-02-02T03:04:18Z",
        "lastEditedBy" : "29c89154-22f7-40ee-b295-115a55734d6c",
        "tags" : [
        ]
      }
    ],
    "commit" : "19340d4fadffc4efe9d4adc823b381c2ec76d590",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +749,753 @@--- So here we use `count(t2.q1, t2.q2)` instead of `count(1)` to keep the query output\n--- unchanged.\nselect t1.q2, count(t2.q1, t2.q2)\nfrom int8_tbl t1 left join int8_tbl t2 on (t1.q2 = t2.q1)\ngroup by t1.q2 order by 1;"
  },
  {
    "id" : "fec2b319-05dd-4c67-9107-9c4f5fc5be2f",
    "prId" : 31286,
    "prUrl" : "https://github.com/apache/spark/pull/31286#pullrequestreview-580949545",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "14a2a1ba-fa55-441b-9315-48a4f6cb281d",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "nit: Could you leave some comments here about why we updated the tests?",
        "createdAt" : "2021-02-02T01:34:50Z",
        "updatedAt" : "2021-02-02T03:04:18Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "afd6b647-c8a6-4e76-9d0d-868456e4306b",
        "parentId" : "14a2a1ba-fa55-441b-9315-48a4f6cb281d",
        "authorId" : "29c89154-22f7-40ee-b295-115a55734d6c",
        "body" : "fixed",
        "createdAt" : "2021-02-02T03:05:51Z",
        "updatedAt" : "2021-02-02T03:05:52Z",
        "lastEditedBy" : "29c89154-22f7-40ee-b295-115a55734d6c",
        "tags" : [
        ]
      }
    ],
    "commit" : "19340d4fadffc4efe9d4adc823b381c2ec76d590",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +749,753 @@--- So here we use `count(t2.q1, t2.q2)` instead of `count(1)` to keep the query output\n--- unchanged.\nselect t1.q2, count(t2.q1, t2.q2)\nfrom int8_tbl t1 left join int8_tbl t2 on (t1.q2 = t2.q1)\ngroup by t1.q2 order by 1;"
  },
  {
    "id" : "166d6acd-6e43-41ac-a263-6a981c5cdbcc",
    "prId" : 26459,
    "prUrl" : "https://github.com/apache/spark/pull/26459#pullrequestreview-314866831",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e9cfc240-c410-4fea-858d-0fdf807cc9cd",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Also, this looks like a magic number, `10485760`. Could you explain why you choose this value? I don't see this kind of value from the original `https://github.com/postgres/postgres/blob/REL_12_BETA2/src/test/regress/sql/join.sql`.",
        "createdAt" : "2019-11-10T16:47:49Z",
        "updatedAt" : "2019-11-11T12:30:18Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "e5614b2e-f82a-412a-904d-890f93341be3",
        "parentId" : "e9cfc240-c410-4fea-858d-0fdf807cc9cd",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "I just copied them from the other join-related tests (e.g., https://github.com/apache/spark/blob/master/sql/core/src/test/resources/sql-tests/inputs/natural-join.sql#L2-L4), so I'm not sure about why the value chosen. I think this configuration is just to prohibit broadcast hash joins for tests. @mgaido91 might know more about this value.",
        "createdAt" : "2019-11-11T00:26:29Z",
        "updatedAt" : "2019-11-11T12:30:18Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "f25a97a3-7d87-46b6-99bb-8ca28833f2dc",
        "parentId" : "e9cfc240-c410-4fea-858d-0fdf807cc9cd",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "@dongjoon-hyun @maropu \r\n `10 * 1024 * 1024 = 10485760` \r\nThis config's default value is `10m`",
        "createdAt" : "2019-11-11T03:14:11Z",
        "updatedAt" : "2019-11-11T12:30:18Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "edf9ea7e-fd53-40f2-97ab-523f000d6bbd",
        "parentId" : "e9cfc240-c410-4fea-858d-0fdf807cc9cd",
        "authorId" : "24e1dd39-ae3f-4bbb-a391-f60afb62d075",
        "body" : "right, it is the default value",
        "createdAt" : "2019-11-11T09:33:58Z",
        "updatedAt" : "2019-11-11T12:30:18Z",
        "lastEditedBy" : "24e1dd39-ae3f-4bbb-a391-f60afb62d075",
        "tags" : [
        ]
      },
      {
        "id" : "99835d45-29f4-48d4-b7d1-dd7c9abd59e2",
        "parentId" : "e9cfc240-c410-4fea-858d-0fdf807cc9cd",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Thanks, @mgaido91 !",
        "createdAt" : "2019-11-11T12:27:56Z",
        "updatedAt" : "2019-11-11T12:30:18Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "6491985d71981985bbd9e4a02cbcd7f729f2c499",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +9,13 @@\n-- List of configuration the test suite is run against:\n--SET spark.sql.autoBroadcastJoinThreshold=10485760\n--SET spark.sql.autoBroadcastJoinThreshold=-1,spark.sql.join.preferSortMergeJoin=true\n--SET spark.sql.autoBroadcastJoinThreshold=-1,spark.sql.join.preferSortMergeJoin=false"
  }
]