[
  {
    "id" : "9c53c538-53ea-46a5-815d-3583040b0990",
    "prId" : 24782,
    "prUrl" : "https://github.com/apache/spark/pull/24782#pullrequestreview-244905022",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b706ff29-41a9-4368-ac52-aeae6cf4a7a9",
        "parentId" : null,
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "Need to `set spark.sql.crossJoin.enabled=true`. otherwise:\r\n```\r\n-- !query 30\r\nSELECT '' AS Five, NULLIF(a.i,b.i) AS `NULLIF(a.i,b.i)`,\r\n  NULLIF(b.i, 4) AS `NULLIF(b.i,4)`\r\n  FROM CASE_TBL a, CASE2_TBL b\r\n-- !query 30 schema\r\nstruct<>\r\n-- !query 30 output\r\norg.apache.spark.sql.AnalysisException\r\nDetected implicit cartesian product for INNER join between logical plans\r\nProject [i#x]\r\n+- Relation[i#x,f#x] parquet\r\nand\r\nProject [i#x]\r\n+- Relation[i#x,j#x] parquet\r\nJoin condition is missing or trivial.\r\nEither: use the CROSS JOIN syntax to allow cartesian products between these\r\nrelations, or: enable implicit cartesian products by setting the configuration\r\nvariable spark.sql.crossJoin.enabled=true;\r\n```",
        "createdAt" : "2019-06-03T14:12:22Z",
        "updatedAt" : "2019-06-10T12:37:48Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      }
    ],
    "commit" : "89e3a9e935279fcc1cd3f8555057ff66ff40192b",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +9,13 @@-- This test suite contains two Cartesian products without using explicit CROSS JOIN syntax.\n-- Thus, we set spark.sql.crossJoin.enabled to true.\nset spark.sql.crossJoin.enabled=true;\nCREATE TABLE CASE_TBL (\n  i integer,"
  },
  {
    "id" : "a93cf502-d68c-46e6-9e14-842dce77f322",
    "prId" : 24782,
    "prUrl" : "https://github.com/apache/spark/pull/24782#pullrequestreview-247388101",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "37ccc2d3-4bef-4d4c-90d7-725534138191",
        "parentId" : null,
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "Skip `UPDATE` cases? I add a comment here.",
        "createdAt" : "2019-06-03T14:20:29Z",
        "updatedAt" : "2019-06-10T12:37:48Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      },
      {
        "id" : "5c59b06c-051e-446c-b593-70da126e98a4",
        "parentId" : "37ccc2d3-4bef-4d4c-90d7-725534138191",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Hi, @gatorsmile and @wangyum . The half of the file is `comment` which is irrelevant to Apache Spark. Do we need to keep all the invalid comments? In fact, the original will be changed time to time, too. For the simply invalid one (which has no SPARK JIRA), shall we skip adding comments?",
        "createdAt" : "2019-06-09T02:39:02Z",
        "updatedAt" : "2019-06-10T12:37:48Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "89e3a9e935279fcc1cd3f8555057ff66ff40192b",
    "line" : 146,
    "diffHunk" : "@@ -1,1 +144,148 @@  WHERE COALESCE(f,b.i) = 2;\n\n-- We don't support update now.\n--\n-- Examples of updates involving tables"
  }
]