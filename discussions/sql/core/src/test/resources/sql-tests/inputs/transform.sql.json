[
  {
    "id" : "7111aba1-ea36-4db5-9b95-b2ff25b05c48",
    "prId" : 33363,
    "prUrl" : "https://github.com/apache/spark/pull/33363#pullrequestreview-712331589",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "57d52384-d4e1-4f5e-9ca9-3bbf812ea13c",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "What if `NULL DEFINED` includes a meta character, e.g., `\\n`? It works well?",
        "createdAt" : "2021-07-16T02:03:44Z",
        "updatedAt" : "2021-07-16T02:03:48Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "395deac2-cea9-4ebb-b1cd-47522799d213",
        "parentId" : "57d52384-d4e1-4f5e-9ca9-3bbf812ea13c",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> What if `NULL DEFINED` includes a meta character, e.g., `\\n`? It works well?\r\n\r\nNo, also in hive\r\n![image](https://user-images.githubusercontent.com/46485123/125881169-4cbd510c-0a61-4125-8045-94073764f150.png)\r\n",
        "createdAt" : "2021-07-16T02:15:19Z",
        "updatedAt" : "2021-07-16T02:15:19Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "01764fbb-cfde-442d-98aa-44b4cbe3076d",
        "parentId" : "57d52384-d4e1-4f5e-9ca9-3bbf812ea13c",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Can you explain it instead of just throwing out a screenshot? What's the behavior of Hive if `NULL DEFINED AS '\\n'`?",
        "createdAt" : "2021-07-21T05:52:29Z",
        "updatedAt" : "2021-07-21T05:52:29Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "a2d2789b-ac91-4f27-8def-2026605043ad",
        "parentId" : "57d52384-d4e1-4f5e-9ca9-3bbf812ea13c",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ping @AngersZhuuuu ",
        "createdAt" : "2021-07-21T14:39:10Z",
        "updatedAt" : "2021-07-21T14:39:10Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "fa35a75b-d2d4-4b3c-8eee-6491d2823dce",
        "parentId" : "57d52384-d4e1-4f5e-9ca9-3bbf812ea13c",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> Can you explain it instead of just throwing out a screenshot? What's the behavior of Hive if `NULL DEFINED AS '\\n'`?\r\n\r\nSorry for miss this.\r\n\r\nIf hive set `NULL DEFINED AS '\\n'`, null value will be converted to `\\n` and when handle output, we split  line with `\\n` first.  then the string `\\n` for replacing null value was regarded as line separator too and split a new line.\r\nSuch as we have one line inpurt\r\n```\r\n1@true@Spark SQL@\\n\r\n```\r\n\r\nthen it will split to two line output\r\n```\r\n1@true@Spark SQL@\r\n\r\n```\r\nthe first line will be split as \"1\", \"true\", \"Spark SQL\", \"\"\r\nthe second line was split as \"\"\r\nAfter pad null value.the result is \r\n```\r\n1   true        Spark SQL\r\n     NULL     NULL              NULL\r\n```",
        "createdAt" : "2021-07-22T03:05:34Z",
        "updatedAt" : "2021-07-22T03:05:34Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "4f44917dd2b2c789ea46ca365a1b60cd5fa4ee24",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +130,134 @@  FIELDS TERMINATED BY '@'\n  LINES TERMINATED BY '\\n'\n  NULL DEFINED AS 'NULL'\nFROM t;\n"
  },
  {
    "id" : "5443078a-b232-4130-9eb2-58316b434a05",
    "prId" : 32333,
    "prUrl" : "https://github.com/apache/spark/pull/32333#pullrequestreview-644349213",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "aee8063d-3b62-42a7-abc2-6ebb05dfce72",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can we use the standard TRANSFORM syntax? Or we write the tests for hive compatibility?",
        "createdAt" : "2021-04-26T06:47:02Z",
        "updatedAt" : "2021-04-26T07:36:41Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "b4a3f1fa-9a68-4056-9f2f-3ce103745f8a",
        "parentId" : "aee8063d-3b62-42a7-abc2-6ebb05dfce72",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> can we use the standard TRANSFORM syntax? Or we write the tests for hive compatibility?\r\n\r\nYea, for compatibility, since we have less test about transform before. Since I am always checking transform use case between hive and spark. Since this is a important use case of hive's script transform, so add tests to confirm the compatibility. \r\n",
        "createdAt" : "2021-04-26T06:54:24Z",
        "updatedAt" : "2021-04-26T07:36:41Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "68f19f1f-4580-4557-a479-474867ec081a",
        "parentId" : "aee8063d-3b62-42a7-abc2-6ebb05dfce72",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Are MAP and REDUCE really compatible between Spark and Hive?",
        "createdAt" : "2021-04-26T07:27:21Z",
        "updatedAt" : "2021-04-26T07:36:41Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "d1b9da9e-06d9-41e0-a03d-11442c4e6c92",
        "parentId" : "aee8063d-3b62-42a7-abc2-6ebb05dfce72",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> Are MAP and REDUCE really compatible between Spark and Hive?\r\n\r\nRemove this two case.",
        "createdAt" : "2021-04-26T07:36:45Z",
        "updatedAt" : "2021-04-26T07:36:46Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "63ba9ff9f1de4b9bb81cefbd891b498146e21cf0",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +357,361 @@\n-- SPARK-33985: TRANSFORM with CLUSTER BY/ORDER BY/SORT BY\nFROM (\n  SELECT TRANSFORM(a, b)\n    USING 'cat' AS (a, b)"
  },
  {
    "id" : "f4cb51b1-9cc7-404a-bb6a-113e4ea882c8",
    "prId" : 29087,
    "prUrl" : "https://github.com/apache/spark/pull/29087#pullrequestreview-561824183",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "437c445f-095e-45d3-84e2-1e750f6755cc",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "These queries above are not supported in the current master?",
        "createdAt" : "2021-01-05T07:54:22Z",
        "updatedAt" : "2021-03-25T08:21:51Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "fb26dd7a-13b7-4e98-88e6-3fc567a8adf1",
        "parentId" : "437c445f-095e-45d3-84e2-1e750f6755cc",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> These queries above are not supported in the current master?\r\n\r\nSupport, what's wrong? It have a correct answer.",
        "createdAt" : "2021-01-05T07:58:30Z",
        "updatedAt" : "2021-03-25T08:21:51Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "eef94581-c979-42a2-b457-ef5af664fbc0",
        "parentId" : "437c445f-095e-45d3-84e2-1e750f6755cc",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "I just want to know why these tests are added in this PR... That's because these tests seems to be not related to aggregation/window/lateralView.",
        "createdAt" : "2021-01-05T14:05:26Z",
        "updatedAt" : "2021-03-25T08:21:51Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "1ce8c89b-518c-4667-a88a-9593900d17d8",
        "parentId" : "437c445f-095e-45d3-84e2-1e750f6755cc",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> I just want to know why these tests are added in this PR... That's because these tests seems to be not related to aggregation/window/lateralView.\r\n\r\nYea, here want to show after this pr's change, each kind of expressions can work well, such as `alias`, `case when`, `binary compute` etc...",
        "createdAt" : "2021-01-05T14:19:05Z",
        "updatedAt" : "2021-03-25T08:21:51Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "12787053aec9d015506d5c59c58e91dd23d5bb82",
    "line" : 50,
    "diffHunk" : "@@ -1,1 +224,228 @@  USING 'cat' AS (a, b, c)\nFROM script_trans\nWHERE a <= 4;\n\nSELECT TRANSFORM(b AS d, MAX(a) as max_a, CAST(SUM(c) AS STRING))"
  },
  {
    "id" : "f27ea38c-cb11-4ff2-8df9-f56eb08e52e8",
    "prId" : 29087,
    "prUrl" : "https://github.com/apache/spark/pull/29087#pullrequestreview-561580192",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "27b004b5-839f-4fee-bb50-1f86efb1fa44",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "nit: add `SET spark.sql.legacy.parser.havingWithoutGroupByAsWhere=false;`",
        "createdAt" : "2021-01-05T07:56:26Z",
        "updatedAt" : "2021-03-25T08:21:51Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "1456bcc1-e42f-4ea2-9641-e741d6f8066b",
        "parentId" : "27b004b5-839f-4fee-bb50-1f86efb1fa44",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "Done",
        "createdAt" : "2021-01-05T08:02:40Z",
        "updatedAt" : "2021-03-25T08:21:51Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "12787053aec9d015506d5c59c58e91dd23d5bb82",
    "line" : 132,
    "diffHunk" : "@@ -1,1 +306,310 @@FROM script_trans\nHAVING true;\n\nSET spark.sql.legacy.parser.havingWithoutGroupByAsWhere=false;\n"
  },
  {
    "id" : "51e5680d-6d45-4b81-b33d-7f7c1d337a19",
    "prId" : 29087,
    "prUrl" : "https://github.com/apache/spark/pull/29087#pullrequestreview-634348603",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2675c359-de62-4301-bb1b-a0eadce42176",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "nit: 2 spaces indentation",
        "createdAt" : "2021-04-13T09:03:02Z",
        "updatedAt" : "2021-04-13T09:03:02Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "12787053aec9d015506d5c59c58e91dd23d5bb82",
    "line" : 138,
    "diffHunk" : "@@ -1,1 +312,316 @@\nSELECT TRANSFORM(`(a|b)?+.+`)\n USING 'cat' AS (c)\nFROM script_trans;\n"
  },
  {
    "id" : "4a1a80ec-08b0-452c-862a-e37ad4dc44a4",
    "prId" : 29087,
    "prUrl" : "https://github.com/apache/spark/pull/29087#pullrequestreview-634362020",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "48ece01c-931d-423d-afee-ad694f327e17",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can we test something like `TRANSFORM(distinct a, b)` and check the error message?",
        "createdAt" : "2021-04-13T09:03:24Z",
        "updatedAt" : "2021-04-13T09:03:25Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "aec37a3e-364b-4f25-b7d8-bcd7295dcc87",
        "parentId" : "48ece01c-931d-423d-afee-ad694f327e17",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "Will raise a follow up soon",
        "createdAt" : "2021-04-13T09:17:00Z",
        "updatedAt" : "2021-04-13T09:17:00Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "12787053aec9d015506d5c59c58e91dd23d5bb82",
    "line" : 142,
    "diffHunk" : "@@ -1,1 +316,320 @@\nSET spark.sql.parser.quotedRegexColumnNames=false;\n\n-- SPARK-34634: self join using CTE contains transform\nWITH temp AS ("
  },
  {
    "id" : "67ceb4e3-b774-4a99-af73-9f527f45e2f1",
    "prId" : 29085,
    "prUrl" : "https://github.com/apache/spark/pull/29085#pullrequestreview-451281297",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c83a21e3-7d99-402b-b866-76bca07dac21",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "How about adding tests for the other clauses in TRANSFORM? Even if unsupported cases, I think we need tests for them.\r\nhttps://github.com/apache/spark/blob/32a0451376ab775fdd4ac364388e46179d9ee550/sql/catalyst/src/main/antlr4/org/apache/spark/sql/catalyst/parser/SqlBase.g4#L512-L521",
        "createdAt" : "2020-07-20T00:07:33Z",
        "updatedAt" : "2020-07-23T03:08:36Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "2abae5c6-760a-444c-b7a1-32f08360a69d",
        "parentId" : "c83a21e3-7d99-402b-b866-76bca07dac21",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "Added some case without serde.\r\nWith serde will show different when with/without hive",
        "createdAt" : "2020-07-20T03:56:56Z",
        "updatedAt" : "2020-07-23T03:08:36Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "03d3409f6ca641a4f10fdc2ac71479445220f676",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +6,10 @@AS t(a, b, c, d, e, f, g, h, i, j, k, l);\n\nSELECT TRANSFORM(a)\nUSING 'cat' AS (a)\nFROM t;"
  },
  {
    "id" : "9e42324d-e3f3-4057-8193-9669bbc7b431",
    "prId" : 29085,
    "prUrl" : "https://github.com/apache/spark/pull/29085#pullrequestreview-451229954",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1d44be99-de16-4d9c-8243-bf6f9369ca7b",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "How about adding `assume(TestUtils.testCommandAvailable(\"/bin/bash\"))` somewhere in `SQLQueryTestSuite`?",
        "createdAt" : "2020-07-20T00:16:10Z",
        "updatedAt" : "2020-07-23T03:08:36Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "ddc58884-971b-41d4-aa05-f1d8036fda15",
        "parentId" : "1d44be99-de16-4d9c-8243-bf6f9369ca7b",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "Yea",
        "createdAt" : "2020-07-20T01:58:09Z",
        "updatedAt" : "2020-07-23T03:08:36Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "03d3409f6ca641a4f10fdc2ac71479445220f676",
    "line" : 66,
    "diffHunk" : "@@ -1,1 +64,68 @@\nSELECT TRANSFORM(a, b)\nUSING 'cat'\nFROM t;\n"
  },
  {
    "id" : "9dd1623f-69b8-4d92-840f-8b4fabfae6fe",
    "prId" : 29085,
    "prUrl" : "https://github.com/apache/spark/pull/29085#pullrequestreview-452994465",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2d08da1c-3f6e-4b42-b923-e8fe97ffc987",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "How about the test cases, `TRANSFORM(a)` and `TRANSFORM(a, b, c...)` with schemaless enabled?",
        "createdAt" : "2020-07-22T02:35:35Z",
        "updatedAt" : "2020-07-23T03:08:36Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "8407dfef-3e32-4bc8-8604-af00e1fe10f7",
        "parentId" : "2d08da1c-3f6e-4b42-b923-e8fe97ffc987",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> schemaless\r\n\r\nDone",
        "createdAt" : "2020-07-22T04:58:49Z",
        "updatedAt" : "2020-07-23T03:08:36Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "03d3409f6ca641a4f10fdc2ac71479445220f676",
    "line" : 65,
    "diffHunk" : "@@ -1,1 +63,67 @@FROM t;\n\nSELECT TRANSFORM(a, b)\nUSING 'cat'\nFROM t;"
  },
  {
    "id" : "c66b6683-b879-47a7-a864-d5492cb08992",
    "prId" : 29085,
    "prUrl" : "https://github.com/apache/spark/pull/29085#pullrequestreview-452982867",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2eeb2348-2b0e-44dd-a7c1-59055516992f",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "nit: remove unnecessary spaces.",
        "createdAt" : "2020-07-22T02:36:44Z",
        "updatedAt" : "2020-07-23T03:08:36Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "acee495b-bb53-4b0f-bef4-e44c696645a6",
        "parentId" : "2eeb2348-2b0e-44dd-a7c1-59055516992f",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "DOne",
        "createdAt" : "2020-07-22T04:17:48Z",
        "updatedAt" : "2020-07-23T03:08:36Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "03d3409f6ca641a4f10fdc2ac71479445220f676",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +9,13 @@USING 'cat' AS (a)\nFROM t;\n\n-- with non-exist command\nSELECT TRANSFORM(a)"
  },
  {
    "id" : "88c5f2f8-eece-44f0-96c3-f502f7c8dd90",
    "prId" : 29085,
    "prUrl" : "https://github.com/apache/spark/pull/29085#pullrequestreview-453097931",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "52e68edc-35ab-4af5-8548-4832df90190c",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "nit: remove blank line.",
        "createdAt" : "2020-07-22T07:06:00Z",
        "updatedAt" : "2020-07-23T03:08:37Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "a94a99fe-2652-4a29-be62-4da32426c3ec",
        "parentId" : "52e68edc-35ab-4af5-8548-4832df90190c",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "Done",
        "createdAt" : "2020-07-22T08:01:43Z",
        "updatedAt" : "2020-07-23T03:08:37Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "3acc75ec-2cdd-4b52-846e-185ba6df94a8",
        "parentId" : "52e68edc-35ab-4af5-8548-4832df90190c",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "Done",
        "createdAt" : "2020-07-22T08:20:46Z",
        "updatedAt" : "2020-07-23T03:08:37Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "03d3409f6ca641a4f10fdc2ac71479445220f676",
    "line" : 103,
    "diffHunk" : "@@ -1,1 +101,105 @@NULL DEFINED AS 'NULL'\nFROM t;\n\nSELECT TRANSFORM(a, b, c, null)\nROW FORMAT DELIMITED"
  },
  {
    "id" : "0e346699-86a9-450c-bd8c-dff243f174de",
    "prId" : 29085,
    "prUrl" : "https://github.com/apache/spark/pull/29085#pullrequestreview-453087891",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f26c6847-eb12-42f7-ab81-69177f8d0d78",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Could you add a test for output as strings like this?\r\n```\r\n-- common supported data types between no serde and serde transform\r\nSELECT a, b, decode(c, 'UTF-8'), d, e, f, g, h, i, j, k, l FROM (\r\n    SELECT TRANSFORM(a, b, c, d, e, f, g, h, i, j, k, l)\r\n    USING 'cat' AS (\r\n        a string,\r\n        b string,\r\n        c string,\r\n        d...\r\n        ...\r\n    FROM t1\r\n) tmp;\r\n```",
        "createdAt" : "2020-07-22T07:09:58Z",
        "updatedAt" : "2020-07-23T03:08:37Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "c0eb9a08-7542-4a28-9e18-59be984113f0",
        "parentId" : "f26c6847-eb12-42f7-ab81-69177f8d0d78",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "DOne",
        "createdAt" : "2020-07-22T08:07:04Z",
        "updatedAt" : "2020-07-23T03:08:37Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "03d3409f6ca641a4f10fdc2ac71479445220f676",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +19,23 @@USING 'python some_non_existent_file' AS (a)\nFROM t;\n\n-- common supported data types between no serde and serde transform\nSELECT a, b, decode(c, 'UTF-8'), d, e, f, g, h, i, j, k, l FROM ("
  },
  {
    "id" : "bed19580-c4d5-48a7-bfa3-85a1d96fc01b",
    "prId" : 29085,
    "prUrl" : "https://github.com/apache/spark/pull/29085#pullrequestreview-453297852",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f453208c-4853-4dd7-85e3-e0c50e5bd48a",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Add the jira ID `SPARK-32388` here in the comment.",
        "createdAt" : "2020-07-22T11:52:35Z",
        "updatedAt" : "2020-07-23T03:08:37Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "28e95ea8-a888-46ce-97dc-8e0e606ec940",
        "parentId" : "f453208c-4853-4dd7-85e3-e0c50e5bd48a",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "Done",
        "createdAt" : "2020-07-22T13:07:32Z",
        "updatedAt" : "2020-07-23T03:08:37Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "03d3409f6ca641a4f10fdc2ac71479445220f676",
    "line" : 61,
    "diffHunk" : "@@ -1,1 +59,63 @@\n-- SPARK-32388 handle schema less\nSELECT TRANSFORM(a)\nUSING 'cat'\nFROM t;"
  }
]