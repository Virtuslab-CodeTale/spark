[
  {
    "id" : "8c21acbc-b792-42b2-ac60-418d3b0e9004",
    "prId" : 28766,
    "prUrl" : "https://github.com/apache/spark/pull/28766#pullrequestreview-428084975",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "91242ec2-1109-44c0-af1c-313da51512e5",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "let's add a comment to explain why we need to test csv: because it's lenient and Spark should throw upgrade exception.",
        "createdAt" : "2020-06-10T14:02:09Z",
        "updatedAt" : "2020-06-10T14:24:59Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "78c676e1d60a5c9c785b40d3b42ac756b72c54e4",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +18,22 @@-- add a special case to test csv, because the legacy formatter it uses is lenient then Spark should\n-- throw SparkUpgradeException\nselect from_csv('2018-366', 'date Date', map('dateFormat', 'yyyy-DDD'))"
  }
]