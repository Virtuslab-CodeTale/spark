[
  {
    "id" : "d41b3509-a501-423b-a7f6-a6d22c5337cd",
    "prId" : 33729,
    "prUrl" : "https://github.com/apache/spark/pull/33729#pullrequestreview-729322013",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "77d8753a-5501-4b70-93d2-1e3df79a4f4a",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "I wonder why the type is `interval year to month` but not `interval year`",
        "createdAt" : "2021-08-13T05:38:06Z",
        "updatedAt" : "2021-08-13T05:38:11Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "523ebca9-92b3-44d8-938b-647be3bee361",
        "parentId" : "77d8753a-5501-4b70-93d2-1e3df79a4f4a",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "good point. This is probably something we should fix.",
        "createdAt" : "2021-08-13T05:56:13Z",
        "updatedAt" : "2021-08-13T05:56:13Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "d07ede6b-a2b3-475d-8451-3642423bbea3",
        "parentId" : "77d8753a-5501-4b70-93d2-1e3df79a4f4a",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "I am ok to fix this in a separate PR. @gengliangwang Could you open a sub-task in https://issues.apache.org/jira/browse/SPARK-27790, please.",
        "createdAt" : "2021-08-13T06:25:16Z",
        "updatedAt" : "2021-08-13T06:25:16Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "c4e56e33-feff-49aa-aaf8-2a8762d244a7",
        "parentId" : "77d8753a-5501-4b70-93d2-1e3df79a4f4a",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "This is the data type of `DivideYMInterval`, which is the default YM interval type.",
        "createdAt" : "2021-08-13T06:34:23Z",
        "updatedAt" : "2021-08-13T06:34:23Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "503d4142-0b34-48fb-9748-59ebd7ce57ee",
        "parentId" : "77d8753a-5501-4b70-93d2-1e3df79a4f4a",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "It's to have a wider data type as the division result. Just like the following\r\n```\r\nscala> spark.sql(\"select 1 /null\")\r\nres0: org.apache.spark.sql.DataFrame = [(1 / NULL): double]\r\n```\r\n",
        "createdAt" : "2021-08-13T07:01:16Z",
        "updatedAt" : "2021-08-13T07:01:16Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "7fed7619-5729-43b2-a72a-661d25abd030",
        "parentId" : "77d8753a-5501-4b70-93d2-1e3df79a4f4a",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Got it. Thanks.",
        "createdAt" : "2021-08-13T07:05:57Z",
        "updatedAt" : "2021-08-13T07:05:57Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "b5d974d3a86fc59c3a2f1e2a072685a55cc09dff",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +130,134 @@select interval '2' year / null\n-- !query schema\nstruct<(INTERVAL '2' YEAR / NULL):interval year to month>\n-- !query output\nNULL"
  },
  {
    "id" : "7ab32b1a-c35f-4ed6-9f0f-1ecd8b21e67d",
    "prId" : 33707,
    "prUrl" : "https://github.com/apache/spark/pull/33707#pullrequestreview-727627993",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "01ca7f2a-7c56-4265-91a2-19f78de51fb4",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I think this should fail.",
        "createdAt" : "2021-08-11T15:23:14Z",
        "updatedAt" : "2021-08-11T15:23:14Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "f4d9e0527b2e7aa9aaa5521f5a057126114c4009",
    "line" : 107,
    "diffHunk" : "@@ -1,1 +1192,1196 @@\n-- !query\nselect interval '2' year - '4'\n-- !query schema\nstruct<(INTERVAL '2' YEAR - 4):interval year>"
  },
  {
    "id" : "f7cfaee4-b4fd-43ab-9bc8-18386961d816",
    "prId" : 33707,
    "prUrl" : "https://github.com/apache/spark/pull/33707#pullrequestreview-727628480",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4e084746-b6c9-47c2-a23d-498d00b164d7",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "we should cast string to interval, cc @gengliangwang ",
        "createdAt" : "2021-08-11T15:23:40Z",
        "updatedAt" : "2021-08-11T15:23:41Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "f4d9e0527b2e7aa9aaa5521f5a057126114c4009",
    "line" : 133,
    "diffHunk" : "@@ -1,1 +1205,1209 @@-- !query output\njava.time.DateTimeException\nCannot cast 4 11:11 to TimestampType.\n\n"
  },
  {
    "id" : "01a599c1-a326-4da1-a171-9fea1ab3019d",
    "prId" : 33707,
    "prUrl" : "https://github.com/apache/spark/pull/33707#pullrequestreview-727629597",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "af4c5710-f4ce-4c46-b1f3-15d159874128",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ditto",
        "createdAt" : "2021-08-11T15:24:34Z",
        "updatedAt" : "2021-08-11T15:24:35Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "f4d9e0527b2e7aa9aaa5521f5a057126114c4009",
    "line" : 151,
    "diffHunk" : "@@ -1,1 +1214,1218 @@-- !query output\njava.time.DateTimeException\nCannot cast 4 12:12:12 to TimestampType.\n\n"
  },
  {
    "id" : "73eaafe5-6ded-4387-aa3e-90725a89a652",
    "prId" : 33707,
    "prUrl" : "https://github.com/apache/spark/pull/33707#pullrequestreview-727637593",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d8307fe3-6331-43fb-b85f-4c45660a75a8",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This is also a bug, cc @gengliangwang ",
        "createdAt" : "2021-08-11T15:31:16Z",
        "updatedAt" : "2021-08-11T15:31:17Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "f4d9e0527b2e7aa9aaa5521f5a057126114c4009",
    "line" : 79,
    "diffHunk" : "@@ -1,1 +1179,1183 @@-- !query output\norg.apache.spark.sql.AnalysisException\ncannot resolve 'CAST(CAST(NULL AS TIMESTAMP) + INTERVAL '02' HOUR AS VOID)' due to data type mismatch: cannot cast timestamp to void; line 4 pos 2\n\n"
  },
  {
    "id" : "d5ab4e8b-f4df-4322-b7f2-c4badd8712ef",
    "prId" : 32949,
    "prUrl" : "https://github.com/apache/spark/pull/32949#pullrequestreview-703206093",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d4a25040-88f6-4dc5-9927-b6b54ebdfb99",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "hmm, so we always print 9 digits for second even if our precision is only microsecond?",
        "createdAt" : "2021-07-09T16:07:54Z",
        "updatedAt" : "2021-07-09T16:07:54Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "43536391-8009-40f7-a0c1-0ca9e73dd9fd",
        "parentId" : "d4a25040-88f6-4dc5-9927-b6b54ebdfb99",
        "authorId" : "3a227965-84e0-47cf-9974-11293764f028",
        "body" : "If a query runs through `SparkSQLDriver`, `HIVE_STYLE` is applied. It's not a scope of this change.",
        "createdAt" : "2021-07-09T16:15:46Z",
        "updatedAt" : "2021-07-09T16:15:47Z",
        "lastEditedBy" : "3a227965-84e0-47cf-9974-11293764f028",
        "tags" : [
        ]
      }
    ],
    "commit" : "48f080fc5b3bb2a2d704a0cc6bddb8d6be56f328",
    "line" : 37,
    "diffHunk" : "@@ -1,1 +38,42 @@struct<(INTERVAL '14 00:00:00.000003' DAY TO SECOND * 1.5):interval day to second>\n-- !query output\n21 00:00:00.000005000\n\n"
  },
  {
    "id" : "631bf27f-a02a-40a7-9288-dcb75edecd94",
    "prId" : 32949,
    "prUrl" : "https://github.com/apache/spark/pull/32949#pullrequestreview-703261837",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dca2f8b2-bd6b-4971-b6cc-5272797cb832",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "In CSV, we ignore the interval fields and always print the full format of interval strings? I thought CSV will print `1` for `interval 1 day`.",
        "createdAt" : "2021-07-09T16:12:13Z",
        "updatedAt" : "2021-07-09T16:12:13Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "2e8199c3-28ff-4634-9528-52f8be6546f3",
        "parentId" : "dca2f8b2-bd6b-4971-b6cc-5272797cb832",
        "authorId" : "3a227965-84e0-47cf-9974-11293764f028",
        "body" : "The behavior of `to_csv` for ANSI intervals were changed in #33210.",
        "createdAt" : "2021-07-09T16:29:05Z",
        "updatedAt" : "2021-07-09T16:37:47Z",
        "lastEditedBy" : "3a227965-84e0-47cf-9974-11293764f028",
        "tags" : [
        ]
      },
      {
        "id" : "7d603ce8-c4e6-46e8-8f79-5f8d72fc21c2",
        "parentId" : "dca2f8b2-bd6b-4971-b6cc-5272797cb832",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ah I got it now. `{\"a\":1,\"b\":1 00:00:00.000000000}` is the HIVE_STYLE interval string format, which does not respect the interval fields.",
        "createdAt" : "2021-07-09T17:32:27Z",
        "updatedAt" : "2021-07-09T17:32:27Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "48f080fc5b3bb2a2d704a0cc6bddb8d6be56f328",
    "line" : 371,
    "diffHunk" : "@@ -1,1 +1413,1417 @@struct<from_csv(1, 1 day):struct<a:int,b:interval>,from_csv(1, 1):struct<a:int,b:interval day>,to_csv(from_csv(1, 1 day)):string,to_csv(from_csv(1, 1)):string,to_csv(named_struct(a, INTERVAL '32' HOUR, b, INTERVAL '70' MINUTE)):string,from_csv(to_csv(named_struct(a, INTERVAL '32' HOUR, b, INTERVAL '70' MINUTE))):struct<a:interval hour,b:interval minute>>\n-- !query output\n{\"a\":1,\"b\":1 days}\t{\"a\":1,\"b\":1 00:00:00.000000000}\t1,1 days\t1,INTERVAL '1' DAY\tINTERVAL '32' HOUR,INTERVAL '70' MINUTE\t{\"a\":1 08:00:00.000000000,\"b\":0 01:10:00.000000000}\n\n"
  },
  {
    "id" : "cd2250ed-35ab-4b99-9517-bace400a1a68",
    "prId" : 32850,
    "prUrl" : "https://github.com/apache/spark/pull/32850#pullrequestreview-689761946",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f8dbcdb7-f501-42b6-ab22-53f3ff3ed00e",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "So we allow changing the exception type. Then can we make `SparkError` a concrete exception class and eventually throw `SparkError` everywhere?",
        "createdAt" : "2021-06-22T13:33:25Z",
        "updatedAt" : "2021-06-22T13:33:25Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "0a2ad686-1426-4a5e-9b27-91ef50743d6e",
        "parentId" : "f8dbcdb7-f501-42b6-ab22-53f3ff3ed00e",
        "authorId" : "ada71464-b8c9-4d7b-9020-d49c27251fdb",
        "body" : "My goal here was to create a single trait that exposes the fields we're looking for, such as `sqlState`. By mixing it with base exception types like `java.lang.ArithmeticException` rather than creating a concrete exception class, I'm hoping that we can minimize backwards compatibility issues.",
        "createdAt" : "2021-06-22T16:46:00Z",
        "updatedAt" : "2021-06-22T16:46:00Z",
        "lastEditedBy" : "ada71464-b8c9-4d7b-9020-d49c27251fdb",
        "tags" : [
        ]
      }
    ],
    "commit" : "6d8e915ca62806f511588134a57bbeca99361d86",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +68,72 @@struct<>\n-- !query output\norg.apache.spark.SparkArithmeticException\ndivide by zero\n"
  },
  {
    "id" : "e4417b00-4c8f-4fe3-b529-dbfd3f642632",
    "prId" : 32176,
    "prUrl" : "https://github.com/apache/spark/pull/32176#pullrequestreview-636721907",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f1bb64ae-16fa-45b5-a0a5-fab4294affab",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "shall we run `interval.sql` one more time with legacy config enabled? by using `--IMPORT`",
        "createdAt" : "2021-04-15T13:58:57Z",
        "updatedAt" : "2021-04-16T11:24:15Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "7668405ebd902cea698b76c373d0c06b1e759426",
    "line" : 1,
    "diffHunk" : "@@ -1,1 +11,15 @@\n\n-- !query\nselect interval 4 month 2 weeks 3 microseconds * 1.5\n-- !query schema"
  },
  {
    "id" : "d33cbe68-9a67-4efb-8de9-5a48e530cf13",
    "prId" : 29560,
    "prUrl" : "https://github.com/apache/spark/pull/29560#pullrequestreview-476935318",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e83d37e1-26f6-427f-bbed-bed8c49575fd",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This is a positive change. It's pretty weird that `30 days days` works but `30 day day` does not, under ANSI mode.\r\n\r\nIn general, this PR makes things more lenient.",
        "createdAt" : "2020-08-27T17:28:54Z",
        "updatedAt" : "2020-08-28T04:46:32Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "264e48d71500ca9252191600c17cda1212d3ca4d",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +358,362 @@struct<day:interval>\n-- !query output\n30 days\n\n"
  },
  {
    "id" : "786589eb-ac2d-4608-b2e3-6f719fda8886",
    "prId" : 29560,
    "prUrl" : "https://github.com/apache/spark/pull/29560#pullrequestreview-476936029",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "105f3e67-4316-4e6f-8a3e-df1c410fd49a",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ditto, it's better to make `day` and `days` have consistent behavior/error message.",
        "createdAt" : "2020-08-27T17:29:49Z",
        "updatedAt" : "2020-08-28T04:46:32Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "264e48d71500ca9252191600c17cda1212d3ca4d",
    "line" : 37,
    "diffHunk" : "@@ -1,1 +659,663 @@-- !query output\norg.apache.spark.sql.AnalysisException\nUndefined function: 'interval'. This function is neither a registered temporary function nor a permanent function registered in the database 'default'.; line 1 pos 7\n\n"
  },
  {
    "id" : "becf8dff-f808-4553-8043-a2c96897deb7",
    "prId" : 28402,
    "prUrl" : "https://github.com/apache/spark/pull/28402#pullrequestreview-403230208",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c411c9d1-84cf-4d3a-8997-eddda0f38094",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Just to check; why is the table name added in the output schema?",
        "createdAt" : "2020-04-29T22:46:36Z",
        "updatedAt" : "2020-04-29T22:46:36Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "d463652d-a86a-4956-b46c-dea8378658cd",
        "parentId" : "c411c9d1-84cf-4d3a-8997-eddda0f38094",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "This is because this expression is being runtime replaced, so the `AttiributeReference`s here are not getting the chance to become a `PettyAttribute` to not print a debug style string.\r\n\r\nYou may take a look at the `Extract` expression which is newly added by yourself as an example, https://github.com/apache/spark/blob/ea525fe8c0cc6336a7ba8d98bada3198795f8aed/sql/core/src/test/resources/sql-tests/results/extract.sql.out#L16\r\n\r\nIf we are going to make pretty strings for `RuntimeReplaceable` expressions, I think we should do this for them all in separate PR explicitly. WDYT?\r\n",
        "createdAt" : "2020-04-30T02:39:25Z",
        "updatedAt" : "2020-04-30T02:47:17Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "92a9f18c-4a60-4eda-89f2-6ac0209c1919",
        "parentId" : "c411c9d1-84cf-4d3a-8997-eddda0f38094",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "makes sense, let's fix it in a followup.",
        "createdAt" : "2020-04-30T03:25:51Z",
        "updatedAt" : "2020-04-30T03:25:52Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "0e4d470b-79a3-42f9-bd20-96681b94d233",
        "parentId" : "c411c9d1-84cf-4d3a-8997-eddda0f38094",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "+1 on the fix. Thanks for the explanation, @yaooqinn ",
        "createdAt" : "2020-04-30T05:13:24Z",
        "updatedAt" : "2020-04-30T05:13:25Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "ff2419d2-0a01-4e7e-ada0-42685ddbca44",
        "parentId" : "c411c9d1-84cf-4d3a-8997-eddda0f38094",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "thank you all, I will fix this ASAP.",
        "createdAt" : "2020-04-30T06:17:49Z",
        "updatedAt" : "2020-04-30T06:17:50Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "bc1bacca0696c9150e4ec7a837add7972563dc57",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +690,694 @@from interval_arithmetic\n-- !query schema\nstruct<dateval:date,interval_arithmetic.`dateval` - INTERVAL '2 years 2 months':date,interval_arithmetic.`dateval` - INTERVAL '-2 years -2 months':date,dateval + INTERVAL '2 years 2 months':date,dateval + INTERVAL '-2 years -2 months':date,dateval + (- INTERVAL '2 years 2 months'):date,dateval + INTERVAL '2 years 2 months':date>\n-- !query output\n2012-01-01\t2009-11-01\t2014-03-01\t2014-03-01\t2009-11-01\t2009-11-01\t2014-03-01"
  },
  {
    "id" : "b375decc-7331-4357-a072-60129c11bfa3",
    "prId" : 26815,
    "prUrl" : "https://github.com/apache/spark/pull/26815#pullrequestreview-371845971",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "85603ae3-53fe-4a32-a66d-6e5792396dd9",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "not related to this PR, but we should only ask users to set the legacy config if it works.",
        "createdAt" : "2020-03-10T10:47:33Z",
        "updatedAt" : "2020-03-10T10:47:39Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "4556ad4f01dcbb68892ccc9f25ad4ae92384e8c0",
    "line" : 49,
    "diffHunk" : "@@ -1,1 +843,847 @@\nrequirement failed: Interval string must match day-time format of '^(?<sign>[+|-])?(?<day>\\d+) (?<hour>\\d{1,2}):(?<minute>\\d{1,2}):(?<second>(\\d{1,2})(\\.(\\d{1,9}))?)$': \n-\t10\t 12:34:46.789\t, set spark.sql.legacy.fromDayTimeString.enabled to true to restore the behavior before Spark 3.0.(line 1, pos 16)\n\n== SQL =="
  },
  {
    "id" : "5d808dec-cb27-4f96-a103-226be554f9c8",
    "prId" : 26592,
    "prUrl" : "https://github.com/apache/spark/pull/26592#pullrequestreview-318888483",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2186e0d7-c5a0-4427-be88-fe2c180488a5",
        "parentId" : null,
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "```sql\r\npostgres=# select interval '13.123456789 seconds';\r\n    interval\r\n-----------------\r\n 00:00:13.123457\r\n(1 row)\r\n\r\npostgres=# select interval '-13.123456789 seconds';\r\n     interval\r\n------------------\r\n -00:00:13.123457\r\n(1 row)\r\n```",
        "createdAt" : "2019-11-19T09:28:25Z",
        "updatedAt" : "2019-11-27T06:08:31Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "fe3e6bad7e0e8d53c751a042343c03c277dfaf8d",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +482,486 @@struct<INTERVAL '13.123457 seconds':interval,INTERVAL '-13.123457 seconds':interval>\n-- !query 59 output\n13.123457 seconds\t-13.123457 seconds\n\n"
  },
  {
    "id" : "197f1567-b286-44bd-9a71-224192590371",
    "prId" : 26134,
    "prUrl" : "https://github.com/apache/spark/pull/26134#pullrequestreview-302502165",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "83b20931-8f1d-4f67-b8be-c44ff0403d6e",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Why it there difference of 1 hour?",
        "createdAt" : "2019-10-16T08:51:06Z",
        "updatedAt" : "2019-11-01T05:44:12Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "08d7eb84-0f07-48f0-b5aa-b3f1ec95b22d",
        "parentId" : "83b20931-8f1d-4f67-b8be-c44ff0403d6e",
        "authorId" : "58a5dec8-caad-405f-b8fe-9510071c1cb9",
        "body" : "as you know it's caused by daylight saving",
        "createdAt" : "2019-10-16T11:27:48Z",
        "updatedAt" : "2019-11-01T05:44:12Z",
        "lastEditedBy" : "58a5dec8-caad-405f-b8fe-9510071c1cb9",
        "tags" : [
        ]
      }
    ],
    "commit" : "2f901894eb24d7deec31947708b9afdaae2a4866",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +239,243 @@struct<tsval:timestamp,CAST(tsval - interval 14 weeks 1 days 11 hours 22 minutes 33 seconds 123 milliseconds 456 microseconds AS TIMESTAMP):timestamp,CAST(tsval - interval -14 weeks -1 days -11 hours -22 minutes -33 seconds -123 milliseconds -456 microseconds AS TIMESTAMP):timestamp,CAST(tsval + interval 14 weeks 1 days 11 hours 22 minutes 33 seconds 123 milliseconds 456 microseconds AS TIMESTAMP):timestamp,CAST(tsval + interval -14 weeks -1 days -11 hours -22 minutes -33 seconds -123 milliseconds -456 microseconds AS TIMESTAMP):timestamp,CAST(tsval + (- interval 14 weeks 1 days 11 hours 22 minutes 33 seconds 123 milliseconds 456 microseconds) AS TIMESTAMP):timestamp,CAST(tsval + interval 14 weeks 1 days 11 hours 22 minutes 33 seconds 123 milliseconds 456 microseconds AS TIMESTAMP):timestamp>\n-- !query 17 output\n2012-01-01 00:00:00\t2011-09-23 12:37:26.876544\t2012-04-09 11:22:33.123456\t2012-04-09 11:22:33.123456\t2011-09-23 12:37:26.876544\t2011-09-23 12:37:26.876544\t2012-04-09 11:22:33.123456\n\n"
  }
]