[
  {
    "id" : "d41b3509-a501-423b-a7f6-a6d22c5337cd",
    "prId" : 33729,
    "prUrl" : "https://github.com/apache/spark/pull/33729#pullrequestreview-729322013",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "77d8753a-5501-4b70-93d2-1e3df79a4f4a",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "I wonder why the type is `interval year to month` but not `interval year`",
        "createdAt" : "2021-08-13T05:38:06Z",
        "updatedAt" : "2021-08-13T05:38:11Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "523ebca9-92b3-44d8-938b-647be3bee361",
        "parentId" : "77d8753a-5501-4b70-93d2-1e3df79a4f4a",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "good point. This is probably something we should fix.",
        "createdAt" : "2021-08-13T05:56:13Z",
        "updatedAt" : "2021-08-13T05:56:13Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "d07ede6b-a2b3-475d-8451-3642423bbea3",
        "parentId" : "77d8753a-5501-4b70-93d2-1e3df79a4f4a",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "I am ok to fix this in a separate PR. @gengliangwang Could you open a sub-task in https://issues.apache.org/jira/browse/SPARK-27790, please.",
        "createdAt" : "2021-08-13T06:25:16Z",
        "updatedAt" : "2021-08-13T06:25:16Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "c4e56e33-feff-49aa-aaf8-2a8762d244a7",
        "parentId" : "77d8753a-5501-4b70-93d2-1e3df79a4f4a",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "This is the data type of `DivideYMInterval`, which is the default YM interval type.",
        "createdAt" : "2021-08-13T06:34:23Z",
        "updatedAt" : "2021-08-13T06:34:23Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "503d4142-0b34-48fb-9748-59ebd7ce57ee",
        "parentId" : "77d8753a-5501-4b70-93d2-1e3df79a4f4a",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "It's to have a wider data type as the division result. Just like the following\r\n```\r\nscala> spark.sql(\"select 1 /null\")\r\nres0: org.apache.spark.sql.DataFrame = [(1 / NULL): double]\r\n```\r\n",
        "createdAt" : "2021-08-13T07:01:16Z",
        "updatedAt" : "2021-08-13T07:01:16Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "7fed7619-5729-43b2-a72a-661d25abd030",
        "parentId" : "77d8753a-5501-4b70-93d2-1e3df79a4f4a",
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Got it. Thanks.",
        "createdAt" : "2021-08-13T07:05:57Z",
        "updatedAt" : "2021-08-13T07:05:57Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "b5d974d3a86fc59c3a2f1e2a072685a55cc09dff",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +130,134 @@select interval '2' year / null\n-- !query schema\nstruct<(INTERVAL '2' YEAR / NULL):interval year to month>\n-- !query output\nNULL"
  },
  {
    "id" : "7ab32b1a-c35f-4ed6-9f0f-1ecd8b21e67d",
    "prId" : 33707,
    "prUrl" : "https://github.com/apache/spark/pull/33707#pullrequestreview-727627993",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "01ca7f2a-7c56-4265-91a2-19f78de51fb4",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I think this should fail.",
        "createdAt" : "2021-08-11T15:23:14Z",
        "updatedAt" : "2021-08-11T15:23:14Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "f4d9e0527b2e7aa9aaa5521f5a057126114c4009",
    "line" : 107,
    "diffHunk" : "@@ -1,1 +1192,1196 @@\n-- !query\nselect interval '2' year - '4'\n-- !query schema\nstruct<(INTERVAL '2' YEAR - 4):interval year>"
  },
  {
    "id" : "f7cfaee4-b4fd-43ab-9bc8-18386961d816",
    "prId" : 33707,
    "prUrl" : "https://github.com/apache/spark/pull/33707#pullrequestreview-727628480",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4e084746-b6c9-47c2-a23d-498d00b164d7",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "we should cast string to interval, cc @gengliangwang ",
        "createdAt" : "2021-08-11T15:23:40Z",
        "updatedAt" : "2021-08-11T15:23:41Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "f4d9e0527b2e7aa9aaa5521f5a057126114c4009",
    "line" : 133,
    "diffHunk" : "@@ -1,1 +1205,1209 @@-- !query output\njava.time.DateTimeException\nCannot cast 4 11:11 to TimestampType.\n\n"
  },
  {
    "id" : "01a599c1-a326-4da1-a171-9fea1ab3019d",
    "prId" : 33707,
    "prUrl" : "https://github.com/apache/spark/pull/33707#pullrequestreview-727629597",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "af4c5710-f4ce-4c46-b1f3-15d159874128",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ditto",
        "createdAt" : "2021-08-11T15:24:34Z",
        "updatedAt" : "2021-08-11T15:24:35Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "f4d9e0527b2e7aa9aaa5521f5a057126114c4009",
    "line" : 151,
    "diffHunk" : "@@ -1,1 +1214,1218 @@-- !query output\njava.time.DateTimeException\nCannot cast 4 12:12:12 to TimestampType.\n\n"
  },
  {
    "id" : "73eaafe5-6ded-4387-aa3e-90725a89a652",
    "prId" : 33707,
    "prUrl" : "https://github.com/apache/spark/pull/33707#pullrequestreview-727637593",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d8307fe3-6331-43fb-b85f-4c45660a75a8",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This is also a bug, cc @gengliangwang ",
        "createdAt" : "2021-08-11T15:31:16Z",
        "updatedAt" : "2021-08-11T15:31:17Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "f4d9e0527b2e7aa9aaa5521f5a057126114c4009",
    "line" : 79,
    "diffHunk" : "@@ -1,1 +1179,1183 @@-- !query output\norg.apache.spark.sql.AnalysisException\ncannot resolve 'CAST(CAST(NULL AS TIMESTAMP) + INTERVAL '02' HOUR AS VOID)' due to data type mismatch: cannot cast timestamp to void; line 4 pos 2\n\n"
  },
  {
    "id" : "d5ab4e8b-f4df-4322-b7f2-c4badd8712ef",
    "prId" : 32949,
    "prUrl" : "https://github.com/apache/spark/pull/32949#pullrequestreview-703206093",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d4a25040-88f6-4dc5-9927-b6b54ebdfb99",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "hmm, so we always print 9 digits for second even if our precision is only microsecond?",
        "createdAt" : "2021-07-09T16:07:54Z",
        "updatedAt" : "2021-07-09T16:07:54Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "43536391-8009-40f7-a0c1-0ca9e73dd9fd",
        "parentId" : "d4a25040-88f6-4dc5-9927-b6b54ebdfb99",
        "authorId" : "3a227965-84e0-47cf-9974-11293764f028",
        "body" : "If a query runs through `SparkSQLDriver`, `HIVE_STYLE` is applied. It's not a scope of this change.",
        "createdAt" : "2021-07-09T16:15:46Z",
        "updatedAt" : "2021-07-09T16:15:47Z",
        "lastEditedBy" : "3a227965-84e0-47cf-9974-11293764f028",
        "tags" : [
        ]
      }
    ],
    "commit" : "48f080fc5b3bb2a2d704a0cc6bddb8d6be56f328",
    "line" : 37,
    "diffHunk" : "@@ -1,1 +38,42 @@struct<(INTERVAL '14 00:00:00.000003' DAY TO SECOND * 1.5):interval day to second>\n-- !query output\n21 00:00:00.000005000\n\n"
  },
  {
    "id" : "631bf27f-a02a-40a7-9288-dcb75edecd94",
    "prId" : 32949,
    "prUrl" : "https://github.com/apache/spark/pull/32949#pullrequestreview-703261837",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dca2f8b2-bd6b-4971-b6cc-5272797cb832",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "In CSV, we ignore the interval fields and always print the full format of interval strings? I thought CSV will print `1` for `interval 1 day`.",
        "createdAt" : "2021-07-09T16:12:13Z",
        "updatedAt" : "2021-07-09T16:12:13Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "2e8199c3-28ff-4634-9528-52f8be6546f3",
        "parentId" : "dca2f8b2-bd6b-4971-b6cc-5272797cb832",
        "authorId" : "3a227965-84e0-47cf-9974-11293764f028",
        "body" : "The behavior of `to_csv` for ANSI intervals were changed in #33210.",
        "createdAt" : "2021-07-09T16:29:05Z",
        "updatedAt" : "2021-07-09T16:37:47Z",
        "lastEditedBy" : "3a227965-84e0-47cf-9974-11293764f028",
        "tags" : [
        ]
      },
      {
        "id" : "7d603ce8-c4e6-46e8-8f79-5f8d72fc21c2",
        "parentId" : "dca2f8b2-bd6b-4971-b6cc-5272797cb832",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ah I got it now. `{\"a\":1,\"b\":1 00:00:00.000000000}` is the HIVE_STYLE interval string format, which does not respect the interval fields.",
        "createdAt" : "2021-07-09T17:32:27Z",
        "updatedAt" : "2021-07-09T17:32:27Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "48f080fc5b3bb2a2d704a0cc6bddb8d6be56f328",
    "line" : 371,
    "diffHunk" : "@@ -1,1 +1413,1417 @@struct<from_csv(1, 1 day):struct<a:int,b:interval>,from_csv(1, 1):struct<a:int,b:interval day>,to_csv(from_csv(1, 1 day)):string,to_csv(from_csv(1, 1)):string,to_csv(named_struct(a, INTERVAL '32' HOUR, b, INTERVAL '70' MINUTE)):string,from_csv(to_csv(named_struct(a, INTERVAL '32' HOUR, b, INTERVAL '70' MINUTE))):struct<a:interval hour,b:interval minute>>\n-- !query output\n{\"a\":1,\"b\":1 days}\t{\"a\":1,\"b\":1 00:00:00.000000000}\t1,1 days\t1,INTERVAL '1' DAY\tINTERVAL '32' HOUR,INTERVAL '70' MINUTE\t{\"a\":1 08:00:00.000000000,\"b\":0 01:10:00.000000000}\n\n"
  }
]