[
  {
    "id" : "e04147fe-14d3-477d-b82f-ffe477fb4a17",
    "prId" : 33424,
    "prUrl" : "https://github.com/apache/spark/pull/33424#pullrequestreview-710152200",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a70bed50-ce38-4564-a0f3-d3a36d71c898",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "what was the result  before this PR?",
        "createdAt" : "2021-07-20T03:24:33Z",
        "updatedAt" : "2021-07-20T03:24:34Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "76b6f4c4-8b06-4d5d-ab16-4b24a00120bc",
        "parentId" : "a70bed50-ce38-4564-a0f3-d3a36d71c898",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "```\r\n+-- !query\r\n+DESC EXTENDED t PARTITION (C='Us', D=1)\r\n+-- !query schema\r\n+struct<>\r\n+-- !query output\r\n+org.apache.spark.sql.AnalysisException\r\n+Partition spec is invalid. The spec (C, D) must match the partition spec (c, d) defined in table '`default`.`t`'\r\n+\r\n```",
        "createdAt" : "2021-07-20T03:41:38Z",
        "updatedAt" : "2021-07-20T03:41:38Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "ce08ba43bcc6df16ffe72cd7f1932a14e424c72b",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +326,330 @@\n-- !query\nDESC EXTENDED t PARTITION (C='Us', D=1)\n-- !query schema\nstruct<col_name:string,data_type:string,comment:string>"
  },
  {
    "id" : "1683c165-645c-447f-8050-46d08f5ee773",
    "prId" : 30881,
    "prUrl" : "https://github.com/apache/spark/pull/30881#pullrequestreview-559343671",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5b0c4d94-7a6a-4980-86c9-0cca3cef8fb8",
        "parentId" : null,
        "authorId" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "body" : "Now that attribute is resolved, a fully qualified name is passed to `DescribeColumnCommand`",
        "createdAt" : "2020-12-29T00:46:15Z",
        "updatedAt" : "2020-12-30T16:14:02Z",
        "lastEditedBy" : "b14448be-63dd-4b59-ab38-deeb2a38de86",
        "tags" : [
        ]
      }
    ],
    "commit" : "a19f5f0b965d6c9dc59f1963ce6296e1639df751",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +562,566 @@== Physical Plan ==\nExecute DescribeColumnCommand\n   +- DescribeColumnCommand `default`.`t`, [spark_catalog, default, t, b], false\n\n"
  },
  {
    "id" : "0a2b445d-f552-4506-bc2c-77941c4b4208",
    "prId" : 27550,
    "prUrl" : "https://github.com/apache/spark/pull/27550#pullrequestreview-358205057",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "aa0f1d38-108e-47ad-83a1-a4affe096c66",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "This is the consequence of removing the hack. Now `ResolvedTable` can get qualified table name even from session catalog.",
        "createdAt" : "2020-02-13T13:15:32Z",
        "updatedAt" : "2020-02-14T10:56:14Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "f4a3d08d096ee44d2fc7bf5d23f6223f9700865a",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +531,535 @@== Physical Plan ==\nExecute DescribeTableCommand\n   +- DescribeTableCommand `default`.`t`, true\n\n"
  }
]