[
  {
    "id" : "cb7eae75-54e1-4b87-94fe-6290bd50083f",
    "prId" : 32995,
    "prUrl" : "https://github.com/apache/spark/pull/32995#pullrequestreview-688654745",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b54b872c-3f11-47d3-92f1-524108dc936b",
        "parentId" : null,
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "I will have a follow up to improve the error message.\r\nThis error message is used in multiple SQL output files and some of them are not related to this PR.",
        "createdAt" : "2021-06-21T07:47:19Z",
        "updatedAt" : "2021-06-21T07:47:25Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "2d4f1be1-e8ce-48fe-a66a-73ccfdd88b35",
        "parentId" : "b54b872c-3f11-47d3-92f1-524108dc936b",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "good point. The new function should bypass this upgrade check in the timestamp formatter.",
        "createdAt" : "2021-06-21T16:40:34Z",
        "updatedAt" : "2021-06-21T16:40:34Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "d5afd6abdb6eb56e91b2d95b0fecad6468d2a64b",
    "line" : 323,
    "diffHunk" : "@@ -1,1 +1221,1225 @@-- !query output\norg.apache.spark.SparkUpgradeException\nYou may get a different result due to the upgrading of Spark 3.0: Fail to recognize 'yyyy-MM-dd GGGGG' pattern in the DateTimeFormatter. 1) You can set spark.sql.legacy.timeParserPolicy to LEGACY to restore the behavior before Spark 3.0. 2) You can form a valid datetime pattern with the guide from https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html\n\n"
  }
]