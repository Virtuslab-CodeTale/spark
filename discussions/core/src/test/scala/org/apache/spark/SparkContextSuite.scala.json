[
  {
    "id" : "c355eaa4-7673-4c8e-b4c6-762f2be25d04",
    "prId" : 31515,
    "prUrl" : "https://github.com/apache/spark/pull/31515#pullrequestreview-585102643",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a0fda6eb-3a50-4b11-8d6f-11fb8f58c674",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "This is still a `Hadoop` conf although it's `Overlay` property.",
        "createdAt" : "2021-02-08T00:30:11Z",
        "updatedAt" : "2021-02-08T00:30:11Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "189cddf23b30147812ce3761573f49914380cd82",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +1156,1160 @@    val bufferKey = \"io.file.buffer.size\"\n    val hadoopConf0 = new Configuration()\n    hadoopConf0.set(testKey, \"/tmp/hive_zero\")\n\n    val hiveConfFile = Utils.getContextOrSparkClassLoader.getResource(\"hive-site.xml\")"
  },
  {
    "id" : "ffb12959-c994-4ac9-9734-edb434510094",
    "prId" : 31515,
    "prUrl" : "https://github.com/apache/spark/pull/31515#pullrequestreview-585124206",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ddb34ae3-1c2f-45d9-b489-ba0f07d0ea63",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "This is okay because Apache Spark UT aims to test line 1170 ~ 1172.\r\n```\r\n    assert(sc.hadoopConfiguration.get(testKey) === \"/tmp/hive_one\",\r\n      \"hive configs have higher priority than hadoop ones \")\r\n    assert(sc.hadoopConfiguration.get(bufferKey).toInt === 65536,\r\n      \"spark configs have higher priority than hive ones\")\r\n```",
        "createdAt" : "2021-02-08T00:33:14Z",
        "updatedAt" : "2021-02-08T00:33:14Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "6b83c108-a721-4596-833e-5b2960ae7267",
        "parentId" : "ddb34ae3-1c2f-45d9-b489-ba0f07d0ea63",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "w/ this change, `\"/tmp/hive_one\"` in `hive-site.xml` overlays `\"/tmp/hive_{user}\"` not  `\"/tmp/hive_zero\"`, which happens in `SparkHadoopUtil.appendS3AndSparkHadoopHiveConfigurations`.\r\n\r\nAs `hadoopConf0` is not passed to `SparkHadoopUtil`, while `core-site.xml` is, so here to reduce test flakiness, we can remove those `assert`s for `hadoopConf0`, as they are just used to check `hive-site.xml` overrides `core-site.xml`. ",
        "createdAt" : "2021-02-08T01:26:21Z",
        "updatedAt" : "2021-02-08T01:26:21Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "9485901e-de90-43ae-93ca-bd7c95c333c3",
        "parentId" : "ddb34ae3-1c2f-45d9-b489-ba0f07d0ea63",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "@yaooqinn, can you open a PR for that, or push some changes into this PR? I think the test is not flaky but broken. It doesn't look obvious because we don't always run YarnClusterSuite.",
        "createdAt" : "2021-02-08T02:27:16Z",
        "updatedAt" : "2021-02-08T02:27:16Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "189cddf23b30147812ce3761573f49914380cd82",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +1161,1165 @@    assert(hiveConfFile != null)\n    hadoopConf0.addResource(hiveConfFile)\n    assert(hadoopConf0.get(testKey) === \"/tmp/hive_zero\")\n    assert(hadoopConf0.get(bufferKey) === \"201811\")\n"
  }
]