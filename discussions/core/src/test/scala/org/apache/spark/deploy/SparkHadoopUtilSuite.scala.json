[
  {
    "id" : "91f239e9-cd18-4b92-8e96-d3a18358936d",
    "prId" : 33064,
    "prUrl" : "https://github.com/apache/spark/pull/33064#pullrequestreview-692759847",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "765764f2-9a25-4104-98f3-c6dff805a307",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Thank you for adding this.",
        "createdAt" : "2021-06-25T12:20:09Z",
        "updatedAt" : "2021-06-25T12:20:09Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "4116751df2f413e8da4130e704e996811b91d7e0",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +34,38 @@    new SparkHadoopUtil().appendSparkHadoopConfigs(sc, hadoopConf)\n    assertConfigValue(hadoopConf, \"orc.filterPushdown\", \"true\" )\n    assertConfigValue(hadoopConf, \"fs.s3a.downgrade.syncable.exceptions\", \"true\")\n    assertConfigValue(hadoopConf, \"fs.s3a.endpoint\", \"s3.amazonaws.com\")\n  }"
  }
]