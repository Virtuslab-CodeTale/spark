[
  {
    "id" : "51821ebb-c44f-4678-9504-836282df0d24",
    "prId" : 26916,
    "prUrl" : "https://github.com/apache/spark/pull/26916#pullrequestreview-332993384",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ef2e978b-b323-4184-a776-f298d64e3463",
        "parentId" : null,
        "authorId" : "bc001dd4-5224-4ca1-afdd-49d69783d7f2",
        "body" : "We should ensure the content in the output file is correct.",
        "createdAt" : "2019-12-17T02:27:02Z",
        "updatedAt" : "2019-12-17T02:27:03Z",
        "lastEditedBy" : "bc001dd4-5224-4ca1-afdd-49d69783d7f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "559c45c697ff7b207275e6549c6b8f6396a8e32b",
    "line" : 39,
    "diffHunk" : "@@ -1,1 +727,731 @@    val outputFilePath1 = new File(tempDir, \"/out1\").getAbsolutePath\n    pairRDD.saveAsTextFile(outputFilePath1)\n    assert(sc.textFile(outputFilePath1).collect() === Array(\"(1,1)\", \"(2,2)\", \"(3,3)\"))\n\n    // Test saveAsNewAPIHadoopDataset()"
  }
]