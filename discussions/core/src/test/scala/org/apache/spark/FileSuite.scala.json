[
  {
    "id" : "51821ebb-c44f-4678-9504-836282df0d24",
    "prId" : 26916,
    "prUrl" : "https://github.com/apache/spark/pull/26916#pullrequestreview-332993384",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ef2e978b-b323-4184-a776-f298d64e3463",
        "parentId" : null,
        "authorId" : "bc001dd4-5224-4ca1-afdd-49d69783d7f2",
        "body" : "We should ensure the content in the output file is correct.",
        "createdAt" : "2019-12-17T02:27:02Z",
        "updatedAt" : "2019-12-17T02:27:03Z",
        "lastEditedBy" : "bc001dd4-5224-4ca1-afdd-49d69783d7f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "559c45c697ff7b207275e6549c6b8f6396a8e32b",
    "line" : 39,
    "diffHunk" : "@@ -1,1 +727,731 @@    val outputFilePath1 = new File(tempDir, \"/out1\").getAbsolutePath\n    pairRDD.saveAsTextFile(outputFilePath1)\n    assert(sc.textFile(outputFilePath1).collect() === Array(\"(1,1)\", \"(2,2)\", \"(3,3)\"))\n\n    // Test saveAsNewAPIHadoopDataset()"
  },
  {
    "id" : "47e1c0f9-0073-4ca9-9f68-d842ce313d16",
    "prId" : 24431,
    "prUrl" : "https://github.com/apache/spark/pull/24431#pullrequestreview-231407088",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9928088b-44d2-4e40-a945-9861bc048908",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "The indent looks incorrect here.",
        "createdAt" : "2019-04-27T03:23:08Z",
        "updatedAt" : "2019-04-27T18:03:34Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "cb288f1ef0f83ba176ab776c423f05f19d1ced11",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +208,212 @@      sc = new SparkContext(\"local\", \"test\")\n      val objs = sc.makeRDD(1 to 3).map { _ =>\n        Utils.classForName[AnyRef](className, noSparkClassLoader = true).\n          getConstructor().newInstance()\n      }"
  }
]