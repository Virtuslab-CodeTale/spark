[
  {
    "id" : "218febca-9f6e-459c-a6a3-489546066a07",
    "prId" : 33425,
    "prUrl" : "https://github.com/apache/spark/pull/33425#pullrequestreview-714234740",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4eb2a971-ee01-4982-b4b0-c307ea60a7da",
        "parentId" : null,
        "authorId" : "9953a478-bdd8-4f15-be59-f6f654ff85ae",
        "body" : "Can we extend this UT to verify the driver host is excluded? It will ensure that any future changes will not change this.",
        "createdAt" : "2021-07-20T05:43:51Z",
        "updatedAt" : "2021-07-20T05:44:25Z",
        "lastEditedBy" : "9953a478-bdd8-4f15-be59-f6f654ff85ae",
        "tags" : [
        ]
      },
      {
        "id" : "5e6a4310-29d6-42b4-b080-910f472ac731",
        "parentId" : "4eb2a971-ee01-4982-b4b0-c307ea60a7da",
        "authorId" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "body" : "I tried doing that, currently the BlockManagerMaster is mocked, therefore it doesn't register due to which it won't be added as part of `blockManagerIdByExecutor`. If not the test should have failed in the first place itself, as we are explicitly having tests checking for the hosts. But I will see if there is any other way add tests for this thing.",
        "createdAt" : "2021-07-20T17:33:46Z",
        "updatedAt" : "2021-07-20T17:33:46Z",
        "lastEditedBy" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "tags" : [
        ]
      },
      {
        "id" : "17186400-f978-404c-bc04-f32147f0ef31",
        "parentId" : "4eb2a971-ee01-4982-b4b0-c307ea60a7da",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Sounds fine.",
        "createdAt" : "2021-07-21T01:58:59Z",
        "updatedAt" : "2021-07-21T01:58:59Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "6a6c86c0-fc8f-4835-82a4-4e694c28ec66",
        "parentId" : "4eb2a971-ee01-4982-b4b0-c307ea60a7da",
        "authorId" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "body" : "@Ngone51 Any suggestions? or is this fine as it is? I don't think there is any other way if not we need to significantly refactor the tests or something.",
        "createdAt" : "2021-07-21T17:16:38Z",
        "updatedAt" : "2021-07-21T17:16:38Z",
        "lastEditedBy" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "tags" : [
        ]
      },
      {
        "id" : "e898593e-326c-4bf3-a32d-9101eb498668",
        "parentId" : "4eb2a971-ee01-4982-b4b0-c307ea60a7da",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "It's fine as it is.",
        "createdAt" : "2021-07-24T13:32:35Z",
        "updatedAt" : "2021-07-24T13:32:35Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "e3ef56393e612e6803b88fbce5c87178743528bc",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +2099,2103 @@    master.removeShufflePushMergerLocation(\"hostA\")\n    assert(master.getShufflePushMergerLocations(4, Set.empty).map(_.host).sorted ===\n      Seq(\"hostB\", \"hostC\", \"hostD\").sorted)\n  }\n"
  },
  {
    "id" : "322affbe-09da-4824-b656-f344e0034e7d",
    "prId" : 33425,
    "prUrl" : "https://github.com/apache/spark/pull/33425#pullrequestreview-715176315",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3cd610a7-2649-4376-ab14-644ea97e1255",
        "parentId" : null,
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "Add a driver block manager to this test ? It will catch the issue being fixed in `BlockManagerMasterEndpoint`, right ?\r\n",
        "createdAt" : "2021-07-25T06:28:08Z",
        "updatedAt" : "2021-07-25T06:28:08Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      },
      {
        "id" : "8c3de49b-a6aa-48d9-aab6-87355d49421b",
        "parentId" : "3cd610a7-2649-4376-ab14-644ea97e1255",
        "authorId" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "body" : "I tried adding test but like I mentioned in this [comment](https://github.com/apache/spark/pull/33425#discussion_r673340152) currently `BlockManagerMaster` is mocked due to which it doesn't registered and won't be in `blockManagerIdByExecutor`. That is why I didn't add the test.",
        "createdAt" : "2021-07-25T15:01:10Z",
        "updatedAt" : "2021-07-25T15:01:10Z",
        "lastEditedBy" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "tags" : [
        ]
      },
      {
        "id" : "57a4b686-b142-4fce-82ba-a127861f06f5",
        "parentId" : "3cd610a7-2649-4376-ab14-644ea97e1255",
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "Why would this not work ?\r\n\r\n```\r\n    assert(master.getExecutorEndpointRef(SparkContext.DRIVER_IDENTIFIER).isEmpty)\r\n    makeBlockManager(100, SparkContext.DRIVER_IDENTIFIER,\r\n      transferService = Some(new MockBlockTransferService(10, \"host0\")))\r\n    assert(master.getExecutorEndpointRef(SparkContext.DRIVER_IDENTIFIER).isDefined)\r\n```",
        "createdAt" : "2021-07-26T18:50:33Z",
        "updatedAt" : "2021-07-26T18:50:33Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      }
    ],
    "commit" : "e3ef56393e612e6803b88fbce5c87178743528bc",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +2094,2098 @@    assert(master.getShufflePushMergerLocations(3, Set.empty).size == 3)\n    assert(master.getShufflePushMergerLocations(3, Set.empty).map(_.host).sorted ===\n      Seq(\"hostC\", \"hostB\", \"hostD\").sorted)\n    assert(master.getShufflePushMergerLocations(4, Set.empty).map(_.host).sorted ===\n      Seq(\"hostB\", \"hostA\", \"hostC\", \"hostD\").sorted)"
  },
  {
    "id" : "b8bcc321-b5cb-4e72-91df-64fa9a39125d",
    "prId" : 33425,
    "prUrl" : "https://github.com/apache/spark/pull/33425#pullrequestreview-715340506",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2ea17467-6c01-4c2f-8393-513480390019",
        "parentId" : null,
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "This does not look right; we cant have it both empty and defined :-)\r\nIt will be defined only after we add the driver.",
        "createdAt" : "2021-07-26T22:43:44Z",
        "updatedAt" : "2021-07-26T22:44:02Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      }
    ],
    "commit" : "e3ef56393e612e6803b88fbce5c87178743528bc",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +2087,2091 @@    assert(master.getExecutorEndpointRef(SparkContext.DRIVER_IDENTIFIER).isEmpty)\n    makeBlockManager(100, SparkContext.DRIVER_IDENTIFIER,\n      transferService = Some(new MockBlockTransferService(10, \"host-driver\")))\n    assert(master.getExecutorEndpointRef(SparkContext.DRIVER_IDENTIFIER).isDefined)\n    master.removeExecutor(\"execA\")"
  },
  {
    "id" : "13a2b81d-977c-45da-90a2-5e202879c212",
    "prId" : 32727,
    "prUrl" : "https://github.com/apache/spark/pull/32727#pullrequestreview-675731162",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a7fd665d-a1a2-4bf4-8da9-07b7b5a954ba",
        "parentId" : null,
        "authorId" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "body" : "As I see the test body here is the same as the one below (\"test migration of shuffle blocks during decommissioning - no limit\") so are we calling `testShuffleBlockDecommissioning(None, true)` twice with just a different test name. Is not it?\r\n\r\nIf I am right then we should come up with a common name for those two tests and keep only one with the new name as testing is already takes considerable time and we should avoid duplicating the same tests.",
        "createdAt" : "2021-06-03T02:36:16Z",
        "updatedAt" : "2021-06-03T02:45:06Z",
        "lastEditedBy" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "tags" : [
        ]
      },
      {
        "id" : "8d89201b-f6c3-47d3-a7e8-afa102a82e84",
        "parentId" : "a7fd665d-a1a2-4bf4-8da9-07b7b5a954ba",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Ya, you are correct. During refactoring to minimize the patch, I missed the duplication. I'll remove new test case.\r\n> As I see the test body here is the same as the one below (\"test migration of shuffle blocks during decommissioning - no limit\") so are we calling testShuffleBlockDecommissioning(None, true) twice with just a different test name. Is not it?",
        "createdAt" : "2021-06-03T21:17:19Z",
        "updatedAt" : "2021-06-03T21:17:19Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "a1700a9c135a3d982a887cba4ef321b366157efb",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +1994,1998 @@\n  test(\"SPARK-35589: test migration of index-only shuffle blocks during decommissioning\") {\n    testShuffleBlockDecommissioning(None, true)\n  }\n"
  },
  {
    "id" : "1340de0a-8922-424e-9eeb-652e263fa9a5",
    "prId" : 31493,
    "prUrl" : "https://github.com/apache/spark/pull/31493#pullrequestreview-585760292",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "807992b0-b484-40b0-8f80-a305919afbfe",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "I think this can not ensure that the block fails due to the disk size limitation. Block migration may doesn't finish within 1 second.",
        "createdAt" : "2021-02-06T14:22:35Z",
        "updatedAt" : "2021-02-08T20:53:03Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "fc90a012-1090-4b5a-983e-dbbadd891821",
        "parentId" : "807992b0-b484-40b0-8f80-a305919afbfe",
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "Yeah it does, in this situation we assert above in the normal case that the blocks migrate within one second.",
        "createdAt" : "2021-02-08T17:44:17Z",
        "updatedAt" : "2021-02-08T20:53:03Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      }
    ],
    "commit" : "69b25406b9d5ee1f0862f06614f579a4ed9a1e03",
    "line" : 59,
    "diffHunk" : "@@ -1,1 +1978,1982 @@          === shuffleIndexBlockContent)\n      } else {\n        Thread.sleep(1000)\n        assert(mapOutputTracker.shuffleStatuses(0).mapStatuses(0).location === bm1.blockManagerId)\n      }"
  },
  {
    "id" : "20cbd200-1ca8-436c-aae5-eb7cc675a3d6",
    "prId" : 30164,
    "prUrl" : "https://github.com/apache/spark/pull/30164#pullrequestreview-529106672",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cf2b5322-8bdf-48c1-9fbc-5e218ecc5a57",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "If we want to get 4 merges, it should also include `hostA`? If yes, shall we also test this case?",
        "createdAt" : "2020-11-12T13:54:25Z",
        "updatedAt" : "2020-11-20T00:32:25Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "5ce29340c8aa4a6aadfc8d00cb5053a9be9aa839",
    "line" : 47,
    "diffHunk" : "@@ -1,1 +2011,2015 @@    master.removeExecutor(\"execE\")\n\n    assert(master.getShufflePushMergerLocations(3, Set.empty).size == 3)\n    assert(master.getShufflePushMergerLocations(3, Set.empty).map(_.host).sorted ===\n      Seq(\"hostC\", \"hostB\", \"hostD\").sorted)"
  }
]