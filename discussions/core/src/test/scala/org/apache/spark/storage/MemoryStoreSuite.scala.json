[
  {
    "id" : "2551d6e6-beee-4509-a589-96fa4208e18f",
    "prId" : 29407,
    "prUrl" : "https://github.com/apache/spark/pull/29407#pullrequestreview-470508911",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c9afe4a6-efdc-4a5f-8646-c3f1bbba9b9f",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Should this second arg be true here? Some tests that don't set this currently now set it to true, some to false. ",
        "createdAt" : "2020-08-19T13:56:58Z",
        "updatedAt" : "2020-08-19T18:13:47Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "4aaf6572-a0aa-4892-be8e-1ed652a23710",
        "parentId" : "c9afe4a6-efdc-4a5f-8646-c3f1bbba9b9f",
        "authorId" : "aab20068-362f-4797-b579-1c8e6e480ffb",
        "body" : "Yeah, this test suite assumes that compressed oops are enabled. The comment above alludes to this but the original code didn't actually override it. This leads to test failures when running a JVM where compressed oops are disabled.\r\n\r\nIn another test (\"64-bit arch with no compressed oops\") the test was inheriting the compressed oops setting of false from a preceding test rather than setting it itself. Since the preceding test is now cleaning up after itself that test now explicitly needs to set compressed oops to false.\r\n\r\nIn general it seems better to explicitly set these settings. Or we could try and make the tests more robust to different arch and compressed oops combinations. That is a bit more involved than this patch though.",
        "createdAt" : "2020-08-19T14:19:34Z",
        "updatedAt" : "2020-08-19T18:13:47Z",
        "lastEditedBy" : "aab20068-362f-4797-b579-1c8e6e480ffb",
        "tags" : [
        ]
      },
      {
        "id" : "4ea64106-c80f-4a48-b2a7-5e076e9c1e5d",
        "parentId" : "c9afe4a6-efdc-4a5f-8646-c3f1bbba9b9f",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "OK if they're all on purpose and as intended, that's fine.",
        "createdAt" : "2020-08-19T14:21:55Z",
        "updatedAt" : "2020-08-19T18:13:47Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      }
    ],
    "commit" : "a5c158e9dfeb0fc9e5a57f172a5780f8cae6a17b",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +74,78 @@    super.beforeEach()\n    // Set the arch to 64-bit and compressedOops to true to get a deterministic test-case\n    reinitializeSizeEstimator(\"amd64\", \"true\")\n  }\n"
  },
  {
    "id" : "e078f123-a527-4033-8a2f-e6abf45d2bc5",
    "prId" : 24463,
    "prUrl" : "https://github.com/apache/spark/pull/24463#pullrequestreview-230923850",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "07d6a236-158e-45ff-a8a5-1cfc69a662ad",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "The way Scala closures work, the inner class will see updates to this var.",
        "createdAt" : "2019-04-25T23:08:39Z",
        "updatedAt" : "2019-04-25T23:08:58Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      }
    ],
    "commit" : "f599a65b3a074fec3cfae3e7ca3ffe30e713cba9",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +62,66 @@    val memManager = new UnifiedMemoryManager(conf, maxMem, maxMem / 2, 1)\n    val blockInfoManager = new BlockInfoManager\n    var memoryStore: MemoryStore = null\n    val blockEvictionHandler = new BlockEvictionHandler {\n      override private[storage] def dropFromMemory[T: ClassTag]("
  }
]