[
  {
    "id" : "96da717e-1679-46a5-a164-270f31d07e8c",
    "prId" : 26821,
    "prUrl" : "https://github.com/apache/spark/pull/26821#pullrequestreview-331022756",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b675d0d1-6a2f-4907-b2b2-4dfdfb16cf0d",
        "parentId" : null,
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "I know most of tests in FsHistoryProviderSuite don't deal with rolling event log, but this should really deal with it, as it's not just simple sequential reading of files.",
        "createdAt" : "2019-12-12T09:17:47Z",
        "updatedAt" : "2019-12-12T09:22:06Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      }
    ],
    "commit" : "b6b2c5a3cc46d25595bfa7e187846187dd5ac806",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +192,196 @@  }\n\n  test(\"support incremental parsing of the event logs\") {\n    val provider = new FsHistoryProvider(createTestConf(true))\n"
  },
  {
    "id" : "ac380b94-6293-44a8-bff4-641fe3343cb2",
    "prId" : 26821,
    "prUrl" : "https://github.com/apache/spark/pull/26821#pullrequestreview-331022756",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0b3e719f-1c35-4e9e-b108-a56e3bdbebae",
        "parentId" : null,
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "I think it should really check whether store reflects the events correctly. It's not enough to just check it's loaded or not. That should cover these cases - initial read / new addition of events in same file / new file.",
        "createdAt" : "2019-12-12T09:20:11Z",
        "updatedAt" : "2019-12-12T09:22:06Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      }
    ],
    "commit" : "b6b2c5a3cc46d25595bfa7e187846187dd5ac806",
    "line" : 46,
    "diffHunk" : "@@ -1,1 +221,225 @@      provider.getAttempt(\"app1\", None).logPath should endWith(EventLogFileWriter.IN_PROGRESS)\n      val appUi = provider.getAppUI(\"app1\", None)\n      appUi should not be null\n    }\n"
  },
  {
    "id" : "3973a8a6-d42f-4cf1-a00c-117cf241561a",
    "prId" : 25797,
    "prUrl" : "https://github.com/apache/spark/pull/25797#pullrequestreview-332915243",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b5a5aabd-f060-4ee1-81fc-43b6117e6288",
        "parentId" : null,
        "authorId" : "0b3111e2-9584-4813-8cb5-8f40e119f71c",
        "body" : "No need to use `.key` here.\r\n\r\n(I'll fix this during merge.)",
        "createdAt" : "2019-12-16T22:38:54Z",
        "updatedAt" : "2019-12-16T22:39:31Z",
        "lastEditedBy" : "0b3111e2-9584-4813-8cb5-8f40e119f71c",
        "tags" : [
        ]
      }
    ],
    "commit" : "e9ebb6fd690c6e3a786b3285058c59850107386b",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +1324,1328 @@  test(\"SPARK-29043: clean up specified event log\") {\n    val clock = new ManualClock()\n    val conf = createTestConf().set(MAX_LOG_AGE_S.key, \"0\").set(CLEANER_ENABLED.key, \"true\")\n    val provider = new FsHistoryProvider(conf, clock)\n"
  }
]