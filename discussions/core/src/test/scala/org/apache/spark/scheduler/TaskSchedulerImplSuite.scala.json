[
  {
    "id" : "3854c666-3276-4a1f-952a-bf4cc2102606",
    "prId" : 27207,
    "prUrl" : "https://github.com/apache/spark/pull/27207#pullrequestreview-370906528",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "77a5c377-19da-48c2-b403-b0ba61d39369",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "why call `resourceOffers` here when there is no task set submitted?",
        "createdAt" : "2020-03-05T14:24:23Z",
        "updatedAt" : "2020-04-03T05:29:22Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "47b23fbd-e64a-4abd-89ac-6f99afa3533b",
        "parentId" : "77a5c377-19da-48c2-b403-b0ba61d39369",
        "authorId" : "29a3e834-d9e3-42dc-ab25-20ba332ef3f2",
        "body" : "adding comment.",
        "createdAt" : "2020-03-09T03:55:26Z",
        "updatedAt" : "2020-04-03T05:29:22Z",
        "lastEditedBy" : "29a3e834-d9e3-42dc-ab25-20ba332ef3f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "24c8ad9ae23d360c7bb5bc813d04e6f5f6715d93",
    "line" : 41,
    "diffHunk" : "@@ -1,1 +234,238 @@    // See TaskSetManager.computeValidLocalityLevels()\n    // This begins the task set as PROCESS_LOCAL locality level\n    taskScheduler.resourceOffers(IndexedSeq(WorkerOffer(\"exec1\", \"host1\", 1)))\n    taskScheduler.submitTasks(taskSet)\n    taskScheduler"
  },
  {
    "id" : "91d378a0-82ce-4488-b3d3-60658f006473",
    "prId" : 27207,
    "prUrl" : "https://github.com/apache/spark/pull/27207#pullrequestreview-370907433",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c2ce94f2-f9e4-43e0-9831-15368e262207",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I'm trying to understand this test case. Why the first resource off is accepted (and launched one task) while the second one is rejected?",
        "createdAt" : "2020-03-05T14:26:15Z",
        "updatedAt" : "2020-04-03T05:29:22Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "4e85d5da-7cd5-4c60-80f4-59fadfff31b1",
        "parentId" : "c2ce94f2-f9e4-43e0-9831-15368e262207",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "The comment mentions if the timer is reset or not, but people may need a little more context about how it leads to rejecting resources.",
        "createdAt" : "2020-03-05T14:29:34Z",
        "updatedAt" : "2020-04-03T05:29:22Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "c556ba93-3881-4644-bc40-764cd0a42e9b",
        "parentId" : "c2ce94f2-f9e4-43e0-9831-15368e262207",
        "authorId" : "29a3e834-d9e3-42dc-ab25-20ba332ef3f2",
        "body" : "locality level starts at PROCESS_LOCAL.\r\nthe first resource is process local exec1, host1\r\nthe second resource is only node local exec2, host1\r\n\r\nall the test cases I added start at PROCESS_LOCAL (the reason why the resource exec1, host1 was offered before submitting tasks), was that the confusing part?",
        "createdAt" : "2020-03-09T04:00:43Z",
        "updatedAt" : "2020-04-03T05:29:22Z",
        "lastEditedBy" : "29a3e834-d9e3-42dc-ab25-20ba332ef3f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "24c8ad9ae23d360c7bb5bc813d04e6f5f6715d93",
    "line" : 66,
    "diffHunk" : "@@ -1,1 +259,263 @@        IndexedSeq(WorkerOffer(\"exec1\", \"host1\", 1)),\n        isAllFreeResources = false)\n      .flatten.length === 1)\n\n    // This NODE_LOCAL task should not be accepted."
  },
  {
    "id" : "2eeec088-1ac3-4010-a435-ef804bf86c5f",
    "prId" : 27207,
    "prUrl" : "https://github.com/apache/spark/pull/27207#pullrequestreview-371135228",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5154c28a-552f-4bd4-9acf-ffbda876a3c7",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "There are 4 `resourceOffers` call in this test, which one resets timer?",
        "createdAt" : "2020-03-09T12:50:56Z",
        "updatedAt" : "2020-04-03T05:29:22Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "24c8ad9ae23d360c7bb5bc813d04e6f5f6715d93",
    "line" : 143,
    "diffHunk" : "@@ -1,1 +336,340 @@    // This line resets the timer and locality level is reset to PROCESS_LOCAL.\n    assert(taskScheduler\n      .resourceOffers(\n        IndexedSeq(WorkerOffer(\"exec1\", \"host1\", 1)),\n        isAllFreeResources = false)"
  },
  {
    "id" : "644c835c-1637-41bc-addd-d0eb37fa2903",
    "prId" : 27207,
    "prUrl" : "https://github.com/apache/spark/pull/27207#pullrequestreview-371140018",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e04ed1ed-1f51-4b84-a5c3-8cce7be3e231",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I'd like to see more comments to explain what happens when we call `resourceOffers`\r\n\r\nFor example, this one: `It's not a node-local resource, no task is scheduled due to delay scheduling`.",
        "createdAt" : "2020-03-09T12:53:57Z",
        "updatedAt" : "2020-04-03T05:29:22Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "24c8ad9ae23d360c7bb5bc813d04e6f5f6715d93",
    "line" : 172,
    "diffHunk" : "@@ -1,1 +365,369 @@    // NODE_LOCAL full resource offer is rejected, so delay scheduling is not reset.\n    assert(taskScheduler\n      .resourceOffers(\n        IndexedSeq(WorkerOffer(\"exec2\", \"host1\", 1)),\n        isAllFreeResources = true)"
  },
  {
    "id" : "e033907b-b601-4f2b-9859-256eb934a340",
    "prId" : 27207,
    "prUrl" : "https://github.com/apache/spark/pull/27207#pullrequestreview-384362388",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4d32f703-2d72-4a3b-9ea7-cba21072ea9c",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "So now we must have a resource offset first to set up the initial locality level? Would this cause perf regression compared to Spark 2.4?",
        "createdAt" : "2020-03-30T14:29:28Z",
        "updatedAt" : "2020-04-03T05:29:22Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "ccfd3bc1-7233-4573-99db-0491dcd80d0e",
        "parentId" : "4d32f703-2d72-4a3b-9ea7-cba21072ea9c",
        "authorId" : "29a3e834-d9e3-42dc-ab25-20ba332ef3f2",
        "body" : "we don't need it, just otherwise the test behaves differently because the resources aren't scheduled the same (more resources are accepted up front with new code)\r\nI can also make the test pass by setting the legacy flag, or changing more logic in the test\r\n\r\nPreviously the locality level would be reset on every task launch, now it is once per resourceOffers call (with certain conditions met).\r\nWorkloads that relied on the old behavior would possibly regress.",
        "createdAt" : "2020-03-31T02:32:17Z",
        "updatedAt" : "2020-04-03T05:29:22Z",
        "lastEditedBy" : "29a3e834-d9e3-42dc-ab25-20ba332ef3f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "24c8ad9ae23d360c7bb5bc813d04e6f5f6715d93",
    "line" : 260,
    "diffHunk" : "@@ -1,1 +1146,1150 @@    val taskScheduler = setupScheduler()\n\n    taskScheduler.resourceOffers(IndexedSeq(new WorkerOffer(\"executor0\", \"host0\", 1)))\n    taskScheduler.submitTasks(FakeTask.createTaskSet(2, stageId = 0, stageAttemptId = 0,\n      (0 until 2).map { _ => Seq(TaskLocation(\"host0\", \"executor2\")) }: _*"
  },
  {
    "id" : "0b2a4e7b-aa9b-44bd-9506-722d4bcdb10c",
    "prId" : 27207,
    "prUrl" : "https://github.com/apache/spark/pull/27207#pullrequestreview-386939968",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2808f64c-4d0e-422b-8b5c-47a4f6f98ba0",
        "parentId" : null,
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "nit need space before isAllFreeResources",
        "createdAt" : "2020-04-02T14:57:33Z",
        "updatedAt" : "2020-04-03T05:29:22Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      },
      {
        "id" : "23fd46e2-038e-4c9d-824a-a465d94b80de",
        "parentId" : "2808f64c-4d0e-422b-8b5c-47a4f6f98ba0",
        "authorId" : "29a3e834-d9e3-42dc-ab25-20ba332ef3f2",
        "body" : "good ðŸ‘€ ",
        "createdAt" : "2020-04-03T05:09:23Z",
        "updatedAt" : "2020-04-03T05:29:22Z",
        "lastEditedBy" : "29a3e834-d9e3-42dc-ab25-20ba332ef3f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "24c8ad9ae23d360c7bb5bc813d04e6f5f6715d93",
    "line" : 77,
    "diffHunk" : "@@ -1,1 +270,274 @@\n  test(\"SPARK-18886 - delay scheduling timer is reset when it accepts all resources offered when \" +\n    \"isAllFreeResources = true\") {\n    val clock = new ManualClock()\n    // All tasks created here are local to exec1, host1."
  },
  {
    "id" : "23fd7039-1e1d-4325-9f29-bb507a281179",
    "prId" : 27207,
    "prUrl" : "https://github.com/apache/spark/pull/27207#pullrequestreview-386939958",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "922e4e4f-2b0e-465e-a0ee-c9906c5a8562",
        "parentId" : null,
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "nit remove extra line",
        "createdAt" : "2020-04-02T15:01:46Z",
        "updatedAt" : "2020-04-03T05:29:22Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      },
      {
        "id" : "fe43b3eb-ba2f-4a78-bf35-f28aa4f67b78",
        "parentId" : "922e4e4f-2b0e-465e-a0ee-c9906c5a8562",
        "authorId" : "29a3e834-d9e3-42dc-ab25-20ba332ef3f2",
        "body" : "ðŸ‘ ",
        "createdAt" : "2020-04-03T05:09:19Z",
        "updatedAt" : "2020-04-03T05:29:22Z",
        "lastEditedBy" : "29a3e834-d9e3-42dc-ab25-20ba332ef3f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "24c8ad9ae23d360c7bb5bc813d04e6f5f6715d93",
    "line" : 155,
    "diffHunk" : "@@ -1,1 +348,352 @@      .flatten.isEmpty)\n  }\n\n  // This tests two cases\n  // 1. partial resource offer doesn't reset timer after full resource offer had rejected resources"
  },
  {
    "id" : "27bced49-8603-40c0-863d-efce88d17f33",
    "prId" : 26696,
    "prUrl" : "https://github.com/apache/spark/pull/26696#pullrequestreview-326339858",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a180625d-1a78-4a4b-ba04-6568d379edae",
        "parentId" : null,
        "authorId" : "29a3e834-d9e3-42dc-ab25-20ba332ef3f2",
        "body" : "note of why this line was necessary.\r\n\r\nThe current locality level (currentLocalityIndex) of a TSM is defaulted to the current \"most local\" level when a taskset is submitted. Before this line was added, that level was ANY as the scheduler was not aware of any resources.\r\n\r\nLocality levels are recomputed whenever a new executor is detected, but the current locality level remains the same. Previously the test was passing because the first task that began running was NODE_LOCAL, hence the locality level was set to node local, causing the second task not to run.\r\n\r\nSince this PR only resets locality level when all slots are utilized, this locality level reset not happening.\r\nThis new line makes it such that the starting locality level is not ANY",
        "createdAt" : "2019-12-03T18:01:20Z",
        "updatedAt" : "2019-12-19T05:50:56Z",
        "lastEditedBy" : "29a3e834-d9e3-42dc-ab25-20ba332ef3f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "f9a85f9475d5851f5bdd79e18141950330421445",
    "line" : 177,
    "diffHunk" : "@@ -1,1 +1077,1081 @@    val taskScheduler = setupScheduler()\n\n    taskScheduler.resourceOffers(IndexedSeq(new WorkerOffer(\"executor0\", \"host0\", 1)))\n    taskScheduler.submitTasks(FakeTask.createTaskSet(2, stageId = 0, stageAttemptId = 0,\n      (0 until 2).map { _ => Seq(TaskLocation(\"host0\", \"executor2\")) }: _*"
  },
  {
    "id" : "7f0dd3c2-0126-4574-ae68-2a67b905fb52",
    "prId" : 26696,
    "prUrl" : "https://github.com/apache/spark/pull/26696#pullrequestreview-329048016",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0e53226b-4ee1-475d-8da4-64a4da9a43a5",
        "parentId" : null,
        "authorId" : "e913f9af-103d-40d4-976e-9aa8e12e7211",
        "body" : "shoudl add some tests with more executors getting added & removed.",
        "createdAt" : "2019-12-09T16:40:28Z",
        "updatedAt" : "2019-12-19T05:50:56Z",
        "lastEditedBy" : "e913f9af-103d-40d4-976e-9aa8e12e7211",
        "tags" : [
        ]
      }
    ],
    "commit" : "f9a85f9475d5851f5bdd79e18141950330421445",
    "line" : 100,
    "diffHunk" : "@@ -1,1 +292,296 @@    // and locality wait has not expired\n    assert(taskScheduler.resourceOffers(IndexedSeq(WorkerOffer(\"exec2\", \"host2\", 1)))\n      .flatten.isEmpty)\n\n    // Offer a total of 2 slots on exec 3, non are taken since non-local"
  }
]