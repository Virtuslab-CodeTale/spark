[
  {
    "id" : "cb7b7a9f-cae7-4b7b-a43b-8ff9f8ad0daf",
    "prId" : 32184,
    "prUrl" : "https://github.com/apache/spark/pull/32184#pullrequestreview-637301476",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e48de507-526a-43c5-a946-57b49152609c",
        "parentId" : null,
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "This check is to avoid `java.io.IOException: No FileSystem for scheme: http` if we use hadoop 2.7 which Spark still supports.",
        "createdAt" : "2021-04-16T03:23:15Z",
        "updatedAt" : "2021-04-16T03:23:15Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "bfd2a55bb1f3988428f7671f406757aff72f7870",
    "line" : 88,
    "diffHunk" : "@@ -1,1 +348,352 @@    // HttpFileSystem supported since hadoop 2.9\n    assume(hadoopVersion.head.toInt >= 3 ||\n      (hadoopVersion.head.toInt == 2 && hadoopVersion(1).toInt >= 9))\n\n    val xmlPath = new Path("
  },
  {
    "id" : "ac75b4f6-5406-4d8d-ad2b-30747cab5879",
    "prId" : 27871,
    "prUrl" : "https://github.com/apache/spark/pull/27871#pullrequestreview-375582752",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "23af4527-3cbc-4e02-bb03-c3839607bbe2",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "`FairSchedulableBuilder` -> `FIFOSchedulableBuilder`.",
        "createdAt" : "2020-03-16T21:06:45Z",
        "updatedAt" : "2020-03-16T21:07:25Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "001b2340859c02be845598869bacc7e96ac34d2f",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +352,356 @@\n    val rootPool = new Pool(\"\", FIFO, 0, 0)\n    val schedulableBuilder = new FairSchedulableBuilder(rootPool, conf)\n    schedulableBuilder.buildPools()\n"
  },
  {
    "id" : "f089aabf-fded-484e-b70e-9a1f8d9a4ac9",
    "prId" : 26696,
    "prUrl" : "https://github.com/apache/spark/pull/26696#pullrequestreview-328525989",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5df36b8f-fc64-4940-86c5-425e773ca050",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Add a blank line above.",
        "createdAt" : "2019-12-07T01:02:27Z",
        "updatedAt" : "2019-12-19T05:50:56Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "f9a85f9475d5851f5bdd79e18141950330421445",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +52,56 @@  }\n\n  test(\"validate FIFO slot distributions\") {\n    sc = new SparkContext(LOCAL, APP_NAME)\n    val taskScheduler = new TaskSchedulerImpl(sc)"
  },
  {
    "id" : "70aa1f6e-2a8c-4c24-80c5-cbaace798c36",
    "prId" : 26696,
    "prUrl" : "https://github.com/apache/spark/pull/26696#pullrequestreview-329048016",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "84d81164-d318-4f99-8b31-b19006c18f78",
        "parentId" : null,
        "authorId" : "e913f9af-103d-40d4-976e-9aa8e12e7211",
        "body" : "same here, expand this to include removing  and adding tasksets",
        "createdAt" : "2019-12-09T16:34:44Z",
        "updatedAt" : "2019-12-19T05:50:56Z",
        "lastEditedBy" : "e913f9af-103d-40d4-976e-9aa8e12e7211",
        "tags" : [
        ]
      }
    ],
    "commit" : "f9a85f9475d5851f5bdd79e18141950330421445",
    "line" : 97,
    "diffHunk" : "@@ -1,1 +145,149 @@    assert(taskSetManager1.numAvailableSlot === 0)\n    assert(taskSetManager2.numAvailableSlot === 2)\n    assert(taskSetManager3.numAvailableSlot === 2)\n\n    rootPool.getSchedulableByName(\"pool2\").removeSchedulable(taskSetManager2)"
  }
]