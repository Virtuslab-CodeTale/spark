[
  {
    "id" : "6b115ca5-649c-4fa7-835d-26b4691b0ad6",
    "prId" : 26916,
    "prUrl" : "https://github.com/apache/spark/pull/26916#pullrequestreview-332993789",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "56423efa-2e4a-4ac3-afeb-7957e0608456",
        "parentId" : null,
        "authorId" : "bc001dd4-5224-4ca1-afdd-49d69783d7f2",
        "body" : "We only need to test the object returned by `HadoopMapReduceCommitProtocol.commitTask()`, thus no need to create a mutable map/set then convert it.",
        "createdAt" : "2019-12-17T02:28:44Z",
        "updatedAt" : "2019-12-17T02:28:44Z",
        "lastEditedBy" : "bc001dd4-5224-4ca1-afdd-49d69783d7f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "559c45c697ff7b207275e6549c6b8f6396a8e32b",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +371,375 @@    val partitionPaths = Set(\"test3\")\n\n    val taskCommitMessage1 = new TaskCommitMessage(addedAbsPathFiles -> partitionPaths)\n    val taskCommitMessage2 = new TaskCommitMessage(Map.empty -> Set.empty)\n    Seq(taskCommitMessage1, taskCommitMessage2).foreach { taskCommitMessage =>"
  }
]