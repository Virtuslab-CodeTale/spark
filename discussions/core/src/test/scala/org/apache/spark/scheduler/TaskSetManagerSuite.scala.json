[
  {
    "id" : "3ca406ef-5798-4b4d-a8d1-7b681f2f89b2",
    "prId" : 29468,
    "prUrl" : "https://github.com/apache/spark/pull/29468#pullrequestreview-470647653",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ad5b3034-e35f-4110-8dc8-9eafdaf5e503",
        "parentId" : null,
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "I think you should also call `sched.executorDecommission(exec1, ExecutorDecommissionInfo(\"test\", true))` (ie for exec1), to mimic the production behavior which would always decommission all executors on a decommissioned host.\r\n\r\nIn addition, I think we should also test decommissioning when the entire host hasn't been taken down ? ",
        "createdAt" : "2020-08-19T16:51:04Z",
        "updatedAt" : "2020-08-20T06:22:17Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      }
    ],
    "commit" : "65f6e0525b2d1472c1e6956587253e5ae6263676",
    "line" : 45,
    "diffHunk" : "@@ -1,1 +675,679 @@\n    // Decommission all executors on host0, to mimic CoarseGrainedSchedulerBackend.\n    sched.executorDecommission(exec0, ExecutorDecommissionInfo(\"test\", true))\n    sched.executorDecommission(exec1, ExecutorDecommissionInfo(\"test\", true))\n"
  },
  {
    "id" : "710c3b8d-c881-492c-9651-8233dae58832",
    "prId" : 29240,
    "prUrl" : "https://github.com/apache/spark/pull/29240#pullrequestreview-455461842",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b84c2058-5db4-4119-8218-e6810c3c3af4",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "LGTM. Maybe it would have been better if we leave a comment so people don't mistakenly remove for the time being :-).",
        "createdAt" : "2020-07-27T01:47:48Z",
        "updatedAt" : "2020-07-27T01:47:49Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "cb5667a1-bb10-4be0-bdfb-58e89c24c995",
        "parentId" : "b84c2058-5db4-4119-8218-e6810c3c3af4",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Thanks. Ya. It's a general problem in Scala 2.13 because we don't have any CIs. Not only tests, Scala 2.13 compilation itself is already broken in `sql/catalyst`. It's sad that there is no way to protect properly. :(\r\n\r\nMaybe, we had better consider enable Scala 2.13 CI partially for compilation and testing.\r\n\r\nWDYT, @HyukjinKwon and @srowen ?",
        "createdAt" : "2020-07-27T02:11:19Z",
        "updatedAt" : "2020-07-27T02:11:20Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "d9c48a03-5b6e-4eaf-8932-498d6dac3c95",
        "parentId" : "b84c2058-5db4-4119-8218-e6810c3c3af4",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "I haven't tested it by myself yet so I don't know the stability about 2.13 yet but +1 for the idea.",
        "createdAt" : "2020-07-27T04:17:31Z",
        "updatedAt" : "2020-07-27T04:17:31Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "1cf43b9b8b909baba486c004169c973fbbd0a18b",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +32,36 @@import org.scalatest.concurrent.Eventually\n\nimport org.apache.spark.{FakeSchedulerBackend => _, _}\nimport org.apache.spark.internal.Logging\nimport org.apache.spark.internal.config"
  },
  {
    "id" : "d59f3c18-f8e2-4e99-bf20-f4bd2f67abed",
    "prId" : 28619,
    "prUrl" : "https://github.com/apache/spark/pull/28619#pullrequestreview-418426154",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4bb4abd1-bfa4-4f5c-8c26-b06f8b364f8b",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "It seems `startedTasks` is updated asynchronically by `FakeDAGScheduler`. Maybe we could use `eventually` to pretend the potential failure.",
        "createdAt" : "2020-05-26T05:45:15Z",
        "updatedAt" : "2020-06-15T14:14:24Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "cd323a70-4173-4325-a29f-c4a89c597448",
        "parentId" : "4bb4abd1-bfa4-4f5c-8c26-b06f8b364f8b",
        "authorId" : "ad4cb313-47b2-4cfa-9c1f-0a3596794a67",
        "body" : "`dagScheduler.taskStarted` is called as part of `resourceOffer` and the overridden taskStarted method of FakeDagScheduler appends it to `startedTasks` set. So it seems synchronus only?",
        "createdAt" : "2020-05-26T14:59:28Z",
        "updatedAt" : "2020-06-15T14:14:24Z",
        "lastEditedBy" : "ad4cb313-47b2-4cfa-9c1f-0a3596794a67",
        "tags" : [
        ]
      },
      {
        "id" : "adf5a33a-c9bb-43a1-b48e-b34b3e7f71f8",
        "parentId" : "4bb4abd1-bfa4-4f5c-8c26-b06f8b364f8b",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "I see. you're right.",
        "createdAt" : "2020-05-26T15:37:14Z",
        "updatedAt" : "2020-06-15T14:14:24Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "d87b311be85819ae884e2a24d94926fdd51165de",
    "line" : 35,
    "diffHunk" : "@@ -1,1 +1943,1947 @@    assert(taskOption3.get.executorId === \"exec2\")\n\n    assert(sched.startedTasks.toSet === Set(0, 1, 2, 3))\n\n    clock.advance(4*1000) // time = 10s"
  },
  {
    "id" : "c9aeb882-fdb8-48d7-a697-696253fd4e6a",
    "prId" : 28619,
    "prUrl" : "https://github.com/apache/spark/pull/28619#pullrequestreview-418386530",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9ba3b1f9-d869-451e-a4f7-554b06685914",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Could you assert `tidToExecutorKillTimeMapping` here?",
        "createdAt" : "2020-05-26T05:46:48Z",
        "updatedAt" : "2020-06-15T14:14:24Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "15e7aec7-6bf7-48af-8925-70b2a14e2852",
        "parentId" : "9ba3b1f9-d869-451e-a4f7-554b06685914",
        "authorId" : "ad4cb313-47b2-4cfa-9c1f-0a3596794a67",
        "body" : "done.",
        "createdAt" : "2020-05-26T14:59:38Z",
        "updatedAt" : "2020-06-15T14:14:24Z",
        "lastEditedBy" : "ad4cb313-47b2-4cfa-9c1f-0a3596794a67",
        "tags" : [
        ]
      }
    ],
    "commit" : "d87b311be85819ae884e2a24d94926fdd51165de",
    "line" : 53,
    "diffHunk" : "@@ -1,1 +1961,1965 @@    // executorDecommissionSpeculationTriggerTimeoutOpt\n    // (TASK 2 -> 15, TASK 3 -> 15)\n    manager.executorDecommission(\"exec2\")\n    assert(manager.tidToExecutorKillTimeMapping.keySet === Set(2, 3))\n    assert(manager.tidToExecutorKillTimeMapping(2) === 15*1000)"
  }
]