[
  {
    "id" : "c48fa5cd-487a-4a41-a3e0-a88920ba46d5",
    "prId" : 32007,
    "prUrl" : "https://github.com/apache/spark/pull/32007#pullrequestreview-675978323",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ce6655e3-d67a-4285-a803-e648fe072bf3",
        "parentId" : null,
        "authorId" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "body" : "Nit: should keep the original import list and just add the new class you are importing.",
        "createdAt" : "2021-05-27T20:49:33Z",
        "updatedAt" : "2021-05-27T20:49:33Z",
        "lastEditedBy" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "tags" : [
        ]
      },
      {
        "id" : "a1b3fda5-17fe-490a-842e-eb021eba8b5f",
        "parentId" : "ce6655e3-d67a-4285-a803-e648fe072bf3",
        "authorId" : "e942fa3e-a5b9-4a9f-b9a5-a1afd3c29b2c",
        "body" : "Wu Yi recommended to change to java.io._ in former comments so I changed it.",
        "createdAt" : "2021-05-27T22:20:59Z",
        "updatedAt" : "2021-05-27T22:20:59Z",
        "lastEditedBy" : "e942fa3e-a5b9-4a9f-b9a5-a1afd3c29b2c",
        "tags" : [
        ]
      },
      {
        "id" : "15e248b3-750d-4f9f-822d-74c5e3f1c55b",
        "parentId" : "ce6655e3-d67a-4285-a803-e648fe072bf3",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "I don't remember I recommended ever...but yes it's recommended to use wildcard imports when [there're more than  6 entities](https://github.com/databricks/scala-style-guide#imports).\r\n\r\n",
        "createdAt" : "2021-06-03T11:45:04Z",
        "updatedAt" : "2021-06-03T11:48:57Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "ee74e0db-76a0-4de8-9d4a-d7974a42ec7f",
        "parentId" : "ce6655e3-d67a-4285-a803-e648fe072bf3",
        "authorId" : "e942fa3e-a5b9-4a9f-b9a5-a1afd3c29b2c",
        "body" : "You did recommend this change in former reviews. https://github.com/apache/spark/pull/32007#discussion_r622840432",
        "createdAt" : "2021-06-04T07:05:02Z",
        "updatedAt" : "2021-06-04T07:05:03Z",
        "lastEditedBy" : "e942fa3e-a5b9-4a9f-b9a5-a1afd3c29b2c",
        "tags" : [
        ]
      }
    ],
    "commit" : "e630725ca5c161cea62a2afcc7668a67a3e6d72e",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +18,22 @@package org.apache.spark.util\n\nimport java.io._\nimport java.lang.reflect.Field\nimport java.net.{BindException, ServerSocket, URI}"
  },
  {
    "id" : "0cb4d190-09a3-4884-9c18-91672099ba67",
    "prId" : 31742,
    "prUrl" : "https://github.com/apache/spark/pull/31742#pullrequestreview-604458667",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ed5bcaa6-2d85-43f7-a20a-2cf1556d2239",
        "parentId" : null,
        "authorId" : "fd6ebc48-7da4-490b-8d41-2e8530d92720",
        "body" : "The comment blocks above these constants explain that they _must_ have a certain order to them. So I figured it would be helpful to check that ordering explicitly in a test.",
        "createdAt" : "2021-03-04T19:11:37Z",
        "updatedAt" : "2021-03-04T19:11:38Z",
        "lastEditedBy" : "fd6ebc48-7da4-490b-8d41-2e8530d92720",
        "tags" : [
        ]
      }
    ],
    "commit" : "ee6782bd376c0ea7ec720dabc436b9bb69a69651",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +763,767 @@    }\n    assert(SPARK_CONTEXT_SHUTDOWN_PRIORITY < DEFAULT_SHUTDOWN_PRIORITY)\n    assert(TEMP_DIR_SHUTDOWN_PRIORITY < SPARK_CONTEXT_SHUTDOWN_PRIORITY)\n  }\n"
  },
  {
    "id" : "a665f084-1e0e-43c7-8f70-afab1ebaae15",
    "prId" : 28931,
    "prUrl" : "https://github.com/apache/spark/pull/28931#pullrequestreview-444882130",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "75dd7d2b-8a3e-4191-84c2-147689c437d9",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "In this case, it would be great if we check the error message to prevent future regression.",
        "createdAt" : "2020-07-08T15:28:44Z",
        "updatedAt" : "2020-07-10T12:52:38Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "768e7c46bff5b5df76efa52dc30d432b45bb6f16",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +1316,1320 @@    var e: AssertionError = intercept[AssertionError] {\n      Utils.checkHost(\"0.0.0.0:0\")\n    }\n    assert(e.getMessage.contains(\"Expected hostname or IP but got 0.0.0.0:0\"))\n    e = intercept[AssertionError] {"
  },
  {
    "id" : "a81d7c92-ba46-45fd-9845-14e053b58f82",
    "prId" : 24800,
    "prUrl" : "https://github.com/apache/spark/pull/24800#pullrequestreview-247422578",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "621442f0-18b3-41c9-8d31-9906a143f311",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Sorry, but what's new in this test case? The existing test cases seems to cover these, doesn't they?\r\n```\r\ntest(\"redact sensitive information\")\r\ntest(\"redact sensitive information in command line args\")\r\n```",
        "createdAt" : "2019-06-09T01:34:36Z",
        "updatedAt" : "2019-06-10T16:39:38Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "307a12a4-5b6a-4618-aa65-29dcee32496a",
        "parentId" : "621442f0-18b3-41c9-8d31-9906a143f311",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "If the last two cases (`(999, \"spark.my.password=12345\")` and `(\"my.password\", 12345)`)  are meaningful, shall we add the last two only?",
        "createdAt" : "2019-06-09T01:35:35Z",
        "updatedAt" : "2019-06-10T16:39:38Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "d1aae660-bff4-4d46-95cb-2785e866c1ed",
        "parentId" : "621442f0-18b3-41c9-8d31-9906a143f311",
        "authorId" : "f5b3f57a-75a6-496c-af94-c32580ada13a",
        "body" : "Agree first 2 cases are somewhat duplicating, however this test is the more direct/pure unit testing for `Utils.redact`, it spells out the exact contract for it. The other 2 tests seem to test other APIs while eventually call Utils.redact.",
        "createdAt" : "2019-06-10T00:48:09Z",
        "updatedAt" : "2019-06-10T16:39:38Z",
        "lastEditedBy" : "f5b3f57a-75a6-496c-af94-c32580ada13a",
        "tags" : [
        ]
      }
    ],
    "commit" : "1055a220f5eb867d596f708f67a1c9f1c0385e2e",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +1121,1125 @@  }\n\n  test(\"redact sensitive information in sequence of key value pairs\") {\n    val secretKeys = Some(\"my.password\".r)\n    assert(Utils.redact(secretKeys, Seq((\"spark.my.password\", \"12345\"))) ==="
  }
]