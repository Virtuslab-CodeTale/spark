[
  {
    "id" : "cc13fd08-f63e-4c8e-b3d4-b8b1c662491f",
    "prId" : 25551,
    "prUrl" : "https://github.com/apache/spark/pull/25551#pullrequestreview-279189922",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2b22fcd5-6b0c-4303-a38f-3075f55917e2",
        "parentId" : null,
        "authorId" : "0b3111e2-9584-4813-8cb5-8f40e119f71c",
        "body" : "You could have used mockito's `verify` instead of this, but this is ok.",
        "createdAt" : "2019-08-23T19:44:08Z",
        "updatedAt" : "2019-08-23T19:44:16Z",
        "lastEditedBy" : "0b3111e2-9584-4813-8cb5-8f40e119f71c",
        "tags" : [
        ]
      }
    ],
    "commit" : "c8b0da9de38304fbf0f905104f13879ba9bcab17",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +339,343 @@    conf.set(DYN_ALLOCATION_SHUFFLE_TRACKING, true).set(SHUFFLE_SERVICE_ENABLED, true)\n    monitor = new ExecutorMonitor(conf, client, bus, clock) {\n      override def onOtherEvent(event: SparkListenerEvent): Unit = {\n        throw new IllegalStateException(\"No event should be sent.\")\n      }"
  },
  {
    "id" : "6ecf5121-2e5a-4364-8dee-1021d016f1f7",
    "prId" : 24817,
    "prUrl" : "https://github.com/apache/spark/pull/24817#pullrequestreview-255941954",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9bd87e1a-bdfc-4ddd-b6e7-3dfa1245a376",
        "parentId" : null,
        "authorId" : "e913f9af-103d-40d4-976e-9aa8e12e7211",
        "body" : "you should also test another job after this, which references the same shuffles from the earlier jobs, to make sure things get properly moved out of being idle.\r\n\r\nAlso one thing to keep an eye on is that if you re-use old shuffles, the DAGScheduler creates new stages, which then get skipped, but should keep the consistent shuffle ids.  I'm thinking of simple pipelines where they get broken with a count or something, but logically its all one thing eg.\r\n\r\n```scala\r\nval cachedAfterFirstShuffle = someRdd.reduceByKey{ ...}.cache()\r\ncachedAfterFirstShuffle.count() // job 1\r\ncachedAfterFirstShuffle.map ... // job 2, etc.\r\n```",
        "createdAt" : "2019-06-27T16:54:20Z",
        "updatedAt" : "2019-07-15T18:05:50Z",
        "lastEditedBy" : "e913f9af-103d-40d4-976e-9aa8e12e7211",
        "tags" : [
        ]
      },
      {
        "id" : "142482eb-3312-4373-9096-fb10a5ccc998",
        "parentId" : "9bd87e1a-bdfc-4ddd-b6e7-3dfa1245a376",
        "authorId" : "0b3111e2-9584-4813-8cb5-8f40e119f71c",
        "body" : "That's job 3, isn't it? (L318)",
        "createdAt" : "2019-06-27T22:33:28Z",
        "updatedAt" : "2019-07-15T18:05:50Z",
        "lastEditedBy" : "0b3111e2-9584-4813-8cb5-8f40e119f71c",
        "tags" : [
        ]
      },
      {
        "id" : "c9686ba4-3241-483c-a12a-ec9049d794a7",
        "parentId" : "9bd87e1a-bdfc-4ddd-b6e7-3dfa1245a376",
        "authorId" : "e913f9af-103d-40d4-976e-9aa8e12e7211",
        "body" : "again, my fault, I looked at this test too quickly after thinking I had found the bug above",
        "createdAt" : "2019-06-28T19:35:35Z",
        "updatedAt" : "2019-07-15T18:05:50Z",
        "lastEditedBy" : "e913f9af-103d-40d4-976e-9aa8e12e7211",
        "tags" : [
        ]
      }
    ],
    "commit" : "6154bf486e68dbb5a4c16dc9e71030cc20d8ca58",
    "line" : 102,
    "diffHunk" : "@@ -1,1 +320,324 @@    assert(monitor.timedOutExecutors(shuffleDeadline) === Seq(\"1\"))\n\n    // Clean up the shuffles, executor now should now time out at the idle deadline.\n    monitor.shuffleCleaned(0)\n    assert(monitor.timedOutExecutors(idleDeadline).isEmpty)"
  }
]