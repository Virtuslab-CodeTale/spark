[
  {
    "id" : "81512807-62ba-4b27-9561-5af038d96184",
    "prId" : 32389,
    "prUrl" : "https://github.com/apache/spark/pull/32389#pullrequestreview-662272747",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "948c5660-75f3-48c7-bdde-76759a39436f",
        "parentId" : null,
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "nit: `tContext.taskMetrics.createTempShuffleReadMetrics()`",
        "createdAt" : "2021-05-14T21:55:22Z",
        "updatedAt" : "2021-05-14T22:06:59Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      },
      {
        "id" : "e033a98e-2bff-46d3-8db7-c6348a783097",
        "parentId" : "948c5660-75f3-48c7-bdde-76759a39436f",
        "authorId" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "body" : "`taskMetrics()` is defined as an empty-paren method so it should be called with parenthesis:\r\n```\r\n  def taskMetrics(): TaskMetrics\r\n```",
        "createdAt" : "2021-05-17T17:40:53Z",
        "updatedAt" : "2021-05-17T17:41:18Z",
        "lastEditedBy" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "tags" : [
        ]
      },
      {
        "id" : "d449900e-3977-40a2-9fd4-2ee2dc0baea7",
        "parentId" : "948c5660-75f3-48c7-bdde-76759a39436f",
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "You are right !\r\nSo we had broken code before, sigh (that was directly lifted from line: 171 in prev class)",
        "createdAt" : "2021-05-18T15:55:41Z",
        "updatedAt" : "2021-05-18T15:55:41Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      }
    ],
    "commit" : "eea80f5c8c487a7117036b7cfb963137a4b7eeb5",
    "line" : 115,
    "diffHunk" : "@@ -1,1 +159,163 @@      detectCorrupt,\n      detectCorruptUseExtraMemory,\n      shuffleMetrics.getOrElse(tContext.taskMetrics().createTempShuffleReadMetrics()),\n      doBatchFetch)\n  }"
  },
  {
    "id" : "00fea512-2060-44bd-97b5-8a869473b8b8",
    "prId" : 32140,
    "prUrl" : "https://github.com/apache/spark/pull/32140#pullrequestreview-681457279",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "edc39322-7a52-46ad-91f1-a8905126ad40",
        "parentId" : null,
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "Also add tests for:\r\na) deserialization failure results in initiating fallback.\r\nb) fetch failure of both merged block and fallback block should get reported to driver as fetch failure.\r\n\r\nAre these handled already ?",
        "createdAt" : "2021-06-10T17:58:12Z",
        "updatedAt" : "2021-06-10T17:58:43Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      },
      {
        "id" : "a0341f6b-c8ca-466e-806e-1f26b734da3c",
        "parentId" : "edc39322-7a52-46ad-91f1-a8905126ad40",
        "authorId" : "9953a478-bdd8-4f15-be59-f6f654ff85ae",
        "body" : "> a) deserialization failure results in initiating fallback.\r\n\r\nYes, the test `fallback to original shuffle block when a merged block chunk is corrupt` does this. It tests the fallback when the shuffle merged chunk is deserialized during processing of `SuccessFetchResult`.\r\n\r\n> b) fetch failure of both merged block and fallback block should get reported to driver as fetch failure.\r\n\r\nWhen there is a fetch failure of a merged block, then the iterator falls back to fetch original blocks. So, we don't report that to the driver because the task didn't fail because of it. It tries to fetch the original blocks that make up that merged blocks.\r\n\r\nI have added tests for the various conditions that trigger fallback but these simulate fetches of all original blocks to be successful.  I haven't added a test which triggers fallback but the iterator fails to fetch an original block and that throws FetchFailedException. That follows the existing code but I will still add this test for it.\r\n",
        "createdAt" : "2021-06-10T18:42:34Z",
        "updatedAt" : "2021-06-10T18:42:34Z",
        "lastEditedBy" : "9953a478-bdd8-4f15-be59-f6f654ff85ae",
        "tags" : [
        ]
      },
      {
        "id" : "232b135c-9d6a-4046-99dd-5643c683d293",
        "parentId" : "edc39322-7a52-46ad-91f1-a8905126ad40",
        "authorId" : "9953a478-bdd8-4f15-be59-f6f654ff85ae",
        "body" : "I have added test for (b) `failed to fetch merged block as well as fallback block should throw a FetchFailedException`",
        "createdAt" : "2021-06-10T23:57:51Z",
        "updatedAt" : "2021-06-10T23:57:51Z",
        "lastEditedBy" : "9953a478-bdd8-4f15-be59-f6f654ff85ae",
        "tags" : [
        ]
      },
      {
        "id" : "e4d43518-8c94-4906-8084-65a2a590844d",
        "parentId" : "edc39322-7a52-46ad-91f1-a8905126ad40",
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "To clarify, what I meant was that on both failing, driver should see it as a fetch failure (wont see the merge part - but will see a fetch failure).",
        "createdAt" : "2021-06-11T05:19:31Z",
        "updatedAt" : "2021-06-11T05:19:31Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      }
    ],
    "commit" : "ad89a0208a5e3f880fca502c297362388a104dd7",
    "line" : 34,
    "diffHunk" : "@@ -1,1 +49,53 @@\nclass ShuffleBlockFetcherIteratorSuite extends SparkFunSuite with PrivateMethodTester {\n\n  private var transfer: BlockTransferService = _\n  private var mapOutputTracker: MapOutputTracker = _"
  },
  {
    "id" : "7949f0a2-4eb1-4e60-8ddd-9a704e7208c8",
    "prId" : 28911,
    "prUrl" : "https://github.com/apache/spark/pull/28911#pullrequestreview-478159369",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e1466a7a-4b71-4e5d-942b-f6bf2798b85c",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Thank you for adding this helper.",
        "createdAt" : "2020-08-29T22:55:48Z",
        "updatedAt" : "2020-09-01T06:44:20Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "a23ab1721b1225e0a95fb27660fe81847287c622",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +67,71 @@  }\n\n  private def createMockBlockManager(): BlockManager = {\n    val blockManager = mock(classOf[BlockManager])\n    val localBmId = BlockManagerId(\"test-client\", \"test-local-host\", 1)"
  },
  {
    "id" : "9823028e-3938-4ff6-8f5e-3b73b72a0bf7",
    "prId" : 28911,
    "prUrl" : "https://github.com/apache/spark/pull/28911#pullrequestreview-478558578",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8a12c7e4-166e-4304-a5cc-9d8c23cfe64b",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Just a question. Currently, is there an instance which is not using this default?",
        "createdAt" : "2020-08-29T22:57:43Z",
        "updatedAt" : "2020-09-01T06:44:20Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "78aa955d-ddbf-4bcd-94eb-77e651b1cdde",
        "parentId" : "8a12c7e4-166e-4304-a5cc-9d8c23cfe64b",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "tests like:\r\n\r\n`successful 3 local + 4 host local + 2 remote reads`\r\n`fetch continuous blocks in batch successful 3 local + 4 host local + 2 remote reads`",
        "createdAt" : "2020-08-31T12:08:46Z",
        "updatedAt" : "2020-09-01T06:44:20Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "a23ab1721b1225e0a95fb27660fe81847287c622",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +72,76 @@    doReturn(localBmId).when(blockManager).blockManagerId\n    // By default, the mock BlockManager returns None for hostLocalDirManager. One could\n    // still use initHostLocalDirManager() to specify a custom hostLocalDirManager.\n    doReturn(None).when(blockManager).hostLocalDirManager\n    blockManager"
  }
]