[
  {
    "id" : "dd9addf5-8d7b-4aa3-93fa-4d4ddfc05560",
    "prId" : 31166,
    "prUrl" : "https://github.com/apache/spark/pull/31166#pullrequestreview-566950166",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "167c8bfb-487a-4e4c-adf6-0c72ba76ad9e",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Oops..I wondered why it's flaky at this place and thought it was already 60s....",
        "createdAt" : "2021-01-13T07:24:23Z",
        "updatedAt" : "2021-01-13T07:25:17Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "1fa211aa-5b15-4d4b-9210-2c10e4161faf",
        "parentId" : "167c8bfb-487a-4e4c-adf6-0c72ba76ad9e",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "ah, I guess it's a typo : )",
        "createdAt" : "2021-01-13T07:27:46Z",
        "updatedAt" : "2021-01-13T07:27:47Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "e4d9bb9d74e7af58d3fe0726a8c2abf7827be17f",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +50,54 @@        .set(config.STORAGE_DECOMMISSION_ENABLED, isEnabled)\n      sc = new SparkContext(conf)\n      TestUtils.waitUntilExecutorsUp(sc, 2, 60000)\n      val executors = sc.getExecutorIds().toArray\n      val decommissionListener = new SparkListener {"
  },
  {
    "id" : "200e1edd-881c-43ca-a959-7968e8aeab70",
    "prId" : 29817,
    "prUrl" : "https://github.com/apache/spark/pull/29817#pullrequestreview-565574304",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "54ec13f2-e664-4ee1-b3d7-06269f17017c",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "I got test failure in my PR #31131 (the PR is not related to the test I believe):\r\n```\r\n[info] BlockManagerDecommissionIntegrationSuite:\r\n[info] - SPARK-32850: BlockManager decommission should respect the configuration (enabled=false) *** FAILED *** (6 seconds, 165 milliseconds)\r\n[info]   java.util.concurrent.TimeoutException: Can't find 2 executors before 6000 milliseconds elapsed\r\n[info]   at org.apache.spark.TestUtils$.waitUntilExecutorsUp(TestUtils.scala:374)\r\n[info]   at org.apache.spark.storage.BlockManagerDecommissionIntegrationSuite.$anonfun$new$2(BlockManagerDecommissionIntegrationSuite.scala:52)\r\n[info]   at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n```",
        "createdAt" : "2021-01-11T17:19:40Z",
        "updatedAt" : "2021-01-11T17:19:51Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "3c1e033089e392066425139d7ccb52cd501dcc31",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +50,54 @@        .set(config.STORAGE_DECOMMISSION_ENABLED, isEnabled)\n      sc = new SparkContext(conf)\n      TestUtils.waitUntilExecutorsUp(sc, 2, 6000)\n      val executors = sc.getExecutorIds().toArray\n      val decommissionListener = new SparkListener {"
  },
  {
    "id" : "adbf0b01-b744-4767-ab77-c15c440765a0",
    "prId" : 29367,
    "prUrl" : "https://github.com/apache/spark/pull/29367#pullrequestreview-462895798",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d8440fbf-9012-4bcf-9d68-fc7f54c3a2b1",
        "parentId" : null,
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "This definitely is coming from the other PR",
        "createdAt" : "2020-08-06T05:55:18Z",
        "updatedAt" : "2020-08-12T19:09:04Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      },
      {
        "id" : "f45d280e-2e6e-4df3-8d68-57799c47e5fa",
        "parentId" : "d8440fbf-9012-4bcf-9d68-fc7f54c3a2b1",
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "I left a comment in the other PR that said I'd address this in the follow up.",
        "createdAt" : "2020-08-06T19:31:57Z",
        "updatedAt" : "2020-08-12T19:09:04Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      },
      {
        "id" : "7910d2d9-bacb-4914-b955-47ddff73694f",
        "parentId" : "d8440fbf-9012-4bcf-9d68-fc7f54c3a2b1",
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "Ah !. Okay. ",
        "createdAt" : "2020-08-06T21:40:58Z",
        "updatedAt" : "2020-08-12T19:09:04Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      }
    ],
    "commit" : "e970cb10147fb64533f5088edc3a448b5ef198cf",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +280,284 @@\n    // Wait for the executor to be removed automatically after migration.\n    // This is set to a high value since github actions is sometimes high latency\n    // but I've never seen this go for more than a minute.\n    assert(executorRemovedSem.tryAcquire(1, 5L, TimeUnit.MINUTES))"
  },
  {
    "id" : "bc778492-e9c1-48c6-8d71-4392a55322bb",
    "prId" : 29367,
    "prUrl" : "https://github.com/apache/spark/pull/29367#pullrequestreview-464633397",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "58e72430-c84c-40e1-bc8f-fc29f0f0ec33",
        "parentId" : null,
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "Why is this true and not false ? We explicitly want to kill and discard the executor here without replacing it. Although the test does not truly care, but still why the change ?",
        "createdAt" : "2020-08-08T17:27:51Z",
        "updatedAt" : "2020-08-12T19:09:04Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      },
      {
        "id" : "649ee70f-dc1a-4e86-b109-0809905f29af",
        "parentId" : "58e72430-c84c-40e1-bc8f-fc29f0f0ec33",
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "Same please reread the code",
        "createdAt" : "2020-08-08T18:32:11Z",
        "updatedAt" : "2020-08-12T19:09:04Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      },
      {
        "id" : "a4c6f805-62f5-4b80-9d03-eb60e833c2e8",
        "parentId" : "58e72430-c84c-40e1-bc8f-fc29f0f0ec33",
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "Copy pasting the response from the similar comment in `WorkerDecommissionSuite.scala`:\r\n\r\n> I did reread the code and now I am sure I understand it: I think adjustTargetNumExecutors flag should continue to remain false here, so that it matches the old semantics:\r\n>\r\n> Before this PR: decommissioning wouldn't change the requested executors. They remain whatever the test application requested previously. This should continue to hold: This test does not use dynamic allocation and I don't see a need to change this test behavior.\r\n",
        "createdAt" : "2020-08-08T22:16:03Z",
        "updatedAt" : "2020-08-12T19:09:05Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      },
      {
        "id" : "f8be0fc0-d240-47aa-bfe0-f91eb541c263",
        "parentId" : "58e72430-c84c-40e1-bc8f-fc29f0f0ec33",
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "^^^ @holdenk ... any thoughts/followup on this ?",
        "createdAt" : "2020-08-10T19:45:04Z",
        "updatedAt" : "2020-08-12T19:09:05Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      },
      {
        "id" : "5ba2b770-fef3-4f4b-9d38-1e6e6c76b718",
        "parentId" : "58e72430-c84c-40e1-bc8f-fc29f0f0ec33",
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "Same.",
        "createdAt" : "2020-08-10T21:54:02Z",
        "updatedAt" : "2020-08-12T19:09:05Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      },
      {
        "id" : "486a6f95-d4fb-4eb9-8ec3-129bba4967a8",
        "parentId" : "58e72430-c84c-40e1-bc8f-fc29f0f0ec33",
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "This is also resolved. Reasoning sounds good -- although do you want to add the same comment as above: \r\n\r\n// Decommission executor and ensure it is not relaunched by setting adjustTargetNumExecutors",
        "createdAt" : "2020-08-10T22:36:13Z",
        "updatedAt" : "2020-08-12T19:09:05Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      }
    ],
    "commit" : "e970cb10147fb64533f5088edc3a448b5ef198cf",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +194,198 @@      execToDecommission,\n      ExecutorDecommissionInfo(\"\", isHostDecommissioned = false),\n      adjustTargetNumExecutors = true)\n    val decomTime = new SystemClock().getTimeMillis()\n"
  },
  {
    "id" : "aaf26327-9fa3-4716-bbbc-fe705388191f",
    "prId" : 29226,
    "prUrl" : "https://github.com/apache/spark/pull/29226#pullrequestreview-456252052",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ade8ac99-5093-40fc-9b98-f71aafe9253a",
        "parentId" : null,
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "This goes against the purpose of this test: making sure that an executor with a running task that receives a decom has the block migrated. It is not migrating during decommissioning in the same way.",
        "createdAt" : "2020-07-27T19:56:43Z",
        "updatedAt" : "2020-07-29T01:29:23Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      },
      {
        "id" : "bee3fbf3-ec86-4d3e-825b-18566f43e9ad",
        "parentId" : "ade8ac99-5093-40fc-9b98-f71aafe9253a",
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "In which case, I don't follow how this is supposed to work in the first place. Consider the root cause: You decommission an executor while a (result) task is running. The block manager associated with the executor enters the decom state. The task tries to write the RDD persisted block. The block manager fails that because it is decom'd, thereby failing the task. The task reruns somewhere else and the job succeeds. Now you go to check if that executor has migrated the block: That check fails because the block was never written in the first place.\r\n\r\nSo I am relaxing the notion of \"migrate during\" to mean \"migrate while the job is running\". The question is \"which executor\" do you want to decommission and force a migration off ? Picking a wrong executor as above can mean that no migrations indeed happen because no real blocks were written (or written and thence discarded).\r\n\r\nIf that's the intent of the test then I think we need to change the block manager decommissioning (production) code to realize the intent. \r\n\r\nWithout this PR: This test is fundamentally racy and thus provides low signal. The race is between the task's end and the block manager's decommission: If the task ends successfully before the decom, the test passes. Otherwise the test fails.\r\n\r\n",
        "createdAt" : "2020-07-27T20:08:31Z",
        "updatedAt" : "2020-07-29T01:29:23Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      },
      {
        "id" : "63a898fd-3302-4621-a269-a07439152486",
        "parentId" : "ade8ac99-5093-40fc-9b98-f71aafe9253a",
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "So I think another way we could make sure the test covers what we want is to run a job repeatedly until all 3 executors come up.\r\n\r\nThe block manager (in decom state) does indeed refuses puts, but RDD computation on the executor goes through `getOrElseUpdate` which immediately calls `doPutIterator` if there is not a cache hit *before* the iterator starts being computed. Since the check to see if the block manager is decommissioning occurs before the start of the computation, not at the end we want to ensure that block can be put (and then later migrated).\r\n\r\n",
        "createdAt" : "2020-07-27T20:47:10Z",
        "updatedAt" : "2020-07-29T01:29:23Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      },
      {
        "id" : "d2a677cd-59e3-4df3-8f04-24119822611e",
        "parentId" : "ade8ac99-5093-40fc-9b98-f71aafe9253a",
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "Maybe we should add a comment where we do the `isDecommissioning` check to explain that it is intentionally done there so that we don't reject blocks which have already started computation. Do you think that would help?",
        "createdAt" : "2020-07-27T20:48:26Z",
        "updatedAt" : "2020-07-29T01:29:23Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      },
      {
        "id" : "e18d31a8-7399-4379-b1e5-06173cbb6451",
        "parentId" : "ade8ac99-5093-40fc-9b98-f71aafe9253a",
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "> The block manager (in decom state) does indeed refuses puts, but RDD computation on the executor goes through `getOrElseUpdate` which immediately calls `doPutIterator` if there is not a cache hit _before_ the iterator starts being computed.\r\n\r\nI don't see this. This is what I see: (BM stands for BlockManager)\r\n- RDD.getOrCompute -> BM.getOrElseUpdate -> BM.doPutIterator -> BM.doPut \r\n\r\nBM.doPut throws BlockSavedOnDecommissionedBlockManagerException if `isDecommissioning`. And this fails the job. I am not sure what it should do instead off the top of my head since I am new to this codepath. But it is certainly not continuing on with the computation (as far as I can tell).\r\n\r\nIf the intent of the test is indeed to test decommissioning \"Before the task has ended\", I think then we need another BlockManager PR to actually realize it :-) ",
        "createdAt" : "2020-07-27T21:15:03Z",
        "updatedAt" : "2020-07-29T01:29:23Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      },
      {
        "id" : "2d40cdcc-f4d0-47f9-a504-71e0d25e3a7a",
        "parentId" : "ade8ac99-5093-40fc-9b98-f71aafe9253a",
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "I don't believe we need another block manager PR to realize it, I think this is just a flaky test because we took out the original sleep and tried to use TestUtils which doesn't do a good enough job of waiting for the executor to fully come up.\r\n\r\nSince doPut is called *before* the task starts computation, we don't throw away any of the in-progress data.\r\n\r\nI'll make an alternate PR to this one to illustrate my understanding and hopefully we can iron it out and make the code path clear for everyone :) ",
        "createdAt" : "2020-07-27T21:31:35Z",
        "updatedAt" : "2020-07-29T01:29:23Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      },
      {
        "id" : "54471290-58c6-4ac8-9164-07bf79380898",
        "parentId" : "ade8ac99-5093-40fc-9b98-f71aafe9253a",
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "Cool ! Looking forward to your alternate PR to fix this.\r\n\r\n> I don't believe we need another block manager PR to realize it, I think this is just a flaky test because we took out the original sleep and tried to use TestUtils which doesn't do a good enough job of waiting for the executor to fully come up.\r\n\r\nI don't think the issue is that the executor does not come up. It does come up. The issue I think is that it tries to run the task and fails because it is decommissioned.\r\n\r\n> Since doPut is called _before_ the task starts computation, we don't throw away any of the in-progress data.\r\n\r\nI agree that doPut is called _before_ the task starts computation. I didn't follow what you mean by \"in-progress data\" ?. Per my understanding, the task is simply failing before the iterator is even created. \r\n\r\nPlease check this for yourself by doing a decommission in the `onTaskStart` listener callback and ensuring that the task has a long enough sleep time to ensure that it waits for this decommissioning to happen.\r\n\r\n> \r\n> I'll make an alternate PR to this one to illustrate my understanding and hopefully we can iron it out and make the code path clear for everyone :)\r\n\r\nHurray :-) \r\n",
        "createdAt" : "2020-07-27T21:41:48Z",
        "updatedAt" : "2020-07-29T01:29:23Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      },
      {
        "id" : "5e0dd187-1908-497b-b97b-669b1f6fe584",
        "parentId" : "ade8ac99-5093-40fc-9b98-f71aafe9253a",
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "@holdenk, Please take a look at the PR once again. I have added another test to specifically capture the intent of decommissioning after the task has started but before the task has ended. ",
        "createdAt" : "2020-07-28T02:03:50Z",
        "updatedAt" : "2020-07-29T01:29:23Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      }
    ],
    "commit" : "1b469fb0101730916c9327d22cf5b3e27bf4eadb",
    "line" : 183,
    "diffHunk" : "@@ -1,1 +171,175 @@      // Wait for one of the tasks to succeed and finish writing its blocks.\n      // This way we know that this executor had real data to migrate when it is subsequently\n      // decommissioned below.\n      val intervalMs = if (whenToDecom == TaskStarted) {\n        3.milliseconds"
  },
  {
    "id" : "52b25390-38b4-4d7a-afa8-cd9a25a4b661",
    "prId" : 29211,
    "prUrl" : "https://github.com/apache/spark/pull/29211#pullrequestreview-454580531",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a440616c-7f5d-41fa-aff0-acc183fe9291",
        "parentId" : null,
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "Why was this changed to 10 seconds ? If it is related to this PR (as opposed to just reducing flakyness), then please document that.",
        "createdAt" : "2020-07-24T00:14:38Z",
        "updatedAt" : "2020-08-05T18:39:14Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      },
      {
        "id" : "fc0b2c7b-a2b4-4f90-aaa4-495518b87d9c",
        "parentId" : "a440616c-7f5d-41fa-aff0-acc183fe9291",
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "Just reduced the log spam in debugging this test but still allowed the test to complete quickly.",
        "createdAt" : "2020-07-24T00:51:31Z",
        "updatedAt" : "2020-08-05T18:39:14Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      }
    ],
    "commit" : "e81c3fc2d0b8c28cd0aedf08a7ea1e86a153ae49",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +72,76 @@      // Just replicate blocks quickly during testing, there isn't another\n      // workload we need to worry about.\n      .set(config.STORAGE_DECOMMISSION_REPLICATION_REATTEMPT_INTERVAL, 10L)\n\n    if (whenToDecom == TaskStarted) {"
  },
  {
    "id" : "6fa900be-5c03-4748-b01f-6284a20a23b6",
    "prId" : 29211,
    "prUrl" : "https://github.com/apache/spark/pull/29211#pullrequestreview-462017839",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7fb8088e-d8fc-40b6-be9a-674e289a524f",
        "parentId" : null,
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "Can this timeout be shortened ? 5 minutes is a bit long ? Why would it take this much time ? Can we play around with some of the other configs to reduce this ?",
        "createdAt" : "2020-08-04T04:53:15Z",
        "updatedAt" : "2020-08-05T18:39:14Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      },
      {
        "id" : "94000839-784c-432b-9fe3-f6e190246f5a",
        "parentId" : "7fb8088e-d8fc-40b6-be9a-674e289a524f",
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "So this is a high timeout because github actions seems to occasionally be very slow and I figured a higher value here was safer from a test reliability perpsective. I've normally seen these complete in under a minute on my machine. I think it's better to have the high timeout here given our multiple CI environments.",
        "createdAt" : "2020-08-04T13:16:39Z",
        "updatedAt" : "2020-08-05T18:39:14Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      },
      {
        "id" : "22924f40-d7bf-494a-a72f-b3b7f1e0064d",
        "parentId" : "7fb8088e-d8fc-40b6-be9a-674e289a524f",
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "I get that it can take up to 5 minutes, but I would like to understand better whether it should take 5 minutes ? The executor is supposed to exit as soon as the migration is over, right ? Or if there is some polling there -- that polling should ideally be configurable. So the only thing we are really waiting for here is the migration : That migration shouldn't take 5 minutes -- we don't have that much data to migrate.\r\n\r\nPerhaps you can greatly reduce the executor heartbeat interval such  that this can be sped up ? (I use this trick in the other block manager decommissioning test)",
        "createdAt" : "2020-08-04T19:05:31Z",
        "updatedAt" : "2020-08-05T18:39:14Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      },
      {
        "id" : "53dfe101-d150-4787-9708-3f0332a2d3c5",
        "parentId" : "7fb8088e-d8fc-40b6-be9a-674e289a524f",
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "It doesn't take up to 5 minutes in my experience, I'm just picking a high enough timeout it won't flake. I'm not open to changing this, I've dealt with too many flaky tests from timeouts that were set too low.",
        "createdAt" : "2020-08-05T18:38:23Z",
        "updatedAt" : "2020-08-05T18:39:14Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      },
      {
        "id" : "9d611522-6a58-4d82-b92a-a97ab4ce7025",
        "parentId" : "7fb8088e-d8fc-40b6-be9a-674e289a524f",
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "Sounds good. Would it be okay to add a comment about how long does it usually take in the code itself and mention that the larger timeout is for good measure ? ",
        "createdAt" : "2020-08-05T20:57:20Z",
        "updatedAt" : "2020-08-05T20:58:08Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      }
    ],
    "commit" : "e81c3fc2d0b8c28cd0aedf08a7ea1e86a153ae49",
    "line" : 41,
    "diffHunk" : "@@ -1,1 +277,281 @@\n    // Wait for the executor to be removed automatically after migration.\n    assert(executorRemovedSem.tryAcquire(1, 5L, TimeUnit.MINUTES))\n\n    // Since the RDD is cached or shuffled so further usage of same RDD should use the"
  }
]