[
  {
    "id" : "dd9addf5-8d7b-4aa3-93fa-4d4ddfc05560",
    "prId" : 31166,
    "prUrl" : "https://github.com/apache/spark/pull/31166#pullrequestreview-566950166",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "167c8bfb-487a-4e4c-adf6-0c72ba76ad9e",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Oops..I wondered why it's flaky at this place and thought it was already 60s....",
        "createdAt" : "2021-01-13T07:24:23Z",
        "updatedAt" : "2021-01-13T07:25:17Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "1fa211aa-5b15-4d4b-9210-2c10e4161faf",
        "parentId" : "167c8bfb-487a-4e4c-adf6-0c72ba76ad9e",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "ah, I guess it's a typo : )",
        "createdAt" : "2021-01-13T07:27:46Z",
        "updatedAt" : "2021-01-13T07:27:47Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "e4d9bb9d74e7af58d3fe0726a8c2abf7827be17f",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +50,54 @@        .set(config.STORAGE_DECOMMISSION_ENABLED, isEnabled)\n      sc = new SparkContext(conf)\n      TestUtils.waitUntilExecutorsUp(sc, 2, 60000)\n      val executors = sc.getExecutorIds().toArray\n      val decommissionListener = new SparkListener {"
  },
  {
    "id" : "200e1edd-881c-43ca-a959-7968e8aeab70",
    "prId" : 29817,
    "prUrl" : "https://github.com/apache/spark/pull/29817#pullrequestreview-565574304",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "54ec13f2-e664-4ee1-b3d7-06269f17017c",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "I got test failure in my PR #31131 (the PR is not related to the test I believe):\r\n```\r\n[info] BlockManagerDecommissionIntegrationSuite:\r\n[info] - SPARK-32850: BlockManager decommission should respect the configuration (enabled=false) *** FAILED *** (6 seconds, 165 milliseconds)\r\n[info]   java.util.concurrent.TimeoutException: Can't find 2 executors before 6000 milliseconds elapsed\r\n[info]   at org.apache.spark.TestUtils$.waitUntilExecutorsUp(TestUtils.scala:374)\r\n[info]   at org.apache.spark.storage.BlockManagerDecommissionIntegrationSuite.$anonfun$new$2(BlockManagerDecommissionIntegrationSuite.scala:52)\r\n[info]   at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n```",
        "createdAt" : "2021-01-11T17:19:40Z",
        "updatedAt" : "2021-01-11T17:19:51Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "3c1e033089e392066425139d7ccb52cd501dcc31",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +50,54 @@        .set(config.STORAGE_DECOMMISSION_ENABLED, isEnabled)\n      sc = new SparkContext(conf)\n      TestUtils.waitUntilExecutorsUp(sc, 2, 6000)\n      val executors = sc.getExecutorIds().toArray\n      val decommissionListener = new SparkListener {"
  }
]