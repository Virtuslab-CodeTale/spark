[
  {
    "id" : "63712db5-f8e6-4b20-b45a-5976e99bd18c",
    "prId" : 29910,
    "prUrl" : "https://github.com/apache/spark/pull/29910#pullrequestreview-500244416",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "21ac4ec0-b1be-4d93-8f63-456b811b01ee",
        "parentId" : null,
        "authorId" : "334a081c-cba1-403e-ac80-30e6124077d1",
        "body" : "no longer needed ?",
        "createdAt" : "2020-10-01T11:18:02Z",
        "updatedAt" : "2020-10-01T11:18:03Z",
        "lastEditedBy" : "334a081c-cba1-403e-ac80-30e6124077d1",
        "tags" : [
        ]
      }
    ],
    "commit" : "e431fb8edd16f9d112c7a6ead44e6e871db1e17f",
    "line" : 59,
    "diffHunk" : "@@ -1,1 +367,371 @@          throw e;\n        }\n        // The new array could not be allocated, but that is not an issue as it is longer needed,\n        // as all records were spilled.\n      }"
  },
  {
    "id" : "8abe6d64-912d-4b6f-a207-ad2f0abe78e5",
    "prId" : 29787,
    "prUrl" : "https://github.com/apache/spark/pull/29787#pullrequestreview-490693561",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a798021e-a184-4e1f-8ec5-9bae6fff64fe",
        "parentId" : null,
        "authorId" : "ff1f962a-1f58-4eea-92c9-0f188dc7dd78",
        "body" : "`spill()` synchronizes on `UnsafeExternalSorter.this` when accessing `allocatedPages`. I presume this is to avoid concurrency issues with `cleanupResources`. However, I think we're pretty much screwed here anyway if there's a concurrent call to `cleanupResources` as that will free the page of the record that we are loading here.",
        "createdAt" : "2020-09-17T14:59:56Z",
        "updatedAt" : "2020-09-18T08:04:27Z",
        "lastEditedBy" : "ff1f962a-1f58-4eea-92c9-0f188dc7dd78",
        "tags" : [
        ]
      }
    ],
    "commit" : "1728eb32621ee9fcf1c05fd4825f5bf2623bf2f0",
    "line" : 72,
    "diffHunk" : "@@ -1,1 +602,606 @@            // `TaskMemoryManager.acquireExecutionMemory`.\n            pageToFree = lastPage;\n            allocatedPages.clear();\n            lastPage = null;\n          }"
  },
  {
    "id" : "68dd563f-b04f-4654-a8b1-f1c873b80988",
    "prId" : 29787,
    "prUrl" : "https://github.com/apache/spark/pull/29787#pullrequestreview-491239950",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "82bf485d-fe75-4c31-8b7d-8e35fbdf3064",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "when all records have been read, the `numRecords` will be 0, and we will reach the else branch here, which doesn't do spill either?",
        "createdAt" : "2020-09-18T06:42:41Z",
        "updatedAt" : "2020-09-18T08:04:27Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "9d492500-ef92-4d7d-b576-27c49b1b4553",
        "parentId" : "82bf485d-fe75-4c31-8b7d-8e35fbdf3064",
        "authorId" : "ff1f962a-1f58-4eea-92c9-0f188dc7dd78",
        "body" : "There is nothing to spill to disk here, as all records have already been read, but we still need to free the memory. Before this PR we would keep the memory allocated.\r\nAdded a comment to the code to clarify this.",
        "createdAt" : "2020-09-18T08:06:20Z",
        "updatedAt" : "2020-09-18T08:06:20Z",
        "lastEditedBy" : "ff1f962a-1f58-4eea-92c9-0f188dc7dd78",
        "tags" : [
        ]
      }
    ],
    "commit" : "1728eb32621ee9fcf1c05fd4825f5bf2623bf2f0",
    "line" : 37,
    "diffHunk" : "@@ -1,1 +545,549 @@          // Nothing to spill as all records have been read already, but do not return yet, as the\n          // memory still has to be freed.\n          upstream = null;\n        }\n"
  },
  {
    "id" : "8212972e-efb7-4626-840c-40f22472d7ca",
    "prId" : 29785,
    "prUrl" : "https://github.com/apache/spark/pull/29785#pullrequestreview-490564847",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c77abb12-e447-41cb-9968-6d12f7884ab5",
        "parentId" : null,
        "authorId" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "body" : "The inMemSorter currently preallocates memory in its constructor right? What happens to that memory when we hit this block? I think it leaks :)... BTW shouldn't we just check whether the inMemorySorter has memory allocated?",
        "createdAt" : "2020-09-17T12:32:33Z",
        "updatedAt" : "2020-09-25T10:44:05Z",
        "lastEditedBy" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "tags" : [
        ]
      },
      {
        "id" : "27eee8c3-fd86-412f-b880-1bbea88eef4c",
        "parentId" : "c77abb12-e447-41cb-9968-6d12f7884ab5",
        "authorId" : "ff1f962a-1f58-4eea-92c9-0f188dc7dd78",
        "body" : "We won't hit this block with the preallocated memory. Initially `inMemSorter.hasSpaceForAnotherRecord()` will be true, which can only become false after records have been inserted, at which point `inMemSorter.numRecords() <= 0` won't be true anymore.\r\n\r\nWe could just check whether `inMemSorter` has memory allocated, but I tried to somewhat abstract the internals of `inMemSorter`. Not sure if that was the right decision though, given how tightly coupled `UnsafeExternalSorter` and `UnsafeInMemorySorter` currently are.",
        "createdAt" : "2020-09-17T12:46:36Z",
        "updatedAt" : "2020-09-25T10:44:05Z",
        "lastEditedBy" : "ff1f962a-1f58-4eea-92c9-0f188dc7dd78",
        "tags" : [
        ]
      },
      {
        "id" : "3381c21a-921b-4d6d-a4c0-73b51792dd02",
        "parentId" : "c77abb12-e447-41cb-9968-6d12f7884ab5",
        "authorId" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "body" : "Ok, makes sense.",
        "createdAt" : "2020-09-17T12:59:10Z",
        "updatedAt" : "2020-09-25T10:44:05Z",
        "lastEditedBy" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "tags" : [
        ]
      }
    ],
    "commit" : "fc510ebb94ea54228dc004d63b79b898b8203dde",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +344,348 @@    assert(inMemSorter != null);\n    if (!inMemSorter.hasSpaceForAnotherRecord()) {\n      if (inMemSorter.numRecords() <= 0) {\n        // Spilling was triggered just before this method was called. The pointer array was freed\n        // during the spill, so a new pointer array needs to be allocated here."
  },
  {
    "id" : "b4916bf4-1f13-47cd-a3b5-6516f18c6179",
    "prId" : 29772,
    "prUrl" : "https://github.com/apache/spark/pull/29772#pullrequestreview-489717424",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0b9a7806-f92d-4eaf-b13c-414aaa25c3b9",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I haven't touched this file for a long time. Do you mind providing more context? Does `inMemSorter == null || numRecords <= 0` mean this sorter has not been inserted any records yet?",
        "createdAt" : "2020-09-16T14:55:03Z",
        "updatedAt" : "2020-09-16T14:55:03Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "dc59c9e3-567b-4f97-b15b-289e00e67baa",
        "parentId" : "0b9a7806-f92d-4eaf-b13c-414aaa25c3b9",
        "authorId" : "ff1f962a-1f58-4eea-92c9-0f188dc7dd78",
        "body" : "I think it was originally supposed to mean this, but it could also mean that all records have been read. This is actually a bug as during the call to spill it would prevent freeing the memory that's no longer necessary. I've kept this bug here to keep the changelist as small as possible (there's a little bit more to this than just removing the check). I'll address this issue in a separate ticket.",
        "createdAt" : "2020-09-16T14:59:41Z",
        "updatedAt" : "2020-09-16T15:00:24Z",
        "lastEditedBy" : "ff1f962a-1f58-4eea-92c9-0f188dc7dd78",
        "tags" : [
        ]
      }
    ],
    "commit" : "e514327b4e071f0e4c8e3402cbf03d54c83ab8a4",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +528,532 @@    public long spill() throws IOException {\n      synchronized (this) {\n        if (inMemSorter == null || numRecords <= 0) {\n          return 0L;\n        }"
  },
  {
    "id" : "ff124520-739e-4226-afe2-16a22c546e84",
    "prId" : 28780,
    "prUrl" : "https://github.com/apache/spark/pull/28780#pullrequestreview-435402299",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a2f17dc5-8cbe-4387-b5b9-ccc7b2f17023",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Why didn't you set this value in the caller side (`UnsafeKVExternalSorter`)?",
        "createdAt" : "2020-06-10T09:34:55Z",
        "updatedAt" : "2020-06-10T09:34:56Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "91af3e99-c042-4417-a18c-cfc522f3938a",
        "parentId" : "a2f17dc5-8cbe-4387-b5b9-ccc7b2f17023",
        "authorId" : "31f9c2ba-7775-44e4-b6fa-5e9ab26c8dff",
        "body" : "I have no strong preference on this.  One benefits is that others who calls `createWithExistingInMemorySorter` will not forget to update memory spilled any more. (though only `UnsafeKVExternalSorter` used this function currently)",
        "createdAt" : "2020-06-10T12:17:40Z",
        "updatedAt" : "2020-06-10T12:17:41Z",
        "lastEditedBy" : "31f9c2ba-7775-44e4-b6fa-5e9ab26c8dff",
        "tags" : [
        ]
      },
      {
        "id" : "62e933eb-b077-4610-a51f-436e996d3ec6",
        "parentId" : "a2f17dc5-8cbe-4387-b5b9-ccc7b2f17023",
        "authorId" : "31f9c2ba-7775-44e4-b6fa-5e9ab26c8dff",
        "body" : "cc @maropu @cloud-fan ",
        "createdAt" : "2020-06-15T11:26:09Z",
        "updatedAt" : "2020-06-15T11:26:10Z",
        "lastEditedBy" : "31f9c2ba-7775-44e4-b6fa-5e9ab26c8dff",
        "tags" : [
        ]
      },
      {
        "id" : "39a609fc-ed54-4590-ac53-1484ce05950b",
        "parentId" : "a2f17dc5-8cbe-4387-b5b9-ccc7b2f17023",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Is it the same to use `inMemorySorter.getMemoryUsage`?\r\n\r\nAlso, shall we update `sorter.totalSpillBytes`?",
        "createdAt" : "2020-06-22T06:15:39Z",
        "updatedAt" : "2020-06-22T06:15:46Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "9affd9ab-bd4a-4ae5-a137-3d7a2a59cfef",
        "parentId" : "a2f17dc5-8cbe-4387-b5b9-ccc7b2f17023",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Or, if we can do `final long spillSize = freeMemory() + inMemorySorter.getMemoryUsage()` in `sorter.spill()`? \r\n\r\nSeem like the size of inMemorySorter is included in log info by `getMemoryUsage()`, while `spillSize` doesn't.",
        "createdAt" : "2020-06-22T06:36:12Z",
        "updatedAt" : "2020-06-22T06:37:42Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "25b7d686-405f-4716-9ede-9cffe6b0673a",
        "parentId" : "a2f17dc5-8cbe-4387-b5b9-ccc7b2f17023",
        "authorId" : "31f9c2ba-7775-44e4-b6fa-5e9ab26c8dff",
        "body" : "> Is it the same to use `inMemorySorter.getMemoryUsage`?\r\n> \r\n> Also, shall we update `sorter.totalSpillBytes`?\r\n\r\n1. It's not the same with `inMemorySorter.getMemoryUsage`.\r\n\r\nWhen we insert a record into `UnsafeExternalSorter`, the record itself is copied to sorter's `allocatedPages`, and stores the memory address into `InMemorySorter`. So when we spill it, the memory size is the sum of `inMemorySorter.getMemoryUsage` \r\n and `allocatePages`, that's what it does in `UnsafeExternalSorter.spill`.\r\n\r\nBut when we do `sorter.spill`  in `UnsafeExternalSorter.createWithExistingInMemorySorter`,  the sorter's `allocatedPages` is empty since we didn't copy any records to it. The memory address in `inMemorySorter` points to the memory pages in `BytesToBytesMap`.\r\n\r\nThe passed parameter denotes the size of memory pages in `BytesToBytesMap`.\r\n\r\n2. yes, seems we also need to update `sorter.totalSpillBytes`",
        "createdAt" : "2020-06-22T09:53:17Z",
        "updatedAt" : "2020-06-22T09:53:18Z",
        "lastEditedBy" : "31f9c2ba-7775-44e4-b6fa-5e9ab26c8dff",
        "tags" : [
        ]
      },
      {
        "id" : "f56615a1-d3c4-450f-b49a-f61af3bad099",
        "parentId" : "a2f17dc5-8cbe-4387-b5b9-ccc7b2f17023",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "I see, thanks for your explanation.",
        "createdAt" : "2020-06-23T02:46:14Z",
        "updatedAt" : "2020-06-23T02:46:14Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "247ebaf3188ddd5f5522749ab19e057711486aec",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +111,115 @@        pageSizeBytes, numElementsForSpillThreshold, inMemorySorter, false /* ignored */);\n    sorter.spill(Long.MAX_VALUE, sorter);\n    taskContext.taskMetrics().incMemoryBytesSpilled(existingMemoryConsumption);\n    // The external sorter will be used to insert records, in-memory sorter is not needed.\n    sorter.inMemSorter = null;"
  },
  {
    "id" : "19b7c2c9-c5bf-40a5-982b-f20937b23a82",
    "prId" : 28780,
    "prUrl" : "https://github.com/apache/spark/pull/28780#pullrequestreview-434780134",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bf5cfddc-b1c3-41d0-86e1-2727a4d8baec",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "just for reference, where do we update the disk spill metrics?",
        "createdAt" : "2020-06-22T07:47:53Z",
        "updatedAt" : "2020-06-22T07:47:53Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "6ab7d11d-2f44-4c08-8ed7-e994a7a5dffb",
        "parentId" : "bf5cfddc-b1c3-41d0-86e1-2727a4d8baec",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "You can see it at the end of `sorter.spill()`.",
        "createdAt" : "2020-06-22T09:46:47Z",
        "updatedAt" : "2020-06-22T09:46:48Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "35b3043c-c1c6-436c-9617-8ea1249d9f1c",
        "parentId" : "bf5cfddc-b1c3-41d0-86e1-2727a4d8baec",
        "authorId" : "31f9c2ba-7775-44e4-b6fa-5e9ab26c8dff",
        "body" : "At the end of `sorter.spill`,  it increase memory bytes spilled and disk bytes spilled. \r\nBut the size of memory bytes spilled is not correct because the real data pages are not `UnsafeExternalSorter.allocatedPages`, but `BytesToBytesMap.dataPages`,  as explained here https://github.com/apache/spark/pull/28780#discussion_r443445290, but the disk bytes spilled is correct because it's the real size write to disk.",
        "createdAt" : "2020-06-22T10:03:32Z",
        "updatedAt" : "2020-06-22T10:03:32Z",
        "lastEditedBy" : "31f9c2ba-7775-44e4-b6fa-5e9ab26c8dff",
        "tags" : [
        ]
      }
    ],
    "commit" : "247ebaf3188ddd5f5522749ab19e057711486aec",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +111,115 @@        pageSizeBytes, numElementsForSpillThreshold, inMemorySorter, false /* ignored */);\n    sorter.spill(Long.MAX_VALUE, sorter);\n    taskContext.taskMetrics().incMemoryBytesSpilled(existingMemoryConsumption);\n    // The external sorter will be used to insert records, in-memory sorter is not needed.\n    sorter.inMemSorter = null;"
  },
  {
    "id" : "512b6b6b-099f-456f-8089-544d0c6b683c",
    "prId" : 27246,
    "prUrl" : "https://github.com/apache/spark/pull/27246#pullrequestreview-425723324",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "03357931-323a-4695-98ff-3c8ee6e5693e",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "```\r\n    @Override\r\n    public void loadNext() throws IOException {\r\n      this.hasNext();\r\n    }\r\n```",
        "createdAt" : "2020-06-04T00:20:28Z",
        "updatedAt" : "2020-08-01T17:33:48Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "6e209293-d432-4ac4-a6c8-1a277e2ce781",
        "parentId" : "03357931-323a-4695-98ff-3c8ee6e5693e",
        "authorId" : "39b78cdc-063e-4571-aeca-1b5a0e92b697",
        "body" : "Thank you for the suggestion. I will start my feedback with my understanding of your suggestion. Your idea is to reuse the code. You are proposing that content of loadNext() method be replaced by invocation of method hasNext().\r\n\r\nI would kindly suggest if you could look loadNext() method again. Perhaps you missed the fact that last call inside of loadNext()  is “current.loadNext()”. The last call of hasNext() method is “current.hasNext()”. If we follow your recommendation, then we would change behavior of loadNext() method. I think that loadNext() moves to the next element, and hasNext() check if next element exists but it does not move to the next element. I believe that we cannot reuse the code here.\r\n\r\nCould you please let me know if my reasoning make sense. Thank you for your time.",
        "createdAt" : "2020-06-06T01:42:08Z",
        "updatedAt" : "2020-08-01T17:33:48Z",
        "lastEditedBy" : "39b78cdc-063e-4571-aeca-1b5a0e92b697",
        "tags" : [
        ]
      },
      {
        "id" : "b6877359-13b4-40cc-8d47-5dfb6f681c06",
        "parentId" : "03357931-323a-4695-98ff-3c8ee6e5693e",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Sounds fine.",
        "createdAt" : "2020-06-06T08:07:15Z",
        "updatedAt" : "2020-08-01T17:33:48Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "9d5bd99e317d5d0f73b645f8e29276c5d99ed39a",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +698,702 @@\n    @Override\n    public void loadNext() throws IOException {\n      nextIterator();\n      current.loadNext();"
  },
  {
    "id" : "811ac449-4ad5-49e8-bd18-23b2ae9d947f",
    "prId" : 27246,
    "prUrl" : "https://github.com/apache/spark/pull/27246#pullrequestreview-425702972",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e0c94d7d-d9ba-41fa-ae8d-269073d43d1e",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "nit: How about this? (Semantically, `this.current` should be null before `initializeNumRecords` called)\r\n```\r\n    ChainedIterator(Queue<UnsafeSorterIterator> iterators) {\r\n      ...\r\n      this.current = null;\r\n    }\r\n\r\n    private void initializeNumRecords() throws IOException {\r\n      if (numRecords == 0) {\r\n        for (UnsafeSorterIterator iter: iterators) {\r\n          numRecords += iter.getNumRecords();\r\n        }\r\n        this.current = iterators.remove();\r\n      }\r\n    }\r\n```",
        "createdAt" : "2020-06-04T00:25:34Z",
        "updatedAt" : "2020-08-01T17:33:48Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "00d8890c-9c3b-42f8-bb36-7da69a099a1b",
        "parentId" : "e0c94d7d-d9ba-41fa-ae8d-269073d43d1e",
        "authorId" : "39b78cdc-063e-4571-aeca-1b5a0e92b697",
        "body" : "Thank you for the suggestion. It make sense. I will do it and test it.",
        "createdAt" : "2020-06-06T01:43:41Z",
        "updatedAt" : "2020-08-01T17:33:48Z",
        "lastEditedBy" : "39b78cdc-063e-4571-aeca-1b5a0e92b697",
        "tags" : [
        ]
      }
    ],
    "commit" : "9d5bd99e317d5d0f73b645f8e29276c5d99ed39a",
    "line" : 58,
    "diffHunk" : "@@ -1,1 +722,726 @@        this.current = iterators.remove();\n      }\n    }\n\n    private void nextIterator() throws IOException {"
  },
  {
    "id" : "b3c7fea0-7c47-4647-a51b-9621bb59c002",
    "prId" : 26323,
    "prUrl" : "https://github.com/apache/spark/pull/26323#pullrequestreview-319849170",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4e78f6e8-756b-4fc4-a13a-7bac34295de2",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "low-level code is hard to review as nobody remembers all the details all the time. Can you briefly explain the spill process to help people review?",
        "createdAt" : "2019-11-19T11:43:48Z",
        "updatedAt" : "2019-11-19T11:43:48Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "15b07014-e704-4b42-ba3e-e7fba4753c01",
        "parentId" : "4e78f6e8-756b-4fc4-a13a-7bac34295de2",
        "authorId" : "8de20372-3c43-4f6b-838b-45ccb852019b",
        "body" : "Before [SPARK-14851](https://issues.apache.org/jira/browse/SPARK-14851), ```UnsafeInMemorySorter.getSortedIterator()```, the returned type is ```UnsafeInMemorySorter.SortedIterator```.\r\n\r\nNow, when the radio sort is turned on and there are some empty values, the return type is ```UnsafeExternalSorter.ChainedIterator(UnsafeInMemorySorter.SortedIterator)```.\r\nIn ```UnsafeExternalSorter.SpillableIterator#spill```, this situation cannot be spilled.\r\n\r\n\r\nWhen ```UnsafeExternalSorter#getSortedIterator``` is called, part of the last written data is saved in memory.\r\n\r\nWhen the task needs more execution memory, the spill fails.\r\n\r\nTaskMemoryManager#acquireExecutionMemory->UnsafeExternalSorter#spill->UnsafeExternalSorter.SpillableIterator#spill",
        "createdAt" : "2019-11-20T13:46:58Z",
        "updatedAt" : "2019-11-20T13:46:59Z",
        "lastEditedBy" : "8de20372-3c43-4f6b-838b-45ccb852019b",
        "tags" : [
        ]
      }
    ],
    "commit" : "b916e017df8837e162bc035975949244b149adcf",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +519,523 @@    }\n\n    public long spill() throws IOException {\n      synchronized (this) {\n        if (!(nextUpstream == null && numRecords > 0)) {"
  }
]