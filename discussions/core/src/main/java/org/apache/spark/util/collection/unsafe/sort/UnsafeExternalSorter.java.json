[
  {
    "id" : "63712db5-f8e6-4b20-b45a-5976e99bd18c",
    "prId" : 29910,
    "prUrl" : "https://github.com/apache/spark/pull/29910#pullrequestreview-500244416",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "21ac4ec0-b1be-4d93-8f63-456b811b01ee",
        "parentId" : null,
        "authorId" : "334a081c-cba1-403e-ac80-30e6124077d1",
        "body" : "no longer needed ?",
        "createdAt" : "2020-10-01T11:18:02Z",
        "updatedAt" : "2020-10-01T11:18:03Z",
        "lastEditedBy" : "334a081c-cba1-403e-ac80-30e6124077d1",
        "tags" : [
        ]
      }
    ],
    "commit" : "e431fb8edd16f9d112c7a6ead44e6e871db1e17f",
    "line" : 59,
    "diffHunk" : "@@ -1,1 +367,371 @@          throw e;\n        }\n        // The new array could not be allocated, but that is not an issue as it is longer needed,\n        // as all records were spilled.\n      }"
  },
  {
    "id" : "8abe6d64-912d-4b6f-a207-ad2f0abe78e5",
    "prId" : 29787,
    "prUrl" : "https://github.com/apache/spark/pull/29787#pullrequestreview-490693561",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a798021e-a184-4e1f-8ec5-9bae6fff64fe",
        "parentId" : null,
        "authorId" : "ff1f962a-1f58-4eea-92c9-0f188dc7dd78",
        "body" : "`spill()` synchronizes on `UnsafeExternalSorter.this` when accessing `allocatedPages`. I presume this is to avoid concurrency issues with `cleanupResources`. However, I think we're pretty much screwed here anyway if there's a concurrent call to `cleanupResources` as that will free the page of the record that we are loading here.",
        "createdAt" : "2020-09-17T14:59:56Z",
        "updatedAt" : "2020-09-18T08:04:27Z",
        "lastEditedBy" : "ff1f962a-1f58-4eea-92c9-0f188dc7dd78",
        "tags" : [
        ]
      }
    ],
    "commit" : "1728eb32621ee9fcf1c05fd4825f5bf2623bf2f0",
    "line" : 72,
    "diffHunk" : "@@ -1,1 +602,606 @@            // `TaskMemoryManager.acquireExecutionMemory`.\n            pageToFree = lastPage;\n            allocatedPages.clear();\n            lastPage = null;\n          }"
  },
  {
    "id" : "68dd563f-b04f-4654-a8b1-f1c873b80988",
    "prId" : 29787,
    "prUrl" : "https://github.com/apache/spark/pull/29787#pullrequestreview-491239950",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "82bf485d-fe75-4c31-8b7d-8e35fbdf3064",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "when all records have been read, the `numRecords` will be 0, and we will reach the else branch here, which doesn't do spill either?",
        "createdAt" : "2020-09-18T06:42:41Z",
        "updatedAt" : "2020-09-18T08:04:27Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "9d492500-ef92-4d7d-b576-27c49b1b4553",
        "parentId" : "82bf485d-fe75-4c31-8b7d-8e35fbdf3064",
        "authorId" : "ff1f962a-1f58-4eea-92c9-0f188dc7dd78",
        "body" : "There is nothing to spill to disk here, as all records have already been read, but we still need to free the memory. Before this PR we would keep the memory allocated.\r\nAdded a comment to the code to clarify this.",
        "createdAt" : "2020-09-18T08:06:20Z",
        "updatedAt" : "2020-09-18T08:06:20Z",
        "lastEditedBy" : "ff1f962a-1f58-4eea-92c9-0f188dc7dd78",
        "tags" : [
        ]
      }
    ],
    "commit" : "1728eb32621ee9fcf1c05fd4825f5bf2623bf2f0",
    "line" : 37,
    "diffHunk" : "@@ -1,1 +545,549 @@          // Nothing to spill as all records have been read already, but do not return yet, as the\n          // memory still has to be freed.\n          upstream = null;\n        }\n"
  },
  {
    "id" : "8212972e-efb7-4626-840c-40f22472d7ca",
    "prId" : 29785,
    "prUrl" : "https://github.com/apache/spark/pull/29785#pullrequestreview-490564847",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c77abb12-e447-41cb-9968-6d12f7884ab5",
        "parentId" : null,
        "authorId" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "body" : "The inMemSorter currently preallocates memory in its constructor right? What happens to that memory when we hit this block? I think it leaks :)... BTW shouldn't we just check whether the inMemorySorter has memory allocated?",
        "createdAt" : "2020-09-17T12:32:33Z",
        "updatedAt" : "2020-09-25T10:44:05Z",
        "lastEditedBy" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "tags" : [
        ]
      },
      {
        "id" : "27eee8c3-fd86-412f-b880-1bbea88eef4c",
        "parentId" : "c77abb12-e447-41cb-9968-6d12f7884ab5",
        "authorId" : "ff1f962a-1f58-4eea-92c9-0f188dc7dd78",
        "body" : "We won't hit this block with the preallocated memory. Initially `inMemSorter.hasSpaceForAnotherRecord()` will be true, which can only become false after records have been inserted, at which point `inMemSorter.numRecords() <= 0` won't be true anymore.\r\n\r\nWe could just check whether `inMemSorter` has memory allocated, but I tried to somewhat abstract the internals of `inMemSorter`. Not sure if that was the right decision though, given how tightly coupled `UnsafeExternalSorter` and `UnsafeInMemorySorter` currently are.",
        "createdAt" : "2020-09-17T12:46:36Z",
        "updatedAt" : "2020-09-25T10:44:05Z",
        "lastEditedBy" : "ff1f962a-1f58-4eea-92c9-0f188dc7dd78",
        "tags" : [
        ]
      },
      {
        "id" : "3381c21a-921b-4d6d-a4c0-73b51792dd02",
        "parentId" : "c77abb12-e447-41cb-9968-6d12f7884ab5",
        "authorId" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "body" : "Ok, makes sense.",
        "createdAt" : "2020-09-17T12:59:10Z",
        "updatedAt" : "2020-09-25T10:44:05Z",
        "lastEditedBy" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "tags" : [
        ]
      }
    ],
    "commit" : "fc510ebb94ea54228dc004d63b79b898b8203dde",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +344,348 @@    assert(inMemSorter != null);\n    if (!inMemSorter.hasSpaceForAnotherRecord()) {\n      if (inMemSorter.numRecords() <= 0) {\n        // Spilling was triggered just before this method was called. The pointer array was freed\n        // during the spill, so a new pointer array needs to be allocated here."
  },
  {
    "id" : "b4916bf4-1f13-47cd-a3b5-6516f18c6179",
    "prId" : 29772,
    "prUrl" : "https://github.com/apache/spark/pull/29772#pullrequestreview-489717424",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0b9a7806-f92d-4eaf-b13c-414aaa25c3b9",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I haven't touched this file for a long time. Do you mind providing more context? Does `inMemSorter == null || numRecords <= 0` mean this sorter has not been inserted any records yet?",
        "createdAt" : "2020-09-16T14:55:03Z",
        "updatedAt" : "2020-09-16T14:55:03Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "dc59c9e3-567b-4f97-b15b-289e00e67baa",
        "parentId" : "0b9a7806-f92d-4eaf-b13c-414aaa25c3b9",
        "authorId" : "ff1f962a-1f58-4eea-92c9-0f188dc7dd78",
        "body" : "I think it was originally supposed to mean this, but it could also mean that all records have been read. This is actually a bug as during the call to spill it would prevent freeing the memory that's no longer necessary. I've kept this bug here to keep the changelist as small as possible (there's a little bit more to this than just removing the check). I'll address this issue in a separate ticket.",
        "createdAt" : "2020-09-16T14:59:41Z",
        "updatedAt" : "2020-09-16T15:00:24Z",
        "lastEditedBy" : "ff1f962a-1f58-4eea-92c9-0f188dc7dd78",
        "tags" : [
        ]
      }
    ],
    "commit" : "e514327b4e071f0e4c8e3402cbf03d54c83ab8a4",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +528,532 @@    public long spill() throws IOException {\n      synchronized (this) {\n        if (inMemSorter == null || numRecords <= 0) {\n          return 0L;\n        }"
  },
  {
    "id" : "ff124520-739e-4226-afe2-16a22c546e84",
    "prId" : 28780,
    "prUrl" : "https://github.com/apache/spark/pull/28780#pullrequestreview-435402299",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a2f17dc5-8cbe-4387-b5b9-ccc7b2f17023",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Why didn't you set this value in the caller side (`UnsafeKVExternalSorter`)?",
        "createdAt" : "2020-06-10T09:34:55Z",
        "updatedAt" : "2020-06-10T09:34:56Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "91af3e99-c042-4417-a18c-cfc522f3938a",
        "parentId" : "a2f17dc5-8cbe-4387-b5b9-ccc7b2f17023",
        "authorId" : "31f9c2ba-7775-44e4-b6fa-5e9ab26c8dff",
        "body" : "I have no strong preference on this.  One benefits is that others who calls `createWithExistingInMemorySorter` will not forget to update memory spilled any more. (though only `UnsafeKVExternalSorter` used this function currently)",
        "createdAt" : "2020-06-10T12:17:40Z",
        "updatedAt" : "2020-06-10T12:17:41Z",
        "lastEditedBy" : "31f9c2ba-7775-44e4-b6fa-5e9ab26c8dff",
        "tags" : [
        ]
      },
      {
        "id" : "62e933eb-b077-4610-a51f-436e996d3ec6",
        "parentId" : "a2f17dc5-8cbe-4387-b5b9-ccc7b2f17023",
        "authorId" : "31f9c2ba-7775-44e4-b6fa-5e9ab26c8dff",
        "body" : "cc @maropu @cloud-fan ",
        "createdAt" : "2020-06-15T11:26:09Z",
        "updatedAt" : "2020-06-15T11:26:10Z",
        "lastEditedBy" : "31f9c2ba-7775-44e4-b6fa-5e9ab26c8dff",
        "tags" : [
        ]
      },
      {
        "id" : "39a609fc-ed54-4590-ac53-1484ce05950b",
        "parentId" : "a2f17dc5-8cbe-4387-b5b9-ccc7b2f17023",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Is it the same to use `inMemorySorter.getMemoryUsage`?\r\n\r\nAlso, shall we update `sorter.totalSpillBytes`?",
        "createdAt" : "2020-06-22T06:15:39Z",
        "updatedAt" : "2020-06-22T06:15:46Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "9affd9ab-bd4a-4ae5-a137-3d7a2a59cfef",
        "parentId" : "a2f17dc5-8cbe-4387-b5b9-ccc7b2f17023",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Or, if we can do `final long spillSize = freeMemory() + inMemorySorter.getMemoryUsage()` in `sorter.spill()`? \r\n\r\nSeem like the size of inMemorySorter is included in log info by `getMemoryUsage()`, while `spillSize` doesn't.",
        "createdAt" : "2020-06-22T06:36:12Z",
        "updatedAt" : "2020-06-22T06:37:42Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "25b7d686-405f-4716-9ede-9cffe6b0673a",
        "parentId" : "a2f17dc5-8cbe-4387-b5b9-ccc7b2f17023",
        "authorId" : "31f9c2ba-7775-44e4-b6fa-5e9ab26c8dff",
        "body" : "> Is it the same to use `inMemorySorter.getMemoryUsage`?\r\n> \r\n> Also, shall we update `sorter.totalSpillBytes`?\r\n\r\n1. It's not the same with `inMemorySorter.getMemoryUsage`.\r\n\r\nWhen we insert a record into `UnsafeExternalSorter`, the record itself is copied to sorter's `allocatedPages`, and stores the memory address into `InMemorySorter`. So when we spill it, the memory size is the sum of `inMemorySorter.getMemoryUsage` \r\n and `allocatePages`, that's what it does in `UnsafeExternalSorter.spill`.\r\n\r\nBut when we do `sorter.spill`  in `UnsafeExternalSorter.createWithExistingInMemorySorter`,  the sorter's `allocatedPages` is empty since we didn't copy any records to it. The memory address in `inMemorySorter` points to the memory pages in `BytesToBytesMap`.\r\n\r\nThe passed parameter denotes the size of memory pages in `BytesToBytesMap`.\r\n\r\n2. yes, seems we also need to update `sorter.totalSpillBytes`",
        "createdAt" : "2020-06-22T09:53:17Z",
        "updatedAt" : "2020-06-22T09:53:18Z",
        "lastEditedBy" : "31f9c2ba-7775-44e4-b6fa-5e9ab26c8dff",
        "tags" : [
        ]
      },
      {
        "id" : "f56615a1-d3c4-450f-b49a-f61af3bad099",
        "parentId" : "a2f17dc5-8cbe-4387-b5b9-ccc7b2f17023",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "I see, thanks for your explanation.",
        "createdAt" : "2020-06-23T02:46:14Z",
        "updatedAt" : "2020-06-23T02:46:14Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "247ebaf3188ddd5f5522749ab19e057711486aec",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +111,115 @@        pageSizeBytes, numElementsForSpillThreshold, inMemorySorter, false /* ignored */);\n    sorter.spill(Long.MAX_VALUE, sorter);\n    taskContext.taskMetrics().incMemoryBytesSpilled(existingMemoryConsumption);\n    // The external sorter will be used to insert records, in-memory sorter is not needed.\n    sorter.inMemSorter = null;"
  },
  {
    "id" : "19b7c2c9-c5bf-40a5-982b-f20937b23a82",
    "prId" : 28780,
    "prUrl" : "https://github.com/apache/spark/pull/28780#pullrequestreview-434780134",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bf5cfddc-b1c3-41d0-86e1-2727a4d8baec",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "just for reference, where do we update the disk spill metrics?",
        "createdAt" : "2020-06-22T07:47:53Z",
        "updatedAt" : "2020-06-22T07:47:53Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "6ab7d11d-2f44-4c08-8ed7-e994a7a5dffb",
        "parentId" : "bf5cfddc-b1c3-41d0-86e1-2727a4d8baec",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "You can see it at the end of `sorter.spill()`.",
        "createdAt" : "2020-06-22T09:46:47Z",
        "updatedAt" : "2020-06-22T09:46:48Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "35b3043c-c1c6-436c-9617-8ea1249d9f1c",
        "parentId" : "bf5cfddc-b1c3-41d0-86e1-2727a4d8baec",
        "authorId" : "31f9c2ba-7775-44e4-b6fa-5e9ab26c8dff",
        "body" : "At the end of `sorter.spill`,  it increase memory bytes spilled and disk bytes spilled. \r\nBut the size of memory bytes spilled is not correct because the real data pages are not `UnsafeExternalSorter.allocatedPages`, but `BytesToBytesMap.dataPages`,  as explained here https://github.com/apache/spark/pull/28780#discussion_r443445290, but the disk bytes spilled is correct because it's the real size write to disk.",
        "createdAt" : "2020-06-22T10:03:32Z",
        "updatedAt" : "2020-06-22T10:03:32Z",
        "lastEditedBy" : "31f9c2ba-7775-44e4-b6fa-5e9ab26c8dff",
        "tags" : [
        ]
      }
    ],
    "commit" : "247ebaf3188ddd5f5522749ab19e057711486aec",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +111,115 @@        pageSizeBytes, numElementsForSpillThreshold, inMemorySorter, false /* ignored */);\n    sorter.spill(Long.MAX_VALUE, sorter);\n    taskContext.taskMetrics().incMemoryBytesSpilled(existingMemoryConsumption);\n    // The external sorter will be used to insert records, in-memory sorter is not needed.\n    sorter.inMemSorter = null;"
  }
]