[
  {
    "id" : "9d46fb33-81ae-4f6a-9308-fe4bdc3180af",
    "prId" : 32401,
    "prUrl" : "https://github.com/apache/spark/pull/32401#pullrequestreview-684717353",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dd279e0c-b964-4060-bb44-f66dc3398a77",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "TBH I don't think the current shuffle API provides enough abstraction to do checksum. I'm OK with this change as the shuffle API is still private, but we should revisit the shuffle API later, so that checksum can be done at the shuffle implementation side.\r\n\r\nThe current issue I see is, Spark writes local spill files and then asks the shuffle implementation to \"transfer\" the spill files. Then Spark has to do checksum by itself during spill file writing, to reduce the perf overhead.\r\n\r\nWe can discuss it later.",
        "createdAt" : "2021-06-16T04:44:28Z",
        "updatedAt" : "2021-06-16T04:44:29Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "4bdde58a3791691f275968b117eeff260ef3016f",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +77,81 @@   *                  partition id) if shuffle checksum enabled. Otherwise, it's empty.\n   */\n  MapOutputCommitMessage commitAllPartitions(long[] checksums) throws IOException;\n\n  /**"
  },
  {
    "id" : "790bb20b-c958-4044-bbac-643f25929705",
    "prId" : 28616,
    "prUrl" : "https://github.com/apache/spark/pull/28616#pullrequestreview-417779927",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "20b1fb5a-97eb-4c5b-b821-f007f110ef49",
        "parentId" : null,
        "authorId" : "39fe625f-8c54-48bc-ac6f-7279921adf02",
        "body" : "need rewrite above comment?",
        "createdAt" : "2020-05-25T15:30:23Z",
        "updatedAt" : "2020-06-03T20:44:54Z",
        "lastEditedBy" : "39fe625f-8c54-48bc-ac6f-7279921adf02",
        "tags" : [
        ]
      }
    ],
    "commit" : "4fd056dffc46e3db9547133c97589e0e2aba7f77",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +70,74 @@   * 2) An optional metadata blob that can be used by shuffle readers.\n   */\n  MapOutputCommitMessage commitAllPartitions() throws IOException;\n\n  /**"
  },
  {
    "id" : "6c81829d-1ec5-4d4d-9bba-35bdd34e34ac",
    "prId" : 25007,
    "prUrl" : "https://github.com/apache/spark/pull/25007#pullrequestreview-264078834",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9164e392-33a2-42c8-9461-a2d93b7b78b0",
        "parentId" : null,
        "authorId" : "34f85564-3e6b-4cb5-99f3-d5e383ee52fa",
        "body" : "Shouldn't this return `Optional<MapShuffleLocations>`?",
        "createdAt" : "2019-07-12T05:10:48Z",
        "updatedAt" : "2019-07-30T18:18:01Z",
        "lastEditedBy" : "34f85564-3e6b-4cb5-99f3-d5e383ee52fa",
        "tags" : [
        ]
      },
      {
        "id" : "8f33ca1c-7a11-4f2d-80b0-30b9b4f45136",
        "parentId" : "9164e392-33a2-42c8-9461-a2d93b7b78b0",
        "authorId" : "b4e64da3-d07f-4391-82fc-7bfc071fcb0b",
        "body" : "@gczsjdy any reason to return `Optional<MapShuffleLocations>`?",
        "createdAt" : "2019-07-17T06:52:34Z",
        "updatedAt" : "2019-07-30T18:18:01Z",
        "lastEditedBy" : "b4e64da3-d07f-4391-82fc-7bfc071fcb0b",
        "tags" : [
        ]
      },
      {
        "id" : "4ae4b576-deea-48f3-8600-521903b077e6",
        "parentId" : "9164e392-33a2-42c8-9461-a2d93b7b78b0",
        "authorId" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "body" : "We ended up adjusting the API for shuffle locations. This will come later.",
        "createdAt" : "2019-07-18T00:48:14Z",
        "updatedAt" : "2019-07-30T18:18:01Z",
        "lastEditedBy" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "tags" : [
        ]
      },
      {
        "id" : "c6fd275d-c568-4f05-9ef9-155f86367839",
        "parentId" : "9164e392-33a2-42c8-9461-a2d93b7b78b0",
        "authorId" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "body" : "I believe the SPIP has the latest API.",
        "createdAt" : "2019-07-18T00:48:31Z",
        "updatedAt" : "2019-07-30T18:18:01Z",
        "lastEditedBy" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "tags" : [
        ]
      },
      {
        "id" : "6b874272-a1d8-4f71-b5b8-40d98d694855",
        "parentId" : "9164e392-33a2-42c8-9461-a2d93b7b78b0",
        "authorId" : "34f85564-3e6b-4cb5-99f3-d5e383ee52fa",
        "body" : "@jerryshao @mccheah has explained well, because `Optional<MapShuffleLocations>` make implementers customize locations recorded in Driver. @mccheah This will be in driver lifecycle subissue?",
        "createdAt" : "2019-07-18T02:28:24Z",
        "updatedAt" : "2019-07-30T18:18:01Z",
        "lastEditedBy" : "34f85564-3e6b-4cb5-99f3-d5e383ee52fa",
        "tags" : [
        ]
      },
      {
        "id" : "33dbfec1-5d9a-4716-9330-6aab5613ade2",
        "parentId" : "9164e392-33a2-42c8-9461-a2d93b7b78b0",
        "authorId" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "body" : "Something to that effect yeah - it also has implications on the reader API, but these are concerns to be addressed in subsequent patches.",
        "createdAt" : "2019-07-18T02:38:22Z",
        "updatedAt" : "2019-07-30T18:18:01Z",
        "lastEditedBy" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "tags" : [
        ]
      },
      {
        "id" : "5193d860-db40-4e44-8559-9241f123be99",
        "parentId" : "9164e392-33a2-42c8-9461-a2d93b7b78b0",
        "authorId" : "34f85564-3e6b-4cb5-99f3-d5e383ee52fa",
        "body" : "Got it. : )",
        "createdAt" : "2019-07-19T08:40:24Z",
        "updatedAt" : "2019-07-30T18:18:02Z",
        "lastEditedBy" : "34f85564-3e6b-4cb5-99f3-d5e383ee52fa",
        "tags" : [
        ]
      }
    ],
    "commit" : "7dceec971784049442ec3d4cb71ddaa225e1e21f",
    "line" : 62,
    "diffHunk" : "@@ -1,1 +60,64 @@   * This can also close any resources and clean up temporary state if necessary.\n   */\n  void commitAllPartitions() throws IOException;\n\n  /**"
  },
  {
    "id" : "01f71919-13db-4da6-ae6a-07c0602b74fc",
    "prId" : 25007,
    "prUrl" : "https://github.com/apache/spark/pull/25007#pullrequestreview-263671448",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b90773a9-70a6-4e48-bfdb-2895d788ae49",
        "parentId" : null,
        "authorId" : "34f85564-3e6b-4cb5-99f3-d5e383ee52fa",
        "body" : ":nit remove `<p>`s?",
        "createdAt" : "2019-07-17T02:08:01Z",
        "updatedAt" : "2019-07-30T18:18:01Z",
        "lastEditedBy" : "34f85564-3e6b-4cb5-99f3-d5e383ee52fa",
        "tags" : [
        ]
      },
      {
        "id" : "62913b41-8d43-4dd8-86bd-78bb9a3f7432",
        "parentId" : "b90773a9-70a6-4e48-bfdb-2895d788ae49",
        "authorId" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "body" : "I think we want these to have line breaks in the generated HTML. But I'm not sure what the stance is across the rest of the codebase - we can remove these if pretty-formatting with line breaks isn't necessary.",
        "createdAt" : "2019-07-18T00:49:20Z",
        "updatedAt" : "2019-07-30T18:18:01Z",
        "lastEditedBy" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "tags" : [
        ]
      },
      {
        "id" : "ec121ea5-de43-44cf-94aa-7fd199598978",
        "parentId" : "b90773a9-70a6-4e48-bfdb-2895d788ae49",
        "authorId" : "e913f9af-103d-40d4-976e-9aa8e12e7211",
        "body" : "yeah, I think it is needed for javadoc, though its not needed for scaladoc.  IMO its worth keeping them.\r\n\r\nhttps://www.oracle.com/technetwork/java/javase/documentation/index-137868.html#format",
        "createdAt" : "2019-07-18T13:55:48Z",
        "updatedAt" : "2019-07-30T18:18:02Z",
        "lastEditedBy" : "e913f9af-103d-40d4-976e-9aa8e12e7211",
        "tags" : [
        ]
      }
    ],
    "commit" : "7dceec971784049442ec3d4cb71ddaa225e1e21f",
    "line" : 37,
    "diffHunk" : "@@ -1,1 +35,39 @@   * Creates a writer that can open an output stream to persist bytes targeted for a given reduce\n   * partition id.\n   * <p>\n   * The chunk corresponds to bytes in the given reduce partition. This will not be called twice\n   * for the same partition within any given map task. The partition identifier will be in the"
  },
  {
    "id" : "2676106b-aa11-4234-8c0f-e78fcf5517fb",
    "prId" : 25007,
    "prUrl" : "https://github.com/apache/spark/pull/25007#pullrequestreview-264384263",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6909f057-0dd4-4a9f-8dc9-a7bced27b110",
        "parentId" : null,
        "authorId" : "34f85564-3e6b-4cb5-99f3-d5e383ee52fa",
        "body" : "Should we mention `in order`?",
        "createdAt" : "2019-07-19T08:31:13Z",
        "updatedAt" : "2019-07-30T18:18:02Z",
        "lastEditedBy" : "34f85564-3e6b-4cb5-99f3-d5e383ee52fa",
        "tags" : [
        ]
      },
      {
        "id" : "dcafb7a5-bad3-496c-a1d9-1f838f70ce05",
        "parentId" : "6909f057-0dd4-4a9f-8dc9-a7bced27b110",
        "authorId" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "body" : "I made the docs more thorough, indicating ordering and also indicating how there's no guarantee that this will be called for an empty partition.",
        "createdAt" : "2019-07-19T19:06:55Z",
        "updatedAt" : "2019-07-30T18:18:02Z",
        "lastEditedBy" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "tags" : [
        ]
      }
    ],
    "commit" : "7dceec971784049442ec3d4cb71ddaa225e1e21f",
    "line" : 40,
    "diffHunk" : "@@ -1,1 +38,42 @@   * The chunk corresponds to bytes in the given reduce partition. This will not be called twice\n   * for the same partition within any given map task. The partition identifier will be in the\n   * range of precisely 0 (inclusive) to numPartitions (exclusive), where numPartitions was\n   * provided upon the creation of this map output writer via\n   * {@link ShuffleExecutorComponents#createMapOutputWriter(int, int, long, int)}."
  },
  {
    "id" : "7ec06267-a264-4c71-9bca-fedd62e0adcb",
    "prId" : 25007,
    "prUrl" : "https://github.com/apache/spark/pull/25007#pullrequestreview-267990982",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d5a4ee23-a7a3-4f00-acd1-ad0fd7e0d1a1",
        "parentId" : null,
        "authorId" : "c52c39ef-2b7f-4855-a2f1-2a2e50a719ae",
        "body" : "Why \"calls to this method will be invoked with monotonically increasing reducePartitionIds\"? This may cause potential issues in future and cause burden on implementation. for example, if people want to implement multiple partition writers and write shuffle data in parallel. It cannot guarantee monotonically increasing reducePartitionIds.",
        "createdAt" : "2019-07-29T18:33:15Z",
        "updatedAt" : "2019-07-30T18:18:02Z",
        "lastEditedBy" : "c52c39ef-2b7f-4855-a2f1-2a2e50a719ae",
        "tags" : [
        ]
      },
      {
        "id" : "99c8f27b-9718-4583-af8a-2e8f9d8c2438",
        "parentId" : "d5a4ee23-a7a3-4f00-acd1-ad0fd7e0d1a1",
        "authorId" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "body" : "People using this will be using it with `SortShuffleManager` which has a specific algorithm that won't open streams in parallel. If these invariants are broken, it implies the algorithm has changed, in which case we'd need to reconsider these APIs.",
        "createdAt" : "2019-07-29T19:27:22Z",
        "updatedAt" : "2019-07-30T18:18:02Z",
        "lastEditedBy" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "tags" : [
        ]
      }
    ],
    "commit" : "7dceec971784049442ec3d4cb71ddaa225e1e21f",
    "line" : 50,
    "diffHunk" : "@@ -1,1 +48,52 @@   * no guarantees are made as to whether or not this method will be called for empty partitions.\n   */\n  ShufflePartitionWriter getPartitionWriter(int reducePartitionId) throws IOException;\n\n  /**"
  },
  {
    "id" : "47fecfc4-5cb0-4058-8e1a-f10fc098e0bd",
    "prId" : 25007,
    "prUrl" : "https://github.com/apache/spark/pull/25007#pullrequestreview-270406106",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "75424929-29d6-4e02-ba34-e40d5b1a38a6",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "How useful is this? I think we can make Spark shuffle more flexible if we don't guarantee this. Do you have a concrete example of how an implementation can leverage this guarantee?",
        "createdAt" : "2019-08-02T17:15:11Z",
        "updatedAt" : "2019-08-02T17:15:12Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "0b5f7c46-10e8-49f5-8b20-a13c0b1d8337",
        "parentId" : "75424929-29d6-4e02-ba34-e40d5b1a38a6",
        "authorId" : "e913f9af-103d-40d4-976e-9aa8e12e7211",
        "body" : "spark's existing implementation makes this assumption.  The index & data file assume they are in sequential order.  \r\n\r\nthough it would be really easy to change the index format to allow for the order to random (just need to include a start and end, rather having the end be implicit).",
        "createdAt" : "2019-08-02T21:38:07Z",
        "updatedAt" : "2019-08-02T21:38:07Z",
        "lastEditedBy" : "e913f9af-103d-40d4-976e-9aa8e12e7211",
        "tags" : [
        ]
      }
    ],
    "commit" : "7dceec971784049442ec3d4cb71ddaa225e1e21f",
    "line" : 44,
    "diffHunk" : "@@ -1,1 +42,46 @@   * {@link ShuffleExecutorComponents#createMapOutputWriter(int, int, long, int)}.\n   * <p>\n   * Calls to this method will be invoked with monotonically increasing reducePartitionIds; each\n   * call to this method will be called with a reducePartitionId that is strictly greater than\n   * the reducePartitionIds given to any previous call to this method. This method is not"
  }
]