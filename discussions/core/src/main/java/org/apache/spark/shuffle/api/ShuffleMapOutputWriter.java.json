[
  {
    "id" : "9d46fb33-81ae-4f6a-9308-fe4bdc3180af",
    "prId" : 32401,
    "prUrl" : "https://github.com/apache/spark/pull/32401#pullrequestreview-684717353",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dd279e0c-b964-4060-bb44-f66dc3398a77",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "TBH I don't think the current shuffle API provides enough abstraction to do checksum. I'm OK with this change as the shuffle API is still private, but we should revisit the shuffle API later, so that checksum can be done at the shuffle implementation side.\r\n\r\nThe current issue I see is, Spark writes local spill files and then asks the shuffle implementation to \"transfer\" the spill files. Then Spark has to do checksum by itself during spill file writing, to reduce the perf overhead.\r\n\r\nWe can discuss it later.",
        "createdAt" : "2021-06-16T04:44:28Z",
        "updatedAt" : "2021-06-16T04:44:29Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "4bdde58a3791691f275968b117eeff260ef3016f",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +77,81 @@   *                  partition id) if shuffle checksum enabled. Otherwise, it's empty.\n   */\n  MapOutputCommitMessage commitAllPartitions(long[] checksums) throws IOException;\n\n  /**"
  }
]