[
  {
    "id" : "4b4ef9c8-478b-4a71-ac9d-74e699bfde6d",
    "prId" : 25850,
    "prUrl" : "https://github.com/apache/spark/pull/25850#pullrequestreview-291462765",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f734d049-77de-4db9-9aa6-15d8ce29e42d",
        "parentId" : null,
        "authorId" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "body" : "How about directly call `taskSetManager.handleFailedTask` here?\r\nIf `canFetchMoreResults` return false, taskSetManger.isZombie has set to true. `scheduler.handlerFailedTask` equally same with `taskSetManager.handleFailedTask`, and this will make UT easy to write.",
        "createdAt" : "2019-09-20T16:53:56Z",
        "updatedAt" : "2019-09-23T08:15:53Z",
        "lastEditedBy" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "tags" : [
        ]
      },
      {
        "id" : "4829b2ac-d408-4b7c-9663-17e88cc7f34c",
        "parentId" : "f734d049-77de-4db9-9aa6-15d8ce29e42d",
        "authorId" : "1b042d83-ef8f-494b-9256-66d2f5434320",
        "body" : "calling `scheduler.handleFailedTask` is to be consistent with other cases in this function.",
        "createdAt" : "2019-09-21T11:59:33Z",
        "updatedAt" : "2019-09-23T08:15:53Z",
        "lastEditedBy" : "1b042d83-ef8f-494b-9256-66d2f5434320",
        "tags" : [
        ]
      }
    ],
    "commit" : "aa4134810f777db452de729bc952793ea0d31b34",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +66,70 @@              if (!taskSetManager.canFetchMoreResults(serializedData.limit())) {\n                // kill the task so that it will not become zombie task\n                scheduler.handleFailedTask(taskSetManager, tid, TaskState.KILLED, TaskKilled(\n                  \"Tasks result size has exceeded maxResultSize\"))\n                return"
  },
  {
    "id" : "1fe80fbb-4fdd-4f22-87b1-5d6281e3e38f",
    "prId" : 25850,
    "prUrl" : "https://github.com/apache/spark/pull/25850#pullrequestreview-291618054",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "26211884-a661-4623-8c60-21453d2d51e9",
        "parentId" : null,
        "authorId" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "body" : "Better to leave a comment here to explain why we handle the oversize task as a killed task.",
        "createdAt" : "2019-09-23T07:53:56Z",
        "updatedAt" : "2019-09-23T08:15:53Z",
        "lastEditedBy" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "tags" : [
        ]
      },
      {
        "id" : "c65ff30a-06e5-4dc8-afb2-65dcb962ea4d",
        "parentId" : "26211884-a661-4623-8c60-21453d2d51e9",
        "authorId" : "1b042d83-ef8f-494b-9256-66d2f5434320",
        "body" : "Updated, thanks.",
        "createdAt" : "2019-09-23T08:16:29Z",
        "updatedAt" : "2019-09-23T08:16:29Z",
        "lastEditedBy" : "1b042d83-ef8f-494b-9256-66d2f5434320",
        "tags" : [
        ]
      }
    ],
    "commit" : "aa4134810f777db452de729bc952793ea0d31b34",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +66,70 @@              if (!taskSetManager.canFetchMoreResults(serializedData.limit())) {\n                // kill the task so that it will not become zombie task\n                scheduler.handleFailedTask(taskSetManager, tid, TaskState.KILLED, TaskKilled(\n                  \"Tasks result size has exceeded maxResultSize\"))\n                return"
  }
]