[
  {
    "id" : "91b61b14-5b59-42c6-9203-ae5de1e7d381",
    "prId" : 29788,
    "prUrl" : "https://github.com/apache/spark/pull/29788#pullrequestreview-493092579",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2f595ed4-ad2d-4d5c-a75b-08d4b35ca775",
        "parentId" : null,
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "Why are we renaming this?",
        "createdAt" : "2020-09-17T16:03:16Z",
        "updatedAt" : "2020-09-17T16:08:16Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      },
      {
        "id" : "2fb9c754-6316-4cfe-b5be-e550d1cc91a0",
        "parentId" : "2f595ed4-ad2d-4d5c-a75b-08d4b35ca775",
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "+1, I would argue against un-necessary renaming even if it seems a bit \"unnatural\". It creates un-necessary diff noise. \r\n\r\nTo me \"Info\" and \"Reason\" are both similar: They both portend \"additional information\".",
        "createdAt" : "2020-09-18T17:01:51Z",
        "updatedAt" : "2020-09-18T17:38:05Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      },
      {
        "id" : "5e5e863f-2fd8-4014-a09a-202c26f98dec",
        "parentId" : "2f595ed4-ad2d-4d5c-a75b-08d4b35ca775",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "I guess @Ngone51 is trying to follow the style of `TaskEndReason`.",
        "createdAt" : "2020-09-18T22:03:51Z",
        "updatedAt" : "2020-09-18T22:04:05Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "d6987c76-fe55-41c7-87ad-68d8415aabe9",
        "parentId" : "2f595ed4-ad2d-4d5c-a75b-08d4b35ca775",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Thank @dongjoon-hyun for the clarification. In addition to follow the style of `TaskEndReason`, I acutally also want to handle the decommission info/reason in the similar way of `TaskEndReason`.",
        "createdAt" : "2020-09-22T02:26:03Z",
        "updatedAt" : "2020-09-22T02:26:03Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "9bebdd4f2846f12f8ab13279c8cece151e8edfd0",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +18,22 @@package org.apache.spark\n\nimport org.apache.spark.scheduler.ExecutorDecommissionReason\n\n/**"
  },
  {
    "id" : "8dddbb4f-42cc-41a5-87c5-cb03ae25e984",
    "prId" : 29788,
    "prUrl" : "https://github.com/apache/spark/pull/29788#pullrequestreview-491637014",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9323a099-dcc1-4feb-87d8-abc2e97b3a61",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "is it possible that different executors have different `ExecutorDecommissionReason`? If it's not possible, I think we are over-engineering here.",
        "createdAt" : "2020-09-18T07:36:58Z",
        "updatedAt" : "2020-09-18T07:36:58Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "64fdcdf5-51c9-4360-b3c4-453e1cf6ac29",
        "parentId" : "9323a099-dcc1-4feb-87d8-abc2e97b3a61",
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "This is how it was earlier -- so we aren't changing the semantics save the renaming :-) And plus yes this can happen: Different executors on different hosts would have different ExecutorDecommissionReason/Info with different hosts potentially in them. \r\n\r\nThis is simply a bulk api : Instead of making n calls we are folding them into one.",
        "createdAt" : "2020-09-18T17:03:32Z",
        "updatedAt" : "2020-09-18T17:38:05Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      }
    ],
    "commit" : "9bebdd4f2846f12f8ab13279c8cece151e8edfd0",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +95,99 @@   */\n  def decommissionExecutors(\n      executorsAndDecomReason: Array[(String, ExecutorDecommissionReason)],\n      adjustTargetNumExecutors: Boolean): Seq[String] = {\n    killExecutors(executorsAndDecomReason.map(_._1),"
  },
  {
    "id" : "284a6f51-bfea-495e-a53d-3ff7791c8f5c",
    "prId" : 29722,
    "prUrl" : "https://github.com/apache/spark/pull/29722#pullrequestreview-487387132",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "317554f4-f9be-4cb8-871d-54c0f9123f42",
        "parentId" : null,
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "I keep messing this up myself, but is this indentation style change intentional ? If 2 spaces are okay then can we remain at that ?",
        "createdAt" : "2020-09-12T01:15:57Z",
        "updatedAt" : "2020-09-16T06:57:24Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      },
      {
        "id" : "3c395318-5a82-4bca-9c3b-1df1cafb4409",
        "parentId" : "317554f4-f9be-4cb8-871d-54c0f9123f42",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "It's intentional, please see: [For method declarations, use 4 space indentation for their parameters](https://github.com/databricks/scala-style-guide)",
        "createdAt" : "2020-09-14T03:00:43Z",
        "updatedAt" : "2020-09-16T06:57:24Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "290d2c08a1adfce3c0c4afe1cb8c9e214b25ea3d",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +96,100 @@   */\n  def decommissionExecutors(\n      executorsAndDecomInfo: Array[(String, ExecutorDecommissionInfo)],\n      adjustTargetNumExecutors: Boolean,\n      triggeredByExecutor: Boolean): Seq[String] = {"
  },
  {
    "id" : "b20ca511-3340-45fa-a020-b932f9762f29",
    "prId" : 29722,
    "prUrl" : "https://github.com/apache/spark/pull/29722#pullrequestreview-487672838",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d6375fc4-fee1-4fd8-a5bd-dd84aa71eb1f",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "shall we document this new parameter in this method as well?",
        "createdAt" : "2020-09-14T11:47:20Z",
        "updatedAt" : "2020-09-16T06:57:24Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "290d2c08a1adfce3c0c4afe1cb8c9e214b25ea3d",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +98,102 @@      executorsAndDecomInfo: Array[(String, ExecutorDecommissionInfo)],\n      adjustTargetNumExecutors: Boolean,\n      triggeredByExecutor: Boolean): Seq[String] = {\n    killExecutors(executorsAndDecomInfo.map(_._1),\n      adjustTargetNumExecutors,"
  },
  {
    "id" : "96ba8a69-4333-404a-b75d-1f4de1268db9",
    "prId" : 29367,
    "prUrl" : "https://github.com/apache/spark/pull/29367#pullrequestreview-462880750",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "eee607ef-f9d4-4451-b602-c534dddf5067",
        "parentId" : null,
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "IMHO, I find this API a bit confusing: Typically when you have a singular/plural sort of an interface: The plural just delegates to the singular and the singular implements the default implementation. \r\n\r\nFrom the name of the methods, I would have expected decommissionExecutors to call out to the decommissionExecutor, and the latter to delegate to do the kill. In other words the plural decommissionExecutors is just a convenience looping method. \r\n\r\nI am wondering if you think the naming can be cleared up to clarify these two functions intents ? Otherwise the difference is a bit too subtle.",
        "createdAt" : "2020-08-06T05:32:04Z",
        "updatedAt" : "2020-08-12T19:09:04Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      },
      {
        "id" : "530fec47-1c2c-4295-a228-98b16a0381a8",
        "parentId" : "eee607ef-f9d4-4451-b602-c534dddf5067",
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "So I think we'd rather have a convenience method for the single implementation. Decommissioning one executor at a time could lead to a cascading migration, so if we've got a chunk of executors to decommission we'd rather encourage cluster managers to process that message as a block which is why I've implemented it this way.",
        "createdAt" : "2020-08-06T19:11:54Z",
        "updatedAt" : "2020-08-12T19:09:04Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      },
      {
        "id" : "299c6e09-3c95-4724-8fdf-3daac4805ca2",
        "parentId" : "eee607ef-f9d4-4451-b602-c534dddf5067",
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "Makes sense. Please consider marking this single executor decom to be final so that it is clear that it is a helper method using an overrideable API. I agree with you that the default interface should be the bulk one.",
        "createdAt" : "2020-08-06T21:12:49Z",
        "updatedAt" : "2020-08-12T19:09:04Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      }
    ],
    "commit" : "e970cb10147fb64533f5088edc3a448b5ef198cf",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +94,98 @@   * @return the ids of the executors acknowledged by the cluster manager to be removed.\n   */\n  def decommissionExecutors(\n    executorsAndDecomInfo: Array[(String, ExecutorDecommissionInfo)],\n    adjustTargetNumExecutors: Boolean): Seq[String] = {"
  },
  {
    "id" : "144dc5c0-3583-4897-a31c-3b29c8d333cb",
    "prId" : 28818,
    "prUrl" : "https://github.com/apache/spark/pull/28818#pullrequestreview-452863156",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1393972c-b5d5-4406-97ef-b5120787557e",
        "parentId" : null,
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "Why is `adjustTargetNumExecutors` defaulting to true here ? This would mean that all schedulers would try to replinish the executor when asked to `DecommissionExecutor(...)` -- for example by the Master or when an executor gets a SIGPWR. \r\n\r\nI think it shouldn't be the default -- it should atleast be configurable. It only makes sense to have `adjustTargetNumExecutors=true` when called from `org.apache.spark.streaming.scheduler.ExecutorAllocationManager#killExecutor` (ie when it is truly called from dynamic allocation codepath and we have decided that we want to replinish the executor). ",
        "createdAt" : "2020-07-10T00:32:31Z",
        "updatedAt" : "2020-07-23T21:35:22Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      },
      {
        "id" : "353c510c-4ca7-454d-9bb2-ae293e711370",
        "parentId" : "1393972c-b5d5-4406-97ef-b5120787557e",
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "If you look above there is a configurable call. This matches how `killExecutor` is implemented down on line 124.",
        "createdAt" : "2020-07-21T19:38:57Z",
        "updatedAt" : "2020-07-23T21:35:22Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      },
      {
        "id" : "4a1fca33-13eb-4966-8311-20059ddf4e7e",
        "parentId" : "1393972c-b5d5-4406-97ef-b5120787557e",
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "Can you please point me to where is the configurable call ? I don't see a config check in the code paths that call this method.\r\n\r\nIt's fine for killExecutor to unconditionally adjust the target number of executors because it is only called in the dynamic allocation codepath, but decommissionExecutor would be called from many other codepaths as well (for example when the driver gets a DecommissionExecutor message) -- and thus I think it should just assume that it should replenish the executor.",
        "createdAt" : "2020-07-21T20:37:56Z",
        "updatedAt" : "2020-07-23T21:35:22Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      },
      {
        "id" : "374c0258-9215-41a9-91e5-9f8f3dfc8ea1",
        "parentId" : "1393972c-b5d5-4406-97ef-b5120787557e",
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "Look on line 95 of this file. I think we should match the semantics of `killExecutor` as much as possible. If there's a place where we don't want it we can use `decommissionExecutors`",
        "createdAt" : "2020-07-21T20:39:36Z",
        "updatedAt" : "2020-07-23T21:35:22Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      },
      {
        "id" : "36646902-9a0a-4d7f-b9b7-2b5ff6be3bcc",
        "parentId" : "1393972c-b5d5-4406-97ef-b5120787557e",
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "Hmm, Should we rename decommissionExecutor (singular) to decommissionAndKillExecutor to reflect its purpose better ? It would be too easy to confuse it with decommissionExecutors (on line 95 of this file which allows to not replenish the target number of executors).\r\n\r\nDo you want to make the change to the callers of decommissionExecutor in this PR and switch them to `decommissioExecutors(Seq(executorId), false)` instead. The ones I am most concerned about are:\r\n\r\n- The handling of message DecommissionExecutor (both sync and async variants) in CoarseGrainedSchedulerBackend\r\n- StandaloneSchedulerBackend.executorDecommissioned\r\n\r\nIn both the above cases, I think we may not _always_ want replenishing. For example, in the standalone case, when the Worker gets a SIGPWR -- do we want to replenish the executors on the remaining workers (ie oversubscribe the remaining workers) ? Similarly when an executor gets a SIGPWR, do we want to put that load on the remaining executors ? I think the answer to both should be NO unless we are doing a dynamic allocation.\r\n\r\nPersonally I am fine with any choice of naming here as long as the semantics are not silently changed under the cover, as is the case presently. ",
        "createdAt" : "2020-07-21T20:54:11Z",
        "updatedAt" : "2020-07-23T21:35:22Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      },
      {
        "id" : "eb98b66c-e52e-4164-8466-95070a7c3a04",
        "parentId" : "1393972c-b5d5-4406-97ef-b5120787557e",
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "It's a new function, what are we changing?",
        "createdAt" : "2020-07-21T21:13:08Z",
        "updatedAt" : "2020-07-23T21:35:22Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      },
      {
        "id" : "006766eb-da35-4547-9edf-31d949a8dc5c",
        "parentId" : "1393972c-b5d5-4406-97ef-b5120787557e",
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "ExecutorAllocationClient is a base class of CoarseGrainedSchedulerBackend. We moved decommissionExecutor from the latter class to the former and as such it is not a new function. Since CoarseGrainedSchedulerBackend no longer overrides decommissionExecutor, ExecutorAllocationClient.decommissionExecutor will be called when CoarseGrainedSchedulerBackend gets a DecommissionExecutor message -- and the semantics of that codepath have been changed to unconditionally impose adjustTargetNumExecutors=true.",
        "createdAt" : "2020-07-21T21:25:14Z",
        "updatedAt" : "2020-07-23T21:35:22Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      },
      {
        "id" : "f8eeb82a-b70b-43aa-bd29-72c6b14edb0d",
        "parentId" : "1393972c-b5d5-4406-97ef-b5120787557e",
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "cool, I'll update the previous calls to `decommissioExecutor`",
        "createdAt" : "2020-07-21T22:06:09Z",
        "updatedAt" : "2020-07-23T21:35:22Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      }
    ],
    "commit" : "f921ddd3913d8b749abd2d8de645e5d098d73823",
    "line" : 44,
    "diffHunk" : "@@ -1,1 +115,119 @@    val decommissionedExecutors = decommissionExecutors(\n      Seq((executorId, decommissionInfo)),\n      adjustTargetNumExecutors = true)\n    decommissionedExecutors.nonEmpty && decommissionedExecutors(0).equals(executorId)\n  }"
  }
]