[
  {
    "id" : "51bb3f1c-0bf7-48e7-bcc9-ebc794b4a3f4",
    "prId" : 24730,
    "prUrl" : "https://github.com/apache/spark/pull/24730#pullrequestreview-243626882",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "685adb9f-e5b5-4181-9169-9efbc2b34754",
        "parentId" : null,
        "authorId" : "99156419-7ce7-4671-b858-d0b5c4711f88",
        "body" : "could `Seq[JsonResourceInformation]` contain duplicated name? might be (very marginally) better to do \r\n`resource.toMap.map(...)`",
        "createdAt" : "2019-05-29T04:29:49Z",
        "updatedAt" : "2019-05-29T04:35:32Z",
        "lastEditedBy" : "99156419-7ce7-4671-b858-d0b5c4711f88",
        "tags" : [
        ]
      },
      {
        "id" : "8f79b198-4303-488c-bf3e-8a2c323bdcda",
        "parentId" : "685adb9f-e5b5-4181-9169-9efbc2b34754",
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "Sorry, I'm missing what you are saying here with the toMap.map?  I can't do the toMap until I do the first map to (name, ResourceInformation), otherwise you just have a Seq[JsonResourceInformation] and toMap doesn't know how to make that a map. If there are 2 resource with the same name when the current code runs the toMap will choose the last one.\r\n\r\nI had actually tested this and found the json4s parse and extract actually are handling duplicates as well, looks like it chooses the last one, I couldn't find docs on that behavior though either. The resourcesfile is built by the standalone master/worker so it shouldn't really have duplicates.  I'm happy to update though to be explicit so just let me know.",
        "createdAt" : "2019-05-29T13:47:46Z",
        "updatedAt" : "2019-05-29T13:47:46Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      },
      {
        "id" : "c216adf3-f370-41b1-9ef4-e64b51d319d4",
        "parentId" : "685adb9f-e5b5-4181-9169-9efbc2b34754",
        "authorId" : "99156419-7ce7-4671-b858-d0b5c4711f88",
        "body" : "ah yes ;) I just mean it walking through a `Seq` when the goal is a `Map`",
        "createdAt" : "2019-05-30T05:03:12Z",
        "updatedAt" : "2019-05-30T05:03:12Z",
        "lastEditedBy" : "99156419-7ce7-4671-b858-d0b5c4711f88",
        "tags" : [
        ]
      }
    ],
    "commit" : "c046f07f2fb4850a75b954ec423e27c231b36aff",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +147,151 @@      resourceInput.close()\n    }\n    resources.map(r => (r.name, new ResourceInformation(r.name, r.addresses))).toMap\n  }\n}"
  },
  {
    "id" : "b4a96f7b-ab82-4233-b740-d0908b2b0d1f",
    "prId" : 24615,
    "prUrl" : "https://github.com/apache/spark/pull/24615#pullrequestreview-240225034",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1ffbf556-a7b0-47e8-b036-cd09cdbbb10d",
        "parentId" : null,
        "authorId" : "0c812942-02cb-4975-9748-394d1387affa",
        "body" : "not in this PR, it would be nice if we use a class to capsulate the resource request",
        "createdAt" : "2019-05-21T18:34:48Z",
        "updatedAt" : "2019-05-23T14:59:29Z",
        "lastEditedBy" : "0c812942-02cb-4975-9748-394d1387affa",
        "tags" : [
        ]
      }
    ],
    "commit" : "768392ca83c29a2ef6b3ecb2d175cccd20ffa0ab",
    "line" : 113,
    "diffHunk" : "@@ -1,1 +120,124 @@   */\n  def checkActualResourcesMeetRequirements(\n      requiredResources: Map[String, String],\n      actualResources: Map[String, ResourceInformation]): Unit = {\n    requiredResources.foreach { case (rName, reqCount) =>"
  }
]