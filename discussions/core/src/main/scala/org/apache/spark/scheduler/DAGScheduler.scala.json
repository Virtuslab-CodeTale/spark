[
  {
    "id" : "9bbdde18-c31a-4014-8e9d-18bfefa73b69",
    "prId" : 32356,
    "prUrl" : "https://github.com/apache/spark/pull/32356#pullrequestreview-645315412",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cfb75a82-d5a9-4a32-8a7e-4daac8936d9d",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Note that we don't append `\\n` for  this \"Most recent failure reason\" because `message` already contains it:\r\n\r\n```scala\r\nval message = s\"Stage failed because barrier task $task finished unsuccessfully.\\n\" +\r\n  failure.toErrorString\r\n```",
        "createdAt" : "2021-04-27T03:28:27Z",
        "updatedAt" : "2021-04-27T03:28:27Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "0896255f43c622e096cab6b0eee5bc4f715abc40",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +1952,1956 @@            } else {\n              s\"$failedStage (${failedStage.name}) has failed the maximum allowable number of \" +\n                s\"times: $maxConsecutiveStageAttempts. Most recent failure reason: $message\"\n            }\n            abortStage(failedStage, abortMessage, None)"
  },
  {
    "id" : "07661673-37f1-4ff2-91ac-a56f4cdcf4e9",
    "prId" : 31715,
    "prUrl" : "https://github.com/apache/spark/pull/31715#pullrequestreview-603642771",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e7039fba-bacb-4502-b438-a94232d3b931",
        "parentId" : null,
        "authorId" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "body" : "shouldn't we check this config to not take effect, if `spark.shuffle.manager` is `sort` (the default one)?",
        "createdAt" : "2021-03-04T02:20:21Z",
        "updatedAt" : "2021-03-04T02:20:21Z",
        "lastEditedBy" : "8df147d9-bc9d-4fd9-bb98-5dcf9619220b",
        "tags" : [
        ]
      }
    ],
    "commit" : "1418e8f9507375f4fec025d8df357a86cb99ee45",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +2036,2040 @@    // from a Standalone cluster, where the shuffle service lives in the Worker.)\n    val fileLost = (workerHost.isDefined || !env.blockManager.externalShuffleServiceEnabled) &&\n      env.blockManager.markFileLostOnExecutorLost\n    removeExecutorAndUnregisterOutputs(\n      execId = execId,"
  },
  {
    "id" : "e7433168-ebba-4150-b585-ee67e40f84cc",
    "prId" : 30716,
    "prUrl" : "https://github.com/apache/spark/pull/30716#pullrequestreview-568153899",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d5388bbe-2c21-4ef0-b8d4-54d3325e1af1",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "In the corner case, e.g., the rerun stage may only need to rerun one task and the task finished before this FetchFailure...which means the rerun stage attempt could be removed from `taskSetManagerForAttempt`...then, I don't think we should return `true` here..",
        "createdAt" : "2020-12-30T07:43:59Z",
        "updatedAt" : "2020-12-30T09:36:27Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "e7cfa4e7-40c1-4506-8045-2a28614b1adc",
        "parentId" : "d5388bbe-2c21-4ef0-b8d4-54d3325e1af1",
        "authorId" : "31afe32d-3af0-4fcf-93e2-115f5d7bab18",
        "body" : "Compared with before, I think this is acceptable, do you have any idea?",
        "createdAt" : "2021-01-14T11:39:31Z",
        "updatedAt" : "2021-01-14T11:39:31Z",
        "lastEditedBy" : "31afe32d-3af0-4fcf-93e2-115f5d7bab18",
        "tags" : [
        ]
      }
    ],
    "commit" : "8dbfdcbd2146daea48de3199b620594be404c363",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +266,270 @@          latestInfo.stageId, latestInfo.attemptNumber()) match {\n          case Some(tsm: TaskSetManager) => !tsm.hasPartitionId(fetchFailed.mapId.toInt)\n          case _ => true\n        }\n      }"
  },
  {
    "id" : "18ebf8fa-3038-4858-8625-9f5ed814756d",
    "prId" : 30716,
    "prUrl" : "https://github.com/apache/spark/pull/30716#pullrequestreview-559939984",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8229e7b0-aee0-4772-b8fc-b40a2f693ded",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "I think you actually want `fetchFailed.mapIndex` rather than `fetchFailed.mapId`?",
        "createdAt" : "2020-12-30T08:25:15Z",
        "updatedAt" : "2020-12-30T09:36:27Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "8dbfdcbd2146daea48de3199b620594be404c363",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +265,269 @@        taskScheduler.taskSetManagerForAttempt(\n          latestInfo.stageId, latestInfo.attemptNumber()) match {\n          case Some(tsm: TaskSetManager) => !tsm.hasPartitionId(fetchFailed.mapId.toInt)\n          case _ => true\n        }"
  },
  {
    "id" : "1b5cfa39-a85c-4582-8b0a-b58a45901d6e",
    "prId" : 30691,
    "prUrl" : "https://github.com/apache/spark/pull/30691#pullrequestreview-652435188",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d3849148-7486-4cb5-be37-cd87e1291990",
        "parentId" : null,
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "review note: no changes here. Method extracted from `handleTaskCompletion`",
        "createdAt" : "2021-05-05T15:43:23Z",
        "updatedAt" : "2021-05-11T05:07:03Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      }
    ],
    "commit" : "35d06150f37e01256314af4956c6e8fdcf7244b4",
    "line" : 292,
    "diffHunk" : "@@ -1,1 +2092,2096 @@  }\n\n  private def processShuffleMapStageCompletion(shuffleStage: ShuffleMapStage): Unit = {\n    markStageAsFinished(shuffleStage)\n    logInfo(\"looking for newly runnable stages\")"
  },
  {
    "id" : "502ba9b0-269d-4809-9749-c878d3396a05",
    "prId" : 30691,
    "prUrl" : "https://github.com/apache/spark/pull/30691#pullrequestreview-670858886",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2b1b1b68-d309-4213-a799-83ed005a07d0",
        "parentId" : null,
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "What happens if the stage was cancelled during `shuffleMergeFinalizeWaitSec` ?",
        "createdAt" : "2021-05-11T03:00:51Z",
        "updatedAt" : "2021-05-11T05:07:04Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      },
      {
        "id" : "3b05c777-a9b3-4bd0-bc49-a8bd2fa58456",
        "parentId" : "2b1b1b68-d309-4213-a799-83ed005a07d0",
        "authorId" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "body" : "Addressed this comment after discussing with @mridulm offline. Mridul, I tried adding test for the cancellation but the `DAGSchedulerEventProcessLoopTester` is not async as it simply forwards the event for immediate processing. Let me know if you have other ideas to test this particular situation.",
        "createdAt" : "2021-05-25T18:57:02Z",
        "updatedAt" : "2021-05-25T18:57:02Z",
        "lastEditedBy" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "tags" : [
        ]
      },
      {
        "id" : "4d272a64-d565-4b97-bb3c-92ed50df097e",
        "parentId" : "2b1b1b68-d309-4213-a799-83ed005a07d0",
        "authorId" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "body" : "Added additional tests to handle the cases of stage cancellation, barrier stage, late arrival of merge results etc.",
        "createdAt" : "2021-05-28T01:19:20Z",
        "updatedAt" : "2021-05-28T01:19:20Z",
        "lastEditedBy" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "tags" : [
        ]
      }
    ],
    "commit" : "35d06150f37e01256314af4956c6e8fdcf7244b4",
    "line" : 246,
    "diffHunk" : "@@ -1,1 +2046,2050 @@   */\n  private[scheduler] def finalizeShuffleMerge(stage: ShuffleMapStage): Unit = {\n    logInfo(\"%s (%s) finalizing the shuffle merge\".format(stage, stage.name))\n    externalShuffleClient.foreach { shuffleClient =>\n      val shuffleId = stage.shuffleDep.shuffleId"
  },
  {
    "id" : "2ab4da93-7359-4e85-826d-07e59c9ae01b",
    "prId" : 30691,
    "prUrl" : "https://github.com/apache/spark/pull/30691#pullrequestreview-669853548",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dc440513-9907-416d-a4da-a6db4ab199fc",
        "parentId" : null,
        "authorId" : "9953a478-bdd8-4f15-be59-f6f654ff85ae",
        "body" : "@mridulm mentioned that one of the benefits of this way is that we can still accept and register merge statuses which are received after the stage gets finalized.\r\nBut here, we are ignoring these  statuses if shuffle merge is finalized. Why?\r\n In case of deterministic stage retries, accepting merge statuses after finalize is still okay, isn't it.",
        "createdAt" : "2021-05-25T19:31:50Z",
        "updatedAt" : "2021-05-25T19:53:54Z",
        "lastEditedBy" : "9953a478-bdd8-4f15-be59-f6f654ff85ae",
        "tags" : [
        ]
      },
      {
        "id" : "1cd447b9-044b-4e93-827c-0cbc3aa26355",
        "parentId" : "dc440513-9907-416d-a4da-a6db4ab199fc",
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "Let us do it as a follow up work, given the stage would have completed by the time that comes through.\r\nCan you add a TODO for this @venkata91 ?\r\n\r\nNote - the check `runningStages.contains(stage)` is not sufficient - as I detail below for `handleShuffleMergeFinalized`: the same condition applies here too.",
        "createdAt" : "2021-05-27T03:16:44Z",
        "updatedAt" : "2021-05-27T03:39:30Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      },
      {
        "id" : "1d0298f4-cddc-435d-828f-9dd9cb0abcc2",
        "parentId" : "dc440513-9907-416d-a4da-a6db4ab199fc",
        "authorId" : "9953a478-bdd8-4f15-be59-f6f654ff85ae",
        "body" : "In that case, currently there is no need to even post these messages to `eventProcessLoop` after `ShuffleMergeFinalized` message is posted. \r\nSo should `RegisterMergeStatuses`  be posted only when `!timedOut.get()`?  Anyways, these messages are just getting ignored so why to even deserialize them.\r\n                   ",
        "createdAt" : "2021-05-27T07:52:45Z",
        "updatedAt" : "2021-05-27T07:52:45Z",
        "lastEditedBy" : "9953a478-bdd8-4f15-be59-f6f654ff85ae",
        "tags" : [
        ]
      }
    ],
    "commit" : "35d06150f37e01256314af4956c6e8fdcf7244b4",
    "line" : 329,
    "diffHunk" : "@@ -1,1 +2129,2133 @@    // TODO: SPARK-35549: Currently merge statuses results which come after shuffle merge\n    // TODO: is finalized is not registered.\n    if (runningStages.contains(stage) && !stage.shuffleDep.shuffleMergeFinalized) {\n      mapOutputTracker.registerMergeResults(stage.shuffleDep.shuffleId, mergeStatuses)\n    }"
  },
  {
    "id" : "6db4e3c7-0acc-419e-9b7d-5cbbc9f84273",
    "prId" : 30691,
    "prUrl" : "https://github.com/apache/spark/pull/30691#pullrequestreview-670858610",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "59d95cbd-8820-46a9-b422-c90d98c1fc81",
        "parentId" : null,
        "authorId" : "9953a478-bdd8-4f15-be59-f6f654ff85ae",
        "body" : "If the stage is not part of runningStages does it really mean that it was cancelled? \r\nIt seems like runningStages contain active stages. If a stage is completed successfully, it will not be part of runningStages. Why do we unregister all the mergeResults here ? \r\nAlso please add a comment that why we need to unregister all the merge results here",
        "createdAt" : "2021-05-25T19:53:36Z",
        "updatedAt" : "2021-05-25T19:53:54Z",
        "lastEditedBy" : "9953a478-bdd8-4f15-be59-f6f654ff85ae",
        "tags" : [
        ]
      },
      {
        "id" : "d8c973f3-9452-480b-90e7-164043ae034f",
        "parentId" : "59d95cbd-8820-46a9-b422-c90d98c1fc81",
        "authorId" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "body" : "Stage will be active until the shuffle merge is finalized and then only we are processing the map stage completion, isn't it? So if the stage is not part of running stages and we still reach the handling shuffle merge finalize, then we need to unregister the merge results, isn't it?\r\n\r\nCan you think of a scenario where stage is not part of running stages and still shuffle merge is finalized? - Ideally this should not happen.",
        "createdAt" : "2021-05-26T18:35:39Z",
        "updatedAt" : "2021-05-26T18:35:39Z",
        "lastEditedBy" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "tags" : [
        ]
      },
      {
        "id" : "98be8232-f36d-40ca-92a8-36037f9fddd3",
        "parentId" : "59d95cbd-8820-46a9-b422-c90d98c1fc81",
        "authorId" : "9953a478-bdd8-4f15-be59-f6f654ff85ae",
        "body" : "> Stage will be active until the shuffle merge is finalized and then only we are processing the map stage completion, isn't it? So if the stage is not part of running stages and we still reach the handling shuffle merge finalize, then we need to unregister the merge results, isn't it?\r\n\r\nAre you just making an assumption here, that if the stage is not running and then this finalized message is processed that means the stage is cancelled?  Is this a valid assumption?\r\nIf yes, then can you add a comment here. \r\n\r\n> Can you think of a scenario where stage is not part of running stages and still shuffle merge is finalized? - Ideally this should not happen.\r\n\r\nThis is what is throwing me off. If this is not ideally going to happen then why are we unregistering the results here. Again, if the assumption is that this happens when the stage was cancelled then document it. Also, if handling stage cancellation wrt merge finalization is not handled in this PR then why have this unregistration of merge results here?",
        "createdAt" : "2021-05-26T19:49:05Z",
        "updatedAt" : "2021-05-26T19:49:05Z",
        "lastEditedBy" : "9953a478-bdd8-4f15-be59-f6f654ff85ae",
        "tags" : [
        ]
      },
      {
        "id" : "93515e51-3bfc-4ab7-bdbd-541f64ffee83",
        "parentId" : "59d95cbd-8820-46a9-b422-c90d98c1fc81",
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "In scheduler, if a stage is in`runningStages` is the typical way in which we check if a stage is completed or not.\r\nOutside of scheduler, stage.latestInfo.failureReason is used to identify stage failure.\r\n\r\nHaving said that, latestInfo is overwritten when a new attempt starts.\r\n\r\nFor this specific case we had discussed (stage resubmission after a cancellation after initiating merge finalization), given a new stage attempt would result in the stage continuing to be in `runningStages` (but for newer attempt), the way to check would be:\r\n\r\na) Fetch `stage.latestInfo.attemptNumber()` in start of `scheduleShuffleMergeFinalize` (within dag scheduler event loop) - and pass this to finalizeShuffleMerge -> RegisterMergeStatuses and ShuffleMergeFinalized.\r\n\r\nIn handleShuffleMergeFinalized:\r\nb) If stage is not in runningStages (like currently being done), then not running - or\r\nc) If stage.latestInfo.attemptNumber() != ShuffleMergeFinalized.attemptNumber then attempt has changed, and finalization message.",
        "createdAt" : "2021-05-27T03:37:04Z",
        "updatedAt" : "2021-05-27T03:39:30Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      },
      {
        "id" : "44ae1b3a-50ea-4b70-b9ef-a16abd7ba664",
        "parentId" : "59d95cbd-8820-46a9-b422-c90d98c1fc81",
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "On further thought ... my comment about attemptNumber is not valid.\r\nA new job will result in a new stage (since `stage` would have been removed from `shuffleIdToMapStage` and `runningStages` due to cancellation).\r\nA new attempt is scheduled typically when there are fetch failures in current job, and reexecution of parent is followed by re-execution of the stage - and so new attempt.\r\n\r\nI think the code looks fine as is.\r\n\r\n+CC @otterc ... thoughts ?",
        "createdAt" : "2021-05-27T04:20:58Z",
        "updatedAt" : "2021-05-27T04:21:59Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      },
      {
        "id" : "c8e1b254-24b5-4c67-8430-7191ce4775ba",
        "parentId" : "59d95cbd-8820-46a9-b422-c90d98c1fc81",
        "authorId" : "9953a478-bdd8-4f15-be59-f6f654ff85ae",
        "body" : "@mridulm For the case that you pointed out\r\n> stage resubmission after a cancellation after initiating merge finalization\r\n\r\nThe problem that we were registering the mergeResults without a check and that would interfere with resubmission is solved here by not registering merge results if the stage is not running. Also, it makes sense to finalize the stage when it is running.\r\n\r\nHowever, shouldn't unregistering of merge results happen when there is a fetch failure or a stage is cancelled?\r\n\r\nBoth of the above are not part of this PR. So, I just want to understand in the context of this PR, why are we unregistering the merge results in the else part here and what does that help with?\r\n ```\r\n else {      mapOutputTracker.unregisterAllMergeResult(stage.shuffleDep.shuffleId)\r\n ```\r\n Also if there is a good reason to do it, then we should document it here as a comment.",
        "createdAt" : "2021-05-27T07:36:04Z",
        "updatedAt" : "2021-05-27T07:36:05Z",
        "lastEditedBy" : "9953a478-bdd8-4f15-be59-f6f654ff85ae",
        "tags" : [
        ]
      },
      {
        "id" : "a938300a-4c8c-4967-92df-419f33ab8843",
        "parentId" : "59d95cbd-8820-46a9-b422-c90d98c1fc81",
        "authorId" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "body" : "Discussed offline with @mridulm and currently there are few corner cases which needs to be carefully thought through before having this behavior. Created a TODO and a corresponding follow up JIRA - https://issues.apache.org/jira/browse/SPARK-35549",
        "createdAt" : "2021-05-28T01:18:30Z",
        "updatedAt" : "2021-05-28T01:18:30Z",
        "lastEditedBy" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "tags" : [
        ]
      }
    ],
    "commit" : "35d06150f37e01256314af4956c6e8fdcf7244b4",
    "line" : 342,
    "diffHunk" : "@@ -1,1 +2142,2146 @@      // Unregister all merge results if the stage is currently not\n      // active (i.e. the stage is cancelled)\n      mapOutputTracker.unregisterAllMergeResult(stage.shuffleDep.shuffleId)\n    }\n  }"
  },
  {
    "id" : "f8e7c7a5-5f50-4d68-b00a-b1944dbbac77",
    "prId" : 30691,
    "prUrl" : "https://github.com/apache/spark/pull/30691#pullrequestreview-673695267",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b2a7b269-91b6-4b3d-8e16-f90c0b121bf9",
        "parentId" : null,
        "authorId" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "body" : "@otterc one question which I couldn't understand from the internal fix is, should we pass `mapId` or `mapIndex` to the `unregisterMergeResult` here?",
        "createdAt" : "2021-06-01T17:31:15Z",
        "updatedAt" : "2021-06-01T17:31:15Z",
        "lastEditedBy" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "tags" : [
        ]
      },
      {
        "id" : "cd633651-c87a-41e1-9303-55b840b834d3",
        "parentId" : "b2a7b269-91b6-4b3d-8e16-f90c0b121bf9",
        "authorId" : "9953a478-bdd8-4f15-be59-f6f654ff85ae",
        "body" : "We need to pass `mapIndex`. The intention here is to unregister the mergeStatus if the block corresponding to the <shuffleId, mapIndex, reduceId> got merged for the reduce partition <shuffleId, reduceId>.  mergeStatus tracks mapIndex. \r\nAlso we can add a comment here that why are we doing this:\r\nWhen there is fetch failure for a block <shuffleId, mapIndex, reduceId> and if that block was merged to partition <shuffleId, reduceId>, it indicates that the iterator also failed to fetch the merged block for <shuffleId, reduceId>. So, we unregister the mergeResult for partition<shuffleId, reduceId> as there is no guarantee that the merged block for <shuffleId, reduceId> from the same blockManager will be successful the next time this stage is resubmitted.\r\n\r\nOn a side note, this was one of the reasons I thought this change should go with the fetch side change because it makes the explanation easier.",
        "createdAt" : "2021-06-01T19:40:08Z",
        "updatedAt" : "2021-06-01T21:44:37Z",
        "lastEditedBy" : "9953a478-bdd8-4f15-be59-f6f654ff85ae",
        "tags" : [
        ]
      },
      {
        "id" : "46a2b445-2411-4807-a081-dbd5d5e61c6b",
        "parentId" : "b2a7b269-91b6-4b3d-8e16-f90c0b121bf9",
        "authorId" : "9953a478-bdd8-4f15-be59-f6f654ff85ae",
        "body" : "@venkata91 I corrected the above response. Passing mapIndex is correct, because that is what we send in the ShuffleBlockPush message. ",
        "createdAt" : "2021-06-01T21:47:18Z",
        "updatedAt" : "2021-06-01T21:47:18Z",
        "lastEditedBy" : "9953a478-bdd8-4f15-be59-f6f654ff85ae",
        "tags" : [
        ]
      },
      {
        "id" : "ff439e51-11fd-4709-be9d-3518a7c438a3",
        "parentId" : "b2a7b269-91b6-4b3d-8e16-f90c0b121bf9",
        "authorId" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "body" : "Thanks. Added a comment to keep it clear as well.",
        "createdAt" : "2021-06-02T00:43:51Z",
        "updatedAt" : "2021-06-02T00:43:51Z",
        "lastEditedBy" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "tags" : [
        ]
      }
    ],
    "commit" : "35d06150f37e01256314af4956c6e8fdcf7244b4",
    "line" : 195,
    "diffHunk" : "@@ -1,1 +1763,1767 @@              // mapIndex is part of the merge result of <shuffleId, reduceId>\n              mapOutputTracker.\n                unregisterMergeResult(shuffleId, reduceId, bmAddress, Option(mapIndex))\n            }\n          }"
  },
  {
    "id" : "4fa3f504-bb0d-4422-8078-6733d9137b3b",
    "prId" : 30691,
    "prUrl" : "https://github.com/apache/spark/pull/30691#pullrequestreview-678961411",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3e365131-3d97-486a-9d8a-fe26ff92f8bb",
        "parentId" : null,
        "authorId" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "body" : "So we decide to use a fixed number of threads instead of exposing a config?",
        "createdAt" : "2021-06-08T18:29:57Z",
        "updatedAt" : "2021-06-08T18:29:57Z",
        "lastEditedBy" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "tags" : [
        ]
      },
      {
        "id" : "f0517b53-1eac-478a-a04d-91e5b0b11e58",
        "parentId" : "3e365131-3d97-486a-9d8a-fe26ff92f8bb",
        "authorId" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "body" : "Yes, I don't think we need a config as of now. In future, if needed we can always add a config.",
        "createdAt" : "2021-06-08T20:16:53Z",
        "updatedAt" : "2021-06-08T20:16:53Z",
        "lastEditedBy" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "tags" : [
        ]
      }
    ],
    "commit" : "35d06150f37e01256314af4956c6e8fdcf7244b4",
    "line" : 46,
    "diffHunk" : "@@ -1,1 +275,279 @@\n  private val shuffleMergeFinalizeScheduler =\n    ThreadUtils.newDaemonThreadPoolScheduledExecutor(\"shuffle-merge-finalizer\", 8)\n\n  /**"
  },
  {
    "id" : "46712c36-b58e-4e1d-8d55-99adeda82e17",
    "prId" : 30691,
    "prUrl" : "https://github.com/apache/spark/pull/30691#pullrequestreview-678893443",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a5ffbdc2-d19f-48c1-967d-12345ba9b5b7",
        "parentId" : null,
        "authorId" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "body" : "Is it safe to put the second check into this assert?\r\nIt could be for submitting a retry of an already merge finalized map stage.",
        "createdAt" : "2021-06-08T18:49:28Z",
        "updatedAt" : "2021-06-08T18:49:28Z",
        "lastEditedBy" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "tags" : [
        ]
      },
      {
        "id" : "f20a2ec1-9d96-48e2-a6e7-99d047850b51",
        "parentId" : "a5ffbdc2-d19f-48c1-967d-12345ba9b5b7",
        "authorId" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "body" : "I see that this case is now handled outside of this method.\r\nYou can ignore this comment.",
        "createdAt" : "2021-06-08T18:52:30Z",
        "updatedAt" : "2021-06-08T18:52:30Z",
        "lastEditedBy" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "tags" : [
        ]
      }
    ],
    "commit" : "35d06150f37e01256314af4956c6e8fdcf7244b4",
    "line" : 82,
    "diffHunk" : "@@ -1,1 +1297,1301 @@   */\n  private def prepareShuffleServicesForShuffleMapStage(stage: ShuffleMapStage): Unit = {\n    assert(stage.shuffleDep.shuffleMergeEnabled && !stage.shuffleDep.shuffleMergeFinalized)\n    if (stage.shuffleDep.getMergerLocs.isEmpty) {\n      val mergerLocs = sc.schedulerBackend.getShufflePushMergerLocations("
  },
  {
    "id" : "fa7449bd-e197-4af8-8164-1304f35d69df",
    "prId" : 30691,
    "prUrl" : "https://github.com/apache/spark/pull/30691#pullrequestreview-679095366",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a0607dc0-ce5c-4083-b891-ca3856c69bd3",
        "parentId" : null,
        "authorId" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "body" : "If we make this change, is SPARK-32923 (for properly handling indeterminate stage retries) still needed as part of SPARK-30602?\r\nThis will always recompute all partitions.\r\nShould we also reset the other metadata here, such as resetting `sms.shuffleDep.shuffleMergeEnabled`?\r\nThis way it would make sure that the later invocation to `prepareShuffleServicesForShuffleMapStage` would not be interfered from the previous attempt of this indeterminate stage.",
        "createdAt" : "2021-06-08T18:50:34Z",
        "updatedAt" : "2021-06-08T18:50:34Z",
        "lastEditedBy" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "tags" : [
        ]
      },
      {
        "id" : "17366aa5-fb75-4c56-84c9-5ddcf96d22cf",
        "parentId" : "a0607dc0-ce5c-4083-b891-ca3856c69bd3",
        "authorId" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "body" : "Made a comment here to handle clean up of shuffle merge metadata as part of handling SPARK-32923 (non-deterministic stage retries) and in SPARK-35547 (handling barrier execution mode)",
        "createdAt" : "2021-06-08T23:47:28Z",
        "updatedAt" : "2021-06-08T23:47:28Z",
        "lastEditedBy" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "tags" : [
        ]
      }
    ],
    "commit" : "35d06150f37e01256314af4956c6e8fdcf7244b4",
    "line" : 107,
    "diffHunk" : "@@ -1,1 +1326,1330 @@        // TODO: SPARK-32923: Clean all push-based shuffle metadata like merge enabled and\n        // TODO: finalized as we are clearing all the merge results.\n        mapOutputTracker.unregisterAllMapAndMergeOutput(sms.shuffleDep.shuffleId)\n      case _ =>\n    }"
  },
  {
    "id" : "353d556b-b473-4c6b-9d05-37993d9ca130",
    "prId" : 30691,
    "prUrl" : "https://github.com/apache/spark/pull/30691#pullrequestreview-679096983",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "55689607-5c08-4f84-9eb5-bb3299469c29",
        "parentId" : null,
        "authorId" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "body" : "Similar to the handling of indeterminate stage retry, should we also reset other metadata here?",
        "createdAt" : "2021-06-08T19:10:46Z",
        "updatedAt" : "2021-06-08T19:10:46Z",
        "lastEditedBy" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "tags" : [
        ]
      },
      {
        "id" : "2f117bbd-7908-426a-98bd-023ed0d6086f",
        "parentId" : "55689607-5c08-4f84-9eb5-bb3299469c29",
        "authorId" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "body" : "Same as above, added a comment here to handle it as part of handling barrier execution mode handling.",
        "createdAt" : "2021-06-08T23:51:38Z",
        "updatedAt" : "2021-06-08T23:51:39Z",
        "lastEditedBy" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "tags" : [
        ]
      }
    ],
    "commit" : "35d06150f37e01256314af4956c6e8fdcf7244b4",
    "line" : 187,
    "diffHunk" : "@@ -1,1 +1755,1759 @@            // TODO: SPARK-35547: Clean all push-based shuffle metadata like merge enabled and\n            // TODO: finalized as we are clearing all the merge results.\n            mapOutputTracker.unregisterAllMapAndMergeOutput(shuffleId)\n          } else if (mapIndex != -1) {\n            // Mark the map whose fetch failed as broken in the map stage"
  },
  {
    "id" : "c902f171-824f-476a-827c-de088ee9d588",
    "prId" : 30691,
    "prUrl" : "https://github.com/apache/spark/pull/30691#pullrequestreview-678944960",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d12ccf81-5867-4959-bce3-5cc3d1161467",
        "parentId" : null,
        "authorId" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "body" : "By removing the `timedOut` field, we will always register MergeStatus even after the timeout.\r\nThe original code was also doing the same, but it was easier to fix this there.\r\nSo SPARK-35549 will address this?",
        "createdAt" : "2021-06-08T19:49:08Z",
        "updatedAt" : "2021-06-08T19:49:08Z",
        "lastEditedBy" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "tags" : [
        ]
      },
      {
        "id" : "13cb14fd-0188-413d-9696-35cd68aa386f",
        "parentId" : "d12ccf81-5867-4959-bce3-5cc3d1161467",
        "authorId" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "body" : "Ignore this comment.\r\nI see that you already handle this during `handleRegisterMergeStatuses` by checking if the shuffle is already merge finalized.",
        "createdAt" : "2021-06-08T19:56:15Z",
        "updatedAt" : "2021-06-08T19:56:15Z",
        "lastEditedBy" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "tags" : [
        ]
      }
    ],
    "commit" : "35d06150f37e01256314af4956c6e8fdcf7244b4",
    "line" : 251,
    "diffHunk" : "@@ -1,1 +2051,2055 @@      val numMergers = stage.shuffleDep.getMergerLocs.length\n      val results = (0 until numMergers).map(_ => SettableFuture.create[Boolean]())\n\n      stage.shuffleDep.getMergerLocs.zipWithIndex.foreach {\n        case (shuffleServiceLoc, index) =>"
  },
  {
    "id" : "1810bc64-f85a-40b5-97aa-8c45adf42f80",
    "prId" : 30691,
    "prUrl" : "https://github.com/apache/spark/pull/30691#pullrequestreview-678955416",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "63b83d26-f9b0-4a44-8a86-7dbddc358d2f",
        "parentId" : null,
        "authorId" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "body" : "Could you help me to understand why we need SPARK-35549?\r\nWhy do we want to register late MergeStatus?",
        "createdAt" : "2021-06-08T20:00:17Z",
        "updatedAt" : "2021-06-08T20:00:17Z",
        "lastEditedBy" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "tags" : [
        ]
      },
      {
        "id" : "6593970f-32c9-4b57-9a05-cfb7748a669a",
        "parentId" : "63b83d26-f9b0-4a44-8a86-7dbddc358d2f",
        "authorId" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "body" : "Yes, that is correct. That would help in getting better overall merge ratio eventually right?",
        "createdAt" : "2021-06-08T20:09:14Z",
        "updatedAt" : "2021-06-08T20:09:15Z",
        "lastEditedBy" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "tags" : [
        ]
      }
    ],
    "commit" : "35d06150f37e01256314af4956c6e8fdcf7244b4",
    "line" : 327,
    "diffHunk" : "@@ -1,1 +2127,2131 @@      mergeStatuses: Seq[(Int, MergeStatus)]): Unit = {\n    // Register merge statuses if the stage is still running and shuffle merge is not finalized yet.\n    // TODO: SPARK-35549: Currently merge statuses results which come after shuffle merge\n    // TODO: is finalized is not registered.\n    if (runningStages.contains(stage) && !stage.shuffleDep.shuffleMergeFinalized) {"
  },
  {
    "id" : "cb78d91b-ddca-47ea-9ba8-a669fb910df9",
    "prId" : 30164,
    "prUrl" : "https://github.com/apache/spark/pull/30164#pullrequestreview-530769583",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "52920637-58c6-4457-852f-441aff554b52",
        "parentId" : null,
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "QQ: Are we planning on exposing merger location is any of the spark listener events ?",
        "createdAt" : "2020-10-30T06:51:08Z",
        "updatedAt" : "2020-11-20T00:32:25Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      },
      {
        "id" : "f2b115b7-fee2-4e78-87fe-17e72a1ab38e",
        "parentId" : "52920637-58c6-4457-852f-441aff554b52",
        "authorId" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "body" : "@mridulm Can you please elaborate a bit on exposing merger locations through `SparkListener` events? Are you thinking about passing merger locations to `ExecutorAllocationManager` to request new executors based on this info?",
        "createdAt" : "2020-11-02T17:14:35Z",
        "updatedAt" : "2020-11-20T00:32:25Z",
        "lastEditedBy" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "tags" : [
        ]
      },
      {
        "id" : "459bc007-1f85-40f6-9fa0-782a0a0add10",
        "parentId" : "52920637-58c6-4457-852f-441aff554b52",
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "No, I meant as part of relevant `SparkListenerEvent`.\r\nSo that UI and/or analysis tools can see where the mergers are, how many merged blocks are hosted by that shuffle service, etc..",
        "createdAt" : "2020-11-02T19:19:58Z",
        "updatedAt" : "2020-11-20T00:32:25Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      },
      {
        "id" : "dc104144-7e93-408c-872e-1279b8c5aee3",
        "parentId" : "52920637-58c6-4457-852f-441aff554b52",
        "authorId" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "body" : "How about doing this as part of client side metrics changes? That can introduce so many changes if we do as part of this change. ",
        "createdAt" : "2020-11-02T21:02:40Z",
        "updatedAt" : "2020-11-20T00:32:25Z",
        "lastEditedBy" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "tags" : [
        ]
      },
      {
        "id" : "9c43139d-3c6e-4c90-8b21-0458d6f70672",
        "parentId" : "52920637-58c6-4457-852f-441aff554b52",
        "authorId" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "body" : "Should we expose the list of merger locations or just a count of number of merges for a given ShuffleMapStage?\r\nHaving a long list of merge locations might increase the event size.",
        "createdAt" : "2020-11-15T06:06:37Z",
        "updatedAt" : "2020-11-20T00:32:25Z",
        "lastEditedBy" : "15ef9b5b-1583-47d9-b883-14ebfd23a00a",
        "tags" : [
        ]
      }
    ],
    "commit" : "5ce29340c8aa4a6aadfc8d00cb5053a9be9aa839",
    "line" : 37,
    "diffHunk" : "@@ -1,1 +1279,1283 @@      logInfo(\"No available merger locations.\" +\n        s\" Push-based shuffle disabled for $stage (${stage.name})\")\n    }\n  }\n"
  },
  {
    "id" : "9c4adc59-969d-44d1-8cdf-8e06043849c3",
    "prId" : 30164,
    "prUrl" : "https://github.com/apache/spark/pull/30164#pullrequestreview-523948778",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e22e1571-ca07-41e0-b629-c0a3eff2c6ec",
        "parentId" : null,
        "authorId" : "9953a478-bdd8-4f15-be59-f6f654ff85ae",
        "body" : "Where is this being used?",
        "createdAt" : "2020-11-05T06:17:50Z",
        "updatedAt" : "2020-11-20T00:32:25Z",
        "lastEditedBy" : "9953a478-bdd8-4f15-be59-f6f654ff85ae",
        "tags" : [
        ]
      }
    ],
    "commit" : "5ce29340c8aa4a6aadfc8d00cb5053a9be9aa839",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +250,254 @@  taskScheduler.setDAGScheduler(this)\n\n  private val pushBasedShuffleEnabled = Utils.isPushBasedShuffleEnabled(sc.getConf)\n\n  /**"
  },
  {
    "id" : "af0c7b6c-3443-409c-be9a-17b5d0e2cd72",
    "prId" : 29869,
    "prUrl" : "https://github.com/apache/spark/pull/29869#pullrequestreview-499679928",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c3a8c7ce-9e88-4bf9-bf27-9ecd46bee619",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "\"Heavy\" means that accumulated values are too big? If so, we cannot just check the size here and pre-merge it if the size goes over a threshold? IMHO it is not a good idea for developers to control the accumulator behavior explicitly via the name prefix.",
        "createdAt" : "2020-09-28T11:32:01Z",
        "updatedAt" : "2020-09-28T11:32:01Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "7ad5f1b6-f63a-47dc-b5df-915aca74157b",
        "parentId" : "c3a8c7ce-9e88-4bf9-bf27-9ecd46bee619",
        "authorId" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "body" : "Yes. \"Heavy\" means the size is too big, such as the accumulator value contains thousands of file paths. I know this looks not a good solution. Do you mean to use a size threshold to filter out the big accumulator values? The problem that way is we split the same accumulators (same name with different sizes). Actually, Spark uses METRICS_PREFIX to distinguish the internal metrics from all accumulators `val METRICS_PREFIX = \"internal.metrics.\"`. We can separate them to `val (externalAccumUpdates, internalAccumUpdates)` and update/merge the `externalAccumUpdates` before they entering into event loop. But, you know, we still cannot forbid developers to use the \"internal.metrics.\" prefix. We only could add some comments in code and document it.",
        "createdAt" : "2020-09-30T02:11:33Z",
        "updatedAt" : "2020-09-30T02:12:58Z",
        "lastEditedBy" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "tags" : [
        ]
      },
      {
        "id" : "c54a1e26-7c67-4b59-98cb-a11167c5787c",
        "parentId" : "c3a8c7ce-9e88-4bf9-bf27-9ecd46bee619",
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "internal configs and user facing are completely different.  Yes if someone reads the code they could create internal ones but that is use at your own risk and we don't guarantee any api. This is user facing api essentially.  I agree with @maropu I'm not really fond of the prefix approach.   Is this only for CollectionAccumulator or SetAccumulator? Although it looks like the SetAccumulator is specific to delta.",
        "createdAt" : "2020-09-30T17:56:34Z",
        "updatedAt" : "2020-09-30T17:56:35Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      }
    ],
    "commit" : "d9ecb25257827a85db6b536c5dc7fc270ef24ec2",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +277,281 @@    // It may cause heavy full GC problem if some heavy external accumulators keep in memory.\n    // We update these heavy accumulators before they entering into Spark listener event loop.\n    val (heavyAccumUpdates, otherAccumUpdates) = accumUpdates.partition { acc =>\n      acc.name.exists(_.startsWith(ExternalHeavyAccumulator.HEAVY_PREFIX))\n    }"
  },
  {
    "id" : "1f2f930c-1610-4a05-ab12-781f8d1868fa",
    "prId" : 29869,
    "prUrl" : "https://github.com/apache/spark/pull/29869#pullrequestreview-499042171",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e348ea6d-5909-4b32-97cd-ae408a559ce0",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "This code part looks almost the same with `updateAccumulators`, so could we share it between them?",
        "createdAt" : "2020-09-28T11:38:49Z",
        "updatedAt" : "2020-09-28T11:38:49Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "3d3f93f7-1f94-45fb-96ed-78254f67292d",
        "parentId" : "e348ea6d-5909-4b32-97cd-ae408a559ce0",
        "authorId" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "body" : "Yes. We can extract the common part as a new private method.",
        "createdAt" : "2020-09-30T02:20:23Z",
        "updatedAt" : "2020-09-30T02:20:24Z",
        "lastEditedBy" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "tags" : [
        ]
      }
    ],
    "commit" : "d9ecb25257827a85db6b536c5dc7fc270ef24ec2",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +281,285 @@    }\n    heavyAccumUpdates.foreach { updates =>\n      val id = updates.id\n      try {\n        // Find the corresponding accumulator on the driver and update it"
  },
  {
    "id" : "09c8f5e7-7ec4-4e13-8795-909d7d8fd29a",
    "prId" : 29788,
    "prUrl" : "https://github.com/apache/spark/pull/29788#pullrequestreview-493095001",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0bb3c3df-54d2-4659-8474-bdd17b83b0d6",
        "parentId" : null,
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "See comment below for `ExecutorDecommission` ... Should this be changed to a:\r\n\r\n```\r\ncase decom @ ExecutorDecommission => decom.workerHost // or decom.host\r\n```\r\n\r\nYou don't need to add an extra '_' then.",
        "createdAt" : "2020-09-18T17:11:36Z",
        "updatedAt" : "2020-09-18T17:38:05Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      },
      {
        "id" : "51e93da7-506f-448d-8f75-81fea1bebfe5",
        "parentId" : "0bb3c3df-54d2-4659-8474-bdd17b83b0d6",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Yeah, this actually a good point! This's actually a rule of  Databricks' scala style guide. But I just follow the style of above `ExecutorProcessLost` here. I think it's acceptable when there're not many arugumenetes are being expaned.",
        "createdAt" : "2020-09-22T02:37:22Z",
        "updatedAt" : "2020-09-22T02:37:22Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "9bebdd4f2846f12f8ab13279c8cece151e8edfd0",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +2369,2373 @@      val workerHost = reason match {\n        case ExecutorProcessLost(_, workerHost, _) => workerHost\n        case ExecutorDecommission(_, host) => host\n        case _ => None\n      }"
  },
  {
    "id" : "88e3c1e7-845c-4156-84d4-f9aa68ffca54",
    "prId" : 29422,
    "prUrl" : "https://github.com/apache/spark/pull/29422#pullrequestreview-467904649",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dfbdea39-4922-48be-8382-a62e1125844b",
        "parentId" : null,
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "Can we have a comment here clarifying the reasoning behind this logic?",
        "createdAt" : "2020-08-14T17:45:13Z",
        "updatedAt" : "2020-08-17T23:52:14Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      },
      {
        "id" : "350c6853-b44c-487f-b191-5670f52686a2",
        "parentId" : "dfbdea39-4922-48be-8382-a62e1125844b",
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "Will do. Good idea.\r\n\r\nAdded a comment on the caller. The changes in this function are simply tweaking the existing logic to honor the newly added flag. So I thought it would be more interesting to describe why this unconditional forcing is required when a host is decommissioned.",
        "createdAt" : "2020-08-14T22:24:20Z",
        "updatedAt" : "2020-08-17T23:52:14Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      }
    ],
    "commit" : "df128e507a2c7bd11d33197fca6b4fa10f4e9256",
    "line" : 40,
    "diffHunk" : "@@ -1,1 +2031,2035 @@      clearCacheLocs()\n    }\n    if (fileLost) {\n      val remove = if (ignoreShuffleFileLostEpoch) {\n        true"
  },
  {
    "id" : "36bc9e9e-af9f-4386-a0e0-04a514655f0a",
    "prId" : 29014,
    "prUrl" : "https://github.com/apache/spark/pull/29014#pullrequestreview-453406412",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "375a2a96-7875-4a95-aac2-a5b580d292cf",
        "parentId" : null,
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "So would we want to do this unless local fetch is disabled (which since it isn't merged yet it will be) and the executor is decommissioned or the the host is decommissioned? Should we use isShuffleLost here instead?",
        "createdAt" : "2020-07-17T22:32:07Z",
        "updatedAt" : "2020-07-29T01:25:46Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      },
      {
        "id" : "cdfa25e3-e979-483b-ba67-1e0e5ee8be58",
        "parentId" : "375a2a96-7875-4a95-aac2-a5b580d292cf",
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "@holdenk .. by \"local fetch\", did you mean https://github.com/apache/spark/pull/28911 ? \r\n\r\nTypically `isHostDecommissioned` is set by the cluster manager: It knows for sure that the host is lost or not. For example, the Master knows when a Worker goes away for real. Something similar would have to be done for YARN.\r\n\r\nIs the reasoning for adding this check: We don't need to clear the shuffle state if an executor is decommissioned even if external shuffle service is disabled, as long as there are other executors on that host ? \r\n\r\nIf I understand you correctly, the condition you are hinting at is this (please do confirm):\r\n\r\n```\r\n   if (host is decommissioned) {\r\n    // clear shuffle state for the entire host\r\n   } else if (!isLocalFetchEnabled || numRemainingLiveExecutorsOnThisHost == 0) {\r\n    // clear shuffle state for just this executor that suffered the fetch failure\r\n    // because we can be sure that no one else will serve this executor's data\r\n   }\r\n```\r\n\r\nI will consider using `isShuffleLost ` here to determine if the shuffle has been lost here. ",
        "createdAt" : "2020-07-18T00:23:33Z",
        "updatedAt" : "2020-07-29T01:25:46Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      },
      {
        "id" : "20f28767-a2f4-4d69-8613-2101d5d4753b",
        "parentId" : "375a2a96-7875-4a95-aac2-a5b580d292cf",
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "`isShuffleLost` is not very applicable here. Actually that method was too narrow in scope so I inlined it. It strictly means that shuffle is lost for this executor. \r\n\r\nIn this context, we already know that shuffle is lost for the executor: We are simply trying to determine if it is also lost for the entire host. I updated the code to reflect the logic/intent better. \r\n\r\nI will create a follow up Jira under the master ticket to track changing this logic when \"Local Fetch\" is merged in.",
        "createdAt" : "2020-07-18T02:14:53Z",
        "updatedAt" : "2020-07-29T01:25:46Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      },
      {
        "id" : "7e8f493b-3c1a-4d44-aa4c-7215e76d55c7",
        "parentId" : "375a2a96-7875-4a95-aac2-a5b580d292cf",
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "Yes that is correct reading of my comment. In the else if block though I'd also add that the external shuffle service is not enabled.",
        "createdAt" : "2020-07-20T21:29:43Z",
        "updatedAt" : "2020-07-29T01:25:46Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      },
      {
        "id" : "14c107a3-d2d7-49c9-a129-861d845dcf26",
        "parentId" : "375a2a96-7875-4a95-aac2-a5b580d292cf",
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "I thought a bit more about this and I think that the author of #28911 should implement the optimization of whether or not a shuffle state should be cleared when you get a fetchf failure from an executor -- when other \"local\" executors might serve those outputs. \r\n\r\nThis is an optimization in that it leverages the Local fetch feature introduced in #28911. I don't know enough about local fetch implementation to comment more about it.\r\n\r\nFrom my perspective of decommissioning, I have changed the logic to be: Executors on the host are fate shared if either we know that they share an external shuffle service or if we know that the host has been decommissioned. In that case, mark the entire host as lost (if the feature flag `unRegisterOutputOnHostOnFetchFailure` is enabled).\r\n\r\ncc: @Ngone51 (author of #28911)",
        "createdAt" : "2020-07-21T18:14:13Z",
        "updatedAt" : "2020-07-29T01:25:46Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      },
      {
        "id" : "813e7c69-4eb2-4a04-b63f-1acd3ef36f6f",
        "parentId" : "375a2a96-7875-4a95-aac2-a5b580d292cf",
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "Sounds reasonable. So long as we reconcile how these two features work together before 3.1.",
        "createdAt" : "2020-07-21T20:42:59Z",
        "updatedAt" : "2020-07-29T01:25:46Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      },
      {
        "id" : "aca2d861-b3f0-48a5-a925-3bf97ff8babd",
        "parentId" : "375a2a96-7875-4a95-aac2-a5b580d292cf",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "> if (host is decommissioned) {\r\n    // clear shuffle state for the entire host\r\n   } else if (!isLocalFetchEnabled || numRemainingLiveExecutorsOnThisHost == 0) {\r\n    // clear shuffle state for just this executor that suffered the fetch failure\r\n    // because we can be sure that no one else will serve this executor's data\r\n   }\r\n\r\n> should implement the optimization of whether or not a shuffle state should be cleared when you get a fetchf failure from an executor \r\n\r\nThese're actually good idea! I just have a few concerns that whether they are doable with current implementation... I mean, when fetch failure happens on an executor, the possible reasons may be executor lost or shuffle data corrupt. For these two reasons, host-local shuffle reading could still result in fetch failure at the end. Because, even if we use host-local shuffle data reading, we need to ask the lost executor for the directory first. And if the shuffle data is corrupted, we'll fail to read the shuffle data anyway. Though, in the case of executor lost, it's maybe doable as we have local disk directories cache locally so that the executor on the same host won't ask the lost executor for the directory. However, the problem is that the driver is not aware of the status of the cache. Thus, the driver also has no idea whether we should clean up the shuffle state for the lost executor or not.",
        "createdAt" : "2020-07-22T15:01:37Z",
        "updatedAt" : "2020-07-29T01:25:46Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "dbc478b0d96de0f1a48f93d90f1e648229b5790c",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +1825,1829 @@            val isHostDecommissioned = taskScheduler\n              .getExecutorDecommissionInfo(bmAddress.executorId)\n              .exists(_.isHostDecommissioned)\n\n            // Shuffle output of all executors on host `bmAddress.host` may be lost if:"
  },
  {
    "id" : "1cc17fea-e0be-45bb-a9cb-55129df3f9bc",
    "prId" : 28848,
    "prUrl" : "https://github.com/apache/spark/pull/28848#pullrequestreview-438640786",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "98178bda-ccc9-4455-b63e-7ac3e81fa62a",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "nit. If you don't mind, can we avoid a style change like this in order to focus the feature?\r\n```\r\n- logInfo(\"Executor lost: %s (epoch %d)\".format(execId, currentEpoch))\r\n+ logInfo(s\"Executor lost: $execId (epoch $currentEpoch)\")\r\n```",
        "createdAt" : "2020-06-20T00:19:12Z",
        "updatedAt" : "2020-07-15T00:52:03Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "33cb5498-ecc9-4d9e-ac50-27394fa6a058",
        "parentId" : "98178bda-ccc9-4455-b63e-7ac3e81fa62a",
        "authorId" : "119f7711-a251-4127-b455-51a922a097f1",
        "body" : "@attilapiros requested this change. I'm fine with either style. Both styles are used in the file.\r\nI can change it back, but I don't want to keep changing back and forth.\r\nSo let me do that only if you are satisfied with the substantive part of this change and are prepared to approve it.",
        "createdAt" : "2020-06-22T20:38:52Z",
        "updatedAt" : "2020-07-15T00:52:03Z",
        "lastEditedBy" : "119f7711-a251-4127-b455-51a922a097f1",
        "tags" : [
        ]
      },
      {
        "id" : "ba756904-5c8d-47fd-b1a1-65e6a585c9cc",
        "parentId" : "98178bda-ccc9-4455-b63e-7ac3e81fa62a",
        "authorId" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "body" : "Guilty as charged. My thinking was the following: as the string interpolation preferred in the project and the change itself is quite tiny and has zero risk and we are here and touching these lines it would be good to do it now (aka Boy Scout Rule).",
        "createdAt" : "2020-06-23T05:27:45Z",
        "updatedAt" : "2020-07-15T00:52:03Z",
        "lastEditedBy" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "tags" : [
        ]
      },
      {
        "id" : "cf0cd5f8-96ac-4ef5-a4f1-497102046869",
        "parentId" : "98178bda-ccc9-4455-b63e-7ac3e81fa62a",
        "authorId" : "e913f9af-103d-40d4-976e-9aa8e12e7211",
        "body" : "while I don't think this is a big deal either way, I also try to follow the \"boy scout rule\" as long as its fixing stuff very close to the actual change.",
        "createdAt" : "2020-06-24T14:34:01Z",
        "updatedAt" : "2020-07-15T00:52:03Z",
        "lastEditedBy" : "e913f9af-103d-40d4-976e-9aa8e12e7211",
        "tags" : [
        ]
      },
      {
        "id" : "1ad6aeda-b392-4f23-8b1e-46380f901818",
        "parentId" : "98178bda-ccc9-4455-b63e-7ac3e81fa62a",
        "authorId" : "119f7711-a251-4127-b455-51a922a097f1",
        "body" : "@dongjoon-hyun based on Attila's and Imran's comments, I'm inclined to stick with the string interpolation here and below, since it is all within the method I'm actively modifying.\r\nAre you ok with resolving this then?",
        "createdAt" : "2020-06-26T23:13:36Z",
        "updatedAt" : "2020-07-15T00:52:03Z",
        "lastEditedBy" : "119f7711-a251-4127-b455-51a922a097f1",
        "tags" : [
        ]
      }
    ],
    "commit" : "0e0086288f6279569e8a11cef9d928b87c40469b",
    "line" : 98,
    "diffHunk" : "@@ -1,1 +1976,1980 @@    if (!executorFailureEpoch.contains(execId) || executorFailureEpoch(execId) < currentEpoch) {\n      executorFailureEpoch(execId) = currentEpoch\n      logInfo(s\"Executor lost: $execId (epoch $currentEpoch)\")\n      blockManagerMaster.removeExecutor(execId)\n      clearCacheLocs()"
  },
  {
    "id" : "7ede9f8f-9f5a-4caf-9a66-3217a59872c2",
    "prId" : 28848,
    "prUrl" : "https://github.com/apache/spark/pull/28848#pullrequestreview-434386355",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3105d38c-b69a-4c7a-b98b-2cd5ecbcd047",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "ditto.",
        "createdAt" : "2020-06-20T00:20:23Z",
        "updatedAt" : "2020-07-15T00:52:03Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "0e0086288f6279569e8a11cef9d928b87c40469b",
    "line" : 120,
    "diffHunk" : "@@ -1,1 +1985,1989 @@      hostToUnregisterOutputs match {\n        case Some(host) =>\n          logInfo(s\"Shuffle files lost for host: $host (epoch $currentEpoch)\")\n          mapOutputTracker.removeOutputsOnHost(host)\n        case None =>"
  },
  {
    "id" : "4481ffac-fd48-4e7d-9aca-bb2ed215a170",
    "prId" : 28848,
    "prUrl" : "https://github.com/apache/spark/pull/28848#pullrequestreview-434386370",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "41016bba-e1d7-4dad-8917-bace0b98c3dc",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "ditto.",
        "createdAt" : "2020-06-20T00:20:31Z",
        "updatedAt" : "2020-07-15T00:52:03Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "0e0086288f6279569e8a11cef9d928b87c40469b",
    "line" : 123,
    "diffHunk" : "@@ -1,1 +1988,1992 @@          mapOutputTracker.removeOutputsOnHost(host)\n        case None =>\n          logInfo(s\"Shuffle files lost for executor: $execId (epoch $currentEpoch)\")\n          mapOutputTracker.removeOutputsOnExecutor(execId)\n      }"
  },
  {
    "id" : "1e66b763-23f5-4775-bd7d-365bc3fc4d2f",
    "prId" : 28848,
    "prUrl" : "https://github.com/apache/spark/pull/28848#pullrequestreview-435254473",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7c5c26e8-4996-4523-ad05-78abced1b546",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "nit: `;` -> `,`",
        "createdAt" : "2020-06-22T02:34:40Z",
        "updatedAt" : "2020-07-15T00:52:03Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "0a33de1b-5bc0-4fdf-8a4a-ef8c819a7ab0",
        "parentId" : "7c5c26e8-4996-4523-ad05-78abced1b546",
        "authorId" : "119f7711-a251-4127-b455-51a922a097f1",
        "body" : "I deliberately used a semicolon; it was not a typo.",
        "createdAt" : "2020-06-22T20:36:06Z",
        "updatedAt" : "2020-07-15T00:52:03Z",
        "lastEditedBy" : "119f7711-a251-4127-b455-51a922a097f1",
        "tags" : [
        ]
      }
    ],
    "commit" : "0e0086288f6279569e8a11cef9d928b87c40469b",
    "line" : 94,
    "diffHunk" : "@@ -1,1 +1972,1976 @@      maybeEpoch: Option[Long] = None): Unit = {\n    val currentEpoch = maybeEpoch.getOrElse(mapOutputTracker.getEpoch)\n    logDebug(s\"Considering removal of executor $execId; \" +\n      s\"fileLost: $fileLost, currentEpoch: $currentEpoch\")\n    if (!executorFailureEpoch.contains(execId) || executorFailureEpoch(execId) < currentEpoch) {"
  }
]