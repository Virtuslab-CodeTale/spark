[
  {
    "id" : "a5b60c87-a18d-45e2-9a74-0219d63af849",
    "prId" : 31348,
    "prUrl" : "https://github.com/apache/spark/pull/31348#pullrequestreview-584114799",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5bdeacdd-32a3-451d-8ef7-56a051f7bacb",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "This change moves the handling of `ExecutorStateChanged` from `receive` to `receiveAndReply` and `context.reply(true)` is the only difference.\r\n",
        "createdAt" : "2021-02-05T08:27:35Z",
        "updatedAt" : "2021-02-19T04:46:17Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "7e55532799f98b55ec6bae47fd2bd830d5be4b78",
    "line" : 60,
    "diffHunk" : "@@ -1,1 +504,508 @@      }\n\n    case ExecutorStateChanged(appId, execId, state, message, exitStatus) =>\n      val execOption = idToApp.get(appId).flatMap(app => app.executors.get(execId))\n      execOption match {"
  },
  {
    "id" : "70196b48-4899-4e48-aa01-2772d729a9f5",
    "prId" : 30131,
    "prUrl" : "https://github.com/apache/spark/pull/30131#pullrequestreview-516489592",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d8cd7b10-6da5-4a2a-ae7b-c57f038eaa57",
        "parentId" : null,
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "Clean Timeout worker with a delay is ok. ",
        "createdAt" : "2020-10-26T06:16:44Z",
        "updatedAt" : "2020-11-26T00:49:06Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "5643ec267a339877c1004aae9e1ed8ae1f8f6cca",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +154,158 @@    }\n    checkForWorkerTimeOutTask = forwardMessageThread.scheduleWithFixedDelay(\n      () => Utils.tryLogNonFatalError { self.send(CheckForWorkerTimeOut) },\n      0, workerTimeoutMs, TimeUnit.MILLISECONDS)\n"
  },
  {
    "id" : "79d8521c-d12e-430d-8408-4503e852c841",
    "prId" : 30131,
    "prUrl" : "https://github.com/apache/spark/pull/30131#pullrequestreview-538681948",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d679df58-a23f-45c8-9afa-b56f1f00b2cf",
        "parentId" : null,
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "+CC @Ngone51 Any thoughts on how this will impact standalone ? For changes to both `Master` and `Worker` classes.\r\nTypically I would not prefer a behavior change for a cleanup PR.",
        "createdAt" : "2020-11-25T16:45:12Z",
        "updatedAt" : "2020-11-26T00:49:06Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      }
    ],
    "commit" : "5643ec267a339877c1004aae9e1ed8ae1f8f6cca",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +154,158 @@    }\n    checkForWorkerTimeOutTask = forwardMessageThread.scheduleWithFixedDelay(\n      () => Utils.tryLogNonFatalError { self.send(CheckForWorkerTimeOut) },\n      0, workerTimeoutMs, TimeUnit.MILLISECONDS)\n"
  },
  {
    "id" : "91965cc6-6bb9-4924-8eea-a34ca8330d78",
    "prId" : 29722,
    "prUrl" : "https://github.com/apache/spark/pull/29722#pullrequestreview-489303229",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "85db06ae-cd6c-4329-a187-0bcfdf05903e",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "shall we skip it for `if (state == RecoveryState.STANDBY)` ?",
        "createdAt" : "2020-09-16T06:09:37Z",
        "updatedAt" : "2020-09-16T06:57:25Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "9db698d0-7d71-4ff8-95bc-107bce98fdb8",
        "parentId" : "85db06ae-cd6c-4329-a187-0bcfdf05903e",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "or it will never happen because the request comes from master web UI?",
        "createdAt" : "2020-09-16T06:10:09Z",
        "updatedAt" : "2020-09-16T06:57:25Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "e94b43f9-9e37-43ed-a464-f7271c091f79",
        "parentId" : "85db06ae-cd6c-4329-a187-0bcfdf05903e",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "It has been checked by the caller when handling `DecommissionWorkersOnHosts`.",
        "createdAt" : "2020-09-16T06:11:35Z",
        "updatedAt" : "2020-09-16T06:57:25Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "de826e69-6f01-4d09-8e4e-c85585a791a4",
        "parentId" : "85db06ae-cd6c-4329-a187-0bcfdf05903e",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "ok, make sense.",
        "createdAt" : "2020-09-16T06:14:04Z",
        "updatedAt" : "2020-09-16T06:57:25Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "cef50efe-3ba1-4edb-926e-d5b84ffaad77",
        "parentId" : "85db06ae-cd6c-4329-a187-0bcfdf05903e",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ah i see",
        "createdAt" : "2020-09-16T06:14:11Z",
        "updatedAt" : "2020-09-16T06:57:25Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "290d2c08a1adfce3c0c4afe1cb8c9e214b25ea3d",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +258,262 @@      // so it should not be the STANDBY\n      assert(state != RecoveryState.STANDBY)\n      ids.foreach ( id =>\n        // We use foreach since get gives us an option and we can skip the failures.\n        idToWorker.get(id).foreach { w =>"
  },
  {
    "id" : "49f722c2-0959-4700-944c-e5e92f96f75f",
    "prId" : 29579,
    "prUrl" : "https://github.com/apache/spark/pull/29579#pullrequestreview-481677592",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ba68ae0e-d74e-4bbb-911d-5864f6e62c2c",
        "parentId" : null,
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "nit: can you reword the comment to be more accurate now :-) ",
        "createdAt" : "2020-08-31T06:21:18Z",
        "updatedAt" : "2020-09-07T13:30:39Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      },
      {
        "id" : "bd571560-bc87-4b48-a90a-5c036bb240ce",
        "parentId" : "ba68ae0e-d74e-4bbb-911d-5864f6e62c2c",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Updated a little bit.",
        "createdAt" : "2020-09-03T09:48:24Z",
        "updatedAt" : "2020-09-07T13:30:39Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "d2468407f3d02e5a191ad373b5f2201a930cbb09",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +910,914 @@          exec.id, ExecutorState.DECOMMISSIONED,\n          Some(\"worker decommissioned\"), None,\n          // worker host is being set here to let the driver know that the host (aka. worker)\n          // is also being decommissioned. So the driver can unregister all the shuffle map\n          // statues located at this host when it receives the executor lost event."
  },
  {
    "id" : "4a5c43ed-f8dd-4b44-8f3e-a120472ade30",
    "prId" : 28742,
    "prUrl" : "https://github.com/apache/spark/pull/28742#pullrequestreview-426291962",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "363e9910-e770-4192-b0e8-4fb5c6215f61",
        "parentId" : null,
        "authorId" : "bc001dd4-5224-4ca1-afdd-49d69783d7f2",
        "body" : "Why do you need to verify `waitingApps.length == 1` ?",
        "createdAt" : "2020-06-08T06:41:47Z",
        "updatedAt" : "2020-06-08T06:41:47Z",
        "lastEditedBy" : "bc001dd4-5224-4ca1-afdd-49d69783d7f2",
        "tags" : [
        ]
      },
      {
        "id" : "0bbb8914-9020-4aad-8608-b0fb70e62aec",
        "parentId" : "363e9910-e770-4192-b0e8-4fb5c6215f61",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "hmm..I was also thinking about this question when I was fixing. I think we can extend it to multiple apps. Let me try it.",
        "createdAt" : "2020-06-08T07:06:06Z",
        "updatedAt" : "2020-06-08T07:06:07Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "940bee1e-0bc4-45eb-aa45-1a50154d6cbd",
        "parentId" : "363e9910-e770-4192-b0e8-4fb5c6215f61",
        "authorId" : "bc001dd4-5224-4ca1-afdd-49d69783d7f2",
        "body" : "I'm not sure how useful is this warning message, this just reflects the current status within one round of scheduling, we can tolerant the behavior to not launch a new executor on currently available workers.",
        "createdAt" : "2020-06-08T07:11:10Z",
        "updatedAt" : "2020-06-08T07:11:10Z",
        "lastEditedBy" : "bc001dd4-5224-4ca1-afdd-49d69783d7f2",
        "tags" : [
        ]
      },
      {
        "id" : "1de0a809-2bcd-4ed7-9def-72e798db6634",
        "parentId" : "363e9910-e770-4192-b0e8-4fb5c6215f61",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "It's from https://github.com/apache/spark/pull/25047#discussion_r311779752 originally. The warning is mainly used to detect the possible hang of an application.",
        "createdAt" : "2020-06-08T07:15:09Z",
        "updatedAt" : "2020-06-08T07:15:09Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "3b2e3a5a-84ee-41ab-b668-b8d2e22df1c6",
        "parentId" : "363e9910-e770-4192-b0e8-4fb5c6215f61",
        "authorId" : "bc001dd4-5224-4ca1-afdd-49d69783d7f2",
        "body" : "I don't like this check, but that seems to be the most simple solution for now. Let's keep it then.",
        "createdAt" : "2020-06-08T07:21:27Z",
        "updatedAt" : "2020-06-08T07:21:27Z",
        "lastEditedBy" : "bc001dd4-5224-4ca1-afdd-49d69783d7f2",
        "tags" : [
        ]
      },
      {
        "id" : "245bd195-7a74-464f-b918-120bc43e2b6d",
        "parentId" : "363e9910-e770-4192-b0e8-4fb5c6215f61",
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "I think the idea of ==1 is that there is only 1 active application, if more then 1, other applications could be using resources so unless you did a lot more checking. We could definitely make it a more comprehensive check in the future.  I believe this was supposed to be a simple sanity check for people playing around that may have started the cluster with not enough resources.  The standalone mode does not tell you there aren't enough and will just hang forever.",
        "createdAt" : "2020-06-08T14:21:12Z",
        "updatedAt" : "2020-06-08T14:21:12Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      }
    ],
    "commit" : "55d47307df8f5eb7f303dd3ce4b09fbe45cf6e84",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +716,720 @@          .filter(canLaunchExecutor(_, app.desc))\n          .sortBy(_.coresFree).reverse\n        val appMayHang = waitingApps.length == 1 &&\n          waitingApps.head.executors.isEmpty && usableWorkers.isEmpty\n        if (appMayHang) {"
  },
  {
    "id" : "51c0f19e-6857-42cd-83f0-7bb4d3542271",
    "prId" : 27697,
    "prUrl" : "https://github.com/apache/spark/pull/27697#pullrequestreview-366735887",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5a79b31d-e738-404b-bbb1-1e9b366c44e0",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Could you make a test case for this?",
        "createdAt" : "2020-02-28T23:05:49Z",
        "updatedAt" : "2020-02-28T23:05:49Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "c8fe334d005046a23029b352c057d1b0c00c5129",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +801,805 @@    val allFreeCores = shuffledAliveWorkers.map(_.coresFree).sum\n    val forDriversFreeCores = math.max(allFreeCores - coresReservedForApps, 0)\n    if (forDriversFreeCores > 0) {\n      for (driver <- waitingDrivers.toList) { // iterate over a copy of waitingDrivers\n        // We assign workers to each waiting driver in a round-robin fashion. For each driver, we"
  },
  {
    "id" : "c7f311f1-5dc2-40bf-bd9c-8e85cd6ca9a8",
    "prId" : 26440,
    "prUrl" : "https://github.com/apache/spark/pull/26440#pullrequestreview-315652175",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a7186920-1ec1-4c94-b45c-45e5ec57c2a8",
        "parentId" : null,
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "might want to have a getOrElse or make sure idToWorker contains id in case something else timed out the worker between when message sent and when processed.",
        "createdAt" : "2019-11-08T21:41:57Z",
        "updatedAt" : "2020-02-13T23:10:10Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      },
      {
        "id" : "39eb0c96-4b3d-4976-834f-f26554a5be03",
        "parentId" : "a7186920-1ec1-4c94-b45c-45e5ec57c2a8",
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "So the get returns an option and we use `foreach` instead of `getOrElse`, but I'll the comment to make that clearer.",
        "createdAt" : "2019-11-12T16:08:01Z",
        "updatedAt" : "2020-02-13T23:10:10Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      }
    ],
    "commit" : "af550303e0b929dc9f7436bcfb36438ff36b8208",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +250,254 @@      } else {\n        // We use foreach since get gives us an option and we can skip the failures.\n        idToWorker.get(id).foreach(decommissionWorker)\n      }\n"
  }
]