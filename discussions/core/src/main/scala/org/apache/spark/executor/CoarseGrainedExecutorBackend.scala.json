[
  {
    "id" : "5df4914a-18f9-4168-a280-d035caa122fc",
    "prId" : 33759,
    "prUrl" : "https://github.com/apache/spark/pull/33759#pullrequestreview-731662363",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b59b5b87-b103-4edf-9959-924c77d8ea54",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "can we add some comments to explain when can this happen?",
        "createdAt" : "2021-08-17T09:35:54Z",
        "updatedAt" : "2021-08-17T09:35:55Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "e5a12bbf-c730-43a2-a0ed-fffc5960af15",
        "parentId" : "b59b5b87-b103-4edf-9959-924c77d8ea54",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "added",
        "createdAt" : "2021-08-17T11:48:53Z",
        "updatedAt" : "2021-08-17T11:48:54Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "57dc0ca8672f8e981f770752e89f705d8d567e6a",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +205,209 @@          // `executor` can be null if there's any error in `CoarseGrainedExecutorBackend.onStart`\n          // or fail to create `Executor`.\n          if (executor == null) {\n            System.exit(1)\n          } else {"
  },
  {
    "id" : "07475686-945b-4a22-84d2-65e0551dedbb",
    "prId" : 33028,
    "prUrl" : "https://github.com/apache/spark/pull/33028#pullrequestreview-695642220",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8600e946-dafe-43bf-80bb-6519a766b70d",
        "parentId" : null,
        "authorId" : "bc001dd4-5224-4ca1-afdd-49d69783d7f2",
        "body" : "If stopping is true, we should add a log saying we entered the `exitExecutor` function, but skipped actual actions because we already tried to exit before.",
        "createdAt" : "2021-06-23T19:17:44Z",
        "updatedAt" : "2021-06-23T19:17:45Z",
        "lastEditedBy" : "bc001dd4-5224-4ca1-afdd-49d69783d7f2",
        "tags" : [
        ]
      },
      {
        "id" : "4a902bdd-a563-4677-b73f-00957752e86f",
        "parentId" : "8600e946-dafe-43bf-80bb-6519a766b70d",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Added.",
        "createdAt" : "2021-06-30T02:23:43Z",
        "updatedAt" : "2021-06-30T02:23:43Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "2af82e5d4b83781194c9f0ebd51ada3be04f9279",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +272,276 @@                             throwable: Throwable = null,\n                             notifyDriver: Boolean = true) = {\n    if (stopping.compareAndSet(false, true)) {\n      val message = \"Executor self-exiting due to : \" + reason\n      if (throwable != null) {"
  },
  {
    "id" : "972f71bc-cdfe-424b-bf0a-d27f654b85d1",
    "prId" : 32287,
    "prUrl" : "https://github.com/apache/spark/pull/32287#pullrequestreview-654118765",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9945c97e-199f-4e98-9fd1-6a6e0f2b34f6",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "I tried to write a unit test for this change but realized it's not easy while I was trying. So I gave it up. But I have done the manual test and looks fine. cc @mridulm ",
        "createdAt" : "2021-05-07T06:18:04Z",
        "updatedAt" : "2021-05-10T10:25:15Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "4af6ee73221a55e3cd7239f151ec33d5e802cbe4",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +97,101 @@          s\"'${MAX_REMOTE_BLOCK_SIZE_FETCH_TO_MEM.key}', but got \" +\n          s\"${PlatformDependent.maxDirectMemory()} bytes < \" +\n          s\"${env.conf.get(MAX_REMOTE_BLOCK_SIZE_FETCH_TO_MEM)}\")\n      }\n"
  },
  {
    "id" : "13967d02-36e2-4e75-b36b-4c85f9293fe4",
    "prId" : 31102,
    "prUrl" : "https://github.com/apache/spark/pull/31102#pullrequestreview-576116782",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bd9b6bb0-1f20-4f9d-b8f5-c6e1129e0186",
        "parentId" : null,
        "authorId" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "body" : "Based on the above lines does `STORAGE_DECOMMISSION_ENABLED` has any role now? \r\nSo what about removing this config?",
        "createdAt" : "2021-01-15T14:19:43Z",
        "updatedAt" : "2021-03-23T02:08:10Z",
        "lastEditedBy" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "tags" : [
        ]
      },
      {
        "id" : "f51ed1f7-e406-470c-8618-c5a47ed5dd98",
        "parentId" : "bd9b6bb0-1f20-4f9d-b8f5-c6e1129e0186",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Thatâ€˜s my concern too. But removal involves the API change. I intentionally try to avoid that in this refactor PR. But I still think it's worth a try in a separate PR, especially since the 3.1 hasn't released yet. cc @holdenk what's your opinion?",
        "createdAt" : "2021-01-20T09:38:59Z",
        "updatedAt" : "2021-03-23T02:08:10Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "251c52cf-4c48-4b98-8a40-7514a94e4c0c",
        "parentId" : "bd9b6bb0-1f20-4f9d-b8f5-c6e1129e0186",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "kindly ping @holdenk ",
        "createdAt" : "2021-01-26T08:29:20Z",
        "updatedAt" : "2021-03-23T02:08:10Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "88a205ec8af63f744fdbee8b4e61cb718d3ec207",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +299,303 @@      val migrationEnabled = env.conf.get(STORAGE_DECOMMISSION_ENABLED) &&\n        (env.conf.get(STORAGE_DECOMMISSION_RDD_BLOCKS_ENABLED) ||\n          env.conf.get(STORAGE_DECOMMISSION_SHUFFLE_BLOCKS_ENABLED))\n      if (migrationEnabled) {\n        env.blockManager.decommissionBlockManager()"
  },
  {
    "id" : "b6fb681b-899d-40b4-a7df-b50a44264936",
    "prId" : 31102,
    "prUrl" : "https://github.com/apache/spark/pull/31102#pullrequestreview-569300026",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "59bc5f3c-1a9e-45d4-babb-1f109955b73e",
        "parentId" : null,
        "authorId" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "body" : "By removing the `STORAGE_DECOMMISSION_ENABLED` config this part would simply disappear. ",
        "createdAt" : "2021-01-15T14:21:58Z",
        "updatedAt" : "2021-03-23T02:08:10Z",
        "lastEditedBy" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "tags" : [
        ]
      }
    ],
    "commit" : "88a205ec8af63f744fdbee8b4e61cb718d3ec207",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +302,306 @@      if (migrationEnabled) {\n        env.blockManager.decommissionBlockManager()\n      } else if (env.conf.get(STORAGE_DECOMMISSION_ENABLED)) {\n        logError(s\"Storage decommissioning attempted but neither \" +\n          s\"${STORAGE_DECOMMISSION_SHUFFLE_BLOCKS_ENABLED.key} or \" +"
  }
]