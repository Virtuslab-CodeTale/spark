[
  {
    "id" : "24a24744-ee30-495f-8508-ad6916b22e4b",
    "prId" : 32283,
    "prUrl" : "https://github.com/apache/spark/pull/32283#pullrequestreview-708904197",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b3da9ce1-7005-4e69-9e1e-42d296ca0daf",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Can we check if we're in K8s here ?",
        "createdAt" : "2021-07-16T00:14:03Z",
        "updatedAt" : "2021-07-16T00:14:03Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "e58b3228-2845-45ef-b340-2b5e2ee9b6e8",
        "parentId" : "b3da9ce1-7005-4e69-9e1e-42d296ca0daf",
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "+1 to making it k8s specific ...\r\nIdeally, we should be using daemon threads for most of our background work ...",
        "createdAt" : "2021-07-16T01:38:38Z",
        "updatedAt" : "2021-07-16T01:38:38Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      },
      {
        "id" : "16d73a3a-5e1c-4a52-8973-0de2b37912cc",
        "parentId" : "b3da9ce1-7005-4e69-9e1e-42d296ca0daf",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "+1",
        "createdAt" : "2021-07-16T02:28:20Z",
        "updatedAt" : "2021-07-16T02:28:20Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "4813eff1-b620-4730-9023-b91a4288411b",
        "parentId" : "b3da9ce1-7005-4e69-9e1e-42d296ca0daf",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Since SPARK-34674 was released already via Apache Spark 3.1.2, I will make another JIRA for this, @HyukjinKwon , @mridulm , @Ngone51 .",
        "createdAt" : "2021-07-17T09:27:17Z",
        "updatedAt" : "2021-07-17T09:27:17Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "eb8cc3e3-8662-4d3c-8073-20f09764e08d",
        "parentId" : "b3da9ce1-7005-4e69-9e1e-42d296ca0daf",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Here is the PR.\r\n- https://github.com/apache/spark/pull/33403",
        "createdAt" : "2021-07-17T09:41:54Z",
        "updatedAt" : "2021-07-17T09:41:54Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "814e391a0f7df53c7a1ad96c895c80f5745e591e",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +954,958 @@        throw findCause(t)\n    } finally {\n      if (!isShell(args.primaryResource) && !isSqlShell(args.mainClass) &&\n        !isThriftServer(args.mainClass)) {\n        try {"
  },
  {
    "id" : "6e9361b9-0565-40b6-b8e6-387b3986c3d5",
    "prId" : 32081,
    "prUrl" : "https://github.com/apache/spark/pull/32081#pullrequestreview-707937935",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f63f82d2-ed13-4c8c-95e7-d3f232c28101",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Just reading this and https://github.com/apache/spark/pull/33154, shouldn't we enable this only w/ Kubernates (and also when it's not a Thirftserver, shall, etc.)?\r\n\r\nAlso, I think we might have to add some comments on that.",
        "createdAt" : "2021-07-04T02:18:43Z",
        "updatedAt" : "2021-07-04T02:18:44Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "b5c73a84-41f6-46d0-8caf-2b9a52ceb261",
        "parentId" : "f63f82d2-ed13-4c8c-95e7-d3f232c28101",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "cc @sunpe too FYI",
        "createdAt" : "2021-07-04T02:19:01Z",
        "updatedAt" : "2021-07-04T02:19:01Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "a1a02829-ec8d-4fd9-ac91-b56577ac5c2b",
        "parentId" : "f63f82d2-ed13-4c8c-95e7-d3f232c28101",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "@HyukjinKwon This PR was reverted once and resubmitted https://github.com/apache/spark/pull/32283 (in which Thirftserver and others are excluded).\r\n\r\nBut I agree with you that we should only do this for K8s. Otherwise, it looks like a behavior change to me.",
        "createdAt" : "2021-07-15T15:58:29Z",
        "updatedAt" : "2021-07-15T15:58:30Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "c20ec7a9-7f46-42ae-aacd-42e047bfc3bb",
        "parentId" : "f63f82d2-ed13-4c8c-95e7-d3f232c28101",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Shall we continue the discussion on the latest one, #32282 , please?",
        "createdAt" : "2021-07-15T16:32:37Z",
        "updatedAt" : "2021-07-15T16:32:37Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "754c83bd-7a46-49c9-b006-07d4a3b7ee91",
        "parentId" : "f63f82d2-ed13-4c8c-95e7-d3f232c28101",
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "@dongjoon-hyun that pr looks unrelated, right ? Not sure if I am missing something.",
        "createdAt" : "2021-07-15T17:29:58Z",
        "updatedAt" : "2021-07-15T17:29:59Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      },
      {
        "id" : "4daa389d-27de-4259-8148-5cae8430cda4",
        "parentId" : "f63f82d2-ed13-4c8c-95e7-d3f232c28101",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Oops. It's a typo of #32283 . I tried to mention the one from @Ngone51 's comment. ",
        "createdAt" : "2021-07-15T21:57:31Z",
        "updatedAt" : "2021-07-15T21:57:31Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "9bdf1481-d28a-4bb4-9cf3-fe8a07425d84",
        "parentId" : "f63f82d2-ed13-4c8c-95e7-d3f232c28101",
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "Thanks @dongjoon-hyun ! Was not sure if there was another pr also I should be looking at :-)",
        "createdAt" : "2021-07-16T01:36:04Z",
        "updatedAt" : "2021-07-16T01:36:04Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      }
    ],
    "commit" : "e3946b459533dbeb92d873d3587cf6af7ca8ad34",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +955,959 @@    } finally {\n      try {\n        SparkContext.getActive.foreach(_.stop())\n      } catch {\n        case e: Throwable => logError(s\"Failed to close SparkContext: $e\")"
  },
  {
    "id" : "45dc4e2b-cbaf-4024-8e1f-4e7788856094",
    "prId" : 32080,
    "prUrl" : "https://github.com/apache/spark/pull/32080#pullrequestreview-630350153",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3d568b0d-55c4-4759-8016-638a61b5559e",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Please remove the extra space at the end of this line.\r\n```\r\n[error] /home/runner/work/spark/spark/core/src/main/scala/org/apache/spark/deploy/SparkSubmit.scala:1034:30: Whitespace at end of line\r\n```",
        "createdAt" : "2021-04-07T18:13:57Z",
        "updatedAt" : "2021-04-07T18:13:58Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "cdb346533e2314e781d1a145f3635d16d3cc9fe0",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +1032,1036 @@          case e: SparkUserAppException =>\n            exitFn(e.exitCode)\n          case _: Throwable => \n            exitFn(1)\n        }"
  },
  {
    "id" : "b5989623-7a80-454f-90de-213dd4023c69",
    "prId" : 32080,
    "prUrl" : "https://github.com/apache/spark/pull/32080#pullrequestreview-630971609",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2f8b9653-b510-4b47-87a2-e003088087b3",
        "parentId" : null,
        "authorId" : "c89ce77d-ed7a-49e7-811e-5be0290f30a1",
        "body" : "This changes will not fix [the problem](https://issues.apache.org/jira/browse/SPARK-34674) completely.\r\nIf the main() method completes successfully,  the application will still hang in K8S.\r\nCould you consider also call to exitFn in case of successfull?",
        "createdAt" : "2021-04-07T21:44:18Z",
        "updatedAt" : "2021-04-07T21:44:20Z",
        "lastEditedBy" : "c89ce77d-ed7a-49e7-811e-5be0290f30a1",
        "tags" : [
        ]
      },
      {
        "id" : "5242f081-ca3d-4216-8e68-8a9dfccfb9c1",
        "parentId" : "2f8b9653-b510-4b47-87a2-e003088087b3",
        "authorId" : "211509dc-9936-40ab-b814-4a246e4e060e",
        "body" : "Yes, you are right.",
        "createdAt" : "2021-04-08T04:41:26Z",
        "updatedAt" : "2021-04-08T04:41:26Z",
        "lastEditedBy" : "211509dc-9936-40ab-b814-4a246e4e060e",
        "tags" : [
        ]
      }
    ],
    "commit" : "cdb346533e2314e781d1a145f3635d16d3cc9fe0",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1033,1037 @@            exitFn(e.exitCode)\n          case _: Throwable => \n            exitFn(1)\n        }\n      }"
  },
  {
    "id" : "e930a783-8bba-4ee6-b813-a69849f40396",
    "prId" : 31849,
    "prUrl" : "https://github.com/apache/spark/pull/31849#pullrequestreview-615018375",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e10bcd75-e7c5-464b-a2a7-c3d837ceb54e",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "While I agree with the intention (I faced the same problem and had to manually remove cache too), I concern that it will actually make users more confused in a way because it's Maven or Ivy's standard behaviour, and now we're changing how they work by default in Spark, which probably users wouldn't know.\r\n\r\nI know it's very unlikely but some users might want to use one cached snapshot (presumably as they know the behaviours of Maven or Ivy resolvers work). Let's say, one CI regularly publishes snapshot, and users want to test one specific version created at the specific time. After this PR, they are forced to use the newest snapshot always.\r\n",
        "createdAt" : "2021-03-18T04:47:39Z",
        "updatedAt" : "2021-03-18T04:48:12Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "c522647b-284b-43fc-b57e-ef36e0c1540b",
        "parentId" : "e10bcd75-e7c5-464b-a2a7-c3d837ceb54e",
        "authorId" : "6e99a03b-1d60-4065-9e56-3151748ea94e",
        "body" : "The major reason for this change is to reduce frictions for developers, especially new ones, to contribute to Spark external modules. \r\n\r\nI think the behavior proposed here matches the standard ones in Ivy. See \"use a naming convention like a special suffix\" in https://ant.apache.org/ivy/history/latest-milestone/bestpractices.html, and the implementation in ivy's `IBiblioResolver`: https://github.com/apache/ant-ivy/blob/master/src/java/org/apache/ivy/plugins/resolver/IBiblioResolver.java#L88-L92\r\n",
        "createdAt" : "2021-03-18T06:27:00Z",
        "updatedAt" : "2021-03-18T06:27:00Z",
        "lastEditedBy" : "6e99a03b-1d60-4065-9e56-3151748ea94e",
        "tags" : [
        ]
      },
      {
        "id" : "c5f71b0e-1e9f-4e7a-90a1-23da176af5e2",
        "parentId" : "e10bcd75-e7c5-464b-a2a7-c3d837ceb54e",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Thanks @bozhang2820 for correcting me. Yeah, I think it makes sense.",
        "createdAt" : "2021-03-18T06:30:52Z",
        "updatedAt" : "2021-03-18T06:30:52Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "2e8d869e28adfbdc5d54517199005dc21e0d9b9e",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +1155,1159 @@    cr.setName(\"spark-list\")\n    cr.setChangingMatcher(PatternMatcher.REGEXP)\n    cr.setChangingPattern(\".*-SNAPSHOT\")\n\n    val localM2 = new IBiblioResolver"
  },
  {
    "id" : "b774765b-554b-44f6-9534-452e2b272cac",
    "prId" : 30922,
    "prUrl" : "https://github.com/apache/spark/pull/30922#pullrequestreview-561198665",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c4f5970f-1f3a-4134-9c78-d6e352778bc8",
        "parentId" : null,
        "authorId" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "body" : "@AngersZhuuuu  FYI you missed updating the `@return` Scaladoc tag here, as well as the description which explicitly mentions a comma-delimited list. Would you mind submitting a follow-on to update?",
        "createdAt" : "2021-01-04T17:17:29Z",
        "updatedAt" : "2021-01-04T17:18:03Z",
        "lastEditedBy" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "tags" : [
        ]
      }
    ],
    "commit" : "4d8849644ae25ce94e5afbcc9b7270fe909ae869",
    "line" : 33,
    "diffHunk" : "@@ -1,1 +1200,1204 @@   * @param cacheDirectory directory where jars are cached\n   * @return a comma-delimited list of paths for the dependencies\n   */\n  def resolveDependencyPaths(\n      artifacts: Array[AnyRef],"
  },
  {
    "id" : "3ea786c4-976a-4fa8-a830-527b46afecf1",
    "prId" : 30895,
    "prUrl" : "https://github.com/apache/spark/pull/30895#pullrequestreview-557431356",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bba87a32-7ef9-4003-8d0e-2f043adfdd40",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "nit. Just a question. Why this is different from the original patch?\r\n\r\nThe original patch didn't change the order of lines here. So, `pyFiles` should be at the first instead of `jars`.",
        "createdAt" : "2020-12-22T23:18:18Z",
        "updatedAt" : "2020-12-22T23:49:41Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "67f09daa-c09c-4503-aa0c-ef5d97e04dfb",
        "parentId" : "bba87a32-7ef9-4003-8d0e-2f043adfdd40",
        "authorId" : "714bd96c-2aea-4b32-9fc8-de23712eb87d",
        "body" : "Oops, this got it while resolving a conflict with cherry-pick (`spark.executor.instances` was removed in branch-3). I've put it back in order (although I believe it should not affect anything).",
        "createdAt" : "2020-12-22T23:51:09Z",
        "updatedAt" : "2020-12-22T23:51:09Z",
        "lastEditedBy" : "714bd96c-2aea-4b32-9fc8-de23712eb87d",
        "tags" : [
        ]
      },
      {
        "id" : "c3802f22-989a-4116-9079-d3f6f8df064d",
        "parentId" : "bba87a32-7ef9-4003-8d0e-2f043adfdd40",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Thanks!",
        "createdAt" : "2020-12-22T23:53:13Z",
        "updatedAt" : "2020-12-22T23:53:13Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "d621d0dcae6b7153399f9232f44f62b3d99414ee",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +526,530 @@        mergeFn = Some(mergeFileLists(_, _))),\n      OptionAssigner(args.jars, YARN, ALL_DEPLOY_MODES, confKey = \"spark.yarn.dist.jars\",\n        mergeFn = Some(mergeFileLists(_, _))),\n      OptionAssigner(args.files, YARN, ALL_DEPLOY_MODES, confKey = \"spark.yarn.dist.files\",\n        mergeFn = Some(mergeFileLists(_, _))),"
  },
  {
    "id" : "93cd11f8-bc4d-45b7-a85e-bd9ae4ba4c27",
    "prId" : 30735,
    "prUrl" : "https://github.com/apache/spark/pull/30735#pullrequestreview-551848329",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8bd2884b-4eab-44f2-8b51-4d51dfd6f190",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "`spark.files` looks having the same issue too. However, I would like to avoid dealing all together in this PR.",
        "createdAt" : "2020-12-11T13:09:56Z",
        "updatedAt" : "2020-12-13T02:04:32Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "6df88715-519d-4aa9-a723-42766b4db463",
        "parentId" : "8bd2884b-4eab-44f2-8b51-4d51dfd6f190",
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "did you file a separate lira then?",
        "createdAt" : "2020-12-14T14:42:40Z",
        "updatedAt" : "2020-12-14T14:42:40Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      },
      {
        "id" : "5c73cebe-9969-45ec-9b99-64e5994d1221",
        "parentId" : "8bd2884b-4eab-44f2-8b51-4d51dfd6f190",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Sure, will file a JIRA.",
        "createdAt" : "2020-12-14T19:10:06Z",
        "updatedAt" : "2020-12-14T19:10:06Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "2aaf9a86-2381-450f-9081-8ea42dfc4d56",
        "parentId" : "8bd2884b-4eab-44f2-8b51-4d51dfd6f190",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "SPARK-33782",
        "createdAt" : "2020-12-14T20:02:21Z",
        "updatedAt" : "2020-12-14T20:02:21Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "5f13c30a1d6a9df0b48f161d2d5d28b75c149bf4",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +400,404 @@          // SPARK-33748: this mimics the behaviour of Yarn cluster mode. If the driver is running\n          // in cluster mode, the archives should be available in the driver's current working\n          // directory too.\n          Utils.stringToSeq(localArchives).map(Utils.resolveURI).zip(resolvedUris).map {\n            case (localArchive, resolvedUri) =>"
  }
]