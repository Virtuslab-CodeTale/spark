[
  {
    "id" : "88b21bd0-1f68-474c-93f7-d8b823674e58",
    "prId" : 25002,
    "prUrl" : "https://github.com/apache/spark/pull/25002#pullrequestreview-257266221",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8b32311c-1c9d-401e-944d-02716fff14ea",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "I'm wondering if this doesn't break anything. Did you run the UT locally?",
        "createdAt" : "2019-07-03T04:01:16Z",
        "updatedAt" : "2019-07-24T05:07:16Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "9a4a5bd1-c326-4656-9c6d-1b7675620ed5",
        "parentId" : "8b32311c-1c9d-401e-944d-02716fff14ea",
        "authorId" : "8e87861a-4202-49a2-baf7-6d51f6aaa5a2",
        "body" : "Internally this is only called in PythonRDD and I have replaced all the invocations with merged SparkContext's hadoop conf. So it shouldn't break things in spark side. I ran the UTs of Scala side, haven't run python unit tests though.",
        "createdAt" : "2019-07-03T05:28:43Z",
        "updatedAt" : "2019-07-24T05:07:16Z",
        "lastEditedBy" : "8e87861a-4202-49a2-baf7-6d51f6aaa5a2",
        "tags" : [
        ]
      }
    ],
    "commit" : "612dadbf25a3f273a38bc68f7bc35832dc0a6744",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +157,161 @@   */\n  def mapToConf(map: java.util.Map[String, String]): Configuration = {\n    val conf = new Configuration(false)\n    map.asScala.foreach { case (k, v) => conf.set(k, v) }\n    conf"
  }
]