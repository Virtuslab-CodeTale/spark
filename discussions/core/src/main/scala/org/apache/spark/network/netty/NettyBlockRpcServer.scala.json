[
  {
    "id" : "9df0769d-8a14-4fea-b80a-f6cfbf185e0e",
    "prId" : 27539,
    "prUrl" : "https://github.com/apache/spark/pull/27539#pullrequestreview-359618898",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ae8bf767-db3c-4b31-970c-19472c99019d",
        "parentId" : null,
        "authorId" : "f3166ab8-4dba-4d22-b10b-31a984dfa2ad",
        "body" : "Instead of a new exception,\r\nCan we use the exception object thrown at https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/storage/BlockManager.scala#L1315?\r\n",
        "createdAt" : "2020-02-12T05:31:30Z",
        "updatedAt" : "2020-02-18T05:34:04Z",
        "lastEditedBy" : "f3166ab8-4dba-4d22-b10b-31a984dfa2ad",
        "tags" : [
        ]
      },
      {
        "id" : "904ba4f5-b8a9-463a-b60f-ae03b0f41635",
        "parentId" : "ae8bf767-db3c-4b31-970c-19472c99019d",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "what specific exception class do you mean?",
        "createdAt" : "2020-02-12T10:49:46Z",
        "updatedAt" : "2020-02-18T05:34:04Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "36ea763f-1cf9-4b0f-8588-d3ed3125c939",
        "parentId" : "ae8bf767-db3c-4b31-970c-19472c99019d",
        "authorId" : "ad4cb313-47b2-4cfa-9c1f-0a3596794a67",
        "body" : "I think @karuppayya is trying to say that we can throw specific exceptions from the \"blockManager.putBlockData()\" in order to pass exact failure message from server to client.\r\n\r\nThe \"putBlockData\" method of \"BlockDataManager\" interface has a boolean return type. So it can still return false in case it is not able to store a block. If this line throws exception, the same exception message will be passed to client as RPC failure - No change in that behavior.\r\n\r\nThis PR handles the scenario where it returns false. In that case also we should send RPC failure to client.",
        "createdAt" : "2020-02-17T10:09:07Z",
        "updatedAt" : "2020-02-18T05:34:04Z",
        "lastEditedBy" : "ad4cb313-47b2-4cfa-9c1f-0a3596794a67",
        "tags" : [
        ]
      }
    ],
    "commit" : "91e3a360f061546ef172a994b60a736baa1ea7d9",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +110,114 @@          responseContext.onSuccess(ByteBuffer.allocate(0))\n        } else {\n          val exception = new Exception(s\"Upload block for $blockId failed. This mostly happens \" +\n            s\"when there is not sufficient space available to store the block.\")\n          responseContext.onFailure(exception)"
  },
  {
    "id" : "e61d3773-7556-44fb-849a-110cef15d426",
    "prId" : 24740,
    "prUrl" : "https://github.com/apache/spark/pull/24740#pullrequestreview-267554793",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "774dd578-ea30-4def-942c-ab8bd5331261",
        "parentId" : null,
        "authorId" : "1a7af33a-9000-4d4e-9729-ac32a9505710",
        "body" : "Redundant for `shuffleFetchSplit`?",
        "createdAt" : "2019-07-29T03:29:39Z",
        "updatedAt" : "2019-07-29T03:48:59Z",
        "lastEditedBy" : "1a7af33a-9000-4d4e-9729-ac32a9505710",
        "tags" : [
        ]
      }
    ],
    "commit" : "2edfc958e9374e22bdc88f5785eed105d96d4da4",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +67,71 @@        val shuffleFetchSplit = fetchShuffleBlocks.shuffleFetchSplit;\n        val blocks = fetchShuffleBlocks.mapIds.zipWithIndex.flatMap { case (mapId, index) =>\n          if (shuffleFetchSplit) {\n            fetchShuffleBlocks.reduceIds.apply(index).zip(fetchShuffleBlocks.segments.apply(index))\n              .flatMap { kv =>"
  }
]