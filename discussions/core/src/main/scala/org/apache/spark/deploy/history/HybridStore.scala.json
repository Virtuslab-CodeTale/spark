[
  {
    "id" : "eb4190d0-4d55-46e6-afc4-ddf5b97e9e4f",
    "prId" : 29149,
    "prUrl" : "https://github.com/apache/spark/pull/29149#pullrequestreview-451020781",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "350b1f25-6050-44df-a0d4-b5227d1a64dc",
        "parentId" : null,
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "This would be OK, given all entries are from inMemoryStore which are already materialized into memory.",
        "createdAt" : "2020-07-18T01:36:42Z",
        "updatedAt" : "2020-07-19T02:53:22Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      }
    ],
    "commit" : "a12e1783aa238d2c08ebdf34708c1539017b477d",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +147,151 @@      try {\n        for (klass <- klassMap.keys().asScala) {\n          val values = Lists.newArrayList(\n              inMemoryStore.view(klass).closeableIterator())\n          levelDB.writeAll(values)"
  }
]