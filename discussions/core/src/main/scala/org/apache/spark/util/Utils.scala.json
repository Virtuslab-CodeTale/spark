[
  {
    "id" : "ffee5878-e639-4f46-afd6-4d90b3749111",
    "prId" : 33101,
    "prUrl" : "https://github.com/apache/spark/pull/33101#pullrequestreview-698556736",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "23b0443e-ea25-4403-92e0-e299132b5ce4",
        "parentId" : null,
        "authorId" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "body" : "@Ngone51 I understand you requested this check to be brought back in your [previous comment](https://github.com/apache/spark/pull/33101#discussion_r661245031), but it doesn't seem right to me. Based on the [Javadoc for createDirectories](https://docs.oracle.com/javase/7/docs/api/java/nio/file/Files.html#createDirectories(java.nio.file.Path,%20java.nio.file.attribute.FileAttribute...)), the contract is that the directory will be created successfully, or an exception will be thrown. Keeping the `exists`/`isDirectory` checks after is redundant. If we're worried about a JDK bug as [described here](https://github.com/apache/spark/pull/33101#discussion_r661579528), why do we trust the implementation of `File#exists()` and `File#isDirectory()` but not `Files.createDirectories()`? IMO the whole point of switching from `File` to the NIO APIs is that they have more sensible semantics and so we don't need to jump through hoops like this.",
        "createdAt" : "2021-06-30T15:29:36Z",
        "updatedAt" : "2021-06-30T15:29:44Z",
        "lastEditedBy" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "tags" : [
        ]
      },
      {
        "id" : "837a986b-96f4-422f-8cb0-5bfd98fc6666",
        "parentId" : "23b0443e-ea25-4403-92e0-e299132b5ce4",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : ">  Based on the Javadoc for createDirectories, the contract is that the directory will be created successfully, or an exception will be thrown.\r\n\r\nI didn't find such a contract there, but only \" Unlike the createDirectory method, an exception is not thrown if the directory could not be created because it already exists.\"...\r\n\r\n> If we're worried about a JDK bug as described here, why do we trust the implementation of File#exists() and File#isDirectory() but not Files.createDirectories()?\r\n\r\nIt's not about which method we should trust but which way is safer to go.  If there's such a contract as you mentioned, I agree we don't need the check. Otherwise, I think it's safer to follow the original way to avoid suffering from the old issue.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
        "createdAt" : "2021-07-01T02:20:04Z",
        "updatedAt" : "2021-07-01T02:20:04Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "e468efd7-aafc-4fa1-9981-ccc2f9ace29f",
        "parentId" : "23b0443e-ea25-4403-92e0-e299132b5ce4",
        "authorId" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "body" : "The word \"contract\" is not used, but I think that is rarely the case in method descriptions. For example none of the methods on `Dataset` explicitly state contracts or guarantees, but we are expected to assume that the method will do what it says it does, and indicate an error condition using an exception otherwise. My impression here is that the weird semantics of `File#mkdirs()` are translating into FUD about the potential shortcomings of `Files.createDirectories()` and that, if the method were taken without that historical context, we wouldn't be worrying about it.\r\n\r\nThis all being said, it's only three lines of code extra, so of course it is no big detriment to be on the safe side.",
        "createdAt" : "2021-07-01T16:55:38Z",
        "updatedAt" : "2021-07-01T16:55:38Z",
        "lastEditedBy" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "tags" : [
        ]
      },
      {
        "id" : "d9a57dd6-2e04-425e-9928-72524240a243",
        "parentId" : "23b0443e-ea25-4403-92e0-e299132b5ce4",
        "authorId" : "afcafcea-ead3-4649-a4d8-74eb9dfd1a22",
        "body" : "> The word \"contract\" is not used, but I think that is rarely the case in method descriptions. For example none of the methods on `Dataset` explicitly state contracts or guarantees, but we are expected to assume that the method will do what it says it does, and indicate an error condition using an exception otherwise. My impression here is that the weird semantics of `File#mkdirs()` are translating into FUD about the potential shortcomings of `Files.createDirectories()` and that, if the method were taken without that historical context, we wouldn't be worrying about it.\r\n> \r\n> This all being said, it's only three lines of code extra, so of course it is no big detriment to be on the safe side.\r\n\r\nI agree with you in terms of safety and minimizing modification points.Do you have any questions with my current code?",
        "createdAt" : "2021-07-02T03:12:13Z",
        "updatedAt" : "2021-07-02T03:12:13Z",
        "lastEditedBy" : "afcafcea-ead3-4649-a4d8-74eb9dfd1a22",
        "tags" : [
        ]
      },
      {
        "id" : "440e139b-495d-4e93-91d2-8b20fa81582a",
        "parentId" : "23b0443e-ea25-4403-92e0-e299132b5ce4",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "@Shockang Could you leave a comment above the check to give the historical context, e.g.,\r\n\r\n\"The check was required by File#mkdirs() because it could sporadically fail silently. After switching to  Files.createDirectories(), ideally, there should no longer be silent fails. But the check is kept for the safety concern. We can remove the check when we're sure that Files.createDirectories() would never fail silently.\" ",
        "createdAt" : "2021-07-02T07:51:50Z",
        "updatedAt" : "2021-07-02T07:51:50Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "d4afb5de-68f2-4685-be6e-0813726d2296",
        "parentId" : "23b0443e-ea25-4403-92e0-e299132b5ce4",
        "authorId" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "body" : "> Do you have any questions with my current code?\r\n\r\nNo, just wanted to explain my viewpoint. Current code is fine. I agree with @Ngone51 that a comment is helpful to explain the context.",
        "createdAt" : "2021-07-02T16:36:48Z",
        "updatedAt" : "2021-07-02T16:36:48Z",
        "lastEditedBy" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "tags" : [
        ]
      },
      {
        "id" : "932de0fe-9f1e-4dd2-99cb-ba830683d6c9",
        "parentId" : "23b0443e-ea25-4403-92e0-e299132b5ce4",
        "authorId" : "afcafcea-ead3-4649-a4d8-74eb9dfd1a22",
        "body" : "> @Shockang Could you leave a comment above the check to give the historical context, e.g.,\r\n> \r\n> \"The check was required by File#mkdirs() because it could sporadically fail silently. After switching to Files.createDirectories(), ideally, there should no longer be silent fails. But the check is kept for the safety concern. We can remove the check when we're sure that Files.createDirectories() would never fail silently.\"\r\n\r\nThis comment looks perfect. Thank you very much for your comments.",
        "createdAt" : "2021-07-03T02:06:08Z",
        "updatedAt" : "2021-07-03T02:06:08Z",
        "lastEditedBy" : "afcafcea-ead3-4649-a4d8-74eb9dfd1a22",
        "tags" : [
        ]
      }
    ],
    "commit" : "6d123ba1258250e681a6f812303299f5fb67d90c",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +293,297 @@      if ( !dir.exists() || !dir.isDirectory) {\n        logError(s\"Failed to create directory \" + dir)\n      }\n      dir.isDirectory\n    } catch {"
  },
  {
    "id" : "9fef151e-3089-4342-b928-fe1daf042e68",
    "prId" : 33084,
    "prUrl" : "https://github.com/apache/spark/pull/33084#pullrequestreview-692857925",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "39cf041f-4d75-4270-9a57-64aef1e42e9a",
        "parentId" : null,
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "Yeah, mutable.Seq to scala.Seq now requires explicit conversion as it refers to immutable.Seq. Looks like it's by intention of Scala 2.13 change.",
        "createdAt" : "2021-06-25T13:41:09Z",
        "updatedAt" : "2021-06-25T13:41:09Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      },
      {
        "id" : "f2cf34c7-7248-4ccb-8608-9fd907051bb2",
        "parentId" : "39cf041f-4d75-4270-9a57-64aef1e42e9a",
        "authorId" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "body" : "Yup, the Scala 2.13 build passed in the latest commit.",
        "createdAt" : "2021-06-25T14:06:13Z",
        "updatedAt" : "2021-06-25T14:06:13Z",
        "lastEditedBy" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "tags" : [
        ]
      },
      {
        "id" : "9b3c83a6-c49a-4764-9e82-7cb03f0ca89e",
        "parentId" : "39cf041f-4d75-4270-9a57-64aef1e42e9a",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Yes, I confirmed that the last commit passed Scala 2.13 build.",
        "createdAt" : "2021-06-25T14:07:15Z",
        "updatedAt" : "2021-06-25T14:07:16Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "25c1583da4b91a8285b53cfa04984cadc1a2ce14",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +3153,3157 @@      IOUtils.closeQuietly(out)\n    }\n    files.toSeq\n  }\n}"
  },
  {
    "id" : "62ddaa4e-0757-4593-82c6-35d5daf7e3e4",
    "prId" : 32767,
    "prUrl" : "https://github.com/apache/spark/pull/32767#pullrequestreview-690418782",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7f99eb5f-2c3c-4972-bcb6-f66d4099cafa",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "We don't process directory. Could you also mention it in the method doc?",
        "createdAt" : "2021-06-22T06:35:45Z",
        "updatedAt" : "2021-06-22T06:51:07Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "25e92c50-bead-4234-8b67-cdbb43292db7",
        "parentId" : "7f99eb5f-2c3c-4972-bcb6-f66d4099cafa",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "It'd be ideal if we make it clear in method name, like `unzipFilesFromFile`.  (Ideally I'd like to see this also extracts the directory, but let's postpone it till necessary.)\r\n\r\nIn general we expect unzipping will extract the directories as well. That said, we need to make the behavior very clear to the caller side. I agree this should be mentioned to the java doc, but method name should be also intuitive to expect the actual behavior.",
        "createdAt" : "2021-06-22T07:14:15Z",
        "updatedAt" : "2021-06-22T07:44:26Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      },
      {
        "id" : "c40ff0ad-f0b8-4360-bb29-025419fe795f",
        "parentId" : "7f99eb5f-2c3c-4972-bcb6-f66d4099cafa",
        "authorId" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "body" : "Make sense, method name changed and comment added.",
        "createdAt" : "2021-06-23T09:26:12Z",
        "updatedAt" : "2021-06-23T09:26:13Z",
        "lastEditedBy" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "tags" : [
        ]
      }
    ],
    "commit" : "7279d434ddba27a93924577458f8dedf6bf340c5",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +3135,3139 @@      var entry = in.getNextEntry()\n      while (entry != null) {\n        if (!entry.isDirectory) {\n          val fileName = localDir.toPath.resolve(entry.getName).getFileName.toString\n          val outFile = new File(localDir, fileName)"
  },
  {
    "id" : "36808955-30be-44ce-87a5-32a194bf049b",
    "prId" : 32767,
    "prUrl" : "https://github.com/apache/spark/pull/32767#pullrequestreview-690420282",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cc3620e6-08ad-46d1-a5a8-aada669ae3dc",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Hmm, are we sure we don't need to process any error during unzipping?",
        "createdAt" : "2021-06-22T06:36:36Z",
        "updatedAt" : "2021-06-22T06:51:07Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "28c55468-f1e1-4544-8901-fe1024399410",
        "parentId" : "cc3620e6-08ad-46d1-a5a8-aada669ae3dc",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "This looks safe; if there's an exception we may see some files being extracted and the one of output files may be broken, but callers will catch an exception and indicate the output directory is not healthy. If necessary let's document this in javadoc as well.",
        "createdAt" : "2021-06-22T07:23:51Z",
        "updatedAt" : "2021-06-22T07:44:26Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      },
      {
        "id" : "b5995ee6-141b-4060-af8f-64560f67703f",
        "parentId" : "cc3620e6-08ad-46d1-a5a8-aada669ae3dc",
        "authorId" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "body" : "Yes, we rely on the caller side to address any exceptions. Javadoc added as well.",
        "createdAt" : "2021-06-23T09:27:39Z",
        "updatedAt" : "2021-06-23T09:27:39Z",
        "lastEditedBy" : "cd38bd5a-0fae-4d8e-8acd-36dc13753759",
        "tags" : [
        ]
      }
    ],
    "commit" : "7279d434ddba27a93924577458f8dedf6bf340c5",
    "line" : 55,
    "diffHunk" : "@@ -1,1 +3152,3156 @@      IOUtils.closeQuietly(in)\n      IOUtils.closeQuietly(out)\n    }\n    files\n  }"
  },
  {
    "id" : "c57cd14d-8add-4d3f-a6fd-8e7c6b590034",
    "prId" : 31244,
    "prUrl" : "https://github.com/apache/spark/pull/31244#pullrequestreview-571119868",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "896807f0-bae4-4e10-99cf-3d74a864f727",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "I understand that this change tried to be conservative to avoid any breakage but `isTesting` isn't an API (it's `private[spark] object Utils` so it's fine to directly change `def isTesting` to `lazy val isTesting`",
        "createdAt" : "2021-01-19T10:35:24Z",
        "updatedAt" : "2021-01-19T11:00:42Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "d78d5578-67f3-461b-b8e1-af24a44043f5",
        "parentId" : "896807f0-bae4-4e10-99cf-3d74a864f727",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "`spark.testing` configuration is a static configuration that doesn't allow runtime modification. So theoretically it's fine to cache in general.",
        "createdAt" : "2021-01-19T10:37:26Z",
        "updatedAt" : "2021-01-19T11:00:42Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "4fb8c725-d2ae-4416-b4ba-8a01eaa5c572",
        "parentId" : "896807f0-bae4-4e10-99cf-3d74a864f727",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Or can we use `System.getenv()` instead directly?",
        "createdAt" : "2021-01-19T10:45:28Z",
        "updatedAt" : "2021-01-19T11:00:42Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "06e48e90-1e90-4b5a-9b2d-4b97adbeac87",
        "parentId" : "896807f0-bae4-4e10-99cf-3d74a864f727",
        "authorId" : "b0528688-02f1-4aa6-96e7-bea60c0c919c",
        "body" : "There are a testcases which set the property IS_TESTING (e.g. SparkFunSuite), I do not wanted to break them.\r\n\r\n",
        "createdAt" : "2021-01-19T10:47:01Z",
        "updatedAt" : "2021-01-19T11:00:42Z",
        "lastEditedBy" : "b0528688-02f1-4aa6-96e7-bea60c0c919c",
        "tags" : [
        ]
      }
    ],
    "commit" : "b52e42769220fc8f4c0af2ae035472e039f2601c",
    "line" : 3,
    "diffHunk" : "@@ -1,1 +1939,1943 @@   * Indicates whether Spark is currently running unit tests.\n   */\n  def isTesting: Boolean = {\n    // Scala's `sys.env` creates a ton of garbage by constructing Scala immutable maps, so\n    // we directly use the Java APIs instead."
  },
  {
    "id" : "783dfd69-51cd-4ed5-95f9-8656e09b36c8",
    "prId" : 30486,
    "prUrl" : "https://github.com/apache/spark/pull/30486#pullrequestreview-537551339",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "69f0c55f-7508-4b00-ad9b-8041b0e444a0",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Our `spark.files` and `SparkContext.addFile` have a sort of undocumented and hidden behaviour. Only in executor side, it untars if the files are `.tar.gz` or `tgz`. I think it makes sense to deprecate this behaviour and encourage users to use explicit archive handling.\r\n\r\nAlso, I believe it's a good practice to avoid relying on external programs anyway.",
        "createdAt" : "2020-11-24T14:33:57Z",
        "updatedAt" : "2020-11-30T05:09:49Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "e35e94cad2888c98e03feb391a8dfcca8afa365c",
    "line" : 48,
    "diffHunk" : "@@ -1,1 +550,554 @@            \"instead.\")\n        logInfo(\"Untarring \" + fileName)\n        executeAndGetOutput(Seq(\"tar\", \"-xzf\", fileName), targetDir)\n      } else if (fileName.endsWith(\".tar\")) {\n        logWarning("
  },
  {
    "id" : "14188630-4768-4797-a3ae-8b0f5dd540fa",
    "prId" : 30486,
    "prUrl" : "https://github.com/apache/spark/pull/30486#pullrequestreview-538096850",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "287211d6-8e92-4e79-8bfa-a194344ce186",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "In L487, could you document what the new param `shouldUntar` is?",
        "createdAt" : "2020-11-25T02:22:02Z",
        "updatedAt" : "2020-11-30T05:09:49Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "e35e94cad2888c98e03feb391a8dfcca8afa365c",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +501,505 @@      timestamp: Long,\n      useCache: Boolean,\n      shouldUntar: Boolean = true): File = {\n    val fileName = decodeFileNameInURI(new URI(url))\n    val targetFile = new File(targetDir, fileName)"
  },
  {
    "id" : "9e2d5478-78af-492f-86c0-366e709a1ec9",
    "prId" : 30337,
    "prUrl" : "https://github.com/apache/spark/pull/30337#pullrequestreview-530807400",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0de00521-8d95-4777-801f-ccbff780ed91",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Will this work in the case of an FTP URI?\r\nMaybe needs some pattern matching to only set this if this is an HttpURLConnection and user info is not null.",
        "createdAt" : "2020-11-15T15:10:31Z",
        "updatedAt" : "2020-11-15T15:10:45Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      }
    ],
    "commit" : "26e7b085625983917caf0d0b566fe63ef91b5535",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +745,749 @@      case \"http\" | \"https\" | \"ftp\" =>\n        val url_object = new URL(url)\n        val uc = url_object.openConnection().asInstanceOf[HttpURLConnection]\n        uc.setDoInput(true)\n        uc.setRequestMethod(\"GET\")"
  },
  {
    "id" : "9f66cfbb-2421-492e-87e4-bd2cf3eeeec8",
    "prId" : 30337,
    "prUrl" : "https://github.com/apache/spark/pull/30337#pullrequestreview-530807400",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "419f7130-352e-4657-a6ad-8807d0b30e79",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Is this actually needed?",
        "createdAt" : "2020-11-15T15:10:40Z",
        "updatedAt" : "2020-11-15T15:10:45Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      }
    ],
    "commit" : "26e7b085625983917caf0d0b566fe63ef91b5535",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +746,750 @@        val url_object = new URL(url)\n        val uc = url_object.openConnection().asInstanceOf[HttpURLConnection]\n        uc.setDoInput(true)\n        uc.setRequestMethod(\"GET\")\n        if (url_object.getUserInfo != null) {"
  },
  {
    "id" : "714f7964-441c-4b01-b430-6a866fdeafdd",
    "prId" : 29552,
    "prUrl" : "https://github.com/apache/spark/pull/29552#pullrequestreview-478159866",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4b10cfc8-51b3-4c1f-981f-ea5039d0bc15",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Thank you for adding the extended description.",
        "createdAt" : "2020-08-29T23:10:49Z",
        "updatedAt" : "2020-08-30T07:26:31Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "2dd78a4b2793356f2a66bec9f67e0b4aa80d3aa9",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +272,276 @@  /**\n   * Move data to trash if 'spark.sql.truncate.trash.enabled' is true, else\n   * delete the data permanently. If move data to trash failed fallback to hard deletion.\n   */\n  def moveToTrashOrDelete("
  }
]