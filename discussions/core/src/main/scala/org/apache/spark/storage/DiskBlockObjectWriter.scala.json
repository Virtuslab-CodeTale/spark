[
  {
    "id" : "c59bff0f-07ab-4ae4-a1ef-748ebce20498",
    "prId" : 33731,
    "prUrl" : "https://github.com/apache/spark/pull/33731#pullrequestreview-729186523",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3c4d3e18-e4b9-49e8-a8f2-374af19273a6",
        "parentId" : null,
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "Ideally, we should handle this in `closeResources` - but it is fine here as well, given this is not `close` but `manualClose` and we control the semantics of it :-)",
        "createdAt" : "2021-08-13T01:04:45Z",
        "updatedAt" : "2021-08-13T01:04:45Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      }
    ],
    "commit" : "49216a2262ddff76252fed56d094478b64305633",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +65,69 @@    }\n\n    def manualClose(): Unit = {\n      try {\n        super.close()"
  },
  {
    "id" : "b37887de-6996-4453-8ce1-105144d2cb4c",
    "prId" : 33267,
    "prUrl" : "https://github.com/apache/spark/pull/33267#pullrequestreview-708016503",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9bf2ee0a-f7bb-4a30-8a53-ddab856ac387",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Why not keep it as a member function of `DiskBlockObjectWriter` ?",
        "createdAt" : "2021-07-08T14:05:43Z",
        "updatedAt" : "2021-07-08T14:05:43Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "e9a11e52-7268-4857-9ee8-9b894a142091",
        "parentId" : "9bf2ee0a-f7bb-4a30-8a53-ddab856ac387",
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "@Ngone51 That's a good question, but I think it's a little strange for an `OutputStream( DiskBlockObjectWriter extends OutputStream)` to delete itself. \r\n\r\nFor example, `o.a.h.fs.FileSystem` can `create` a `FSDataOutputStream`,  although the `FSDataOutputStream` has the capabilities of `write data` and `close itself`, but we still need to use the `o.a.h.fs.FileSystem` to delete the file.\r\n\r\nOf course, The `java.io.File` API has the ability to delete itself, the `java.io.File` can `createNewFile` and the `File` instance can `delete` itself, but it still needs to be wrap as `FileOutputStream` to write data, and `FileOutputStream` cannot delete itself too.\r\n\r\nAt present, I choose the former because `DiskBlockObjectWriter` is an `OutputStream` rather than a `File` ,  but I also accept it as a member function of `DiskBlockObjectWriter`.\r\n\r\nDo you think `keep it as a member function of DiskBlockObjectWriter` is better?\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
        "createdAt" : "2021-07-09T02:34:55Z",
        "updatedAt" : "2021-07-09T02:47:04Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      },
      {
        "id" : "6d7f3fd8-e28e-418c-940f-cfafa2d9be68",
        "parentId" : "9bf2ee0a-f7bb-4a30-8a53-ddab856ac387",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Ok, I got your point. Make sense to me.\r\n\r\nBut, to be honest, I think the usage of the helper method `deleteAbnormalDiskBlockObjectFile` is less straightforward compares to the current one.\r\n\r\n",
        "createdAt" : "2021-07-15T15:22:49Z",
        "updatedAt" : "2021-07-15T15:22:50Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "3720cfa3-18db-4b4d-b88b-5fe4b0a0d223",
        "parentId" : "9bf2ee0a-f7bb-4a30-8a53-ddab856ac387",
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "Got it ~  I will close this pr",
        "createdAt" : "2021-07-16T05:23:28Z",
        "updatedAt" : "2021-07-16T05:23:28Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      }
    ],
    "commit" : "fc14fb8b3b9ae0d2a6aa8cdc89ac611f6e3f922d",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +296,300 @@   * DiskBlockObjectWriter.\n   */\n  def deleteAbnormalDiskBlockObjectFile(writer: DiskBlockObjectWriter): Unit = {\n    val file = writer.revertPartialWritesAndClose()\n    if (file.exists()) {"
  },
  {
    "id" : "900bac5f-4e8f-415e-a522-eaf994473c2c",
    "prId" : 32648,
    "prUrl" : "https://github.com/apache/spark/pull/32648#pullrequestreview-666441823",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d803c6e9-e37f-4803-8bd6-ebb66fadbe07",
        "parentId" : null,
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "```\r\n[ERROR] [Error] /spark/core/src/main/scala/org/apache/spark/storage/DiskBlockObjectWriter.scala:286: weaker access privileges in overriding\r\ndef flush(): Unit (defined in class OutputStream)\r\n  override should be public\r\n```",
        "createdAt" : "2021-05-24T06:46:08Z",
        "updatedAt" : "2021-05-24T06:47:32Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      }
    ],
    "commit" : "2a867a6277c1c6c4f1a6497973588304f907bede",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +284,288 @@\n  // For testing\n  override def flush(): Unit = {\n    objOut.flush()\n    bs.flush()"
  },
  {
    "id" : "2b0a7fa7-69be-457d-b414-76a528aeee94",
    "prId" : 32401,
    "prUrl" : "https://github.com/apache/spark/pull/32401#pullrequestreview-704722214",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b9f5eea3-f625-4fd4-b15b-9fc4306cdb48",
        "parentId" : null,
        "authorId" : "9953a478-bdd8-4f15-be59-f6f654ff85ae",
        "body" : "So `checksumOutputStream` is not null after DiskBlockObjectWriter is initialized. Is the intention here to change the checksum even after this initialization?",
        "createdAt" : "2021-07-12T20:51:18Z",
        "updatedAt" : "2021-07-12T20:51:18Z",
        "lastEditedBy" : "9953a478-bdd8-4f15-be59-f6f654ff85ae",
        "tags" : [
        ]
      },
      {
        "id" : "80175900-d276-40af-96c2-b6d4351bc8a1",
        "parentId" : "b9f5eea3-f625-4fd4-b15b-9fc4306cdb48",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Yes, it's intentional. In the case of `ShuffleExternalSorter` spill, one `DiskBlockObjectWriter` would serve multiple partitions and different partitions should use different checksums.",
        "createdAt" : "2021-07-13T03:57:36Z",
        "updatedAt" : "2021-07-13T03:57:36Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "4bdde58a3791691f275968b117eeff260ef3016f",
    "line" : 35,
    "diffHunk" : "@@ -1,1 +117,121 @@      this.checksum = checksum\n    } else {\n      checksumOutputStream.setChecksum(checksum)\n    }\n  }"
  },
  {
    "id" : "83b15405-e6c4-4833-9ba9-6018f983b946",
    "prId" : 25342,
    "prUrl" : "https://github.com/apache/spark/pull/25342#pullrequestreview-279882655",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "06795551-dfb7-4bc5-bdc8-df490f185764",
        "parentId" : null,
        "authorId" : "34f85564-3e6b-4cb5-99f3-d5e383ee52fa",
        "body" : ":nit add `override` to one function",
        "createdAt" : "2019-08-12T03:43:08Z",
        "updatedAt" : "2019-08-28T21:40:35Z",
        "lastEditedBy" : "34f85564-3e6b-4cb5-99f3-d5e383ee52fa",
        "tags" : [
        ]
      },
      {
        "id" : "cf947347-afe4-4419-bf5a-356bd138a69c",
        "parentId" : "06795551-dfb7-4bc5-bdc8-df490f185764",
        "authorId" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "body" : "Think this should be done now",
        "createdAt" : "2019-08-26T23:08:30Z",
        "updatedAt" : "2019-08-28T21:40:35Z",
        "lastEditedBy" : "806aa501-9ea7-4cec-b017-a84d9a1602d8",
        "tags" : [
        ]
      }
    ],
    "commit" : "d4831577120f73b6bfe20ca887659566abcabb31",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +49,53 @@  extends OutputStream\n  with Logging\n  with PairsWriter {\n\n  /**"
  }
]