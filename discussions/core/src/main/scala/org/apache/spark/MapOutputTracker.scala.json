[
  {
    "id" : "9c851137-56a5-41e5-8586-232ce2889b04",
    "prId" : 32730,
    "prUrl" : "https://github.com/apache/spark/pull/32730#pullrequestreview-675429736",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "69a331c5-e4d4-440c-907e-1585cc5a4b6d",
        "parentId" : null,
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "This has potential for interacting badly with correctness changes, right ?\r\nSee `DAGScheduler.submitMissingTasks` when stage is Indeterminate",
        "createdAt" : "2021-06-02T04:09:28Z",
        "updatedAt" : "2021-06-02T04:09:28Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      },
      {
        "id" : "ca8eb4e2-d9fe-4ec5-a4e4-7a7bfa3baad4",
        "parentId" : "69a331c5-e4d4-440c-907e-1585cc5a4b6d",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Thank you for review. In that case, `mapId` is not the same, isn't it? We are reusing with `mapId` at [line 170](https://github.com/apache/spark/pull/32730/files#diff-a3b15298f97577c1fadcc2d76d015eebd6343e246c6717417d33f3c458847f46R170), @mridulm .\r\n```\r\nval index = mapStatusesDeleted.indexWhere(x => x != null && x.mapId == mapId)\r\n```",
        "createdAt" : "2021-06-02T05:48:40Z",
        "updatedAt" : "2021-06-02T05:51:10Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "46bd8d36-2a0b-4421-b7f0-77d9dc7cf739",
        "parentId" : "69a331c5-e4d4-440c-907e-1585cc5a4b6d",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "BTW, I agree with you that we don't have a test coverage for the indeterministic stage case. Let me try to add some.",
        "createdAt" : "2021-06-02T05:50:37Z",
        "updatedAt" : "2021-06-02T05:51:40Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "7ef50fd7-cc24-4c22-b63e-f64fbbc2cd67",
        "parentId" : "69a331c5-e4d4-440c-907e-1585cc5a4b6d",
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "You are right, the check on mapId and mapIndex ensure correctness. Thanks for clarifying !",
        "createdAt" : "2021-06-03T15:39:10Z",
        "updatedAt" : "2021-06-03T15:39:10Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      }
    ],
    "commit" : "a9bf099c653ccd485e3409dc20f9d067974deb53",
    "line" : 52,
    "diffHunk" : "@@ -1,1 +252,256 @@      if (mapStatuses(mapIndex) != null && f(mapStatuses(mapIndex).location)) {\n        _numAvailableMapOutputs -= 1\n        mapStatusesDeleted(mapIndex) = mapStatuses(mapIndex)\n        mapStatuses(mapIndex) = null\n        invalidateSerializedMapOutputStatusCache()"
  },
  {
    "id" : "91f5234f-a934-4c50-b38b-dc1a1aaed9b7",
    "prId" : 32033,
    "prUrl" : "https://github.com/apache/spark/pull/32033#pullrequestreview-626783590",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "94e3c9b4-8e2e-49a8-bb0e-3647a41c1b7f",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Expose this for test.",
        "createdAt" : "2021-04-02T04:39:36Z",
        "updatedAt" : "2021-04-03T07:53:33Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "7719c3afa3fcb7c205048b785f23947e1844d804",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +101,105 @@   * explicitly destroyed later on when the ShuffleMapStage is garbage-collected.\n   */\n  private[spark] var cachedSerializedBroadcast: Broadcast[Array[Byte]] = _\n\n  /**"
  },
  {
    "id" : "67e2b157-3c4a-404f-80fb-43fbb256538d",
    "prId" : 32033,
    "prUrl" : "https://github.com/apache/spark/pull/32033#pullrequestreview-626845118",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "49405ab4-a00d-4f58-b1d0-2ee3812e1824",
        "parentId" : null,
        "authorId" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "body" : "The failure could be `DIRECT`, how can you ensure it's only catching exception from broadcast?",
        "createdAt" : "2021-04-02T07:55:41Z",
        "updatedAt" : "2021-04-03T07:53:33Z",
        "lastEditedBy" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "tags" : [
        ]
      },
      {
        "id" : "10e10fa6-becd-4394-960a-443f118332ff",
        "parentId" : "49405ab4-a00d-4f58-b1d0-2ee3812e1824",
        "authorId" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "body" : "Oh, never mind. I saw the code in the following.",
        "createdAt" : "2021-04-02T07:56:31Z",
        "updatedAt" : "2021-04-03T07:53:33Z",
        "lastEditedBy" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "tags" : [
        ]
      }
    ],
    "commit" : "7719c3afa3fcb7c205048b785f23947e1844d804",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +847,851 @@            fetchedStatuses = MapOutputTracker.deserializeMapStatuses(fetchedBytes, conf)\n          } catch {\n            case e: SparkException =>\n              throw new MetadataFetchFailedException(shuffleId, -1,\n                s\"Unable to deserialize broadcasted map statuses for shuffle $shuffleId: \" +"
  },
  {
    "id" : "31e3766f-a390-4995-8e33-e8f6cd2123ce",
    "prId" : 32033,
    "prUrl" : "https://github.com/apache/spark/pull/32033#pullrequestreview-627082927",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dfcb82d5-9a80-46e5-9af3-2debca167ee7",
        "parentId" : null,
        "authorId" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "body" : "Maybe we should move line 964 to 967 out of the try block like in `DIRECT` case.",
        "createdAt" : "2021-04-02T07:58:43Z",
        "updatedAt" : "2021-04-03T07:53:33Z",
        "lastEditedBy" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "tags" : [
        ]
      },
      {
        "id" : "89e925e2-59c0-4d8f-8449-81a6f764e9c5",
        "parentId" : "dfcb82d5-9a80-46e5-9af3-2debca167ee7",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "This is for the need of writing the test case. In the test case, if we call `getStatuses`, the mapoutput tracker worker will ask tracker master for new broadcasted value. So we cannot test the situation we need.",
        "createdAt" : "2021-04-02T16:28:37Z",
        "updatedAt" : "2021-04-03T07:53:33Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "7719c3afa3fcb7c205048b785f23947e1844d804",
    "line" : 50,
    "diffHunk" : "@@ -1,1 +966,970 @@            asInstanceOf[Broadcast[Array[Byte]]]\n          logInfo(\"Broadcast mapstatuses size = \" + bytes.length +\n            \", actual size = \" + bcast.value.length)\n          // Important - ignore the DIRECT tag ! Start from offset 1\n          deserializeObject(bcast.value, 1, bcast.value.length - 1).asInstanceOf[Array[MapStatus]]"
  },
  {
    "id" : "df8b90a5-6698-4c97-bedb-7a5797820051",
    "prId" : 32033,
    "prUrl" : "https://github.com/apache/spark/pull/32033#pullrequestreview-627732980",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a02f64a4-6ff5-45d5-8eac-b6801ced85d8",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "shall we throw MetadataFetchFailedException directly here?",
        "createdAt" : "2021-04-05T07:21:32Z",
        "updatedAt" : "2021-04-05T07:21:32Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "e5b920b4-2eaf-41cf-adc5-b91067cb907b",
        "parentId" : "a02f64a4-6ff5-45d5-8eac-b6801ced85d8",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "<del>Throw `MetadataFetchFailedException` here and catch it and rethrow?</del>",
        "createdAt" : "2021-04-05T07:46:25Z",
        "updatedAt" : "2021-04-05T07:53:06Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "4ca4c43b-788f-4697-af9d-44b071a6531f",
        "parentId" : "a02f64a4-6ff5-45d5-8eac-b6801ced85d8",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Oh, recall why I did this. To construct `MetadataFetchFailedException` needs `shuffleId`.\r\n\r\nI choose to not throw `MetadataFetchFailedException` as `deserializeMapStatuses ` doesn't have `shuffleId` and doesn't need it at all.",
        "createdAt" : "2021-04-05T07:50:20Z",
        "updatedAt" : "2021-04-05T07:50:20Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "41ce4a40-efc4-4e45-ac89-03370d3d479f",
        "parentId" : "a02f64a4-6ff5-45d5-8eac-b6801ced85d8",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "ah I see, thanks for the explanation!",
        "createdAt" : "2021-04-05T09:24:36Z",
        "updatedAt" : "2021-04-05T09:24:36Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "7719c3afa3fcb7c205048b785f23947e1844d804",
    "line" : 56,
    "diffHunk" : "@@ -1,1 +972,976 @@          case e: IOException =>\n            logWarning(\"Exception encountered during deserializing broadcasted map statuses: \", e)\n            throw new SparkException(\"Unable to deserialize broadcasted map statuses\", e)\n        }\n      case _ => throw new IllegalArgumentException(\"Unexpected byte tag = \" + bytes(0))"
  },
  {
    "id" : "626fb1b5-fb32-46e6-852d-c230dcd03aac",
    "prId" : 30763,
    "prUrl" : "https://github.com/apache/spark/pull/30763#pullrequestreview-576508076",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5b19a9d7-1f77-4877-933b-696ebfb89985",
        "parentId" : null,
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "The blocking param does not seem to be used here?",
        "createdAt" : "2020-12-18T19:03:34Z",
        "updatedAt" : "2021-03-08T08:42:24Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      },
      {
        "id" : "a7737170-e274-4ffc-90e4-b75c41bfe48e",
        "parentId" : "5b19a9d7-1f77-4877-933b-696ebfb89985",
        "authorId" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "body" : "\r\nNo, it isn't used in this implementation. \r\n\r\nBut this  param is still needed in the interface  to override the abstract method coming from the `MapOutputTracker` class:\r\nhttps://github.com/apache/spark/blob/a09ced3589d90c533744a04f0c3b976d4bb42352/core/src/main/scala/org/apache/spark/MapOutputTracker.scala#L391 \r\n\r\nAnd in the abstract `MapOutputTracker` method is introduced to reuse this method in the context cleaning.\r\nhttps://github.com/attilapiros/spark/blob/a09ced3589d90c533744a04f0c3b976d4bb42352/core/src/main/scala/org/apache/spark/ContextCleaner.scala#L223\r\n\r\nWhere we could trigger a blocking or a non-blocking cleanup depending on the config: `spark.cleaner.referenceTracking.blocking.shuffle`.\r\n\r\nSo I think this is fine here.\r\n ",
        "createdAt" : "2021-01-26T16:07:52Z",
        "updatedAt" : "2021-03-08T08:42:24Z",
        "lastEditedBy" : "123cc67f-f678-49be-8742-95bc35d8c5c4",
        "tags" : [
        ]
      }
    ],
    "commit" : "8e54b41702fd3f8f78d14a57eeb3cf9277b666cc",
    "line" : 142,
    "diffHunk" : "@@ -1,1 +884,888 @@\n  /** Unregister shuffle data. */\n  def unregisterShuffle(shuffleId: Int, blocking: Boolean): Boolean = {\n    mapStatuses.remove(shuffleId).isDefined\n  }"
  },
  {
    "id" : "65aa4854-7190-4fb0-befa-5b709f026a6d",
    "prId" : 30691,
    "prUrl" : "https://github.com/apache/spark/pull/30691#pullrequestreview-675632947",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "de50587e-dd4d-4b77-af6d-892a2146dc80",
        "parentId" : null,
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "Is this more logically part of SPARK-32923 and move it out of this PR ?",
        "createdAt" : "2021-06-02T03:42:49Z",
        "updatedAt" : "2021-06-02T03:42:50Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      },
      {
        "id" : "d2294fb9-a391-4d03-b6ba-4388378cf23a",
        "parentId" : "de50587e-dd4d-4b77-af6d-892a2146dc80",
        "authorId" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "body" : "[SPARK-32923](https://issues.apache.org/jira/browse/SPARK-32923) would handle non deterministic stage retries right? Do you mean we should remove the `mapOutputTracker.unregisterMergeResult` call in `DAGScheduler`? This change is already added as part of [SPARK-32921](https://issues.apache.org/jira/browse/SPARK-32921)",
        "createdAt" : "2021-06-02T05:24:35Z",
        "updatedAt" : "2021-06-02T05:24:35Z",
        "lastEditedBy" : "4da55a4a-8a34-454a-9445-fb8101f62652",
        "tags" : [
        ]
      },
      {
        "id" : "e7d3a389-9d77-46ed-a4a2-83b3cea2e89a",
        "parentId" : "de50587e-dd4d-4b77-af6d-892a2146dc80",
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "This was actually for `unregisterAllMergeResult` below - ended up commenting at wrong line.\r\nBut this is required, let me resolve this comment thread.",
        "createdAt" : "2021-06-03T19:02:50Z",
        "updatedAt" : "2021-06-03T19:02:50Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      }
    ],
    "commit" : "35d06150f37e01256314af4956c6e8fdcf7244b4",
    "line" : 74,
    "diffHunk" : "@@ -1,1 +760,764 @@        if (mergeStatus != null &&\n          (mapIndex.isEmpty || mergeStatus.tracker.contains(mapIndex.get))) {\n          shuffleStatus.removeMergeResult(reduceId, bmAddress)\n          incrementEpoch()\n        }"
  }
]