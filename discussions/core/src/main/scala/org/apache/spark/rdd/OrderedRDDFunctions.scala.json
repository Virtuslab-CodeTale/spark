[
  {
    "id" : "31892f03-8cdc-40d7-bc25-9914a7e2077d",
    "prId" : 31480,
    "prUrl" : "https://github.com/apache/spark/pull/31480#pullrequestreview-611105052",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "98751dbc-b986-450d-bf1b-d073c63cad26",
        "parentId" : null,
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "I probably mentioned this in the earlier version of this PR as well.\r\nCan we unify the code in this if block with what is in BlockStoreShuffleReader as well ?\r\nWe are duplicating this.",
        "createdAt" : "2021-02-19T21:43:59Z",
        "updatedAt" : "2021-03-19T05:46:28Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      },
      {
        "id" : "0aeb4337-1919-42d1-bb14-355e1beda0fc",
        "parentId" : "98751dbc-b986-450d-bf1b-d073c63cad26",
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "I misunderstood your previous comments. I am going to unify this in some way.",
        "createdAt" : "2021-02-20T03:21:32Z",
        "updatedAt" : "2021-03-19T05:46:28Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      },
      {
        "id" : "5e966b16-04c9-4a77-8154-d8529e761bea",
        "parentId" : "98751dbc-b986-450d-bf1b-d073c63cad26",
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "Nice fix !",
        "createdAt" : "2021-03-12T19:58:50Z",
        "updatedAt" : "2021-03-19T05:46:28Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      }
    ],
    "commit" : "83947ab67d22d62f17f774451fdd5d4f9616000a",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +82,86 @@          sorter.insertAllAndUpdateMetrics(iter).asInstanceOf[Iterator[(K, V)]])\n      }, preservesPartitioning = true)\n    } else {\n      new ShuffledRDD[K, V, V](self, partitioner).setKeyOrdering(ordering)\n    }"
  },
  {
    "id" : "68599c94-f321-424b-b626-431839ebce05",
    "prId" : 29185,
    "prUrl" : "https://github.com/apache/spark/pull/29185#pullrequestreview-579015589",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7d99b659-5268-439e-a623-4e4d2f1f14cf",
        "parentId" : null,
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "Can we refactor the code here and `BlockStoreShuffleReader.read` ?",
        "createdAt" : "2020-08-10T22:13:49Z",
        "updatedAt" : "2020-08-10T22:18:05Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      },
      {
        "id" : "6d6bab9d-1468-410c-bf85-d47a4d573d61",
        "parentId" : "7d99b659-5268-439e-a623-4e4d2f1f14cf",
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "@mridulm sorry for the late reply.\r\nI think I am missing something, I don't quite understand why/how to refactor here, do you mean adding a Listener like this?\r\n```\r\n        // Use completion callback to stop sorter if task was finished/cancelled.\r\n        context.addTaskCompletionListener[Unit](_ => {\r\n          sorter.stop()\r\n        })\r\n```\r\n",
        "createdAt" : "2021-01-29T07:29:44Z",
        "updatedAt" : "2021-01-29T07:29:45Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      },
      {
        "id" : "6c04d6b8-d9aa-4e50-801d-403cf40008e9",
        "parentId" : "7d99b659-5268-439e-a623-4e4d2f1f14cf",
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "current pr is also similar to `def distinct(numPartitions: Int)` in `RDD.scala`, I think the main difference is that : in `distinct(numPartitions: Int)` a ExternalAppendOnlyMap is used.",
        "createdAt" : "2021-01-29T08:00:37Z",
        "updatedAt" : "2021-01-29T08:00:37Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      }
    ],
    "commit" : "cb1148c6c97ca52f35288dc739138930ac07f295",
    "line" : 29,
    "diffHunk" : "@@ -1,1 +87,91 @@          sorter.iterator.asInstanceOf[Iterator[(K, V)]])\n        CompletionIterator[(K, V), Iterator[(K, V)]](outputIter, sorter.stop)\n      }, preservesPartitioning = true)\n    } else {\n      new ShuffledRDD[K, V, V](self, partitioner).setKeyOrdering(ordering)"
  }
]