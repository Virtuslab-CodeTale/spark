[
  {
    "id" : "77ae7ec0-1c53-4df0-889d-78c1f8cd2cd8",
    "prId" : 33457,
    "prUrl" : "https://github.com/apache/spark/pull/33457#pullrequestreview-716870447",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1a99987b-05fa-4b25-b3f5-d97b84f9882b",
        "parentId" : null,
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "btw, why do we need to attach all the handlers again? And there are so many \"attachAllHandler\" in the code changes.",
        "createdAt" : "2021-07-27T12:34:15Z",
        "updatedAt" : "2021-07-27T12:34:54Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "774d52b2-af84-493b-9541-a0019bc3581c",
        "parentId" : "1a99987b-05fa-4b25-b3f5-d97b84f9882b",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> btw, why do we need to attach all the handlers again? And there are so many \"attachAllHandler\" in the code changes.\r\n\r\nThat me clarify the process.\r\nBefore this change. We add handlers to SparkUI but not start it when init SparkUI since we not start jetty server.\r\nThen it call `bind()`, in this method we start jetty server and attach all handler to server.\r\nthis cause a problem that when we call `bind()`, we expose all servlet API to user. But application not fully started yet.\r\nNow in this pr, I split the behavior of start jetty server and attach handlers to server.\r\nWe need to bind address(start jetty server) first before start AM since we need driver url address to bind with spark proxy server.\r\n\r\nThen after application fully started, we attach all handlers to server(means expose UI url to user).\r\n\r\n\r\nFor this comment https://github.com/apache/spark/pull/33457#issuecomment-886624148\r\nI add a initHandler to handle all request between  starting jetty server and  fully start application to show the hint message.\r\n",
        "createdAt" : "2021-07-27T12:46:16Z",
        "updatedAt" : "2021-07-27T12:46:17Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "cf960bda-fdb6-47e2-96d8-059d398f6f20",
        "parentId" : "1a99987b-05fa-4b25-b3f5-d97b84f9882b",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "> I split the behavior of start jetty server and attach handlers to server\r\n\r\nI add some logging and find that `attachHandler` is still called multiple times before `attachAllHandler`",
        "createdAt" : "2021-07-27T13:37:09Z",
        "updatedAt" : "2021-07-27T13:37:09Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "2fd16ec9-92d2-4e6d-a34c-d2891bbac962",
        "parentId" : "1a99987b-05fa-4b25-b3f5-d97b84f9882b",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> > I split the behavior of start jetty server and attach handlers to server\r\n> \r\n> I add some logging and find that `attachHandler` is still called multiple times before `attachAllHandler`\r\n\r\nYes, but when we call `attachHandler()` the `serverInfo` is none, so the handler is not attached to the server.\r\n",
        "createdAt" : "2021-07-27T13:56:18Z",
        "updatedAt" : "2021-07-27T13:56:18Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "05716be7-44bf-4df0-a12c-10bb18c1aa06",
        "parentId" : "1a99987b-05fa-4b25-b3f5-d97b84f9882b",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "Is there a way to avoid calling `attachAllHandler` in so many places?",
        "createdAt" : "2021-07-27T15:35:59Z",
        "updatedAt" : "2021-07-27T15:35:59Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "26148544-974d-41f5-8b5a-7dc7cfa3af33",
        "parentId" : "1a99987b-05fa-4b25-b3f5-d97b84f9882b",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> Is there a way to avoid calling `attachAllHandler` in so many places?\r\n\r\nAdd a new method call it `bindAndAttachAllHandler()` then replace other place to call this one? only call `bind()` and `attachAllHandler` in  SparkContext?",
        "createdAt" : "2021-07-27T16:04:16Z",
        "updatedAt" : "2021-07-27T16:04:17Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "c6243036-a033-4bde-a2c3-9a1811c897a0",
        "parentId" : "1a99987b-05fa-4b25-b3f5-d97b84f9882b",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "Will that work for history server and master/worker UI? If yes let's try to avoid changing them.",
        "createdAt" : "2021-07-27T16:18:17Z",
        "updatedAt" : "2021-07-27T16:18:17Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "18c38b9d-cd03-4b70-a850-ed37f9f8faaf",
        "parentId" : "1a99987b-05fa-4b25-b3f5-d97b84f9882b",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> Will that work for history server and master/worker UI? If yes let's try to avoid changing them.\r\n\r\nHow about current?",
        "createdAt" : "2021-07-27T16:45:01Z",
        "updatedAt" : "2021-07-27T16:45:01Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      },
      {
        "id" : "cd8483bf-0017-4096-b3b5-11def3522e75",
        "parentId" : "1a99987b-05fa-4b25-b3f5-d97b84f9882b",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "I mean, will history server and master/worker UI show the same page(spark is starting up...) on starting up?",
        "createdAt" : "2021-07-28T10:53:07Z",
        "updatedAt" : "2021-07-28T10:53:27Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "9ace0a0c-5ade-484a-bc50-6f4d2b75fc85",
        "parentId" : "1a99987b-05fa-4b25-b3f5-d97b84f9882b",
        "authorId" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "body" : "> I mean, will history server and master/worker UI show the same page(spark is starting up...) on starting up?\r\n\r\nWith current code, won't impact history server/master/worker web UI. and   history server/master/worker web UI doesn't have such problem.",
        "createdAt" : "2021-07-28T11:09:38Z",
        "updatedAt" : "2021-07-28T11:09:38Z",
        "lastEditedBy" : "594db420-88ec-4875-8cd3-0d8b0bec131c",
        "tags" : [
        ]
      }
    ],
    "commit" : "0c9c3ce97871ae1d081c3e3cdc32034b1a1e66fd",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +639,643 @@\n    // After application started, attach handlers to started server and start handler.\n    _ui.foreach(_.attachAllHandler())\n    // Attach the driver metrics servlet handler to the web ui after the metrics system is started.\n    _env.metricsSystem.getServletHandlers.foreach(handler => ui.foreach(_.attachHandler(handler)))"
  },
  {
    "id" : "d6c99155-4ed9-46d7-8370-b357a5812735",
    "prId" : 32648,
    "prUrl" : "https://github.com/apache/spark/pull/32648#pullrequestreview-666442028",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8131f32c-6de4-402c-9ac0-174b1604cd79",
        "parentId" : null,
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "```\r\n[ERROR] [Error] /spark/core/src/main/scala/org/apache/spark/SparkContext.scala:355: weaker access privileges in overriding\r\nprivate[package lang] def childValue(x$1: java.util.Properties): java.util.Properties (defined in class ThreadLocal)\r\n  override should at least be private[lang]\r\n```",
        "createdAt" : "2021-05-24T06:46:31Z",
        "updatedAt" : "2021-05-24T06:47:20Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      }
    ],
    "commit" : "2a867a6277c1c6c4f1a6497973588304f907bede",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +353,357 @@  // Thread Local variable that can be used by users to pass information down the stack\n  protected[spark] val localProperties = new InheritableThreadLocal[Properties] {\n    override def childValue(parent: Properties): Properties = {\n      // Note: make a clone such that changes in the parent properties aren't reflected in\n      // the those of the children threads, which has confusing semantics (SPARK-10563)."
  },
  {
    "id" : "cfcc8465-afde-4c8d-b5de-cd24d7b93459",
    "prId" : 32518,
    "prUrl" : "https://github.com/apache/spark/pull/32518#pullrequestreview-657993847",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2f5bcd94-36a6-4ba7-a534-b491778fca6d",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "@dongjoon-hyun, should we maybe do this in `SparkSubmitArguments` with `sparkProperties` like `ignoreNonSparkProperties` handling? I think that;s as early as possible",
        "createdAt" : "2021-05-12T06:29:13Z",
        "updatedAt" : "2021-05-12T06:29:13Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "c8e3baa8-42ba-4640-a1b1-f0fe955f641e",
        "parentId" : "2f5bcd94-36a6-4ba7-a534-b491778fca6d",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Yes, it's possible to handle there for SparkSubmit command parameters, however Hadoop configurations also can be handed over to `SparkSession` inside Spark Apps after Spark submits.",
        "createdAt" : "2021-05-12T14:56:23Z",
        "updatedAt" : "2021-05-12T15:07:18Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "afeb68fadb57b7d02258cbd3a2cc540e73f803ff",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +398,402 @@    }\n    // This should be set as early as possible.\n    SparkContext.fillMissingMagicCommitterConfsIfNeeded(_conf)\n\n    _driverLogger = DriverLogger(_conf)"
  },
  {
    "id" : "81ae343f-05e5-4ca5-bd99-c8ddbd466646",
    "prId" : 31953,
    "prUrl" : "https://github.com/apache/spark/pull/31953#pullrequestreview-619747303",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "599c394f-0296-41af-81ba-a17faf09cc4c",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "You can probably simplify by creating two Options for the two properties as vals first",
        "createdAt" : "2021-03-24T13:55:18Z",
        "updatedAt" : "2021-03-24T13:55:18Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      }
    ],
    "commit" : "8bafffbdafccad64b961bdc85337594588aaff84",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +2187,2191 @@   */\n  private[spark] def getCallSite(): CallSite = {\n    if (getLocalProperty(CallSite.SHORT_FORM) == null\n      || getLocalProperty(CallSite.LONG_FORM) == null) {\n      val callSite = Utils.getCallSite()"
  },
  {
    "id" : "874796f6-b076-45dc-b377-fd76521c367a",
    "prId" : 31953,
    "prUrl" : "https://github.com/apache/spark/pull/31953#pullrequestreview-622939903",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "076d2ca9-a076-4380-9691-9e424ae33307",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "@lxian, it would be great if we can elabourate how it causes the lock as you did in JIRA. In addition, to clarify, this is not an issue in Spark 3+ as we dropped Scala 2.11 at SPARK-26132.\r\n\r\nCan you create a PR for bracnh-2.4 alone? cc @viirya and @dongjoon-hyun FYI",
        "createdAt" : "2021-03-25T03:11:46Z",
        "updatedAt" : "2021-03-25T03:11:46Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "34858135-4a86-4d7c-ac60-26ec532f81e6",
        "parentId" : "076d2ca9-a076-4380-9691-9e424ae33307",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Is this easy to add test? Otherwise we can also show up how to reproduce it manually in the description.",
        "createdAt" : "2021-03-25T06:59:43Z",
        "updatedAt" : "2021-03-25T06:59:43Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "9b2668b5-b687-4c68-a9b7-e6e900081462",
        "parentId" : "076d2ca9-a076-4380-9691-9e424ae33307",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "@lxian Can you create a PR for branch-2.4? If you are busy, would you mind I create a PR for branch-2.4? Thanks.",
        "createdAt" : "2021-03-29T03:55:51Z",
        "updatedAt" : "2021-03-29T03:55:51Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "11ee410e-1b40-4bbd-ad68-0afcd1a55947",
        "parentId" : "076d2ca9-a076-4380-9691-9e424ae33307",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "@viirya I believe it's fine for you to just go ahead IMO .. the author became inactive 4 days and this is the blocker of 2.4 (I guess?).",
        "createdAt" : "2021-03-29T04:07:42Z",
        "updatedAt" : "2021-03-29T04:07:42Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "894cb5f1-88f7-4967-9841-e3fafab9b2b8",
        "parentId" : "076d2ca9-a076-4380-9691-9e424ae33307",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "This is the last issue for 2.4, I think. Okay, let me create a PR first. I can close it if the author opens his after.",
        "createdAt" : "2021-03-29T04:16:22Z",
        "updatedAt" : "2021-03-29T04:16:23Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "5300db07-bb52-4a4c-83d8-3265ac060112",
        "parentId" : "076d2ca9-a076-4380-9691-9e424ae33307",
        "authorId" : "9708b891-7e0d-4e53-ab50-2cc008f04131",
        "body" : "@viirya Thank you for creating the PR. you can close mine if needed. ",
        "createdAt" : "2021-03-29T07:19:03Z",
        "updatedAt" : "2021-03-29T07:19:03Z",
        "lastEditedBy" : "9708b891-7e0d-4e53-ab50-2cc008f04131",
        "tags" : [
        ]
      },
      {
        "id" : "bb712e7a-fff3-4b2b-b3b3-60f60a128bc2",
        "parentId" : "076d2ca9-a076-4380-9691-9e424ae33307",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Thank you @lxian. Your authorship is still kept in the commit.",
        "createdAt" : "2021-03-29T07:40:33Z",
        "updatedAt" : "2021-03-29T07:40:33Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "8bafffbdafccad64b961bdc85337594588aaff84",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +2187,2191 @@   */\n  private[spark] def getCallSite(): CallSite = {\n    if (getLocalProperty(CallSite.SHORT_FORM) == null\n      || getLocalProperty(CallSite.LONG_FORM) == null) {\n      val callSite = Utils.getCallSite()"
  },
  {
    "id" : "1e938f96-f40a-4f7c-9c93-01903a0d2df7",
    "prId" : 31718,
    "prUrl" : "https://github.com/apache/spark/pull/31718#pullrequestreview-635372845",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b56631da-8d5b-469f-8318-e9a9721882e8",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "@sarutak, I think we can just repalce `Path` here too (looks like you're fixing this problem across the codebase, right?)",
        "createdAt" : "2021-04-14T01:47:42Z",
        "updatedAt" : "2021-04-14T01:47:42Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "6380025c-1dcc-4563-a9fd-b50c683c50ad",
        "parentId" : "b56631da-8d5b-469f-8318-e9a9721882e8",
        "authorId" : "3a227965-84e0-47cf-9974-11293764f028",
        "body" : "Yeah, the behavior of `Path` seems to be a little bit confusable and there may be lots of places where `Path` does not behave  as we expect.\r\nO.K, I'll looking into it.",
        "createdAt" : "2021-04-14T01:55:58Z",
        "updatedAt" : "2021-04-14T01:55:58Z",
        "lastEditedBy" : "3a227965-84e0-47cf-9974-11293764f028",
        "tags" : [
        ]
      },
      {
        "id" : "207ab294-3d60-46d1-9318-cd246bc7c86d",
        "parentId" : "b56631da-8d5b-469f-8318-e9a9721882e8",
        "authorId" : "3a227965-84e0-47cf-9974-11293764f028",
        "body" : "@HyukjinKwon BTW, Just replacing `Path` is my first idea of this PR.\r\nhttps://github.com/apache/spark/pull/31718/commits/3c40f988de81600a75190751bf9987dfc93d09e9#diff-1e596e9e9bd50e3075847a66f8fecee741289b2b0478f9099c3bf2b680ebaa35R1586\r\n\r\nBut I changed to reflect [your comment](https://github.com/apache/spark/pull/31718#issuecomment-792225217).\r\nAnyway, I'll open a followup PR.",
        "createdAt" : "2021-04-14T07:32:20Z",
        "updatedAt" : "2021-04-14T07:32:21Z",
        "lastEditedBy" : "3a227965-84e0-47cf-9974-11293764f028",
        "tags" : [
        ]
      },
      {
        "id" : "802e7e53-ccc3-40fc-bdb7-a01d95b31e83",
        "parentId" : "b56631da-8d5b-469f-8318-e9a9721882e8",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Yeah, I know :). Sorry for a bit of forth and back. If we change it all in the code base, I think it makes more sense to land a correct fix rather then staying safer and conservative with a bandaid fix",
        "createdAt" : "2021-04-14T08:53:07Z",
        "updatedAt" : "2021-04-14T08:53:07Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "9dc15b92d3ea94e6bb5f00ff02da3655fa9ae381",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +1591,1595 @@      }\n    } else {\n      Utils.resolveURI(path)\n    }\n    val schemeCorrectedURI = uri.getScheme match {"
  },
  {
    "id" : "f9417e83-d1dd-4288-bd8e-b5535db310ff",
    "prId" : 31521,
    "prUrl" : "https://github.com/apache/spark/pull/31521#pullrequestreview-585570977",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a683af74-2c14-47ab-9c87-38ad4d33e2f8",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Do we expect users would set `spark.job.interruptOnCance` (as I notice it's private)? I think it may be better to prevent users from setting this kind of private property instead of doing the valid check.  And we could recommend users to use `setJobGroup` instead. cc @tgravescs @mridulm any thoughts about this?\r\n",
        "createdAt" : "2021-02-08T12:33:22Z",
        "updatedAt" : "2021-02-08T14:29:58Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "639aad76-d2a1-440b-8515-892fe64817db",
        "parentId" : "a683af74-2c14-47ab-9c87-38ad4d33e2f8",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "I perfer to the suggestion, forbid is better. If so we might need an another internal method to set local property for some test case.",
        "createdAt" : "2021-02-08T14:29:38Z",
        "updatedAt" : "2021-02-08T14:29:38Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      },
      {
        "id" : "de6782c3-c45a-4857-8350-4041b6b13ac0",
        "parentId" : "a683af74-2c14-47ab-9c87-38ad4d33e2f8",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Yeah, we need the internal method if we want to forbid. May let's see others' feedback first.",
        "createdAt" : "2021-02-08T14:32:54Z",
        "updatedAt" : "2021-02-08T14:32:54Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "d938f3c4-65c6-4695-be36-f9452ad3731e",
        "parentId" : "a683af74-2c14-47ab-9c87-38ad4d33e2f8",
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "we should just change this to use the ConfigBuilder. mark it as internal and the toBoolean function already does this same check to make sure valid.  That doesn't prevent them from doing it though so if we wanted to add other checking for all internal that might be a bit more work and complex as I'm sure we use some for testing.",
        "createdAt" : "2021-02-08T14:42:58Z",
        "updatedAt" : "2021-02-08T14:42:58Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      },
      {
        "id" : "ad62af8f-20b2-4f2b-9347-56925e36bf0a",
        "parentId" : "a683af74-2c14-47ab-9c87-38ad4d33e2f8",
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "oh sorry I guess we can't do that because local property, I would like to more about context ",
        "createdAt" : "2021-02-08T14:44:32Z",
        "updatedAt" : "2021-02-08T14:46:11Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      }
    ],
    "commit" : "17669d900568635be2151870101f0d6b33885230",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +720,724 @@      localProperties.get.remove(key)\n    } else {\n      checkLocalProperty(key, value)\n      localProperties.get.setProperty(key, value)\n    }"
  },
  {
    "id" : "be4db0f2-b21e-439c-bce3-abff8427ad7f",
    "prId" : 31227,
    "prUrl" : "https://github.com/apache/spark/pull/31227#pullrequestreview-570476370",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "34ca2a53-360d-496f-bc31-285565e3c3a5",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "We can define it in sql/core module, as it's only used there and the STS module. Probably in `SQLExecution` object.",
        "createdAt" : "2021-01-18T13:11:13Z",
        "updatedAt" : "2021-01-18T13:11:13Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "1a751ba9933b42750b33efd4c65dbee065425781",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +2769,2773 @@   * Statement id is only used for thrift server\n   */\n  private[spark] val SPARK_STATEMENT_ID = \"spark.statement.id\"\n\n  /**"
  },
  {
    "id" : "4c5bfcf1-692c-4624-bb36-e754c84417b4",
    "prId" : 30581,
    "prUrl" : "https://github.com/apache/spark/pull/30581#pullrequestreview-543951766",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "16cf9175-0b06-464f-a167-1d8a6895b887",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "This change is actually not related but I found it during debug. This isn't a bug but improvement:\r\n\r\nBy using `file:/` instead of `spark:/`  on the driver side, we can directly copy the file in driver side instead of fetching through the Netty file server layer. This is matched with `spark.files`.\r\n",
        "createdAt" : "2020-12-03T13:29:04Z",
        "updatedAt" : "2020-12-04T05:52:39Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "9f048008d061bbed27e8df6831b3b5386088669f",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +1642,1646 @@      // If the scheme is file, use URI to simply copy instead of downloading.\n      val uriToUse = if (!isLocal && scheme == \"file\") uri else new URI(key)\n      val uriToDownload = UriBuilder.fromUri(uriToUse).fragment(null).build()\n      val source = Utils.fetchFile(uriToDownload.toString, Utils.createTempDir(), conf,\n        env.securityManager, hadoopConfiguration, timestamp, useCache = false, shouldUntar = false)"
  }
]