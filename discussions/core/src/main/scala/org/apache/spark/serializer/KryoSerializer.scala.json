[
  {
    "id" : "dc029e67-980c-49ed-be21-f0d21a847b12",
    "prId" : 31597,
    "prUrl" : "https://github.com/apache/spark/pull/31597#pullrequestreview-604236659",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0f6e5143-cffe-4481-b129-44bd270b33a3",
        "parentId" : null,
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "Comment on why we are not handling SpecificRecordBase, SpecificFixed ?",
        "createdAt" : "2021-02-28T07:54:15Z",
        "updatedAt" : "2021-03-04T15:36:20Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      },
      {
        "id" : "1d78f8d9-6b62-4443-bca2-164682f04085",
        "parentId" : "0f6e5143-cffe-4481-b129-44bd270b33a3",
        "authorId" : "a9818936-8272-4717-aeaf-31025433b84d",
        "body" : "I think for specific records we will need to use a different codepath inside Avro for serde viz. `SpecificDatum(Reader|Writer)` instead of `GenericDatum(Reader|Writer)` which is currently how `GenericAvroSerializer` is implemented. Also I think we will need to register each concrete SpecificRecord class for Kryo to work correctly. Thoughts?",
        "createdAt" : "2021-03-03T00:06:02Z",
        "updatedAt" : "2021-03-04T15:36:20Z",
        "lastEditedBy" : "a9818936-8272-4717-aeaf-31025433b84d",
        "tags" : [
        ]
      },
      {
        "id" : "bb6e1a78-6758-4566-ac67-e7eb0dff3fad",
        "parentId" : "0f6e5143-cffe-4481-b129-44bd270b33a3",
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "To clarify, can we add that a comment ? :-)",
        "createdAt" : "2021-03-03T17:18:14Z",
        "updatedAt" : "2021-03-04T15:36:20Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      },
      {
        "id" : "56f0c5d3-6873-4ed8-a85e-dc251ec871a0",
        "parentId" : "0f6e5143-cffe-4481-b129-44bd270b33a3",
        "authorId" : "a9818936-8272-4717-aeaf-31025433b84d",
        "body" : "Ahh! Done",
        "createdAt" : "2021-03-04T15:35:48Z",
        "updatedAt" : "2021-03-04T15:36:20Z",
        "lastEditedBy" : "a9818936-8272-4717-aeaf-31025433b84d",
        "tags" : [
        ]
      }
    ],
    "commit" : "bdbe0ea952c04a9b97c824494bfcd221d8082d56",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +165,169 @@    registerAvro[GenericData.Array[_]]\n    registerAvro[GenericData.EnumSymbol]\n    registerAvro[GenericData.Fixed]\n\n    // Use the default classloader when calling the user registrator."
  },
  {
    "id" : "ca55e728-8315-4d5a-b176-0115e8823dd2",
    "prId" : 24555,
    "prUrl" : "https://github.com/apache/spark/pull/24555#pullrequestreview-235379377",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "60efb58d-2999-42f0-9db5-987a74d4bd7f",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Are these actually different types, if the generic type is all that varies?",
        "createdAt" : "2019-05-08T16:33:15Z",
        "updatedAt" : "2019-05-09T02:57:58Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "0afa975e-36cb-4e30-b68d-2868d6031a0b",
        "parentId" : "60efb58d-2999-42f0-9db5-987a74d4bd7f",
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "Like [https://github.com/apache/spark/blob/master/graphx/src/main/scala/org/apache/spark/graphx/GraphXUtils.scala#L45](url), I think they are different, since type specialization is used in [https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/util/collection/OpenHashSet.scala#L44](url)",
        "createdAt" : "2019-05-09T02:54:17Z",
        "updatedAt" : "2019-05-09T02:57:58Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      }
    ],
    "commit" : "928f36ab39a009df558f2cefa7590d635f62e002",
    "line" : 37,
    "diffHunk" : "@@ -1,1 +506,510 @@    classOf[BitSet],\n    classOf[CompactBuffer[_]],\n    classOf[OpenHashSet[Int]],\n    classOf[OpenHashSet[Long]],\n    classOf[OpenHashSet[Float]],"
  },
  {
    "id" : "920901cc-e1c3-47f3-abf6-facc5b925b0b",
    "prId" : 24555,
    "prUrl" : "https://github.com/apache/spark/pull/24555#pullrequestreview-235378811",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0dd57afa-0038-4f6a-bbc3-8c86205762c2",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "These are synthetic classes and their name may change. Are they needed?",
        "createdAt" : "2019-05-08T16:33:29Z",
        "updatedAt" : "2019-05-09T02:57:58Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "f7d63941-12ec-4ba8-b764-bb542c608d91",
        "parentId" : "0dd57afa-0038-4f6a-bbc3-8c86205762c2",
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "Yes, they are needed if we want to register `Edge`, since type specialization is used in [https://github.com/apache/spark/blob/master/graphx/src/main/scala/org/apache/spark/graphx/Edge.scala#L32](url)\r\n\r\nI had test this, if we do not reigster `org.apache.spark.graphx.Edge$mcB$sp`, Edge[Boolean] will not be handled by kryo.",
        "createdAt" : "2019-05-09T02:50:37Z",
        "updatedAt" : "2019-05-09T02:57:58Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      }
    ],
    "commit" : "928f36ab39a009df558f2cefa7590d635f62e002",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +215,219 @@    Seq(\n      \"org.apache.spark.graphx.Edge\",\n      \"org.apache.spark.graphx.Edge$mcB$sp\",\n      \"org.apache.spark.graphx.Edge$mcC$sp\",\n      \"org.apache.spark.graphx.Edge$mcD$sp\","
  }
]