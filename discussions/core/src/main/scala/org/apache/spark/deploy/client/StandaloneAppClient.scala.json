[
  {
    "id" : "38423335-f655-4df5-a0c8-4dc11e638ebd",
    "prId" : 29579,
    "prUrl" : "https://github.com/apache/spark/pull/29579#pullrequestreview-482014642",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1642ca56-277c-4567-a8ba-2a9a3a7a44b4",
        "parentId" : null,
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "Personally, I would still be okay with workerLost being an Option[String] instead of a Boolean. Obviously, had it been called \"workerIsLost\" then we would have to rename it. But I am also fine with the new name workerHost as well. I don't particularly think that the name workerLost must connote a boolean.\r\n\r\nThis ExecutorUpdated message is a case in point where the \"lost\" part is meaningful because it refers to the \"worker that is lost\" as opposed to some random worker-host. \r\n\r\nBut no strong feelings on this and I am happy with the choice workerHost.",
        "createdAt" : "2020-09-03T16:42:32Z",
        "updatedAt" : "2020-09-07T13:30:39Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      }
    ],
    "commit" : "d2468407f3d02e5a191ad373b5f2201a930cbb09",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +176,180 @@        listener.executorAdded(fullId, workerId, hostPort, cores, memory)\n\n      case ExecutorUpdated(id, state, message, exitStatus, workerHost) =>\n        val fullId = appId + \"/\" + id\n        val messageText = message.map(s => \" (\" + s + \")\").getOrElse(\"\")"
  },
  {
    "id" : "6b8d2180-0aa7-49ae-aec5-d95e0677d041",
    "prId" : 29032,
    "prUrl" : "https://github.com/apache/spark/pull/29032#pullrequestreview-449524268",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4e809c0f-8254-43d8-b219-8470b85955d4",
        "parentId" : null,
        "authorId" : "bc001dd4-5224-4ca1-afdd-49d69783d7f2",
        "body" : "how is the flag `isHostDecommissioned` actually used?",
        "createdAt" : "2020-07-16T05:50:44Z",
        "updatedAt" : "2020-07-22T05:41:05Z",
        "lastEditedBy" : "bc001dd4-5224-4ca1-afdd-49d69783d7f2",
        "tags" : [
        ]
      },
      {
        "id" : "f49ff8aa-35c6-4a12-b73c-a25ec19c1a74",
        "parentId" : "4e809c0f-8254-43d8-b219-8470b85955d4",
        "authorId" : "bc001dd4-5224-4ca1-afdd-49d69783d7f2",
        "body" : "oh I see https://github.com/apache/spark/pull/29032#discussion_r455401121",
        "createdAt" : "2020-07-16T05:51:32Z",
        "updatedAt" : "2020-07-22T05:41:05Z",
        "lastEditedBy" : "bc001dd4-5224-4ca1-afdd-49d69783d7f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "88060be29d84e9d26a14d35c33f906a3f49434ef",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +184,188 @@        } else if (state == ExecutorState.DECOMMISSIONED) {\n          listener.executorDecommissioned(fullId,\n            ExecutorDecommissionInfo(message.getOrElse(\"\"), isHostDecommissioned = workerLost))\n        }\n"
  }
]