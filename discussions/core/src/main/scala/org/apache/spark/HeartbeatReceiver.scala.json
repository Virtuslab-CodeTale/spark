[
  {
    "id" : "d58300ca-75eb-46ae-b2a1-287aaf28810a",
    "prId" : 31373,
    "prUrl" : "https://github.com/apache/spark/pull/31373#pullrequestreview-578575706",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b9095a8f-474b-4248-bf7d-3c83c1b27f33",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "This sounds like a race condition that happens during SparkContext shutdown. So it's also possible that the SparkContext is stopped right after we sent the `HeartbeatResponse`. In that case, IIUC, the issue will still exist.\r\n\r\nDoes the current behavior cause any real issue?",
        "createdAt" : "2021-01-28T09:45:09Z",
        "updatedAt" : "2021-01-28T09:45:15Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "7e3cbcf9-874a-4a89-8dac-93d4130c1a7e",
        "parentId" : "b9095a8f-474b-4248-bf7d-3c83c1b27f33",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Thank. you for review, @Ngone51 . That's true. In the production environment, I hit those intermediate status. And, this will help us simplify the situation.\r\n\r\n1. The case you mentioned, `Send HeartbeatResponse and  sc.stop invoked`, is a normal situation. The users don't complain about this.\r\n2. The case in this PR, `sc.stop invoked and Spark works inefficiently by sending HeartbeatResponse(true)` is a problem. The users complain about this.\r\n\r\nFor the following, yes. We are After the apps `sc.stop` takes a longer time than we expect.\r\n> Does the current behavior cause any real issue?",
        "createdAt" : "2021-01-28T17:31:37Z",
        "updatedAt" : "2021-01-28T17:51:35Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "510a505bd226d684ae771b911e0eed04946019d6",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +129,133 @@    // Messages received from executors\n    case heartbeat @ Heartbeat(executorId, accumUpdates, blockManagerId, executorUpdates) =>\n      var reregisterBlockManager = !sc.isStopped\n      if (scheduler != null) {\n        if (executorLastSeen.contains(executorId)) {"
  },
  {
    "id" : "70dde018-1864-4e51-89b0-63d521b3c239",
    "prId" : 30547,
    "prUrl" : "https://github.com/apache/spark/pull/30547#pullrequestreview-542467247",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a31200bc-0051-47e3-9506-69bf35e13325",
        "parentId" : null,
        "authorId" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "body" : "@HyukjinKwon  There are two reasons for change from \r\n```\r\nsc.conf.get(\r\n  config.STORAGE_BLOCKMANAGER_HEARTBEAT_TIMEOUT\r\n).getOrElse(sc.conf.getTimeAsMs(Network.NETWORK_TIMEOUT.key))\r\n```\r\nto \r\n\r\n```\r\nsc.conf.get(\r\n    config.STORAGE_BLOCKMANAGER_HEARTBEAT_TIMEOUT\r\n  ).getOrElse(Utils.timeStringAsMs(s\"${sc.conf.get(Network.NETWORK_TIMEOUT)}s\"))\r\n```\r\nï¼š\r\n\r\n- Maybe `Network.NETWORK_TIMEOUT` is not configured, need a default value\r\n\r\n- TimeUnit of `Network.NETWORK_TIMEOUT` is `TimeUnit.SECONDS` , so if user configure  `Network.NETWORK_TIMEOUT`  to `200` not `200s`, the result of `executorTimeoutMs` will be `200ms` not `200000ms` when use `sc.conf.getTimeAsMs(Network.NETWORK_TIMEOUT.key)`, it should be wrong",
        "createdAt" : "2020-12-02T03:13:57Z",
        "updatedAt" : "2020-12-02T03:14:11Z",
        "lastEditedBy" : "c7afbd1a-ab9f-4878-b837-32685ae783b0",
        "tags" : [
        ]
      },
      {
        "id" : "197faa0b-94e8-4a97-94a1-68e631441ef1",
        "parentId" : "a31200bc-0051-47e3-9506-69bf35e13325",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Yeah, that's fine.",
        "createdAt" : "2020-12-02T03:14:52Z",
        "updatedAt" : "2020-12-02T03:14:53Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "908863543372655091b8f6114b8ec5ec0290763e",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +83,87 @@  private val executorTimeoutMs = sc.conf.get(\n    config.STORAGE_BLOCKMANAGER_HEARTBEAT_TIMEOUT\n  ).getOrElse(Utils.timeStringAsMs(s\"${sc.conf.get(Network.NETWORK_TIMEOUT)}s\"))\n\n  private val checkTimeoutIntervalMs = sc.conf.get(Network.NETWORK_TIMEOUT_INTERVAL)"
  }
]