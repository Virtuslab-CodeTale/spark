[
  {
    "id" : "7190b629-9d94-466c-9581-d088a7a863ab",
    "prId" : 29268,
    "prUrl" : "https://github.com/apache/spark/pull/29268#pullrequestreview-456844236",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "192357f4-8e79-497d-afe1-10b3f6b1fc4d",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "is it possible to reuse the `_recordsWritten` accumulator?",
        "createdAt" : "2020-07-28T11:01:41Z",
        "updatedAt" : "2020-09-18T03:36:15Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "bed84721-e320-4e9b-af22-2717883a8304",
        "parentId" : "192357f4-8e79-497d-afe1-10b3f6b1fc4d",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "nvm, we need to collect the size array for reducers per task.",
        "createdAt" : "2020-07-28T17:15:44Z",
        "updatedAt" : "2020-09-18T03:36:15Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "d0e0084211109c819d2176b85c26f02abf09ec77",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +34,38 @@  private[executor] val _recordsWritten = new LongAccumulator\n  private[executor] val _writeTime = new LongAccumulator\n  private[executor] val _rowCountInfo = new CollectionAccumulator[RowCountInfo]\n\n  /**"
  }
]