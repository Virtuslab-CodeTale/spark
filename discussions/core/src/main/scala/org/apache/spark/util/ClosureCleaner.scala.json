[
  {
    "id" : "6d3a957a-482f-4373-865d-cb335260eb81",
    "prId" : 28577,
    "prUrl" : "https://github.com/apache/spark/pull/28577#pullrequestreview-414131795",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a745db17-fe09-48fc-95b8-10f4914bd21a",
        "parentId" : null,
        "authorId" : "3a12ce0f-9e73-4cfb-a4b4-b19368cddc2f",
        "body" : "cc @kiszk note that the Spark 2.4 version of this file imports `scala.language.existentials`",
        "createdAt" : "2020-05-19T06:19:59Z",
        "updatedAt" : "2020-05-19T06:23:14Z",
        "lastEditedBy" : "3a12ce0f-9e73-4cfb-a4b4-b19368cddc2f",
        "tags" : [
        ]
      }
    ],
    "commit" : "0b7bc9f3aa2d642673c4445919b8e19390adc38f",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +23,27 @@import scala.collection.JavaConverters._\nimport scala.collection.mutable.{Map, Set, Stack}\nimport scala.language.existentials\n\nimport org.apache.commons.lang3.ClassUtils"
  },
  {
    "id" : "a77172ca-ae08-494d-b84c-c21c790b0090",
    "prId" : 28577,
    "prUrl" : "https://github.com/apache/spark/pull/28577#pullrequestreview-414131795",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dc690320-d125-4296-8571-877f8a9f2b89",
        "parentId" : null,
        "authorId" : "3a12ce0f-9e73-4cfb-a4b4-b19368cddc2f",
        "body" : "This is Spark 2.4-specific. It was there in the existing code in `ClosureCleaner.getSerializedLambda`, and I'm porting it over to the new code as well.",
        "createdAt" : "2020-05-19T06:21:01Z",
        "updatedAt" : "2020-05-19T06:23:14Z",
        "lastEditedBy" : "3a12ce0f-9e73-4cfb-a4b4-b19368cddc2f",
        "tags" : [
        ]
      }
    ],
    "commit" : "0b7bc9f3aa2d642673c4445919b8e19390adc38f",
    "line" : 205,
    "diffHunk" : "@@ -1,1 +460,464 @@      //       but that's not the default and we don't expect it to be in use.\n      return None\n    }\n\n    def isClosureCandidate(cls: Class[_]): Boolean = {"
  },
  {
    "id" : "cd412547-860e-4374-83e1-627b8b6310c4",
    "prId" : 28577,
    "prUrl" : "https://github.com/apache/spark/pull/28577#pullrequestreview-414131795",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bb58ebaa-18a5-4237-88c7-66cbec0905a8",
        "parentId" : null,
        "authorId" : "3a12ce0f-9e73-4cfb-a4b4-b19368cddc2f",
        "body" : "cc @kiszk I've addressed your comment in this Spark 2.4 backport PR: removed the unused `owner` parameter.",
        "createdAt" : "2020-05-19T06:21:38Z",
        "updatedAt" : "2020-05-19T06:23:15Z",
        "lastEditedBy" : "3a12ce0f-9e73-4cfb-a4b4-b19368cddc2f",
        "tags" : [
        ]
      }
    ],
    "commit" : "0b7bc9f3aa2d642673c4445919b8e19390adc38f",
    "line" : 276,
    "diffHunk" : "@@ -1,1 +531,535 @@   */\n  def isInnerClassCtorCapturingOuter(\n      op: Int, name: String, desc: String, callerInternalName: String): Boolean = {\n    op == INVOKESPECIAL && name == \"<init>\" && desc.startsWith(s\"(L$callerInternalName;\")\n  }"
  },
  {
    "id" : "a154cd14-473a-45f0-8139-ba922c115fb6",
    "prId" : 28577,
    "prUrl" : "https://github.com/apache/spark/pull/28577#pullrequestreview-414131795",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "838199f5-8672-40e2-8f79-fc01a8a188a6",
        "parentId" : null,
        "authorId" : "3a12ce0f-9e73-4cfb-a4b4-b19368cddc2f",
        "body" : "cc @kiszk I've addressed your comment in this Spark 2.4 backport PR: use destructuring pattern matching assignment here. This is possible because of the extra import at the top of this file.",
        "createdAt" : "2020-05-19T06:22:15Z",
        "updatedAt" : "2020-05-19T06:23:15Z",
        "lastEditedBy" : "3a12ce0f-9e73-4cfb-a4b4-b19368cddc2f",
        "tags" : [
        ]
      }
    ],
    "commit" : "0b7bc9f3aa2d642673c4445919b8e19390adc38f",
    "line" : 448,
    "diffHunk" : "@@ -1,1 +703,707 @@            logDebug(s\"    found inner class $ownerExternalName\")\n            // val innerClassInfo = getOrUpdateClassInfo(owner)\n            val (innerClass, innerClassNode) = getOrUpdateClassInfo(owner)\n            // val innerClass = innerClassInfo._1\n            // val innerClassNode = innerClassInfo._2"
  }
]