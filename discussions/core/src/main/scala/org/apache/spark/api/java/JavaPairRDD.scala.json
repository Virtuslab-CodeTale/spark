[
  {
    "id" : "a433b4dd-a35b-486b-85df-8754182c7ded",
    "prId" : 28293,
    "prUrl" : "https://github.com/apache/spark/pull/28293#pullrequestreview-398413524",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a057c47b-b08d-4922-9067-5fb1dcb0f790",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "You'll want the `@Since(\"3.1.0\")` annotations on these methods",
        "createdAt" : "2020-04-22T14:57:57Z",
        "updatedAt" : "2020-04-22T20:49:37Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "4c0c6242-7330-45af-8d40-8fa0b5eaf764",
        "parentId" : "a057c47b-b08d-4922-9067-5fb1dcb0f790",
        "authorId" : "571aa343-d3a5-4c10-9c95-550bf191ba73",
        "body" : "Sure. I am also wondering whether it makes sense to backport this in 2.4 by the way?",
        "createdAt" : "2020-04-22T15:00:14Z",
        "updatedAt" : "2020-04-22T20:49:37Z",
        "lastEditedBy" : "571aa343-d3a5-4c10-9c95-550bf191ba73",
        "tags" : [
        ]
      },
      {
        "id" : "32f979dd-07d3-43b7-b8a0-1efdbf9980d1",
        "parentId" : "a057c47b-b08d-4922-9067-5fb1dcb0f790",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "No, it's not a bug fix per se. I wouldn't put it in 3.0 even necessarily.",
        "createdAt" : "2020-04-22T15:03:36Z",
        "updatedAt" : "2020-04-22T20:49:37Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "f5fa71f5-3666-41da-a6f9-6f0e4e763a4f",
        "parentId" : "a057c47b-b08d-4922-9067-5fb1dcb0f790",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Thank you for your first contribution, @wetneb !  +1 for @srowen 's answers.",
        "createdAt" : "2020-04-22T16:19:25Z",
        "updatedAt" : "2020-04-22T20:49:37Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "3de991df-e55f-47b1-90d5-2df0c7d68227",
        "parentId" : "a057c47b-b08d-4922-9067-5fb1dcb0f790",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "Just for curiosity, of the two since marks, Spark's scala `@Since` annotation and java `@since` tag, how to choose them? IMHO,  `@since` tag seems better here to let the version show up in the generated Java API documentation.  @dongjoon-hyun @srowen thanks. ",
        "createdAt" : "2020-04-22T16:56:14Z",
        "updatedAt" : "2020-04-22T20:49:37Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "cb9c1d6b-7e0d-49cf-81c6-b3f221182a86",
        "parentId" : "a057c47b-b08d-4922-9067-5fb1dcb0f790",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "For the generated Java API doc,  you should put `@since` into the comment.\r\n```\r\n  /**\r\n   * Return a RDD containing only the elements in the inclusive range `lower` to `upper`.\r\n   * If the RDD has been partitioned using a `RangePartitioner`, then this operation can be\r\n   * performed efficiently by only scanning the partitions that might containt matching elements.\r\n   * Otherwise, a standard `filter` is applied to all partitions.\r\n   *\r\n   * @since 3.1.0\r\n   */\r\n```\r\n\r\nFor example,\r\n- https://dist.apache.org/repos/dist/dev/spark/v3.0.0-rc1-docs/_site/api/java/org/apache/spark/sql/DataFrameNaFunctions.html\r\n- https://github.com/apache/spark/blob/master/sql/core/src/main/scala/org/apache/spark/sql/DataFrameNaFunctions.scala#L33",
        "createdAt" : "2020-04-22T17:02:33Z",
        "updatedAt" : "2020-04-22T20:49:37Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "f0452a74-7fe3-407b-bf2c-dc32b5d5f095",
        "parentId" : "a057c47b-b08d-4922-9067-5fb1dcb0f790",
        "authorId" : "571aa343-d3a5-4c10-9c95-550bf191ba73",
        "body" : "Thanks, I have added that too.",
        "createdAt" : "2020-04-22T17:16:33Z",
        "updatedAt" : "2020-04-22T20:49:37Z",
        "lastEditedBy" : "571aa343-d3a5-4c10-9c95-550bf191ba73",
        "tags" : [
        ]
      },
      {
        "id" : "31c63ef4-2ab0-4cb6-af51-025c46d86e4c",
        "parentId" : "a057c47b-b08d-4922-9067-5fb1dcb0f790",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Yep that's right, my mistake, I was thinking of Scala",
        "createdAt" : "2020-04-22T17:25:42Z",
        "updatedAt" : "2020-04-22T20:49:37Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      }
    ],
    "commit" : "62dd41ce5456a437f4c283d3f657c22759809809",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +948,952 @@   */\n  @Since(\"3.1.0\")\n  def filterByRange(lower: K, upper: K): JavaPairRDD[K, V] = {\n    val comp = com.google.common.collect.Ordering.natural().asInstanceOf[Comparator[K]]\n    filterByRange(comp, lower, upper)"
  }
]