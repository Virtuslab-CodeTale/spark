[
  {
    "id" : "666f1bb2-ef80-4f0d-a875-ae12829676cf",
    "prId" : 32530,
    "prUrl" : "https://github.com/apache/spark/pull/32530#pullrequestreview-659313592",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5f8e2bc3-ca1c-48c9-bcdd-365984ac665b",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "do we need to do the rename when `dynamicPartitionOverwrite == false`?",
        "createdAt" : "2021-05-13T13:35:32Z",
        "updatedAt" : "2021-05-13T13:35:32Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "08f10df3-883b-411e-9927-52bc97f71fef",
        "parentId" : "5f8e2bc3-ca1c-48c9-bcdd-365984ac665b",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I'm asking because this is different from https://github.com/apache/spark/pull/32207/files#diff-714f288ff8f97acca2fc3449e005d4abcab4a5d95883498652f507fa42a92a6aR191",
        "createdAt" : "2021-05-13T13:36:53Z",
        "updatedAt" : "2021-05-13T13:36:53Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "0fbd1216-6890-4edc-97c2-37b02225fbc1",
        "parentId" : "5f8e2bc3-ca1c-48c9-bcdd-365984ac665b",
        "authorId" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "body" : "I believe we do actually need the rename here. My PR was based on a very limited understanding of what was going on here and made the assumption that, with HDFS semantics, the code works properly. Later investigations (as in the comments) showed this wasn't the case and that this rename step is actually necessary.",
        "createdAt" : "2021-05-13T15:11:32Z",
        "updatedAt" : "2021-05-13T15:11:32Z",
        "lastEditedBy" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "tags" : [
        ]
      },
      {
        "id" : "7ff2e1c6-5475-4025-b41f-1168ec79a93a",
        "parentId" : "5f8e2bc3-ca1c-48c9-bcdd-365984ac665b",
        "authorId" : "d0706b4b-56e1-4a0a-a5a1-1f93c9c8ebd0",
        "body" : "Yes, [staging files for custom partition are under `.spark-staging...`](https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/internal/io/HadoopMapReduceCommitProtocol.scala#L149),  even when `dynamicPartitionOverwrite == false` ",
        "createdAt" : "2021-05-13T21:22:31Z",
        "updatedAt" : "2021-05-13T21:22:31Z",
        "lastEditedBy" : "d0706b4b-56e1-4a0a-a5a1-1f93c9c8ebd0",
        "tags" : [
        ]
      }
    ],
    "commit" : "68fd13176673f2b4fbcec54661fd7dcf8e900e39",
    "line" : 16,
    "diffHunk" : "@@ -1,1 +197,201 @@      absParentPaths.foreach(fs.mkdirs)\n      for ((src, dst) <- filesToMove) {\n        if (!fs.rename(new Path(src), new Path(dst))) {\n          throw new IOException(s\"Failed to rename $src to $dst when committing files staged for \" +\n            s\"absolute locations\")"
  },
  {
    "id" : "4a31427e-b2f1-449a-b463-6febb8b8f81e",
    "prId" : 32530,
    "prUrl" : "https://github.com/apache/spark/pull/32530#pullrequestreview-662703141",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f98e862a-c6ca-42e5-aea7-ae7f00cc3966",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "If `dynamicPartitionOverwrite == false`, we don't delete `absParentPaths`. Why do we always make dirs here?",
        "createdAt" : "2021-05-17T15:56:02Z",
        "updatedAt" : "2021-05-17T15:56:03Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "0001fc10-60dd-4639-b481-8487913c55ac",
        "parentId" : "f98e862a-c6ca-42e5-aea7-ae7f00cc3966",
        "authorId" : "d0706b4b-56e1-4a0a-a5a1-1f93c9c8ebd0",
        "body" : "It's in case that `absParentPaths` has never been created before the job.",
        "createdAt" : "2021-05-19T01:38:17Z",
        "updatedAt" : "2021-05-19T01:38:17Z",
        "lastEditedBy" : "d0706b4b-56e1-4a0a-a5a1-1f93c9c8ebd0",
        "tags" : [
        ]
      }
    ],
    "commit" : "68fd13176673f2b4fbcec54661fd7dcf8e900e39",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +195,199 @@      }\n      logDebug(s\"Create absolute parent directories: $absParentPaths\")\n      absParentPaths.foreach(fs.mkdirs)\n      for ((src, dst) <- filesToMove) {\n        if (!fs.rename(new Path(src), new Path(dst))) {"
  },
  {
    "id" : "fb83a371-c1b4-4036-afad-ca07d4493df5",
    "prId" : 29000,
    "prUrl" : "https://github.com/apache/spark/pull/29000#pullrequestreview-460637765",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ff261b18-2d41-4f14-970d-444f4a6e96db",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Could we make sure that we actually only support `dynamicPartitionOverwrite` with `FileOutputCommitter`?",
        "createdAt" : "2020-08-01T14:06:14Z",
        "updatedAt" : "2020-11-24T16:38:32Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "12392a76-59ae-49cc-8509-46f0591cd64f",
        "parentId" : "ff261b18-2d41-4f14-970d-444f4a6e96db",
        "authorId" : "19bcd642-216d-45ca-9e34-13e334fdc8fc",
        "body" : "Hmm, AFAIK yes, dynamicPartitionOverwrite only works for FileOutputCommitter, correct me if wrong :)",
        "createdAt" : "2020-08-02T16:13:26Z",
        "updatedAt" : "2020-11-24T16:38:32Z",
        "lastEditedBy" : "19bcd642-216d-45ca-9e34-13e334fdc8fc",
        "tags" : [
        ]
      },
      {
        "id" : "25daabc3-9019-42a8-98c4-e796aef9c436",
        "parentId" : "ff261b18-2d41-4f14-970d-444f4a6e96db",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "cc: @cloud-fan @turboFei ?",
        "createdAt" : "2020-08-04T09:14:00Z",
        "updatedAt" : "2020-11-24T16:38:32Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "85aa12a618ceadfe510a4f9fc3718a746a1bc357",
    "line" : 56,
    "diffHunk" : "@@ -1,1 +124,128 @@      // For FileOutputCommitter it has its own staging path called \"work path\".\n      case f: FileOutputCommitter =>\n        if (dynamicPartitionOverwrite) {\n          assert(dir.isDefined,\n            \"The dataset to be written must be partitioned when dynamicPartitionOverwrite is true.\")"
  },
  {
    "id" : "80110691-b9aa-4d2c-ba84-ba8ccf32a4e8",
    "prId" : 29000,
    "prUrl" : "https://github.com/apache/spark/pull/29000#pullrequestreview-477218500",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3b8ad848-6a14-4f4e-87a3-4a4c1530a89d",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "What about the case of `dynamicPartitionOverwrite=true` but `dir.isEmpty`?  IIUC, the workPath will be `/path/to/outputPath/.spark-staging-{jobId}/_temporary/{appAttemptId}/_temporary/{taskAttemptId}/` in this case. And it will be committed to `/path/to/outputPath/.spark-staging-{jobId}/` then. But it seems we don't move them to the `/path/to/outputPath/` in the end.",
        "createdAt" : "2020-08-27T16:14:08Z",
        "updatedAt" : "2020-11-24T16:38:32Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "edd93213-6cf3-45a3-a4d0-2a7fc1b1f1cd",
        "parentId" : "3b8ad848-6a14-4f4e-87a3-4a4c1530a89d",
        "authorId" : "19bcd642-216d-45ca-9e34-13e334fdc8fc",
        "body" : "IFAIKï¼Œ`assert(dir.isDefined, ...)` already avoid this case, `dir.isDefined` means` !dir.isEmpty`, correct me if wrong :)",
        "createdAt" : "2020-08-28T02:31:09Z",
        "updatedAt" : "2020-11-24T16:38:32Z",
        "lastEditedBy" : "19bcd642-216d-45ca-9e34-13e334fdc8fc",
        "tags" : [
        ]
      },
      {
        "id" : "2fd4d6a0-82bd-45f3-bb8b-f6e45ada2bc5",
        "parentId" : "3b8ad848-6a14-4f4e-87a3-4a4c1530a89d",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "oh, I see. My mistake.",
        "createdAt" : "2020-08-28T03:33:16Z",
        "updatedAt" : "2020-11-24T16:38:32Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "85aa12a618ceadfe510a4f9fc3718a746a1bc357",
    "line" : 61,
    "diffHunk" : "@@ -1,1 +129,133 @@          partitionPaths += dir.get\n        }\n        new Path(Option(f.getWorkPath).map(_.toString).getOrElse(path))\n      case _ => new Path(path)\n    }"
  },
  {
    "id" : "4a590d4d-1569-4469-a54e-08b561396ba9",
    "prId" : 29000,
    "prUrl" : "https://github.com/apache/spark/pull/29000#pullrequestreview-681881561",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e4872de2-4351-4288-983c-68f728e40897",
        "parentId" : null,
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "so this isn't the normal behavior of the algorithm version 2, right?  Normally it writes the task files directly to the final output location.  The whole point of algorithm 2 is to prevent all of the extra moves on the driver at the end of the job. For large jobs this time can be huge.   I'm not sure the benefit here of algorithm 2 because that is all happening distributed on each task?",
        "createdAt" : "2021-06-11T14:16:30Z",
        "updatedAt" : "2021-06-11T14:16:30Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      }
    ],
    "commit" : "85aa12a618ceadfe510a4f9fc3718a746a1bc357",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +56,60 @@ *                                  then move them to\n *                                  /path/to/outputPath/.spark-staging-{jobId}/a=1/b=1.\n *                                  2. When [[FileOutputCommitter]] algorithm version set to 2,\n *                                  committing tasks directly move task attempt output files to\n *                                  /path/to/outputPath/.spark-staging-{jobId}/a=1/b=1."
  }
]