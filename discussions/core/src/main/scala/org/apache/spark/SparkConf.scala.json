[
  {
    "id" : "5eae8605-2016-49e4-98fb-102ba3c626ad",
    "prId" : 29870,
    "prUrl" : "https://github.com/apache/spark/pull/29870#pullrequestreview-497385675",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d319515d-783f-4c63-af0a-54a467832fea",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Isn't it virtually same?",
        "createdAt" : "2020-09-27T08:40:55Z",
        "updatedAt" : "2020-09-27T08:40:55Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "7b6744d4-be58-4f28-b99f-d64a6aed4eb4",
        "parentId" : "d319515d-783f-4c63-af0a-54a467832fea",
        "authorId" : "da023277-487f-41ab-9359-5ee7378aba9e",
        "body" : "\"no less\" than is slightly confusing as the application fails if both values are same, hence changing it to greater. Please let me know if it makes sense. ",
        "createdAt" : "2020-09-27T15:56:54Z",
        "updatedAt" : "2020-09-27T15:56:54Z",
        "lastEditedBy" : "da023277-487f-41ab-9359-5ee7378aba9e",
        "tags" : [
        ]
      },
      {
        "id" : "0189671d-ef04-4f3d-87cf-64f63d175723",
        "parentId" : "d319515d-783f-4c63-af0a-54a467832fea",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Okay. it's probably because English isn't my first language. cc @srowen.",
        "createdAt" : "2020-09-28T03:54:08Z",
        "updatedAt" : "2020-09-28T03:54:09Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "e30fd780-8904-43cc-813e-04a8536419a1",
        "parentId" : "d319515d-783f-4c63-af0a-54a467832fea",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "\"no less\" would be \"greater than or equal to\" and the check does look for \"greater than\" so the correction is OK.",
        "createdAt" : "2020-09-28T06:33:35Z",
        "updatedAt" : "2020-09-28T06:33:36Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "64f2b578-e472-4bc6-848e-bcaa691c1655",
        "parentId" : "d319515d-783f-4c63-af0a-54a467832fea",
        "authorId" : "da023277-487f-41ab-9359-5ee7378aba9e",
        "body" : "@srowen Thanks for checking it out, yes, that was the intent. Could you please help in closing this PR? ",
        "createdAt" : "2020-09-28T10:33:12Z",
        "updatedAt" : "2020-09-28T10:33:13Z",
        "lastEditedBy" : "da023277-487f-41ab-9359-5ee7378aba9e",
        "tags" : [
        ]
      }
    ],
    "commit" : "b113ead148ac798f6652dc0c005d3e3c74e5af2e",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +569,573 @@    // it will almost always cause ExecutorLostFailure. See SPARK-22754.\n    require(executorTimeoutThresholdMs > executorHeartbeatIntervalMs, \"The value of \" +\n      s\"${networkTimeout}=${executorTimeoutThresholdMs}ms must be greater than the value of \" +\n      s\"${EXECUTOR_HEARTBEAT_INTERVAL.key}=${executorHeartbeatIntervalMs}ms.\")\n  }"
  },
  {
    "id" : "41977c23-1f64-48a5-b3e3-31229c10862e",
    "prId" : 27727,
    "prUrl" : "https://github.com/apache/spark/pull/27727#pullrequestreview-365904126",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "68293bb1-486c-4474-ab57-e4d7d32ce91b",
        "parentId" : null,
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "this is wrong, you are just saying the alternate config is the same as the current config.\r\nAre you just trying to remove spark.yarn.driver.memoryOverhead reference altogether?",
        "createdAt" : "2020-02-27T17:01:14Z",
        "updatedAt" : "2020-02-27T17:01:14Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      },
      {
        "id" : "5fa41c8b-a3fc-4083-8d53-7e40494bb46f",
        "parentId" : "68293bb1-486c-4474-ab57-e4d7d32ce91b",
        "authorId" : "f2b84c73-5fe1-4d69-9ebc-216d224cf406",
        "body" : "@tgravescs you're right, the idea t is to eliminate the old configuration for the following versions",
        "createdAt" : "2020-02-27T18:39:48Z",
        "updatedAt" : "2020-02-27T18:39:48Z",
        "lastEditedBy" : "f2b84c73-5fe1-4d69-9ebc-216d224cf406",
        "tags" : [
        ]
      }
    ],
    "commit" : "e3a2a7a83da7885a5dcd25e173b52ee606c28933",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +690,694 @@      AlternateConfig(\"spark.scheduler.listenerbus.eventqueue.size\", \"2.3\")),\n    DRIVER_MEMORY_OVERHEAD.key -> Seq(\n      AlternateConfig(\"spark.driver.memoryOverhead\", \"2.3\")),\n    EXECUTOR_MEMORY_OVERHEAD.key -> Seq(\n      AlternateConfig(\"spark.executor.memoryOverhead\", \"2.3\")),"
  }
]