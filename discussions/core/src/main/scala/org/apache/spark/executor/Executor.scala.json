[
  {
    "id" : "bf923002-0281-409d-97a4-a87b5e94aca3",
    "prId" : 30528,
    "prUrl" : "https://github.com/apache/spark/pull/30528#pullrequestreview-540413112",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a1831fde-d52f-4d16-839e-6d01fbf05b54",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Just in case, we are sure that OOM cannot be caused by a fatal error, and it cannot present somewhere in the chain?",
        "createdAt" : "2020-11-28T19:01:12Z",
        "updatedAt" : "2020-11-29T00:59:59Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "14cb17bb-ed68-4b66-9ad1-715941e42f1e",
        "parentId" : "a1831fde-d52f-4d16-839e-6d01fbf05b54",
        "authorId" : "2d6b46ba-4100-4c4d-9341-fff5e39647ec",
        "body" : "This is an existing behavior. #20014 added SparkOutOfMemoryError to avoid killing the executor when it's not thrown by JVM.",
        "createdAt" : "2020-11-28T19:39:47Z",
        "updatedAt" : "2020-11-29T00:59:59Z",
        "lastEditedBy" : "2d6b46ba-4100-4c4d-9341-fff5e39647ec",
        "tags" : [
        ]
      }
    ],
    "commit" : "312f0422f7c6379747762c0b2eaf523e76c96a9b",
    "line" : 46,
    "diffHunk" : "@@ -1,1 +1015,1019 @@    } else {\n      t match {\n        case _: SparkOutOfMemoryError => false\n        case e if Utils.isFatalError(e) => true\n        case e if e.getCause != null => isFatalError(e.getCause, depthToCheck - 1)"
  },
  {
    "id" : "5d67c2fc-42f3-41bd-8eca-800bf9132a19",
    "prId" : 29977,
    "prUrl" : "https://github.com/apache/spark/pull/29977#pullrequestreview-506644131",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e460bd20-d398-4db5-aa01-5c9cacb641a1",
        "parentId" : null,
        "authorId" : "8ecc847b-2206-4bed-9e78-8f539674d7cf",
        "body" : "Maybe we can make the `plugins` parameter optional or default to some `EmptyPluginContainer`?:\r\n```suggestion\r\n      private val plugins: Option[PluginContainer] = None)\r\n```",
        "createdAt" : "2020-10-08T16:04:13Z",
        "updatedAt" : "2020-10-15T10:29:34Z",
        "lastEditedBy" : "8ecc847b-2206-4bed-9e78-8f539674d7cf",
        "tags" : [
        ]
      },
      {
        "id" : "aa24728c-c234-418c-9dd8-d6c3178703d0",
        "parentId" : "e460bd20-d398-4db5-aa01-5c9cacb641a1",
        "authorId" : "8ecc847b-2206-4bed-9e78-8f539674d7cf",
        "body" : "Same for `Task#run`.",
        "createdAt" : "2020-10-08T16:04:18Z",
        "updatedAt" : "2020-10-15T10:29:34Z",
        "lastEditedBy" : "8ecc847b-2206-4bed-9e78-8f539674d7cf",
        "tags" : [
        ]
      },
      {
        "id" : "c187593e-d9f9-4156-a62c-9b874ff6de34",
        "parentId" : "e460bd20-d398-4db5-aa01-5c9cacb641a1",
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "@rshkv, what is the reason to make this default to None?  This is an internal api and only called from here. It's an option already so people can check it easily.  In some ways its nice to force it so you make sure all uses of it have been updated.  \r\nAre there cases you know this is used outside Spark?",
        "createdAt" : "2020-10-12T14:11:31Z",
        "updatedAt" : "2020-10-15T10:29:34Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      }
    ],
    "commit" : "8a5e43671b3ffc16a6d3630886027cde97380558",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +334,338 @@      execBackend: ExecutorBackend,\n      private val taskDescription: TaskDescription,\n      private val plugins: Option[PluginContainer])\n    extends Runnable {\n"
  },
  {
    "id" : "70d3ad35-78eb-48e2-8a50-5505e5761d31",
    "prId" : 28528,
    "prUrl" : "https://github.com/apache/spark/pull/28528#pullrequestreview-542200983",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dfaba7bf-0b65-43d8-bcf4-212423bc1d3d",
        "parentId" : null,
        "authorId" : "2d6b46ba-4100-4c4d-9341-fff5e39647ec",
        "body" : "Nit: Looks like this one is never been cleaned. It would be great to avoid using a global `executorSourceLocalModeOnly` to save a state of a specific executor. Can we move this to SparkEnv so that a state of one test won't be leaked to other tests?",
        "createdAt" : "2020-11-28T17:59:27Z",
        "updatedAt" : "2020-11-28T17:59:27Z",
        "lastEditedBy" : "2d6b46ba-4100-4c4d-9341-fff5e39647ec",
        "tags" : [
        ]
      },
      {
        "id" : "0958e1fb-a61b-4797-930f-5175638486e2",
        "parentId" : "dfaba7bf-0b65-43d8-bcf4-212423bc1d3d",
        "authorId" : "acf5aefc-4c46-451e-a28d-492ceaffd160",
        "body" : "Thanks @zsxwing , I'll have a look at it.",
        "createdAt" : "2020-12-01T18:54:16Z",
        "updatedAt" : "2020-12-01T18:54:17Z",
        "lastEditedBy" : "acf5aefc-4c46-451e-a28d-492ceaffd160",
        "tags" : [
        ]
      }
    ],
    "commit" : "c8ce5a31cd64e23496984c9f06f41675384aeca1",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +987,991 @@\n  // Used to store executorSource, for local mode only\n  var executorSourceLocalModeOnly: ExecutorSource = null\n}"
  },
  {
    "id" : "f3d0ec55-79f8-4d31-bac1-3d97e8cd9be4",
    "prId" : 26624,
    "prUrl" : "https://github.com/apache/spark/pull/26624#pullrequestreview-406046075",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "74646889-435c-41e7-8372-b7d5d811b3bf",
        "parentId" : null,
        "authorId" : "bc001dd4-5224-4ca1-afdd-49d69783d7f2",
        "body" : "nit: remove this empty line.",
        "createdAt" : "2020-05-05T18:01:10Z",
        "updatedAt" : "2020-05-19T06:04:49Z",
        "lastEditedBy" : "bc001dd4-5224-4ca1-afdd-49d69783d7f2",
        "tags" : [
        ]
      },
      {
        "id" : "aa850303-431e-4e92-b4ab-8882085e7ad3",
        "parentId" : "74646889-435c-41e7-8372-b7d5d811b3bf",
        "authorId" : "d26e612c-2d3f-45a5-bb51-33e844905a11",
        "body" : "Done",
        "createdAt" : "2020-05-05T18:25:12Z",
        "updatedAt" : "2020-05-19T06:04:49Z",
        "lastEditedBy" : "d26e612c-2d3f-45a5-bb51-33e844905a11",
        "tags" : [
        ]
      }
    ],
    "commit" : "d5c1aa97bd69a25de5de03ec79284f39dace3198",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +402,406 @@\n    override def run(): Unit = {\n\n      setMDCForTask(taskName, mdcProperties)\n"
  },
  {
    "id" : "4d5c2e17-9749-4bae-b531-62e2b1b4325b",
    "prId" : 26170,
    "prUrl" : "https://github.com/apache/spark/pull/26170#pullrequestreview-309509434",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c1640bbf-9bc6-4c81-a5ae-8989df71f0e5",
        "parentId" : null,
        "authorId" : "acf5aefc-4c46-451e-a28d-492ceaffd160",
        "body" : "I am not sure that plugins should be loaded at this stage when running in local mode, maybe only the driver side of the plugin is sufficient in local mode?\r\nMetrics source registration at this stage, when executed in local mode, will not get the application id. Other metrics handled in executors.scala are not registered when running in local mode.\r\nThe current implementation of executor plugins sends a \"isLocal boolean\" via the pluginContext to handle this case in the plugin logic.",
        "createdAt" : "2019-10-30T20:07:43Z",
        "updatedAt" : "2019-10-30T20:07:43Z",
        "lastEditedBy" : "acf5aefc-4c46-451e-a28d-492ceaffd160",
        "tags" : [
        ]
      },
      {
        "id" : "09623e96-45fa-4ae0-bda2-27303bc13858",
        "parentId" : "c1640bbf-9bc6-4c81-a5ae-8989df71f0e5",
        "authorId" : "0b3111e2-9584-4813-8cb5-8f40e119f71c",
        "body" : "You can check if you're running in local mode by looking at the spark.master value. I intentionally did not add to the API since it would be redundant.\r\n\r\nI'm also not especially worried about local mode. It's mostly for debugging. If something doesn't work 100% as intended for plugins, I'm totally fine with it.",
        "createdAt" : "2019-10-30T20:34:43Z",
        "updatedAt" : "2019-10-30T20:34:43Z",
        "lastEditedBy" : "0b3111e2-9584-4813-8cb5-8f40e119f71c",
        "tags" : [
        ]
      },
      {
        "id" : "a4cf40d3-fdb6-4279-9058-81e5de2fc385",
        "parentId" : "c1640bbf-9bc6-4c81-a5ae-8989df71f0e5",
        "authorId" : "acf5aefc-4c46-451e-a28d-492ceaffd160",
        "body" : "Indeed, that should be fine.",
        "createdAt" : "2019-10-30T20:45:21Z",
        "updatedAt" : "2019-10-30T20:45:22Z",
        "lastEditedBy" : "acf5aefc-4c46-451e-a28d-492ceaffd160",
        "tags" : [
        ]
      }
    ],
    "commit" : "37ad680ec33ec6afac9d031897a549321e782d9c",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +168,172 @@\n  // Plugins need to load using a class loader that includes the executor's user classpath\n  private val plugins: Option[PluginContainer] = Utils.withContextClassLoader(replClassLoader) {\n    PluginContainer(env)\n  }"
  },
  {
    "id" : "d271c82a-8e6d-4b42-a633-ca8a80b96e9d",
    "prId" : 25634,
    "prUrl" : "https://github.com/apache/spark/pull/25634#pullrequestreview-282321271",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0bd4c3d0-1ee1-4b42-8167-365e9a09e685",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Hi, @iRakson . At the PR description, could you describe your reason why this should be `INFO`?",
        "createdAt" : "2019-08-30T16:43:41Z",
        "updatedAt" : "2019-08-30T16:43:42Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "9ee1d20a-279f-4f93-987d-6de1501c3123",
        "parentId" : "0bd4c3d0-1ee1-4b42-8167-365e9a09e685",
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "It sounds reasonable to use logInfo for this message. The message is only shown once for each executor. Debug level might be too low here. ",
        "createdAt" : "2019-08-31T22:10:31Z",
        "updatedAt" : "2019-08-31T22:10:32Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      }
    ],
    "commit" : "069e4abf41263daef571f7465d06e89220fac6c0",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +140,144 @@    val pluginNames = conf.get(EXECUTOR_PLUGINS)\n    if (pluginNames.nonEmpty) {\n      logInfo(s\"Initializing the following plugins: ${pluginNames.mkString(\", \")}\")\n\n      // Plugins need to load using a class loader that includes the executor's user classpath"
  }
]