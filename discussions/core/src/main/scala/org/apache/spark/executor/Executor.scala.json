[
  {
    "id" : "bf923002-0281-409d-97a4-a87b5e94aca3",
    "prId" : 30528,
    "prUrl" : "https://github.com/apache/spark/pull/30528#pullrequestreview-540413112",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a1831fde-d52f-4d16-839e-6d01fbf05b54",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Just in case, we are sure that OOM cannot be caused by a fatal error, and it cannot present somewhere in the chain?",
        "createdAt" : "2020-11-28T19:01:12Z",
        "updatedAt" : "2020-11-29T00:59:59Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "14cb17bb-ed68-4b66-9ad1-715941e42f1e",
        "parentId" : "a1831fde-d52f-4d16-839e-6d01fbf05b54",
        "authorId" : "2d6b46ba-4100-4c4d-9341-fff5e39647ec",
        "body" : "This is an existing behavior. #20014 added SparkOutOfMemoryError to avoid killing the executor when it's not thrown by JVM.",
        "createdAt" : "2020-11-28T19:39:47Z",
        "updatedAt" : "2020-11-29T00:59:59Z",
        "lastEditedBy" : "2d6b46ba-4100-4c4d-9341-fff5e39647ec",
        "tags" : [
        ]
      }
    ],
    "commit" : "312f0422f7c6379747762c0b2eaf523e76c96a9b",
    "line" : 46,
    "diffHunk" : "@@ -1,1 +1015,1019 @@    } else {\n      t match {\n        case _: SparkOutOfMemoryError => false\n        case e if Utils.isFatalError(e) => true\n        case e if e.getCause != null => isFatalError(e.getCause, depthToCheck - 1)"
  },
  {
    "id" : "5d67c2fc-42f3-41bd-8eca-800bf9132a19",
    "prId" : 29977,
    "prUrl" : "https://github.com/apache/spark/pull/29977#pullrequestreview-506644131",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e460bd20-d398-4db5-aa01-5c9cacb641a1",
        "parentId" : null,
        "authorId" : "8ecc847b-2206-4bed-9e78-8f539674d7cf",
        "body" : "Maybe we can make the `plugins` parameter optional or default to some `EmptyPluginContainer`?:\r\n```suggestion\r\n      private val plugins: Option[PluginContainer] = None)\r\n```",
        "createdAt" : "2020-10-08T16:04:13Z",
        "updatedAt" : "2020-10-15T10:29:34Z",
        "lastEditedBy" : "8ecc847b-2206-4bed-9e78-8f539674d7cf",
        "tags" : [
        ]
      },
      {
        "id" : "aa24728c-c234-418c-9dd8-d6c3178703d0",
        "parentId" : "e460bd20-d398-4db5-aa01-5c9cacb641a1",
        "authorId" : "8ecc847b-2206-4bed-9e78-8f539674d7cf",
        "body" : "Same for `Task#run`.",
        "createdAt" : "2020-10-08T16:04:18Z",
        "updatedAt" : "2020-10-15T10:29:34Z",
        "lastEditedBy" : "8ecc847b-2206-4bed-9e78-8f539674d7cf",
        "tags" : [
        ]
      },
      {
        "id" : "c187593e-d9f9-4156-a62c-9b874ff6de34",
        "parentId" : "e460bd20-d398-4db5-aa01-5c9cacb641a1",
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "@rshkv, what is the reason to make this default to None?  This is an internal api and only called from here. It's an option already so people can check it easily.  In some ways its nice to force it so you make sure all uses of it have been updated.  \r\nAre there cases you know this is used outside Spark?",
        "createdAt" : "2020-10-12T14:11:31Z",
        "updatedAt" : "2020-10-15T10:29:34Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      }
    ],
    "commit" : "8a5e43671b3ffc16a6d3630886027cde97380558",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +334,338 @@      execBackend: ExecutorBackend,\n      private val taskDescription: TaskDescription,\n      private val plugins: Option[PluginContainer])\n    extends Runnable {\n"
  },
  {
    "id" : "70d3ad35-78eb-48e2-8a50-5505e5761d31",
    "prId" : 28528,
    "prUrl" : "https://github.com/apache/spark/pull/28528#pullrequestreview-542200983",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dfaba7bf-0b65-43d8-bcf4-212423bc1d3d",
        "parentId" : null,
        "authorId" : "2d6b46ba-4100-4c4d-9341-fff5e39647ec",
        "body" : "Nit: Looks like this one is never been cleaned. It would be great to avoid using a global `executorSourceLocalModeOnly` to save a state of a specific executor. Can we move this to SparkEnv so that a state of one test won't be leaked to other tests?",
        "createdAt" : "2020-11-28T17:59:27Z",
        "updatedAt" : "2020-11-28T17:59:27Z",
        "lastEditedBy" : "2d6b46ba-4100-4c4d-9341-fff5e39647ec",
        "tags" : [
        ]
      },
      {
        "id" : "0958e1fb-a61b-4797-930f-5175638486e2",
        "parentId" : "dfaba7bf-0b65-43d8-bcf4-212423bc1d3d",
        "authorId" : "acf5aefc-4c46-451e-a28d-492ceaffd160",
        "body" : "Thanks @zsxwing , I'll have a look at it.",
        "createdAt" : "2020-12-01T18:54:16Z",
        "updatedAt" : "2020-12-01T18:54:17Z",
        "lastEditedBy" : "acf5aefc-4c46-451e-a28d-492ceaffd160",
        "tags" : [
        ]
      }
    ],
    "commit" : "c8ce5a31cd64e23496984c9f06f41675384aeca1",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +987,991 @@\n  // Used to store executorSource, for local mode only\n  var executorSourceLocalModeOnly: ExecutorSource = null\n}"
  }
]