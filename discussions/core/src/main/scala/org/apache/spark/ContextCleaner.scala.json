[
  {
    "id" : "fc5ab280-9e2c-448e-a47e-fa84bce35337",
    "prId" : 32877,
    "prUrl" : "https://github.com/apache/spark/pull/32877#pullrequestreview-681954969",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d8f37eb5-bec8-49dc-b2a1-542996a791b8",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Hm, the issue is that remove() blocks indefinitely, so this would never let it check `stopped` again if nothing is in the queue?",
        "createdAt" : "2021-06-11T12:41:41Z",
        "updatedAt" : "2021-06-11T12:41:41Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "19586f45-c8d2-47f1-a1da-d9b5578722d8",
        "parentId" : "d8f37eb5-bec8-49dc-b2a1-542996a791b8",
        "authorId" : "6a8d0007-eb0f-4236-a65a-2174a14ac689",
        "body" : "Hm, This is a issue too, I'm thinking, `while (!stopped)` means `while (true)`  if there is no stop all the time, the will lead to some ineffective loop, I'm not sure if there are some ineffective effects?",
        "createdAt" : "2021-06-11T13:57:30Z",
        "updatedAt" : "2021-06-11T13:57:30Z",
        "lastEditedBy" : "6a8d0007-eb0f-4236-a65a-2174a14ac689",
        "tags" : [
        ]
      },
      {
        "id" : "82fa50a1-ede7-4bdb-ae10-35c1ed87f91f",
        "parentId" : "d8f37eb5-bec8-49dc-b2a1-542996a791b8",
        "authorId" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "body" : "+1 with @srowen -- it seems to me that the current behavior is intentional, to allow for periodic checking of `stopped` to allow for the loop to exit. ",
        "createdAt" : "2021-06-11T15:25:46Z",
        "updatedAt" : "2021-06-11T15:25:46Z",
        "lastEditedBy" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "tags" : [
        ]
      }
    ],
    "commit" : "303fcfcd50c40bc54473cb6bb8423ab6403be1c0",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +189,193 @@    while (!stopped) {\n      try {\n        val reference = Option(referenceQueue.remove())\n          .map(_.asInstanceOf[CleanupTaskWeakReference])\n        // Synchronize here to avoid being interrupted on stop()"
  },
  {
    "id" : "5077b94b-42a1-44e1-9bfd-d79f54f9b639",
    "prId" : 31919,
    "prUrl" : "https://github.com/apache/spark/pull/31919#pullrequestreview-617181296",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e8672f0c-1a5b-4d5d-b8be-0c4d13f7563a",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Hi, @Ngone51 . Could you revert the change in this file?",
        "createdAt" : "2021-03-22T03:18:14Z",
        "updatedAt" : "2021-03-23T05:05:01Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "13e03450-ea35-49bf-b0e2-6d5b227ed8af",
        "parentId" : "e8672f0c-1a5b-4d5d-b8be-0c4d13f7563a",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Hi @dongjoon-hyun,  this change intends to let the newly added  `registerSparkListenerForCleanup()` follow the same placement with other `register...ForCleanup` methods. This would make the `ContextCleaner` looks neater. \r\n\r\nThis is a style mistake made in the original PR so I fixed it in this follow-up PR. Does it sound ok to you?",
        "createdAt" : "2021-03-22T04:02:56Z",
        "updatedAt" : "2021-03-23T05:05:01Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "e986a032-6f40-4b2c-9166-8e320aa99818",
        "parentId" : "e8672f0c-1a5b-4d5d-b8be-0c4d13f7563a",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Got it.",
        "createdAt" : "2021-03-22T06:26:29Z",
        "updatedAt" : "2021-03-23T05:05:01Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "ae5d5d669d290de486a4ba473505a753263fb993",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +184,188 @@    referenceBuffer.add(new CleanupTaskWeakReference(task, objectForCleanup, referenceQueue))\n  }\n\n  /** Keep cleaning RDD, shuffle, and broadcast state. */\n  private def keepCleaning(): Unit = Utils.tryOrStopSparkContext(sc) {"
  },
  {
    "id" : "9a7112b3-d556-411e-8b3d-2972307a5b05",
    "prId" : 31839,
    "prUrl" : "https://github.com/apache/spark/pull/31839#pullrequestreview-612501220",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "29e301b3-ec6b-4085-bde4-d715e1d84f46",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Maybe, shall we add a post-log?\r\n```scala\r\nlogDebug(s\"Cleaned Spark listener $listener\")\r\n```",
        "createdAt" : "2021-03-15T18:08:08Z",
        "updatedAt" : "2021-03-17T14:31:40Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "9e81427eb7ac351d7511c0abec6d189eb7b9fbff",
    "line" : 46,
    "diffHunk" : "@@ -1,1 +291,295 @@    try {\n      logDebug(s\"Cleaning Spark listener $listener\")\n      sc.listenerBus.removeListener(listener)\n      logDebug(s\"Cleaned Spark listener $listener\")\n    } catch {"
  },
  {
    "id" : "1f9911ef-280a-457c-bee6-c4c863475bd7",
    "prId" : 31839,
    "prUrl" : "https://github.com/apache/spark/pull/31839#pullrequestreview-612868908",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1018c52d-724a-48dc-af7a-83bcceff70d8",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Does logging `$listener` show meaningful message? It is not like other cases like clean up RDD (rdd id), or clean up broadcast (broadcast id).",
        "createdAt" : "2021-03-16T05:20:41Z",
        "updatedAt" : "2021-03-17T14:31:40Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "eb17e14f-39eb-43c0-93f6-36ed8db9ada9",
        "parentId" : "1018c52d-724a-48dc-af7a-83bcceff70d8",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "It logs the qualified class name and JVM object id of that listener, e.g.,\r\n\r\n> Cleaning Spark listener org.apache.spark.sql.util.ExecutionListenerBus@54600fe\r\n\r\nI think it's enough for users to know which listener is removed.\r\n\r\nOthers log their own ids because users can track them by analyzing the logs since Spark logs those ids in other places too. But Spark doesn't do that for listeners (and the listener itself doesn't have such an identifier or something else) so it should be enough for now. ",
        "createdAt" : "2021-03-16T05:42:33Z",
        "updatedAt" : "2021-03-17T14:31:40Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "9e81427eb7ac351d7511c0abec6d189eb7b9fbff",
    "line" : 45,
    "diffHunk" : "@@ -1,1 +290,294 @@  def doCleanSparkListener(listener: SparkListener): Unit = {\n    try {\n      logDebug(s\"Cleaning Spark listener $listener\")\n      sc.listenerBus.removeListener(listener)\n      logDebug(s\"Cleaned Spark listener $listener\")"
  },
  {
    "id" : "ff9d1da9-4ec0-4112-9cd7-9ca0ba71247d",
    "prId" : 31742,
    "prUrl" : "https://github.com/apache/spark/pull/31742#pullrequestreview-609687053",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bbb044f9-d4d7-4668-8ce4-9cd85e8118e5",
        "parentId" : null,
        "authorId" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "body" : "How are shuffles cleaned? ",
        "createdAt" : "2021-03-10T19:58:56Z",
        "updatedAt" : "2021-03-10T19:58:56Z",
        "lastEditedBy" : "80d631a6-73e8-46a6-a01b-a80d1f1cc6cc",
        "tags" : [
        ]
      },
      {
        "id" : "a698ebb5-4cc8-43d5-8e21-7b0dfdee647f",
        "parentId" : "bbb044f9-d4d7-4668-8ce4-9cd85e8118e5",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Shuffle files are handled by `DiskBlockManager`.",
        "createdAt" : "2021-03-11T12:03:38Z",
        "updatedAt" : "2021-03-11T12:03:39Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "ee6782bd376c0ea7ec720dabc436b9bb69a69651",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +220,224 @@    .foreach { ref =>\n      ref.task match {\n        case CleanCheckpoint(rddId) =>\n          doCleanCheckpoint(rddId)\n        case _ =>"
  },
  {
    "id" : "27318989-933a-48cf-9dbc-fe32ad52a868",
    "prId" : 30131,
    "prUrl" : "https://github.com/apache/spark/pull/30131#pullrequestreview-514582335",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "64b832bb-c898-4701-91fe-60d1af273258",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "This looks like a reasonable change to me.",
        "createdAt" : "2020-10-22T10:31:09Z",
        "updatedAt" : "2020-11-26T00:49:06Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "5643ec267a339877c1004aae9e1ed8ae1f8f6cca",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +127,131 @@    cleaningThread.setName(\"Spark Context Cleaner\")\n    cleaningThread.start()\n    periodicGCService.scheduleWithFixedDelay(() => System.gc(),\n      periodicGCInterval, periodicGCInterval, TimeUnit.SECONDS)\n  }"
  },
  {
    "id" : "50c0c693-cef8-482f-aba1-0098e37037fb",
    "prId" : 28618,
    "prUrl" : "https://github.com/apache/spark/pull/28618#pullrequestreview-471250144",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f613174d-881f-4a60-9b87-0d8de5927395",
        "parentId" : null,
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "Why was the containsShuffle check removed ?",
        "createdAt" : "2020-08-20T05:28:42Z",
        "updatedAt" : "2020-10-17T18:44:19Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      }
    ],
    "commit" : "f69cba7d0632e7b260e38a0aa16cf560bd0d94cc",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +221,225 @@  def doCleanupShuffle(shuffleId: Int, blocking: Boolean): Unit = {\n    try {\n      logDebug(\"Cleaning shuffle \" + shuffleId)\n      val shuffleRemoved = mapOutputTrackerMaster.unregisterShuffle(shuffleId, blocking)\n      if (shuffleRemoved) {"
  }
]