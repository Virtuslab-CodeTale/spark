[
  {
    "id" : "6b1f8548-a67d-42ee-be42-b6d8af3f9c42",
    "prId" : 28085,
    "prUrl" : "https://github.com/apache/spark/pull/28085#pullrequestreview-392955643",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5a01493b-0a1a-4549-b8e6-8213570f3c04",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Can I ask why we divide Python worker's memory by the number of cores? ",
        "createdAt" : "2020-04-13T06:03:06Z",
        "updatedAt" : "2020-04-22T14:03:45Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "db2b70c8-7323-4541-b035-1bdbaeb56104",
        "parentId" : "5a01493b-0a1a-4549-b8e6-8213570f3c04",
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "this was preexisting functionality (https://github.com/apache/spark/pull/28085/files#diff-6bc32eb2bef385137d7c16fc2c75e8b4L88) , I just changed to make it work with the resource profiles. From my understanding its just splitting the memory equally because you get a python worker per task. I thought the comment did decent job of relaying that, but maybe we need to clarify?    Thinking about this some more, there might actually be a bug here (was here before my changes) if the spark.task.cpus is > 1 because the max tasks you get couldn't be equal to number of cores, so your are splitting the memory to much.  I can file a separate jira to look at that though.",
        "createdAt" : "2020-04-13T16:32:03Z",
        "updatedAt" : "2020-04-22T14:03:45Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      },
      {
        "id" : "f0b3578d-1c5f-478a-8212-394cab50c3aa",
        "parentId" : "5a01493b-0a1a-4549-b8e6-8213570f3c04",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Yes ... let's just loop this in a separate JIRA if you don't mind.\r\n\r\nI wary of this Python memory configuration which needed a bunch of followups and separate investigation (see SPARK-25004) when it was first added. This configuration also made Spark 2.4.0 useless on Windows (SPARK-26080).\r\n\r\nThis configuration is even incomplete and conflicts with 'spark.python.worker.memory' configuration, see also SPARK-26679.\r\n\r\n",
        "createdAt" : "2020-04-14T00:51:29Z",
        "updatedAt" : "2020-04-22T14:03:45Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "799f8119-fe8a-4f35-8bbc-01c541c370a5",
        "parentId" : "5a01493b-0a1a-4549-b8e6-8213570f3c04",
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "https://issues.apache.org/jira/browse/SPARK-31444",
        "createdAt" : "2020-04-14T14:00:26Z",
        "updatedAt" : "2020-04-22T14:03:45Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      }
    ],
    "commit" : "354fb0c09ff9ed6be985f0ca7a8b6fae835303a2",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +108,112 @@  // number of concurrent tasks, which is determined by the number of cores in this executor.\n  private def getWorkerMemoryMb(mem: Option[Long], cores: Int): Option[Long] = {\n    mem.map(_ / cores)\n  }\n"
  },
  {
    "id" : "deb4fc86-e5a2-4ee9-8c85-e016cf60cdb6",
    "prId" : 27951,
    "prUrl" : "https://github.com/apache/spark/pull/27951#pullrequestreview-377112442",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b5a6b5f2-d6ef-4c92-bdb4-55767c0691d9",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "You probably don't even need these types here and below, but it won't matter",
        "createdAt" : "2020-03-18T18:03:39Z",
        "updatedAt" : "2020-03-18T18:03:41Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      }
    ],
    "commit" : "baab9655153a1c20bfc8831c54dbf8b19e644e7d",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +421,425 @@            result = BarrierTaskContextMessageProtocol.BARRIER_RESULT_SUCCESS\n          case BarrierTaskContextMessageProtocol.ALL_GATHER_FUNCTION =>\n            val messages: Array[String] = context.asInstanceOf[BarrierTaskContext].allGather(\n              message\n            )"
  },
  {
    "id" : "2783ca03-a833-4ca8-80cc-92fb71cb9f30",
    "prId" : 26953,
    "prUrl" : "https://github.com/apache/spark/pull/26953#pullrequestreview-578856679",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "51331037-a3cd-48fb-86d0-a979868dd513",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Have a couple of questions. \r\n\r\n- Is it possible to merge it with `SQLMetric`? It would be nicer if UI shows it as well.\r\n- Is it possible to integrate with existing Python profiler? The current read time isn't purely Python execution time. It includes socket IO time which can potentially be large.",
        "createdAt" : "2020-01-17T06:27:11Z",
        "updatedAt" : "2020-11-13T09:19:59Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "a0dbe594-513c-46ad-982e-f48c6221cfc8",
        "parentId" : "51331037-a3cd-48fb-86d0-a979868dd513",
        "authorId" : "acf5aefc-4c46-451e-a28d-492ceaffd160",
        "body" : "- I like the idea of adding SQLMetrics for Python UDF instrumentation and use them in the WEBUI. However, I think the work would rather fit for a separate JIRA/PR. The implementation details and the overhead of SQLMetrics are different from Dropwizard-based metrics, so probably we would like to have only a limited number of SQLMetrics instrumenting task activities in this area. Also the implementation of SQLMetrics for `[[PythonUDF]]` execution may require some important changes to the current plan evaluation code.\r\n\r\n- It is indeed the case that the “read time from worker” which is exposed to the users via the dropwizard library as “FetchResultsTimeFromWorkers” contains both socket I/O + deserialization time and Python UDF execution time. Measuring on the Python side could allow to separate the 2 time components, however currently I don’t see how to make a lightweight implementation for that. Python profiler has the possibility to measure on the Python side as you mentioned, but I see its usage more for debugging, while the proposed instrumentation is lightweight and intended to be used for production use cases too. Maybe future work can address this case if there is need?\r\n",
        "createdAt" : "2020-01-22T16:07:06Z",
        "updatedAt" : "2020-11-13T09:19:59Z",
        "lastEditedBy" : "acf5aefc-4c46-451e-a28d-492ceaffd160",
        "tags" : [
        ]
      },
      {
        "id" : "429d813b-f4c4-4813-91a1-a1b68b8e7c26",
        "parentId" : "51331037-a3cd-48fb-86d0-a979868dd513",
        "authorId" : "acf5aefc-4c46-451e-a28d-492ceaffd160",
        "body" : "@HyukjinKwon I have finally managed to work on your suggestion to instrument Python execution using SQL Metrics, so that users can see the metrics via the WebUI. See [SPARK-34265]. I imagine that I could later refactor the work on this PR based on that.",
        "createdAt" : "2021-01-27T16:06:56Z",
        "updatedAt" : "2021-01-27T16:06:56Z",
        "lastEditedBy" : "acf5aefc-4c46-451e-a28d-492ceaffd160",
        "tags" : [
        ]
      },
      {
        "id" : "974e71cf-70bb-4896-b700-ab5d98d00608",
        "parentId" : "51331037-a3cd-48fb-86d0-a979868dd513",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "PR link: https://github.com/apache/spark/pull/31367",
        "createdAt" : "2021-01-29T00:39:34Z",
        "updatedAt" : "2021-01-29T00:39:34Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "750b973b8e810572c7a15e5251d56d6c58066661",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +479,483 @@        nextObj = read()\n        val deltaTime = System.nanoTime()-startTime\n        PythonMetrics.incFromWorkerReadTime(deltaTime)\n        hasNext\n      } else {"
  }
]