[
  {
    "id" : "f29cb0ce-744b-4f2a-9468-566f8cbf1abe",
    "prId" : 28187,
    "prUrl" : "https://github.com/apache/spark/pull/28187#pullrequestreview-391741671",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e90148a4-dd95-4880-be4a-571b30fe9e83",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Although only `getStorageStatus` is used, I added the preventive code into `getMemoryStatus` together.",
        "createdAt" : "2020-04-11T06:38:58Z",
        "updatedAt" : "2020-04-11T08:11:29Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "82e46a868fabb00a0e2f6cb140d22d4dd35c33e5",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +168,172 @@   */\n  def getMemoryStatus: Map[BlockManagerId, (Long, Long)] = {\n    if (driverEndpoint == null) return Map.empty\n    driverEndpoint.askSync[Map[BlockManagerId, (Long, Long)]](GetMemoryStatus)\n  }"
  },
  {
    "id" : "3401350a-5a93-4d71-bf56-1e88a8f35fd6",
    "prId" : 26826,
    "prUrl" : "https://github.com/apache/spark/pull/26826#pullrequestreview-329568259",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fef644fc-768c-4c9d-a083-107824d6e784",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "immutable.Iterable seems to have been the right-er choice for CanBuildFrom here; doesn't require overriding the generic types. It didn't compile otherwise in 2.13.",
        "createdAt" : "2019-12-10T03:16:07Z",
        "updatedAt" : "2019-12-11T17:33:36Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      }
    ],
    "commit" : "d24ed2171587ddaf3a5986d4bdfd8779116c1d2a",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +202,206 @@        Iterable[Option[BlockStatus]]]]\n    val blockStatus = timeout.awaitResult(\n      Future.sequence(futures)(cbf, ThreadUtils.sameThread))\n    if (blockStatus == null) {\n      throw new SparkException(\"BlockManager returned null for BlockStatus query: \" + blockId)"
  }
]