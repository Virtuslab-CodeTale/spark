[
  {
    "id" : "a9a4621d-fe77-4964-a6ae-dea1572a4da4",
    "prId" : 26953,
    "prUrl" : "https://github.com/apache/spark/pull/26953#pullrequestreview-397615994",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "caf1c1e1-1184-47c1-9271-bc735568048b",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "So, these metrics are incremental across all JVM-Python and Python UDFs in single Spark app?",
        "createdAt" : "2020-04-18T16:54:38Z",
        "updatedAt" : "2020-11-13T09:19:59Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "3006dfdc-9c53-457d-b002-0e1e4accd234",
        "parentId" : "caf1c1e1-1184-47c1-9271-bc735568048b",
        "authorId" : "acf5aefc-4c46-451e-a28d-492ceaffd160",
        "body" : "Correct. The metrics values are cumulative, measured and reported for each executor, on the same spirit of other metrics in the metrics system like `cpuTime.count` `runTime.count`, etc.",
        "createdAt" : "2020-04-21T19:37:41Z",
        "updatedAt" : "2020-11-13T09:19:59Z",
        "lastEditedBy" : "acf5aefc-4c46-451e-a28d-492ceaffd160",
        "tags" : [
        ]
      }
    ],
    "commit" : "750b973b8e810572c7a15e5251d56d6c58066661",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +20,24 @@import java.util.concurrent.atomic.AtomicLong\n\nprivate[spark] object PythonMetrics {\n\n  // Instrument with general metrics on serialization/deserialization JVM-to-Python"
  }
]