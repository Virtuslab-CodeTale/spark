[
  {
    "id" : "d7ebc8ef-081c-4f48-9085-64561cde6bc5",
    "prId" : 32526,
    "prUrl" : "https://github.com/apache/spark/pull/32526#pullrequestreview-663634581",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a24cda71-7570-42e5-8c19-9f5383c9e226",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Is the case of 0 different from >1 here? If there is >1 do you want to remove something anyway?",
        "createdAt" : "2021-05-15T17:41:14Z",
        "updatedAt" : "2021-05-15T17:41:14Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "62cf9e3a-7bda-403c-b8d0-dff3ee2b4435",
        "parentId" : "a24cda71-7570-42e5-8c19-9f5383c9e226",
        "authorId" : "607c2c93-3680-41e7-baaf-dc5887b76b9f",
        "body" : "I'm not sure. This behaviour was there before and it is not directly related to the bug.",
        "createdAt" : "2021-05-19T20:31:47Z",
        "updatedAt" : "2021-05-19T20:31:47Z",
        "lastEditedBy" : "607c2c93-3680-41e7-baaf-dc5887b76b9f",
        "tags" : [
        ]
      }
    ],
    "commit" : "887cbfb01dec1d417571b4f416b7ec5150e1e506",
    "line" : 53,
    "diffHunk" : "@@ -1,1 +867,871 @@          resourceProfileIdToStageAttempt(rpForStage.head) -= stageAttempt\n        } else {\n          logWarning(s\"Should have exactly one resource profile for stage $stageAttempt,\" +\n              s\" but have $rpForStage\")\n        }"
  },
  {
    "id" : "1c8f1b6b-f5f3-409a-a5da-6c5f319845c3",
    "prId" : 32526,
    "prUrl" : "https://github.com/apache/spark/pull/32526#pullrequestreview-666843236",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5e698a9c-ffae-4d7b-9e72-a3e9e6bb0571",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Last item - is the point here that there's no point is storing a 0 in the map, as that's the default, and it makes the attempt turn up in the map keys, when you need it not to?",
        "createdAt" : "2021-05-20T21:12:37Z",
        "updatedAt" : "2021-05-20T21:12:38Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "6a91ce09-55cb-48c5-b2ed-e1aea7fc74dc",
        "parentId" : "5e698a9c-ffae-4d7b-9e72-a3e9e6bb0571",
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "I would like to clarify this, is this causing a leak?  ie are you getting some event late or out of order such that this added an entry in stageAttemptToNumRunningTask but then its never removed?    I think this change is actually ok but would like to know if its needed. I would also like to know when it happened to see if perhaps there is a race we can handle elsewhere in the stage attempt being added. ",
        "createdAt" : "2021-05-24T14:00:52Z",
        "updatedAt" : "2021-05-24T14:00:52Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      },
      {
        "id" : "b2d2c401-569e-4741-a4d7-6be4972a7d1c",
        "parentId" : "5e698a9c-ffae-4d7b-9e72-a3e9e6bb0571",
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "guess there is more in the jira:\r\n> If spark-dynamic-executor-allocation thread calls schedule() after a SparkListenerTaskEnd event for the last task in a stage\r\nbut before SparkListenerStageCompleted event for the stage, then stageAttemptToNumRunningTask will not be cleaned up properly.\r\n\r\nI'm not following this though because onTaskEnd both removes the stage from stageAttemptToNumRunningTask as well as removes the stageAttempt from resourceProfileIdToStageAttempt. so when this is called it shouldn't be in  resourceProfileIdToStageAttempt.  Is there a case we are hitting that it is in there, like multiple stages using that resource profile?",
        "createdAt" : "2021-05-24T14:07:02Z",
        "updatedAt" : "2021-05-24T14:07:02Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      },
      {
        "id" : "772db2bf-61c5-4c6e-a503-d2f7a0410e8d",
        "parentId" : "5e698a9c-ffae-4d7b-9e72-a3e9e6bb0571",
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "ok understanding the other issue, makes this one clear now, this change is fine. \r\nthis introduces the possibility to add it back to the map with value 0 and it never be removed, returning 0 here is fine because it is really needs to be added back it will be added in the task start handling",
        "createdAt" : "2021-05-24T14:55:43Z",
        "updatedAt" : "2021-05-24T14:55:44Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      }
    ],
    "commit" : "887cbfb01dec1d417571b4f416b7ec5150e1e506",
    "line" : 64,
    "diffHunk" : "@@ -1,1 +931,935 @@      // attempts is a Set, change to Seq so we keep all values\n      attempts.map { attempt =>\n        stageAttemptToNumRunningTask.getOrElse(attempt, 0)\n      }.sum\n    }"
  },
  {
    "id" : "2c2958b9-4dfb-473f-8e5f-f35ecadd463a",
    "prId" : 32526,
    "prUrl" : "https://github.com/apache/spark/pull/32526#pullrequestreview-666802100",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "66a9bb10-36da-4224-9c61-020bda5b5c85",
        "parentId" : null,
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "from jira:\r\n> If a SparkListenerTaskEnd event for the last task in a stage was processed before SparkListenerStageCompleted for that stage,\r\nthen resourceProfileIdToStageAttempt will not be cleaned up properly.\r\n\r\nI don't follow this, onTaskEnd is where resourceProfileIdToStageAttempt is cleaned up and removed, so how does  SparkListenerStageCompleted being called afterward affect it?  Is it being added back somehow that I\"m not seeing?  If you can give the sequence of events that would be very helpful.",
        "createdAt" : "2021-05-24T14:15:27Z",
        "updatedAt" : "2021-05-24T14:15:28Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      },
      {
        "id" : "67eade0e-c754-43f1-a087-a72ede17f552",
        "parentId" : "66a9bb10-36da-4224-9c61-020bda5b5c85",
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "oh wait, I think I see it.   stageAttemptToNumTasks only gets cleaned up in the onStageCompleted method.",
        "createdAt" : "2021-05-24T14:18:58Z",
        "updatedAt" : "2021-05-24T14:18:58Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      }
    ],
    "commit" : "887cbfb01dec1d417571b4f416b7ec5150e1e506",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +783,787 @@          if (stageAttemptToNumRunningTask(stageAttempt) == 0) {\n            stageAttemptToNumRunningTask -= stageAttempt\n            removeStageFromResourceProfileIfUnused(stageAttempt)\n          }\n        }"
  },
  {
    "id" : "4e698130-c99c-471d-bd77-03b462a9015d",
    "prId" : 32306,
    "prUrl" : "https://github.com/apache/spark/pull/32306#pullrequestreview-642930840",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f5bf136a-9449-4cce-85b8-cc9a895fe4d5",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "previously `pending` is `pendingTasksPerResourceProfile(rp) + pendingSpeculativeTasksPerResourceProfile(rp)`, now we use `pendingTasksPerResourceProfile() + pendingSpeculative`, and `pendingSpeculative` simply calls `pendingSpeculativeTasksPerResourceProfile(...)`\r\n\r\nseems like a straightforward code clean up.",
        "createdAt" : "2021-04-23T04:49:26Z",
        "updatedAt" : "2021-04-23T04:49:26Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "d3ca2c70-cd9f-409f-8ece-b35a2193f30c",
        "parentId" : "f5bf136a-9449-4cce-85b8-cc9a895fe4d5",
        "authorId" : "31afe32d-3af0-4fcf-93e2-115f5d7bab18",
        "body" : "previously  the `pendingSpeculativeTasksPerResourceProfile(rp)` will be called not only  by `totalPendingTasksPerResourceProfile(rpId)` but also  by  ` val pendingSpeculative = listener.pendingSpeculativeTasksPerResourceProfile(rpId)`, this PR  we only call the `pendingSpeculativeTasksPerResourceProfile(rp) ` once  to get the  pendingSpeculativeTasks , and  use  it for   `numRunningOrPendingTasks` and  `pendingSpeculative`.",
        "createdAt" : "2021-04-23T05:14:01Z",
        "updatedAt" : "2021-04-23T05:17:01Z",
        "lastEditedBy" : "31afe32d-3af0-4fcf-93e2-115f5d7bab18",
        "tags" : [
        ]
      }
    ],
    "commit" : "2499f818f0acf16db90b6445d9a28fc9e233b385",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +295,299 @@    val unschedulableTaskSets = listener.pendingUnschedulableTaskSetsPerResourceProfile(rpId)\n    val running = listener.totalRunningTasksPerResourceProfile(rpId)\n    val numRunningOrPendingTasks = pendingTask + pendingSpeculative + running\n    val rp = resourceProfileManager.resourceProfileFromId(rpId)\n    val tasksPerExecutor = rp.maxTasksPerExecutor(conf)"
  },
  {
    "id" : "98aae3a8-f05a-428f-b969-8de3a6865d90",
    "prId" : 31025,
    "prUrl" : "https://github.com/apache/spark/pull/31025#pullrequestreview-561524577",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b4f93e21-d7f6-4703-8379-5c5187c34363",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Since this is non-trivial, could you add some comments describing when this happens?",
        "createdAt" : "2021-01-05T04:48:23Z",
        "updatedAt" : "2021-01-05T05:21:58Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "2d0a3e4c-4f33-4233-93c2-3ecd27e65b4b",
        "parentId" : "b4f93e21-d7f6-4703-8379-5c5187c34363",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Or, we can add some meaningful log message with `else` statement. It will be helpful to understand the job.",
        "createdAt" : "2021-01-05T04:48:53Z",
        "updatedAt" : "2021-01-05T05:21:58Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "6011ca87-3977-4128-9084-f9c9a9c4f5a0",
        "parentId" : "b4f93e21-d7f6-4703-8379-5c5187c34363",
        "authorId" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "body" : "comment added.",
        "createdAt" : "2021-01-05T05:22:15Z",
        "updatedAt" : "2021-01-05T05:22:16Z",
        "lastEditedBy" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "tags" : [
        ]
      },
      {
        "id" : "28ebe6db-58e9-4523-b939-d5ad3e65e493",
        "parentId" : "b4f93e21-d7f6-4703-8379-5c5187c34363",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Thanks!",
        "createdAt" : "2021-01-05T05:34:46Z",
        "updatedAt" : "2021-01-05T05:34:46Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "74be2eade9824137269996e54b170f7f103767d4",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +803,807 @@          if (stageAttemptToNumSpeculativeTasks.contains(stageAttempt)) {\n            stageAttemptToNumSpeculativeTasks(stageAttempt) -= 1\n          }\n        }\n"
  },
  {
    "id" : "d9547d91-7ddc-4307-9146-fcc6f6a1f826",
    "prId" : 30795,
    "prUrl" : "https://github.com/apache/spark/pull/30795#pullrequestreview-557482652",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e4e34873-591c-42a3-8572-02ca9a4b8fc9",
        "parentId" : null,
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "so I don't agree with this, at least not how its defined.  The user defined the maximum number of executors to use, this is getting more than that. I realize that some are excluded, but this also comes down to a resource utilization question as well. If I am in multi-tenant environment, I want to make sure 1 job doesn't take over the entire cluster. max is one way to do this.  I think we would either need to redefine this, which isn't great for backwards compatibility and could result in unexpected behavior or we add another config that is around the excluded nodes. this would either just be an allow to go over or a allow to go over by X. The downside to this is default would be 0 or false so you would have to configure if you do set max and want to use this feature. But I don't see a lot of jobs setting max unless they are trying to be nice in multi-tenant so it seems ok as long as its in release notes, etc.\r\n\r\n  you will notice the other logic for unschedulableTaskSets does not increase this, just increases the number we ask for.",
        "createdAt" : "2020-12-18T15:19:48Z",
        "updatedAt" : "2020-12-18T16:06:17Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      },
      {
        "id" : "c5317faa-ec25-41ce-adec-3733a7f46982",
        "parentId" : "e4e34873-591c-42a3-8572-02ca9a4b8fc9",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Make sense to me. Add an extra conf would be a good choice.\r\n\r\nAlthough, I'm rethinking this change. It only takes effect when users set the max explicitly and the cluster reaches the max.( By default, max is Int.MaxValue. So we won't reach the max normally.) However, we still want to replace those excluded executors even if the cluster doesn't reach the max. For example, max/2 may be enough for task scheduling. And TaskScheduler also thinks there're max/2 executors without realizing X executors actually excluded.\r\n\r\nSo I think what we actually need here is to forcibly replace excluded executors when dynamic allocation & exclusion (but not kill) are both enabled. And it should not be related to the max value.\r\n\r\n\r\n",
        "createdAt" : "2020-12-23T03:01:29Z",
        "updatedAt" : "2020-12-23T03:01:29Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "75cdd1e334c15c8af89c9b0d283bedf12d0f33ee",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +505,509 @@    // launch new executors to replace the excluded executors.\n    val exclude = executorMonitor.excludedExecutorCount\n    val maxOverheadExecutors = maxNumExecutors + exclude\n    // Do not request more executors if it would put our target over the upper bound\n    // this is doing a max check per ResourceProfile"
  },
  {
    "id" : "06b065e2-0b50-4419-8f59-9eeda6cd8651",
    "prId" : 29367,
    "prUrl" : "https://github.com/apache/spark/pull/29367#pullrequestreview-463829692",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d2c4034a-ee7b-427d-b0c5-462005c0d89d",
        "parentId" : null,
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "Please change the warning message to also say something about storage migration. ",
        "createdAt" : "2020-08-06T05:35:08Z",
        "updatedAt" : "2020-08-12T19:09:04Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      },
      {
        "id" : "99d24048-32e7-407c-b1d8-c3e8cb5620f7",
        "parentId" : "d2c4034a-ee7b-427d-b0c5-462005c0d89d",
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "What do you want mentioned about storage migration?",
        "createdAt" : "2020-08-06T18:58:41Z",
        "updatedAt" : "2020-08-12T19:09:04Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      },
      {
        "id" : "d282722b-0be3-46b4-b5f5-e1f996f6db2a",
        "parentId" : "d2c4034a-ee7b-427d-b0c5-462005c0d89d",
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "Ideally I would have a different log message: \r\n\r\n```\r\n     if (conf.get(config.DYN_ALLOCATION_SHUFFLE_TRACKING_ENABLED)) {\r\n        logWarning(\"Dynamic allocation without a shuffle service is an experimental feature.\")\r\n     } else if (conf.get(WORKER_DECOMMISSION_ENABLED) &&\r\n            conf.get(config.STORAGE_DECOMMISSION_SHUFFLE_BLOCKS_ENABLED)) {\r\n        logWarning(\"Decommissioning with shuffle block migration is an experimental feature.\")\r\n     }\r\n```\r\n",
        "createdAt" : "2020-08-06T21:39:09Z",
        "updatedAt" : "2020-08-12T19:09:04Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      },
      {
        "id" : "e55c245b-20e1-4f62-9d4e-3a6602a0793e",
        "parentId" : "d2c4034a-ee7b-427d-b0c5-462005c0d89d",
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "That doesnâ€™t make sense. Dynamic allocation without a shuffle service is the expiremental feature in either case.",
        "createdAt" : "2020-08-08T18:25:14Z",
        "updatedAt" : "2020-08-12T19:09:04Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      },
      {
        "id" : "0ec3bbd6-2f79-40b9-bc55-1d32d760c1df",
        "parentId" : "d2c4034a-ee7b-427d-b0c5-462005c0d89d",
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "Okay. I understand the intention now. Nevermind :-) ",
        "createdAt" : "2020-08-08T22:30:21Z",
        "updatedAt" : "2020-08-12T19:09:05Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      }
    ],
    "commit" : "e970cb10147fb64533f5088edc3a448b5ef198cf",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +214,218 @@          (decommissionEnabled &&\n            conf.get(config.STORAGE_DECOMMISSION_SHUFFLE_BLOCKS_ENABLED))) {\n        logWarning(\"Dynamic allocation without a shuffle service is an experimental feature.\")\n      } else if (!testing) {\n        throw new SparkException(\"Dynamic allocation of executors requires the external \" +"
  },
  {
    "id" : "9d2216ab-358d-4343-817c-b7e802e75c35",
    "prId" : 29367,
    "prUrl" : "https://github.com/apache/spark/pull/29367#pullrequestreview-462895113",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "18b4ca15-c8cc-48b3-a073-e5d4da7c8635",
        "parentId" : null,
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "Question: The default implementation of the ExecutorAllocationClient is to call killExecutors. So what does it mean for the WORKER_DECOM_ENABLED = true and the default implementation being called (ie the decommissionExecutors is not overridden) ? Perhaps it means that decommission is enabled by a config but the cluster manager does not support decommission and is thus ignored ? \r\n\r\nIn such an event should we be at parity with the else codepath -- ie `force` should be set to false in ExecutorAllocationClient ?",
        "createdAt" : "2020-08-06T05:36:56Z",
        "updatedAt" : "2020-08-12T19:09:04Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      },
      {
        "id" : "4b2cc146-a971-4f29-ac7f-3862bb497496",
        "parentId" : "18b4ca15-c8cc-48b3-a073-e5d4da7c8635",
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "So if someones enabled worker decommissioning and there cluster manager doesn't support it, we delegate to kill. Force is set to false already as a default in the call to `killExecutors`.",
        "createdAt" : "2020-08-06T19:01:50Z",
        "updatedAt" : "2020-08-12T19:09:04Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      },
      {
        "id" : "cfb3f764-c14a-4895-a23c-a5c247dc5351",
        "parentId" : "18b4ca15-c8cc-48b3-a073-e5d4da7c8635",
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "Great, thanks for double checking that !",
        "createdAt" : "2020-08-06T21:39:39Z",
        "updatedAt" : "2020-08-12T19:09:04Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      }
    ],
    "commit" : "e970cb10147fb64533f5088edc3a448b5ef198cf",
    "line" : 51,
    "diffHunk" : "@@ -1,1 +579,583 @@        val executorIdsWithoutHostLoss = executorIdsToBeRemoved.toSeq.map(\n          id => (id, ExecutorDecommissionInfo(\"spark scale down\", false))).toArray\n        client.decommissionExecutors(executorIdsWithoutHostLoss, adjustTargetNumExecutors = false)\n      } else {\n        client.killExecutors(executorIdsToBeRemoved.toSeq, adjustTargetNumExecutors = false,"
  },
  {
    "id" : "17027ef5-b59c-42f0-88d0-0896da685c46",
    "prId" : 29367,
    "prUrl" : "https://github.com/apache/spark/pull/29367#pullrequestreview-464610852",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "25105b01-e221-4e85-bf8b-b6354b7797bc",
        "parentId" : null,
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "Actually there is a key big difference between `killExecutors` and `decommissionExecutors`: The former does the actual killing and the latter does 'graceful death': Graceful death waits for all the migrations etc to happen and then the executor exits. I think this may lead to an overcommit: The old executor is still being decommissioned and migrating things, and a new one could be spun up. The two executors are alive at the same time (perhaps on the same node). Would this cause issues ?\r\n\r\nThis problem does not exist for `killExecutors` so much: Kill executor will kill the executor soon enough and thus the overlap window is smaller. ",
        "createdAt" : "2020-08-08T23:29:25Z",
        "updatedAt" : "2020-08-12T19:09:05Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      },
      {
        "id" : "d1fae541-f9b7-421c-9c46-1b33da6dfcde",
        "parentId" : "25105b01-e221-4e85-bf8b-b6354b7797bc",
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "We're talking in standalone mode? Multiple executors on the same worker is a deprecated feature so I don't think we have to worry about supporting new functionality with it.",
        "createdAt" : "2020-08-10T18:23:27Z",
        "updatedAt" : "2020-08-12T19:09:05Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      },
      {
        "id" : "61eddf97-c1b8-4a72-8377-6083121cb970",
        "parentId" : "25105b01-e221-4e85-bf8b-b6354b7797bc",
        "authorId" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "body" : "Okay. It is a little bit unsettling to mer personally, that we don't have a timeout on the time that an executor would take to \"migrate and finally die\", but I guess we can live with that shortcoming for a while. It just reduces the effective cluster capacity for an indeterminate amount of time, which is what makes me slightly queasy about it.",
        "createdAt" : "2020-08-10T19:41:03Z",
        "updatedAt" : "2020-08-12T19:09:05Z",
        "lastEditedBy" : "711a9ca0-8b90-435a-bf87-eb621aa1db13",
        "tags" : [
        ]
      },
      {
        "id" : "6cb63c0a-59b1-4b42-a2ec-6e64cb863a16",
        "parentId" : "25105b01-e221-4e85-bf8b-b6354b7797bc",
        "authorId" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "body" : "So given this is in the Spark planned scale down path that _seems_ to be ok (the goal is to eventually reduce the capacity).",
        "createdAt" : "2020-08-10T21:47:21Z",
        "updatedAt" : "2020-08-12T19:09:05Z",
        "lastEditedBy" : "ae55b635-dd0e-41aa-9272-372de9a35f38",
        "tags" : [
        ]
      }
    ],
    "commit" : "e970cb10147fb64533f5088edc3a448b5ef198cf",
    "line" : 53,
    "diffHunk" : "@@ -1,1 +581,585 @@        client.decommissionExecutors(executorIdsWithoutHostLoss, adjustTargetNumExecutors = false)\n      } else {\n        client.killExecutors(executorIdsToBeRemoved.toSeq, adjustTargetNumExecutors = false,\n          countFailures = false, force = false)\n      }"
  },
  {
    "id" : "1a333294-f37d-45d8-a509-5a7503f76e34",
    "prId" : 28287,
    "prUrl" : "https://github.com/apache/spark/pull/28287#pullrequestreview-442592044",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ebea198e-c006-4681-bddf-52fde5c46a14",
        "parentId" : null,
        "authorId" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "body" : "I think this should be:\n```\nmath.max(totalNeed, executorMonitor.executorCountWithResourceProfile(rpId) + maxNeededForUnschedules)\n```\nIf we were already going to request `maxNeededForUnschedulables` _more_ executors than we currently have as part of `totalNeed`, that already satisfies the requirements. ",
        "createdAt" : "2020-06-29T17:25:36Z",
        "updatedAt" : "2020-07-22T17:58:20Z",
        "lastEditedBy" : "ddb80038-2da6-4937-8c45-4d52fbe0300f",
        "tags" : [
        ]
      },
      {
        "id" : "1849d8b6-a474-4735-bde8-05d8437bbd5a",
        "parentId" : "ebea198e-c006-4681-bddf-52fde5c46a14",
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "Can you update with details about how this was resolved ? The original looked fine to me, but I want to make sure I am not missing something.",
        "createdAt" : "2020-07-04T06:42:29Z",
        "updatedAt" : "2020-07-22T17:58:20Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      },
      {
        "id" : "e0538fd4-6e15-4603-85e1-982f0a474b5e",
        "parentId" : "ebea198e-c006-4681-bddf-52fde5c46a14",
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "Scratch that - what I had seen was probably a modified version, not original ...",
        "createdAt" : "2020-07-04T06:53:32Z",
        "updatedAt" : "2020-07-22T17:58:20Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      }
    ],
    "commit" : "d6f1e73ae49d9641a8efcb1f5e9016bd378a70c6",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +309,313 @@      math.max(maxNeededWithSpeculationLocalityOffset,\n        executorMonitor.executorCountWithResourceProfile(rpId) + maxNeededForUnschedulables)\n    } else {\n      maxNeededWithSpeculationLocalityOffset\n    }"
  },
  {
    "id" : "e0a1730f-7728-4d09-81f6-4d2defed9410",
    "prId" : 28084,
    "prUrl" : "https://github.com/apache/spark/pull/28084#pullrequestreview-384882196",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5c824679-c7d6-497f-b0d8-1b37e4e31656",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "A minor fix.",
        "createdAt" : "2020-03-31T16:02:44Z",
        "updatedAt" : "2020-03-31T16:02:51Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "7dcd604572b192ede1b6b05562dcae22efe8ff1c",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +438,442 @@            logDebug(s\"Lowering target number of executors to\" +\n              s\" ${numExecutorsTargetPerResourceProfileId(rpId)} (previously \" +\n              s\"${targetNum.oldNumExecutorsTarget} for resource profile id: ${rpId}) \" +\n              \"because not all requested executors \" +\n              \"are actually needed\")"
  }
]