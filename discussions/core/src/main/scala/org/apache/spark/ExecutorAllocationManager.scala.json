[
  {
    "id" : "d7ebc8ef-081c-4f48-9085-64561cde6bc5",
    "prId" : 32526,
    "prUrl" : "https://github.com/apache/spark/pull/32526#pullrequestreview-663634581",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a24cda71-7570-42e5-8c19-9f5383c9e226",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Is the case of 0 different from >1 here? If there is >1 do you want to remove something anyway?",
        "createdAt" : "2021-05-15T17:41:14Z",
        "updatedAt" : "2021-05-15T17:41:14Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "62cf9e3a-7bda-403c-b8d0-dff3ee2b4435",
        "parentId" : "a24cda71-7570-42e5-8c19-9f5383c9e226",
        "authorId" : "607c2c93-3680-41e7-baaf-dc5887b76b9f",
        "body" : "I'm not sure. This behaviour was there before and it is not directly related to the bug.",
        "createdAt" : "2021-05-19T20:31:47Z",
        "updatedAt" : "2021-05-19T20:31:47Z",
        "lastEditedBy" : "607c2c93-3680-41e7-baaf-dc5887b76b9f",
        "tags" : [
        ]
      }
    ],
    "commit" : "887cbfb01dec1d417571b4f416b7ec5150e1e506",
    "line" : 53,
    "diffHunk" : "@@ -1,1 +867,871 @@          resourceProfileIdToStageAttempt(rpForStage.head) -= stageAttempt\n        } else {\n          logWarning(s\"Should have exactly one resource profile for stage $stageAttempt,\" +\n              s\" but have $rpForStage\")\n        }"
  },
  {
    "id" : "1c8f1b6b-f5f3-409a-a5da-6c5f319845c3",
    "prId" : 32526,
    "prUrl" : "https://github.com/apache/spark/pull/32526#pullrequestreview-666843236",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5e698a9c-ffae-4d7b-9e72-a3e9e6bb0571",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Last item - is the point here that there's no point is storing a 0 in the map, as that's the default, and it makes the attempt turn up in the map keys, when you need it not to?",
        "createdAt" : "2021-05-20T21:12:37Z",
        "updatedAt" : "2021-05-20T21:12:38Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "6a91ce09-55cb-48c5-b2ed-e1aea7fc74dc",
        "parentId" : "5e698a9c-ffae-4d7b-9e72-a3e9e6bb0571",
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "I would like to clarify this, is this causing a leak?  ie are you getting some event late or out of order such that this added an entry in stageAttemptToNumRunningTask but then its never removed?    I think this change is actually ok but would like to know if its needed. I would also like to know when it happened to see if perhaps there is a race we can handle elsewhere in the stage attempt being added. ",
        "createdAt" : "2021-05-24T14:00:52Z",
        "updatedAt" : "2021-05-24T14:00:52Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      },
      {
        "id" : "b2d2c401-569e-4741-a4d7-6be4972a7d1c",
        "parentId" : "5e698a9c-ffae-4d7b-9e72-a3e9e6bb0571",
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "guess there is more in the jira:\r\n> If spark-dynamic-executor-allocation thread calls schedule() after a SparkListenerTaskEnd event for the last task in a stage\r\nbut before SparkListenerStageCompleted event for the stage, then stageAttemptToNumRunningTask will not be cleaned up properly.\r\n\r\nI'm not following this though because onTaskEnd both removes the stage from stageAttemptToNumRunningTask as well as removes the stageAttempt from resourceProfileIdToStageAttempt. so when this is called it shouldn't be in  resourceProfileIdToStageAttempt.  Is there a case we are hitting that it is in there, like multiple stages using that resource profile?",
        "createdAt" : "2021-05-24T14:07:02Z",
        "updatedAt" : "2021-05-24T14:07:02Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      },
      {
        "id" : "772db2bf-61c5-4c6e-a503-d2f7a0410e8d",
        "parentId" : "5e698a9c-ffae-4d7b-9e72-a3e9e6bb0571",
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "ok understanding the other issue, makes this one clear now, this change is fine. \r\nthis introduces the possibility to add it back to the map with value 0 and it never be removed, returning 0 here is fine because it is really needs to be added back it will be added in the task start handling",
        "createdAt" : "2021-05-24T14:55:43Z",
        "updatedAt" : "2021-05-24T14:55:44Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      }
    ],
    "commit" : "887cbfb01dec1d417571b4f416b7ec5150e1e506",
    "line" : 64,
    "diffHunk" : "@@ -1,1 +931,935 @@      // attempts is a Set, change to Seq so we keep all values\n      attempts.map { attempt =>\n        stageAttemptToNumRunningTask.getOrElse(attempt, 0)\n      }.sum\n    }"
  },
  {
    "id" : "2c2958b9-4dfb-473f-8e5f-f35ecadd463a",
    "prId" : 32526,
    "prUrl" : "https://github.com/apache/spark/pull/32526#pullrequestreview-666802100",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "66a9bb10-36da-4224-9c61-020bda5b5c85",
        "parentId" : null,
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "from jira:\r\n> If a SparkListenerTaskEnd event for the last task in a stage was processed before SparkListenerStageCompleted for that stage,\r\nthen resourceProfileIdToStageAttempt will not be cleaned up properly.\r\n\r\nI don't follow this, onTaskEnd is where resourceProfileIdToStageAttempt is cleaned up and removed, so how does  SparkListenerStageCompleted being called afterward affect it?  Is it being added back somehow that I\"m not seeing?  If you can give the sequence of events that would be very helpful.",
        "createdAt" : "2021-05-24T14:15:27Z",
        "updatedAt" : "2021-05-24T14:15:28Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      },
      {
        "id" : "67eade0e-c754-43f1-a087-a72ede17f552",
        "parentId" : "66a9bb10-36da-4224-9c61-020bda5b5c85",
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "oh wait, I think I see it.   stageAttemptToNumTasks only gets cleaned up in the onStageCompleted method.",
        "createdAt" : "2021-05-24T14:18:58Z",
        "updatedAt" : "2021-05-24T14:18:58Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      }
    ],
    "commit" : "887cbfb01dec1d417571b4f416b7ec5150e1e506",
    "line" : 26,
    "diffHunk" : "@@ -1,1 +783,787 @@          if (stageAttemptToNumRunningTask(stageAttempt) == 0) {\n            stageAttemptToNumRunningTask -= stageAttempt\n            removeStageFromResourceProfileIfUnused(stageAttempt)\n          }\n        }"
  },
  {
    "id" : "4e698130-c99c-471d-bd77-03b462a9015d",
    "prId" : 32306,
    "prUrl" : "https://github.com/apache/spark/pull/32306#pullrequestreview-642930840",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f5bf136a-9449-4cce-85b8-cc9a895fe4d5",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "previously `pending` is `pendingTasksPerResourceProfile(rp) + pendingSpeculativeTasksPerResourceProfile(rp)`, now we use `pendingTasksPerResourceProfile() + pendingSpeculative`, and `pendingSpeculative` simply calls `pendingSpeculativeTasksPerResourceProfile(...)`\r\n\r\nseems like a straightforward code clean up.",
        "createdAt" : "2021-04-23T04:49:26Z",
        "updatedAt" : "2021-04-23T04:49:26Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "d3ca2c70-cd9f-409f-8ece-b35a2193f30c",
        "parentId" : "f5bf136a-9449-4cce-85b8-cc9a895fe4d5",
        "authorId" : "31afe32d-3af0-4fcf-93e2-115f5d7bab18",
        "body" : "previously  the `pendingSpeculativeTasksPerResourceProfile(rp)` will be called not only  by `totalPendingTasksPerResourceProfile(rpId)` but also  by  ` val pendingSpeculative = listener.pendingSpeculativeTasksPerResourceProfile(rpId)`, this PR  we only call the `pendingSpeculativeTasksPerResourceProfile(rp) ` once  to get the  pendingSpeculativeTasks , and  use  it for   `numRunningOrPendingTasks` and  `pendingSpeculative`.",
        "createdAt" : "2021-04-23T05:14:01Z",
        "updatedAt" : "2021-04-23T05:17:01Z",
        "lastEditedBy" : "31afe32d-3af0-4fcf-93e2-115f5d7bab18",
        "tags" : [
        ]
      }
    ],
    "commit" : "2499f818f0acf16db90b6445d9a28fc9e233b385",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +295,299 @@    val unschedulableTaskSets = listener.pendingUnschedulableTaskSetsPerResourceProfile(rpId)\n    val running = listener.totalRunningTasksPerResourceProfile(rpId)\n    val numRunningOrPendingTasks = pendingTask + pendingSpeculative + running\n    val rp = resourceProfileManager.resourceProfileFromId(rpId)\n    val tasksPerExecutor = rp.maxTasksPerExecutor(conf)"
  },
  {
    "id" : "98aae3a8-f05a-428f-b969-8de3a6865d90",
    "prId" : 31025,
    "prUrl" : "https://github.com/apache/spark/pull/31025#pullrequestreview-561524577",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b4f93e21-d7f6-4703-8379-5c5187c34363",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Since this is non-trivial, could you add some comments describing when this happens?",
        "createdAt" : "2021-01-05T04:48:23Z",
        "updatedAt" : "2021-01-05T05:21:58Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "2d0a3e4c-4f33-4233-93c2-3ecd27e65b4b",
        "parentId" : "b4f93e21-d7f6-4703-8379-5c5187c34363",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Or, we can add some meaningful log message with `else` statement. It will be helpful to understand the job.",
        "createdAt" : "2021-01-05T04:48:53Z",
        "updatedAt" : "2021-01-05T05:21:58Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "6011ca87-3977-4128-9084-f9c9a9c4f5a0",
        "parentId" : "b4f93e21-d7f6-4703-8379-5c5187c34363",
        "authorId" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "body" : "comment added.",
        "createdAt" : "2021-01-05T05:22:15Z",
        "updatedAt" : "2021-01-05T05:22:16Z",
        "lastEditedBy" : "0223d15f-93d2-46b2-bee2-7f40fcd0335a",
        "tags" : [
        ]
      },
      {
        "id" : "28ebe6db-58e9-4523-b939-d5ad3e65e493",
        "parentId" : "b4f93e21-d7f6-4703-8379-5c5187c34363",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Thanks!",
        "createdAt" : "2021-01-05T05:34:46Z",
        "updatedAt" : "2021-01-05T05:34:46Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "74be2eade9824137269996e54b170f7f103767d4",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +803,807 @@          if (stageAttemptToNumSpeculativeTasks.contains(stageAttempt)) {\n            stageAttemptToNumSpeculativeTasks(stageAttempt) -= 1\n          }\n        }\n"
  },
  {
    "id" : "d9547d91-7ddc-4307-9146-fcc6f6a1f826",
    "prId" : 30795,
    "prUrl" : "https://github.com/apache/spark/pull/30795#pullrequestreview-557482652",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e4e34873-591c-42a3-8572-02ca9a4b8fc9",
        "parentId" : null,
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "so I don't agree with this, at least not how its defined.  The user defined the maximum number of executors to use, this is getting more than that. I realize that some are excluded, but this also comes down to a resource utilization question as well. If I am in multi-tenant environment, I want to make sure 1 job doesn't take over the entire cluster. max is one way to do this.  I think we would either need to redefine this, which isn't great for backwards compatibility and could result in unexpected behavior or we add another config that is around the excluded nodes. this would either just be an allow to go over or a allow to go over by X. The downside to this is default would be 0 or false so you would have to configure if you do set max and want to use this feature. But I don't see a lot of jobs setting max unless they are trying to be nice in multi-tenant so it seems ok as long as its in release notes, etc.\r\n\r\n  you will notice the other logic for unschedulableTaskSets does not increase this, just increases the number we ask for.",
        "createdAt" : "2020-12-18T15:19:48Z",
        "updatedAt" : "2020-12-18T16:06:17Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      },
      {
        "id" : "c5317faa-ec25-41ce-adec-3733a7f46982",
        "parentId" : "e4e34873-591c-42a3-8572-02ca9a4b8fc9",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Make sense to me. Add an extra conf would be a good choice.\r\n\r\nAlthough, I'm rethinking this change. It only takes effect when users set the max explicitly and the cluster reaches the max.( By default, max is Int.MaxValue. So we won't reach the max normally.) However, we still want to replace those excluded executors even if the cluster doesn't reach the max. For example, max/2 may be enough for task scheduling. And TaskScheduler also thinks there're max/2 executors without realizing X executors actually excluded.\r\n\r\nSo I think what we actually need here is to forcibly replace excluded executors when dynamic allocation & exclusion (but not kill) are both enabled. And it should not be related to the max value.\r\n\r\n\r\n",
        "createdAt" : "2020-12-23T03:01:29Z",
        "updatedAt" : "2020-12-23T03:01:29Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "75cdd1e334c15c8af89c9b0d283bedf12d0f33ee",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +505,509 @@    // launch new executors to replace the excluded executors.\n    val exclude = executorMonitor.excludedExecutorCount\n    val maxOverheadExecutors = maxNumExecutors + exclude\n    // Do not request more executors if it would put our target over the upper bound\n    // this is doing a max check per ResourceProfile"
  }
]