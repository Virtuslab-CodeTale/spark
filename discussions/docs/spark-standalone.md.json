[
  {
    "id" : "7d0c8c77-9918-48e3-8d94-5534b2795bb8",
    "prId" : 28958,
    "prUrl" : "https://github.com/apache/spark/pull/28958#pullrequestreview-440188191",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b67f5b16-7929-4855-9bfa-06981a482405",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Ur, this looks like not a typo, isn't it? So, is this about changing to CamelCase, `resourcesfile` -> `resourcesFile`, only? Is Apache Spark case sensitive?",
        "createdAt" : "2020-06-30T15:56:50Z",
        "updatedAt" : "2020-06-30T15:56:50Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "3f179008-ac59-4a88-9f2d-46618f99fa96",
        "parentId" : "b67f5b16-7929-4855-9bfa-06981a482405",
        "authorId" : "3a227965-84e0-47cf-9974-11293764f028",
        "body" : "I think it's not just about notation. Property names in Apache Spark should be case sensitive.",
        "createdAt" : "2020-06-30T16:10:52Z",
        "updatedAt" : "2020-06-30T16:10:52Z",
        "lastEditedBy" : "3a227965-84e0-47cf-9974-11293764f028",
        "tags" : [
        ]
      },
      {
        "id" : "f421debf-0df3-4d18-9db2-83f8903eb4fe",
        "parentId" : "b67f5b16-7929-4855-9bfa-06981a482405",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Got it. Thanks.",
        "createdAt" : "2020-06-30T16:27:43Z",
        "updatedAt" : "2020-06-30T16:27:43Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "d7d6d25177fefbdbb825c3dc9916b57faea6b395",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +360,364 @@The user must configure the Workers to have a set of resources available so that it can assign them out to Executors. The <code>spark.worker.resource.{resourceName}.amount</code> is used to control the amount of each resource the worker has allocated. The user must also specify either <code>spark.worker.resourcesFile</code> or <code>spark.worker.resource.{resourceName}.discoveryScript</code> to specify how the Worker discovers the resources its assigned. See the descriptions above for each of those to see which method works best for your setup.\n\nThe second part is running an application on Spark Standalone. The only special case from the standard Spark resource configs is when you are running the Driver in client mode. For a Driver in client mode, the user can specify the resources it uses via <code>spark.driver.resourcesFile</code> or <code>spark.driver.resource.{resourceName}.discoveryScript</code>. If the Driver is running on the same host as other Drivers, please make sure the resources file or discovery script only returns resources that do not conflict with other Drivers running on the same node.\n\nNote, the user does not need to specify a discovery script when submitting an application as the Worker will start each Executor with the resources it allocates to it."
  },
  {
    "id" : "6a46e71d-49ae-48dc-a2a4-114b4e1ceaee",
    "prId" : 28258,
    "prUrl" : "https://github.com/apache/spark/pull/28258#pullrequestreview-404547068",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "22945e8b-a6f5-46ef-ad2c-51e235de0e0d",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Nit: Mode -> mode\r\nand newline before the table.",
        "createdAt" : "2020-05-02T15:54:37Z",
        "updatedAt" : "2020-06-08T08:01:52Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "599997df-e588-4c19-8ade-6dc6154510d3",
        "parentId" : "22945e8b-a6f5-46ef-ad2c-51e235de0e0d",
        "authorId" : "da023277-487f-41ab-9359-5ee7378aba9e",
        "body" : "Updated in the latest commit.",
        "createdAt" : "2020-05-02T17:45:49Z",
        "updatedAt" : "2020-06-08T08:01:52Z",
        "lastEditedBy" : "da023277-487f-41ab-9359-5ee7378aba9e",
        "tags" : [
        ]
      }
    ],
    "commit" : "0e152f4b6fd65ac5f8706fa59c1afa74bbb2df53",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +379,383 @@Spark applications supports the following configuration properties specific to standalone mode: \n\n<table class=\"table\">\n  <tr><th style=\"width:21%\">Property Name</th><th>Default Value</th><th>Meaning</th><th>Since Version</th></tr>\n  <tr>"
  },
  {
    "id" : "ee0a7fa5-f0d6-4923-8fb4-7c424bc2655a",
    "prId" : 28064,
    "prUrl" : "https://github.com/apache/spark/pull/28064#pullrequestreview-383364599",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f03a8f0d-37cf-4935-9601-5ac00c4587a1",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "No JIRA ID, commit ID: 46eecd110a4017ea0c86cbb1010d0ccd6a5eb2ef#diff-29dffdccd5a7f4c8b496c293e87c8668",
        "createdAt" : "2020-03-29T01:36:24Z",
        "updatedAt" : "2020-03-29T01:36:25Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "6787d16f5e86e5a6dbcb2d9b25c41ec5dfbedb1d",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +193,197 @@    The maximum number of completed applications to display. Older applications will be dropped from the UI to maintain this limit.<br/>\n  </td>\n  <td>0.8.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "7fc04671-0c93-4f14-a5aa-2a8cb0032a55",
    "prId" : 28064,
    "prUrl" : "https://github.com/apache/spark/pull/28064#pullrequestreview-383364623",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "419c2661-fb0b-4603-a7c7-9881665175a4",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "No JIRA ID, commit ID: 7446f5ff93142d2dd5c79c63fa947f47a1d4db8b#diff-29dffdccd5a7f4c8b496c293e87c8668",
        "createdAt" : "2020-03-29T01:36:47Z",
        "updatedAt" : "2020-03-29T01:36:48Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "6787d16f5e86e5a6dbcb2d9b25c41ec5dfbedb1d",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +201,205 @@   The maximum number of completed drivers to display. Older drivers will be dropped from the UI to maintain this limit.<br/>\n  </td>\n  <td>1.1.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "4565a864-0f3a-4df6-865f-64ef4eda7bee",
    "prId" : 28064,
    "prUrl" : "https://github.com/apache/spark/pull/28064#pullrequestreview-383364635",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1aad5484-3896-47b6-8153-958a96429c9d",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "No JIRA ID, commit ID: bb2b9ff37cd2503cc6ea82c5dd395187b0910af0#diff-0e7ae91819fc8f7b47b0f97be7116325\r\n",
        "createdAt" : "2020-03-29T01:37:08Z",
        "updatedAt" : "2020-03-29T01:37:09Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "6787d16f5e86e5a6dbcb2d9b25c41ec5dfbedb1d",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +211,215 @@    data locality in HDFS, but consolidating is more efficient for compute-intensive workloads. <br/>\n  </td>\n  <td>0.6.1</td>\n</tr>\n<tr>"
  },
  {
    "id" : "9f895c86-8809-469f-87e8-13b5c0674c1b",
    "prId" : 28064,
    "prUrl" : "https://github.com/apache/spark/pull/28064#pullrequestreview-383364655",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7d16cd64-e67b-463c-a83d-21063b5bab12",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "No JIRA ID, commit ID: d8bcc8e9a095c1b20dd7a17b6535800d39bff80e#diff-29dffdccd5a7f4c8b496c293e87c8668",
        "createdAt" : "2020-03-29T01:37:31Z",
        "updatedAt" : "2020-03-29T01:37:32Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "6787d16f5e86e5a6dbcb2d9b25c41ec5dfbedb1d",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +223,227 @@    the whole cluster by default. <br/>\n  </td>\n  <td>0.9.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "4ee9318e-bae6-407c-81d5-d804bd18b074",
    "prId" : 28064,
    "prUrl" : "https://github.com/apache/spark/pull/28064#pullrequestreview-383364671",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "805a3666-bd05-4098-a45b-884f5b63bbad",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-16956, commit ID: ace458f0330f22463ecf7cbee7c0465e10fba8a8#diff-29dffdccd5a7f4c8b496c293e87c8668",
        "createdAt" : "2020-03-29T01:37:54Z",
        "updatedAt" : "2020-03-29T01:37:54Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "6787d16f5e86e5a6dbcb2d9b25c41ec5dfbedb1d",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +239,243 @@    <br/>\n  </td>\n  <td>1.6.3</td>\n</tr>\n<tr>"
  },
  {
    "id" : "35e9d91f-7fde-48bc-85f5-6766fa10154f",
    "prId" : 28064,
    "prUrl" : "https://github.com/apache/spark/pull/28064#pullrequestreview-383364698",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c218db2f-d953-4bb7-821e-928df07e74f5",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-27371, commit ID: cbad616d4cb0c58993a88df14b5e30778c7f7e85#diff-d25032e4a3ae1b85a59e4ca9ccf189a8",
        "createdAt" : "2020-03-29T01:38:32Z",
        "updatedAt" : "2020-03-29T01:38:32Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "6787d16f5e86e5a6dbcb2d9b25c41ec5dfbedb1d",
    "line" : 44,
    "diffHunk" : "@@ -1,1 +256,260 @@    Amount of a particular resource to use on the worker.\n  </td>\n  <td>3.0.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "6a733fc2-5cdb-4355-b77e-85295ad8cb4f",
    "prId" : 28064,
    "prUrl" : "https://github.com/apache/spark/pull/28064#pullrequestreview-383364707",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "597c74f5-df16-44ca-b420-3b9e647d317f",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-27371, commit ID: cbad616d4cb0c58993a88df14b5e30778c7f7e85#diff-d25032e4a3ae1b85a59e4ca9ccf189a8",
        "createdAt" : "2020-03-29T01:38:41Z",
        "updatedAt" : "2020-03-29T01:38:41Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "6787d16f5e86e5a6dbcb2d9b25c41ec5dfbedb1d",
    "line" : 52,
    "diffHunk" : "@@ -1,1 +265,269 @@    And the output of the script should be formatted like the <code>ResourceInformation</code> class.\n  </td>\n  <td>3.0.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "a025370a-c648-42a9-9c5c-d8646271c3ab",
    "prId" : 28064,
    "prUrl" : "https://github.com/apache/spark/pull/28064#pullrequestreview-383364739",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2065705c-fec0-4c87-9c92-7c5f20698f97",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-26288, commit ID: 8b0aa59218c209d39cbba5959302d8668b885cf6#diff-6bdad48cfc34314e89599655442ff210",
        "createdAt" : "2020-03-29T01:39:15Z",
        "updatedAt" : "2020-03-29T01:39:15Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "6787d16f5e86e5a6dbcb2d9b25c41ec5dfbedb1d",
    "line" : 60,
    "diffHunk" : "@@ -1,1 +325,329 @@    eventually gets cleaned up.  This config may be removed in the future.\n  </td>\n  <td>3.0.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "3edc92f9-682d-45ad-9d5b-c44728845a93",
    "prId" : 28064,
    "prUrl" : "https://github.com/apache/spark/pull/28064#pullrequestreview-383364757",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d1688bed-b381-497e-bfef-f7b4150bde3c",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-24340, commit ID: 8ef167a5f9ba8a79bb7ca98a9844fe9cfcfea060#diff-916ca56b663f178f302c265b7ef38499",
        "createdAt" : "2020-03-29T01:39:39Z",
        "updatedAt" : "2020-03-29T01:39:39Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "6787d16f5e86e5a6dbcb2d9b25c41ec5dfbedb1d",
    "line" : 68,
    "diffHunk" : "@@ -1,1 +338,342 @@    This only affects Standalone mode, support of other cluster manangers can be added in the future.\n  </td>\n  <td>2.4.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "338b9f2f-7929-459c-a459-d0cae807c48c",
    "prId" : 28064,
    "prUrl" : "https://github.com/apache/spark/pull/28064#pullrequestreview-383364774",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b64fe85f-21d7-4161-82ef-1b487c87e9be",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "No JIRA ID, commit ID: d66c01f2b6defb3db6c1be99523b734a4d960532#diff-29dffdccd5a7f4c8b496c293e87c8668",
        "createdAt" : "2020-03-29T01:40:04Z",
        "updatedAt" : "2020-03-29T01:40:04Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "6787d16f5e86e5a6dbcb2d9b25c41ec5dfbedb1d",
    "line" : 81,
    "diffHunk" : "@@ -1,1 +504,508 @@    <td><code>spark.deploy.recoveryMode</code></td>\n    <td>Set to FILESYSTEM to enable single-node recovery mode (default: NONE).</td>\n    <td>0.8.1</td>\n  </tr>\n  <tr>"
  },
  {
    "id" : "e0c9234c-2a74-4d49-b54c-f321a5e15923",
    "prId" : 28064,
    "prUrl" : "https://github.com/apache/spark/pull/28064#pullrequestreview-383364787",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e478b973-c137-4dfc-b8e6-fe31d5029154",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "No JIRA ID, commit ID: d66c01f2b6defb3db6c1be99523b734a4d960532#diff-29dffdccd5a7f4c8b496c293e87c8668",
        "createdAt" : "2020-03-29T01:40:29Z",
        "updatedAt" : "2020-03-29T01:40:29Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "6787d16f5e86e5a6dbcb2d9b25c41ec5dfbedb1d",
    "line" : 86,
    "diffHunk" : "@@ -1,1 +509,513 @@    <td><code>spark.deploy.recoveryDirectory</code></td>\n    <td>The directory in which Spark will store recovery state, accessible from the Master's perspective.</td>\n    <td>0.8.1</td>\n  </tr>\n</table>"
  }
]