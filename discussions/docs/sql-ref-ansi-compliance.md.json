[
  {
    "id" : "23cd095c-4cb3-40c1-9650-141dfd9abc13",
    "prId" : 33516,
    "prUrl" : "https://github.com/apache/spark/pull/33516#pullrequestreview-715064600",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e4eea353-d277-44c8-956c-635f019e8413",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "Should we distinguish year-month and day-time interval types? ",
        "createdAt" : "2021-07-26T14:18:50Z",
        "updatedAt" : "2021-07-26T14:21:03Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      },
      {
        "id" : "3c550c68-1623-436d-a27a-e97942c38e56",
        "parentId" : "e4eea353-d277-44c8-956c-635f019e8413",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "Let's keep it simple in this section",
        "createdAt" : "2021-07-26T16:41:56Z",
        "updatedAt" : "2021-07-26T16:41:56Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "f75359a8187d38668a9f2cd37e91d7d11ee8223c",
    "line" : 64,
    "diffHunk" : "@@ -1,1 +178,182 @@| Binary    | Binary                                                           |\n| Boolean   | Boolean                                                          |\n| Interval  | Interval                                                         |\n| Map       | Map**                                                            |\n| Array     | Array**                                                          |"
  },
  {
    "id" : "21c3d6f2-ba94-4d0c-a373-781535057568",
    "prId" : 33516,
    "prUrl" : "https://github.com/apache/spark/pull/33516#pullrequestreview-715853379",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "61aba214-ca0a-439c-b65b-9fd6782c1d11",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "In this section, it says `In future releases, the behaviour of type coercion might change along with the other two type conversion rules.`\r\n\r\nWe should update it.",
        "createdAt" : "2021-07-27T12:33:24Z",
        "updatedAt" : "2021-07-27T12:33:25Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "f75359a8187d38668a9f2cd37e91d7d11ee8223c",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +67,71 @@```\n\n### Cast\n\nWhen `spark.sql.ansi.enabled` is set to `true`, explicit casting by `CAST` syntax throws a runtime exception for illegal cast patterns defined in the standard, e.g. casts from a string to an integer."
  },
  {
    "id" : "231f221c-e757-4b3c-8372-37511647cdf4",
    "prId" : 32129,
    "prUrl" : "https://github.com/apache/spark/pull/32129#pullrequestreview-634124490",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6bd55cb8-5e50-4a29-a77d-e112d637cf45",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "nit: `in a GROUP BY clause` -> `by a GROUP BY clause`?",
        "createdAt" : "2021-04-12T23:00:32Z",
        "updatedAt" : "2021-04-12T23:00:32Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "a92670dc-2179-4a9a-99ce-1919c79e4078",
        "parentId" : "6bd55cb8-5e50-4a29-a77d-e112d637cf45",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "Both should work. The second sentence is from the ANSI SQL standard.",
        "createdAt" : "2021-04-13T02:41:55Z",
        "updatedAt" : "2021-04-13T02:41:55Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      }
    ],
    "commit" : "62cee4f24ed49d9c8f967f82267dbd3f3180c32c",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +184,188 @@  - `array_col[index]`: This operator throws `ArrayIndexOutOfBoundsException` if using invalid indices.\n  - `map_col[key]`: This operator throws `NoSuchElementException` if key does not exist in map.\n  - `GROUP BY`: aliases in a select list can not be used in GROUP BY clauses. Each column referenced in a GROUP BY clause shall unambiguously reference a column of the table resulting from the FROM clause.\n\n### SQL Keywords"
  },
  {
    "id" : "eca331e2-2587-4b51-b211-2946a72c6e18",
    "prId" : 31734,
    "prUrl" : "https://github.com/apache/spark/pull/31734#pullrequestreview-603808380",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "660f9e58-7a08-4b3b-86b8-83195e8d487b",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "not related to this PR. Does section `### Type Conversion` cover the CAST behaviors?",
        "createdAt" : "2021-03-04T07:53:16Z",
        "updatedAt" : "2021-03-04T07:53:17Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "08ca0af6-235a-48d0-b698-2f25136940d2",
        "parentId" : "660f9e58-7a08-4b3b-86b8-83195e8d487b",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "Yes and no.\r\n```\r\nWhen `spark.sql.ansi.enabled` is set to `true`, explicit casting by `CAST` syntax throws a runtime exception for illegal cast patterns defined in the standard, e.g. casts from a string to an integer.\r\n```\r\ncovers this, but we had better write down all the cases that would throw exceptions.\r\n\r\nHow about a follow-up to add a subsection for all these cases under `### Type Conversion`?",
        "createdAt" : "2021-03-04T08:05:23Z",
        "updatedAt" : "2021-03-04T08:05:23Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "d2e8e187-e65e-4ec8-8dd8-e5fb139da360",
        "parentId" : "660f9e58-7a08-4b3b-86b8-83195e8d487b",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "SGTM",
        "createdAt" : "2021-03-04T08:09:38Z",
        "updatedAt" : "2021-03-04T08:09:38Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "78277190f07798956adce09c1257f9e351ea7308",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +166,170 @@  - `CAST(string_col AS TIMESTAMP)`: This operator should fail with an exception if the input string can't be parsed.\n  - `CAST(string_col AS DATE)`: This operator should fail with an exception if the input string can't be parsed.\n  - `CAST(string_col AS BOOLEAN)`: This operator should fail with an exception if the input string can't be parsed.\n\n### SQL Keywords"
  },
  {
    "id" : "0eb8d901-c47b-41c4-96a1-461e265ef9c2",
    "prId" : 31180,
    "prUrl" : "https://github.com/apache/spark/pull/31180#pullrequestreview-568162743",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5bc1a5c5-7482-4679-ba9f-5c72ebb72906",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "We could even make it lower-cased and say these are simple strings or catalog strings .. but I think it's fine either way.",
        "createdAt" : "2021-01-14T09:49:44Z",
        "updatedAt" : "2021-01-14T09:49:46Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "8da4bc2a-6213-4c76-a56b-a5c82b0e1611",
        "parentId" : "5bc1a5c5-7482-4679-ba9f-5c72ebb72906",
        "authorId" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "body" : "Considering there are \"Y\"s and \"N\"s in the table, let's keep the current way.",
        "createdAt" : "2021-01-14T11:08:32Z",
        "updatedAt" : "2021-01-14T11:08:32Z",
        "lastEditedBy" : "15acce7d-132b-48c9-894b-9bc3f4c2b09d",
        "tags" : [
        ]
      },
      {
        "id" : "c8e57e5b-055b-4cf3-9bae-b0a016795979",
        "parentId" : "5bc1a5c5-7482-4679-ba9f-5c72ebb72906",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "üëå ",
        "createdAt" : "2021-01-14T11:52:49Z",
        "updatedAt" : "2021-01-14T11:52:50Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "9fe059ca5bec9a17c15b0f92a0db9ce94069421c",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +71,75 @@‚ÄúY‚Äù indicates that the combination is syntactically valid without restriction and ‚ÄúN‚Äù indicates that the combination is not valid.\n\n| Source\\Target | Numeric | String | Date | Timestamp | Interval | Boolean | Binary | Array | Map | Struct |\n|-----------|---------|--------|------|-----------|----------|---------|--------|-------|-----|--------|\n| Numeric   | Y       | Y      | N    | N         | N        | Y       | N      | N     | N   | N      |"
  },
  {
    "id" : "20effa6b-3de9-4776-9074-e96c226e90f6",
    "prId" : 29055,
    "prUrl" : "https://github.com/apache/spark/pull/29055#pullrequestreview-445978357",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3bf3473d-9147-4775-a221-fbde33772087",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "Ah, I see. We cannot remove this line: `non-reserved|non-reserved|not a keyword`? I think users don't need to care about the words.",
        "createdAt" : "2020-07-09T14:06:33Z",
        "updatedAt" : "2020-07-10T05:54:31Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "055d40ac-d048-42b5-bcd7-f48d88d0811f",
        "parentId" : "3bf3473d-9147-4775-a221-fbde33772087",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "But is DIV a keyword?",
        "createdAt" : "2020-07-09T15:03:44Z",
        "updatedAt" : "2020-07-10T05:54:31Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "a0109c1b-ac08-4ad7-9672-452748e5fb84",
        "parentId" : "3bf3473d-9147-4775-a221-fbde33772087",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "`DIV` is a non-reserved keyword in Apache Spark. I guess we need to have this here.",
        "createdAt" : "2020-07-09T21:22:32Z",
        "updatedAt" : "2020-07-10T05:54:31Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "71e0c13277b11055b33ba5da33f1b911af505cf2",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +194,198 @@|DISTINCT|reserved|non-reserved|reserved|\n|DISTRIBUTE|non-reserved|non-reserved|non-reserved|\n|DIV|non-reserved|non-reserved|not a keyword|\n|DROP|non-reserved|non-reserved|reserved|\n|ELSE|reserved|non-reserved|reserved|"
  },
  {
    "id" : "648d3419-7ba9-4c81-9c4f-1a46cffe2e73",
    "prId" : 29055,
    "prUrl" : "https://github.com/apache/spark/pull/29055#pullrequestreview-446233898",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "468ea371-dd0d-4231-b55f-f9a1fdf67f67",
        "parentId" : null,
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "Is there any consensus to decide which version of ANSI SQL standard that we actually try to comply with? \r\n\r\nOr any protocol to define the compatibility between Spark versions and ANSI SQL standardsÔºü",
        "createdAt" : "2020-07-10T08:02:35Z",
        "updatedAt" : "2020-07-10T08:02:36Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "fc48e77a-5dea-4778-8daf-efa5d02fb057",
        "parentId" : "468ea371-dd0d-4231-b55f-f9a1fdf67f67",
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "I think the latest ANSI SQL standard is preferred.\r\n\r\nAlso to note that: ANSI compliant doesn't mean to follow everything in ANSI SQL. e.g. a keyword reserved in ANSI SQL can be non-reserved in Spark.",
        "createdAt" : "2020-07-10T08:20:58Z",
        "updatedAt" : "2020-07-10T08:20:58Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "1fee10c2-4074-4541-aad4-58f2bb27f6a1",
        "parentId" : "468ea371-dd0d-4231-b55f-f9a1fdf67f67",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "Looking at the history of this standard, the trend of it seems to add more and more keywords and change the non-reserved to reserved. I guess it's ok to follow the latest one here as literally we will add migration guide for every newly added keyword.",
        "createdAt" : "2020-07-10T08:52:39Z",
        "updatedAt" : "2020-07-10T08:52:39Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "71e0c13277b11055b33ba5da33f1b911af505cf2",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +128,132 @@Below is a list of all the keywords in Spark SQL.\n\n|Keyword|Spark SQL<br/>ANSI Mode|Spark SQL<br/>Default Mode|SQL-2016|\n|-------|----------------------|-------------------------|--------|\n|ADD|non-reserved|non-reserved|non-reserved|"
  }
]