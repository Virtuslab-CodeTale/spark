[
  {
    "id" : "53be9dce-9d9e-4a85-9b30-64274de131ce",
    "prId" : 31160,
    "prUrl" : "https://github.com/apache/spark/pull/31160#pullrequestreview-566931683",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "52768b5c-4c75-476e-9f34-cd7a778eccf0",
        "parentId" : null,
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "Totally nit: using a table instead?",
        "createdAt" : "2021-01-13T06:48:26Z",
        "updatedAt" : "2021-01-15T22:21:22Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      }
    ],
    "commit" : "b5d5f49e2c9d2b35f11c8bc81f669683957c47e4",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +1797,1801 @@\n`UnivariateFeatureSelector` operates on categorical/continuous labels with categorical/continuous features. \nUser can set `featureType` and `labelType`, and Spark will pick the score function to use based on the specified \n`featureType` and `labelType`. \n"
  }
]