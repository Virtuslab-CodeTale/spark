[
  {
    "id" : "d0775c05-c6bf-4490-aebc-bf30938bb41b",
    "prId" : 32960,
    "prUrl" : "https://github.com/apache/spark/pull/32960#pullrequestreview-687046195",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1103d7b5-8712-47ee-832c-22394560b91a",
        "parentId" : null,
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "`smaller than the broadcast hash join`  ->  `smaller than the adaptive broadcast hash join`",
        "createdAt" : "2021-06-18T05:39:18Z",
        "updatedAt" : "2021-06-18T05:39:18Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "080429f431f694f794345cda462945786d0d3be5",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +284,288 @@ \n### Converting sort-merge join to broadcast join\nAQE converts sort-merge join to broadcast hash join when the runtime statistics of any join side is smaller than the adaptive broadcast hash join threshold. This is not as efficient as planning a broadcast hash join in the first place, but it's better than keep doing the sort-merge join, as we can save the sorting of both the join sides, and read shuffle files locally to save network traffic(if `spark.sql.adaptive.localShuffleReader.enabled` is true)\n  <table class=\"table\">\n     <tr><th>Property Name</th><th>Default</th><th>Meaning</th><th>Since Version</th></tr>"
  },
  {
    "id" : "3f2253d3-a859-4a9b-9749-7fe1d0934f13",
    "prId" : 32960,
    "prUrl" : "https://github.com/apache/spark/pull/32960#pullrequestreview-703469744",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "13d55e4d-9c40-415d-86bb-97af26faa7e9",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "shall we mention the default value is the same as `spark.sql.autoBroadcastJoinThreshold`?",
        "createdAt" : "2021-07-09T12:21:28Z",
        "updatedAt" : "2021-07-09T12:21:28Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      },
      {
        "id" : "fe963cd1-3b4b-425a-9a5c-eb309f727632",
        "parentId" : "13d55e4d-9c40-415d-86bb-97af26faa7e9",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "yee, mentioned it in `Meaning` description.",
        "createdAt" : "2021-07-10T04:19:57Z",
        "updatedAt" : "2021-07-10T04:19:57Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "080429f431f694f794345cda462945786d0d3be5",
    "line" : 35,
    "diffHunk" : "@@ -1,1 +289,293 @@     <tr>\n       <td><code>spark.sql.adaptive.autoBroadcastJoinThreshold</code></td>\n       <td>(none)</td>\n       <td>\n         Configures the maximum size in bytes for a table that will be broadcast to all worker nodes when performing a join. By setting this value to -1 broadcasting can be disabled. The default value is same with <code>spark.sql.autoBroadcastJoinThreshold</code>. Note that, this config is used only in adaptive framework."
  },
  {
    "id" : "bee8e421-6e01-49b5-ba2f-55b72df8f43e",
    "prId" : 32932,
    "prUrl" : "https://github.com/apache/spark/pull/32932#pullrequestreview-690129572",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dd50ed4c-1652-4e96-bb16-c9cb8395ad7a",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "I think we need to add more details about the new hint in `sql-ref-syntax-qry-select-hints`.",
        "createdAt" : "2021-06-22T19:08:46Z",
        "updatedAt" : "2021-06-22T19:08:46Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "229f15f1-c9e3-4442-b21f-70de680a7cac",
        "parentId" : "dd50ed4c-1652-4e96-bb16-c9cb8395ad7a",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "There are other hints that seems AQE can work optimize, could we have more doc about the difference between each under AQE?",
        "createdAt" : "2021-06-22T19:20:15Z",
        "updatedAt" : "2021-06-22T19:20:16Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "6ee9b4d2-2d83-4ae6-af09-db7bf4340709",
        "parentId" : "dd50ed4c-1652-4e96-bb16-c9cb8395ad7a",
        "authorId" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "body" : "yea, it's better to add docs for the new hint. Since this PR only adds a new hint that has no big difference with previous hint, we can add more docs and use case after adding new rule.",
        "createdAt" : "2021-06-23T01:40:49Z",
        "updatedAt" : "2021-06-23T01:41:16Z",
        "lastEditedBy" : "baca2fab-b749-483f-8c77-c4db14eca9d9",
        "tags" : [
        ]
      }
    ],
    "commit" : "0fe14d0001adedef66696699d478dd4d4e9c392c",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +232,236 @@    SELECT /*+ REBALANCE(c) */ * FROM t\n\nFor more details please refer to the documentation of [Partitioning Hints](sql-ref-syntax-qry-select-hints.html#partitioning-hints).\n\n## Adaptive Query Execution"
  },
  {
    "id" : "eff039be-fa8b-4b1d-b642-3b0450d815dc",
    "prId" : 30376,
    "prUrl" : "https://github.com/apache/spark/pull/30376#pullrequestreview-530609438",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "209ed6f8-9614-43bf-ad9e-88612f14427e",
        "parentId" : null,
        "authorId" : "1a9f8688-cf0f-450f-98b0-de28f86ae603",
        "body" : "LGTM",
        "createdAt" : "2020-11-14T22:41:35Z",
        "updatedAt" : "2020-11-14T22:41:35Z",
        "lastEditedBy" : "1a9f8688-cf0f-450f-98b0-de28f86ae603",
        "tags" : [
        ]
      }
    ],
    "commit" : "cd693e19257f47bbfd8d48b7d3d6b6bc24345c21",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +281,285 @@       <td>10</td>\n       <td>\n         A partition is considered as skewed if its size is larger than this factor multiplying the median partition size and also larger than <code>spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes</code>.\n       </td>\n       <td>3.0.0</td>"
  },
  {
    "id" : "9bc2030c-75c1-4df0-a3b7-81aef07c5750",
    "prId" : 28096,
    "prUrl" : "https://github.com/apache/spark/pull/28096#pullrequestreview-386129843",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "68553572-314b-4e98-b8ee-aa7f513e9794",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-2631, commit ID: 86534d0f5255362618c05a07b0171ec35c915822#diff-41ef65b9ef5b518f77e2a03559893f4d",
        "createdAt" : "2020-04-02T06:10:16Z",
        "updatedAt" : "2020-04-02T06:10:16Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "88d955fcb061461743575833677fbe8388af845d",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +44,48 @@    on statistics of the data.\n  </td>\n  <td>1.0.1</td>\n</tr>\n<tr>"
  },
  {
    "id" : "602490a4-df32-4023-b268-0f6a1233edf7",
    "prId" : 28096,
    "prUrl" : "https://github.com/apache/spark/pull/28096#pullrequestreview-386129984",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "af796874-34c0-4788-9921-1649357a5d58",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-2650, commit ID: 779d1eb26d0f031791e93c908d51a59c3b422a55#diff-41ef65b9ef5b518f77e2a03559893f4d",
        "createdAt" : "2020-04-02T06:10:37Z",
        "updatedAt" : "2020-04-02T06:10:38Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "88d955fcb061461743575833677fbe8388af845d",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +53,57 @@    and compression, but risk OOMs when caching data.\n  </td>\n  <td>1.1.1</td>\n</tr>\n"
  },
  {
    "id" : "2dc1d660-f7ad-47a2-a9c1-9d2773894871",
    "prId" : 28096,
    "prUrl" : "https://github.com/apache/spark/pull/28096#pullrequestreview-386130157",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "91e67e92-ba08-4560-aede-b2535d227650",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-13664, commit ID: 17eec0a71ba8713c559d641e3f43a1be726b037c#diff-32bb9518401c0948c5ea19377b5069ab",
        "createdAt" : "2020-04-02T06:11:04Z",
        "updatedAt" : "2020-04-02T06:11:05Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "88d955fcb061461743575833677fbe8388af845d",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +72,76 @@      This configuration is effective only when using file-based sources such as Parquet, JSON and ORC.\n    </td>\n    <td>2.0.0</td>\n  </tr>\n  <tr>"
  },
  {
    "id" : "01e7b4aa-6957-4206-a327-b0133611d3d6",
    "prId" : 28096,
    "prUrl" : "https://github.com/apache/spark/pull/28096#pullrequestreview-386130369",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "144637d5-d96b-48c4-8feb-abc3fd7bf664",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-14259, commit ID: 400b2f863ffaa01a34a8dae1541c61526fef908b#diff-32bb9518401c0948c5ea19377b5069ab",
        "createdAt" : "2020-04-02T06:11:33Z",
        "updatedAt" : "2020-04-02T06:11:34Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "88d955fcb061461743575833677fbe8388af845d",
    "line" : 46,
    "diffHunk" : "@@ -1,1 +84,88 @@      JSON and ORC.\n    </td>\n    <td>2.0.0</td>\n  </tr>\n  <tr>"
  },
  {
    "id" : "de52ada5-d773-4c3f-a586-beaead68c21b",
    "prId" : 28096,
    "prUrl" : "https://github.com/apache/spark/pull/28096#pullrequestreview-386130577",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "edbd6b1a-16b7-40bb-a122-7eaefe8eaba5",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-4269, commit ID: fa66ef6c97e87c9255b67b03836a4ba50598ebae#diff-41ef65b9ef5b518f77e2a03559893f4d",
        "createdAt" : "2020-04-02T06:12:01Z",
        "updatedAt" : "2020-04-02T06:12:01Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "88d955fcb061461743575833677fbe8388af845d",
    "line" : 59,
    "diffHunk" : "@@ -1,1 +94,98 @@      </p>\n    </td>\n    <td>1.3.0</td>\n  </tr>\n  <tr>"
  },
  {
    "id" : "6785f42e-a9bd-4e7c-a43e-b294610a9b32",
    "prId" : 28096,
    "prUrl" : "https://github.com/apache/spark/pull/28096#pullrequestreview-386130743",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "266f8618-56aa-4db4-8346-ec6167eef651",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-2393, commit ID: c7db274be79f448fda566208946cb50958ea9b1a#diff-41ef65b9ef5b518f77e2a03559893f4d",
        "createdAt" : "2020-04-02T06:12:25Z",
        "updatedAt" : "2020-04-02T06:12:25Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "88d955fcb061461743575833677fbe8388af845d",
    "line" : 67,
    "diffHunk" : "@@ -1,1 +105,109 @@      <code>ANALYZE TABLE &lt;tableName&gt; COMPUTE STATISTICS noscan</code> has been run.\n    </td>\n    <td>1.1.0</td>\n  </tr>\n  <tr>"
  },
  {
    "id" : "f936ae82-7a65-4357-9c32-50a15ad13df6",
    "prId" : 28096,
    "prUrl" : "https://github.com/apache/spark/pull/28096#pullrequestreview-386130934",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a056f366-3f96-41ad-af36-f8acd512a853",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-1508, commit ID: 08ed9ad81397b71206c4dc903bfb94b6105691ed#diff-41ef65b9ef5b518f77e2a03559893f4d",
        "createdAt" : "2020-04-02T06:12:53Z",
        "updatedAt" : "2020-04-02T06:12:53Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "88d955fcb061461743575833677fbe8388af845d",
    "line" : 75,
    "diffHunk" : "@@ -1,1 +113,117 @@      Configures the number of partitions to use when shuffling data for joins or aggregations.\n    </td>\n    <td>1.1.0</td>\n  </tr>\n</table>"
  },
  {
    "id" : "c89f4134-d923-4ed6-ab44-dd9a7aca263c",
    "prId" : 28096,
    "prUrl" : "https://github.com/apache/spark/pull/28096#pullrequestreview-386131128",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "79e7e4e9-833a-49a1-9456-7bc907320daa",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-31037, commit ID: 46b7f1796bd0b96977ce9b473601033f397a3b18#diff-9a6b543db706f1a90f790783d6930a13",
        "createdAt" : "2020-04-02T06:13:23Z",
        "updatedAt" : "2020-04-02T06:13:24Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "88d955fcb061461743575833677fbe8388af845d",
    "line" : 91,
    "diffHunk" : "@@ -1,1 +208,212 @@       When true and <code>spark.sql.adaptive.enabled</code> is true, Spark will coalesce contiguous shuffle partitions according to the target size (specified by <code>spark.sql.adaptive.advisoryPartitionSizeInBytes</code>), to avoid too many small tasks.\n     </td>\n     <td>3.0.0</td>\n   </tr>\n   <tr>"
  },
  {
    "id" : "273852e5-81da-442a-892e-0495a5a14a53",
    "prId" : 28096,
    "prUrl" : "https://github.com/apache/spark/pull/28096#pullrequestreview-386131164",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e64f72f9-0a1c-4c03-9093-c38bb3c82c72",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-31037, commit ID: 46b7f1796bd0b96977ce9b473601033f397a3b18#diff-9a6b543db706f1a90f790783d6930a13",
        "createdAt" : "2020-04-02T06:13:29Z",
        "updatedAt" : "2020-04-02T06:13:29Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "88d955fcb061461743575833677fbe8388af845d",
    "line" : 99,
    "diffHunk" : "@@ -1,1 +216,220 @@       The minimum number of shuffle partitions after coalescing. If not set, the default value is the default parallelism of the Spark cluster. This configuration only has an effect when <code>spark.sql.adaptive.enabled</code> and <code>spark.sql.adaptive.coalescePartitions.enabled</code> are both enabled.\n     </td>\n     <td>3.0.0</td>\n   </tr>\n   <tr>"
  },
  {
    "id" : "4036c867-5ca0-434b-960b-700db9fee78c",
    "prId" : 28096,
    "prUrl" : "https://github.com/apache/spark/pull/28096#pullrequestreview-386131204",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a802ef16-75d8-4128-9dce-528f9fa271a1",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-31037, commit ID: 46b7f1796bd0b96977ce9b473601033f397a3b18#diff-9a6b543db706f1a90f790783d6930a13",
        "createdAt" : "2020-04-02T06:13:35Z",
        "updatedAt" : "2020-04-02T06:13:35Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "88d955fcb061461743575833677fbe8388af845d",
    "line" : 107,
    "diffHunk" : "@@ -1,1 +224,228 @@       The initial number of shuffle partitions before coalescing. By default it equals to <code>spark.sql.shuffle.partitions</code>. This configuration only has an effect when <code>spark.sql.adaptive.enabled</code> and <code>spark.sql.adaptive.coalescePartitions.enabled</code> are both enabled.\n     </td>\n     <td>3.0.0</td>\n   </tr>\n   <tr>"
  },
  {
    "id" : "5d3da48d-24e9-41d3-a4c1-7c439c3aa836",
    "prId" : 28096,
    "prUrl" : "https://github.com/apache/spark/pull/28096#pullrequestreview-386131236",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d82f7e02-ba06-4ecd-9976-4f6aac8f3688",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-31037, commit ID: 46b7f1796bd0b96977ce9b473601033f397a3b18#diff-9a6b543db706f1a90f790783d6930a13",
        "createdAt" : "2020-04-02T06:13:41Z",
        "updatedAt" : "2020-04-02T06:13:42Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "88d955fcb061461743575833677fbe8388af845d",
    "line" : 115,
    "diffHunk" : "@@ -1,1 +232,236 @@       The advisory size in bytes of the shuffle partition during adaptive optimization (when <code>spark.sql.adaptive.enabled</code> is true). It takes effect when Spark coalesces small shuffle partitions or splits skewed shuffle partition.\n     </td>\n     <td>3.0.0</td>\n   </tr>\n </table>"
  },
  {
    "id" : "68fe4827-fc33-44fd-b4fd-194b5c083085",
    "prId" : 28096,
    "prUrl" : "https://github.com/apache/spark/pull/28096#pullrequestreview-386131311",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "37e3c372-0435-4e3f-a54f-1f46260e12f2",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-31037, commit ID: 46b7f1796bd0b96977ce9b473601033f397a3b18#diff-9a6b543db706f1a90f790783d6930a13",
        "createdAt" : "2020-04-02T06:13:54Z",
        "updatedAt" : "2020-04-02T06:13:54Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "88d955fcb061461743575833677fbe8388af845d",
    "line" : 131,
    "diffHunk" : "@@ -1,1 +249,253 @@         When true and <code>spark.sql.adaptive.enabled</code> is true, Spark dynamically handles skew in sort-merge join by splitting (and replicating if needed) skewed partitions.\n       </td>\n       <td>3.0.0</td>\n     </tr>\n     <tr>"
  },
  {
    "id" : "9097cf50-099b-4562-a63a-b9e407a60fe7",
    "prId" : 28096,
    "prUrl" : "https://github.com/apache/spark/pull/28096#pullrequestreview-386131361",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "edc9b845-88b4-4e5d-832c-e630e910a077",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-31037, commit ID: 46b7f1796bd0b96977ce9b473601033f397a3b18#diff-9a6b543db706f1a90f790783d6930a13",
        "createdAt" : "2020-04-02T06:14:00Z",
        "updatedAt" : "2020-04-02T06:14:00Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "88d955fcb061461743575833677fbe8388af845d",
    "line" : 139,
    "diffHunk" : "@@ -1,1 +257,261 @@         A partition is considered as skewed if its size is larger than this factor multiplying the median partition size and also larger than <code>spark.sql.adaptive.skewedPartitionThresholdInBytes</code>.\n       </td>\n       <td>3.0.0</td>\n     </tr>\n     <tr>"
  },
  {
    "id" : "b43f0066-70bf-48cc-ab90-efc80c1ffb9a",
    "prId" : 28096,
    "prUrl" : "https://github.com/apache/spark/pull/28096#pullrequestreview-386131510",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0f2b4ffd-7ccc-4a66-8972-dd21358f1d24",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-31201, commit ID: 8d0800a0803d3c47938bddefa15328d654739bc5#diff-9a6b543db706f1a90f790783d6930a13",
        "createdAt" : "2020-04-02T06:14:21Z",
        "updatedAt" : "2020-04-02T06:14:21Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "88d955fcb061461743575833677fbe8388af845d",
    "line" : 147,
    "diffHunk" : "@@ -1,1 +265,269 @@         A partition is considered as skewed if its size in bytes is larger than this threshold and also larger than <code>spark.sql.adaptive.skewJoin.skewedPartitionFactor</code> multiplying the median partition size. Ideally this config should be set larger than <code>spark.sql.adaptive.advisoryPartitionSizeInBytes</code>.\n       </td>\n       <td>3.0.0</td>\n     </tr>\n   </table>"
  }
]