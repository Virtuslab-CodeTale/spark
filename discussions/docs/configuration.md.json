[
  {
    "id" : "7b99ccd1-e42f-4d33-a35b-86beb5425c8f",
    "prId" : 33615,
    "prUrl" : "https://github.com/apache/spark/pull/33615#pullrequestreview-722033841",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0e6c952c-a215-4571-888b-382ce5506b1f",
        "parentId" : null,
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "`By default, push-based shuffle is disabled at the server side, which does not perform push-based shuffle irrespective of the client side configuration` ->\r\n\r\n`Currently, push-based shuffle is disabled by default at the server side.`\r\n\r\nI am not very sure whether we need the suffix - irrespective of client part.\r\nThoughts ?",
        "createdAt" : "2021-08-04T09:07:46Z",
        "updatedAt" : "2021-08-04T09:25:07Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      }
    ],
    "commit" : "12618284d95d7b1685c2c48c79bffcb618cf4523",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +3184,3188 @@  <td>\n    Class name of the implementation of <code>MergedShuffleFileManager</code> that manages push-based shuffle. This acts as a server side config to disable or enable push-based shuffle. By default, push-based shuffle is disabled at the server side. <p> To enable push-based shuffle on the server side, set this config to <code>org.apache.spark.network.shuffle.RemoteBlockPushResolver</code></p>\n  </td>\n  <td>3.2.0</td>\n</tr>"
  },
  {
    "id" : "3b41b2a0-faba-47f1-981c-e901aae0fd30",
    "prId" : 33615,
    "prUrl" : "https://github.com/apache/spark/pull/33615#pullrequestreview-727774199",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a1b33809-242c-469d-9dff-42b7853242eb",
        "parentId" : null,
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "nit: Remove the config key in the end of the line. The description is for that key.\r\n```\r\nTo enable push-based shuffle on the server side, set this config  to <code>org.apache.spark.network.shuffle.RemoteBlockPushResolver</code></p>\r\n```",
        "createdAt" : "2021-08-11T17:48:31Z",
        "updatedAt" : "2021-08-11T17:57:02Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      }
    ],
    "commit" : "12618284d95d7b1685c2c48c79bffcb618cf4523",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +3184,3188 @@  <td>\n    Class name of the implementation of <code>MergedShuffleFileManager</code> that manages push-based shuffle. This acts as a server side config to disable or enable push-based shuffle. By default, push-based shuffle is disabled at the server side. <p> To enable push-based shuffle on the server side, set this config to <code>org.apache.spark.network.shuffle.RemoteBlockPushResolver</code></p>\n  </td>\n  <td>3.2.0</td>\n</tr>"
  },
  {
    "id" : "915bc95d-d253-4d9f-bbeb-3c16101e9bec",
    "prId" : 33615,
    "prUrl" : "https://github.com/apache/spark/pull/33615#pullrequestreview-727774199",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "91045dc6-7c15-4b11-ba58-7cdf83572696",
        "parentId" : null,
        "authorId" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "body" : "nit: Add a newline after `<code>MB-sized chunks</code>`",
        "createdAt" : "2021-08-11T17:49:47Z",
        "updatedAt" : "2021-08-11T17:57:02Z",
        "lastEditedBy" : "d35df420-57a9-43e8-b8d5-cad0f4002681",
        "tags" : [
        ]
      }
    ],
    "commit" : "12618284d95d7b1685c2c48c79bffcb618cf4523",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +3192,3196 @@  <td>\n    <p> The minimum size of a chunk when dividing a merged shuffle file into multiple chunks during push-based shuffle. A merged shuffle file consists of multiple small shuffle blocks. Fetching the complete merged shuffle file in a single disk I/O increases the memory requirements for both the clients and the external shuffle services. Instead, the external shuffle service serves the merged file in <code>MB-sized chunks</code>.<br /> This configuration controls how big a chunk can get. A corresponding index file for each merged shuffle file will be generated indicating chunk boundaries. </p>\n    <p> Setting this too high would increase the memory requirements on both the clients and the external shuffle service. </p>\n    <p> Setting this too low would increase the overall number of RPC requests to external shuffle service unnecessarily.</p>\n  </td>"
  },
  {
    "id" : "2ab2f2dd-8ba9-4b00-8c14-b2d846c53556",
    "prId" : 31990,
    "prUrl" : "https://github.com/apache/spark/pull/31990#pullrequestreview-623125959",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4160de6e-177a-4af3-8eba-1ad94261f12b",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "what about `spark.files.io.connectionTimeout`?",
        "createdAt" : "2021-03-29T11:27:47Z",
        "updatedAt" : "2021-03-29T12:08:47Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "26f07e9ee3dcf4c1f50fc73e6575d2adb7b6a146",
    "line" : 39,
    "diffHunk" : "@@ -1,1 +2019,2023 @@</tr>\n<tr>\n  <td><code>spark.rpc.io.connectionTimeout</code></td>\n  <td>value of <code>spark.network.timeout</code></td>\n  <td>"
  },
  {
    "id" : "d44a2d5d-f4bd-43fc-bb69-39224043e653",
    "prId" : 31618,
    "prUrl" : "https://github.com/apache/spark/pull/31618#pullrequestreview-601207826",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ad10e182-df49-4ded-b2e9-2c6aeb9f7126",
        "parentId" : null,
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "sorry for coming in late, was out last week, we may want to reference what other codecs can be used here.   @dongjoon-hyun thoughts?",
        "createdAt" : "2021-03-01T17:18:01Z",
        "updatedAt" : "2021-03-01T17:18:01Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      },
      {
        "id" : "f2665c6d-5457-472e-94d5-c73e9bd88df0",
        "parentId" : "ad10e182-df49-4ded-b2e9-2c6aeb9f7126",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Thank you for review, @tgravescs . Sure, I'll make a documentation follow-up.",
        "createdAt" : "2021-03-01T21:56:40Z",
        "updatedAt" : "2021-03-01T21:56:40Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "b84158af-373b-4d60-ba5f-a3c4e4f599da",
        "parentId" : "ad10e182-df49-4ded-b2e9-2c6aeb9f7126",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Here, I made a PR.\r\n- https://github.com/apache/spark/pull/31695",
        "createdAt" : "2021-03-01T22:02:52Z",
        "updatedAt" : "2021-03-01T22:02:52Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "0e88652b99b833551d3e940a24d9d2c217fe4f51",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +1043,1047 @@  <td>zstd</td>\n  <td>\n    The codec to compress logged events.\n  </td>\n  <td>3.0.0</td>"
  },
  {
    "id" : "c3556901-198a-4bf6-b626-f32e3d122d5e",
    "prId" : 31162,
    "prUrl" : "https://github.com/apache/spark/pull/31162#pullrequestreview-567439514",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "32226d14-cbf5-4bab-8bdf-83960f790f53",
        "parentId" : null,
        "authorId" : "363b0980-061e-4268-a6b1-8d344cf0887e",
        "body" : "Is this the correct release to put here?",
        "createdAt" : "2021-01-13T17:07:39Z",
        "updatedAt" : "2021-02-13T00:30:53Z",
        "lastEditedBy" : "363b0980-061e-4268-a6b1-8d344cf0887e",
        "tags" : [
        ]
      }
    ],
    "commit" : "43f30c68017b349b2b776314714c93d05cb12a01",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +2845,2849 @@    wait until it decides that it can't launch the SparkR daemon?\n  </td>\n  <td>3.2.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "2220adc3-8347-41a4-87bd-0bb06b85ce43",
    "prId" : 30710,
    "prUrl" : "https://github.com/apache/spark/pull/30710#pullrequestreview-564482933",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "aa4cade1-eba8-4dc4-b89e-aed3ae961717",
        "parentId" : null,
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "sorry I wasn't clear, I meant for you to keep the second sentence as well to explain its use.\r\n\r\nMaybe something like: \"\r\nMinimum amount of time a task runs before being considered for speculation.\r\nThis can be used to avoid launching speculative copies of tasks that are very short.\"",
        "createdAt" : "2021-01-08T17:20:08Z",
        "updatedAt" : "2021-01-09T06:53:31Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      },
      {
        "id" : "c0461ef4-5ee7-401b-9628-f528ad008807",
        "parentId" : "aa4cade1-eba8-4dc4-b89e-aed3ae961717",
        "authorId" : "fb1da7a4-0c05-42a2-9913-c8bd60c58a4f",
        "body" : "ok",
        "createdAt" : "2021-01-08T18:22:32Z",
        "updatedAt" : "2021-01-09T06:53:31Z",
        "lastEditedBy" : "fb1da7a4-0c05-42a2-9913-c8bd60c58a4f",
        "tags" : [
        ]
      }
    ],
    "commit" : "86c8d8c51050b67ae8714f1dd1249f62d8b56bd0",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +2314,2318 @@  <td>100ms</td>\n  <td>\n    Minimum amount of time a task runs before being considered for speculation.\n    This can be used to avoid launching speculative copies of tasks that are very short.\n  </td>"
  },
  {
    "id" : "d4f956c4-4432-41c4-b4de-c0f5260708e9",
    "prId" : 29090,
    "prUrl" : "https://github.com/apache/spark/pull/29090#pullrequestreview-458404806",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "30292276-39ab-4ab0-bc6d-c28d0640c058",
        "parentId" : null,
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "it seems we are a bit inconsistent across the documentation as wel (pyspark.memory, memoryOverhead)l. other memory settings just say MiB unless otherwise specified but don't mention the suffix options. I wonder if we make them all consistent.  Note one of the yarn configs says: Use lower-case suffixes, e.g. k, m, g, t, and p, for kibi-, mebi-, gibi-, tebi-, and pebibytes, respectively. but again doesn't say m is the default.",
        "createdAt" : "2020-07-30T13:34:33Z",
        "updatedAt" : "2020-08-03T13:06:05Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      }
    ],
    "commit" : "8dfe64373fdf5020f635c1ccac003c97d9a64df4",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +250,254 @@  <td>\n    Amount of memory to use per executor process, in the same format as JVM memory strings with\n    a size unit suffix (\"k\", \"m\", \"g\" or \"t\") (e.g. <code>512m</code>, <code>2g</code>) using\n    \"m\" as the default unit.\n  </td>"
  },
  {
    "id" : "c869612f-bf03-48c6-a9e1-4dc853b59c1f",
    "prId" : 28274,
    "prUrl" : "https://github.com/apache/spark/pull/28274#pullrequestreview-398152976",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "38378a66-f1ab-440d-a436-03b805659f43",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "I intentionally removed the leading spaces here because they are considered actual white spaces. Newer liquid syntax supports to ignore these white spaces but I didn't use in case old Jykill is used.\r\n\r\nSeems like it could make the html format malformed in some cases given my rough testing. Let's remove these leading white spaces next time.",
        "createdAt" : "2020-04-22T11:20:22Z",
        "updatedAt" : "2020-04-22T11:20:22Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "0393b63d-e465-4ed9-8b58-68ed2a83bfd3",
        "parentId" : "38378a66-f1ab-440d-a436-03b805659f43",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "Might the problem be that `### Spark SQL` content was inside the for-loop before?",
        "createdAt" : "2020-04-22T11:25:36Z",
        "updatedAt" : "2020-04-22T11:25:53Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      },
      {
        "id" : "b900280a-cf11-4723-86f9-f8808556e401",
        "parentId" : "38378a66-f1ab-440d-a436-03b805659f43",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "No, we already use the markdown and Liquid syntax together at https://github.com/apache/spark/blob/master/docs/sql-ref-functions-builtin.md",
        "createdAt" : "2020-04-22T12:46:58Z",
        "updatedAt" : "2020-04-22T12:46:58Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "81e043f592da25d03fe7674f00eeab9333a473a5",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +2634,2638 @@{% for static_file in site.static_files %}\n    {% if static_file.name == 'generated-runtime-sql-config-table.html' %}\n        {% include_relative generated-runtime-sql-config-table.html %}\n        {% break %}\n    {% endif %}"
  },
  {
    "id" : "8fce85cb-95ae-4d8e-a0c9-9480152516bd",
    "prId" : 28274,
    "prUrl" : "https://github.com/apache/spark/pull/28274#pullrequestreview-398095226",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "810a1b1c-f577-4105-8702-d619892c4bcb",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "You could mention `spark-default.conf` too, but it's okay.",
        "createdAt" : "2020-04-22T11:21:28Z",
        "updatedAt" : "2020-04-22T11:21:29Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "c53d21c5-128f-484e-9423-4283c29064c1",
        "parentId" : "810a1b1c-f577-4105-8702-d619892c4bcb",
        "authorId" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "body" : "`by the config file` might have the same meaning but it could be better if we use `spark-default.conf`",
        "createdAt" : "2020-04-22T11:28:13Z",
        "updatedAt" : "2020-04-22T11:28:13Z",
        "lastEditedBy" : "c62ded40-3015-4888-8e91-d671d0f615be",
        "tags" : [
        ]
      }
    ],
    "commit" : "81e043f592da25d03fe7674f00eeab9333a473a5",
    "line" : 27,
    "diffHunk" : "@@ -1,1 +2643,2647 @@\nStatic SQL configurations are cross-session, immutable Spark SQL configurations. They can be set with final values by the config file\nand command-line options with `--conf/-c` prefixed, or by setting `SparkConf` that are used to create `SparkSession`.\nExternal users can query the static sql config values via `SparkSession.conf` or via set command, e.g. `SET spark.sql.extensions;`, but cannot set/unset them.\n"
  },
  {
    "id" : "77e6641a-74ba-4f85-880d-e6225ae07ccb",
    "prId" : 28224,
    "prUrl" : "https://github.com/apache/spark/pull/28224#pullrequestreview-396286022",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "288a64f8-9fa1-4906-8f6c-1c9e728f8647",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Looks the spaces are inserted together. I removed it just to be safe.",
        "createdAt" : "2020-04-20T09:26:53Z",
        "updatedAt" : "2020-04-21T00:28:49Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "f302c91fc270fb4a7607381c3ca1af7ccbecd7c1",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +2627,2631 @@### Spark SQL\n\n{% include_relative generated-sql-configuration-table.html %}\n        {% break %}\n    {% endif %}"
  },
  {
    "id" : "04bc4a69-4b49-4a77-9cf9-342bb5a38735",
    "prId" : 28132,
    "prUrl" : "https://github.com/apache/spark/pull/28132#pullrequestreview-387899281",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "42d1154c-3daa-486c-b348-3d47f0881ae8",
        "parentId" : null,
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "`spark.shuffle.service.enabled=false` and `spark.dynamicAllocation.shuffleTracking.enabled=true` is experimental now? https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/ExecutorAllocationManager.scala#L208\r\n\r\nIf so, its better to leave some notes about that here?",
        "createdAt" : "2020-04-06T02:09:35Z",
        "updatedAt" : "2020-04-06T02:09:35Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      },
      {
        "id" : "cc3faa78-611e-4feb-9c9f-1e97d269ebee",
        "parentId" : "42d1154c-3daa-486c-b348-3d47f0881ae8",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "You mean documenting that dynamic allocation without a shuffle service is experimental? I think it's fine as is. That's documented at `spark.dynamicAllocation.shuffleTracking.enabled` at https://github.com/apache/spark/pull/24817/files#diff-76e731333fb756df3bff5ddb3b731c46R2121 (right below), and it will show a warning as you pointed out.",
        "createdAt" : "2020-04-06T02:14:14Z",
        "updatedAt" : "2020-04-06T02:15:19Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "ff3bc758-c215-4d75-b307-5aeb22354e9e",
        "parentId" : "42d1154c-3daa-486c-b348-3d47f0881ae8",
        "authorId" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "body" : "ok",
        "createdAt" : "2020-04-06T02:15:33Z",
        "updatedAt" : "2020-04-06T02:15:33Z",
        "lastEditedBy" : "044062b3-9d96-4ec3-a1e2-3a2f595bbc02",
        "tags" : [
        ]
      }
    ],
    "commit" : "c0491b3f58b6b13cc289edc348b52a66a60daf6a",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +2458,2462 @@    <br><br>\n    This requires <code>spark.shuffle.service.enabled</code> or\n    <code>spark.dynamicAllocation.shuffleTracking.enabled</code> to be set.\n    The following configurations are also relevant:\n    <code>spark.dynamicAllocation.minExecutors</code>,"
  },
  {
    "id" : "6f8c1e52-cc1a-41fc-b54e-05b64e89d01e",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381963402",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fd3b96d1-4204-4c33-b883-ab7d0f3bae6d",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "No JIRA ID, commit ID: 994f080f8ae3372366e6004600ba791c8a372ff0#diff-529fc5c06b9731c1fbda6f3db60b16aa",
        "createdAt" : "2020-03-26T12:34:27Z",
        "updatedAt" : "2020-03-26T12:34:28Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +144,148 @@    The name of your application. This will appear in the UI and in log data.\n  </td>\n  <td>0.9.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "a5b08be8-a211-4e66-9b41-3e23d0571a40",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381964297",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ec3a3c1a-59bc-456b-a2c7-1f74c0fe3ad0",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-27760, commit ID: d30284b5a51dd784f663eb4eea37087b35a54d00#diff-76e731333fb756df3bff5ddb3b731c46",
        "createdAt" : "2020-03-26T12:35:39Z",
        "updatedAt" : "2020-03-26T12:35:39Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +208,212 @@    for the driver to find the resource on startup.\n  </td>\n  <td>3.0.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "c8e55e1b-35fc-4dfc-8577-264c3ac914be",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381964613",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "05397486-41e9-4c8a-bedc-a66287c33d27",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-27488, commit ID: 74e5e41eebf9ed596b48e6db52a2a9c642e5cbc3#diff-76e731333fb756df3bff5ddb3b731c46",
        "createdAt" : "2020-03-26T12:36:05Z",
        "updatedAt" : "2020-03-26T12:36:05Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +219,223 @@    different resource addresses to this driver comparing to other drivers on the same host.\n  </td>\n  <td>3.0.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "bd1f7d85-fa88-4dce-81f1-d415bd996f99",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381964937",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d45a9feb-1077-460d-a04d-f04b7e7830e0",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-27362, commit ID: 1277f8fa92da85d9e39d9146e3099fcb75c71a8f#diff-76e731333fb756df3bff5ddb3b731c46",
        "createdAt" : "2020-03-26T12:36:32Z",
        "updatedAt" : "2020-03-26T12:36:33Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 28,
    "diffHunk" : "@@ -1,1 +230,234 @@    this config would be set to nvidia.com or amd.com)\n  </td>\n  <td>3.0.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "316b9a4b-b9cb-485c-bf82-84c3da841c1f",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381965369",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "880c0f0a-0697-4cd6-be18-0a7adcba1740",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-27760, commit ID: d30284b5a51dd784f663eb4eea37087b35a54d00#diff-76e731333fb756df3bff5ddb3b731c46",
        "createdAt" : "2020-03-26T12:37:07Z",
        "updatedAt" : "2020-03-26T12:37:08Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +298,302 @@    for the executor to find the resource on startup.\n  </td>\n  <td>3.0.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "434c38c2-ff48-4bc0-8427-4d446fd73512",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381965678",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e08294ca-c1a9-4243-89a7-cb14453c06f8",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-27024, commit ID: db2e3c43412e4a7fb4a46c58d73d9ab304a1e949#diff-76e731333fb756df3bff5ddb3b731c46",
        "createdAt" : "2020-03-26T12:37:33Z",
        "updatedAt" : "2020-03-26T12:37:33Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 44,
    "diffHunk" : "@@ -1,1 +308,312 @@    name and an array of addresses.\n  </td>\n  <td>3.0.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "be686ebb-511c-4a49-8e0f-fe60d0b2b2b6",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381966028",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e369a3b9-7c5a-4003-baab-9d143cd9671e",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-27362, commit ID: 1277f8fa92da85d9e39d9146e3099fcb75c71a8f#diff-76e731333fb756df3bff5ddb3b731c46",
        "createdAt" : "2020-03-26T12:38:02Z",
        "updatedAt" : "2020-03-26T12:38:02Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 52,
    "diffHunk" : "@@ -1,1 +319,323 @@    this config would be set to nvidia.com or amd.com)\n  </td>\n  <td>3.0.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "02ae8b14-dddc-4731-83c1-ff9de2e0a588",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381966426",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2fbc91d4-fbf0-4f46-97be-9dfcff3e040d",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "No JIRA ID, commit ID: 0e93891d3d7df849cff6442038c111ffd42a5243#diff-17fd275d280b667722664ed833c6402a",
        "createdAt" : "2020-03-26T12:38:31Z",
        "updatedAt" : "2020-03-26T12:38:31Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 60,
    "diffHunk" : "@@ -1,1 +345,349 @@    LOCAL_DIRS (YARN) environment variables set by the cluster manager.\n  </td>\n  <td>0.5.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "dcd7bfbc-178c-43e1-b0a7-54df62ed3805",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381966699",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "394ff84c-f463-4374-9220-59f2727a0106",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "No JIRA ID, commit ID: d8bcc8e9a095c1b20dd7a17b6535800d39bff80e#diff-364713d7776956cb8b0a771e9b62f82d",
        "createdAt" : "2020-03-26T12:38:55Z",
        "updatedAt" : "2020-03-26T12:38:56Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 68,
    "diffHunk" : "@@ -1,1 +353,357 @@    Logs the effective SparkConf as INFO when a SparkContext is started.\n  </td>\n  <td>0.9.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "f8e3f13b-8bfb-4038-82f9-d284abee45bf",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381966973",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "edfad5eb-87b4-4dd0-ae34-7e21106f3fec",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-544, commit ID: 2573add94cf920a88f74d80d8ea94218d812704d#diff-529fc5c06b9731c1fbda6f3db60b16aa",
        "createdAt" : "2020-03-26T12:39:19Z",
        "updatedAt" : "2020-03-26T12:39:20Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 76,
    "diffHunk" : "@@ -1,1 +362,366 @@    <a href=\"submitting-applications.html#master-urls\"> allowed master URL's</a>.\n  </td>\n  <td>0.9.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "8bfafcc5-074b-415e-a06d-58ff18d1e2d5",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381967316",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1f9f0965-b070-4ad7-b6dc-fb45d427abff",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-23472, commit ID: f83000597f250868de9722d8285fed013abc5ecf#diff-a78ecfc6a89edfaf0b60a5eaa0381970",
        "createdAt" : "2020-03-26T12:39:49Z",
        "updatedAt" : "2020-03-26T12:39:49Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 84,
    "diffHunk" : "@@ -1,1 +478,482 @@    your default properties file.\n  </td>\n  <td>3.0.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "b2013a90-49ec-4b24-9b9c-c2c0ecd5fab0",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381967771",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "06852b46-1668-426f-9d22-0fb7516864fd",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-23472, commit ID: f83000597f250868de9722d8285fed013abc5ecf#diff-a78ecfc6a89edfaf0b60a5eaa0381970",
        "createdAt" : "2020-03-26T12:40:24Z",
        "updatedAt" : "2020-03-26T12:40:24Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 92,
    "diffHunk" : "@@ -1,1 +552,556 @@    <code>-verbose:gc -Xloggc:/tmp/{{APP_ID}}-{{EXECUTOR_ID}}.gc</code>\n  </td>\n  <td>3.0.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "56822596-ef44-40cc-b954-8a72be0ffd3b",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381968119",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8e89505b-cc5b-4873-b389-2f715fcdec22",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "No JIRA ID, commit ID: 642029e7f43322f84abe4f7f36bb0b1b95d8101d#diff-529fc5c06b9731c1fbda6f3db60b16aa",
        "createdAt" : "2020-03-26T12:40:53Z",
        "updatedAt" : "2020-03-26T12:40:53Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 100,
    "diffHunk" : "@@ -1,1 +649,653 @@    process. The user can specify multiple of these to set multiple environment variables.\n  </td>\n  <td>0.9.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "15b63cb2-0a51-4e39-9f96-b60dbe1ea90a",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381968483",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "29190994-6eb6-4000-9a3f-6440fe9919cc",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-3478, commit ID: 1aa549ba9839565274a12c52fa1075b424f138a6#diff-d6fe2792e44f6babc94aabfefc8b9bce",
        "createdAt" : "2020-03-26T12:41:25Z",
        "updatedAt" : "2020-03-26T12:41:25Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 109,
    "diffHunk" : "@@ -1,1 +673,677 @@    passing a profiler class in as a parameter to the <code>SparkContext</code> constructor.\n  </td>\n  <td>1.2.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "df74c174-ef54-4ca2-ae41-c80022829e63",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381968587",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "59ff8660-3db2-4b94-a162-ae80a8b2e881",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-3478, commit ID: 1aa549ba9839565274a12c52fa1075b424f138a6#diff-d6fe2792e44f6babc94aabfefc8b9bce",
        "createdAt" : "2020-03-26T12:41:34Z",
        "updatedAt" : "2020-03-26T12:41:34Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 117,
    "diffHunk" : "@@ -1,1 +684,688 @@    automatically.\n  </td>\n  <td>1.2.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "b28eb90d-15cb-471e-9885-c082777877dd",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381969409",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fa94b80b-cca1-45d5-b00e-e41bd8b6c506",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-2538, commit ID: 14174abd421318e71c16edd24224fd5094bdfed4#diff-d6fe2792e44f6babc94aabfefc8b9bce",
        "createdAt" : "2020-03-26T12:42:40Z",
        "updatedAt" : "2020-03-26T12:42:41Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 125,
    "diffHunk" : "@@ -1,1 +695,699 @@    If the memory used during aggregation goes above this amount, it will spill the data into disks.\n  </td>\n  <td>1.1.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "b35a9443-5c20-467c-9efa-da6e6e634738",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381969826",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "be807a41-bb62-477e-94b3-9f4a320d74d2",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-9263, commit ID: 34335719a372c1951fdb4dd25b75b086faf1076f#diff-63a5d817d2d45ae24de577f6a1bd80f9",
        "createdAt" : "2020-03-26T12:43:13Z",
        "updatedAt" : "2020-03-26T12:43:13Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 133,
    "diffHunk" : "@@ -1,1 +743,747 @@    <a href=\"submitting-applications.html#advanced-dependency-management\">Advanced Dependency Management</a>.\n  </td>\n  <td>1.5.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "5b8a37a9-68c3-41c3-bfc5-90d978e1d28a",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381970006",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "45046077-5bf1-46c2-a634-00630b613b88",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-9263, commit ID: 34335719a372c1951fdb4dd25b75b086faf1076f#diff-63a5d817d2d45ae24de577f6a1bd80f9",
        "createdAt" : "2020-03-26T12:43:28Z",
        "updatedAt" : "2020-03-26T12:43:28Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 141,
    "diffHunk" : "@@ -1,1 +752,756 @@    provided in <code>spark.jars.packages</code> to avoid dependency conflicts.\n  </td>\n  <td>1.5.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "66c3b536-f84d-4052-aac6-7f3ea67b8567",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381970327",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "784c7f45-d4f1-4e01-89fd-9b1e469b955f",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-5341, commit ID: 3b7acd22ab4a134c74746e3b9a803dbd34d43855#diff-63a5d817d2d45ae24de577f6a1bd80f9",
        "createdAt" : "2020-03-26T12:43:54Z",
        "updatedAt" : "2020-03-26T12:43:54Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 149,
    "diffHunk" : "@@ -1,1 +762,766 @@    which defaults to ~/.ivy2.\n  </td>\n  <td>1.3.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "4c45205d-e6c7-4ee5-9d92-05f56cb15a52",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381970640",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7fb1ef5a-0ed7-4570-bf94-5920c6f00e82",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-17568, commit ID: 3bc2eff8880a3ba8d4318118715ea1a47048e3de#diff-4d2ab44195558d5a9d5f15b8803ef39d",
        "createdAt" : "2020-03-26T12:44:19Z",
        "updatedAt" : "2020-03-26T12:44:19Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 157,
    "diffHunk" : "@@ -1,1 +775,779 @@    found at <a href=\"http://ant.apache.org/ivy/history/latest-milestone/settings.html\">Settings Files</a>\n  </td>\n  <td>2.2.0</td>\n</tr>\n <tr>"
  },
  {
    "id" : "11e698bd-0b7c-42be-b7c3-b98d4996b92c",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381971021",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fc331a7d-ccac-47a2-9688-45925f4db8b5",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-21403, commit ID: d8257b99ddae23f702f312640a5335ddb4554403#diff-4d2ab44195558d5a9d5f15b8803ef39d",
        "createdAt" : "2020-03-26T12:44:47Z",
        "updatedAt" : "2020-03-26T12:44:48Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 165,
    "diffHunk" : "@@ -1,1 +784,788 @@    given with <code>--packages</code> or <code>spark.jars.packages</code>.\n  </td>\n  <td>2.3.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "a6bc774b-726f-448a-a4cc-05f6e30c70f1",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381971423",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "52bf608a-136b-4c43-ae3e-59c3ac0e2ad1",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-4188, commit ID: c1ea5c542f3267c0b23a7775887e3a6ece793fe3#diff-d2ce9b38bdc38ca9d7119f9c2cf79907",
        "createdAt" : "2020-03-26T12:45:18Z",
        "updatedAt" : "2020-03-26T12:45:18Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 173,
    "diffHunk" : "@@ -1,1 +870,874 @@    pauses or transient network connectivity issues.\n  </td>\n  <td>1.2.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "56464732-cb85-4296-af9d-d265f4f56239",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381971744",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8998a48c-d002-4a4e-a1e1-9c268c88c099",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-4740, commit ID: 441ec3451730c7ae3dbef8952e313071d6147ab6#diff-d2ce9b38bdc38ca9d7119f9c2cf79907",
        "createdAt" : "2020-03-26T12:45:44Z",
        "updatedAt" : "2020-03-26T12:45:45Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 181,
    "diffHunk" : "@@ -1,1 +880,884 @@    concurrency to saturate all disks, and so users may consider increasing this value.\n  </td>\n  <td>1.2.1</td>\n</tr>\n<tr>"
  },
  {
    "id" : "f2e3fdc8-66b6-4198-9daa-958e22d42ec9",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381972114",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5bd2f6a7-01bb-403c-8bfc-0c26883726ae",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-4188, commit ID: c1ea5c542f3267c0b23a7775887e3a6ece793fe3#diff-d2ce9b38bdc38ca9d7119f9c2cf79907",
        "createdAt" : "2020-03-26T12:46:18Z",
        "updatedAt" : "2020-03-26T12:46:18Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 189,
    "diffHunk" : "@@ -1,1 +890,894 @@    turn this off to force all allocations from Netty to be on-heap.\n  </td>\n  <td>1.2.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "936e0897-5c70-4ba2-8a3c-4a75afab1504",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381972769",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b4c3bf0f-7b19-4727-bd2b-8600aa7b8510",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "No JIRA ID, commit ID: 5e5d8f469a1bea9bbe606f772ccdcab7c184c651#diff-d2ce9b38bdc38ca9d7119f9c2cf79907",
        "createdAt" : "2020-03-26T12:47:14Z",
        "updatedAt" : "2020-03-26T12:47:14Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 197,
    "diffHunk" : "@@ -1,1 +899,903 @@    is 15 seconds by default, calculated as <code>maxRetries * retryWait</code>.\n  </td>\n  <td>1.2.1</td>\n</tr>\n<tr>"
  },
  {
    "id" : "85e2586c-957c-41d3-b0f3-d4a3b92e689f",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381974866",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8a332e60-4aff-4fd0-9c84-2ddc5413397e",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-2468, commit ID: 66b4c81db7e826c00f7fb449b8a8af810cf7dd9a#diff-bdee8e601924d41e93baa7287189e878",
        "createdAt" : "2020-03-26T12:49:57Z",
        "updatedAt" : "2020-03-26T12:49:58Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 205,
    "diffHunk" : "@@ -1,1 +912,916 @@    will fallback to OS default defined by Netty's <code>io.netty.util.NetUtil#SOMAXCONN</code>.\n  </td>\n  <td>1.1.1</td>\n</tr>\n<tr>"
  },
  {
    "id" : "deee5b8a-00c2-4793-b7ca-5bbff7c78e16",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381975233",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "60587236-4e26-40ed-911f-2cfee7223803",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-21501, commit ID: 1662e93119d68498942386906de309d35f4a135f#diff-97d5edc927a83a678e013ae00343df94",
        "createdAt" : "2020-03-26T12:50:28Z",
        "updatedAt" : "2020-03-26T12:50:28Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 213,
    "diffHunk" : "@@ -1,1 +941,945 @@    Cache entries limited to the specified memory footprint, in bytes unless otherwise specified.\n  </td>\n  <td>2.3.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "9245ef8d-ac1a-4516-bafd-39584e4c8661",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381975641",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "32087035-53db-46a6-9222-c9e96872b3af",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-21175, commit ID: 799e13161e89f1ea96cb1bc7b507a05af2e89cd0#diff-0ac65da2bc6b083fb861fe410c7688c2",
        "createdAt" : "2020-03-26T12:51:01Z",
        "updatedAt" : "2020-03-26T12:51:01Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 221,
    "diffHunk" : "@@ -1,1 +953,957 @@    fetch failure.\n  </td>\n  <td>2.3.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "4a12ba9c-b777-4684-830f-7936756622d7",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381975969",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6ffa5f40-436d-4370-8770-920554298100",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-8861 and SPARK-8862, commit ID: ebc3aad272b91cf58e2e1b4aa92b49b8a947a045#diff-81764e4d52817f83bdd5336ef1226bd9",
        "createdAt" : "2020-03-26T12:51:27Z",
        "updatedAt" : "2020-03-26T12:51:27Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 229,
    "diffHunk" : "@@ -1,1 +1261,1265 @@    How many finished executions the Spark UI and status APIs remember before garbage collecting.\n  </td>\n  <td>1.5.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "04f7f9fd-1937-4841-a650-c949b55517a1",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381976353",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "143ffec4-5f64-4262-8623-ed4f33361894",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-1386, commit ID: f36dc3fed0a0671b0712d664db859da28c0a98e2#diff-56b8d67d07284cfab165d5363bd3500e",
        "createdAt" : "2020-03-26T12:51:56Z",
        "updatedAt" : "2020-03-26T12:51:57Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 237,
    "diffHunk" : "@@ -1,1 +1269,1273 @@    How many finished batches the Spark UI and status APIs remember before garbage collecting.\n  </td>\n  <td>1.0.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "98657642-46ce-4d42-91f2-25a0c48d790b",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381976713",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "747fec24-d859-4097-ad61-8632394683ea",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "No JIrA ID, commit ID: e5c4cd8a5e188592f8786a265c0cd073c69ac886#diff-0544ebf7533fa70ff5103e0fe1f0b036",
        "createdAt" : "2020-03-26T12:52:25Z",
        "updatedAt" : "2020-03-26T12:52:26Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 245,
    "diffHunk" : "@@ -1,1 +1663,1667 @@    <code>reduceByKey</code>, and <code>parallelize</code> when not set by user.\n  </td>\n  <td>0.5.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "4d284d10-84e5-423d-906d-e4e07dbceb48",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381977137",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6564daa0-afb9-44e3-9e16-72d9c550c690",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "No JIRA ID, commit ID: f6f9d02e85d17da2f742ed0062f1648a9293e73c#diff-d239aee594001f8391676e1047a0381e",
        "createdAt" : "2020-03-26T12:52:57Z",
        "updatedAt" : "2020-03-26T12:52:57Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 253,
    "diffHunk" : "@@ -1,1 +1683,1687 @@    the driver.\n  </td>\n  <td>1.0.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "1936faec-4449-4f3a-8351-0a0f2e6b9de9",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381977517",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "582943f8-5565-45a1-857a-1d6e75d4a58b",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-6313, commit ID: a2a94a154bdd00753b8d5e344d712664c7151050#diff-d239aee594001f8391676e1047a0381e",
        "createdAt" : "2020-03-26T12:53:25Z",
        "updatedAt" : "2020-03-26T12:53:26Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 261,
    "diffHunk" : "@@ -1,1 +1696,1700 @@    <a href=\"https://issues.apache.org/jira/browse/SPARK-6313\">SPARK-6313</a> for more details).\n  </td>\n  <td>1.2.2</td>\n</tr>\n<tr>"
  },
  {
    "id" : "8d5389d8-ab5c-4d40-bd93-cf8c61c1532c",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-381978057",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9be0975a-36b3-413b-920e-2a930cb2a1aa",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "No JIRA ID, commit ID: 84670f2715392859624df290c1b52eb4ed4a9cb1#diff-d239aee594001f8391676e1047a0381e",
        "createdAt" : "2020-03-26T12:54:08Z",
        "updatedAt" : "2020-03-26T12:54:09Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 269,
    "diffHunk" : "@@ -1,1 +1705,1709 @@    its contents do not match those of the source.\n  </td>\n  <td>1.0.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "017f6eae-f224-4080-a38e-a8f36d67c00b",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-382498282",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "85f16ad2-4214-4b96-be8a-b616908db2ec",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-2546, commit ID: 6d8f1dd15afdc7432b5721c89f9b2b402460322b#diff-83eb37f7b0ebed3c14ccb7bff0d577c2",
        "createdAt" : "2020-03-26T23:56:01Z",
        "updatedAt" : "2020-03-26T23:56:02Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 290,
    "diffHunk" : "@@ -1,1 +1735,1739 @@    are not affected by these issues.\n  </td>\n  <td>1.0.3</td>\n</tr>\n<tr>"
  },
  {
    "id" : "cd118dd6-ff37-4509-b3a9-11d802ff60b5",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-382498438",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "95759fc4-8e82-4108-aff5-20f4372f4d7c",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-1677, commit ID: 8100cbdb7546e8438019443cfc00683017c81278#diff-f70e97c099b5eac05c75288cb215e080",
        "createdAt" : "2020-03-26T23:56:30Z",
        "updatedAt" : "2020-03-26T23:56:30Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 310,
    "diffHunk" : "@@ -1,1 +1748,1752 @@    need to be rewritten to pre-existing output directories during checkpoint recovery.\n  </td>\n  <td>1.0.1</td>\n</tr>\n<tr>"
  },
  {
    "id" : "03bd0bf1-3f27-4628-a041-259475668476",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-382498622",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "07989987-9421-406f-8bed-0ac3fc4bb5d8",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-20107, commit ID: edc87d76efea7b4d19d9d0c4ddba274a3ccb8752#diff-76e731333fb756df3bff5ddb3b731c46",
        "createdAt" : "2020-03-26T23:57:04Z",
        "updatedAt" : "2020-03-26T23:57:04Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 318,
    "diffHunk" : "@@ -1,1 +1768,1772 @@    as per <a href=\"https://issues.apache.org/jira/browse/MAPREDUCE-4815\">MAPREDUCE-4815</a>.\n  </td>\n  <td>2.2.0</td>\n</tr>\n</table>"
  },
  {
    "id" : "18d809a1-664d-403a-8c55-dac4aac2416e",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-382498781",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c5263dd0-9167-4440-9b3f-e403a2b60790",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-27868, commit ID: 09ed64d795d3199a94e175273fff6fcea6b52131#diff-76e731333fb756df3bff5ddb3b731c46",
        "createdAt" : "2020-03-26T23:57:31Z",
        "updatedAt" : "2020-03-26T23:57:31Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 327,
    "diffHunk" : "@@ -1,1 +1883,1887 @@    connections arrives in a short period of time.\n  </td>\n  <td>3.0.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "c542675e-162f-4c0c-ab13-9b7a9adf46b0",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-382498945",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9207f4b7-b8b9-470e-88fc-32b4becfae93",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-24920, commit ID: e103c4a5e72bab8862ff49d6d4c1e62e642fc412#diff-0ac65da2bc6b083fb861fe410c7688c2",
        "createdAt" : "2020-03-26T23:57:59Z",
        "updatedAt" : "2020-03-26T23:57:59Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 336,
    "diffHunk" : "@@ -1,1 +1906,1910 @@    turn this off to force all allocations to be on-heap.\n  </td>\n  <td>3.0.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "22b08403-d96d-487b-a0bb-559f621b9891",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-382499087",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7e1ab762-1ee9-4995-8b6b-248f9770dbb1",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-3565, commit ID: 32f2222e915f31422089139944a077e2cbd442f9#diff-d239aee594001f8391676e1047a0381e",
        "createdAt" : "2020-03-26T23:58:26Z",
        "updatedAt" : "2020-03-26T23:58:26Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 345,
    "diffHunk" : "@@ -1,1 +1918,1922 @@    to port + maxRetries.\n  </td>\n  <td>1.1.1</td>\n</tr>\n<tr>"
  },
  {
    "id" : "1981ea94-7c27-4839-8f47-7e4f2dbe081b",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-382499246",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7948ed69-209c-4cda-9fec-a6c0d8087fd7",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-2677, commit ID: bd3ce2ffb8964abb4d59918ebb2c230fe4614aa2#diff-f748e95f2aa97ed715afa53ddeeac9de",
        "createdAt" : "2020-03-26T23:58:57Z",
        "updatedAt" : "2020-03-26T23:58:58Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 354,
    "diffHunk" : "@@ -1,1 +1961,1965 @@    you can set larger value.\n  </td>\n  <td>1.1.1</td>\n</tr>\n<tr>"
  },
  {
    "id" : "cc4c9180-91ca-49ef-a81c-c04d7094877b",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-382499458",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7e9c49f0-fd78-4412-aef7-168ef877a5ca",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-28574, commit ID: c212c9d9ed7375cd1ea16c118733edd84037ec0d#diff-eb519ad78cc3cf0b95839cc37413b509",
        "createdAt" : "2020-03-26T23:59:35Z",
        "updatedAt" : "2020-03-26T23:59:35Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 362,
    "diffHunk" : "@@ -1,1 +2094,2098 @@    to shared queue are dropped. Increasing this value may result in the driver using more memory.\n  </td>\n  <td>3.0.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "2bfdb91e-f29a-43c4-a80f-8086197d4575",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-382499528",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "81f0b4af-a661-4086-8a9b-06e4434cf487",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-28574, commit ID: c212c9d9ed7375cd1ea16c118733edd84037ec0d#diff-eb519ad78cc3cf0b95839cc37413b509",
        "createdAt" : "2020-03-26T23:59:45Z",
        "updatedAt" : "2020-03-26T23:59:46Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 370,
    "diffHunk" : "@@ -1,1 +2104,2108 @@    Increasing this value may result in the driver using more memory.\n  </td>\n  <td>3.0.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "4028f871-c6d2-4935-86af-f2c8607155a1",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-382499595",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e8cd1515-876f-404c-b6d7-fda1df868469",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-28574, commit ID: c212c9d9ed7375cd1ea16c118733edd84037ec0d#diff-eb519ad78cc3cf0b95839cc37413b509",
        "createdAt" : "2020-03-26T23:59:55Z",
        "updatedAt" : "2020-03-26T23:59:56Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 378,
    "diffHunk" : "@@ -1,1 +2114,2118 @@    executorManagement queue are dropped. Increasing this value may result in the driver using more memory.\n  </td>\n  <td>3.0.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "43a54ea3-55f6-40ed-9c21-0b535802c869",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-382499658",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "171df281-5175-483b-bd9e-94b0eb744c1e",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-28574, commit ID: c212c9d9ed7375cd1ea16c118733edd84037ec0d#diff-eb519ad78cc3cf0b95839cc37413b509",
        "createdAt" : "2020-03-27T00:00:06Z",
        "updatedAt" : "2020-03-27T00:00:06Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 386,
    "diffHunk" : "@@ -1,1 +2124,2128 @@    are dropped. Increasing this value may result in the driver using more memory.\n  </td>\n  <td>3.0.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "8bfd9b3e-9d77-463f-a392-72a7548e6233",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-382499725",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d68d3ba0-2d75-49d1-8491-e37da71d8295",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-28574, commit ID: c212c9d9ed7375cd1ea16c118733edd84037ec0d#diff-eb519ad78cc3cf0b95839cc37413b509",
        "createdAt" : "2020-03-27T00:00:16Z",
        "updatedAt" : "2020-03-27T00:00:16Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 394,
    "diffHunk" : "@@ -1,1 +2134,2138 @@    this value may result in the driver using more memory.\n  </td>\n  <td>3.0.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "7b9e3a77-17f7-4b5f-b0f9-4bf2e4971f5c",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-382499990",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "49f2d5d4-4d87-43b7-9fa1-9e20ffd14276",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-27760, commit ID: d30284b5a51dd784f663eb4eea37087b35a54d00#diff-76e731333fb756df3bff5ddb3b731c46",
        "createdAt" : "2020-03-27T00:01:02Z",
        "updatedAt" : "2020-03-27T00:01:02Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 402,
    "diffHunk" : "@@ -1,1 +2317,2321 @@    4 tasks/resource, not 5).\n  </td>\n  <td>3.0.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "e94fde99-a506-4f92-841d-64989627b10c",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-382500159",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e9439216-bca1-401b-8ab3-c87a016300b6",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-13369, commit ID: 7b5d873aef672aa0aee41e338bab7428101e1ad3#diff-6a9ff7fb74fd490a50462d45db2d5e11",
        "createdAt" : "2020-03-27T00:01:28Z",
        "updatedAt" : "2020-03-27T00:01:29Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 410,
    "diffHunk" : "@@ -1,1 +2382,2386 @@    Number of consecutive stage attempts allowed before a stage is aborted.\n  </td>\n  <td>2.2.0</td>\n</tr>\n</table>"
  },
  {
    "id" : "61885425-529a-4513-825d-6fde07f51f49",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-382500395",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7200ef65-29da-40a2-b976-e282256a53c0",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-10745, commit ID: 7c5b641808740ba5eed05ba8204cdbaf3fc579f5#diff-d2ce9b38bdc38ca9d7119f9c2cf79907",
        "createdAt" : "2020-03-27T00:02:08Z",
        "updatedAt" : "2020-03-27T00:02:08Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 426,
    "diffHunk" : "@@ -1,1 +2581,2585 @@  </td>\n  <td>Number of threads used in the server thread pool</td>\n  <td>1.6.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "8b6ee047-c6cd-48fe-9cc5-a24955965b05",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-382500470",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "51c2bb39-1078-4d59-a3ad-ac85175f2bf3",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-10745, commit ID: 7c5b641808740ba5eed05ba8204cdbaf3fc579f5#diff-d2ce9b38bdc38ca9d7119f9c2cf79907",
        "createdAt" : "2020-03-27T00:02:19Z",
        "updatedAt" : "2020-03-27T00:02:19Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 434,
    "diffHunk" : "@@ -1,1 +2589,2593 @@  </td>\n  <td>Number of threads used in the client thread pool</td>\n  <td>1.6.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "719fb52f-ac04-4a39-9b41-b5254bea90f1",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-382500616",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4dd0173a-1d03-4245-8d52-4850b41215bc",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-29398, commit ID: 2f0a38cb50e3e8b4b72219c7b2b8b15d51f6b931#diff-a68a21481fea5053848ca666dd3201d8",
        "createdAt" : "2020-03-27T00:02:47Z",
        "updatedAt" : "2020-03-27T00:02:47Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 442,
    "diffHunk" : "@@ -1,1 +2597,2601 @@  </td>\n  <td>Number of threads used in RPC message dispatcher thread pool</td>\n  <td>3.0.0</td>\n</tr>\n</table>"
  },
  {
    "id" : "6778390c-c665-41b4-897b-7d86af3efd8d",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-382500766",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6aa6eb0c-84e4-4644-8489-51da97863bb0",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-10971, commit ID: 9695f452e86a88bef3bcbd1f3c0b00ad9e9ac6e1#diff-025470e1b7094d7cf4a78ea353fb3981",
        "createdAt" : "2020-03-27T00:03:16Z",
        "updatedAt" : "2020-03-27T00:03:16Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 451,
    "diffHunk" : "@@ -1,1 +2779,2783 @@    Executable for executing R scripts in client modes for driver. Ignored in cluster modes.\n  </td>\n  <td>1.5.3</td>\n</tr>\n<tr>"
  },
  {
    "id" : "c054e91e-6e38-4185-a1ca-accb68811daa",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-382500922",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "688e481d-324e-4e0a-a668-41c70434b5fb",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-17178, commit ID: fa6347938fc1c72ddc03a5f3cd2e929b5694f0a6#diff-a78ecfc6a89edfaf0b60a5eaa0381970",
        "createdAt" : "2020-03-27T00:03:42Z",
        "updatedAt" : "2020-03-27T00:03:42Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 460,
    "diffHunk" : "@@ -1,1 +2788,2792 @@    <code>spark.r.shell.command</code> is used for sparkR shell while <code>spark.r.driver.command</code> is used for running R script.\n  </td>\n  <td>2.1.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "188b48c9-b86f-4b63-b8cb-1dd9aa7ea121",
    "prId" : 28035,
    "prUrl" : "https://github.com/apache/spark/pull/28035#pullrequestreview-382501106",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9d126e84-1c0d-4a5a-a7d1-f3714ae8bf1c",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-5484, commit ID: f971ce5dd0788fe7f5d2ca820b9ea3db72033ddc#diff-e399679417ffa6eeedf26a7630baca16",
        "createdAt" : "2020-03-27T00:04:15Z",
        "updatedAt" : "2020-03-27T00:04:15Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "9df81a8b01e561de3bafd70e30d7f9510efd106b",
    "line" : 468,
    "diffHunk" : "@@ -1,1 +2820,2824 @@  after lots of iterations. The checkpoint is disabled by default.\n  </td>\n  <td>2.2.0</td>\n</tr>\n</table>"
  },
  {
    "id" : "ebba4d6b-4c85-4ced-a8b2-314a435101d1",
    "prId" : 27931,
    "prUrl" : "https://github.com/apache/spark/pull/27931#pullrequestreview-377409565",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f436caa2-5add-4410-8700-313cbed1240e",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-26700, commit ID: d8613571bc1847775dd5c1945757279234cb388c#diff-6bdad48cfc34314e89599655442ff210",
        "createdAt" : "2020-03-19T04:01:06Z",
        "updatedAt" : "2020-03-19T06:40:42Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "f3c9998f44611a6d7a45f11b1406755a7bcd0b34",
    "line" : 317,
    "diffHunk" : "@@ -1,1 +1933,1937 @@    external shuffle service is at least 2.3.0.\n  </td>\n  <td>3.0.0</td>\n</tr>\n</table>"
  },
  {
    "id" : "8105a995-8d40-434f-9e74-2aea18e5eeaa",
    "prId" : 27898,
    "prUrl" : "https://github.com/apache/spark/pull/27898#pullrequestreview-379225973",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bfa6fc6a-7d15-4510-bb0d-5b5e71619f35",
        "parentId" : null,
        "authorId" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "body" : "The version is not set in the code.",
        "createdAt" : "2020-03-20T13:35:08Z",
        "updatedAt" : "2020-03-21T09:07:40Z",
        "lastEditedBy" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "tags" : [
        ]
      },
      {
        "id" : "ccf1fb5e-14a6-499f-a44e-2034e460478d",
        "parentId" : "bfa6fc6a-7d15-4510-bb0d-5b5e71619f35",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "Thanks. I will document them in a separate PR.",
        "createdAt" : "2020-03-21T01:48:06Z",
        "updatedAt" : "2020-03-21T09:07:40Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      },
      {
        "id" : "1a80359c-75b5-4766-87be-90c7de931b42",
        "parentId" : "bfa6fc6a-7d15-4510-bb0d-5b5e71619f35",
        "authorId" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "body" : "The comment here is to add version(....) to the code which belongs to this PR...",
        "createdAt" : "2020-03-21T06:23:00Z",
        "updatedAt" : "2020-03-21T09:07:40Z",
        "lastEditedBy" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "tags" : [
        ]
      },
      {
        "id" : "55d03218-e3b9-4a00-8c33-2ef8299bafdf",
        "parentId" : "bfa6fc6a-7d15-4510-bb0d-5b5e71619f35",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "OK. I revert it temporarily.",
        "createdAt" : "2020-03-21T09:05:53Z",
        "updatedAt" : "2020-03-21T09:07:40Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      },
      {
        "id" : "6f31ad2a-e997-4d80-baf6-01cfd75d3aab",
        "parentId" : "bfa6fc6a-7d15-4510-bb0d-5b5e71619f35",
        "authorId" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "body" : "That said the added version in the `md` file is fine and we shouldn't revert it (in order to have a complete config list with versions). The suggestion is to add the version in the code like this:\r\n```\r\n  private[spark] val MAX_RATE_PER_PARTITION =\r\n    ConfigBuilder(\"spark.streaming.kafka.maxRatePerPartition\")\r\n    .version(\"1.3.0\")\r\n    .longConf\r\n    .createWithDefault(0)\r\n```\r\n",
        "createdAt" : "2020-03-21T09:56:00Z",
        "updatedAt" : "2020-03-21T09:56:01Z",
        "lastEditedBy" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "tags" : [
        ]
      },
      {
        "id" : "03ef4ad4-0090-4250-8dd6-35eb33b134b1",
        "parentId" : "bfa6fc6a-7d15-4510-bb0d-5b5e71619f35",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "> spark.streaming.kafka.maxRatePerPartition\r\n\r\nThis config exists in `https://github.com/apache/spark/blob/master/external/kafka-0-10/src/main/scala/org/apache/spark/streaming/kafka010/package.scala` and I will add version in another PR.",
        "createdAt" : "2020-03-21T10:52:25Z",
        "updatedAt" : "2020-03-21T10:54:07Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      },
      {
        "id" : "925c00ac-224c-4a0f-8b35-9e3c59d2e7e7",
        "parentId" : "bfa6fc6a-7d15-4510-bb0d-5b5e71619f35",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "@beliefer, I think you had to clarify you're working on this for each file as the logical group. Seems like that missing context is causing the miscommunication here with @gaborgsomogyi.",
        "createdAt" : "2020-03-23T02:11:10Z",
        "updatedAt" : "2020-03-23T02:11:10Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "bed5fb67-02a0-4f7e-8fcc-0a7df865cb1d",
        "parentId" : "bfa6fc6a-7d15-4510-bb0d-5b5e71619f35",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "Thanks for your explanation.",
        "createdAt" : "2020-03-23T03:21:13Z",
        "updatedAt" : "2020-03-23T03:21:13Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      },
      {
        "id" : "986d227b-0df6-480f-90e8-1c16642dbb7e",
        "parentId" : "bfa6fc6a-7d15-4510-bb0d-5b5e71619f35",
        "authorId" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "body" : "Now I see the point and knowing this context LGTM. Thanks.",
        "createdAt" : "2020-03-23T08:47:15Z",
        "updatedAt" : "2020-03-23T08:47:15Z",
        "lastEditedBy" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "tags" : [
        ]
      }
    ],
    "commit" : "cca20498190bad4f707c610ebd05133050292ea1",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +2481,2485 @@    only as fast as the system can process. Internally, this dynamically sets the\n    maximum receiving rate of receivers. This rate is upper bounded by the values\n    <code>spark.streaming.receiver.maxRate</code> and <code>spark.streaming.kafka.maxRatePerPartition</code>\n    if they are set (see below).\n  </td>"
  },
  {
    "id" : "8c3216ce-c048-4f21-8f0b-e8a79dec88ef",
    "prId" : 27898,
    "prUrl" : "https://github.com/apache/spark/pull/27898#pullrequestreview-378904249",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "66d5d426-fcbd-4587-b95c-0b828da987ff",
        "parentId" : null,
        "authorId" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "body" : "Same here.",
        "createdAt" : "2020-03-20T13:35:37Z",
        "updatedAt" : "2020-03-21T09:07:40Z",
        "lastEditedBy" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "tags" : [
        ]
      },
      {
        "id" : "7b1fa5c2-07e4-43c5-99bd-bfa9bcf75ba7",
        "parentId" : "66d5d426-fcbd-4587-b95c-0b828da987ff",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "Thanks. I will document them in a separate PR.",
        "createdAt" : "2020-03-21T01:48:16Z",
        "updatedAt" : "2020-03-21T09:07:40Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      },
      {
        "id" : "1ae4e07f-0520-4114-a5a6-518db2caae85",
        "parentId" : "66d5d426-fcbd-4587-b95c-0b828da987ff",
        "authorId" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "body" : "And here also...",
        "createdAt" : "2020-03-21T06:23:22Z",
        "updatedAt" : "2020-03-21T09:07:40Z",
        "lastEditedBy" : "e6f86365-3ac2-48b4-94f9-21ce737cf1ac",
        "tags" : [
        ]
      },
      {
        "id" : "15f26f8a-d483-4a4b-9c53-8d9babace382",
        "parentId" : "66d5d426-fcbd-4587-b95c-0b828da987ff",
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "I revert it temporarily too.",
        "createdAt" : "2020-03-21T09:06:38Z",
        "updatedAt" : "2020-03-21T09:07:40Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "cca20498190bad4f707c610ebd05133050292ea1",
    "line" : 75,
    "diffHunk" : "@@ -1,1 +2561,2565 @@</tr>\n<tr>\n  <td><code>spark.streaming.kafka.minRatePerPartition</code></td>\n  <td>1</td>\n  <td>"
  },
  {
    "id" : "b76eaa86-37aa-4961-b747-8c69929b713f",
    "prId" : 27563,
    "prUrl" : "https://github.com/apache/spark/pull/27563#pullrequestreview-358907626",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "eacf438c-3a14-4298-804b-672e3988a511",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "@HyukjinKwon is it possible to generate core config document automatically as well?",
        "createdAt" : "2020-02-14T12:27:56Z",
        "updatedAt" : "2020-02-18T06:12:23Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "83fda3c90dd7cea7db4353be881965c8aa9e12ac",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +1642,1646 @@<tr><th>Property Name</th><th>Default</th><th>Meaning</th></tr>\n<tr>\n  <td><code>spark.eventLog.logStageExecutorMetrics</code></td>\n  <td>false</td>\n  <td>"
  },
  {
    "id" : "1682c355-6424-462c-8e2c-c366f0076de0",
    "prId" : 27459,
    "prUrl" : "https://github.com/apache/spark/pull/27459#pullrequestreview-355064478",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "27a5daae-b540-409b-876a-32244c0962c7",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Hm, @nchammas did it work in your local just for doubly sure? It didn't work in my local... static_files seems only referring the files under `_site`.",
        "createdAt" : "2020-02-06T23:15:44Z",
        "updatedAt" : "2020-02-07T23:13:31Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "06c6ce18-6f3f-4d7f-9315-1ffd78e5b9df",
        "parentId" : "27a5daae-b540-409b-876a-32244c0962c7",
        "authorId" : "fd6ebc48-7da4-490b-8d41-2e8530d92720",
        "body" : "Yup, I've tested everything out. What version of Jekyll are you running?\r\n\r\nHere's what I've got:\r\n\r\n```\r\ngem install jekyll:4.0.0 jekyll-redirect-from:0.16.0 rouge:3.15.0\r\npip install sphinx==2.3.1 mkdocs==1.0.4 numpy==1.18.1\r\n```\r\n\r\nBy the way, I am planning to address the fact that we don't pin our doc build dependencies in a follow-up PR.",
        "createdAt" : "2020-02-06T23:19:20Z",
        "updatedAt" : "2020-02-07T23:13:31Z",
        "lastEditedBy" : "fd6ebc48-7da4-490b-8d41-2e8530d92720",
        "tags" : [
        ]
      },
      {
        "id" : "e80ec074-31f6-4222-b91b-f98dd7cc2b50",
        "parentId" : "27a5daae-b540-409b-876a-32244c0962c7",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Okay .. seems I tested wrongly.. it works in my local too.",
        "createdAt" : "2020-02-07T10:30:22Z",
        "updatedAt" : "2020-02-07T23:13:31Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "b08bac43a844376bc870cb99c776d50157c39a01",
    "line" : 43,
    "diffHunk" : "@@ -1,1 +2402,2406 @@\n{% for static_file in site.static_files %}\n    {% if static_file.name == 'sql-configs.html' %}\n### Spark SQL\n"
  },
  {
    "id" : "0e99ea23-c1f3-4685-99c5-5a34fe9aad4c",
    "prId" : 27329,
    "prUrl" : "https://github.com/apache/spark/pull/27329#pullrequestreview-351156300",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f126c337-7df5-426f-b0c5-1dede251f669",
        "parentId" : null,
        "authorId" : "acf5aefc-4c46-451e-a28d-492ceaffd160",
        "body" : "I propose to add that the polling interval is expressed in milliseconds",
        "createdAt" : "2020-01-30T08:55:50Z",
        "updatedAt" : "2020-01-31T19:14:28Z",
        "lastEditedBy" : "acf5aefc-4c46-451e-a28d-492ceaffd160",
        "tags" : [
        ]
      },
      {
        "id" : "9a712705-99e8-40f6-b416-2fb67a44bf8f",
        "parentId" : "f126c337-7df5-426f-b0c5-1dede251f669",
        "authorId" : "119f7711-a251-4127-b455-51a922a097f1",
        "body" : "Added unit.",
        "createdAt" : "2020-01-30T21:32:22Z",
        "updatedAt" : "2020-01-31T19:14:28Z",
        "lastEditedBy" : "119f7711-a251-4127-b455-51a922a097f1",
        "tags" : [
        ]
      }
    ],
    "commit" : "5e134dd1a81e2b9ec20c3f3bfe2bb76172a4a639",
    "line" : 36,
    "diffHunk" : "@@ -1,1 +1657,1661 @@    If 0, the polling is done on executor heartbeats (thus at the heartbeat interval,\n    specified by <code>spark.executor.heartbeatInterval</code>).\n    If positive, the polling is done at this interval.\n  </td>\n</tr>"
  },
  {
    "id" : "a2357923-b357-4879-90c8-e4df3fcee4e3",
    "prId" : 27244,
    "prUrl" : "https://github.com/apache/spark/pull/27244#pullrequestreview-411149051",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dc1c0376-8ae2-4b42-bbce-e34336cda132",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Hi, @FereX98 . So, does this PR aim to match this with `--master local[4]`?",
        "createdAt" : "2020-01-17T03:32:14Z",
        "updatedAt" : "2020-01-17T03:54:33Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "ea14e3f5-3a44-435c-bb30-b6c41e777ac4",
        "parentId" : "dc1c0376-8ae2-4b42-bbce-e34336cda132",
        "authorId" : "a7900701-e1fb-4708-ab11-ea0bbbff1312",
        "body" : "Yeah I guess so",
        "createdAt" : "2020-01-17T03:45:54Z",
        "updatedAt" : "2020-01-17T03:45:54Z",
        "lastEditedBy" : "a7900701-e1fb-4708-ab11-ea0bbbff1312",
        "tags" : [
        ]
      },
      {
        "id" : "399a7e2f-47fb-4b6a-ae3b-d6b1c88d6327",
        "parentId" : "dc1c0376-8ae2-4b42-bbce-e34336cda132",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Could you check the other example in this file?\r\nFor example, line 2725 seems to be the same with this example.\r\n- https://github.com/apache/spark/blame/19ffc9096339bde87f774b92f16c2441adf5841c/docs/configuration.md#L2725",
        "createdAt" : "2020-01-17T04:01:40Z",
        "updatedAt" : "2020-01-17T04:01:41Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "0cebd40a-9d72-419e-a955-fffd932a3849",
        "parentId" : "dc1c0376-8ae2-4b42-bbce-e34336cda132",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "This is fine. It's also fine to say `--master your-master-here` or something to indicate this doesn't matter",
        "createdAt" : "2020-05-13T17:33:17Z",
        "updatedAt" : "2020-05-13T17:33:18Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      }
    ],
    "commit" : "19ffc9096339bde87f774b92f16c2441adf5841c",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +91,95 @@{% highlight bash %}\n./bin/spark-submit --name \"My app\" --master local[4] --conf spark.eventLog.enabled=false\n  --conf \"spark.driver.extraJavaOptions=-XX:+PrintGCDetails -XX:+PrintGCTimeStamps\" myApp.jar\n{% endhighlight %}\n"
  },
  {
    "id" : "fac98239-b581-42a0-b015-e8d60afe616a",
    "prId" : 27230,
    "prUrl" : "https://github.com/apache/spark/pull/27230#pullrequestreview-344411274",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0a7a8b26-47f1-4634-9dac-9ecbed9ae64b",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Just to be clear, do you mean `0 and negative values` by `If set below 1`?",
        "createdAt" : "2020-01-17T00:36:31Z",
        "updatedAt" : "2020-01-17T00:36:31Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "ec693a3e-a2f3-47b3-99bc-99a2125f388f",
        "parentId" : "0a7a8b26-47f1-4634-9dac-9ecbed9ae64b",
        "authorId" : "3df17fba-a6ac-4783-b487-855c477b5786",
        "body" : "yes",
        "createdAt" : "2020-01-17T07:58:34Z",
        "updatedAt" : "2020-01-17T07:58:34Z",
        "lastEditedBy" : "3df17fba-a6ac-4783-b487-855c477b5786",
        "tags" : [
        ]
      }
    ],
    "commit" : "a3d399c4064f045158181186fd16af8245b3e299",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +851,855 @@    up with a large number of connections arriving in a short period of time. This needs to\n    be configured wherever the shuffle service itself is running, which may be outside of the\n    application (see <code>spark.shuffle.service.enabled</code> option below). If set below 1,\n    will fallback to OS default defined by Netty's <code>io.netty.util.NetUtil#SOMAXCONN</code>.\n  </td>"
  },
  {
    "id" : "8e7a8654-e6f8-46da-a2d8-3ecb4fbd063b",
    "prId" : 26676,
    "prUrl" : "https://github.com/apache/spark/pull/26676#pullrequestreview-323404800",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6621951e-5dcc-4028-8d4e-f55c2cc7e650",
        "parentId" : null,
        "authorId" : "bc001dd4-5224-4ca1-afdd-49d69783d7f2",
        "body" : "`spark.scheduler.listenerbus.eventqueue.queueName.capacity` -> `spark.scheduler.listenerbus.eventqueue.${queueName}.capacity`",
        "createdAt" : "2019-11-26T18:57:30Z",
        "updatedAt" : "2019-11-26T18:57:30Z",
        "lastEditedBy" : "bc001dd4-5224-4ca1-afdd-49d69783d7f2",
        "tags" : [
        ]
      },
      {
        "id" : "d92f8985-517f-432f-82b7-b9fdd1694210",
        "parentId" : "6621951e-5dcc-4028-8d4e-f55c2cc7e650",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "err... shall we do another follow up ?",
        "createdAt" : "2019-11-27T03:00:27Z",
        "updatedAt" : "2019-11-27T03:00:27Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "022c62b41c46e79a5a4352a48a2ffa2a09bb012a",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +1854,1858 @@  <td>\n    The default capacity for event queues. Spark will try to initialize an event queue \n    using capacity specified by `spark.scheduler.listenerbus.eventqueue.queueName.capacity` \n    first. If it's not configured, Spark will use the default capacity specified by this \n    config. Note that capacity must be greater than 0. Consider increasing value (e.g. 20000) "
  },
  {
    "id" : "5694ba19-7bc6-4fa6-80ec-018e79f10ae0",
    "prId" : 26624,
    "prUrl" : "https://github.com/apache/spark/pull/26624#pullrequestreview-582886566",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ea9ffc70-b464-40d2-bd17-5b8e0234fd8e",
        "parentId" : null,
        "authorId" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "body" : "`patternLayout ` -> `PatternLayout `. \r\n\r\nCould you give an example to show how to use it in this document? For example, use an example to show how to specify your application names/identifiers. \r\n",
        "createdAt" : "2020-06-17T06:13:39Z",
        "updatedAt" : "2020-06-17T06:13:39Z",
        "lastEditedBy" : "d19fc546-1296-40ce-befb-9eca847aeceb",
        "tags" : [
        ]
      },
      {
        "id" : "c4d5f6da-019a-4cc6-abaf-e7446644c995",
        "parentId" : "ea9ffc70-b464-40d2-bd17-5b8e0234fd8e",
        "authorId" : "ead96df1-9137-40f5-b468-60307b779a18",
        "body" : "@gatorsmile were you able to figure this out? My MDC values are not propagating in my logs after following this same procedure.",
        "createdAt" : "2021-01-28T23:48:18Z",
        "updatedAt" : "2021-01-28T23:48:19Z",
        "lastEditedBy" : "ead96df1-9137-40f5-b468-60307b779a18",
        "tags" : [
        ]
      },
      {
        "id" : "69c425be-ccd9-4bd9-ad45-6909ac6355e9",
        "parentId" : "ea9ffc70-b464-40d2-bd17-5b8e0234fd8e",
        "authorId" : "1225643b-a460-4739-bcad-a1e7ff836415",
        "body" : "@alefischer13 Just a guess, but it looks like this was changed in 54e702c so that the MDC key still includes the `mdc.` prefix.",
        "createdAt" : "2021-02-03T23:11:28Z",
        "updatedAt" : "2021-02-03T23:11:29Z",
        "lastEditedBy" : "1225643b-a460-4739-bcad-a1e7ff836415",
        "tags" : [
        ]
      }
    ],
    "commit" : "d5c1aa97bd69a25de5de03ec79284f39dace3198",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +2957,2961 @@\nBy default, Spark adds 1 record to the MDC (Mapped Diagnostic Context): `taskName`, which shows something\nlike `task 1.0 in stage 0.0`. You can add `%X{taskName}` to your patternLayout in\norder to print it in the logs.\nMoreover, you can use `spark.sparkContext.setLocalProperty(\"mdc.\" + name, \"value\")` to add user specific data into MDC."
  },
  {
    "id" : "3164b168-78c0-42af-b69a-60dd62dcab39",
    "prId" : 26078,
    "prUrl" : "https://github.com/apache/spark/pull/26078#pullrequestreview-300092350",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0bbd7de8-fa82-4546-94c6-7a1231ba48d8",
        "parentId" : null,
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "we should also add that any fractional value specified gets rounded to have an even number of tasks per resource.  ie 0.2222 end up with 4 tasks per resource ",
        "createdAt" : "2019-10-10T14:47:22Z",
        "updatedAt" : "2019-11-01T21:58:00Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      }
    ],
    "commit" : "d579c5d50ee793a09eebbb94f7998012ec81aa1e",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +2003,2007 @@    so that your executors are created with that resource type. In addition to whole amounts, \n    a fractional amount (for example, 0.25, which means 1/4th of a resource) may be specified. \n    Fractional amounts must be less than or equal to 0.5, or in other words, the minimum amount of\n    resource sharing is 2 tasks per resource. Additionally, fractional amounts are floored \n    in order to assign resource slots (e.g. a 0.2222 configuration, or 1/0.2222 slots will become "
  },
  {
    "id" : "230237d2-2f22-417b-94ec-3b5fce251973",
    "prId" : 26047,
    "prUrl" : "https://github.com/apache/spark/pull/26047#pullrequestreview-298395999",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1b6a6b0b-ae86-40eb-bf15-c838d997f5d7",
        "parentId" : null,
        "authorId" : "bc001dd4-5224-4ca1-afdd-49d69783d7f2",
        "body" : "`spark.driver.executor.{resourceName}.discoveryScript` -> `spark.executor.resource.{resourceName}.discoveryScript`",
        "createdAt" : "2019-10-07T20:38:38Z",
        "updatedAt" : "2019-10-07T20:38:39Z",
        "lastEditedBy" : "bc001dd4-5224-4ca1-afdd-49d69783d7f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "6d16c38db954dffb218eb401d772d7098df7cdf5",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +2640,2644 @@deep learning and signal processing. Spark now supports requesting and scheduling generic resources, such as GPUs, with a few caveats. The current implementation requires that the resource have addresses that can be allocated by the scheduler. It requires your cluster manager to support and be properly configured with the resources.\n\nThere are configurations available to request resources for the driver: <code>spark.driver.resource.{resourceName}.amount</code>, request resources for the executor(s): <code>spark.executor.resource.{resourceName}.amount</code> and specify the requirements for each task: <code>spark.task.resource.{resourceName}.amount</code>. The <code>spark.driver.resource.{resourceName}.discoveryScript</code> config is required on YARN, Kubernetes and a client side Driver on Spark Standalone. <code>spark.executor.resource.{resourceName}.discoveryScript</code> config is required for YARN and Kubernetes. Kubernetes also requires <code>spark.driver.resource.{resourceName}.vendor</code> and/or <code>spark.executor.resource.{resourceName}.vendor</code>. See the config descriptions above for more information on each.\n\nSpark will use the configurations specified to first request containers with the corresponding resources from the cluster manager. Once it gets the container, Spark launches an Executor in that container which will discover what resources the container has and the addresses associated with each resource. The Executor will register with the Driver and report back the resources available to that Executor. The Spark scheduler can then schedule tasks to each Executor and assign specific resource addresses based on the resource requirements the user specified. The user can see the resources assigned to a task using the <code>TaskContext.get().resources</code> api. On the driver, the user can see the resources assigned with the SparkContext <code>resources</code> call. It's then up to the user to use the assignedaddresses to do the processing they want or pass those into the ML/AI framework they are using."
  }
]