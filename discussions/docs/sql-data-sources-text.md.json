[
  {
    "id" : "fa6ef30b-ba53-4ecc-8ece-bfc165c2835a",
    "prId" : 32745,
    "prUrl" : "https://github.com/apache/spark/pull/32745#pullrequestreview-674890973",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "29e36c1f-1944-4c48-b532-f0fe45dbea64",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Can we change `wholetext`'s default value to `<code>false</code>`",
        "createdAt" : "2021-06-03T05:37:14Z",
        "updatedAt" : "2021-06-03T05:37:14Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "73d26ac6684a4c6bdef1b8d3f585b8524db9f260",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +55,59 @@    <td>If true, read each file from input path(s) as a single row.</td>\n    <td>read</td>\n  </tr>\n  <tr>\n    <td><code>lineSep</code></td>"
  },
  {
    "id" : "addd836c-6ce0-4447-842e-dde803b84eff",
    "prId" : 32660,
    "prUrl" : "https://github.com/apache/spark/pull/32660#pullrequestreview-668630994",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4df01e35-5f88-48f0-a0e0-d49f40201bbd",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Can you also add CREATE TABLE with OPTIONS clause? (see https://github.com/apache/spark/pull/32546#discussion_r638688399). We will fix other pages too in another Pr.",
        "createdAt" : "2021-05-26T04:43:51Z",
        "updatedAt" : "2021-05-26T04:43:51Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "1eafc34e-3302-4882-8a51-6f8add469de3",
        "parentId" : "4df01e35-5f88-48f0-a0e0-d49f40201bbd",
        "authorId" : "2d8ced12-ada1-43e1-9240-bf1c11a01e4c",
        "body" : "Oh, got it. I'll create the new JIRA and address the other pages, too.",
        "createdAt" : "2021-05-26T04:57:16Z",
        "updatedAt" : "2021-05-26T04:57:16Z",
        "lastEditedBy" : "2d8ced12-ada1-43e1-9240-bf1c11a01e4c",
        "tags" : [
        ]
      },
      {
        "id" : "1a370a61-3165-4859-95cb-d0622eee31d9",
        "parentId" : "4df01e35-5f88-48f0-a0e0-d49f40201bbd",
        "authorId" : "2d8ced12-ada1-43e1-9240-bf1c11a01e4c",
        "body" : "Just created JIRA sub-task here: SPARK-35528",
        "createdAt" : "2021-05-26T06:18:16Z",
        "updatedAt" : "2021-05-26T06:18:38Z",
        "lastEditedBy" : "2d8ced12-ada1-43e1-9240-bf1c11a01e4c",
        "tags" : [
        ]
      }
    ],
    "commit" : "f03c03dfc9ede54920c642f9129560f871c38303",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +45,49 @@  *  `DataFrameWriter`\n  *  `DataStreamReader`\n  *  `DataStreamWriter`\n  *  `OPTIONS` clause at [CREATE TABLE USING DATA_SOURCE](sql-ref-syntax-ddl-create-table-datasource.html)\n"
  },
  {
    "id" : "3ac1c9f1-5ebb-47f4-91a6-fb40b9616f1c",
    "prId" : 32660,
    "prUrl" : "https://github.com/apache/spark/pull/32660#pullrequestreview-669671587",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3a57b898-e372-4117-88a5-f6859a656d94",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Sorry I missed it here. This is not in \"the `.option`/`.options` methods of\". Can you make the level down?",
        "createdAt" : "2021-05-26T09:18:40Z",
        "updatedAt" : "2021-05-26T09:18:40Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "121e3cb6-eae1-40e4-8f0a-e4e80fd8b019",
        "parentId" : "3a57b898-e372-4117-88a5-f6859a656d94",
        "authorId" : "2d8ced12-ada1-43e1-9240-bf1c11a01e4c",
        "body" : "Sure. let me fix it in https://github.com/apache/spark/pull/32658",
        "createdAt" : "2021-05-27T01:35:33Z",
        "updatedAt" : "2021-05-27T01:35:34Z",
        "lastEditedBy" : "2d8ced12-ada1-43e1-9240-bf1c11a01e4c",
        "tags" : [
        ]
      }
    ],
    "commit" : "f03c03dfc9ede54920c642f9129560f871c38303",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +46,50 @@  *  `DataStreamReader`\n  *  `DataStreamWriter`\n  *  `OPTIONS` clause at [CREATE TABLE USING DATA_SOURCE](sql-ref-syntax-ddl-create-table-datasource.html)\n\n<table class=\"table\">"
  },
  {
    "id" : "91694432-a3d4-4c2d-a2bb-5ccc2bec7330",
    "prId" : 32053,
    "prUrl" : "https://github.com/apache/spark/pull/32053#pullrequestreview-629632714",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b8aec39c-f3af-4427-8c9f-e63385e8227a",
        "parentId" : null,
        "authorId" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "body" : "I am not sure this sounds ok \"each line becomes each row\". @srowen WDYT?",
        "createdAt" : "2021-04-07T06:26:19Z",
        "updatedAt" : "2021-04-07T07:03:51Z",
        "lastEditedBy" : "5c8bf89e-8bb3-4151-8b92-286da26c827e",
        "tags" : [
        ]
      }
    ],
    "commit" : "5b647116ddef80ee74cca4405f0292ef41c76f26",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +20,24 @@---\n\nSpark SQL provides `spark.read().text(\"file_name\")` to read a file or directory of text files into a Spark DataFrame, and `dataframe.write().text(\"path\")` to write to a text file. When reading a text file, each line becomes each row that has string \"value\" column by default. The line separator can be changed as shown in the example below. The `option()` function can be used to customize the behavior of reading or writing, such as controlling behavior of the line separator, compression, and so on.\n\n<!--TODO(SPARK-34491): add `option()` document reference-->"
  }
]