[
  {
    "id" : "5d150bde-036c-4bad-9061-5de2bc750b64",
    "prId" : 30049,
    "prUrl" : "https://github.com/apache/spark/pull/30049#pullrequestreview-509549639",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dcd2f551-1919-4f04-aefe-02755cd51d29",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "nit: I think `Only 3 is available for Python3` like below looks better.",
        "createdAt" : "2020-10-15T16:15:35Z",
        "updatedAt" : "2020-10-15T16:15:36Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "d500290b6b0f63184215bc9375ddb9c1387c0fe6",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1088,1092 @@  <td><code>\"3\"</code></td>\n  <td>\n   This sets the major Python version of the docker image used to run the driver and executor containers. Can be 3.\n  </td>\n  <td>2.4.0</td>"
  },
  {
    "id" : "3a530603-6a6f-4f94-a8bb-33da6a4251ce",
    "prId" : 29897,
    "prUrl" : "https://github.com/apache/spark/pull/29897#pullrequestreview-499677590",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ffea49e1-5404-47c0-aca9-0c700ad3ea0d",
        "parentId" : null,
        "authorId" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "body" : "Can you explain why it's useful for DA? Currently, this doesn't support DA yet. I think the use-case will be for people to use larger shuffle disks in Kube where larger local disks are not allowed.",
        "createdAt" : "2020-09-29T19:52:57Z",
        "updatedAt" : "2020-09-29T19:52:57Z",
        "lastEditedBy" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "tags" : [
        ]
      },
      {
        "id" : "fcef8afd-6111-4a31-8ca8-50973ee25e67",
        "parentId" : "ffea49e1-5404-47c0-aca9-0c700ad3ea0d",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "@dbtsai . What do you mean by the following?\r\n>  Currently, this doesn't support DA yet. \r\n\r\nSince Apache Spark 3.0.0, dynamic allocation with K8s has been supported with shuffle data tracking. And, this feature is also developed for both additional large disk requirement and dynamic allocation scenario. For example, in case of dynamic allocation, the executor id increases monotonically and indefinitely, so users cannot prepare unlimited pre-populated PVCs. With this feature, the PVC is created and deleted dynamically with the same lifecycle with the executor pod.",
        "createdAt" : "2020-09-30T06:51:37Z",
        "updatedAt" : "2020-09-30T07:04:52Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "5b6c8d75-f6bb-44d2-ba2c-93c0679fad57",
        "parentId" : "ffea49e1-5404-47c0-aca9-0c700ad3ea0d",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "In short, I made the PVC(and PV) be created at every pod creation in `ExecutorPodsAllocator.scala`. Please see the original code. For example, if you kill some pod, new executor is going to be created with a new PVC.\r\n- https://github.com/apache/spark/pull/29846 [SPARK-32971][K8S] Support dynamic PVC creation/deletion for K8s executors\r\n\r\ncc @viirya ",
        "createdAt" : "2020-09-30T07:03:17Z",
        "updatedAt" : "2020-09-30T07:03:17Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "1c64ba2c-9413-4091-bbdd-fb12f1662a07",
        "parentId" : "ffea49e1-5404-47c0-aca9-0c700ad3ea0d",
        "authorId" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "body" : "Get you. Thanks!",
        "createdAt" : "2020-09-30T17:53:30Z",
        "updatedAt" : "2020-09-30T17:53:31Z",
        "lastEditedBy" : "677aa336-324b-4b93-8300-21f8bd378f26",
        "tags" : [
        ]
      }
    ],
    "commit" : "6e9c1cf2ac7deb673e2c7ff496a2a2b4cc56727d",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +310,314 @@The configuration properties for mounting volumes into the executor pods use prefix `spark.kubernetes.executor.` instead of `spark.kubernetes.driver.`.\n\nFor example, you can mount a dynamically-created persistent volume claim per executor by using `OnDemand` as a claim name and `storageClass` and `sizeLimit` options like the following. This is useful in case of [Dynamic Allocation](configuration.html#dynamic-allocation).\n```\nspark.kubernetes.executor.volumes.persistentVolumeClaim.data.options.claimName=OnDemand"
  },
  {
    "id" : "f69261ad-73b4-4c9d-8dc5-425dcc178db5",
    "prId" : 27875,
    "prUrl" : "https://github.com/apache/spark/pull/27875#pullrequestreview-372561565",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a0245954-4878-478b-91c5-49adda06c7dc",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-22646, commit ID: 3f4060c340d6bac412e8819c4388ccba226efcf3#diff-6e882d5561424e7e6651eb46f10104b8",
        "createdAt" : "2020-03-11T08:43:36Z",
        "updatedAt" : "2020-03-11T08:43:36Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "ae359d50af4ef7a5c948bbedd86d0c33dbe62a1c",
    "line" : 253,
    "diffHunk" : "@@ -1,1 +798,802 @@    for bookkeeping purposes.\n  </td>\n  <td>2.3.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "95a75bb4-7a31-49d1-96ac-1350aa5108d8",
    "prId" : 27875,
    "prUrl" : "https://github.com/apache/spark/pull/27875#pullrequestreview-372561814",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c2387e43-befa-45e5-b33d-490bb7ff3880",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-22646, commit ID: 3f4060c340d6bac412e8819c4388ccba226efcf3#diff-6e882d5561424e7e6651eb46f10104b8",
        "createdAt" : "2020-03-11T08:44:01Z",
        "updatedAt" : "2020-03-11T08:44:01Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "ae359d50af4ef7a5c948bbedd86d0c33dbe62a1c",
    "line" : 261,
    "diffHunk" : "@@ -1,1 +807,811 @@    For example, <code>spark.kubernetes.driver.annotation.something=true</code>.\n  </td>\n  <td>2.3.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "9e46cf79-7158-4c4c-b298-8864e63ff14c",
    "prId" : 27875,
    "prUrl" : "https://github.com/apache/spark/pull/27875#pullrequestreview-372562085",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "53b3e4be-f6e6-4232-be25-b8700a2eb21b",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-22646, commit ID: 3f4060c340d6bac412e8819c4388ccba226efcf3#diff-6e882d5561424e7e6651eb46f10104b8",
        "createdAt" : "2020-03-11T08:44:25Z",
        "updatedAt" : "2020-03-11T08:44:25Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "ae359d50af4ef7a5c948bbedd86d0c33dbe62a1c",
    "line" : 269,
    "diffHunk" : "@@ -1,1 +818,822 @@    for bookkeeping purposes.\n  </td>\n  <td>2.3.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "9392d503-93e3-477c-95db-79bd97a38877",
    "prId" : 27875,
    "prUrl" : "https://github.com/apache/spark/pull/27875#pullrequestreview-372562178",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "22fc5c07-f4a7-4286-8305-335761496717",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-22646, commit ID: 3f4060c340d6bac412e8819c4388ccba226efcf3#diff-6e882d5561424e7e6651eb46f10104b8",
        "createdAt" : "2020-03-11T08:44:35Z",
        "updatedAt" : "2020-03-11T08:44:35Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "ae359d50af4ef7a5c948bbedd86d0c33dbe62a1c",
    "line" : 277,
    "diffHunk" : "@@ -1,1 +827,831 @@    For example, <code>spark.kubernetes.executor.annotation.something=true</code>.\n  </td>\n  <td>2.3.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "97056793-db9d-4ec3-bc74-d8fcb5e44368",
    "prId" : 27875,
    "prUrl" : "https://github.com/apache/spark/pull/27875#pullrequestreview-372562494",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4ccd860e-10da-4fd9-9966-44493218713d",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-18278, commit ID: e9b2070ab2d04993b1c0c1d6c6aba249e6664c8d#diff-6e882d5561424e7e6651eb46f10104b8",
        "createdAt" : "2020-03-11T08:45:07Z",
        "updatedAt" : "2020-03-11T08:45:08Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "ae359d50af4ef7a5c948bbedd86d0c33dbe62a1c",
    "line" : 349,
    "diffHunk" : "@@ -1,1 +914,918 @@     <code>myIdentifier</code>. Multiple node selector keys can be added by setting multiple configurations with this prefix.\n  </td>\n  <td>2.3.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "871b8b7d-2a0c-4c46-a0cd-7138ef3c69ee",
    "prId" : 27875,
    "prUrl" : "https://github.com/apache/spark/pull/27875#pullrequestreview-372562857",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "26bb880e-388e-4e66-815f-c9bcf32d3fbf",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-22646, commit ID: 3f4060c340d6bac412e8819c4388ccba226efcf3#diff-6e882d5561424e7e6651eb46f10104b8",
        "createdAt" : "2020-03-11T08:45:43Z",
        "updatedAt" : "2020-03-11T08:45:44Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "ae359d50af4ef7a5c948bbedd86d0c33dbe62a1c",
    "line" : 357,
    "diffHunk" : "@@ -1,1 +923,927 @@    the Driver process. The user can specify multiple of these to set multiple environment variables.\n  </td>\n  <td>2.3.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "c4c98bcd-be69-40ec-b242-ace6179d097c",
    "prId" : 27875,
    "prUrl" : "https://github.com/apache/spark/pull/27875#pullrequestreview-372563179",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3bdc35da-2675-429a-aa7c-5151418efcbd",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-22757, commit ID: 171f6ddadc6185ffcc6ad82e5f48952fb49095b2#diff-6e882d5561424e7e6651eb46f10104b8",
        "createdAt" : "2020-03-11T08:46:17Z",
        "updatedAt" : "2020-03-11T08:46:17Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "ae359d50af4ef7a5c948bbedd86d0c33dbe62a1c",
    "line" : 365,
    "diffHunk" : "@@ -1,1 +932,936 @@   <code>spark.kubernetes.driver.secrets.spark-secret=/etc/secrets</code>.\n  </td>\n  <td>2.3.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "021b1ca6-3156-415b-b48e-0b2a02ab840b",
    "prId" : 27875,
    "prUrl" : "https://github.com/apache/spark/pull/27875#pullrequestreview-372563278",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "43e27713-deff-4653-b829-cc52e8e03b48",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-22757, commit ID: 171f6ddadc6185ffcc6ad82e5f48952fb49095b2#diff-6e882d5561424e7e6651eb46f10104b8",
        "createdAt" : "2020-03-11T08:46:26Z",
        "updatedAt" : "2020-03-11T08:46:26Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "ae359d50af4ef7a5c948bbedd86d0c33dbe62a1c",
    "line" : 373,
    "diffHunk" : "@@ -1,1 +941,945 @@   <code>spark.kubernetes.executor.secrets.spark-secret=/etc/secrets</code>.\n  </td>\n  <td>2.3.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "03e3b918-e8d4-4a35-9a1b-7fd10040bd65",
    "prId" : 27875,
    "prUrl" : "https://github.com/apache/spark/pull/27875#pullrequestreview-372563709",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8bbcf81b-280e-4610-ae8c-af8835e5b1d4",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-24232, commit ID: 21e1fc7d4aed688d7b685be6ce93f76752159c98#diff-6e882d5561424e7e6651eb46f10104b8",
        "createdAt" : "2020-03-11T08:46:59Z",
        "updatedAt" : "2020-03-11T08:47:00Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "ae359d50af4ef7a5c948bbedd86d0c33dbe62a1c",
    "line" : 381,
    "diffHunk" : "@@ -1,1 +950,954 @@   <code>spark.kubernetes.driver.secretKeyRef.ENV_VAR=spark-secret:key</code>.\n  </td>\n  <td>2.4.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "0df62e91-fc32-4752-999f-9632d9ac288c",
    "prId" : 27875,
    "prUrl" : "https://github.com/apache/spark/pull/27875#pullrequestreview-372563861",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7d8b570f-0c9c-4746-a40b-4a337b8de000",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-24232, commit ID: 21e1fc7d4aed688d7b685be6ce93f76752159c98#diff-6e882d5561424e7e6651eb46f10104b8",
        "createdAt" : "2020-03-11T08:47:13Z",
        "updatedAt" : "2020-03-11T08:47:13Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "ae359d50af4ef7a5c948bbedd86d0c33dbe62a1c",
    "line" : 389,
    "diffHunk" : "@@ -1,1 +959,963 @@   <code>spark.kubernetes.executor.secrets.ENV_VAR=spark-secret:key</code>.\n  </td>\n  <td>2.4.0</td>\n</tr>   \n<tr>"
  },
  {
    "id" : "e9ce9891-e9f1-4106-b5c4-8b7b047de03a",
    "prId" : 27875,
    "prUrl" : "https://github.com/apache/spark/pull/27875#pullrequestreview-372564362",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "54a3e9f0-545b-4ba3-9deb-a5dca2ccaed2",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-23529, commit ID: 5ff1b9ba1983d5601add62aef64a3e87d07050eb#diff-6e882d5561424e7e6651eb46f10104b8",
        "createdAt" : "2020-03-11T08:47:58Z",
        "updatedAt" : "2020-03-11T08:47:58Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "ae359d50af4ef7a5c948bbedd86d0c33dbe62a1c",
    "line" : 397,
    "diffHunk" : "@@ -1,1 +968,972 @@   <code>spark.kubernetes.driver.volumes.persistentVolumeClaim.checkpointpvc.mount.path=/checkpoint</code>.\n  </td>\n  <td>2.4.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "c8fa45b3-980d-4a85-8424-a500cbd0a1be",
    "prId" : 27875,
    "prUrl" : "https://github.com/apache/spark/pull/27875#pullrequestreview-372564714",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e7c539cc-36e6-4536-8ce4-1714034dbae1",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-23529, commit ID: 5ff1b9ba1983d5601add62aef64a3e87d07050eb#diff-6e882d5561424e7e6651eb46f10104b8",
        "createdAt" : "2020-03-11T08:48:33Z",
        "updatedAt" : "2020-03-11T08:48:33Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "ae359d50af4ef7a5c948bbedd86d0c33dbe62a1c",
    "line" : 413,
    "diffHunk" : "@@ -1,1 +986,990 @@   <code>spark.kubernetes.driver.volumes.persistentVolumeClaim.checkpointpvc.mount.readOnly=false</code>.\n  </td>\n  <td>2.4.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "4626545e-c5a0-46ef-9fcc-d54e4b9ceb42",
    "prId" : 27875,
    "prUrl" : "https://github.com/apache/spark/pull/27875#pullrequestreview-372564807",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8555a56e-2b4d-47c4-9adf-14785cd0c530",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-23529, commit ID: 5ff1b9ba1983d5601add62aef64a3e87d07050eb#diff-6e882d5561424e7e6651eb46f10104b8",
        "createdAt" : "2020-03-11T08:48:43Z",
        "updatedAt" : "2020-03-11T08:48:43Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "ae359d50af4ef7a5c948bbedd86d0c33dbe62a1c",
    "line" : 429,
    "diffHunk" : "@@ -1,1 +1004,1008 @@   <code>spark.kubernetes.executor.volumes.persistentVolumeClaim.checkpointpvc.mount.path=/checkpoint</code>.\n  </td>\n  <td>2.4.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "fae6e088-dc0f-4f9a-acbe-3d7bbe87336d",
    "prId" : 27875,
    "prUrl" : "https://github.com/apache/spark/pull/27875#pullrequestreview-372564890",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f8e2df8c-bce1-4e62-985d-d87650d45394",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-23529, commit ID: 5ff1b9ba1983d5601add62aef64a3e87d07050eb#diff-6e882d5561424e7e6651eb46f10104b8",
        "createdAt" : "2020-03-11T08:48:51Z",
        "updatedAt" : "2020-03-11T08:48:52Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "ae359d50af4ef7a5c948bbedd86d0c33dbe62a1c",
    "line" : 445,
    "diffHunk" : "@@ -1,1 +1022,1026 @@   <code>spark.kubernetes.executor.volumes.persistentVolumeClaim.checkpointpvc.mount.readOnly=false</code>.\n  </td>\n  <td>2.4.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "c7fc8f85-10d7-40c4-9aa7-6f64b2a0f023",
    "prId" : 27875,
    "prUrl" : "https://github.com/apache/spark/pull/27875#pullrequestreview-372565471",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "daec0c1e-30d1-4863-bfea-bb3949b8da0c",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-25960, commit ID: 3df307aa515b3564686e75d1b71754bbcaaf2dec#diff-6e882d5561424e7e6651eb46f10104b8",
        "createdAt" : "2020-03-11T08:49:42Z",
        "updatedAt" : "2020-03-11T08:49:42Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "ae359d50af4ef7a5c948bbedd86d0c33dbe62a1c",
    "line" : 405,
    "diffHunk" : "@@ -1,1 +977,981 @@   <code>spark.kubernetes.driver.volumes.persistentVolumeClaim.checkpointpvc.mount.subPath=checkpoint</code>.\n  </td>\n  <td>3.0.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "c126d9bb-3ff4-46ef-be6f-150b21abe2df",
    "prId" : 27875,
    "prUrl" : "https://github.com/apache/spark/pull/27875#pullrequestreview-372565611",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3c7c4e52-62f7-4187-b68d-73283c79b939",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-25960, commit ID: 3df307aa515b3564686e75d1b71754bbcaaf2dec#diff-6e882d5561424e7e6651eb46f10104b8",
        "createdAt" : "2020-03-11T08:49:55Z",
        "updatedAt" : "2020-03-11T08:49:55Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "ae359d50af4ef7a5c948bbedd86d0c33dbe62a1c",
    "line" : 437,
    "diffHunk" : "@@ -1,1 +1013,1017 @@   <code>spark.kubernetes.executor.volumes.persistentVolumeClaim.checkpointpvc.mount.subPath=checkpoint</code>.\n  </td>\n  <td>3.0.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "3f6e6273-404d-43fd-927e-3e6b5f8618bd",
    "prId" : 27875,
    "prUrl" : "https://github.com/apache/spark/pull/27875#pullrequestreview-372566203",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b9ae2043-94cb-4c97-a8e5-48b394ee9519",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-23529, commit ID: 5ff1b9ba1983d5601add62aef64a3e87d07050eb#diff-b5527f236b253e0d9f5db5164bdb43e9",
        "createdAt" : "2020-03-11T08:50:54Z",
        "updatedAt" : "2020-03-11T08:50:55Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "ae359d50af4ef7a5c948bbedd86d0c33dbe62a1c",
    "line" : 421,
    "diffHunk" : "@@ -1,1 +995,999 @@   <code>spark.kubernetes.driver.volumes.persistentVolumeClaim.checkpointpvc.options.claimName=spark-pvc-claim</code>.\n  </td>\n  <td>2.4.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "d4223735-d3f8-417b-9c68-5aa2bbf928aa",
    "prId" : 27875,
    "prUrl" : "https://github.com/apache/spark/pull/27875#pullrequestreview-372566371",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ebce73de-d615-4e63-b8e3-bc541960cb58",
        "parentId" : null,
        "authorId" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "body" : "SPARK-23529, commit ID: 5ff1b9ba1983d5601add62aef64a3e87d07050eb#diff-b5527f236b253e0d9f5db5164bdb43e9",
        "createdAt" : "2020-03-11T08:51:09Z",
        "updatedAt" : "2020-03-11T08:51:09Z",
        "lastEditedBy" : "f26e51a2-ed90-47c7-9856-a6cc134b7f39",
        "tags" : [
        ]
      }
    ],
    "commit" : "ae359d50af4ef7a5c948bbedd86d0c33dbe62a1c",
    "line" : 453,
    "diffHunk" : "@@ -1,1 +1031,1035 @@   <code>spark.kubernetes.executor.volumes.persistentVolumeClaim.checkpointpvc.options.claimName=spark-pvc-claim</code>.\n  </td>\n  <td>2.4.0</td>\n</tr>\n<tr>"
  },
  {
    "id" : "60ccdf90-b4c3-475e-85ec-32aedbb0dc87",
    "prId" : 26433,
    "prUrl" : "https://github.com/apache/spark/pull/26433#pullrequestreview-317862661",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "326a5339-a528-4288-bac3-0a0e44d7739d",
        "parentId" : null,
        "authorId" : "0b3111e2-9584-4813-8cb5-8f40e119f71c",
        "body" : "\"numExecutors\" doesn't really mean anything when you have dynamic allocation on.",
        "createdAt" : "2019-11-15T20:51:20Z",
        "updatedAt" : "2019-11-15T20:54:21Z",
        "lastEditedBy" : "0b3111e2-9584-4813-8cb5-8f40e119f71c",
        "tags" : [
        ]
      }
    ],
    "commit" : "2ef2cd70684da1cbb355db3fb8d78f816c24764b",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +1076,1080 @@<tr>\n  <td><code>spark.kubernetes.max.executor.failures</code></td>\n  <td>numExecutors * 2, with minimum of 3</td>\n  <td>\n    The maximum number of executor failures before failing the application."
  },
  {
    "id" : "e1db5a33-09b0-4028-925f-527dc10bb737",
    "prId" : 25589,
    "prUrl" : "https://github.com/apache/spark/pull/25589#pullrequestreview-310442677",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "46d88199-089d-4e36-86c2-22e76b0f9c4c",
        "parentId" : null,
        "authorId" : "0c8b1620-5174-40bc-8668-c23ebe5822b7",
        "body" : "```suggestion\r\n    configuration's value. For example, setting <code>spark.kubernetes.driver.node.selector.identifier</code> to <code>myIdentifier</code>\r\n```",
        "createdAt" : "2019-11-01T13:09:34Z",
        "updatedAt" : "2019-11-01T13:12:51Z",
        "lastEditedBy" : "0c8b1620-5174-40bc-8668-c23ebe5822b7",
        "tags" : [
        ]
      }
    ],
    "commit" : "9dcb2385c34fe9627d1faa85ca87bd88ad3333fd",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +722,726 @@  <td>\n    Adds to the node selector of the driver pod, with key <code>labelKey</code> and the value as the\n    configuration's value. For example, setting <code>spark.kubernetes.node.selector.identifier</code> to <code>myIdentifier</code>\n    will result in the driver pod having a node selector with key <code>identifier</code> and value\n     <code>myIdentifier</code>. Multiple node selector keys can be added by setting multiple configurations with this prefix."
  },
  {
    "id" : "5b90ac93-1be4-44a7-a268-80f8d8c192c7",
    "prId" : 25589,
    "prUrl" : "https://github.com/apache/spark/pull/25589#pullrequestreview-310442677",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3b3cba18-8b70-4575-9892-d75521e639fa",
        "parentId" : null,
        "authorId" : "0c8b1620-5174-40bc-8668-c23ebe5822b7",
        "body" : "```suggestion\r\n    configuration's value. For example, setting <code>spark.kubernetes.executor.node.selector.identifier</code> to <code>myIdentifier</code>\r\n```",
        "createdAt" : "2019-11-01T13:10:15Z",
        "updatedAt" : "2019-11-01T13:12:51Z",
        "lastEditedBy" : "0c8b1620-5174-40bc-8668-c23ebe5822b7",
        "tags" : [
        ]
      }
    ],
    "commit" : "9dcb2385c34fe9627d1faa85ca87bd88ad3333fd",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +732,736 @@  <td>\n    Adds to the node selector of the executor pods, with key <code>labelKey</code> and the value as the\n    configuration's value. For example, setting <code>spark.kubernetes.node.selector.identifier</code> to <code>myIdentifier</code>\n    will result in the executor pods having a node selector with key <code>identifier</code> and value\n     <code>myIdentifier</code>. Multiple node selector keys can be added by setting multiple configurations with this prefix."
  },
  {
    "id" : "02d14017-0093-43af-a54b-437feb774181",
    "prId" : 24630,
    "prUrl" : "https://github.com/apache/spark/pull/24630#pullrequestreview-239035157",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ef399851-9c07-4e3a-a302-faa1dbfc65b6",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "So, is the goal of this PR to support fractional cpu requests (like `0.5`) and the unit (like `500m`) because `spark.driver.cores` is an integral configuration?",
        "createdAt" : "2019-05-17T03:29:44Z",
        "updatedAt" : "2019-05-18T03:13:34Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "d9b90fbc-b1f7-4484-8cf1-31de003a09cd",
        "parentId" : "ef399851-9c07-4e3a-a302-faa1dbfc65b6",
        "authorId" : "2b63989f-222d-4980-8397-b22b16e4c4cc",
        "body" : "Yes and also since we already have `spark.kubernetes.executor.request.cores` for executor but similar is missing for driver.",
        "createdAt" : "2019-05-17T17:04:20Z",
        "updatedAt" : "2019-05-18T03:13:34Z",
        "lastEditedBy" : "2b63989f-222d-4980-8397-b22b16e4c4cc",
        "tags" : [
        ]
      }
    ],
    "commit" : "ff688c23de7c716cd0d9484846cbd39cafc17a21",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +800,804 @@    Specify the cpu request for the driver pod. Values conform to the Kubernetes <a href=\"https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/#meaning-of-cpu\">convention</a>.\n    Example values include 0.1, 500m, 1.5, 5, etc., with the definition of cpu units documented in <a href=\"https://kubernetes.io/docs/tasks/configure-pod-container/assign-cpu-resource/#cpu-units\">CPU units</a>.\n    This takes precedence over <code>spark.driver.cores</code> for specifying the driver pod cpu request if set.\n  </td>\n</tr>"
  }
]