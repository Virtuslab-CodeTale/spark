[
  {
    "id" : "c80f8baa-17c9-4b6f-800a-c5353748e7f1",
    "prId" : 29331,
    "prUrl" : "https://github.com/apache/spark/pull/29331#pullrequestreview-464314975",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "58d96821-84ec-45d5-b682-238e2735f43f",
        "parentId" : null,
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "it looks like we need to update the table above as well?\r\nit might be nice to say what happens if you specify a level > 1 but you don't have that many executors.",
        "createdAt" : "2020-08-10T14:36:05Z",
        "updatedAt" : "2020-08-10T14:38:26Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      },
      {
        "id" : "3a46261d-408c-41a6-a83b-87bdee45dc12",
        "parentId" : "58d96821-84ec-45d5-b682-238e2735f43f",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Let me rephrase the request.\r\n1. Adding both DISK_ONLY_2 and DISK_ONLY_3 to the above table.\r\n2. Adding a description about the corner case for `MEMORY_ONLY_2`, `MEMORY_AND_DISK_2`, `DISK_ONLY_2`, `DISK_ONLY_3`\r\n\r\nIs there something more I can do, @tgravescs ?",
        "createdAt" : "2020-08-10T15:03:44Z",
        "updatedAt" : "2020-08-10T15:03:44Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "bfa7298b-8cb6-462c-abad-a664513f3a92",
        "parentId" : "58d96821-84ec-45d5-b682-238e2735f43f",
        "authorId" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "body" : "thats it.",
        "createdAt" : "2020-08-10T15:06:32Z",
        "updatedAt" : "2020-08-10T15:06:32Z",
        "lastEditedBy" : "bea80117-7be3-4703-8d54-02b7bf73632c",
        "tags" : [
        ]
      }
    ],
    "commit" : "cc1a7a3379a620f32d835230eebda5980ca7f7d3",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1257,1261 @@**Note:** *In Python, stored objects will always be serialized with the [Pickle](https://docs.python.org/2/library/pickle.html) library,\nso it does not matter whether you choose a serialized level. The available storage levels in Python include `MEMORY_ONLY`, `MEMORY_ONLY_2`,\n`MEMORY_AND_DISK`, `MEMORY_AND_DISK_2`, `DISK_ONLY`, `DISK_ONLY_2`, and `DISK_ONLY_3`.*\n\nSpark also automatically persists some intermediate data in shuffle operations (e.g. `reduceByKey`), even without users calling `persist`. This is done to avoid recomputing the entire input if a node fails during the shuffle. We still recommend users call `persist` on the resulting RDD if they plan to reuse it."
  }
]