[
  {
    "id" : "02f22725-384d-4038-90d4-d78dd0da0710",
    "prId" : 26919,
    "prUrl" : "https://github.com/apache/spark/pull/26919#pullrequestreview-333310055",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fc809a9c-6da5-46b9-8500-ffb3d8ed6531",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Shall we add the Hive 1.2.1 example back after this for users?\r\n```\r\n# With Hive 1.2.1 support\r\n./build/mvn -Pyarn -Phive -Phive-thriftserver -Phive-1.2 -DskipTests clean package\r\n```",
        "createdAt" : "2019-12-17T05:39:16Z",
        "updatedAt" : "2019-12-21T09:25:12Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "be3aa9c1-c34e-4523-bb88-e4931211b14a",
        "parentId" : "fc809a9c-6da5-46b9-8500-ffb3d8ed6531",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "cc @gatorsmile and @srowen ",
        "createdAt" : "2019-12-17T05:39:31Z",
        "updatedAt" : "2019-12-21T09:25:12Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "8fae4ac7-29f1-468e-8e6e-51cbcb053b3d",
        "parentId" : "fc809a9c-6da5-46b9-8500-ffb3d8ed6531",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "OK either way. I guess we kind of want to discourage Hive 1.x, but doesn't mean it should have a line in the docs still",
        "createdAt" : "2019-12-17T14:24:40Z",
        "updatedAt" : "2019-12-21T09:25:12Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      }
    ],
    "commit" : "eef9adc948df743489d284e69b39ed40020f20fb",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +87,91 @@\n    # With Hive 2.3.6 support\n    ./build/mvn -Pyarn -Phive -Phive-thriftserver -DskipTests clean package\n\n## Packaging without Hadoop Dependencies for YARN"
  },
  {
    "id" : "a0415e71-5287-45ab-aa50-ad4ab4e6a31b",
    "prId" : 26844,
    "prUrl" : "https://github.com/apache/spark/pull/26844#pullrequestreview-330337808",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "47d26e68-b886-41a1-beee-465c13bd7ce4",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "~Ur, shall we revert this line since there is Python 3.7 and 3.8?~\r\nOops, Never mind.",
        "createdAt" : "2019-12-11T07:23:01Z",
        "updatedAt" : "2019-12-11T07:24:14Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "a3a76959b131f109f891d6022d9d18aaad1a0ea3",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +67,71 @@    ./dev/make-distribution.sh --name custom-spark --pip --r --tgz -Psparkr -Phive -Phive-thriftserver -Pmesos -Pyarn -Pkubernetes\n\nThis will build Spark distribution along with Python pip and R packages. (Note that build with Python pip package requires Python 3.6). For more information on usage, run `./dev/make-distribution.sh --help`\n\n## Specifying the Hadoop Version and Enabling YARN"
  },
  {
    "id" : "0419673b-c5bf-43db-b0b7-be7ea5f283b7",
    "prId" : 26844,
    "prUrl" : "https://github.com/apache/spark/pull/26844#pullrequestreview-330946883",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "715860c2-6610-483f-aaef-68b67428f8b2",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "nit: I think we can just say \"Note that build with Python pip package requires Python 3.\" without parentheses.",
        "createdAt" : "2019-12-12T01:29:10Z",
        "updatedAt" : "2019-12-12T01:29:19Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "a3a76959b131f109f891d6022d9d18aaad1a0ea3",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +67,71 @@    ./dev/make-distribution.sh --name custom-spark --pip --r --tgz -Psparkr -Phive -Phive-thriftserver -Pmesos -Pyarn -Pkubernetes\n\nThis will build Spark distribution along with Python pip and R packages. (Note that build with Python pip package requires Python 3.6). For more information on usage, run `./dev/make-distribution.sh --help`\n\n## Specifying the Hadoop Version and Enabling YARN"
  },
  {
    "id" : "06881ee8-64dc-435a-88fd-8ea977cbb9b3",
    "prId" : 25345,
    "prUrl" : "https://github.com/apache/spark/pull/25345#pullrequestreview-270505629",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "999839b6-cc31-4de1-8596-58c47d0973a7",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Rscript hides the verbose message and also is consistent with `dev/create-release/spark-rm/Dockerfile`.",
        "createdAt" : "2019-08-03T05:43:02Z",
        "updatedAt" : "2019-08-03T06:50:38Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "dbafdc09-5251-4786-9b75-5f3b3df32980",
        "parentId" : "999839b6-cc31-4de1-8596-58c47d0973a7",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "But it's inconsistent comparing to `appveyor.yml` though but I don't feel strongly about it.",
        "createdAt" : "2019-08-03T15:20:49Z",
        "updatedAt" : "2019-08-03T15:20:49Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "c4a2dd92-d9c7-44c3-b03a-d52cbb412cf7",
        "parentId" : "999839b6-cc31-4de1-8596-58c47d0973a7",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Thanks. Got it~",
        "createdAt" : "2019-08-04T16:41:23Z",
        "updatedAt" : "2019-08-04T16:41:23Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "32b2265485c0342f9c4ebd9ef430025fa89c0847",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +243,247 @@\n    Rscript -e \"install.packages(c('knitr', 'rmarkdown', 'devtools', 'e1071', 'survival'), repos='https://cloud.r-project.org/')\"\n    Rscript -e \"devtools::install_version('testthat', version = '1.0.2', repos='https://cloud.r-project.org/')\"\n\nYou can run just the SparkR tests using the command:"
  }
]