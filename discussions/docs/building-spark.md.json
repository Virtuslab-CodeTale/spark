[
  {
    "id" : "02f22725-384d-4038-90d4-d78dd0da0710",
    "prId" : 26919,
    "prUrl" : "https://github.com/apache/spark/pull/26919#pullrequestreview-333310055",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fc809a9c-6da5-46b9-8500-ffb3d8ed6531",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Shall we add the Hive 1.2.1 example back after this for users?\r\n```\r\n# With Hive 1.2.1 support\r\n./build/mvn -Pyarn -Phive -Phive-thriftserver -Phive-1.2 -DskipTests clean package\r\n```",
        "createdAt" : "2019-12-17T05:39:16Z",
        "updatedAt" : "2019-12-21T09:25:12Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "be3aa9c1-c34e-4523-bb88-e4931211b14a",
        "parentId" : "fc809a9c-6da5-46b9-8500-ffb3d8ed6531",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "cc @gatorsmile and @srowen ",
        "createdAt" : "2019-12-17T05:39:31Z",
        "updatedAt" : "2019-12-21T09:25:12Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "8fae4ac7-29f1-468e-8e6e-51cbcb053b3d",
        "parentId" : "fc809a9c-6da5-46b9-8500-ffb3d8ed6531",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "OK either way. I guess we kind of want to discourage Hive 1.x, but doesn't mean it should have a line in the docs still",
        "createdAt" : "2019-12-17T14:24:40Z",
        "updatedAt" : "2019-12-21T09:25:12Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      }
    ],
    "commit" : "eef9adc948df743489d284e69b39ed40020f20fb",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +87,91 @@\n    # With Hive 2.3.6 support\n    ./build/mvn -Pyarn -Phive -Phive-thriftserver -DskipTests clean package\n\n## Packaging without Hadoop Dependencies for YARN"
  },
  {
    "id" : "a0415e71-5287-45ab-aa50-ad4ab4e6a31b",
    "prId" : 26844,
    "prUrl" : "https://github.com/apache/spark/pull/26844#pullrequestreview-330337808",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "47d26e68-b886-41a1-beee-465c13bd7ce4",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "~Ur, shall we revert this line since there is Python 3.7 and 3.8?~\r\nOops, Never mind.",
        "createdAt" : "2019-12-11T07:23:01Z",
        "updatedAt" : "2019-12-11T07:24:14Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "a3a76959b131f109f891d6022d9d18aaad1a0ea3",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +67,71 @@    ./dev/make-distribution.sh --name custom-spark --pip --r --tgz -Psparkr -Phive -Phive-thriftserver -Pmesos -Pyarn -Pkubernetes\n\nThis will build Spark distribution along with Python pip and R packages. (Note that build with Python pip package requires Python 3.6). For more information on usage, run `./dev/make-distribution.sh --help`\n\n## Specifying the Hadoop Version and Enabling YARN"
  },
  {
    "id" : "0419673b-c5bf-43db-b0b7-be7ea5f283b7",
    "prId" : 26844,
    "prUrl" : "https://github.com/apache/spark/pull/26844#pullrequestreview-330946883",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "715860c2-6610-483f-aaef-68b67428f8b2",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "nit: I think we can just say \"Note that build with Python pip package requires Python 3.\" without parentheses.",
        "createdAt" : "2019-12-12T01:29:10Z",
        "updatedAt" : "2019-12-12T01:29:19Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "a3a76959b131f109f891d6022d9d18aaad1a0ea3",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +67,71 @@    ./dev/make-distribution.sh --name custom-spark --pip --r --tgz -Psparkr -Phive -Phive-thriftserver -Pmesos -Pyarn -Pkubernetes\n\nThis will build Spark distribution along with Python pip and R packages. (Note that build with Python pip package requires Python 3.6). For more information on usage, run `./dev/make-distribution.sh --help`\n\n## Specifying the Hadoop Version and Enabling YARN"
  },
  {
    "id" : "06881ee8-64dc-435a-88fd-8ea977cbb9b3",
    "prId" : 25345,
    "prUrl" : "https://github.com/apache/spark/pull/25345#pullrequestreview-270505629",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "999839b6-cc31-4de1-8596-58c47d0973a7",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Rscript hides the verbose message and also is consistent with `dev/create-release/spark-rm/Dockerfile`.",
        "createdAt" : "2019-08-03T05:43:02Z",
        "updatedAt" : "2019-08-03T06:50:38Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "dbafdc09-5251-4786-9b75-5f3b3df32980",
        "parentId" : "999839b6-cc31-4de1-8596-58c47d0973a7",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "But it's inconsistent comparing to `appveyor.yml` though but I don't feel strongly about it.",
        "createdAt" : "2019-08-03T15:20:49Z",
        "updatedAt" : "2019-08-03T15:20:49Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "c4a2dd92-d9c7-44c3-b03a-d52cbb412cf7",
        "parentId" : "999839b6-cc31-4de1-8596-58c47d0973a7",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Thanks. Got it~",
        "createdAt" : "2019-08-04T16:41:23Z",
        "updatedAt" : "2019-08-04T16:41:23Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "32b2265485c0342f9c4ebd9ef430025fa89c0847",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +243,247 @@\n    Rscript -e \"install.packages(c('knitr', 'rmarkdown', 'devtools', 'e1071', 'survival'), repos='https://cloud.r-project.org/')\"\n    Rscript -e \"devtools::install_version('testthat', version = '1.0.2', repos='https://cloud.r-project.org/')\"\n\nYou can run just the SparkR tests using the command:"
  },
  {
    "id" : "0c76b9bc-20f2-4620-804b-e15b7a08321b",
    "prId" : 24481,
    "prUrl" : "https://github.com/apache/spark/pull/24481#pullrequestreview-231473517",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "963d5783-15d9-4c43-b3b3-5af269815ccc",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "It probably doesn't actually require 3.6.1 over 3.6.0, but this is fine. I think it does require 3.6.x though.",
        "createdAt" : "2019-04-28T14:37:26Z",
        "updatedAt" : "2019-05-03T00:48:54Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "881a7471-72cc-4612-a4d8-a0f2ce70c027",
        "parentId" : "963d5783-15d9-4c43-b3b3-5af269815ccc",
        "authorId" : "813f0961-9a16-4e42-a167-961d914c472c",
        "body" : "It will throw exception if it's not 3.6.1:\r\n```\r\nmvn package -DskipTests=true\r\n...\r\n[INFO] --- maven-enforcer-plugin:3.0.0-M2:enforce (enforce-versions) @ spark-parent_2.12 ---\r\n[WARNING] Rule 0: org.apache.maven.plugins.enforcer.RequireMavenVersion failed with message:\r\nDetected Maven Version: 3.6.0 is not in the allowed range 3.6.1.\r\n...\r\n[ERROR] Failed to execute goal org.apache.maven.plugins:maven-enforcer-plugin:3.0.0-M2:enforce (enforce-versions) on project spark-parent_2.12: Some Enforcer rules have failed. Look above for specific messages explaining why the rule failed. -> [Help 1]\r\n[ERROR]\r\n...\r\n```",
        "createdAt" : "2019-04-28T15:07:00Z",
        "updatedAt" : "2019-05-03T00:48:54Z",
        "lastEditedBy" : "813f0961-9a16-4e42-a167-961d914c472c",
        "tags" : [
        ]
      },
      {
        "id" : "47cdbea3-2838-4b94-bbf9-01b99777dfe1",
        "parentId" : "963d5783-15d9-4c43-b3b3-5af269815ccc",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Yea.. so problem is here. I don't know why it makes the build failed in Appveyor ",
        "createdAt" : "2019-04-28T15:22:57Z",
        "updatedAt" : "2019-05-03T00:48:54Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "2ba886f1e685960c00f171994b89be8494b098b2",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +28,32 @@\nThe Maven-based build is the build of reference for Apache Spark.\nBuilding Spark using Maven requires Maven 3.6.1 and Java 8.\nSpark requires Scala 2.12; support for Scala 2.11 was removed in Spark 3.0.0.\n"
  }
]