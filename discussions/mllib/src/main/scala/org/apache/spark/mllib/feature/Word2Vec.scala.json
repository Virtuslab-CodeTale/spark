[
  {
    "id" : "3a467610-7afc-4b0c-a28e-85a6d1e70ab1",
    "prId" : 30548,
    "prUrl" : "https://github.com/apache/spark/pull/30548#pullrequestreview-543380692",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e5ebb552-032b-41b3-8b64-a360890c01b5",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Is this actually more efficient than slice? Likewise above.",
        "createdAt" : "2020-11-30T15:32:04Z",
        "updatedAt" : "2020-12-03T02:34:43Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "68333bd2-26bb-4849-8bce-71b2ff537c23",
        "parentId" : "e5ebb552-032b-41b3-8b64-a360890c01b5",
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "I guess so, I will do a simple test.",
        "createdAt" : "2020-12-03T01:52:23Z",
        "updatedAt" : "2020-12-03T02:34:43Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      }
    ],
    "commit" : "3ba4fda47dd7627014b0aacfcbdc1b0a93fd924a",
    "line" : 40,
    "diffHunk" : "@@ -1,1 +537,541 @@        val array = Array.ofDim[Double](size)\n        var i = 0\n        while (i < size) { array(i) = wordVectors(offset + i); i += 1 }\n        Vectors.dense(array)\n      case None =>"
  },
  {
    "id" : "9d294021-fdbd-43b2-8106-7245cd90da86",
    "prId" : 30548,
    "prUrl" : "https://github.com/apache/spark/pull/30548#pullrequestreview-543407406",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "142c7603-d1a6-46e2-9282-947cd33231c6",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "How much does this save, if it only happens once and has to happen to use the model?",
        "createdAt" : "2020-11-30T15:34:21Z",
        "updatedAt" : "2020-12-03T02:34:43Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "b07771c3-dcc6-457e-9a88-21d7b786d0fe",
        "parentId" : "142c7603-d1a6-46e2-9282-947cd33231c6",
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "this var `wordVecNorms` is only used in method `findSynonyms` in the .mllib.w2v; however, this `findSynonyms`  is never used in the .ml side. So I think we can make it lazy.",
        "createdAt" : "2020-12-03T01:55:09Z",
        "updatedAt" : "2020-12-03T02:34:43Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      },
      {
        "id" : "2351dadb-0565-4743-8676-6b8dad0b3c32",
        "parentId" : "142c7603-d1a6-46e2-9282-947cd33231c6",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "OK fair enough. There are use cases here that would never need this calculated?",
        "createdAt" : "2020-12-03T02:49:12Z",
        "updatedAt" : "2020-12-03T02:49:12Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "08306eb1-8d60-4962-83b4-23d89241af78",
        "parentId" : "142c7603-d1a6-46e2-9282-947cd33231c6",
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "`however, this findSynonyms is never used in the .ml side. So I think we can make it lazy.`\r\n\r\nI am wrong. this var `wordVecNorms` is used in methods `findSynonyms` and `findSynonymsArray` in the .ml side. Since it is not used in `transform`, so we can still mark it lazy",
        "createdAt" : "2020-12-03T03:05:15Z",
        "updatedAt" : "2020-12-03T03:05:16Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      }
    ],
    "commit" : "3ba4fda47dd7627014b0aacfcbdc1b0a93fd924a",
    "line" : 22,
    "diffHunk" : "@@ -1,1 +509,513 @@  // wordVecNorms: Array of length numWords, each value being the Euclidean norm\n  //               of the wordVector.\n  private lazy val wordVecNorms: Array[Float] = {\n    val size = vectorSize\n    Array.tabulate(numWords)(i => blas.snrm2(size, wordVectors, i * size, 1))"
  },
  {
    "id" : "48b3f0a0-5b37-4ff8-b9d8-9ce5dd4b5802",
    "prId" : 24893,
    "prUrl" : "https://github.com/apache/spark/pull/24893#pullrequestreview-250541697",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "35d6572a-1eb6-4c22-9fce-2846fd88ea31",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "I may remove these asserts before we commit; just a double check",
        "createdAt" : "2019-06-17T14:44:17Z",
        "updatedAt" : "2019-06-17T14:44:21Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      }
    ],
    "commit" : "8d749275c24811d0481ced91b5362d9f8d98dd6b",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +269,273 @@        pos2 += 1\n      }\n      assert(count(min1i) < Long.MaxValue)\n      assert(count(min2i) < Long.MaxValue)\n      count(vocabSize + a) = count(min1i) + count(min2i)"
  },
  {
    "id" : "8a95ba77-e779-40b7-a2ff-8c95af9abee2",
    "prId" : 24814,
    "prUrl" : "https://github.com/apache/spark/pull/24814#pullrequestreview-250541311",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "fa25afd5-3658-48b9-9d73-06bf48f64d88",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Both values are different. Why do we need to change? Can you file a JIRA since before/after aren't virtually same.\r\n\r\n```scala\r\nscala> Int.MaxValue\r\nres0: Int = 2147483647\r\n\r\nscala> 1e9.toInt\r\nres1: Int = 1000000000\r\n```",
        "createdAt" : "2019-06-07T02:39:54Z",
        "updatedAt" : "2019-06-07T02:39:54Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "3315c531-aaad-4965-a4fc-f6eb0cb41e33",
        "parentId" : "fa25afd5-3658-48b9-9d73-06bf48f64d88",
        "authorId" : "0f19ae04-039f-4484-813f-5626dbc09e07",
        "body" : "if VocabWord.cn > 1e9.toInt and  VocabWord.cn < Int.MaxValue,  the createBinaryTree is error;\r\nCauses an infinite loop of line 283ï¼›\r\n",
        "createdAt" : "2019-06-07T10:21:33Z",
        "updatedAt" : "2019-06-07T10:21:33Z",
        "lastEditedBy" : "0f19ae04-039f-4484-813f-5626dbc09e07",
        "tags" : [
        ]
      },
      {
        "id" : "a564d142-e15e-4a37-8f15-88b3278c5143",
        "parentId" : "fa25afd5-3658-48b9-9d73-06bf48f64d88",
        "authorId" : "63281e91-e961-4e6e-b0bb-6855587910d1",
        "body" : "If not mistaken the array holds longs should not be a Long Max? my 2 cents.",
        "createdAt" : "2019-06-07T12:29:34Z",
        "updatedAt" : "2019-06-07T12:29:34Z",
        "lastEditedBy" : "63281e91-e961-4e6e-b0bb-6855587910d1",
        "tags" : [
        ]
      },
      {
        "id" : "e0df310e-0ff2-40f7-b354-c84c7ff677e6",
        "parentId" : "fa25afd5-3658-48b9-9d73-06bf48f64d88",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "I think it can't be Long.MaxValue as later it sums counts which, I guess, could overflow. This is just supposed to be \"a very big value\" and I think it's safe to assume none are over Int.MaxValue. I suppose we could cap the values in the vocab array to this value to be safe. So, I think the change is OK.",
        "createdAt" : "2019-06-07T12:48:59Z",
        "updatedAt" : "2019-06-07T12:49:29Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "9de5b77b-792a-4d32-8833-88291a7b56f6",
        "parentId" : "fa25afd5-3658-48b9-9d73-06bf48f64d88",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "For reference, in an early implementation of word2vec, it uses 1e15: https://github.com/tmikolov/word2vec/blob/master/word2vec.c#L214",
        "createdAt" : "2019-06-07T15:35:04Z",
        "updatedAt" : "2019-06-07T15:35:04Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "7efa3dc3-91bb-4d4c-b899-6549f4df2109",
        "parentId" : "fa25afd5-3658-48b9-9d73-06bf48f64d88",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "@wangbin0227 can you file a JIRA and fill the PR description?",
        "createdAt" : "2019-06-07T16:03:35Z",
        "updatedAt" : "2019-06-07T16:03:46Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "64eccfa6-e058-434e-8c2e-f4e0c71d6b61",
        "parentId" : "fa25afd5-3658-48b9-9d73-06bf48f64d88",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "PS @skonto you are correct. Given how this works, `Long.MaxValue` is fine as those values are never added. I took this over in https://github.com/apache/spark/pull/24893",
        "createdAt" : "2019-06-17T14:43:41Z",
        "updatedAt" : "2019-06-17T14:43:41Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      }
    ],
    "commit" : "342f7ab13ed40f22f59d7d3d5e1e878b15cbef21",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +234,238 @@    }\n    while (a < 2 * vocabSize) {\n      count(a) = Int.MaxValue\n      a += 1\n    }"
  }
]