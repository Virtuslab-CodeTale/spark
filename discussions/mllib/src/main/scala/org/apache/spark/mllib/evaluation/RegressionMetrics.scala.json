[
  {
    "id" : "7f94b4ef-7d90-4e47-bd5d-565b76e6741f",
    "prId" : 24656,
    "prUrl" : "https://github.com/apache/spark/pull/24656#pullrequestreview-240116288",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "93fe8fee-b787-46fd-9aed-82e4fa2b023d",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "It took me a minute but yes I think this is correct.\r\nIt feels like this code would be more straightforward if the summarizer would just expose a sum and squaredL2Norm method, but, maybe for another time.\r\nA few comments about the computations here wouldn't hurt.",
        "createdAt" : "2019-05-21T15:13:21Z",
        "updatedAt" : "2019-05-21T15:13:25Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      }
    ],
    "commit" : "00ac82a5a4f0fe67392c7fc757c78bd28d32c138",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +75,79 @@  private lazy val SSerr = math.pow(summary.normL2(1), 2)\n  private lazy val SStot = summary.variance(0) * (summary.weightSum - 1)\n  private lazy val SSreg = math.pow(summary.normL2(2), 2) +\n    math.pow(summary.mean(0), 2) * summary.weightSum -\n    2 * summary.mean(0) * summary.mean(2) * summary.weightSum"
  }
]