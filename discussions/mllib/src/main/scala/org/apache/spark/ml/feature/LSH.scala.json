[
  {
    "id" : "72af9cac-0797-43dc-9e7a-e4de6ae00d1e",
    "prId" : 26990,
    "prUrl" : "https://github.com/apache/spark/pull/26990#pullrequestreview-336046470",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8706f2b5-fc9b-4960-b3b2-6d71d20a9123",
        "parentId" : null,
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "As discussed in https://github.com/apache/spark/pull/26415,\r\n\r\n\"@param numNearestNeighbors The maximum number of nearest neighbors.\"\r\nIt implies it could return fewer items.",
        "createdAt" : "2019-12-24T00:34:31Z",
        "updatedAt" : "2019-12-24T00:34:32Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      }
    ],
    "commit" : "586d94760217bdb83fb00d27b03d087c333d4311",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +114,118 @@      singleProbe: Boolean,\n      distCol: String): Dataset[_] = {\n    require(numNearestNeighbors > 0, \"The number of nearest neighbors cannot be less than 1\")\n    // Get Hash Value of the key\n    val keyHash = hashFunction(key)"
  },
  {
    "id" : "50b3da69-38d1-4555-bc3b-f0dd8d83ea7e",
    "prId" : 26990,
    "prUrl" : "https://github.com/apache/spark/pull/26990#pullrequestreview-490322959",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6330fd27-6169-4a71-9bea-de24c471334a",
        "parentId" : null,
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "`modelDatasetWithDist.stat.approxQuantile` always ignores nan values:\r\nmultipleApproxQuantiles:\r\n```\r\n    def apply(summaries: Array[QuantileSummaries], row: Row): Array[QuantileSummaries] = {\r\n      var i = 0\r\n      while (i < summaries.length) {\r\n        if (!row.isNullAt(i)) {\r\n          val v = row.getDouble(i)\r\n          if (!v.isNaN) summaries(i) = summaries(i).insert(v)\r\n        }\r\n        i += 1\r\n      }\r\n      summaries\r\n    }\r\n```\r\n\r\n\r\nhere I should had filtered out NaN values. I send a followup https://github.com/apache/spark/pull/29778 for this.",
        "createdAt" : "2020-09-17T07:40:18Z",
        "updatedAt" : "2020-09-17T07:40:58Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      }
    ],
    "commit" : "586d94760217bdb83fb00d27b03d087c333d4311",
    "line" : 55,
    "diffHunk" : "@@ -1,1 +166,170 @@        modelDatasetWithDist\n      } else {\n        val hashThreshold = summary.query(approxQuantile).get\n        // Filter the dataset where the hash value is less than the threshold.\n        modelDatasetWithDist.filter(hashDistCol <= hashThreshold)"
  },
  {
    "id" : "2a09456c-94e7-4d6d-89e1-75d0d03d059b",
    "prId" : 26948,
    "prUrl" : "https://github.com/apache/spark/pull/26948#pullrequestreview-336044286",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2a1719af-4641-4276-a43e-e6f42c68e19f",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Hm, why would we predicate this on numNearestNeighbors? I'm not clear why a priority queue helps particularly when this is small, vs a quantile; both are doing something kinda similar. I'd expect one or the other to be consistently faster or slower. I also generally imagine this argument will be smallish, so, if this approach is good for < 1000, and not bad for 10000 or something, just use the queue?\r\n\r\nI understood when the idea was to collect() small data sets and just pick directly the top k.",
        "createdAt" : "2019-12-20T14:45:32Z",
        "updatedAt" : "2019-12-23T04:49:06Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "84b778d2-ee7c-4257-a1af-2bec006c15a7",
        "parentId" : "2a1719af-4641-4276-a43e-e6f42c68e19f",
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "I set a threshold=1,000 here, just to avoid OOM. maybe 10,000 also works.\r\nThe aggregation cost of both `BoundedPriorityQueue` and `approxNearestNeighbors` should be quite similar.\r\n\r\nBut `BoundedPriorityQueue` do not need an extra pass to get `count` for `val approxQuantile = numNearestNeighbors.toDouble / count + relativeError`\r\n",
        "createdAt" : "2019-12-23T02:25:46Z",
        "updatedAt" : "2019-12-23T04:49:06Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      },
      {
        "id" : "2e31e0e4-6b53-4dda-ad24-3264de402ca0",
        "parentId" : "2a1719af-4641-4276-a43e-e6f42c68e19f",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "I think I have the same question as in the other PR: if this is faster than quantiles for small neighbors, then I'd expect it's faster for everything. I don't know if it is though? my guess is that it wouldn't be. You save the count() but the count() isn't particularly expensive. The question might be how much that saves and at what scale.",
        "createdAt" : "2019-12-23T14:24:30Z",
        "updatedAt" : "2019-12-23T14:24:31Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "15b1cf85-ef0e-472d-9205-421a65f918f1",
        "parentId" : "2a1719af-4641-4276-a43e-e6f42c68e19f",
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "> You save the count() but the count() isn't particularly expensive.\r\n\r\nBut I test the performance but it seem that `count` can not be ignored, since the following computation of threshold has similar cost.\r\n\r\nBut I think we do not need top-K any more, since:\r\n1, the quantile and count can be accumulated together, I will send a PR for it;\r\n2, exact NN candidates is not a good choice as a `recall` step;\r\n",
        "createdAt" : "2019-12-24T00:16:29Z",
        "updatedAt" : "2019-12-24T00:16:29Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      }
    ],
    "commit" : "59fc68b545a75eac405d0ced7514187f16114cff",
    "line" : 40,
    "diffHunk" : "@@ -1,1 +144,148 @@      import spark.implicits._\n\n      if (numNearestNeighbors < 1000) {\n        val r = Random.nextInt\n        val distColIdx = modelDatasetWithDist.schema.fieldNames.indexOf(distCol)"
  },
  {
    "id" : "9166511d-623b-4ed1-bbe7-fa1312f5854a",
    "prId" : 26948,
    "prUrl" : "https://github.com/apache/spark/pull/26948#pullrequestreview-335713416",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e8004097-1b11-46e1-9b9f-bd9a617648d1",
        "parentId" : null,
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "This method extract numNearestNeighbors rows, however, it fails in `BucketedRandomProjectionLSHSuite`.\r\n\r\nI checked the datasets, and found that existing method based on `approxQuantile`/`QuantileSummaries` will generate much more candidate items in the step:\r\nnumNearestNeighbors=100, modelSubset.size=231.\r\n\r\nMethod in current commit will only extract 100 candidates even if there are repeated values, while existing method in master will extract 231 candidates. Then the new method will fail in testsuite because its final precision is not good.\r\n\r\nI wonder that may be we need more candidates here to generate more accuracy final result?\r\nShould I just remove the method base on Top-K, or use a scaled threshold (numNearestNeighbors*3 or numNearestNeighbors*3) here?",
        "createdAt" : "2019-12-23T04:29:26Z",
        "updatedAt" : "2019-12-23T04:49:06Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      },
      {
        "id" : "b86224fd-07c5-4f9e-b53a-6db83c573521",
        "parentId" : "e8004097-1b11-46e1-9b9f-bd9a617648d1",
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "The log of both methods in testsuites:\r\n`approxQuantile/QuantileSummaries`:\r\nnumNearestNeighbors=100, modelSubset.size=231, threshold=0.0\r\n\r\ntopK\r\nnumNearestNeighbors=100, modelSubset.size=100, threshold=0.0",
        "createdAt" : "2019-12-23T04:54:43Z",
        "updatedAt" : "2019-12-23T04:54:43Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      },
      {
        "id" : "b34ece2f-a994-4f40-9a0c-090b40c46dff",
        "parentId" : "e8004097-1b11-46e1-9b9f-bd9a617648d1",
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "There is only one test for singleProbe=false:\r\nnumNearestNeighbors=100,\r\nthe threshold computed by previous `sort` or current `approxQuantile` is 0.0,\r\nfiltered with threshold=0.0, there are 231 items.\r\n",
        "createdAt" : "2019-12-23T05:14:06Z",
        "updatedAt" : "2019-12-23T05:14:07Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      }
    ],
    "commit" : "59fc68b545a75eac405d0ced7514187f16114cff",
    "line" : 53,
    "diffHunk" : "@@ -1,1 +157,161 @@            combOp = (c1, c2) => c1 ++= c2\n          ).flatMap { case (_, c) => c.iterator.map(_._2) }\n        spark.createDataFrame(rows, modelDatasetWithDist.schema)\n\n      } else {"
  },
  {
    "id" : "5ee59b97-6a65-4a11-9c35-36c05914c99c",
    "prId" : 26948,
    "prUrl" : "https://github.com/apache/spark/pull/26948#pullrequestreview-335708094",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6220c629-5db9-4473-bd4c-cd2f7e870bfb",
        "parentId" : null,
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "Here we compute QuantileSummaries & count together, it should be faster than existing impl.",
        "createdAt" : "2019-12-23T04:33:28Z",
        "updatedAt" : "2019-12-23T04:49:06Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      }
    ],
    "commit" : "59fc68b545a75eac405d0ced7514187f16114cff",
    "line" : 61,
    "diffHunk" : "@@ -1,1 +161,165 @@      } else {\n        val relativeError = 0.05\n        val (summaries, count) = modelDatasetWithDist\n          .select(distCol)\n          .as[Double]"
  },
  {
    "id" : "c6553211-efb5-4ad5-8a53-3e1f0201cd6a",
    "prId" : 26858,
    "prUrl" : "https://github.com/apache/spark/pull/26858#pullrequestreview-331010282",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c88d8f11-d941-432a-ae0e-dc8cfa0c8eca",
        "parentId" : null,
        "authorId" : "99765afe-8dbe-4d5f-9ad3-d5bc40f0462b",
        "body" : "what is a good number to use here?",
        "createdAt" : "2019-12-12T06:11:31Z",
        "updatedAt" : "2019-12-12T06:11:31Z",
        "lastEditedBy" : "99765afe-8dbe-4d5f-9ad3-d5bc40f0462b",
        "tags" : [
        ]
      }
    ],
    "commit" : "48a91eefad0901881c2b3abd44e6fb49d024ca8a",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +142,146 @@      val modelDatasetWithDist = modelDataset.withColumn(distCol, hashDistCol)\n      // for a small dataset, use BoundedPriorityQueue\n      if (count < 1000) {\n        val queue = new BoundedPriorityQueue[Double](count.toInt)(Ordering[Double])\n        modelDatasetWithDist.collect().foreach { case Row(keys, values, distCol: Double) =>"
  },
  {
    "id" : "4546f2af-0a87-4946-b036-7aa58ddc977a",
    "prId" : 26858,
    "prUrl" : "https://github.com/apache/spark/pull/26858#pullrequestreview-331546710",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5599037d-d4bd-4385-97d5-f99adc1fed32",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Shouldn't the queue just need numNearestNeighbors elements?",
        "createdAt" : "2019-12-12T14:27:03Z",
        "updatedAt" : "2019-12-12T14:29:40Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "b1fa640f-9113-409c-a0e4-362007fc98fa",
        "parentId" : "5599037d-d4bd-4385-97d5-f99adc1fed32",
        "authorId" : "99765afe-8dbe-4d5f-9ad3-d5bc40f0462b",
        "body" : "Sorry, I should use numNearestNeighbors. Will fix this. ",
        "createdAt" : "2019-12-12T21:47:17Z",
        "updatedAt" : "2019-12-12T21:47:18Z",
        "lastEditedBy" : "99765afe-8dbe-4d5f-9ad3-d5bc40f0462b",
        "tags" : [
        ]
      }
    ],
    "commit" : "48a91eefad0901881c2b3abd44e6fb49d024ca8a",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +143,147 @@      // for a small dataset, use BoundedPriorityQueue\n      if (count < 1000) {\n        val queue = new BoundedPriorityQueue[Double](count.toInt)(Ordering[Double])\n        modelDatasetWithDist.collect().foreach { case Row(keys, values, distCol: Double) =>\n          queue += distCol"
  },
  {
    "id" : "cb3414ce-9f3e-456c-8e6c-7b4a87770f9b",
    "prId" : 26858,
    "prUrl" : "https://github.com/apache/spark/pull/26858#pullrequestreview-331546785",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9818ed35-849c-4c9f-a167-a56058bba65b",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "I might pull `sortedDistCol(numNearestNeighbors - 1)` into a `val` or else this has to send the whole array. (You don't have to clear the queue)",
        "createdAt" : "2019-12-12T14:27:53Z",
        "updatedAt" : "2019-12-12T14:29:40Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "6e2acb25-7552-48ba-9f83-789f7d3b5e16",
        "parentId" : "9818ed35-849c-4c9f-a167-a56058bba65b",
        "authorId" : "99765afe-8dbe-4d5f-9ad3-d5bc40f0462b",
        "body" : "Will fix this. Thanks!",
        "createdAt" : "2019-12-12T21:47:26Z",
        "updatedAt" : "2019-12-12T21:47:26Z",
        "lastEditedBy" : "99765afe-8dbe-4d5f-9ad3-d5bc40f0462b",
        "tags" : [
        ]
      }
    ],
    "commit" : "48a91eefad0901881c2b3abd44e6fb49d024ca8a",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +149,153 @@        var sortedDistCol = queue.toArray.sorted(Ordering[Double])\n        queue.clear()\n        modelDatasetWithDist.filter(col(distCol) <= sortedDistCol(numNearestNeighbors - 1))\n      } else {\n        // Compute threshold to get around k elements."
  },
  {
    "id" : "19843d47-04ba-460f-aec9-03876ba019aa",
    "prId" : 26858,
    "prUrl" : "https://github.com/apache/spark/pull/26858#pullrequestreview-331267030",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "f0651b43-4524-4ebf-bda6-33db7516ef02",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "keys and values can be `_`",
        "createdAt" : "2019-12-12T14:28:32Z",
        "updatedAt" : "2019-12-12T14:29:40Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      }
    ],
    "commit" : "48a91eefad0901881c2b3abd44e6fb49d024ca8a",
    "line" : 25,
    "diffHunk" : "@@ -1,1 +144,148 @@      if (count < 1000) {\n        val queue = new BoundedPriorityQueue[Double](count.toInt)(Ordering[Double])\n        modelDatasetWithDist.collect().foreach { case Row(keys, values, distCol: Double) =>\n          queue += distCol\n        }"
  },
  {
    "id" : "361cba07-77ea-4c76-9370-3e6ff5a4f664",
    "prId" : 26858,
    "prUrl" : "https://github.com/apache/spark/pull/26858#pullrequestreview-334435440",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "638cca76-636a-4b56-b7e2-33d929cf1f01",
        "parentId" : null,
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "This place should be like:\r\n```scala\r\nval exactThreshold = modelDatasetWithDist\r\n.select(distCol)\r\n.as[Double]\r\n.rdd\r\n.treeAggregate(new BoundedPriorityQueue[Double](numNearestNeighbors)(Ordering[Double].reverse))(\r\nseqOp= (q, v) => q += v,\r\ncombOp = (q1, q2) => q1 ++= q2,\r\ndepth = 2\r\n).toArray.max\r\n```\r\n\r\nAnd this impl should have no dependency on the size of dataset.",
        "createdAt" : "2019-12-13T06:24:18Z",
        "updatedAt" : "2019-12-13T06:24:19Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      },
      {
        "id" : "ab9c9df1-7fe8-4f4b-988c-1d1497703e4e",
        "parentId" : "638cca76-636a-4b56-b7e2-33d929cf1f01",
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "this only depends on `numNearestNeighbors`, when it is small (maybe < 10000?).\r\nOn each partition, collect the minmum 10 values, and merge them by `treeAggregate` to get the global minmum 10 values, and the max value in them is the threshold.",
        "createdAt" : "2019-12-13T06:32:47Z",
        "updatedAt" : "2019-12-13T06:32:47Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      },
      {
        "id" : "e7a70f00-9f88-41f8-a0de-e2a56df199bf",
        "parentId" : "638cca76-636a-4b56-b7e2-33d929cf1f01",
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "`BoundedPriorityQueue` only maintains the topK entries, so it is safe to absorb a lot of entries.",
        "createdAt" : "2019-12-13T06:45:34Z",
        "updatedAt" : "2019-12-13T06:45:35Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      },
      {
        "id" : "1a4561ad-a441-4ae9-a1e7-c060654e29dc",
        "parentId" : "638cca76-636a-4b56-b7e2-33d929cf1f01",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "approxQuantile already kind of works this way, so I think the point of this PR is avoiding several passes of Spark jobs for tree reduce in this case.\r\n\r\nHowever it's a fair point, I wonder if, overall, this approach is faster than approxQuantile? it already does something like what you're suggesting.",
        "createdAt" : "2019-12-13T11:04:42Z",
        "updatedAt" : "2019-12-13T11:04:43Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "af5ed5a9-13ef-4337-aa67-5c0dbb87d26d",
        "parentId" : "638cca76-636a-4b56-b7e2-33d929cf1f01",
        "authorId" : "99765afe-8dbe-4d5f-9ad3-d5bc40f0462b",
        "body" : "I tried a small test. I used existing ```BucketedRandomProjectionLSHSuite``` but made the dataset bigger: \r\n```\r\nval data = {\r\n      for (i <- -200 until 200; j <- -200 until 200) yield Vectors.dense(i*10, j*10)\r\n}\r\ndataset = spark.createDataFrame(data1.map(Tuple1.apply)).toDF(\"keys\")\r\n```\r\nSo the dataset count is 160000 and I tested 10000, 9000, 8000, 7000, 6000, 5000, 4000, 3000, 2000 and 1000 nearest neighbors. I didn't see any performance gain using ```BoundedPriorityQueue```. ",
        "createdAt" : "2019-12-15T07:36:32Z",
        "updatedAt" : "2019-12-15T07:36:33Z",
        "lastEditedBy" : "99765afe-8dbe-4d5f-9ad3-d5bc40f0462b",
        "tags" : [
        ]
      },
      {
        "id" : "d4cb7dd7-9668-4093-b561-f62ed0806b51",
        "parentId" : "638cca76-636a-4b56-b7e2-33d929cf1f01",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "OK, so we're back to the original question: is it worth collect and top-k via priority queue for a small data set? I'm OK with it, if it speeds things up. Are there any rough benchmarks for small data sets like 10 or 500 elements? the additional code complexity isn't too bad.",
        "createdAt" : "2019-12-15T14:32:31Z",
        "updatedAt" : "2019-12-15T14:32:31Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "1b68e1c7-cb9f-44ba-b2cd-4a28bb636052",
        "parentId" : "638cca76-636a-4b56-b7e2-33d929cf1f01",
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "I wrongly thought that the `approxNearestNeighbors` only return an approximate threshold, then we can use top-k to obtain an exact threshold.\r\nSince the `approxNearestNeighbors` already gaurantee an enough threshold which had already taken the relative error into account, so **I guess we no longer need a top-k solution.**\r\nA  `BoundedPriorityQueue` only maintains the topK entries, so it should be much smaller than a `QuantileSummaries`, however since there is only one column to process, so there should be no performance gain.\r\n",
        "createdAt" : "2019-12-17T06:26:44Z",
        "updatedAt" : "2019-12-17T06:26:44Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      },
      {
        "id" : "e63d71e8-f397-46f1-8674-8b57f10b2492",
        "parentId" : "638cca76-636a-4b56-b7e2-33d929cf1f01",
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "I wrongly thought that the `approxNearestNeighbors` only return an approximate threshold, then we can use top-k to obtain an exact threshold.\r\nSince the `approxNearestNeighbors` already gaurantee an enough threshold which had already taken the relative error into account, so **I guess we no longer need a top-k solution.**\r\nA  `BoundedPriorityQueue` only maintains the topK entries, so it should be much smaller than a `QuantileSummaries`, however since there is only one column to process, so there should be no performance gain.\r\n",
        "createdAt" : "2019-12-17T06:27:47Z",
        "updatedAt" : "2019-12-17T06:27:47Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      },
      {
        "id" : "1f4d99ff-7828-4381-a117-923fe96fb3ea",
        "parentId" : "638cca76-636a-4b56-b7e2-33d929cf1f01",
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "A slight performance gain may come from that ` BoundedPriorityQueue` do not need a `count` job to compute the var `approxQuantile`.",
        "createdAt" : "2019-12-17T06:30:30Z",
        "updatedAt" : "2019-12-17T06:30:30Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      },
      {
        "id" : "7a02a959-7eea-4fdd-aeeb-b53a46c4024c",
        "parentId" : "638cca76-636a-4b56-b7e2-33d929cf1f01",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "I agree just implementing this in terms of BoundedPriorityQueue is also a viable solution. I don't know which one is faster. I had assumed the approximate quantile would be as I think it does less work overall, but I haven't tested it. That is, I think it will hang on to fewer than k entries per partition",
        "createdAt" : "2019-12-17T14:28:08Z",
        "updatedAt" : "2019-12-17T14:28:09Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "30b1a351-9d77-439e-84b4-1bffd4e64f15",
        "parentId" : "638cca76-636a-4b56-b7e2-33d929cf1f01",
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "I am trying to do some performance tests, however I found that in the public `approxNearestNeighbors` methods , `singleProbe` is always true for now, so our changes in LSH can not be reached in the code path. ",
        "createdAt" : "2019-12-19T06:50:31Z",
        "updatedAt" : "2019-12-19T06:50:31Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      }
    ],
    "commit" : "48a91eefad0901881c2b3abd44e6fb49d024ca8a",
    "line" : 24,
    "diffHunk" : "@@ -1,1 +143,147 @@      // for a small dataset, use BoundedPriorityQueue\n      if (count < 1000) {\n        val queue = new BoundedPriorityQueue[Double](count.toInt)(Ordering[Double])\n        modelDatasetWithDist.collect().foreach { case Row(keys, values, distCol: Double) =>\n          queue += distCol"
  },
  {
    "id" : "6da0dc1a-241b-44d6-b0bf-b30f33981030",
    "prId" : 26415,
    "prUrl" : "https://github.com/apache/spark/pull/26415#pullrequestreview-320653149",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "98ea6ddb-8784-4da2-bb67-9e83ae5eb6c0",
        "parentId" : null,
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "sorry for late reply.\r\n1, Since `approxNearestNeighbors` is for query with only one key, it is supposed to be called many times in practice. Is `val count = dataset.count()` too expensive between calls? Can it be precomputed somewhere?\r\n2, Do we need `numNearestNeighbors <= count`? refer to scala's and RDD's behavior:\r\n```\r\nscala> Array(1).take(2)\r\nres1: Array[Int] = Array(1)\r\n```\r\n\r\n```\r\nscala> val rdd = sc.range(0, 1)\r\nrdd: org.apache.spark.rdd.RDD[Long] = MapPartitionsRDD[1] at range at <console>:24\r\n\r\nscala> rdd.count\r\nres0: Long = 1\r\n\r\nscala> rdd.take\r\ntake   takeAsync   takeOrdered   takeSample\r\n\r\nscala> rdd.take(3)\r\nres1: Array[Long] = Array(0)\r\n```\r\n",
        "createdAt" : "2019-11-21T03:39:13Z",
        "updatedAt" : "2019-11-21T03:45:52Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      },
      {
        "id" : "a0162fca-2b8a-49b8-b954-c3fad1ad9890",
        "parentId" : "98ea6ddb-8784-4da2-bb67-9e83ae5eb6c0",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Fair point, but it's hardly the most expensive operation here, before or after. I'd expect a caller has to cache the input for multiple calls to make sense anyway. I think the count + approxQuantile still beats sort + take.\r\n\r\nI also take the point about take() but relaxing the requirement won't remove the need for count() here. Does it make more sense semantically? You're right it would be more consistent with the original implementation. Hm. I guess I'm neutral on it, but it's a valid question.",
        "createdAt" : "2019-11-21T03:53:21Z",
        "updatedAt" : "2019-11-21T03:53:21Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "b7dcd9b3-2b3c-41d3-86bc-c83e29bdbca3",
        "parentId" : "98ea6ddb-8784-4da2-bb67-9e83ae5eb6c0",
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "According to the [doc](https://github.com/apache/spark/blob/56a65b971d4f1b43c37a5664a3a4e2e4fcad1c14/mllib/src/main/scala/org/apache/spark/ml/feature/LSH.scala#L175) \r\n\"@param numNearestNeighbors The maximum number of nearest neighbors.\"\r\nIt imply that the output should not contain exact `numNearestNeighbors` items.\r\n\r\n1, if we do not require `numNearestNeighbors <= count`, then if `singleProbe` is true, this `count` job can be avoided.\r\n2, if we found that `numNearestNeighbors <= count`, we can directly return `modelDatasetWithDist`.\r\n",
        "createdAt" : "2019-11-21T05:04:48Z",
        "updatedAt" : "2019-11-21T05:04:48Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      },
      {
        "id" : "bee5baba-62ab-4143-844d-a13b6ed9cc14",
        "parentId" : "98ea6ddb-8784-4da2-bb67-9e83ae5eb6c0",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "It implies it _could_ have fewer, yeah. This would be the only case to return fewer, yes, and you'd just return the input. I don't think singleProbe is used (and could be removed). But the count() is still needed below in any event.\r\n\r\nI mean, if the caller cares, they can check count() vs number of neighbors before calling it a bunch of times anyway.",
        "createdAt" : "2019-11-21T05:53:15Z",
        "updatedAt" : "2019-11-21T05:53:15Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      }
    ],
    "commit" : "ddc278bc354c1dadbe6b015ac9c9b6b463edb1c4",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +113,117 @@      singleProbe: Boolean,\n      distCol: String): Dataset[_] = {\n    val count = dataset.count()\n    require(numNearestNeighbors > 0 && numNearestNeighbors <= count, \"The number of\" +\n      \" nearest neighbors cannot be less than 1 or greater than the number of elements in dataset\")"
  },
  {
    "id" : "d217617c-4c60-4ef7-be0a-883a4ac4459b",
    "prId" : 26415,
    "prUrl" : "https://github.com/apache/spark/pull/26415#pullrequestreview-320640009",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "dc171bf2-98ac-4b73-af09-760736e7fb52",
        "parentId" : null,
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "Here can we add a check of `numNearestNeighbors` in the future?\r\n1, if it is a small number, using `TopByKeyAggregator` will skip above `count` job and return a exact threshold;\r\n2, otherwise, using `approxQuantile`\r\n\r\nSimilar logic can be found in `PCA`&`GMM`, with small `numFeatures`&`k`, the impls are differenct from those with large numbers.",
        "createdAt" : "2019-11-21T03:45:47Z",
        "updatedAt" : "2019-11-21T03:45:52Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      },
      {
        "id" : "13618001-f0d3-43b8-a0c0-94099f9b9e12",
        "parentId" : "dc171bf2-98ac-4b73-af09-760736e7fb52",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "From ALS? OK I could see that being an efficient alternative, to get top k per partition and merge them to a final top k -- if k isn't big. The existing impl works on keyed data but a simplified version would work here. I think that could be a valid further improvement.",
        "createdAt" : "2019-11-21T03:56:05Z",
        "updatedAt" : "2019-11-21T03:56:05Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "ccc11eab-2dae-410b-98f1-7a24567246f0",
        "parentId" : "dc171bf2-98ac-4b73-af09-760736e7fb52",
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "Yes, this logic is quite similar to ALS.",
        "createdAt" : "2019-11-21T04:56:05Z",
        "updatedAt" : "2019-11-21T04:56:05Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      }
    ],
    "commit" : "ddc278bc354c1dadbe6b015ac9c9b6b463edb1c4",
    "line" : 23,
    "diffHunk" : "@@ -1,1 +140,144 @@      val hashDistCol = hashDistUDF(col($(outputCol)))\n\n      // Compute threshold to get around k elements.\n      // To guarantee to have enough neighbors in one pass, we need (p - err) * N >= M\n      // so we pick quantile p = M / N + err"
  }
]