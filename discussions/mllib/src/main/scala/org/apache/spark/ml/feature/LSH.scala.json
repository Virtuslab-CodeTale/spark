[
  {
    "id" : "72af9cac-0797-43dc-9e7a-e4de6ae00d1e",
    "prId" : 26990,
    "prUrl" : "https://github.com/apache/spark/pull/26990#pullrequestreview-336046470",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8706f2b5-fc9b-4960-b3b2-6d71d20a9123",
        "parentId" : null,
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "As discussed in https://github.com/apache/spark/pull/26415,\r\n\r\n\"@param numNearestNeighbors The maximum number of nearest neighbors.\"\r\nIt implies it could return fewer items.",
        "createdAt" : "2019-12-24T00:34:31Z",
        "updatedAt" : "2019-12-24T00:34:32Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      }
    ],
    "commit" : "586d94760217bdb83fb00d27b03d087c333d4311",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +114,118 @@      singleProbe: Boolean,\n      distCol: String): Dataset[_] = {\n    require(numNearestNeighbors > 0, \"The number of nearest neighbors cannot be less than 1\")\n    // Get Hash Value of the key\n    val keyHash = hashFunction(key)"
  },
  {
    "id" : "50b3da69-38d1-4555-bc3b-f0dd8d83ea7e",
    "prId" : 26990,
    "prUrl" : "https://github.com/apache/spark/pull/26990#pullrequestreview-490322959",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6330fd27-6169-4a71-9bea-de24c471334a",
        "parentId" : null,
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "`modelDatasetWithDist.stat.approxQuantile` always ignores nan values:\r\nmultipleApproxQuantiles:\r\n```\r\n    def apply(summaries: Array[QuantileSummaries], row: Row): Array[QuantileSummaries] = {\r\n      var i = 0\r\n      while (i < summaries.length) {\r\n        if (!row.isNullAt(i)) {\r\n          val v = row.getDouble(i)\r\n          if (!v.isNaN) summaries(i) = summaries(i).insert(v)\r\n        }\r\n        i += 1\r\n      }\r\n      summaries\r\n    }\r\n```\r\n\r\n\r\nhere I should had filtered out NaN values. I send a followup https://github.com/apache/spark/pull/29778 for this.",
        "createdAt" : "2020-09-17T07:40:18Z",
        "updatedAt" : "2020-09-17T07:40:58Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      }
    ],
    "commit" : "586d94760217bdb83fb00d27b03d087c333d4311",
    "line" : 55,
    "diffHunk" : "@@ -1,1 +166,170 @@        modelDatasetWithDist\n      } else {\n        val hashThreshold = summary.query(approxQuantile).get\n        // Filter the dataset where the hash value is less than the threshold.\n        modelDatasetWithDist.filter(hashDistCol <= hashThreshold)"
  }
]