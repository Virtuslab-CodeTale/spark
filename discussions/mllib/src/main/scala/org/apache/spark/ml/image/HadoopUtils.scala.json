[
  {
    "id" : "191bb180-862c-46c0-bd44-39bb39c1f05c",
    "prId" : 24431,
    "prUrl" : "https://github.com/apache/spark/pull/24431#pullrequestreview-230664876",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "781487f2-8d5b-4b0d-ba9b-f0c8dea2e843",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Not a big deal but I though option and pattern match with Some and None is fine.",
        "createdAt" : "2019-04-25T03:44:45Z",
        "updatedAt" : "2019-04-27T18:03:34Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "5f897406-26c5-44b1-8379-3d0bfc6bd73c",
        "parentId" : "781487f2-8d5b-4b0d-ba9b-f0c8dea2e843",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Same sort of issue: assigning `Option[Class[_]]` caused the warning. Here it seemed as fine to stick with the underlying null vs not-null.",
        "createdAt" : "2019-04-25T14:01:15Z",
        "updatedAt" : "2019-04-27T18:03:34Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      }
    ],
    "commit" : "cb288f1ef0f83ba176ab776c423f05f19d1ced11",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +103,107 @@      val hadoopConf = spark.sparkContext.hadoopConfiguration\n      // scalastyle:on hadoopconfiguration\n      val old = hadoopConf.getClass(flagName, null)\n      hadoopConf.setDouble(SamplePathFilter.ratioParam, sampleRatio)\n      hadoopConf.setLong(SamplePathFilter.seedParam, seed)"
  }
]