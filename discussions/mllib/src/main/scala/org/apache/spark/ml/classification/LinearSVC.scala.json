[
  {
    "id" : "b19af870-3f12-4221-bac7-0aa5f55c64ce",
    "prId" : 28974,
    "prUrl" : "https://github.com/apache/spark/pull/28974#pullrequestreview-442703898",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d07f81f7-d7ea-46b2-b878-67b4fc92e8f0",
        "parentId" : null,
        "authorId" : "99765afe-8dbe-4d5f-9ad3-d5bc40f0462b",
        "body" : "nit: add a scala doc?",
        "createdAt" : "2020-07-05T20:22:02Z",
        "updatedAt" : "2020-07-05T20:22:03Z",
        "lastEditedBy" : "99765afe-8dbe-4d5f-9ad3-d5bc40f0462b",
        "tags" : [
        ]
      }
    ],
    "commit" : "5d7432da2b42c1f895d4864d0fc34da3433a6c80",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +158,162 @@\n  @Since(\"3.1.0\")\n  def setMaxBlockMemoryInMB(value: Int): this.type = set(maxBlockMemoryInMB, value)\n  setDefault(maxBlockMemoryInMB -> 0)\n"
  },
  {
    "id" : "ebd5509c-c0db-48e2-bfb4-251fbcd573d8",
    "prId" : 28349,
    "prUrl" : "https://github.com/apache/spark/pull/28349#pullrequestreview-400476853",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5665e79d-975a-4a27-bc04-c7f1baf2866c",
        "parentId" : null,
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "I think it is up to the end user to choose whether high-level blas is used and which BLAS lib is used.\r\nHere computes the sparsity of dataset, if input it too sparse, log a warning.",
        "createdAt" : "2020-04-26T08:43:14Z",
        "updatedAt" : "2020-05-04T13:25:14Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      }
    ],
    "commit" : "e8abb4ba6b3b03cc0a696dcf43ee5ede109f88ea",
    "line" : 92,
    "diffHunk" : "@@ -1,1 +207,211 @@    instr.logNamedValue(\"highestLabelWeight\", labelSummarizer.histogram.max.toString)\n    instr.logSumOfWeights(summarizer.weightSum)\n    if ($(blockSize) > 1) {\n      val scale = 1.0 / summarizer.count / numFeatures\n      val sparsity = 1 - summarizer.numNonzeros.toArray.map(_ * scale).sum"
  },
  {
    "id" : "925aca25-6a8b-4b4a-adb0-48e38c832591",
    "prId" : 28349,
    "prUrl" : "https://github.com/apache/spark/pull/28349#pullrequestreview-403266596",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bdfffd8e-29db-4761-9225-93e2ef0f0473",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "We might provide a little more comment about what this does. Increasing it increases performance, but at the risk of what, slowing down on sparse input?",
        "createdAt" : "2020-04-29T14:35:41Z",
        "updatedAt" : "2020-05-04T13:25:14Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "d05c4ae3-8ca9-4ff0-8335-4f5300a5a6cf",
        "parentId" : "bdfffd8e-29db-4761-9225-93e2ef0f0473",
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "The choice of size needs tuning, it depends on dataset sparsity and numFeatures, Increasing it may not always increases performance.",
        "createdAt" : "2020-04-30T07:27:34Z",
        "updatedAt" : "2020-05-04T13:25:14Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      }
    ],
    "commit" : "e8abb4ba6b3b03cc0a696dcf43ee5ede109f88ea",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +158,162 @@\n  /**\n   * Set block size for stacking input data in matrices.\n   * If blockSize == 1, then stacking will be skipped, and each vector is treated individually;\n   * If blockSize &gt; 1, then vectors will be stacked to blocks, and high-level BLAS routines"
  },
  {
    "id" : "c0a26189-1ac5-4e91-9c23-d3c3078f1ec0",
    "prId" : 27374,
    "prUrl" : "https://github.com/apache/spark/pull/27374#pullrequestreview-350567817",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d71bead5-f35e-4b58-98f3-ea79cc9bded9",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "So this will become the new default for LinearSVC too? OK if so.",
        "createdAt" : "2020-01-29T14:34:20Z",
        "updatedAt" : "2020-01-30T03:59:49Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "d5a67c36-3d0d-479e-bac7-ff8de425d3f2",
        "parentId" : "d71bead5-f35e-4b58-98f3-ea79cc9bded9",
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "Yes, the new impl of LinearSVC with blocks is quite similar to LR.",
        "createdAt" : "2020-01-30T03:47:22Z",
        "updatedAt" : "2020-01-30T03:59:49Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      }
    ],
    "commit" : "c49b379fe697ffb69bb8565eea6644528992f572",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +158,162 @@  /**\n   * Set block size for stacking input data in matrices.\n   * Default is 1024.\n   *\n   * @group expertSetParam"
  },
  {
    "id" : "ec00c1ff-069d-41fe-9205-ce639ff1aaa6",
    "prId" : 27360,
    "prUrl" : "https://github.com/apache/spark/pull/27360#pullrequestreview-348326720",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "82b39429-524a-41cb-ada4-c4956fc9d9c7",
        "parentId" : null,
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "Move the standardization outside of `HingeAggregator`, so that no longer need to standardize input in each iter.",
        "createdAt" : "2020-01-25T13:49:10Z",
        "updatedAt" : "2020-01-28T08:23:27Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      }
    ],
    "commit" : "819227e618439d376b91367afdb5fa6d47b5913c",
    "line" : 72,
    "diffHunk" : "@@ -1,1 +227,231 @@      }\n\n      val standardized = instances.map {\n        case Instance(label, weight, features) =>\n          val featuresStd = bcFeaturesStd.value"
  }
]