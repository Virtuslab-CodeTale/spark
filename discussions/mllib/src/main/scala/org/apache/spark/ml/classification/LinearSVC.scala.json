[
  {
    "id" : "b19af870-3f12-4221-bac7-0aa5f55c64ce",
    "prId" : 28974,
    "prUrl" : "https://github.com/apache/spark/pull/28974#pullrequestreview-442703898",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d07f81f7-d7ea-46b2-b878-67b4fc92e8f0",
        "parentId" : null,
        "authorId" : "99765afe-8dbe-4d5f-9ad3-d5bc40f0462b",
        "body" : "nit: add a scala doc?",
        "createdAt" : "2020-07-05T20:22:02Z",
        "updatedAt" : "2020-07-05T20:22:03Z",
        "lastEditedBy" : "99765afe-8dbe-4d5f-9ad3-d5bc40f0462b",
        "tags" : [
        ]
      }
    ],
    "commit" : "5d7432da2b42c1f895d4864d0fc34da3433a6c80",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +158,162 @@\n  @Since(\"3.1.0\")\n  def setMaxBlockMemoryInMB(value: Int): this.type = set(maxBlockMemoryInMB, value)\n  setDefault(maxBlockMemoryInMB -> 0)\n"
  },
  {
    "id" : "ebd5509c-c0db-48e2-bfb4-251fbcd573d8",
    "prId" : 28349,
    "prUrl" : "https://github.com/apache/spark/pull/28349#pullrequestreview-400476853",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5665e79d-975a-4a27-bc04-c7f1baf2866c",
        "parentId" : null,
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "I think it is up to the end user to choose whether high-level blas is used and which BLAS lib is used.\r\nHere computes the sparsity of dataset, if input it too sparse, log a warning.",
        "createdAt" : "2020-04-26T08:43:14Z",
        "updatedAt" : "2020-05-04T13:25:14Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      }
    ],
    "commit" : "e8abb4ba6b3b03cc0a696dcf43ee5ede109f88ea",
    "line" : 92,
    "diffHunk" : "@@ -1,1 +207,211 @@    instr.logNamedValue(\"highestLabelWeight\", labelSummarizer.histogram.max.toString)\n    instr.logSumOfWeights(summarizer.weightSum)\n    if ($(blockSize) > 1) {\n      val scale = 1.0 / summarizer.count / numFeatures\n      val sparsity = 1 - summarizer.numNonzeros.toArray.map(_ * scale).sum"
  },
  {
    "id" : "925aca25-6a8b-4b4a-adb0-48e38c832591",
    "prId" : 28349,
    "prUrl" : "https://github.com/apache/spark/pull/28349#pullrequestreview-403266596",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "bdfffd8e-29db-4761-9225-93e2ef0f0473",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "We might provide a little more comment about what this does. Increasing it increases performance, but at the risk of what, slowing down on sparse input?",
        "createdAt" : "2020-04-29T14:35:41Z",
        "updatedAt" : "2020-05-04T13:25:14Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "d05c4ae3-8ca9-4ff0-8335-4f5300a5a6cf",
        "parentId" : "bdfffd8e-29db-4761-9225-93e2ef0f0473",
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "The choice of size needs tuning, it depends on dataset sparsity and numFeatures, Increasing it may not always increases performance.",
        "createdAt" : "2020-04-30T07:27:34Z",
        "updatedAt" : "2020-05-04T13:25:14Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      }
    ],
    "commit" : "e8abb4ba6b3b03cc0a696dcf43ee5ede109f88ea",
    "line" : 31,
    "diffHunk" : "@@ -1,1 +158,162 @@\n  /**\n   * Set block size for stacking input data in matrices.\n   * If blockSize == 1, then stacking will be skipped, and each vector is treated individually;\n   * If blockSize &gt; 1, then vectors will be stacked to blocks, and high-level BLAS routines"
  }
]