[
  {
    "id" : "8934cb29-e839-4748-8060-b4f400cb5664",
    "prId" : 26064,
    "prUrl" : "https://github.com/apache/spark/pull/26064#pullrequestreview-301349293",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "28903e77-0ef1-46c3-b83f-5834a4eb4096",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Nit, while we're here. Is it maybe faster to start with an array of 0, and flip the ones that exceed the threshold? just because the array is already initialized to 0.",
        "createdAt" : "2019-10-10T21:11:09Z",
        "updatedAt" : "2019-10-15T03:26:41Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "bd86af3c-ecf3-479a-b0d4-8d4243c2d837",
        "parentId" : "28903e77-0ef1-46c3-b83f-5834a4eb4096",
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "Oh, if we initialize an array with 0 values, we mast traversal across all elements since the threshold is negativce, implicit 0 will return 0. Then we can not use `foreachActive` to only process active elements.",
        "createdAt" : "2019-10-12T03:14:51Z",
        "updatedAt" : "2019-10-15T03:26:41Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      },
      {
        "id" : "a39d493b-2fa2-40ee-96d3-8874941d0b26",
        "parentId" : "28903e77-0ef1-46c3-b83f-5834a4eb4096",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Oh right of course, nevermind.",
        "createdAt" : "2019-10-14T14:38:23Z",
        "updatedAt" : "2019-10-15T03:26:41Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      }
    ],
    "commit" : "1530f399e155d62cbe26f39ac8fc58f091a569ae",
    "line" : 142,
    "diffHunk" : "@@ -1,1 +135,139 @@            s\"$td will build a dense output, so take care when applying to sparse input.\")\n          udf { vector: Vector =>\n            val values = Array.fill(vector.size)(1.0)\n            vector.foreachActive { (index, value) =>\n              if (value <= td) {"
  },
  {
    "id" : "569237e2-677d-4f5a-abdd-ed727713c304",
    "prId" : 26064,
    "prUrl" : "https://github.com/apache/spark/pull/26064#pullrequestreview-300982232",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "917c70a3-d5d8-4f01-838a-32e688d18417",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Do you also need to check if outputCols and inputCols are set together? or is that already done elsewhere now?",
        "createdAt" : "2019-10-10T21:12:54Z",
        "updatedAt" : "2019-10-15T03:26:41Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "0d356784-f36f-4a4b-a434-3097c401c1a6",
        "parentId" : "917c70a3-d5d8-4f01-838a-32e688d18417",
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "method `ParamValidators.checkSingleVsMultiColumnParams` in `transformSchema`  checks whether they are set together.",
        "createdAt" : "2019-10-12T03:08:15Z",
        "updatedAt" : "2019-10-15T03:26:41Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      }
    ],
    "commit" : "1530f399e155d62cbe26f39ac8fc58f091a569ae",
    "line" : 99,
    "diffHunk" : "@@ -1,1 +102,106 @@    val outputSchema = transformSchema(dataset.schema, logging = true)\n\n    val (inputColNames, outputColNames, tds) =\n      if (isSet(inputCols)) {\n        if (isSet(thresholds)) {"
  },
  {
    "id" : "7e506195-1a29-43fb-8cf8-e66b4f81fb77",
    "prId" : 25829,
    "prUrl" : "https://github.com/apache/spark/pull/25829#pullrequestreview-290507588",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a34bba0d-948a-4bac-8220-e91c21d4db63",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "I think this is OK. It will almost always be dense but not always. The warning is spurious if the input is dense already, but, a negative threshold is rare... I think. I'm trying to recall whether this is ever applied to outputs of classifiers like SVMs that output [-1, 1].",
        "createdAt" : "2019-09-19T11:48:48Z",
        "updatedAt" : "2019-09-19T11:48:54Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      }
    ],
    "commit" : "190c3b891387e2a137964c0cc3b5670dede23a25",
    "line" : 35,
    "diffHunk" : "@@ -1,1 +96,100 @@\n      case _: VectorUDT if td < 0 =>\n        this.logWarning(s\"Binarization operations on sparse dataset with negative threshold \" +\n          s\"$td will build a dense output, so take care when applying to sparse input.\")\n        udf { vector: Vector =>"
  }
]