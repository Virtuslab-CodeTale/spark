[
  {
    "id" : "e5ad2f22-a9e5-4a7d-a408-b8d1b56eec57",
    "prId" : 26135,
    "prUrl" : "https://github.com/apache/spark/pull/26135#pullrequestreview-302384008",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6642cf1c-797d-4c72-8088-5111415c9529",
        "parentId" : null,
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "If the metricName==logloss, then the confusion matrix is not needed, so I make this computation lazy.",
        "createdAt" : "2019-10-16T07:58:02Z",
        "updatedAt" : "2019-10-18T01:59:17Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      }
    ],
    "commit" : "f46046cdf8370a77d77f5afbaab6d4230fa91ffb",
    "line" : 43,
    "diffHunk" : "@@ -1,1 +50,54 @@    })\n\n  private lazy val confusions = predictionAndLabels.map {\n    case (prediction: Double, label: Double, weight: Double, _) =>\n      ((label, prediction), weight)"
  },
  {
    "id" : "46545c6e-4292-4ea2-88ea-9707e9a24711",
    "prId" : 26135,
    "prUrl" : "https://github.com/apache/spark/pull/26135#pullrequestreview-302385117",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6512e663-a3a8-43fb-a2b0-0d40fbebe05e",
        "parentId" : null,
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "matching will not work in pyspark, so I have to use `r.get` instead.\r\n`MultilabelMetrics` also deals with dataframe in this way.",
        "createdAt" : "2019-10-16T08:00:12Z",
        "updatedAt" : "2019-10-18T01:59:17Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      }
    ],
    "commit" : "f46046cdf8370a77d77f5afbaab6d4230fa91ffb",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +41,45 @@   */\n  private[mllib] def this(predictionAndLabels: DataFrame) =\n    this(predictionAndLabels.rdd.map { r =>\n      r.size match {\n        case 2 => (r.getDouble(0), r.getDouble(1), 1.0, null)"
  },
  {
    "id" : "ff405830-7a05-4aeb-87f7-d4ea00bb7f0d",
    "prId" : 26135,
    "prUrl" : "https://github.com/apache/spark/pull/26135#pullrequestreview-303139862",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1e58cf01-a363-4fbd-9f9a-ee97f3cf3646",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "This is my only concern, that you have to plumb through a probability just to support this, but it's not out of the question. ",
        "createdAt" : "2019-10-16T16:49:38Z",
        "updatedAt" : "2019-10-18T01:59:17Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "eb21c90b-cd8a-4f78-9052-1b2bf27c44d1",
        "parentId" : "1e58cf01-a363-4fbd-9f9a-ee97f3cf3646",
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "Since current input do not provide probability for metrics like logloss, so I have to add it here.",
        "createdAt" : "2019-10-17T09:59:28Z",
        "updatedAt" : "2019-10-18T01:59:17Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      }
    ],
    "commit" : "f46046cdf8370a77d77f5afbaab6d4230fa91ffb",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +29,33 @@ * Evaluator for multiclass classification.\n *\n * @param predictionAndLabels an RDD of (prediction, label, weight, probability) or\n *                            (prediction, label, weight) or (prediction, label) tuples.\n */"
  },
  {
    "id" : "e55913ea-c275-4c16-ba72-8a5def73839c",
    "prId" : 24717,
    "prUrl" : "https://github.com/apache/spark/pull/24717#pullrequestreview-242712296",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "443e1f62-0057-45ad-ad68-e7c1edfbd44b",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "This would be a no-op right unless w == 0? what about:\r\n```\r\n} else if (w == 0.0) {\r\n  tpByClass.put(label, 0.0)\r\n}\r\n```\r\nSame below.",
        "createdAt" : "2019-05-28T14:37:12Z",
        "updatedAt" : "2019-05-29T03:03:35Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      }
    ],
    "commit" : "7d83ac39df2a45fca2990e855802055f60804cc6",
    "line" : 81,
    "diffHunk" : "@@ -1,1 +80,84 @@          tpByClass.update(label, w + weight)\n        } else if (w == 0.0) {\n          tpByClass.update(label, w)\n        }\n    }"
  },
  {
    "id" : "796ca68c-92aa-4e77-aae3-fe625eaf8e4b",
    "prId" : 24717,
    "prUrl" : "https://github.com/apache/spark/pull/24717#pullrequestreview-242712296",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9358d167-fc0d-4343-a127-173dc4c17032",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "OK yeah I was also thinking you could just compute these all non-lazily, and do so in one pass over confusions, but, maybe not worth it.",
        "createdAt" : "2019-05-28T14:38:06Z",
        "updatedAt" : "2019-05-29T03:03:35Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      }
    ],
    "commit" : "7d83ac39df2a45fca2990e855802055f60804cc6",
    "line" : 43,
    "diffHunk" : "@@ -1,1 +60,64 @@    .collectAsMap()\n\n  private lazy val labelCountByClass: Map[Double, Double] = {\n    val labelCountByClass = mutable.Map.empty[Double, Double]\n    confusions.iterator.foreach {"
  }
]