[
  {
    "id" : "e5ad2f22-a9e5-4a7d-a408-b8d1b56eec57",
    "prId" : 26135,
    "prUrl" : "https://github.com/apache/spark/pull/26135#pullrequestreview-302384008",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6642cf1c-797d-4c72-8088-5111415c9529",
        "parentId" : null,
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "If the metricName==logloss, then the confusion matrix is not needed, so I make this computation lazy.",
        "createdAt" : "2019-10-16T07:58:02Z",
        "updatedAt" : "2019-10-18T01:59:17Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      }
    ],
    "commit" : "f46046cdf8370a77d77f5afbaab6d4230fa91ffb",
    "line" : 43,
    "diffHunk" : "@@ -1,1 +50,54 @@    })\n\n  private lazy val confusions = predictionAndLabels.map {\n    case (prediction: Double, label: Double, weight: Double, _) =>\n      ((label, prediction), weight)"
  },
  {
    "id" : "46545c6e-4292-4ea2-88ea-9707e9a24711",
    "prId" : 26135,
    "prUrl" : "https://github.com/apache/spark/pull/26135#pullrequestreview-302385117",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6512e663-a3a8-43fb-a2b0-0d40fbebe05e",
        "parentId" : null,
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "matching will not work in pyspark, so I have to use `r.get` instead.\r\n`MultilabelMetrics` also deals with dataframe in this way.",
        "createdAt" : "2019-10-16T08:00:12Z",
        "updatedAt" : "2019-10-18T01:59:17Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      }
    ],
    "commit" : "f46046cdf8370a77d77f5afbaab6d4230fa91ffb",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +41,45 @@   */\n  private[mllib] def this(predictionAndLabels: DataFrame) =\n    this(predictionAndLabels.rdd.map { r =>\n      r.size match {\n        case 2 => (r.getDouble(0), r.getDouble(1), 1.0, null)"
  },
  {
    "id" : "ff405830-7a05-4aeb-87f7-d4ea00bb7f0d",
    "prId" : 26135,
    "prUrl" : "https://github.com/apache/spark/pull/26135#pullrequestreview-303139862",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1e58cf01-a363-4fbd-9f9a-ee97f3cf3646",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "This is my only concern, that you have to plumb through a probability just to support this, but it's not out of the question. ",
        "createdAt" : "2019-10-16T16:49:38Z",
        "updatedAt" : "2019-10-18T01:59:17Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "eb21c90b-cd8a-4f78-9052-1b2bf27c44d1",
        "parentId" : "1e58cf01-a363-4fbd-9f9a-ee97f3cf3646",
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "Since current input do not provide probability for metrics like logloss, so I have to add it here.",
        "createdAt" : "2019-10-17T09:59:28Z",
        "updatedAt" : "2019-10-18T01:59:17Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      }
    ],
    "commit" : "f46046cdf8370a77d77f5afbaab6d4230fa91ffb",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +29,33 @@ * Evaluator for multiclass classification.\n *\n * @param predictionAndLabels an RDD of (prediction, label, weight, probability) or\n *                            (prediction, label, weight) or (prediction, label) tuples.\n */"
  }
]