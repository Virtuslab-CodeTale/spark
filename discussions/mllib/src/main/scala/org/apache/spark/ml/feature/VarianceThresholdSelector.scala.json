[
  {
    "id" : "7ed6ec73-e623-4244-80eb-bfca4d2afacf",
    "prId" : 27954,
    "prUrl" : "https://github.com/apache/spark/pull/27954#pullrequestreview-378886986",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ff76ab8b-00c4-4ec5-9631-41e7c4ec34b5",
        "parentId" : null,
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "I'd like to keep previous comments here : \r\n\"# Use peak-to-peak to avoid numeric precision issues for constant features\"\r\n",
        "createdAt" : "2020-03-21T03:05:36Z",
        "updatedAt" : "2020-03-21T05:38:57Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      }
    ],
    "commit" : "3f5ecef0988f2a1838c407fb65876ff65847e7ad",
    "line" : 99,
    "diffHunk" : "@@ -1,1 +97,101 @@    val indices = Array.tabulate(numFeatures) { i =>\n      // Use peak-to-peak to avoid numeric precision issues for constant features\n      (i, if (maxs(i) == mins(i)) 0.0 else variances(i))\n    }.filter(_._2 > getVarianceThreshold).map(_._1)\n    copyValues(new VarianceThresholdSelectorModel(uid, indices.sorted)"
  }
]