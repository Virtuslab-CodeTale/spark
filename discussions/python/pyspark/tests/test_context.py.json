[
  {
    "id" : "4ea77df2-ee32-4700-8cfa-1d241b3b10d4",
    "prId" : 28986,
    "prUrl" : "https://github.com/apache/spark/pull/28986#pullrequestreview-442352128",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ad0d4df1-a96d-4aa5-a6cd-2ba9b8678556",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "I would put a JIRA ID and a short comment like as we lately documented it at http://spark.apache.org/contributing.html\r\n\r\n```python\r\ndef test_case(self):\r\n    # SPARK-12345: a short description of the test\r\n    ...\r\n```",
        "createdAt" : "2020-07-03T11:34:59Z",
        "updatedAt" : "2020-07-07T18:01:23Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "0faac2a4495bebc67819122d7a2d23a750c71ddd",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +270,274 @@    def test_disallow_to_create_spark_context_in_executors(self):\n        # SPARK-32160: SparkContext should not be created in executors.\n        with SparkContext(\"local-cluster[3, 1, 1024]\") as sc:\n            with self.assertRaises(Exception) as context:\n                sc.range(2).foreach(lambda _: SparkContext())"
  },
  {
    "id" : "d68fd333-0d38-423d-a691-6906ef7324f8",
    "prId" : 25047,
    "prUrl" : "https://github.com/apache/spark/pull/25047#pullrequestreview-267225927",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "474ce31e-3c70-46b8-98af-1fb30280a672",
        "parentId" : null,
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "This only passed on my laptop locally, but always failed on Jenkins:\r\n\r\n```\r\nPy4JJavaError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\r\n: java.lang.AssertionError: assertion failed: spark.test.home is not set!\r\n\tat scala.Predef$.assert(Predef.scala:223)\r\n\tat org.apache.spark.resource.ResourceUtils$.$anonfun$getOrCreateResourcesDir$1(ResourceUtils.scala:321)\r\n\tat scala.Option.getOrElse(Option.scala:138)\r\n\tat org.apache.spark.resource.ResourceUtils$.getOrCreateResourcesDir(ResourceUtils.scala:319)\r\n\tat org.apache.spark.resource.ResourceUtils$.acquireLock(ResourceUtils.scala:279)\r\n\tat org.apache.spark.resource.ResourceUtils$.acquireResources(ResourceUtils.scala:128)\r\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:399)\r\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\r\n\tat sun.reflect.GeneratedConstructorAccessor17.newInstance(Unknown Source)\r\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\r\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:238)\r\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\r\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n```\r\n\r\nAny ideas ? @tgravescs @HyukjinKwon ",
        "createdAt" : "2019-07-18T16:24:34Z",
        "updatedAt" : "2019-08-09T02:27:38Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      },
      {
        "id" : "5a5b1cd3-f189-4d23-b55c-4bfeb70492a9",
        "parentId" : "474ce31e-3c70-46b8-98af-1fb30280a672",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "This is because `spark.test.home` property is only set in testing mode in JVM. I left a comment https://github.com/apache/spark/pull/25047/files/95111b0b9c0a4732041d19b5e221eecea4408147#r306121558",
        "createdAt" : "2019-07-23T04:12:32Z",
        "updatedAt" : "2019-08-09T02:27:38Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "2cc685fc-55b1-44c0-abac-b079635ddd7a",
        "parentId" : "474ce31e-3c70-46b8-98af-1fb30280a672",
        "authorId" : "171fe41b-96df-4362-a600-2d1f030de577",
        "body" : "Thank you for your help :)",
        "createdAt" : "2019-07-26T14:36:55Z",
        "updatedAt" : "2019-08-09T02:27:38Z",
        "lastEditedBy" : "171fe41b-96df-4362-a600-2d1f030de577",
        "tags" : [
        ]
      }
    ],
    "commit" : "15a9897131f06ec115b13d97e86c497ef36dace8",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +274,278 @@        os.chmod(self.tempFile.name, stat.S_IRWXU | stat.S_IXGRP | stat.S_IRGRP |\n                 stat.S_IROTH | stat.S_IXOTH)\n        conf = SparkConf().set(\"spark.test.home\", SPARK_HOME)\n        conf = conf.set(\"spark.driver.resource.gpu.amount\", \"1\")\n        conf = conf.set(\"spark.driver.resource.gpu.discoveryScript\", self.tempFile.name)"
  }
]