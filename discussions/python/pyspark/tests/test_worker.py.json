[
  {
    "id" : "4602215d-e65c-42ae-99d1-ff90ff25aa41",
    "prId" : 30248,
    "prUrl" : "https://github.com/apache/spark/pull/30248#pullrequestreview-526965650",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e587125e-9dc6-4b46-844d-91c833b66b74",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Can you add a short description with JIRA id? See \"Pull Request\" in http://spark.apache.org/contributing.html",
        "createdAt" : "2020-11-10T03:43:40Z",
        "updatedAt" : "2020-11-10T08:53:29Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "38ba2062-39b8-41c5-bc26-43d26b27fe4f",
        "parentId" : "e587125e-9dc6-4b46-844d-91c833b66b74",
        "authorId" : "de37844d-d6ad-4742-9b26-373261f5169e",
        "body" : "updated",
        "createdAt" : "2020-11-10T08:37:12Z",
        "updatedAt" : "2020-11-10T08:53:29Z",
        "lastEditedBy" : "de37844d-d6ad-4742-9b26-373261f5169e",
        "tags" : [
        ]
      }
    ],
    "commit" : "e5c33f0b28e58110de04e9dbc6e1d75bc59d53f0",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +96,100 @@        self.assertEqual(100, rdd.map(str).count())\n\n    def test_after_non_exception_error(self):\n        # SPARK-33339: Pyspark application will hang due to non Exception\n        def raise_system_exit(_):"
  },
  {
    "id" : "f4a28025-ab19-4292-8e5a-40914dabbede",
    "prId" : 27158,
    "prUrl" : "https://github.com/apache/spark/pull/27158#pullrequestreview-340923963",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2b92b0af-0630-4d10-b8d4-b198d6983d37",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "The only other thing I can think of is that this toy memory limit is too low. What if it were 8m or something? if you feel like it you could try testing that too",
        "createdAt" : "2020-01-10T01:55:31Z",
        "updatedAt" : "2020-01-10T02:08:47Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "0993d5b7-24ca-4497-bb77-d698e581c6f2",
        "parentId" : "2b92b0af-0630-4d10-b8d4-b198d6983d37",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "The odd thing is that it passes with local dev. (MacOS, python3 - 3.7.4/python2 - 2.7.10/pypy - Python 2.7.13 & pypy 7.3.0 GCC 4.2.1) so not clear it would help, but if we suspect it we can try.",
        "createdAt" : "2020-01-10T01:57:51Z",
        "updatedAt" : "2020-01-10T02:08:47Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      },
      {
        "id" : "6713fba1-aadf-45db-b549-6c2e2e876889",
        "parentId" : "2b92b0af-0630-4d10-b8d4-b198d6983d37",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "It will pass on Mac OS because Mac doesn't actually limits the memory. it doesn't work on Windows either. So, this hypothesis could make sense. Can we increase to something like 8m?",
        "createdAt" : "2020-01-10T02:00:27Z",
        "updatedAt" : "2020-01-10T02:08:47Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "5e3c7a03-73bf-4031-87f6-aae210e83092",
        "parentId" : "2b92b0af-0630-4d10-b8d4-b198d6983d37",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "OK let me do it instead. Let's modify the PR title/description after confirming it works.",
        "createdAt" : "2020-01-10T02:02:43Z",
        "updatedAt" : "2020-01-10T02:08:47Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      },
      {
        "id" : "4f12432b-82b5-43c8-bac4-ce45121917e3",
        "parentId" : "2b92b0af-0630-4d10-b8d4-b198d6983d37",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Maybe it's best to file a JIRA btw.",
        "createdAt" : "2020-01-10T02:06:06Z",
        "updatedAt" : "2020-01-10T02:08:47Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "9455b63c-ffc7-4239-a264-414e16423281",
        "parentId" : "2b92b0af-0630-4d10-b8d4-b198d6983d37",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "What about filing an issue after confirming the trick doesn't work and we have to disable? We may be able to just treat this PR as MINOR but mentioning the new JIRA issue in \"reason\" which is expected to address this.",
        "createdAt" : "2020-01-10T02:12:48Z",
        "updatedAt" : "2020-01-10T02:12:48Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      },
      {
        "id" : "c174a069-d07a-4f83-96cc-c0192715c0f4",
        "parentId" : "2b92b0af-0630-4d10-b8d4-b198d6983d37",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Sure, that works too. FWIW, I doubt if it consistently fails in the master yet. If that's the case, it should better fix the test here.",
        "createdAt" : "2020-01-10T02:16:18Z",
        "updatedAt" : "2020-01-10T02:16:18Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "fb403cdf-4348-4895-9dd6-96f5a31af449",
        "parentId" : "2b92b0af-0630-4d10-b8d4-b198d6983d37",
        "authorId" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "body" : "FYI #27159 is the patch increasing the value to 8m",
        "createdAt" : "2020-01-10T02:19:31Z",
        "updatedAt" : "2020-01-10T02:19:31Z",
        "lastEditedBy" : "0c28e5da-df9b-4076-bb67-3b6878f1f4ce",
        "tags" : [
        ]
      }
    ],
    "commit" : "23ad40bbe874fcd99e13a4911622a9d63e40ee0f",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +184,188 @@    @unittest.skip(\"disabled temporarily since it's failing consistently\")\n    def test_memory_limit(self):\n        self.sc._conf.set(\"spark.executor.pyspark.memory\", \"1m\")\n        rdd = self.sc.parallelize(xrange(1), 1)\n"
  }
]