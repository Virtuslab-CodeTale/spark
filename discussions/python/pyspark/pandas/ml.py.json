[
  {
    "id" : "4ded304b-3555-49d7-ac57-f23d59a74772",
    "prId" : 33356,
    "prUrl" : "https://github.com/apache/spark/pull/33356#pullrequestreview-707008513",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "759d2836-6541-478d-b811-b8d346761e84",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "I couldn't figure out how to fix:\r\n\r\n```\r\npython/pyspark/pandas/ml.py:81: error: Value of type variable \"_DTypeScalar_co\" of \"dtype\" cannot be \"object\"\r\n```",
        "createdAt" : "2021-07-15T07:20:39Z",
        "updatedAt" : "2021-07-15T07:20:39Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "35f6ca756f18b974f1ece419ec0a1bff216f45c1",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +79,83 @@    # TODO, it should be more robust.\n    accepted_types = {\n        np.dtype(dt)  # type: ignore\n        for dt in [np.int8, np.int16, np.int32, np.int64, np.float32, np.float64, np.bool_]\n    }"
  }
]