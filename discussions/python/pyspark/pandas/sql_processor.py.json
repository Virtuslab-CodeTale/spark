[
  {
    "id" : "41e9b5a3-de58-41b3-b766-d554bfb62a1a",
    "prId" : 33450,
    "prUrl" : "https://github.com/apache/spark/pull/33450#pullrequestreview-712300069",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "4771ab6a-18e1-48fb-a789-37914e79e707",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "I mean I don't know the standard way of describing the list of strings (`list of str`). Are you able to find any example like this in pandas or NumPy documentation?",
        "createdAt" : "2021-07-21T11:40:53Z",
        "updatedAt" : "2021-07-21T11:40:53Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "90d439d1-1e0b-4c71-b8d3-3d6364a6b230",
        "parentId" : "4771ab6a-18e1-48fb-a789-37914e79e707",
        "authorId" : "2d8ced12-ada1-43e1-9240-bf1c11a01e4c",
        "body" : "Yes, seems like they have an example in their official [documents](https://numpydoc.readthedocs.io/en/latest/format.html).\r\n\r\n![Screen Shot 2021-07-22 at 10 03 27 AM](https://user-images.githubusercontent.com/44108233/126577733-7c6d0aec-ba40-4f00-8346-a7647a033cdf.png)\r\n\r\nAnd pandas also has some cases using `list of str` such as https://github.com/pandas-dev/pandas/blob/0eceea496746769e4781f081b8c7159b1ce9f8f0/pandas/core/accessor.py#L70 or https://github.com/pandas-dev/pandas/blob/059c8bac51e47d6eaaa3e36d6a293a22312925e6/pandas/tests/reshape/merge/test_merge_index_as_string.py#L71-L76.",
        "createdAt" : "2021-07-22T01:07:10Z",
        "updatedAt" : "2021-07-22T01:07:30Z",
        "lastEditedBy" : "2d8ced12-ada1-43e1-9240-bf1c11a01e4c",
        "tags" : [
        ]
      }
    ],
    "commit" : "9bac117c2518d1f6c35cdb3a68da939bd0640d8f",
    "line" : 30,
    "diffHunk" : "@@ -1,1 +69,73 @@    query : str\n        the SQL query\n    index_col : str or list of str, optional\n        Column names to be used in Spark to represent pandas-on-Spark's index. The index name\n        in pandas-on-Spark is ignored. By default, the index is always lost."
  },
  {
    "id" : "42b28afa-99d3-4222-a862-6c7b0eba373f",
    "prId" : 32069,
    "prUrl" : "https://github.com/apache/spark/pull/32069#pullrequestreview-629503054",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c03ae16d-372c-4e14-8f9c-2c1c1d8c1847",
        "parentId" : null,
        "authorId" : "43998e22-6c2f-401d-9914-8cecf6fad929",
        "body" : "Renamed the file name from `sql.py` to `sql_processor.py` to avoid the name conflict between `sql` module and `pp.sql` function.",
        "createdAt" : "2021-04-07T00:27:25Z",
        "updatedAt" : "2021-04-07T00:59:10Z",
        "lastEditedBy" : "43998e22-6c2f-401d-9914-8cecf6fad929",
        "tags" : [
        ]
      }
    ],
    "commit" : "2651cfb83ccdbf871bcf1d5bc05df9b237e3b493",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +308,312 @@    import sys\n    from pyspark.sql import SparkSession\n    import pyspark.pandas.sql_processor\n\n    os.chdir(os.environ[\"SPARK_HOME\"])"
  }
]