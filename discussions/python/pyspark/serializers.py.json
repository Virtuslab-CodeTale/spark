[
  {
    "id" : "8bdc16db-f20e-4003-b49b-8a7b6c2ffdd6",
    "prId" : 24965,
    "prUrl" : "https://github.com/apache/spark/pull/24965#pullrequestreview-253903526",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "450c02ba-01c1-4be8-82d5-89625e6b4f2d",
        "parentId" : null,
        "authorId" : "627d34e9-eba3-4504-aa67-ffc2f967c413",
        "body" : "I wanted to read these also using the message reader but for some reason pa.read_schema(self_reader.read_next_message()) didn't work.",
        "createdAt" : "2019-06-25T10:12:04Z",
        "updatedAt" : "2019-07-02T08:59:40Z",
        "lastEditedBy" : "627d34e9-eba3-4504-aa67-ffc2f967c413",
        "tags" : [
        ]
      }
    ],
    "commit" : "d15dabbf71ad3007ea0c37e71c997e6fa1799e51",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +361,365 @@    def __init__(self, stream):\n        import pyarrow as pa\n        self._schema1 = pa.read_schema(stream)\n        self._schema2 = pa.read_schema(stream)\n        self._reader = pa.MessageReader.open_stream(stream)"
  },
  {
    "id" : "d4b01229-e332-4e80-9130-b5e5a1600e5d",
    "prId" : 24844,
    "prUrl" : "https://github.com/apache/spark/pull/24844#pullrequestreview-249023075",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e48ba901-c242-4c37-819a-68aaa20ae36d",
        "parentId" : null,
        "authorId" : "499ab9d4-efdc-4d13-8c25-3de4ce119ce7",
        "body" : "Removing this doesn't fail existing tests. @BryanCutler do you remember why are we doing `fillna(0)` here?",
        "createdAt" : "2019-06-11T20:33:36Z",
        "updatedAt" : "2019-06-21T18:47:14Z",
        "lastEditedBy" : "499ab9d4-efdc-4d13-8c25-3de4ce119ce7",
        "tags" : [
        ]
      },
      {
        "id" : "49524230-6d77-44dd-ad90-25af752c57b1",
        "parentId" : "e48ba901-c242-4c37-819a-68aaa20ae36d",
        "authorId" : "0c293c45-22a6-4358-8a40-adbf7c470575",
        "body" : "I believe it was due to a Pandas error, most likely because we were testing with 0.19.2 at the time. Can you manually run some tests with different Pandas versions? It will be best to test with older versions, but it might be kind of hard to get 0.19.2 working with pyarrow 0.12.1 though..",
        "createdAt" : "2019-06-12T17:34:06Z",
        "updatedAt" : "2019-06-21T18:47:14Z",
        "lastEditedBy" : "0c293c45-22a6-4358-8a40-adbf7c470575",
        "tags" : [
        ]
      },
      {
        "id" : "cd1d4967-aded-4268-8475-2b94c07299a4",
        "parentId" : "e48ba901-c242-4c37-819a-68aaa20ae36d",
        "authorId" : "499ab9d4-efdc-4d13-8c25-3de4ce119ce7",
        "body" : "Yeah pandas 0.19.2 doesn't work with pyarrow 0.12. I cannot run arrow tests with pandas 0.19.2 anymore.\r\n\r\nSince we are requiring min arrow version to be 0.12, it means pandas version 0.19.2 is not supported if the user wants to use Arrow.",
        "createdAt" : "2019-06-12T21:15:56Z",
        "updatedAt" : "2019-06-21T18:47:14Z",
        "lastEditedBy" : "499ab9d4-efdc-4d13-8c25-3de4ce119ce7",
        "tags" : [
        ]
      }
    ],
    "commit" : "bda31b5811c9ac2eff27bfcec548ad2b3b0d2f3a",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +297,301 @@            # Ensure timestamp series are in expected form for Spark internal representation\n            if t is not None and pa.types.is_timestamp(t):\n                s = _check_series_convert_timestamps_internal(s, self._timezone)\n            try:\n                array = pa.Array.from_pandas(s, mask=mask, type=t, safe=self._safecheck)"
  },
  {
    "id" : "7d0e1cbf-64ba-463e-912f-c3f439265bac",
    "prId" : 24519,
    "prUrl" : "https://github.com/apache/spark/pull/24519#pullrequestreview-233316019",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "06ee4dee-9538-47d0-b30f-c7e0762a602f",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "We can use `pickle.DEFAULT_PROTOCOL` too but let me stick with constant since seems protocol 4 has this bug.",
        "createdAt" : "2019-05-03T03:10:31Z",
        "updatedAt" : "2019-05-03T03:10:31Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "ab2e1f17-8b63-41c6-ba54-1ce441c49c3b",
        "parentId" : "06ee4dee-9538-47d0-b30f-c7e0762a602f",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "It looks nice and solid. BTW, do you think we can have a pointer for the upstream bug issue against `pickle`?",
        "createdAt" : "2019-05-03T03:21:59Z",
        "updatedAt" : "2019-05-03T03:35:56Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "67560a30-d4a5-4278-8a6e-191d63c373d5",
        "parentId" : "06ee4dee-9538-47d0-b30f-c7e0762a602f",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Do you mean the bug issue related to the root cause somewhere? (I think) it's more like an issue within Pryolite library .. I am not 100% sure yet. I will update that when I have it. I am looking into this to identify the cause.",
        "createdAt" : "2019-05-03T03:50:18Z",
        "updatedAt" : "2019-05-03T03:50:18Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "3ab6eb27614a888295b82b1c3e3b0b914f9f99a3",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +68,72 @@    basestring = unicode = str\n    xrange = range\n    pickle_protocol = 3\n\nfrom pyspark import cloudpickle"
  }
]