[
  {
    "id" : "9591ccdb-868b-4ab4-b1c4-a658e01865f6",
    "prId" : 28795,
    "prUrl" : "https://github.com/apache/spark/pull/28795#pullrequestreview-428577054",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "72667d9c-9f78-44b2-a99e-1dd70c59be90",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "In this case, we don't compare `[Row(name=u'b', avg=102.0), Row(name=u'a', avg=102.0)]`?",
        "createdAt" : "2020-06-11T03:27:11Z",
        "updatedAt" : "2020-06-11T03:28:05Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "cd3af8ca-6eb0-42ef-b1b9-1a55d7e453a0",
        "parentId" : "72667d9c-9f78-44b2-a99e-1dd70c59be90",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "I think we could compare them as are. It's just to prevent an issue such as SPARK-29748 or similar issues in the future.",
        "createdAt" : "2020-06-11T03:52:24Z",
        "updatedAt" : "2020-06-11T03:52:24Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "0704a9d5-d6bb-4e4a-b6c5-889089c5a549",
        "parentId" : "72667d9c-9f78-44b2-a99e-1dd70c59be90",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Got it~ No problem~",
        "createdAt" : "2020-06-11T04:02:06Z",
        "updatedAt" : "2020-06-11T04:02:07Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "e7a99746deea89e98cd800c5cdee9a8cedbf6088",
    "line" : 37,
    "diffHunk" : "@@ -1,1 +384,388 @@        row = self.spark.sql(\n            \"SELECT name, javaUDAF(id) as avg from df group by name order by name desc\").first()\n        self.assertEqual(row.asDict(), Row(name='b', avg=102.0).asDict())\n\n    def test_non_existed_udf(self):"
  },
  {
    "id" : "3d84109a-905d-45b3-af0d-074650a6ac39",
    "prId" : 25138,
    "prUrl" : "https://github.com/apache/spark/pull/25138#pullrequestreview-262172583",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2df72a10-7c03-4416-a338-0c4881e4a84b",
        "parentId" : null,
        "authorId" : "7e665d8b-d739-4edf-88c8-7379ff8585c2",
        "body" : "Verify read stdin get EOF immediately.\r\nShould we add more test such as verifying the worker process actually exit ?\r\nBut I think current test is enough, the fact we can only read EOF from stdin represent the stdin is dummy and safe file descriptor, it won't influence other file descriptors in daemon.",
        "createdAt" : "2019-07-16T03:32:17Z",
        "updatedAt" : "2019-07-30T12:45:04Z",
        "lastEditedBy" : "7e665d8b-d739-4edf-88c8-7379ff8585c2",
        "tags" : [
        ]
      }
    ],
    "commit" : "51b1a660d663d5b0ae5c521072ca15563a59b9de",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +624,628 @@            res = sys.stdin.read()\n            # Because the standard input is '/dev/null', it reaches to EOF.\n            assert res == '', \"Expect read EOF from stdin.\"\n            return iterator\n"
  }
]