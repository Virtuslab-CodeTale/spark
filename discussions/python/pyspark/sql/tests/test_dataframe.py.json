[
  {
    "id" : "43ae3450-ca64-4cf1-a715-6706fd487a01",
    "prId" : 33484,
    "prUrl" : "https://github.com/apache/spark/pull/33484#pullrequestreview-713427680",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "791cda7a-e933-43e8-b5e3-4a010a16ba1e",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Let's add a comment here, see \"Pull Requests\" at https://spark.apache.org/contributing.html",
        "createdAt" : "2021-07-23T04:00:36Z",
        "updatedAt" : "2021-07-23T04:00:36Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "13088609-145d-42f1-9c93-6b911797a66b",
        "parentId" : "791cda7a-e933-43e8-b5e3-4a010a16ba1e",
        "authorId" : "c4ecf4e4-1fda-4fed-9980-aed6c3b3e8e4",
        "body" : "Done",
        "createdAt" : "2021-07-23T06:28:22Z",
        "updatedAt" : "2021-07-23T06:28:23Z",
        "lastEditedBy" : "c4ecf4e4-1fda-4fed-9980-aed6c3b3e8e4",
        "tags" : [
        ]
      }
    ],
    "commit" : "90675b0d300a299a047f97274e9d0814b2366a37",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +391,395 @@        self.assertEqual(3, logical_plan.toString().count(\"itworks\"))\n\n    def test_observe(self):\n        # SPARK-36263: tests the DataFrame.observe(Observation, *Column) method\n        from pyspark.sql import Observation"
  },
  {
    "id" : "34ef1a06-5979-45d8-a6d2-ecd79791bf02",
    "prId" : 33054,
    "prUrl" : "https://github.com/apache/spark/pull/33054#pullrequestreview-691517363",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7e13feb0-0dcf-4c7f-a55c-a0b5bc327de6",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "You should run this conditionally. See `python/pyspark/sql/tests/test_arrow.py`.",
        "createdAt" : "2021-06-24T09:08:01Z",
        "updatedAt" : "2021-06-24T09:08:01Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "e3349906c1b6586bbc850557bc1ce087c34c22e5",
    "line" : 7,
    "diffHunk" : "@@ -1,1 +859,863 @@        not have_pandas or not have_pyarrow,\n        pandas_requirement_message or pyarrow_requirement_message)  # type: ignore\n    def test_to_pandas_on_spark(self):\n        import pandas as pd\n        from pandas.testing import assert_frame_equal"
  },
  {
    "id" : "b8ad4794-66c4-4279-88a4-8408275eebb1",
    "prId" : 32555,
    "prUrl" : "https://github.com/apache/spark/pull/32555#pullrequestreview-660398451",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "063898b6-32f6-4174-b3e0-a15633b73882",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "I would add a comment with a JIRA, see also https://spark.apache.org/contributing.html",
        "createdAt" : "2021-05-16T01:06:13Z",
        "updatedAt" : "2021-05-16T01:06:13Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "a30729a1d66bb357ffc2c7909f6a9889fa1513d3",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +842,846 @@        # to DataFrame.show\n\n        df = self.spark.createDataFrame([('foo',)])\n        df.show(5)\n        df.show(5, True)"
  },
  {
    "id" : "2bdcf6a3-86e9-4802-b770-9fca26b527c5",
    "prId" : 27247,
    "prUrl" : "https://github.com/apache/spark/pull/27247#pullrequestreview-344346256",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "509d69bf-33e6-4eb5-bef4-6a732ab6e85a",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Oh, do we need to re-open SPARK-29188 then because we know that `toPandas()` will fail when spark.sql.execution.arrow.pyspark.enabled=True?",
        "createdAt" : "2020-01-17T02:45:56Z",
        "updatedAt" : "2020-01-17T02:45:56Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "b2d0b338-0817-434a-914b-54b910d0971d",
        "parentId" : "509d69bf-33e6-4eb5-bef4-6a732ab6e85a",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "hmmm .. I will just open another one just to make the management simpler.",
        "createdAt" : "2020-01-17T02:54:28Z",
        "updatedAt" : "2020-01-17T02:54:29Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "0e0e095d-1e5a-4879-8faf-1b10e52600a3",
        "parentId" : "509d69bf-33e6-4eb5-bef4-6a732ab6e85a",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "I opened, here https://issues.apache.org/jira/browse/SPARK-30537.",
        "createdAt" : "2020-01-17T02:56:13Z",
        "updatedAt" : "2020-01-17T02:56:14Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "327be1ca-8c09-45e9-a76d-bd6e862d1fb3",
        "parentId" : "509d69bf-33e6-4eb5-bef4-6a732ab6e85a",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "+1.",
        "createdAt" : "2020-01-17T03:26:42Z",
        "updatedAt" : "2020-01-17T03:26:43Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "507b625a4c669d68f9ac57a9a204fd30f41d0ab9",
    "line" : 21,
    "diffHunk" : "@@ -1,1 +551,555 @@    def test_to_pandas_from_empty_dataframe(self):\n        with self.sql_conf({\"spark.sql.execution.arrow.pyspark.enabled\": False}):\n            # SPARK-29188 test that toPandas() on an empty dataframe has the correct dtypes\n            import numpy as np\n            sql = \"\"\""
  }
]