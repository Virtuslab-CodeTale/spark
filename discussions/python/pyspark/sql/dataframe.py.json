[
  {
    "id" : "4a01fac6-78f7-47e8-97fe-063c789f046b",
    "prId" : 33484,
    "prUrl" : "https://github.com/apache/spark/pull/33484#pullrequestreview-714300427",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5a06afcd-6bc8-49e2-a1bb-eacc45b9cae7",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Let's move this under \"A user can retrieve ...\"",
        "createdAt" : "2021-07-25T01:44:52Z",
        "updatedAt" : "2021-07-25T01:44:52Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "2518baf2-2f40-4fa7-8f8e-1d0e809dadba",
        "parentId" : "5a06afcd-6bc8-49e2-a1bb-eacc45b9cae7",
        "authorId" : "c4ecf4e4-1fda-4fed-9980-aed6c3b3e8e4",
        "body" : "moved",
        "createdAt" : "2021-07-25T10:16:42Z",
        "updatedAt" : "2021-07-25T10:16:42Z",
        "lastEditedBy" : "c4ecf4e4-1fda-4fed-9980-aed6c3b3e8e4",
        "tags" : [
        ]
      }
    ],
    "commit" : "90675b0d300a299a047f97274e9d0814b2366a37",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +1837,1841 @@        A user can retrieve the metrics by accessing `Observation.get`.\n\n        .. versionadded:: 3.3.0\n\n        Parameters"
  },
  {
    "id" : "b8d0bc44-0b78-4c34-82fe-8eedf93ca3a5",
    "prId" : 33364,
    "prUrl" : "https://github.com/apache/spark/pull/33364#pullrequestreview-708067922",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5c54ec25-f7d1-49da-9182-99f4b447da16",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "```suggestion\r\n            raise TypeError(\"Parameter 'subset' must be a list of columns or a single column\")\r\n```",
        "createdAt" : "2021-07-16T07:05:13Z",
        "updatedAt" : "2021-07-16T07:05:14Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "2c720e2d8b4edcab3f52f611849373b18377829f",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +1984,1988 @@        if subset is not None and (\n                not isinstance(subset, Iterable) or isinstance(subset, str)):\n            raise TypeError(\"Parameter 'subset' must be a list of columns\")\n\n        if subset is None:"
  },
  {
    "id" : "37660dd0-ff7a-4b61-b6a6-b98335be1675",
    "prId" : 33054,
    "prUrl" : "https://github.com/apache/spark/pull/33054#pullrequestreview-692124029",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "59865833-d09c-4470-8427-e818873fc6a0",
        "parentId" : null,
        "authorId" : "43998e22-6c2f-401d-9914-8cecf6fad929",
        "body" : "We need to add the signature in `dataframe.pyi` file?",
        "createdAt" : "2021-06-24T19:03:13Z",
        "updatedAt" : "2021-06-24T19:03:51Z",
        "lastEditedBy" : "43998e22-6c2f-401d-9914-8cecf6fad929",
        "tags" : [
        ]
      }
    ],
    "commit" : "e3349906c1b6586bbc850557bc1ce087c34c22e5",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +2696,2700 @@        return DataFrameWriterV2(self, table)\n\n    def to_pandas_on_spark(self, index_col=None):\n        \"\"\"\n        Converts the existing DataFrame into a pandas-on-Spark DataFrame."
  },
  {
    "id" : "739aac11-68c0-4638-8c05-9fb2f1e9e3cb",
    "prId" : 32555,
    "prUrl" : "https://github.com/apache/spark/pull/32555#pullrequestreview-660398123",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2cd4baf9-4797-49a5-af19-c9315e17a75e",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "While we're here, would you mind fix the docs above `truncate : bool, optional` -> `truncate : bool or int, optional`.",
        "createdAt" : "2021-05-16T00:59:17Z",
        "updatedAt" : "2021-05-16T00:59:17Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "a30729a1d66bb357ffc2c7909f6a9889fa1513d3",
    "line" : 10,
    "diffHunk" : "@@ -1,1 +480,484 @@         name | Alice\n        -RECORD 1-----\n         age  | 5\n         name | Bob\n        \"\"\""
  },
  {
    "id" : "fc165313-05bc-46cc-ab7f-7b75697cceb3",
    "prId" : 32555,
    "prUrl" : "https://github.com/apache/spark/pull/32555#pullrequestreview-660462900",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d1c6e1ad-4f26-404d-b212-47f7d7cb9e7a",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "why do we need to check if `n` is `bool`? bool inherits `int` anyway so it's no-op to remove",
        "createdAt" : "2021-05-16T01:05:22Z",
        "updatedAt" : "2021-05-16T01:05:22Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "18941085-a936-438b-9641-6404d1f3ed54",
        "parentId" : "d1c6e1ad-4f26-404d-b212-47f7d7cb9e7a",
        "authorId" : "e7dcdd7d-a86f-415f-875c-a80eec9bc0f6",
        "body" : "if we pass `n=False` then ` not isinstance(n, int)` is `False` and with this alone the error would not be raised. We need to have an explicit check to reject the `bool`-typed `n`",
        "createdAt" : "2021-05-16T06:05:42Z",
        "updatedAt" : "2021-05-16T06:05:58Z",
        "lastEditedBy" : "e7dcdd7d-a86f-415f-875c-a80eec9bc0f6",
        "tags" : [
        ]
      },
      {
        "id" : "81ebb0ff-c828-4a38-861b-6411cd42a0f4",
        "parentId" : "d1c6e1ad-4f26-404d-b212-47f7d7cb9e7a",
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Is this trying to catch the case where a user calls `.show(False)` for example, meaning `.show(truncate=False)`? I get it. While I think we could equally check so many other methods like this, maybe this is worth checking more thoroughly here.",
        "createdAt" : "2021-05-16T14:13:18Z",
        "updatedAt" : "2021-05-16T14:16:51Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "1f31d52d-01c4-4906-a777-862a8d138194",
        "parentId" : "d1c6e1ad-4f26-404d-b212-47f7d7cb9e7a",
        "authorId" : "e7dcdd7d-a86f-415f-875c-a80eec9bc0f6",
        "body" : "Maybe we can come up with a generic mechanism  to tackle  non-existing method exceptions from`ReflectionEngine.getMethod`",
        "createdAt" : "2021-05-16T20:14:24Z",
        "updatedAt" : "2021-05-16T20:14:24Z",
        "lastEditedBy" : "e7dcdd7d-a86f-415f-875c-a80eec9bc0f6",
        "tags" : [
        ]
      }
    ],
    "commit" : "a30729a1d66bb357ffc2c7909f6a9889fa1513d3",
    "line" : 14,
    "diffHunk" : "@@ -1,1 +484,488 @@        \"\"\"\n\n        if not isinstance(n, int) or isinstance(n, bool):\n            raise TypeError(\"Parameter 'n' (number of rows) must be an int\")\n"
  },
  {
    "id" : "31d68372-0afc-4d1e-a99c-5ff78dccaec3",
    "prId" : 32276,
    "prUrl" : "https://github.com/apache/spark/pull/32276#pullrequestreview-641189944",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "cd06a248-4430-41df-b47c-6849be6ccfec",
        "parentId" : null,
        "authorId" : "c13f1277-0254-494b-8e7a-bd7c261b2e9f",
        "body" : "Note that there are some wrong usage on ValueError in some other methods, I add an issue on https://issues.apache.org/jira/browse/SPARK-35176",
        "createdAt" : "2021-04-21T14:49:28Z",
        "updatedAt" : "2021-04-21T14:49:28Z",
        "lastEditedBy" : "c13f1277-0254-494b-8e7a-bd7c261b2e9f",
        "tags" : [
        ]
      }
    ],
    "commit" : "b2dbe9b6c9225267b7a3160e59be13530c7b7f52",
    "line" : 32,
    "diffHunk" : "@@ -1,1 +2459,2463 @@        \"\"\"\n        if not isinstance(colName, (str, list, tuple)):\n            raise TypeError(\"colName must be string or list/tuple of column names.\")\n        if not isinstance(col, (Column, list, tuple)):\n            raise TypeError(\"col must be a column or list/tuple of columns.\")"
  },
  {
    "id" : "bada8e78-8579-4d41-a934-b03aea0bab75",
    "prId" : 32276,
    "prUrl" : "https://github.com/apache/spark/pull/32276#pullrequestreview-641197434",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8aee84b2-e8a8-47dc-8ec1-c6926179983c",
        "parentId" : null,
        "authorId" : "c13f1277-0254-494b-8e7a-bd7c261b2e9f",
        "body" : "Notice that I use the `withColumns` in here which is a [private method](https://github.com/apache/spark/blob/b5241c97b17a1139a4ff719bfce7f68aef094d95/sql/core/src/main/scala/org/apache/spark/sql/Dataset.scala#L2402) in scala. The scala private [withColumns API](https://github.com/apache/spark/blob/b5241c97b17a1139a4ff719bfce7f68aef094d95/sql/core/src/main/scala/org/apache/spark/sql/Dataset.scala#L2396) can receive multiple columns now.",
        "createdAt" : "2021-04-21T14:55:21Z",
        "updatedAt" : "2021-04-22T02:01:50Z",
        "lastEditedBy" : "c13f1277-0254-494b-8e7a-bd7c261b2e9f",
        "tags" : [
        ]
      }
    ],
    "commit" : "b2dbe9b6c9225267b7a3160e59be13530c7b7f52",
    "line" : 45,
    "diffHunk" : "@@ -1,1 +2472,2476 @@\n        return DataFrame(\n            self._jdf.withColumns(_to_seq(self._sc, col_names), self._jcols(col)),\n            self.sql_ctx\n        )"
  },
  {
    "id" : "3163c8c3-d0e7-4215-8986-2f06781f33dd",
    "prId" : 32122,
    "prUrl" : "https://github.com/apache/spark/pull/32122#pullrequestreview-632974485",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3e1c2be6-d719-4aad-baca-fd414e8c4758",
        "parentId" : null,
        "authorId" : "c13f1277-0254-494b-8e7a-bd7c261b2e9f",
        "body" : "The scalar eventTime is also `str`\r\nhttps://github.com/apache/spark/blob/61d038f26e1beeeb39638fdf9703d2e86d058342/sql/core/src/main/scala/org/apache/spark/sql/Dataset.scala#L753\r\nand python implements is also validated as string\r\nhttps://github.com/apache/spark/blob/ff1fc5ed4b685b4f5f83d5f600b24f089dd4522e/python/pyspark/sql/dataframe.py#L608-L609\r\n\r\nbut wrong doc on the param and typehints",
        "createdAt" : "2021-04-11T05:41:45Z",
        "updatedAt" : "2021-04-12T12:01:34Z",
        "lastEditedBy" : "c13f1277-0254-494b-8e7a-bd7c261b2e9f",
        "tags" : [
        ]
      }
    ],
    "commit" : "a45bdbb9bf4137cc9028e973e7b042d5af40b792",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +589,593 @@        Parameters\n        ----------\n        eventTime : str\n            the name of the column that contains the event time of the row.\n        delayThreshold : str"
  },
  {
    "id" : "54acadb7-72bf-4e41-96c4-bfd163377f57",
    "prId" : 30181,
    "prUrl" : "https://github.com/apache/spark/pull/30181#pullrequestreview-520377841",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "24ed1ef7-66ea-4d29-813f-7461b2f6c38a",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Is this `versionchanged` put among parameters intentionally?",
        "createdAt" : "2020-10-30T01:11:39Z",
        "updatedAt" : "2020-11-03T00:49:21Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "6332c051-5ef2-43b0-83cb-e67a2ae68cef",
        "parentId" : "24ed1ef7-66ea-4d29-813f-7461b2f6c38a",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Yeah because it was the change into the specific parameter `col` (SPARK-25381). Looks like at least this is what pandas does.",
        "createdAt" : "2020-10-30T05:00:59Z",
        "updatedAt" : "2020-11-03T00:49:21Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "40bc04996ab651411656c08849b5ec0495cd8468",
    "line" : 791,
    "diffHunk" : "@@ -1,1 +1104,1108 @@\n            .. versionchanged:: 3.0\n               Added sampling by a column of :class:`Column`\n        fractions : dict\n            sampling fraction for each stratum. If a stratum is not"
  },
  {
    "id" : "eab09d52-823a-4aa5-aadb-49450d2aa66c",
    "prId" : 30181,
    "prUrl" : "https://github.com/apache/spark/pull/30181#pullrequestreview-520264562",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2a04a7ff-34df-4603-a629-935cf4dd0a8f",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : ":class:`Row`?",
        "createdAt" : "2020-10-30T01:16:05Z",
        "updatedAt" : "2020-11-03T00:49:21Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "40bc04996ab651411656c08849b5ec0495cd8468",
    "line" : 1132,
    "diffHunk" : "@@ -1,1 +1574,1578 @@        -------\n        If n is greater than 1, return a list of :class:`Row`.\n        If n is 1, return a single Row.\n\n        Examples"
  },
  {
    "id" : "aabf2cb3-9018-4e9f-b906-70be14f78a07",
    "prId" : 30181,
    "prUrl" : "https://github.com/apache/spark/pull/30181#pullrequestreview-520264562",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "41e16cd9-f232-453d-88e7-322865fe363f",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "`list` is removed?",
        "createdAt" : "2020-10-30T01:17:44Z",
        "updatedAt" : "2020-11-03T00:49:21Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      }
    ],
    "commit" : "40bc04996ab651411656c08849b5ec0495cd8468",
    "line" : 1473,
    "diffHunk" : "@@ -1,1 +2104,2108 @@            If the value is a dict, then `value` is ignored or can be omitted, and `to_replace`\n            must be a mapping between a value and a replacement.\n        value : bool, int, float, string or None, optional\n            The replacement value must be a bool, int, float, string or None. If `value` is a\n            list, `value` should be of the same length and type as `to_replace`."
  },
  {
    "id" : "3f07c91e-340d-4851-a6a0-9e0ba79f6cae",
    "prId" : 30060,
    "prUrl" : "https://github.com/apache/spark/pull/30060#pullrequestreview-509923390",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d381c93a-1275-4b80-8db6-ccb0aa54c41a",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Thank you for your contribution. Is this the last one? Could you check the other examples in this file, please?",
        "createdAt" : "2020-10-15T19:49:59Z",
        "updatedAt" : "2020-10-15T19:50:00Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "de403bd6-79fd-4904-9114-c544b89f489e",
        "parentId" : "d381c93a-1275-4b80-8db6-ccb0aa54c41a",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "cc @HyukjinKwon ",
        "createdAt" : "2020-10-15T19:50:19Z",
        "updatedAt" : "2020-10-15T19:50:20Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "9021f2dc-687d-4749-95ec-4a0bdb80834b",
        "parentId" : "d381c93a-1275-4b80-8db6-ccb0aa54c41a",
        "authorId" : "19f11a93-e55a-4dc1-a32c-961e80fbe837",
        "body" : "> Thank you for your contribution. Is this the last one? Could you check the other examples in this file, please?\r\n\r\nMy pleasure. This is the only instance in the current version branch.",
        "createdAt" : "2020-10-15T20:00:23Z",
        "updatedAt" : "2020-10-15T20:00:23Z",
        "lastEditedBy" : "19f11a93-e55a-4dc1-a32c-961e80fbe837",
        "tags" : [
        ]
      },
      {
        "id" : "259d05bb-307f-447b-84a3-feb583ebfd27",
        "parentId" : "d381c93a-1275-4b80-8db6-ccb0aa54c41a",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Thanks!",
        "createdAt" : "2020-10-16T00:22:16Z",
        "updatedAt" : "2020-10-16T00:22:17Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "1614635b4fe00ecd32a7c15181cd7d06d5190112",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +1515,1519 @@    def agg(self, *exprs):\n        \"\"\" Aggregate on the entire :class:`DataFrame` without groups\n        (shorthand for ``df.groupBy().agg()``).\n\n        >>> df.agg({\"age\": \"max\"}).collect()"
  },
  {
    "id" : "95679d59-bea7-49a4-8663-38d8f8654a01",
    "prId" : 29242,
    "prUrl" : "https://github.com/apache/spark/pull/29242#pullrequestreview-483254520",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9bcafb4a-7fff-47a7-a70a-687b59fca45e",
        "parentId" : null,
        "authorId" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "body" : "Now I see the confusion. In Scala, `MEMORY_AND_DISK` means `deserialized=true`, while in Python, `MEMORY_AND_DISK` means `deserialized=false`.",
        "createdAt" : "2020-09-07T05:44:53Z",
        "updatedAt" : "2020-09-08T13:56:44Z",
        "lastEditedBy" : "b1f2cebb-db23-4759-b446-886279d07e99",
        "tags" : [
        ]
      }
    ],
    "commit" : "ba3c2ef8a90dc21df08d59a40b23c33dfaae6920",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +679,683 @@\n    @since(1.3)\n    def persist(self, storageLevel=StorageLevel.MEMORY_AND_DISK_DESER):\n        \"\"\"Sets the storage level to persist the contents of the :class:`DataFrame` across\n        operations after the first time it is computed. This can only be used to assign"
  },
  {
    "id" : "4b6e8d51-cbee-4e2b-948f-5ee90de3f3ad",
    "prId" : 29214,
    "prUrl" : "https://github.com/apache/spark/pull/29214#pullrequestreview-454802408",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "96cfe229-b131-4ff5-aa4e-4661ba7373c8",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Can you update the migration guide at https://github.com/apache/spark/blob/master/docs/pyspark-migration-guide.md? You can create a new title \"Upgrading from PySpark 3.0 to 3.1\"",
        "createdAt" : "2020-07-24T05:54:31Z",
        "updatedAt" : "2020-07-24T11:05:35Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "b574b785-e48a-4a83-9dbb-437185828410",
        "parentId" : "96cfe229-b131-4ff5-aa4e-4661ba7373c8",
        "authorId" : "84d37f6c-0769-44e9-80b2-42fe4b57dce5",
        "body" : "done",
        "createdAt" : "2020-07-24T11:05:49Z",
        "updatedAt" : "2020-07-24T11:05:50Z",
        "lastEditedBy" : "84d37f6c-0769-44e9-80b2-42fe4b57dce5",
        "tags" : [
        ]
      }
    ],
    "commit" : "2a3be294950f9a59c61cd16f2e52e1c342e20f53",
    "line" : 15,
    "diffHunk" : "@@ -1,1 +1334,1338 @@        if n is None:\n            rs = self.head(1)\n            return rs[0] if rs else []\n        return self.take(n)\n"
  },
  {
    "id" : "7cfcad14-e9fe-41b9-bb5e-dcdb75a8db8c",
    "prId" : 28957,
    "prUrl" : "https://github.com/apache/spark/pull/28957#pullrequestreview-442361693",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "94c0e54a-f5ab-4abe-a06e-0af8293f6261",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "So this is also because of https://github.com/apache/spark/pull/28957/files#r449475633",
        "createdAt" : "2020-07-03T11:54:02Z",
        "updatedAt" : "2020-07-13T09:52:43Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "f2356c80a105c0b74e578152282013c1d3b9c647",
    "line" : 806,
    "diffHunk" : "@@ -1,1 +2336,2340 @@    globs['df5'] = sc.parallelize([Row(age=10, name='Alice', spy=False),\n                                   Row(age=5, name='Bob', spy=None),\n                                   Row(age=None, name='Mallory', spy=True)]).toDF()\n    globs['sdf'] = sc.parallelize([Row(name='Tom', time=1479441846),\n                                   Row(name='Bob', time=1479442946)]).toDF()"
  }
]