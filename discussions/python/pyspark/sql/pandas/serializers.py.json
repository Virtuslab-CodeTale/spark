[
  {
    "id" : "354f65e2-db1e-416c-8053-e04c03ca53a2",
    "prId" : 32026,
    "prUrl" : "https://github.com/apache/spark/pull/32026#pullrequestreview-626807546",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "2020e626-eb9b-4494-8ec6-b02f91eefab6",
        "parentId" : null,
        "authorId" : "f6398a50-7f9b-4c64-9d3a-f384404338b3",
        "body" : "mypy lint\r\n```\r\npython/pyspark/sql/pandas/serializers.py:23: error: Module 'pyspark.sql.types' has no attribute '_has_udt'\r\n```\r\nI think it is wrongly reported by mypy. I don't know how to make it happy.",
        "createdAt" : "2021-04-02T06:17:55Z",
        "updatedAt" : "2021-04-24T07:13:10Z",
        "lastEditedBy" : "f6398a50-7f9b-4c64-9d3a-f384404338b3",
        "tags" : [
        ]
      }
    ],
    "commit" : "5845ee2419515b9243ea4396005f731eb294b6a9",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +22,26 @@from pyspark.serializers import Serializer, read_int, write_int, UTF8Deserializer\nfrom pyspark.sql.types import DataType, UserDefinedType, StructType, \\\n    _has_udt\nfrom pyspark.sql.pandas.types import to_arrow_type, _serialize_pandas_with_udt\n"
  },
  {
    "id" : "ca4fc47b-3a51-4d4c-a6ab-b08233881049",
    "prId" : 29951,
    "prUrl" : "https://github.com/apache/spark/pull/29951#pullrequestreview-502639956",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "5d2925f6-c107-4ca4-b35c-499b82cdfdb9",
        "parentId" : null,
        "authorId" : "0c293c45-22a6-4358-8a40-adbf7c470575",
        "body" : "errors during safe conversion will be `ArrowInvalid`, which subclasses ValueError",
        "createdAt" : "2020-10-06T07:08:23Z",
        "updatedAt" : "2020-10-06T07:08:23Z",
        "lastEditedBy" : "0c293c45-22a6-4358-8a40-adbf7c470575",
        "tags" : [
        ]
      }
    ],
    "commit" : "e7a09e9dce49f6246957cb1965c26dbe846acbe8",
    "line" : 11,
    "diffHunk" : "@@ -1,1 +154,158 @@            try:\n                array = pa.Array.from_pandas(s, mask=mask, type=t, safe=self._safecheck)\n            except ValueError as e:\n                if self._safecheck:\n                    error_msg = \"Exception thrown when converting pandas.Series (%s) to \" + \\"
  },
  {
    "id" : "24168b92-6a19-42f1-87c7-6dc1df82213c",
    "prId" : 29951,
    "prUrl" : "https://github.com/apache/spark/pull/29951#pullrequestreview-503441125",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9b9d3f62-3872-403b-adce-0de01e8eadd1",
        "parentId" : null,
        "authorId" : "0c293c45-22a6-4358-8a40-adbf7c470575",
        "body" : "Now that we dropped Python 2, this seems more appropriate",
        "createdAt" : "2020-10-06T07:08:26Z",
        "updatedAt" : "2020-10-06T07:08:27Z",
        "lastEditedBy" : "0c293c45-22a6-4358-8a40-adbf7c470575",
        "tags" : [
        ]
      },
      {
        "id" : "17c86eaa-3a0e-4737-b7a5-035d0750bbad",
        "parentId" : "9b9d3f62-3872-403b-adce-0de01e8eadd1",
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "In `branch-3.0`.\r\n\r\n```\r\n  File \"/home/jenkins/workspace/spark-branch-3.0-test-sbt-hadoop-2.7-hive-1.2/python/pyspark/sql/pandas/serializers.py\", line 166\r\n    raise ValueError(error_msg % (s.dtype, t)) from e\r\n                                              ^\r\nSyntaxError: invalid syntax\r\n```",
        "createdAt" : "2020-10-07T00:07:32Z",
        "updatedAt" : "2020-10-07T00:07:32Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      }
    ],
    "commit" : "e7a09e9dce49f6246957cb1965c26dbe846acbe8",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +161,165 @@                                \"can be disabled by using SQL config \" + \\\n                                \"`spark.sql.execution.pandas.convertToArrowArraySafely`.\"\n                    raise ValueError(error_msg % (s.dtype, t)) from e\n                else:\n                    raise e"
  }
]