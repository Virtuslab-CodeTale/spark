[
  {
    "id" : "7fe1ce77-b0d7-469c-a1dc-0471705513b5",
    "prId" : 33440,
    "prUrl" : "https://github.com/apache/spark/pull/33440#pullrequestreview-710581012",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a722c135-bf8b-494d-b64b-d61066a64fc3",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "This is fine, but do we do it consistently? if that would be a big change, I wonder how much it's worth it",
        "createdAt" : "2021-07-20T13:04:47Z",
        "updatedAt" : "2021-07-20T13:04:51Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "f084d5e7-3cbe-4cc8-9f41-f75c3b20e1fd",
        "parentId" : "a722c135-bf8b-494d-b64b-d61066a64fc3",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Yeah, I agree.",
        "createdAt" : "2021-07-20T13:12:48Z",
        "updatedAt" : "2021-07-20T13:12:48Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "7717864b-47bb-4598-908a-42a99ff6a788",
        "parentId" : "a722c135-bf8b-494d-b64b-d61066a64fc3",
        "authorId" : "a11dba3f-db3a-4777-869c-d3d9569e1a25",
        "body" : "It seems to be already done in most classes below sql .. these were just a couple of exceptions I noticed",
        "createdAt" : "2021-07-20T13:28:39Z",
        "updatedAt" : "2021-07-20T13:28:39Z",
        "lastEditedBy" : "a11dba3f-db3a-4777-869c-d3d9569e1a25",
        "tags" : [
        ]
      },
      {
        "id" : "6ccd4443-61c9-4395-b522-7a493b56e47f",
        "parentId" : "a722c135-bf8b-494d-b64b-d61066a64fc3",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "If these are all of them, I think it's good to go.",
        "createdAt" : "2021-07-20T13:30:53Z",
        "updatedAt" : "2021-07-20T13:30:54Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "7bcb8e7e90ba3cf4f239fb48113bd5d3eb803a86",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +74,78 @@    A SparkSession can be used create :class:`DataFrame`, register :class:`DataFrame` as\n    tables, execute SQL over tables, cache tables, and read parquet files.\n    To create a :class:`SparkSession`, use the following builder pattern:\n\n    .. autoattribute:: builder"
  },
  {
    "id" : "3016e73d-e569-4828-ac09-1ddeb036bbaa",
    "prId" : 30042,
    "prUrl" : "https://github.com/apache/spark/pull/30042#pullrequestreview-510189348",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "a6173cc7-3831-4ab7-9791-a4d99a4f7e67",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Hey, you don't need to manually reflect here. package level private accessor is already accessible in Java as you did so you can just mimic it here via `getattr(getattr(spark._jvm, \"SparkSession$\"), \"MODULE$\").setActiveSessionInternal`(...).",
        "createdAt" : "2020-10-16T06:31:24Z",
        "updatedAt" : "2020-10-16T06:31:24Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "d4368e6a-2ef3-4e97-b6c7-bd9a35cf5241",
        "parentId" : "a6173cc7-3831-4ab7-9791-a4d99a4f7e67",
        "authorId" : "cce1c782-0596-44b6-8b99-6b77d2cca53c",
        "body" : "OK, I will test and update in next PR, thanks @HyukjinKwon ",
        "createdAt" : "2020-10-16T06:33:19Z",
        "updatedAt" : "2020-10-16T06:33:19Z",
        "lastEditedBy" : "cce1c782-0596-44b6-8b99-6b77d2cca53c",
        "tags" : [
        ]
      },
      {
        "id" : "d3b68151-ca12-443d-a916-b0b6004e5bef",
        "parentId" : "a6173cc7-3831-4ab7-9791-a4d99a4f7e67",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Thanks, please go ahead for a followup.",
        "createdAt" : "2020-10-16T06:35:55Z",
        "updatedAt" : "2020-10-16T06:35:56Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "aa7bf5b50c4388e6caa24826d1bc83572af60e5a",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +234,238 @@                .getDeclaredField(\"MODULE$\")\\\n                .get(None)\\\n                .setActiveSessionInternal(self._jsparkSession)\n\n    def _repr_html_(self):"
  },
  {
    "id" : "5ab35c3b-4a12-464e-a483-447482096ca6",
    "prId" : 30042,
    "prUrl" : "https://github.com/apache/spark/pull/30042#pullrequestreview-510188239",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "775aa08d-09fc-4618-b235-8fe497d2d4b5",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "`Class.forName` should better not directly used. This is banned by Scala style:\r\n\r\nhttps://github.com/apache/spark/blob/e93b8f02cd706bedc47c9b55a73f632fe9e61ec3/scalastyle-config.xml#L197-L206",
        "createdAt" : "2020-10-16T06:33:23Z",
        "updatedAt" : "2020-10-16T06:33:23Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "aa7bf5b50c4388e6caa24826d1bc83572af60e5a",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +231,235 @@            SparkSession._activeSession = self\n            self._jvm.SparkSession.setDefaultSession(self._jsparkSession)\n            self._jvm.java.lang.Class.forName(\"org.apache.spark.sql.SparkSession$\")\\\n                .getDeclaredField(\"MODULE$\")\\\n                .get(None)\\"
  },
  {
    "id" : "8a76550b-19e3-4609-b8b8-f4f5712a1910",
    "prId" : 29510,
    "prUrl" : "https://github.com/apache/spark/pull/29510#pullrequestreview-473598817",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "30ad1e58-7f17-4e49-b3d8-fceb895f7029",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Let's also remove the one below:\r\n\r\n```python\r\n        if type(first) is dict:\r\n            warnings.warn(\"Using RDD of dict to inferSchema is deprecated. \"\r\n                          \"Use pyspark.sql.Row instead\")\r\n```",
        "createdAt" : "2020-08-22T00:52:54Z",
        "updatedAt" : "2020-08-24T17:55:29Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "754e0f67-2067-4821-88bf-1cdf414f6d00",
        "parentId" : "30ad1e58-7f17-4e49-b3d8-fceb895f7029",
        "authorId" : "fd6ebc48-7da4-490b-8d41-2e8530d92720",
        "body" : "Whoops, good catch.",
        "createdAt" : "2020-08-24T15:12:42Z",
        "updatedAt" : "2020-08-24T17:55:29Z",
        "lastEditedBy" : "fd6ebc48-7da4-490b-8d41-2e8530d92720",
        "tags" : [
        ]
      }
    ],
    "commit" : "5136829a12ef4762f70feaf8c22561fed36660d5",
    "line" : 20,
    "diffHunk" : "@@ -1,1 +370,374 @@        schema = reduce(_merge_type, (_infer_schema(row, names) for row in data))\n        if _has_nulltype(schema):\n            raise ValueError(\"Some of types cannot be determined after inferring\")\n        return schema\n"
  },
  {
    "id" : "8b3b1530-7019-4863-96e3-fc7b3d3ac3e1",
    "prId" : 29180,
    "prUrl" : "https://github.com/apache/spark/pull/29180#pullrequestreview-497025722",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "ffd8532d-cfa3-424e-8c87-ea1153502ab9",
        "parentId" : null,
        "authorId" : "981b170c-729a-429c-b115-0350ea50b32b",
        "body" : "I believe we can skip this one.",
        "createdAt" : "2020-09-26T19:32:05Z",
        "updatedAt" : "2020-09-26T19:47:56Z",
        "lastEditedBy" : "981b170c-729a-429c-b115-0350ea50b32b",
        "tags" : [
        ]
      }
    ],
    "commit" : "2af1250e02b6debdf31409f2a356a1aa3dbee7d9",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +77,81 @@\n        _lock = RLock()\n        _options = {}  # type: ignore\n        _sc = None\n"
  }
]