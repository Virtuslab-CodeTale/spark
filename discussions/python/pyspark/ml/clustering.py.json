[
  {
    "id" : "9fc5fe72-841e-450d-b59c-157b3b00ff28",
    "prId" : 28595,
    "prUrl" : "https://github.com/apache/spark/pull/28595#pullrequestreview-417832488",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1c971741-1425-4f8e-a9b3-68b88f5dc42e",
        "parentId" : null,
        "authorId" : "39fe625f-8c54-48bc-ac6f-7279921adf02",
        "body" : "need more meaningful name instead of short name: HasK. say, HasNumClusters?",
        "createdAt" : "2020-05-25T15:27:20Z",
        "updatedAt" : "2020-05-25T19:40:04Z",
        "lastEditedBy" : "39fe625f-8c54-48bc-ac6f-7279921adf02",
        "tags" : [
        ]
      },
      {
        "id" : "a6f0b278-cc2d-476f-ae83-bc68ce42aa5e",
        "parentId" : "1c971741-1425-4f8e-a9b3-68b88f5dc42e",
        "authorId" : "99765afe-8dbe-4d5f-9ad3-d5bc40f0462b",
        "body" : "Thanks for your comment.  Unfortunately we can't change to ```HasNumOfClusters``` because  ```k``` /```getK```/```setK``` were used in the previous releases. ",
        "createdAt" : "2020-05-25T18:06:39Z",
        "updatedAt" : "2020-05-25T18:06:39Z",
        "lastEditedBy" : "99765afe-8dbe-4d5f-9ad3-d5bc40f0462b",
        "tags" : [
        ]
      }
    ],
    "commit" : "2d6e87b1892683b6035bfdf6ed8c475bada5bbc8",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +100,104 @@class _GaussianMixtureParams(HasMaxIter, HasFeaturesCol, HasSeed, HasPredictionCol,\n                             HasProbabilityCol, HasTol, HasAggregationDepth, HasWeightCol,\n                             HasBlockSize, HasK):\n    \"\"\"\n    Params for :py:class:`GaussianMixture` and :py:class:`GaussianMixtureModel`."
  },
  {
    "id" : "2109acc1-03bd-41fa-9e18-7b102504e875",
    "prId" : 27519,
    "prUrl" : "https://github.com/apache/spark/pull/27519#pullrequestreview-367001416",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e8cb3bf7-b28a-4309-a836-6a702303d558",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "This seems kind of unlikely, as probabilities? is this valid?",
        "createdAt" : "2020-02-28T20:11:48Z",
        "updatedAt" : "2020-03-03T08:08:02Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "0531afc7-f6b1-4e17-9a4e-b8626e954ce3",
        "parentId" : "e8cb3bf7-b28a-4309-a836-6a702303d558",
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "I had checked it in master, and when maxIter is set to 30, then the model also output `DenseVector([0.0, 0.0, 1.0])`",
        "createdAt" : "2020-03-02T07:49:52Z",
        "updatedAt" : "2020-03-03T08:08:02Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      },
      {
        "id" : "eeb567b1-c349-4740-bce2-8396e441fc5e",
        "parentId" : "e8cb3bf7-b28a-4309-a836-6a702303d558",
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "![image](https://user-images.githubusercontent.com/7322292/75656008-01064e00-5c9e-11ea-945c-2c95daf1de2c.png)\r\n\r\nThe result in `model.transform(df).show()` are not `DenseVector([0.0, 0.0, 1.0])`, it is about `[6.74824658670777...`;\r\n\r\nbut the `model.transform(df).head()` shows `DenseVector([0.0, 0.0, 1.0])`.\r\n\r\nIs this a kind of rounding in `Vector.toString`?\r\n\r\n![image](https://user-images.githubusercontent.com/7322292/75656394-cc46c680-5c9e-11ea-8b0a-a83b4527bf0e.png)\r\n",
        "createdAt" : "2020-03-02T07:55:38Z",
        "updatedAt" : "2020-03-03T08:08:02Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      }
    ],
    "commit" : "936e8bfe02ee5119471c47194a5a3597f271fb06",
    "line" : 18,
    "diffHunk" : "@@ -1,1 +253,257 @@    2\n    >>> model.predictProbability(df.head().features)\n    DenseVector([0.0, 0.0, 1.0])\n    >>> model.hasSummary\n    True"
  },
  {
    "id" : "4c6278e8-a465-4e10-bb05-634bbfdc2ed4",
    "prId" : 27519,
    "prUrl" : "https://github.com/apache/spark/pull/27519#pullrequestreview-366998756",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "330ca62f-60ba-43eb-bf3b-84bc2fed06ed",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Same question, I just wonder why the answer changes so significantly?",
        "createdAt" : "2020-02-28T20:12:35Z",
        "updatedAt" : "2020-03-03T08:08:02Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      },
      {
        "id" : "d3c2f140-38a0-457e-923d-9c4379b7d09d",
        "parentId" : "330ca62f-60ba-43eb-bf3b-84bc2fed06ed",
        "authorId" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "body" : "Since the maxIter was changed from 10 to 30, the model coefficients are different.\r\nI had checked the model coefficients of both master and this PR with maxIter=30, they are the same. But they are different from coefficients at iteration=10;",
        "createdAt" : "2020-03-02T07:49:04Z",
        "updatedAt" : "2020-03-03T08:08:02Z",
        "lastEditedBy" : "685f805b-e4fa-4f21-b066-58afcecf9ce6",
        "tags" : [
        ]
      }
    ],
    "commit" : "936e8bfe02ee5119471c47194a5a3597f271fb06",
    "line" : 55,
    "diffHunk" : "@@ -1,1 +280,284 @@    DenseVector([-0.055, -0.075])\n    >>> gaussians[2].cov\n    DenseMatrix(2, 2, [0.002, -0.0011, -0.0011, 0.0006], 0)\n    >>> model.gaussiansDF.select(\"mean\").head()\n    Row(mean=DenseVector([0.825, 0.8675]))"
  },
  {
    "id" : "21129e06-d387-4c86-a42e-d4ace8c0113f",
    "prId" : 26232,
    "prUrl" : "https://github.com/apache/spark/pull/26232#pullrequestreview-342027479",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "d3b53288-0fef-4d35-90b7-5edf3aa790dd",
        "parentId" : null,
        "authorId" : "981b170c-729a-429c-b115-0350ea50b32b",
        "body" : "If anything, shouldn't we have model specific dosctring here?  This one just duplicates what we already have in estimator:\r\n\r\nhttps://github.com/apache/spark/blob/b389b8c5f0650a7e63098f18437fcaa29998732a/python/pyspark/ml/clustering.py#L1159-L1160",
        "createdAt" : "2020-01-13T16:11:18Z",
        "updatedAt" : "2020-01-13T16:11:19Z",
        "lastEditedBy" : "981b170c-729a-429c-b115-0350ea50b32b",
        "tags" : [
        ]
      },
      {
        "id" : "6ee7344d-39b0-46d5-9ffc-f3b6168aee9c",
        "parentId" : "d3b53288-0fef-4d35-90b7-5edf3aa790dd",
        "authorId" : "99765afe-8dbe-4d5f-9ad3-d5bc40f0462b",
        "body" : "I am in the middle of rechecking this PR and other ml parity PRs. I will have a follow up PR soon to fix this along with a few other problems I found. ",
        "createdAt" : "2020-01-13T16:41:40Z",
        "updatedAt" : "2020-01-13T16:41:41Z",
        "lastEditedBy" : "99765afe-8dbe-4d5f-9ad3-d5bc40f0462b",
        "tags" : [
        ]
      },
      {
        "id" : "89344d00-2305-4016-ade4-1048b113804c",
        "parentId" : "d3b53288-0fef-4d35-90b7-5edf3aa790dd",
        "authorId" : "981b170c-729a-429c-b115-0350ea50b32b",
        "body" : "Thanks @huaxingao. If you don't mind me asking â€’ should I expect any serious shifts? \r\n\r\n(I am [in the middle](https://github.com/zero323/pyspark-stubs/tree/SPARK-29093) of handling annotations for this, and it might be useful to know what to expect)",
        "createdAt" : "2020-01-13T17:11:21Z",
        "updatedAt" : "2020-01-13T17:16:19Z",
        "lastEditedBy" : "981b170c-729a-429c-b115-0350ea50b32b",
        "tags" : [
        ]
      },
      {
        "id" : "5840697e-9747-4a95-9885-569c5d9b96a9",
        "parentId" : "d3b53288-0fef-4d35-90b7-5edf3aa790dd",
        "authorId" : "99765afe-8dbe-4d5f-9ad3-d5bc40f0462b",
        "body" : "No. Just fix the small things I overlooked before, for example, I have setters in ```TrainValidationSplitModel/CrossValidatorModel``` because these setters are used  in ```_from_java```.  I will remove the setters and use _set instead.",
        "createdAt" : "2020-01-13T17:26:45Z",
        "updatedAt" : "2020-01-13T17:26:45Z",
        "lastEditedBy" : "99765afe-8dbe-4d5f-9ad3-d5bc40f0462b",
        "tags" : [
        ]
      },
      {
        "id" : "9a5cec87-6fc5-4bf6-a8db-e646c2330796",
        "parentId" : "d3b53288-0fef-4d35-90b7-5edf3aa790dd",
        "authorId" : "981b170c-729a-429c-b115-0350ea50b32b",
        "body" : "Thanks @huaxingao.",
        "createdAt" : "2020-01-13T17:54:13Z",
        "updatedAt" : "2020-01-13T17:54:14Z",
        "lastEditedBy" : "981b170c-729a-429c-b115-0350ea50b32b",
        "tags" : [
        ]
      }
    ],
    "commit" : "03c2e4a6c7581402de0c1067c31f5655d9992364",
    "line" : 268,
    "diffHunk" : "@@ -1,1 +1069,1073 @@        Sets the value of :py:attr:`topicDistributionCol`.\n\n        >>> algo = LDA().setTopicDistributionCol(\"topicDistributionCol\")\n        >>> algo.getTopicDistributionCol()\n        'topicDistributionCol'"
  }
]