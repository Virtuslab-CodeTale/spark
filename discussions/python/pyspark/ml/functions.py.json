[
  {
    "id" : "696ab701-9290-41de-901c-42b2126d7bf0",
    "prId" : 27522,
    "prUrl" : "https://github.com/apache/spark/pull/27522#pullrequestreview-357412385",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "237e7e88-5335-4616-948d-20df3df26b49",
        "parentId" : null,
        "authorId" : "7e665d8b-d739-4edf-88c8-7379ff8585c2",
        "body" : "Add doc for params and return type.",
        "createdAt" : "2020-02-12T12:28:13Z",
        "updatedAt" : "2020-02-13T09:06:46Z",
        "lastEditedBy" : "7e665d8b-d739-4edf-88c8-7379ff8585c2",
        "tags" : [
        ]
      }
    ],
    "commit" : "848220d8a892e08e6bc99f5b6293b3c57dd892c4",
    "line" : 9,
    "diffHunk" : "@@ -1,1 +23,27 @@def vector_to_array(col, dtype=\"float64\"):\n    \"\"\"\n    Converts a column of MLlib sparse/dense vectors into a column of dense arrays.\n    :param col: A string of the column name or a Column\n    :param dtype: The data type of the output array. Valid values: \"float64\" or \"float32\"."
  },
  {
    "id" : "cdc11e71-e155-422f-986d-02058eead794",
    "prId" : 26910,
    "prUrl" : "https://github.com/apache/spark/pull/26910#pullrequestreview-333677509",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "8fe1a1f6-20ec-4ccf-bf05-ebe8ac64aa2f",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Is this file documented in PySpark API? I think we should add this module into `spark/python/docs/pyspark.ml.rst`",
        "createdAt" : "2019-12-18T01:06:14Z",
        "updatedAt" : "2019-12-21T03:51:28Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "d257dce703986e4ed325af0bae07c88a467a684e",
    "line" : 1,
    "diffHunk" : "@@ -1,1 +-1,3 @@#\n# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with"
  },
  {
    "id" : "fc962694-f823-4518-b24f-7eed97f55254",
    "prId" : 26910,
    "prUrl" : "https://github.com/apache/spark/pull/26910#pullrequestreview-333810641",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "419b153e-8447-43a6-8ad9-687d273ed905",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "I think you should run the doctests:\r\n\r\n```python\r\ndef _test():\r\n    import doctest\r\n    import pyspark.ml.functions\r\n    globs = pyspark.ml.functions.__dict__.copy()\r\n    spark = SparkSession.builder\\\r\n        .master(\"local[2]\")\\\r\n        .appName(\"ml.functions tests\")\\\r\n        .getOrCreate()\r\n    globs['spark'] = spark\r\n\r\n    (failure_count, test_count) = doctest.testmod(pyspark.ml.functions, globs=globs)\r\n    spark.stop()\r\n    if failure_count:\r\n        sys.exit(-1)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    _test()\r\n```",
        "createdAt" : "2019-12-18T01:10:45Z",
        "updatedAt" : "2019-12-21T03:51:28Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "45ffa4a9-cd41-4112-b302-68e2a5da2676",
        "parentId" : "419b153e-8447-43a6-8ad9-687d273ed905",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "@WeichenXu123, this seems missed. Otherwise it won't run the doctests in Jenkins.",
        "createdAt" : "2019-12-18T08:49:29Z",
        "updatedAt" : "2019-12-21T03:51:28Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "d257dce703986e4ed325af0bae07c88a467a684e",
    "line" : 42,
    "diffHunk" : "@@ -1,1 +40,44 @@    sc = SparkContext._active_spark_context\n    return Column(\n        sc._jvm.org.apache.spark.ml.functions.vector_to_array(_to_java_column(col)))\n\n"
  },
  {
    "id" : "6bbb2213-d772-4738-b7dc-fa29d76f1d80",
    "prId" : 26910,
    "prUrl" : "https://github.com/apache/spark/pull/26910#pullrequestreview-333679089",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "56e27721-e616-45ac-a48a-50a027627edf",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "and add the module to `pyspark_mllib` at `spark/dev/sparktestsupport/modules.py` so we run the tests in Jenkins.",
        "createdAt" : "2019-12-18T01:11:36Z",
        "updatedAt" : "2019-12-21T03:51:28Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "d257dce703986e4ed325af0bae07c88a467a684e",
    "line" : 42,
    "diffHunk" : "@@ -1,1 +40,44 @@    sc = SparkContext._active_spark_context\n    return Column(\n        sc._jvm.org.apache.spark.ml.functions.vector_to_array(_to_java_column(col)))\n\n"
  }
]