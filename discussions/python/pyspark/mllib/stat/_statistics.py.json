[
  {
    "id" : "ef826c8c-febd-409a-99d6-86ed779393aa",
    "prId" : 30413,
    "prUrl" : "https://github.com/apache/spark/pull/30413#pullrequestreview-537836355",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "46e00643-12b5-4321-a1e6-c479c0886e40",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "`RDD[Vector]` looks Scala syntax? How about RDD of Vector?",
        "createdAt" : "2020-11-24T17:57:58Z",
        "updatedAt" : "2020-11-25T00:00:49Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "114d0402-7978-4302-ba81-4e0c3232ecf7",
        "parentId" : "46e00643-12b5-4321-a1e6-c479c0886e40",
        "authorId" : "981b170c-729a-429c-b115-0350ea50b32b",
        "body" : "Conveniently, that's syntax we use both for Scala and Python, with corresponding type hints looking like this:\r\n\r\nhttps://github.com/apache/spark/blob/048a9821c788b6796d52d1e2a0cd174377ebd0f0/python/pyspark/mllib/stat/_statistics.pyi#L44",
        "createdAt" : "2020-11-24T19:26:22Z",
        "updatedAt" : "2020-11-25T00:00:49Z",
        "lastEditedBy" : "981b170c-729a-429c-b115-0350ea50b32b",
        "tags" : [
        ]
      }
    ],
    "commit" : "eca86aa9c490cc359643fb95a93d9fb61999e17f",
    "line" : 12,
    "diffHunk" : "@@ -1,1 +69,73 @@        ----------\n        rdd : :py:class:`pyspark.RDD`\n            an RDD[Vector] for which column-wise summary statistics\n            are to be computed.\n"
  }
]