[
  {
    "id" : "df8133b3-99db-4318-a311-3e6b5d85b71e",
    "prId" : 30266,
    "prUrl" : "https://github.com/apache/spark/pull/30266#pullrequestreview-525026383",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1fa2e16b-7072-4bef-929d-f594b2147231",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Can you update shell.R too for SparkR?",
        "createdAt" : "2020-11-06T03:49:11Z",
        "updatedAt" : "2020-11-09T14:34:53Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "fe9e48ec-e991-430c-b086-4436f01c9f53",
        "parentId" : "1fa2e16b-7072-4bef-929d-f594b2147231",
        "authorId" : "b81be73a-4737-4677-82f4-098034b8df5d",
        "body" : "@HyukjinKwon I have done `shell.R` and manual test result has been update above, please review it when you are free",
        "createdAt" : "2020-11-06T10:23:54Z",
        "updatedAt" : "2020-11-09T14:34:53Z",
        "lastEditedBy" : "b81be73a-4737-4677-82f4-098034b8df5d",
        "tags" : [
        ]
      }
    ],
    "commit" : "9742ad9b855eaf0a71d927e751b7367a7173bc73",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +64,68 @@    platform.python_build()[1]))\nprint(\"Spark context Web UI available at %s\" % (sc.uiWebUrl))\nprint(\"Spark context available as 'sc' (master = %s, app id = %s).\" % (sc.master, sc.applicationId))\nprint(\"SparkSession available as 'spark'.\")\n"
  },
  {
    "id" : "dc14541e-c3fa-447d-a042-c4c426ce05ed",
    "prId" : 25489,
    "prUrl" : "https://github.com/apache/spark/pull/25489#pullrequestreview-277444362",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c5aaf928-7105-4b68-8214-3442f0d48d27",
        "parentId" : null,
        "authorId" : "85145f22-5f6d-4316-99b9-b83a848a0bd3",
        "body" : "This is worth calling out as a significant change, as it means C and col would automatically be imported into the REPL.  Makes sense to do this because col is by far the most commonly used function in all of pyspark and it increases user-friendliness.",
        "createdAt" : "2019-08-20T21:14:17Z",
        "updatedAt" : "2019-08-20T21:14:17Z",
        "lastEditedBy" : "85145f22-5f6d-4316-99b9-b83a848a0bd3",
        "tags" : [
        ]
      }
    ],
    "commit" : "207bd03c7d382d00986dc6ed8cef41344a225040",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +32,36 @@from pyspark.context import SparkContext\nfrom pyspark.sql import SparkSession, SQLContext\nfrom pyspark.sql.functions import C, col\n\nif os.environ.get(\"SPARK_EXECUTOR_URI\"):"
  }
]