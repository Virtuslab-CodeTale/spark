[
  {
    "id" : "109fc6bc-755d-4dce-86e2-56183c98f484",
    "prId" : 32386,
    "prUrl" : "https://github.com/apache/spark/pull/32386#pullrequestreview-649410437",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1ba6e337-9298-486c-8b1c-659df671b1af",
        "parentId" : null,
        "authorId" : "c13f1277-0254-494b-8e7a-bd7c261b2e9f",
        "body" : "nit: pyarrow minimun version is introduced in _minimum_pyarrow_version, but if we introduce the `pyarrow>=0.10` for pandas_on_spark in here, maybe we could change the `_minimum_pyarrow_version` to something like `_minimum_sql_pyarrow_version`\r\n\r\n[1] https://github.com/apache/spark/pull/32386/files#diff-eb8b42d9346d0a5d371facf21a8bfa2d16fb49e213ae7c21f03863accebe0fcfR115",
        "createdAt" : "2021-04-29T02:28:28Z",
        "updatedAt" : "2021-04-30T17:05:43Z",
        "lastEditedBy" : "c13f1277-0254-494b-8e7a-bd7c261b2e9f",
        "tags" : [
        ]
      },
      {
        "id" : "7031eb8b-ae02-4e8b-b3ca-650dd7827eb4",
        "parentId" : "1ba6e337-9298-486c-8b1c-659df671b1af",
        "authorId" : "8194e9fe-1d06-4199-937e-9633d15a18cb",
        "body" : "Good catch! There is only one usage of `_minimum_pyarrow_version`. How about removing the variable and using the value instead?",
        "createdAt" : "2021-04-29T16:59:56Z",
        "updatedAt" : "2021-04-30T17:05:43Z",
        "lastEditedBy" : "8194e9fe-1d06-4199-937e-9633d15a18cb",
        "tags" : [
        ]
      },
      {
        "id" : "23057971-f905-47bf-ae99-a43d0e385204",
        "parentId" : "1ba6e337-9298-486c-8b1c-659df671b1af",
        "authorId" : "c13f1277-0254-494b-8e7a-bd7c261b2e9f",
        "body" : "If we can use the same lower bound, I prefer just use `_minimum_pyarrow_version` directly as suggestion in  https://github.com/apache/spark/pull/32386#discussion_r623528856\r\n\r\n```python\r\n'pandas_on_spark': [\r\n    'pandas>=%s' % _minimum_pandas_version,\r\n    'pyarrow>=%s', % _minimum_pyarrow_version,\r\n]\r\n```",
        "createdAt" : "2021-04-30T01:49:02Z",
        "updatedAt" : "2021-04-30T17:05:43Z",
        "lastEditedBy" : "c13f1277-0254-494b-8e7a-bd7c261b2e9f",
        "tags" : [
        ]
      },
      {
        "id" : "03a6a754-d014-4531-bc68-9aa247875c0a",
        "parentId" : "1ba6e337-9298-486c-8b1c-659df671b1af",
        "authorId" : "8194e9fe-1d06-4199-937e-9633d15a18cb",
        "body" : "Sounds good.",
        "createdAt" : "2021-04-30T16:58:13Z",
        "updatedAt" : "2021-04-30T17:05:43Z",
        "lastEditedBy" : "8194e9fe-1d06-4199-937e-9633d15a18cb",
        "tags" : [
        ]
      }
    ],
    "commit" : "f8a08202ea7b5478a31e61468c6f83c24cb3e77c",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +264,268 @@            'sql': [\n                'pandas>=%s' % _minimum_pandas_version,\n                'pyarrow>=%s' % _minimum_pyarrow_version,\n            ],\n            'pandas_on_spark': ["
  },
  {
    "id" : "279b3d9b-1288-4bb1-86f0-5d117aec63d7",
    "prId" : 31028,
    "prUrl" : "https://github.com/apache/spark/pull/31028#pullrequestreview-561579394",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "79f8c4f9-2239-4e29-9da0-c067c3bba805",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Why also change SPARK_VERSION -> PYSPARK_VERSION here? Is it related to PYSPARK_HADOOP_VERSION?",
        "createdAt" : "2021-01-05T07:55:01Z",
        "updatedAt" : "2021-01-05T07:55:01Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "3ef24d04-b71c-4ab4-881a-89e34a068f62",
        "parentId" : "79f8c4f9-2239-4e29-9da0-c067c3bba805",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "`SPARK_VERSION` is just for testing purpose and I just simply thought it's good to make it consistent ;-).. the env `SPARK_VERSION` can be likely conflicted with something else anyway.",
        "createdAt" : "2021-01-05T07:57:36Z",
        "updatedAt" : "2021-01-05T07:57:37Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "e1624f56-595d-44b6-946c-6d24b77a5bdb",
        "parentId" : "79f8c4f9-2239-4e29-9da0-c067c3bba805",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "As we use variable names `spark_version` in many places, is it good to change to `PYSPARK_VERSION` here?",
        "createdAt" : "2021-01-05T07:58:08Z",
        "updatedAt" : "2021-01-05T07:58:08Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "52ab4b9f-7731-4068-b5ed-99913c63af15",
        "parentId" : "79f8c4f9-2239-4e29-9da0-c067c3bba805",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Oh, okay.",
        "createdAt" : "2021-01-05T07:59:17Z",
        "updatedAt" : "2021-01-05T07:59:17Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "ae79179a-b499-4089-beaa-9049b771d098",
        "parentId" : "79f8c4f9-2239-4e29-9da0-c067c3bba805",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "I think it's okay. It's same for `hadoop_version` and `hive_version` too. I don't mind changing it back if you feel strongly. This is just for internal and testing purpose.",
        "createdAt" : "2021-01-05T08:01:07Z",
        "updatedAt" : "2021-01-05T08:01:08Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "e764a7a3da81a8dda6510869bc4711d831edbbd3",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +127,131 @@\n        if (\"PYSPARK_HADOOP_VERSION\" in os.environ) or (\"PYSPARK_HIVE_VERSION\" in os.environ):\n            # Note that PYSPARK_VERSION environment is just a testing purpose.\n            # PYSPARK_HIVE_VERSION environment variable is also internal for now in case\n            # we support another version of Hive in the future."
  }
]