[
  {
    "id" : "109fc6bc-755d-4dce-86e2-56183c98f484",
    "prId" : 32386,
    "prUrl" : "https://github.com/apache/spark/pull/32386#pullrequestreview-649410437",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "1ba6e337-9298-486c-8b1c-659df671b1af",
        "parentId" : null,
        "authorId" : "c13f1277-0254-494b-8e7a-bd7c261b2e9f",
        "body" : "nit: pyarrow minimun version is introduced in _minimum_pyarrow_version, but if we introduce the `pyarrow>=0.10` for pandas_on_spark in here, maybe we could change the `_minimum_pyarrow_version` to something like `_minimum_sql_pyarrow_version`\r\n\r\n[1] https://github.com/apache/spark/pull/32386/files#diff-eb8b42d9346d0a5d371facf21a8bfa2d16fb49e213ae7c21f03863accebe0fcfR115",
        "createdAt" : "2021-04-29T02:28:28Z",
        "updatedAt" : "2021-04-30T17:05:43Z",
        "lastEditedBy" : "c13f1277-0254-494b-8e7a-bd7c261b2e9f",
        "tags" : [
        ]
      },
      {
        "id" : "7031eb8b-ae02-4e8b-b3ca-650dd7827eb4",
        "parentId" : "1ba6e337-9298-486c-8b1c-659df671b1af",
        "authorId" : "8194e9fe-1d06-4199-937e-9633d15a18cb",
        "body" : "Good catch! There is only one usage of `_minimum_pyarrow_version`. How about removing the variable and using the value instead?",
        "createdAt" : "2021-04-29T16:59:56Z",
        "updatedAt" : "2021-04-30T17:05:43Z",
        "lastEditedBy" : "8194e9fe-1d06-4199-937e-9633d15a18cb",
        "tags" : [
        ]
      },
      {
        "id" : "23057971-f905-47bf-ae99-a43d0e385204",
        "parentId" : "1ba6e337-9298-486c-8b1c-659df671b1af",
        "authorId" : "c13f1277-0254-494b-8e7a-bd7c261b2e9f",
        "body" : "If we can use the same lower bound, I prefer just use `_minimum_pyarrow_version` directly as suggestion in  https://github.com/apache/spark/pull/32386#discussion_r623528856\r\n\r\n```python\r\n'pandas_on_spark': [\r\n    'pandas>=%s' % _minimum_pandas_version,\r\n    'pyarrow>=%s', % _minimum_pyarrow_version,\r\n]\r\n```",
        "createdAt" : "2021-04-30T01:49:02Z",
        "updatedAt" : "2021-04-30T17:05:43Z",
        "lastEditedBy" : "c13f1277-0254-494b-8e7a-bd7c261b2e9f",
        "tags" : [
        ]
      },
      {
        "id" : "03a6a754-d014-4531-bc68-9aa247875c0a",
        "parentId" : "1ba6e337-9298-486c-8b1c-659df671b1af",
        "authorId" : "8194e9fe-1d06-4199-937e-9633d15a18cb",
        "body" : "Sounds good.",
        "createdAt" : "2021-04-30T16:58:13Z",
        "updatedAt" : "2021-04-30T17:05:43Z",
        "lastEditedBy" : "8194e9fe-1d06-4199-937e-9633d15a18cb",
        "tags" : [
        ]
      }
    ],
    "commit" : "f8a08202ea7b5478a31e61468c6f83c24cb3e77c",
    "line" : 17,
    "diffHunk" : "@@ -1,1 +264,268 @@            'sql': [\n                'pandas>=%s' % _minimum_pandas_version,\n                'pyarrow>=%s' % _minimum_pyarrow_version,\n            ],\n            'pandas_on_spark': ["
  },
  {
    "id" : "279b3d9b-1288-4bb1-86f0-5d117aec63d7",
    "prId" : 31028,
    "prUrl" : "https://github.com/apache/spark/pull/31028#pullrequestreview-561579394",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "79f8c4f9-2239-4e29-9da0-c067c3bba805",
        "parentId" : null,
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Why also change SPARK_VERSION -> PYSPARK_VERSION here? Is it related to PYSPARK_HADOOP_VERSION?",
        "createdAt" : "2021-01-05T07:55:01Z",
        "updatedAt" : "2021-01-05T07:55:01Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "3ef24d04-b71c-4ab4-881a-89e34a068f62",
        "parentId" : "79f8c4f9-2239-4e29-9da0-c067c3bba805",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "`SPARK_VERSION` is just for testing purpose and I just simply thought it's good to make it consistent ;-).. the env `SPARK_VERSION` can be likely conflicted with something else anyway.",
        "createdAt" : "2021-01-05T07:57:36Z",
        "updatedAt" : "2021-01-05T07:57:37Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "e1624f56-595d-44b6-946c-6d24b77a5bdb",
        "parentId" : "79f8c4f9-2239-4e29-9da0-c067c3bba805",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "As we use variable names `spark_version` in many places, is it good to change to `PYSPARK_VERSION` here?",
        "createdAt" : "2021-01-05T07:58:08Z",
        "updatedAt" : "2021-01-05T07:58:08Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "52ab4b9f-7731-4068-b5ed-99913c63af15",
        "parentId" : "79f8c4f9-2239-4e29-9da0-c067c3bba805",
        "authorId" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "body" : "Oh, okay.",
        "createdAt" : "2021-01-05T07:59:17Z",
        "updatedAt" : "2021-01-05T07:59:17Z",
        "lastEditedBy" : "5e28de51-305c-4276-b3a0-78bcc74eb6f2",
        "tags" : [
        ]
      },
      {
        "id" : "ae79179a-b499-4089-beaa-9049b771d098",
        "parentId" : "79f8c4f9-2239-4e29-9da0-c067c3bba805",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "I think it's okay. It's same for `hadoop_version` and `hive_version` too. I don't mind changing it back if you feel strongly. This is just for internal and testing purpose.",
        "createdAt" : "2021-01-05T08:01:07Z",
        "updatedAt" : "2021-01-05T08:01:08Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "e764a7a3da81a8dda6510869bc4711d831edbbd3",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +127,131 @@\n        if (\"PYSPARK_HADOOP_VERSION\" in os.environ) or (\"PYSPARK_HIVE_VERSION\" in os.environ):\n            # Note that PYSPARK_VERSION environment is just a testing purpose.\n            # PYSPARK_HIVE_VERSION environment variable is also internal for now in case\n            # we support another version of Hive in the future."
  },
  {
    "id" : "0e34499a-92d1-489c-8360-818793966d96",
    "prId" : 29686,
    "prUrl" : "https://github.com/apache/spark/pull/29686#pullrequestreview-484464920",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "576dd9da-7748-4757-8d4c-892b0740c6cd",
        "parentId" : null,
        "authorId" : "43998e22-6c2f-401d-9914-8cecf6fad929",
        "body" : "üëç ",
        "createdAt" : "2020-09-08T20:20:25Z",
        "updatedAt" : "2020-09-09T18:18:52Z",
        "lastEditedBy" : "43998e22-6c2f-401d-9914-8cecf6fad929",
        "tags" : [
        ]
      }
    ],
    "commit" : "1cf7db18ce4f0ee94410298ad6baf460bd912dc5",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +97,101 @@        sys.exit(-1)\n\n# If you are changing the versions here, please also change ./python/pyspark/sql/pandas/utils.py\n# For Arrow, you should also check ./pom.xml and ensure there are no breaking changes in the\n# binary format protocol with the Java version, see ARROW_HOME/format/* for specifications."
  },
  {
    "id" : "8fe5f4ed-9ef5-4384-a9ff-1b159e0a3143",
    "prId" : 29180,
    "prUrl" : "https://github.com/apache/spark/pull/29180#pullrequestreview-497025722",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "9223706d-4eee-468c-8ed5-2bf61aca9050",
        "parentId" : null,
        "authorId" : "981b170c-729a-429c-b115-0350ea50b32b",
        "body" : "I don't think it is required",
        "createdAt" : "2020-09-26T19:42:52Z",
        "updatedAt" : "2020-09-26T19:47:56Z",
        "lastEditedBy" : "981b170c-729a-429c-b115-0350ea50b32b",
        "tags" : [
        ]
      }
    ],
    "commit" : "2af1250e02b6debdf31409f2a356a1aa3dbee7d9",
    "line" : 6,
    "diffHunk" : "@@ -1,1 +30,34 @@    sys.exit(-1)\n\nVERSION = __version__  # type: ignore  # noqa\n# A temporary path so we can access above the Python project root and fetch scripts and jars we need\nTEMP_PATH = \"deps\""
  },
  {
    "id" : "63f7e105-bf4b-44d9-9482-f3011ec9bc19",
    "prId" : 28469,
    "prUrl" : "https://github.com/apache/spark/pull/28469#pullrequestreview-407112237",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "c368f67a-0f9f-4512-84cf-6c3e63014dab",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "We didn't officially drop Python 2 yet. It should be retained.",
        "createdAt" : "2020-05-07T02:36:22Z",
        "updatedAt" : "2020-05-07T02:36:23Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "1598f67ca16c7c617ae2fe589ba24b91fc0f8ed4",
    "line" : 2,
    "diffHunk" : "@@ -1,1 +-1,3 @@#!/usr/bin/env python3\n\n#"
  },
  {
    "id" : "6e05d21b-35ff-467e-ab49-5d91c9b6ec39",
    "prId" : 27376,
    "prUrl" : "https://github.com/apache/spark/pull/27376#pullrequestreview-349828725",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "3a609235-3ccd-4429-a4d5-ff60497de05a",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Yea, I think PyPi renders md files fine without rst.",
        "createdAt" : "2020-01-29T01:53:05Z",
        "updatedAt" : "2020-01-30T05:19:12Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "b4e200bc-401e-4386-910b-c17a29f30e10",
        "parentId" : "3a609235-3ccd-4429-a4d5-ff60497de05a",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "@nchammas, can we remove here too:\r\n\r\nhttps://github.com/apache/spark/blob/04e99c1e1b29b691a8fb51ecfcd7e99482ee0bb3/dev/run-pip-tests#L88",
        "createdAt" : "2020-01-29T01:54:49Z",
        "updatedAt" : "2020-01-30T05:19:12Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "e3e54b36-b606-4f5e-9183-1abdb21ab2bc",
        "parentId" : "3a609235-3ccd-4429-a4d5-ff60497de05a",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "We should remove here too https://github.com/apache/spark/blob/master/dev/create-release/spark-rm/Dockerfile#L37\r\n\r\nwith the comment https://github.com/apache/spark/blob/master/dev/create-release/spark-rm/Dockerfile#L23",
        "createdAt" : "2020-01-29T02:22:28Z",
        "updatedAt" : "2020-01-30T05:19:12Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "98e0a31c37c6666fa8f5887a5ad98340c968e2e3",
    "line" : 13,
    "diffHunk" : "@@ -1,1 +154,158 @@    scripts.append(\"pyspark/find_spark_home.py\")\n\n    with open('README.md') as f:\n        long_description = f.read()\n"
  },
  {
    "id" : "84b8047a-11d4-4dfd-9ea3-5f713747a745",
    "prId" : 27109,
    "prUrl" : "https://github.com/apache/spark/pull/27109#pullrequestreview-339590628",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "26ba869b-1879-477b-a132-d46aa0632ee3",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Just a question. Is this `avro` change required in this Pandas refactoring PR?",
        "createdAt" : "2020-01-07T22:57:21Z",
        "updatedAt" : "2020-01-07T22:59:31Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "a92cd009-c1ab-4132-bd68-e3ea462ac7c1",
        "parentId" : "26ba869b-1879-477b-a132-d46aa0632ee3",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Ah, no. All packages had to be added and `pyspark.sql.avro` was missing; otherwise, avro package wouldn't be available in PySpark installed by pip. I fixed it together while I am here.",
        "createdAt" : "2020-01-08T00:32:48Z",
        "updatedAt" : "2020-01-08T00:32:48Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "c63c271d95e7864b69ca477c51e4e2d22b7d9029",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +180,184 @@                  'pyspark.ml.param',\n                  'pyspark.sql',\n                  'pyspark.sql.avro',\n                  'pyspark.sql.pandas',\n                  'pyspark.streaming',"
  },
  {
    "id" : "31be072b-2049-4c7a-a880-f91ef1eb3255",
    "prId" : 27109,
    "prUrl" : "https://github.com/apache/spark/pull/27109#pullrequestreview-339593462",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "0e934e78-3de4-49ed-9038-3d6cf3c71799",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Here, I piggyback another fix by adding `pyspark.sql.avro`. See https://github.com/apache/spark/pull/27109/files#r364017167",
        "createdAt" : "2020-01-08T00:43:09Z",
        "updatedAt" : "2020-01-08T00:43:09Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "c63c271d95e7864b69ca477c51e4e2d22b7d9029",
    "line" : 4,
    "diffHunk" : "@@ -1,1 +180,184 @@                  'pyspark.ml.param',\n                  'pyspark.sql',\n                  'pyspark.sql.avro',\n                  'pyspark.sql.pandas',\n                  'pyspark.streaming',"
  }
]