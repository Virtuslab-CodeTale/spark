[
  {
    "id" : "a8210c2c-4105-492d-9595-e73530bfa907",
    "prId" : 29639,
    "prUrl" : "https://github.com/apache/spark/pull/29639#pullrequestreview-483230828",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "536c6fef-2ff9-45f9-b3c1-a165c232f4fc",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "BTW, @itholic is working on documenting local PyCharm setup in another page (at SPARK-32189). We could add a link here once that page is finished.",
        "createdAt" : "2020-09-07T04:12:18Z",
        "updatedAt" : "2020-09-08T01:22:16Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "adcbe4f5f67dac7d7fdccc6fdde5e987aa104863",
    "line" : 38,
    "diffHunk" : "@@ -1,1 +36,40 @@Note that,\n\n- If you are running locally, you can directly debug the driver side via using your IDE without the remote debug feature.\n- *There are many other ways of debugging PySpark applications*. For example, you can remotely debug by using the open source `Remote Debugger <https://www.pydev.org/manual_adv_remote_debugger.html>`_ instead of using PyCharm Professional documented here.\n"
  }
]