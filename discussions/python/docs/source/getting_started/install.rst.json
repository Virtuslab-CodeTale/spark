[
  {
    "id" : "7bdb2fc6-7b36-4119-ac5e-e465b14a1b7a",
    "prId" : 30436,
    "prUrl" : "https://github.com/apache/spark/pull/30436#pullrequestreview-535040050",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "e54bc1f9-2cff-402b-9a15-e765b696dc0c",
        "parentId" : null,
        "authorId" : "43998e22-6c2f-401d-9914-8cecf6fad929",
        "body" : "Awesome!",
        "createdAt" : "2020-11-20T03:04:55Z",
        "updatedAt" : "2020-11-20T03:05:31Z",
        "lastEditedBy" : "43998e22-6c2f-401d-9914-8cecf6fad929",
        "tags" : [
        ]
      }
    ],
    "commit" : "4826a68e73449cbeb4460121ee3496dcf68b2757",
    "line" : 19,
    "diffHunk" : "@@ -1,1 +73,77 @@- ``without``: Spark pre-built with user-provided Apache Hadoop\n- ``2.7``: Spark pre-built for Apache Hadoop 2.7\n- ``3.2``: Spark pre-built for Apache Hadoop 3.2 and later (default)\n\nNote that this installation way of PySpark with/without a specific Hadoop version is experimental. It can change or be removed between minor releases."
  },
  {
    "id" : "d0b61b3f-0093-47da-a53c-6ff72b5608d5",
    "prId" : 29779,
    "prUrl" : "https://github.com/apache/spark/pull/29779#pullrequestreview-492164297",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "7b3c44ae-8adb-4a0f-ab63-b4b3fd362c81",
        "parentId" : null,
        "authorId" : "7694af3d-5af2-4788-8413-c0558915c452",
        "body" : "Is `3.0.0` used because we need to land this to `branch-3.0`?",
        "createdAt" : "2020-09-18T21:09:47Z",
        "updatedAt" : "2020-09-20T01:02:53Z",
        "lastEditedBy" : "7694af3d-5af2-4788-8413-c0558915c452",
        "tags" : [
        ]
      },
      {
        "id" : "fda0b788-cddc-4bf3-8318-a9f3651f1f2d",
        "parentId" : "7b3c44ae-8adb-4a0f-ab63-b4b3fd362c81",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Oh,  I thought I clarified that this is just an example. Let me fix",
        "createdAt" : "2020-09-20T00:55:41Z",
        "updatedAt" : "2020-09-20T01:02:53Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "ccfebbed10b91e6b9d81f5b97e0436769a4c500c",
    "line" : 106,
    "diffHunk" : "@@ -1,1 +104,108 @@.. code-block:: bash\n\n    tar xzvf spark-3.0.0-bin-hadoop2.7.tgz\n\nEnsure the ``SPARK_HOME`` environment variable points to the directory where the tar file has been extracted."
  }
]