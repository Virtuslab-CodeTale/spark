[
  {
    "id" : "4895ae07-e17f-4091-ac70-6722e2d49c42",
    "prId" : 32835,
    "prUrl" : "https://github.com/apache/spark/pull/32835#pullrequestreview-680277892",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "6aeee19f-4e30-48d2-b0a2-c026e523eaa9",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "ditto",
        "createdAt" : "2021-06-10T01:51:48Z",
        "updatedAt" : "2021-06-10T01:51:48Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "b12b6b48586b0e835faee0cdd14a532aa0b8289e",
    "line" : 123,
    "diffHunk" : "@@ -1,1 +206,210 @@\nWhen pandas APIs on Spark Dataframe are converted from Spark DataFrame, it loses the index information, which results in using\nthe default index in pandas APIs on Spark DataFrame. The default index is inefficient in general comparing to explicitly specifying\nthe index column. Specify the index column whenever possible.\n"
  }
]