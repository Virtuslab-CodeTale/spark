[
  {
    "id" : "9c6c9782-ba92-4778-832b-c71204d01e94",
    "prId" : 28256,
    "prUrl" : "https://github.com/apache/spark/pull/28256#pullrequestreview-442257588",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b40771d7-311f-42e0-ae51-a5bada13f4fd",
        "parentId" : null,
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "Hmmm .. can we strip the non-printable characters instead?\r\nRespecting `PYSPARK_DRIVER_PYTHON` falling back to `PYSPARK_PYTHON` is expected. ",
        "createdAt" : "2020-04-20T12:40:36Z",
        "updatedAt" : "2020-07-18T20:38:57Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "bb5b3682-df45-49e4-a6af-5f350f0b0dd1",
        "parentId" : "b40771d7-311f-42e0-ae51-a5bada13f4fd",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "At least I can come up with one way although it's hacky. e.g.)\r\n\r\n```bash\r\na=$(ipython -c \"import sys; print('/User', file=sys.stderr)\" 2>&1 >/dev/null)\r\nls $a\r\n```",
        "createdAt" : "2020-04-20T13:17:15Z",
        "updatedAt" : "2020-07-18T20:38:57Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      },
      {
        "id" : "fcdcfc48-3cc1-4b64-8ab1-e654e8b2db80",
        "parentId" : "b40771d7-311f-42e0-ae51-a5bada13f4fd",
        "authorId" : "8a740af3-140d-4556-a7d5-2ab0ce4c563e",
        "body" : "That's a workaround for `ipython`, but not for `jupyter`, because `jupyter` doesn't support `jupyter find_spark_home.py`. I think `PYSPARK_DRIVER_PYTHON` is more meant for \"frontend\". This fix enables `\r\nPYSPARK_DRIVER_PYTHON=jupyter PYSPARK_DRIVER_PYTHON_OPTS=notebookÂ  pyspark` too.",
        "createdAt" : "2020-04-20T18:09:48Z",
        "updatedAt" : "2020-07-18T20:38:57Z",
        "lastEditedBy" : "8a740af3-140d-4556-a7d5-2ab0ce4c563e",
        "tags" : [
        ]
      },
      {
        "id" : "b9712532-f17c-49e0-ab9a-1954aa405da3",
        "parentId" : "b40771d7-311f-42e0-ae51-a5bada13f4fd",
        "authorId" : "8a740af3-140d-4556-a7d5-2ab0ce4c563e",
        "body" : "Btw,  `PYSPARK_DRIVER_PYTHON`'s falling back to `PYSPARK_PYTHON` happens after `find-spark-home` too: https://github.com/apache/spark/blob/f1fde0cc2272d5c04cf25960be1ebd46001c5354/bin/pyspark#L45",
        "createdAt" : "2020-04-20T18:15:04Z",
        "updatedAt" : "2020-07-18T20:38:57Z",
        "lastEditedBy" : "8a740af3-140d-4556-a7d5-2ab0ce4c563e",
        "tags" : [
        ]
      },
      {
        "id" : "dfb56a87-752d-44ac-9877-251714555d86",
        "parentId" : "b40771d7-311f-42e0-ae51-a5bada13f4fd",
        "authorId" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "body" : "@mzhang-code, can we just add a bandaid fix like: if `PYSPARK_DRIVER_PYTHON` ends with `jupyter` or `ipython`, uses `PYSPARK_PYTHON` or `python` for now with some comments about why we're using `PYSPARK_PYTHON` instead of `PYSPARK_DRIVER_PYTHON`?",
        "createdAt" : "2020-07-03T08:55:34Z",
        "updatedAt" : "2020-07-18T20:38:57Z",
        "lastEditedBy" : "5e07d5ab-b4b3-41e4-beca-fefd635980c6",
        "tags" : [
        ]
      }
    ],
    "commit" : "4376ae70c76de52bc141e6278473ad8879692ca6",
    "line" : 8,
    "diffHunk" : "@@ -1,1 +35,39 @@  # We are pip installed, use the Python script to resolve a reasonable SPARK_HOME\n  # Default to standard python interpreter unless told otherwise\n  export SPARK_HOME=$(${PYSPARK_PYTHON:-\"python\"} \"$FIND_SPARK_HOME_PYTHON_SCRIPT\")\nfi"
  }
]