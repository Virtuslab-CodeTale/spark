[
  {
    "id" : "e7edfb40-25ef-4931-9a1b-6579e359249e",
    "prId" : 31827,
    "prUrl" : "https://github.com/apache/spark/pull/31827#pullrequestreview-615764801",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "b7b14581-9c78-4f74-9269-e2c1267f6af8",
        "parentId" : null,
        "authorId" : "2d8ced12-ada1-43e1-9240-bf1c11a01e4c",
        "body" : "ditto ?",
        "createdAt" : "2021-03-18T06:27:53Z",
        "updatedAt" : "2021-04-03T01:58:58Z",
        "lastEditedBy" : "2d8ced12-ada1-43e1-9240-bf1c11a01e4c",
        "tags" : [
        ]
      },
      {
        "id" : "e22feecb-2de6-4483-8bd6-127e89220673",
        "parentId" : "b7b14581-9c78-4f74-9269-e2c1267f6af8",
        "authorId" : "dc906849-022d-4a32-8e1f-e2d629f953d0",
        "body" : "Fixed.",
        "createdAt" : "2021-03-18T18:59:37Z",
        "updatedAt" : "2021-04-03T01:58:58Z",
        "lastEditedBy" : "dc906849-022d-4a32-8e1f-e2d629f953d0",
        "tags" : [
        ]
      }
    ],
    "commit" : "b60ba7e2f749b331d9649ce1806a81a36b8eced3",
    "line" : 52,
    "diffHunk" : "@@ -1,1 +289,293 @@    val df4 = spark.read.options(Map(\"delimiter\"->\";\", \"header\"->\"true\")).csv(path)\n\n    // \"output\" is a folder which contains multiple csv files and a _SUCCESS file.\n    df3.write.csv(\"output\")\n"
  }
]