[
  {
    "id" : "1ec0d6ed-de54-4aad-98c0-324d3ffc38b0",
    "prId" : 29111,
    "prUrl" : "https://github.com/apache/spark/pull/29111#pullrequestreview-448445918",
    "prSource" : "GitHub",
    "comments" : [
      {
        "id" : "564afd9d-84fc-49e5-beb3-e0681a79d270",
        "parentId" : null,
        "authorId" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "body" : "Not quite sure why, but a few calls to `reduceByKey` didn't like the existing syntax in 2.13. I had to break out a typed method. `missing parameter type for expanded function`",
        "createdAt" : "2020-07-14T20:36:24Z",
        "updatedAt" : "2020-07-15T17:00:12Z",
        "lastEditedBy" : "707cf6e1-750c-4aea-8774-f79c13fb7add",
        "tags" : [
        ]
      }
    ],
    "commit" : "6390b6c46f5bf35e0c92b140bfbe12f98c35cd8f",
    "line" : 5,
    "diffHunk" : "@@ -1,1 +83,87 @@      val closest = data.map (p => (closestPoint(p, kPoints), (p, 1)))\n\n      val pointStats = closest.reduceByKey(mergeResults)\n\n      val newPoints = pointStats.map {pair =>"
  }
]